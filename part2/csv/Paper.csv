paper_id,title,abstract,date_published,url
346,On a conjecture related to geometric routing,,2004-07-16,https://www.semanticscholar.org/paper/90300646c319d9a798ab55a07562b17610c0e269,Theoretical Computer Science
3327,Population Dynamics of a Reintroduced Asiatic Wild Ass (Equus Hemionus) Herd,"Reintroduction is the release of animals into an area where they were extir- pated or have significantly declined. Little is known about the factors that determine the success or failure of ungulate reintroduction. We studied the dynamics of a reintroduced Asiatic wild ass (Equus hemionus) population for 10 yr (1983-1993) following the first successful release into the wild. A total of 14 adult females and 14 adult males were released into a nature reserve in the Negev Desert of southern Israel. Over this 10-yr span the female population has grown to only 16 adults. Reproductive success of reintroduced females was low in the first 5 yr following release (0.0-0.8 foals.female-l yr-'), but increased to 0.5- 1.0 foals-female-1'yr-' in the last 5 yr. Reproductive success of wild-born females -3 yr old was higher than that of reintroduced females of similar ages, and ranged from 0.5-1.0 foals female'-lyr-1. Our study and data from the E. hem.ionus studbook suggest that young nonprimiparous females produced primarily males, while primiparous and old females produced primarily females. We attribute the low reproductive success following reintro- duction to the stress caused by capture, transport, and release procedures; we consider the age-dependent progeny sex ratio within the framework of Trivers and Willard's (1973) maternal allocation hypothesis. We conclude that the slow growth of the female population was due to: (a) low reproductive success of females in the early years following reintro- duction, and (b) a male-skewed progeny sex ratio among prime-aged reintroduced females. A simple stochastic Leslie matrix model suggests that high survival and improved repro- ductive success of reintroduced females at later stages of the study, and the reproductive success of wild-born females, make the population relatively unsusceptible to extinction from random demographic processes. In-depth knowledge of the dynamics of reintroduced populations is vital for the correct assessment of their viability. We offer suggestions for increasing the efficacy of future wild ass reintroductions.",1995-05-01,https://www.semanticscholar.org/paper/2e4d8fa7ab4b38f37cca2b79fa34a54daa6c9f31,
2789,A monocyte-keratinocyte-derived co-culture assay accurately identifies efficacies of BET inhibitors as therapeutic candidates for psoriasiform dermatitis.,,2020-08-15,https://www.semanticscholar.org/paper/a564638f5a22aadcb253481962933351656294f7,Journal of dermatological science (Amsterdam)
3601,A concept design (Rev. 1),"We describe a design of “concepts” (a type system for types) for improved support of generic programming in C++. This paper presents a current best-effort design based on previous work followed by lengthy discussions of technical details. The design is based on the principles that simple things should be simple (whereas more advanced programming techniques may require some extra work), that there should be no performance degradation compared to current template techniques, and that essentially all current template techniques should be improved by the use of concepts. The design achieves perfect checking of separately compiled templates at the cost of minor restrictions on the instantiation mechanism.",,https://www.semanticscholar.org/paper/2fc5ef95c9c6286167552cf6a94c81f9cff0b4d7,
2158,"Neutrophils form extracellular traps in response to Opisthorchis viverrini crude antigens, which are elevated in neutrophils from opisthorchiasis patients with hepatobiliary abnormalities","ABSTRACT Opisthorchis viverrini (Ov) infection can cause several disease conditions of the bile duct including hepatobiliary abnormalities (HBAs) and the most severe, cholangiocarcinoma (CCA). Fibrosis occurs when tissues are damaged and normal wound-healing responses are dysregulated. Neutrophils are the first cells to migrate to an infection site to protect the host from intruding extracellular pathogens through a wide range of effector mechanisms such as phagocytosis, production of reactive oxygen species, proteases, or release of neutrophil extracellular traps (NETs). In this work, we used confocal microscopy to assess whether Ov crude antigens can cause release of NETs from neutrophils from Ov-free individuals. We demonstrated for the first time that these antigens could induce release of NETs ex vivo in a dose-dependent manner from neutrophils isolated from Ov-free individuals. Intriguingly, when we measured NETs from neutrophils isolated from Ov-infected patients, we found increased spontaneous production of NETs in patients with HBAs. Interestingly, exposure to Ov crude antigens lowered the level of NETs released by neutrophils from patients with active Ov infection regardless of HBA status. We propose that in the case of acute Ov infection, even when concentration of Ov antigens is relatively low, neutrophils can form NETs. However, when this infection becomes chronic, manifesting as a definite HBA, the levels of NET production are reduced when treated with Ov crude antigens. Excessive production of proinflammatory mediators from these NETs might have effects on the parasites, but may also lead to excessive injury of surrounding tissues resulting in HBAs and may lead eventually to the most severe complications such as CCA.",2023-07-26,https://www.semanticscholar.org/paper/14e5adb5f91f22d64b86845a001bc48fed8a98ce,Biology Open
764,Recursive Concurrent Stochastic Games,"We study Recursive Concurrent Stochastic Games (RCSGs), extending our recent analysis of recursive simple stochastic games [14, 15] to a concurrent setting where the two players choose moves simultaneously and independently at each state. For multi-exit games, our earlier work already showed undecidability for basic questions like termination, thus we focus on the important case of single-exit RCSGs (1-RCSGs) 
 
We first characterize the value of a 1-RCSG termination game as the least fixed point solution of a system of nonlinear minimax functional equations, and use it to show PSPACE decidability for the quantitative termination problem. We then give a strategy improvement technique, which we use to show that player 1 (maximizer) has e-optimal randomized Stackless & Memoryless (r-SM) strategies, while player 2 (minimizer) has optimal r-SM strategies. Thus, such games are r-SM-determined. These results mirror and generalize in a strong sense the randomized memoryless determinacy results for finite stochastic games, and extend the classic Hoffman-Karp [19] strategy improvement approach from the finite to an infinite state setting. The proofs in our infinite-state setting are very different however 
 
We show that our upper bounds, even for qualitative termination, can not be improved without a major breakthrough, by giving two reductions: first a P-time reduction from the long-standing square-root sum problem to the quantitative termination decision problem for finite concurrent stochastic games, and then a P-time reduction from the latter problem to the qualitative termination problem for 1-RCSGs",2006-07-10,https://www.semanticscholar.org/paper/aed9b30a7110548d71186b8c5c0ab86bb3c6a311,Log. Methods Comput. Sci.
2553,Content-aware layout,"We describe content-aware layout (CAL), a technique that automatically arranges windows on a user.s desktop. Unlike conventional window managers that automatically cascade or tile each window without regard to its content, CAL uses information about the contents of windows to help decide if and where they should be placed. We present the approach to designing CAL, as well as its implementation. We then conclude with a discussion about future work and CAL.s potential use in large display environments.",2007-04-28,https://www.semanticscholar.org/paper/17997b04f3c02db4d634fd2418812db0c2a22f92,CHI Extended Abstracts
174,Sex: The power of randomization.,,2019-10-01,https://www.semanticscholar.org/paper/9ffb06970cd9b71fe590e26fea287129b0477c3d,Theoretical Population Biology
2352,Inhibition of myeloperoxidase by salicylhydroxamic acid.,"Salicylhydroxamic acid inhibited the luminol-dependent chemiluminescence of human neutrophils stimulated by phorbol 12-myristate 13-acetate or the chemotactic peptide N-formylmethionyl-leucyl-phenylalanine (fMet-Leu-Phe). This compound had no inhibitory effect on the kinetics of O2.- generation or O2 uptake during the respiratory burst, but inhibited both the peroxidative activity of purified myeloperoxidase and the chemiluminescence generated by a cell-free myeloperoxidase/H2O2 system. The concentration of salicylhydroxamic acid necessary for complete inhibition of myeloperoxidase activity was 30-50 microM (I50 values of 3-5 microM) compared with the non-specific inhibitor NaN3, which exhibited maximal inhibition at 100-200 microM (I50 values of 30-50 microM). Whereas taurine inhibited the luminol chemiluminescence of an H2O2/HOC1 system by HOC1 scavenging, this compound had little effect on myeloperoxidase/H2O2-dependent luminol chemiluminescence; in contrast, 10 microM-salicylhydroxamic acid did not quench HOC1 significantly but greatly diminished myeloperoxidase/H2O2-dependent luminol chemiluminescence, indicating that its effects on myeloperoxidase chemiluminescence were largely due to peroxidase inhibition rather than non-specific HOC1 scavenging. Salicylhydroxamic acid prevented the formation of myeloperoxidase Compound II, but only at low H2O2 concentrations, suggesting that it may compete for the H2O2-binding site on the enzyme. These data suggest that salicylhydroxamic acid may be used as a potent inhibitor to delineate the function of myeloperoxidase in neutrophil-mediated inflammatory events.",1989-03-15,https://www.semanticscholar.org/paper/15d4ba3c7f1d0b738a97a74c8174a26771ef9da0,Biochemical Journal
3628,Language-technical aspects of reuse,"Reuse happens only when a variety of social conditions are favorable. However, social conditions, development processes, and design methods alone cannot guarantee success. In the end, working code must be produced, and at this stage programming languages and programming styles can make a critical difference. The paper focuses on C++ and its use because that's where the author's experience is, and because reuse in the abstract is a sterile exercise. To yield its obvious benefits, reuse must be practised. Reuse is a result of good design; it is not something you get from simple minded use of special language features. The paper presents examples of how designs of components for use in several contexts can be expressed directly and efficiently in C++. Concrete types, abstract classes, class hierarchies, and generic programming using templates are mentioned.",1996-04-23,https://www.semanticscholar.org/paper/80f17151348d458fef29b2b2a54c90381caeba1d,Proceedings of Fourth IEEE International Conference on Software Reuse
580,Two remarks on the power of counting,,1983-01-05,https://www.semanticscholar.org/paper/56c02b7ae0dbd215b0fc1cfd218ad544dc02ef7c,Theoretical Computer Science
1250,Dark matter detection with cryogenic detectors,"Direct detection of dark matter in the form of Weakly-Interacting Massive Particles (WIMPS) is an active field of research. Cryogenic detectors have been in the forefront of the field, due to their exquisite ability to reject backgrounds from interactions of normal matter. In this paper, I describe the current status and future prospects for such experiments.",2008-07-01,https://www.semanticscholar.org/paper/bb362b42ba45af68460dda0644743992f2219170,
216,Locally Adaptive Optimization: Adaptive Seeding for Monotone Submodular Functions,"The Adaptive Seeding problem is an algorithmic challenge motivated by influence maximization in social networks: One seeks to select among certain accessible nodes in a network, and then select, adaptively, among neighbors of those nodes as they become accessible in order to maximize a global objective function. More generally, adaptive seeding is a stochastic optimization framework where the choices in the first stage affect the realizations in the second stage, over which we aim to optimize. Our main result is a (1 -- 1/e)2-approximation for the adaptive seeding problem for any monotone submodular function. While adaptive policies are often approximated via non-adaptive policies, our algorithm is based on a novel method we call locally-adaptive policies. These policies combine a non-adaptive global structure, with local adaptive optimizations. This method enables the (1 -- 1/e)2-approximation for general monotone submodular functions and circumvents some of the impossibilities associated with non-adaptive policies. We also introduce a fundamental problem in submodular optimization that may be of independent interest: given a ground set of elements where every element appears with some small probability, find a set of expected size at most k that has the highest expected value over the realization of the elements. We show a surprising result: there are classes of monotone submodular functions (including coverage) that can be approximated almost optimally as the probability vanishes. For general monotone submodular functions we show via a reduction from P lanted -C lique that approximations for this problem are not likely to be obtainable. This optimization problem is an important tool for adaptive seeding via non-adaptive policies, and its hardness motivates the introduction of locally-adaptive policies we use in the main result.",2015-07-09,https://www.semanticscholar.org/paper/2d0a8afb099cbd1afb8d4635d4fd0813f94cf4f8,ACM-SIAM Symposium on Discrete Algorithms
1951,A Framework for Root Cause Detection of Sub-Batch Processing System for Semiconductor Manufacturing Big Data Analytics,"Root cause detecting and rapid yield ramping for advanced technology nodes are crucial to maintain competitive advantages for semiconductor manufacturing. Since the data structure is increasingly complicated in a fully automated wafer fabrication facility, it is difficult to diagnose the whole production system for fault detection. A number of approaches have been proposed for fault diagnosis and root cause detection. However, many constraints in real settings restrict the usage of conventional approaches, due to the big data with complicated data structure. In particular, a batch may not be considered as a run in the present sub-batch processing system for wafer fabrication, in which the processing paths of the wafers in a batch could be different. Motivated by realistic needs, this paper aims to develop a root cause detection framework for the sub-batch processing system. Briefly, the proposed framework consists of three phases: data preparation, data dimension reduction, and the sub-batch processing model construction and evaluation. The proposed approach has been validated by a sequence of simulations and an empirical study conducted in a leading semiconductor manufacturing company in Taiwan. The results have shown practical viability of the proposed approach. Indeed, the developed approach is incorporated in the engineering data analysis system in this case company.",2014-09-09,https://www.semanticscholar.org/paper/0baf6e977362cc537010d76d50613051c5c1d6c5,IEEE transactions on semiconductor manufacturing
3038,A measurement study of google play,"Although millions of users download and use third-party Android applications from the Google Play store, little information is known on an aggregated level about these applications. We have built PlayDrone, the first scalable Google Play store crawler, and used it to index and analyze over 1,100,000 applications in the Google Play store on a daily basis, the largest such index of Android applications. PlayDrone leverages various hacking techniques to circumvent Google's roadblocks for indexing Google Play store content, and makes proprietary application sources available, including source code for over 880,000 free applications. We demonstrate the usefulness of PlayDrone in decompiling and analyzing application content by exploring four previously unaddressed issues: the characterization of Google Play application content at large scale and its evolution over time, library usage in applications and its impact on application portability, duplicative application content in Google Play, and the ineffectiveness of OAuth and related service authentication mechanisms resulting in malicious users being able to easily gain unauthorized access to user data and resources on Amazon Web Services and Facebook.",2014-06-16,https://www.semanticscholar.org/paper/a58b4e6528a9c2698edd45ac1e16e017b82143b8,Measurement and Modeling of Computer Systems
2282,Microbial Cell Wall Oligomannan Inhibits Neutrophil Chemiluminescence: A Possible Mechanism for Granuloma Formation in Crohn's Disease?,,2002-03-01,https://www.semanticscholar.org/paper/cb3dcef44880424bf196ceef6795ee6f1a67561d,
929,Issues of correctness in database concurrency control by locking,"Our aim in this paper is to show that there is a mathematically inherent reason why existing systems enforce D-serializability (rather than just because of its simplicity): it is because they are based on locking. Our main result is a characterization of the power of locking which states that if a locking policy is safe then it must allow only D-serializable schedules. Furthermore any such schedule can be produced by some safe locking policy.
 The rest of the paper is organized as follows. In Section 2 we formalize our concepts and describe the model. In Section 3 we characterize D-serializability in semantic terms. In Section 4 we examine when a set of transactions can be let to run safely by themselves without locking or any intervention from the scheduler. Section 5 is concerned with locking policies and in Section 6 we discuss some implications of our results.",1981-05-11,https://www.semanticscholar.org/paper/fa87e502eb71cf480a25602354704c89af8d6ce1,Symposium on the Theory of Computing
395,Algorithmic aspects of protein folding and protein structure similarity,"In this dissertation, we study two important computational biological problems inspired by the structures of proteins. The first is the protein folding problem. The object of this problem is to determine a protein's structure given its linear amino acid sequence. We consider a widely-accepted model of protein folding, the two-dimensional hydrophobichydrophilic model, which was formulated by Dill in 1990. This model abstracts what is thought to be the dominant force in protein folding, that hydrophobic amino acids tend to cluster together in order to avoid exposure to water, and the protein is modelled as a two-dimensional self-avoiding walk in the square lattice. This model was proposed as an ultimate simplification of protein folding. We answer the open question of the protein folding problem's tractability in this model by proving it is NP-hard. 
The second problem, protein structure similarity, focuses on determining a measure of the similarity of two protein structures. We consider the contact map overlap measure, which was formulated by Godzik, Skolnick, and Kolinski in 1993. This measure involves finding an order-preserving mapping between subsets of the protein amino acid sets so that the largest possible number of nearby amino acid pairs, or contacts, is preserved. The study of contact maps, graphs whose edges capture these nearby amino acid pairs, is interesting in itself. We provide polynomial-time algorithms for computing the contact map overlap of special classes of contact maps, including stacks and two new classes called staircases and augmented staircases. Using these algorithms, we derive a 2-approximation algorithm for computing the contact overlap of any two RNA structures. We study contact maps using a self-avoiding walk in the two-dimensional square lattice as a protein model. We prove structural theorems establishing that the contact maps induced by self-avoiding walks can be decomposed into two stacks and one queue, or two augmented staircases and one stack. As a corollary to these theorems, we derive a 3-approximation algorithm for computing the contact map overlap of walks. Finally, we prove that computing contact overlap is NP-complete, even when the contact maps are induced by self-avoiding walks. To our knowledge, this is the first theoretical study of protein structure similarity.",,https://www.semanticscholar.org/paper/7477b57de38b1efa4b1efd3e07c99ac834860436,
782,Compression of Partially Ordered Strings,,2003-09-03,https://www.semanticscholar.org/paper/f430e4abf2ef6447572e23f892e9d78b08247f30,International Conference on Concurrency Theory
1026,Control and locomotion of hydrodynamically coupled rigid spheres,"The coupling interactions between two spherical swimmers in an ideal fluid have known analytic approximations for certain types of motion. We apply these results to produce locomotion and coordination through the actuation of internal masses inside each swimmer. Through control of either both swimmers or one of them, the latter case taking advantage of compliance in the passive swimmer, desired motion along the spheres' line of centers can be achieved. We subsequently treat general 2D motion as a superposition of motion components along and perpendicular to the spheres' line of centers, leading to a derivation of a full model of controlled locomotion and coordination of two spheres in a planar fluid.",2017-05-01,https://www.semanticscholar.org/paper/0e613a415a30ac06a937644bcd070284bd43e4eb,American Control Conference
2285,BCL‐2 family expression in human neutrophils during delayed and accelerated apoptosis,"The human neutrophil spontaneously undergoes apoptosis, but this type of cell death can be delayed or accelerated by a wide variety of agents. There are wide discrepancies in the literature regarding the expression of the Bcl‐2 family of proteins in human neutrophils. Here, we show that A1, Mcl‐1, Bcl‐XL, and Bad are major transcripts in human neutrophils and that levels of these transcripts are cytokine regulated. However, no Bcl‐XL protein was detected in Western blots. Protein levels for the proapoptotic proteins Bad, Bax, Bak, and Bik remained constant during culture, despite changes in the levels of mRNA for these gene products. These proapoptotic proteins were extremely stable, having very long half‐lives. In contrast, A1 and Mcl‐1 transcripts were extremely unstable (with ∼3‐h half‐lives), and Mcl‐1 protein was also subject to rapid turnover. These results indicate that neutrophil survival is regulated by the inducible expression of the short‐lived Mcl‐1 and possibly the A1 gene products. In the absence of their continued expression, these prosurvival gene products are rapidly turned over, and then the activity of the stable death proteins predominates and promotes apoptosis.",2001-11-01,https://www.semanticscholar.org/paper/90865be31e0bd92e2d2866a0f3004d7be598033a,Journal of Leukocyte Biology
1498,ouble parton interactions in 7 + 3 jet events in p p collisions at ^ / s = 1 . 96 TeV,,,https://www.semanticscholar.org/paper/40f365375d0fbafa872da9bf2d792879c7de9567,
1677,Bayesian Nonparametric Models,,,https://www.semanticscholar.org/paper/47658bb25ed3ed76a44b6c4e8ff2e20ded61809e,
1804,Simultaneous image classification and annotation,"Image classification and annotation are important problems in computer vision, but rarely considered together. Intuitively, annotations provide evidence for the class label, and the class label provides evidence for annotations. For example, an image of class highway is more likely annotated with words “road,” “car,” and “traffic” than words “fish,” “boat,” and “scuba.” In this paper, we develop a new probabilistic model for jointly modeling the image, its class label, and its annotations. Our model treats the class label as a global description of the image, and treats annotation terms as local descriptions of parts of the image. Its underlying probabilistic assumptions naturally integrate these two sources of information. We derive an approximate inference and estimation algorithms based on variational methods, as well as efficient approximations for classifying and annotating new images. We examine the performance of our model on two real-world image data sets, illustrating that a single model provides competitive annotation performance, and superior classification performance.",2009-06-20,https://www.semanticscholar.org/paper/7fdf31d5ebdd293b3027e6555e256a936ff5515a,2009 IEEE Conference on Computer Vision and Pattern Recognition
2635,P Information Displays in Ar View Management Information at a Glance______________________________ Visualization Viewpoints Asking for More Information Graphics Accelerator and a Centimeter-level-accurate Real-time-kinematic Global Positioning System and Global Navigation Satellite System (glonass) ,"ersonal digital assistants (PDAs) combined with wireless networking are beginning to let mobile users access the same information they once used only from the office or at home. However, researchers have long realized that it's important not to treat mobile computing simply as a scaled-down version of desktop computing. Rather, mobility has profound consequences for the way in which we use computers. 1 For example, desktop users might concentrate on a computer display for long periods, but mobile users are often mobile because they want to interact with the world around them. Consequently, a common situation when using a PDA to find information about our immediate environment is to continuously switch between looking around and looking at the PDA display. What if we could instead visualize and interact with information directly in the context of our surround-ings? Our research group is exploring how augmented reality 2 (AR) could someday make this possible. AR integrates a complementary virtual world with the physical world—for example, by using head-tracked see-through head-worn displays to overlay graphics on what we see. Instead of looking back and forth between the real world and a PDA, we look directly at the real world and the virtual information overlaid on it. At the heart of this approach is context-aware computing, 3 computing systems that are sensitive to the context in which they operate, ranging from human relationships to physical location. For example, information might be tied to specific locations within a global, Earth-centered, coordinate system. 4 How can we design effective mobile AR user inter-faces? We've been trying to answer this question in part by developing the experimental AR research prototypes we describe here. In AR, as in work on information visu-alization using desktop technologies, the amount of information available can far exceed what a system can legibly display at a given time, necessitating information filtering. Julier et al. 5 have developed information filtering techniques for AR that depend on the user's goals, object importance, and proximity. In the descriptions that follow, we assume that a system can accomplish information filtering of this sort and that our system is displaying everything it should. We're especially interested in how an AR system could provide information at a glance to aid a mobile user exploring an unfamiliar environment. Such a user might be a tourist visiting a foreign city or a native trying to find a building from its address. …",,https://www.semanticscholar.org/paper/a227a27467eae5bdba55f63e2779302099473e2b,
102,Energy Data Collection Project Year 1,"The massive amount of statistical and text data available from Federal Agencies has created a set of daunting challenges to both research and analysis communities. These problems include heterogeneity, size, distribution, and control of terminology. At the Digital Government Research Center we are investigating solutions to three key problems, namely, (1) ontological mappings for terminology standardization; (2) data integration across data bases with high speed query processing; and (3) interfaces for query input and presentation of results. This collaboration between researchers from Columbia University and the Information Sciences Institute of the University of Southern California employs technology developed at both locations, in particular the SENSUS ontology, the SIMS multi-database access planner, the LKB automated dictionary and terminology analysis system, and others. The pilot application targets gasoline data from BLS, EIA, Census, and other agencies.",,https://www.semanticscholar.org/paper/c0596a0978e91fffbb046669e99a1ea33e42fa88,
3066,KVM for ARM,"As ARM CPUs grow in performance and ubiquity across phones, netbooks, and embedded computers, providing virtualization support for ARM-based devices is increasingly important. We present KVM/ARM, a KVM-based virtualization solution for ARM-based devices that can run virtual machines with nearly unmodified operating systems. Because ARM is not virtualizable, KVM/ARM uses lightweight paravirtualization, a script-based method to automatically modify the source code of an operating system kernel to allow it to run in a virtual machine. Lightweight paravirtualization is architecture specific, but operating system independent. It is minimally intrusive, completely automated, and requires no knowledge or understanding of the guest operating system kernel code. By leveraging KVM, which is an intrinsic part of the Linux kernel, KVM/ARM’s code base can be always kept in line with new kernel releases without additional maintenance costs, and can be easily included in most Linux distributions. We have implemented a KVM/ARM prototype based on the Linux kernel used in Google Android, and demonstrated its ability to successfully run nearly unmodified Linux guest operating systems.",,https://www.semanticscholar.org/paper/ff295ed8975c78be41d88455493d261bdb3ee18f,
1053,Bound-free pair production in relativistic nuclear collisions from the NICA to the HE LHC colliders,,2020-06-02,https://www.semanticscholar.org/paper/99482751b565309e528c1f464037729dcc579463,European Physical Journal A
2993,Microstructural evolution of DS CM186LC during creep and thermal exposure,,2000-03-01,https://www.semanticscholar.org/paper/1694fa77ff357c073837aca87687e66bc33d172b,
2353,Role of myeloperoxidase in intracellular and extracellular chemiluminescence of neutrophils.,"Activated polymorphonuclear leucocytes (neutrophils) can generate both intracellular and extracellular luminol dependent chemiluminescence. As luminol dependent chemiluminescence largely measures the activity of the myeloperoxidase-H2O2 system, and as the extracellular activity of this enzyme may be responsible for the tissue damage associated with inflammatory conditions such as rheumatoid arthritis, the aim of this work was to distinguish between intracellular and extracellular chemiluminescence so that the extracellular activity of this enzyme could be evaluated. Azide was used as a non-specific inhibitor of both intracellular and extracellular chemiluminescence, whereas anti-(human myeloperoxidase) IgG was used to inhibit specifically the extracellular activity of myeloperoxidase. Thus this IgG is a useful analytical tool for studying the extracellular activity of the myeloperoxidase-H2O2 system in the pathology of rheumatoid arthritis.",1989-01-01,https://www.semanticscholar.org/paper/4cfa5d1488717e4fbc3ce88c1afb3402919af596,Annals of the Rheumatic Diseases
3634,The design and evolution of C++,,,https://www.semanticscholar.org/paper/1251daa3bb5eaab0316bef252f2bf007e370c573,
704,The Complexity of Finding S-factors in Regular Graphs,"A graph G has an S-factor if there exists a spanning subgraph F of G such that for all v ∈ V : degF (v) ∈ S. The simplest example of such factor is a 1-factor, which corresponds to a perfect matching in a graph. In this paper we study the computational complexity of finding S-factors in regular graphs. Our techniques combine some classical as well as recent tools from graph theory. 2012 ACM Subject Classification Mathematics of computing → Matchings and factors; Theory of computation → Problems, reductions and completeness",,https://www.semanticscholar.org/paper/7d38c50398a8d94af33c3cbd8a7fe4edd9aba1a4,Electron. Colloquium Comput. Complex.
1084,LUX-ZEPLIN (LZ) Technical Design Report,In this Technical Design Report (TDR) we describe the LZ detector to be built at the Sanford Underground Research Facility (SURF). The LZ dark matter experiment is designed to achieve sensitivity to a WIMP-nucleon spin-independent cross section of three times ten to the negative forty-eighth square centimeters.,2017-03-27,https://www.semanticscholar.org/paper/b795d5b3dfc324346e40cac684f856c49248acbb,
2057,Using DEA for relative efficiency analysis of wafer fabrication facilities,"Semiconductor industry is capital-incentive, competitive, and having complicated manufacturing processes. It is essential to utilize resources efficiently to provide products and services for maintaining competitive advantages. Knowing whether the resource is properly utilized is the foundation for future improvements and/or production decision. Due to the disparate units involved, direct evaluation and comparison among the fabs is difficult. This study aims to develop a two-stage model for relative comparison on fabrication operations by adopting data envelopment analysis (DEA). The proposed model clearly defines and differentiates the performance of fab production, and provides an overall performance index while considering different aspects.",2008-10-01,https://www.semanticscholar.org/paper/d3aaad3e8cac28957dc87b3444c6e067d81b06b5,International Symposium on Semiconductor Manufacturing
2903,Predicting residual stress in a 316L electron beam weld joint incorporating plastic properties derived from a crystal plasticity finite element model,,2022-12-01,https://www.semanticscholar.org/paper/4e90bb0f343c0b534d29c8bffc13e9d4a568f2e9,International Journal of Pressure Vessels and Piping
2955,Erratum: Characterization of functional methylomes by next-generation capture sequencing identifies novel disease-associated variants,,2015-07-29,https://www.semanticscholar.org/paper/22f927c037e8d05a685684b8cdab1b4328e57fd4,Nature Communications
2619,A hypermedia authoring tool for augmented and virtual reality,"Most existing hypermedia authoring systems are intended for use on desktop computers. These systems are typically designed for the creation of 2D documents and therefore employ 2D authoring mechanisms. In contrast, authoring systems for nontraditional multimedia/hypermedia experiences for 3D virtual or augmented worlds focus mainly on creating separate media objects and embedding them within the user's surroundings. As a result, linking these media objects to create 3D hypermedia is a tedious manual task. To address this issue, we present an authoring tool for creating and editing linked 3D hypermedia narratives that are interwoven with a wearable computer user's surrounding environment. Our system is designed for use by authors who are not programmers, and allows them to preview their results on a desktop workstation, as well as with an augmented or virtual reality system.",2003-01-01,https://www.semanticscholar.org/paper/69834836ece8f5370b76507902f49356b192772f,New Rev. Hypermedia Multim.
1822,Hierarchical maximum entropy density estimation,"We study the problem of simultaneously estimating several densities where the datasets are organized into overlapping groups, such as a hierarchy. For this problem, we propose a maximum entropy formulation, which systematically incorporates the groups and allows us to share the strength of prediction across similar datasets. We derive general performance guarantees, and show how some previous approaches, such as hierarchical shrinkage and hierarchical priors, can be derived as special cases. We demonstrate the proposed technique on synthetic data and in a real-world application to modeling the geographic distributions of species hierarchically grouped in a taxonomy. Specifically, we model the geographic distributions of species in the Australian wet tropics and Northeast New South Wales. In these regions, small numbers of samples per species significantly hinder effective prediction. Substantial benefits are obtained by combining information across taxonomic groups.",2007-06-20,https://www.semanticscholar.org/paper/4854e506a1b19e6158bce5e5b43697d4aaa1c12a,International Conference on Machine Learning
3217,"Apparent Competition, Lion Predation, and Managed Livestock Grazing: Can Conservation Value Be Enhanced?","Predator restorations often result in apparent competition, where co-occurring prey populations experience asymmetric predation pressure driven by predator preferences. In many rangeland ecosystems, livestock share the landscape with wildlife, including ungulates and the large carnivores that consume them. We examined whether apparent competition reorganized prey communities following restoration of lions (Panthera leo) to a savanna ecosystem, and whether and how livestock management could alter this indirect interaction between lions and their prey. Three lines of evidence supported the hypothesis that Jackson’s hartebeest (Alcelaphus bucelaphus lelwel; an ungulate of conservation concern) are suppressed via lion-mediated apparent competition. First, hartebeest exhibited an Allee effect where they were exposed to lions, but displayed negative density-dependent population growth where they were protected from lions. Second, spatial overlap between plains zebra (Equus burchelli; the primary prey of lions) and hartebeest further exacerbated lion predation on hartebeest. Finally, hartebeest were killed selectively by lions, whereas zebra were killed by lions in proportion to their abundance. We then tested whether glades (nutrient-rich hotspots created by abandoned cattle [Bos indicus] corrals) could be used to manipulate top-down control of hartebeest via their influence on the spatial distribution of zebra. Zebra aggregated at glades, and survival of hartebeest increased with increasing distance from glades, suggesting that corrals may be placed on the landscape away from hartebeest to create spatial refuges from lions. Our findings demonstrate how informed placement of livestock corrals can be used to manipulate the spatial distribution of primary prey (zebra), thereby reducing apparent competition suffered by hartebeest. Our work further provides an example of how integrating apparent competition theory with proactive livestock management can improve conservation efforts in multiple-use landscapes.",,https://www.semanticscholar.org/paper/eda4a9915eaced140eb4376ef59c5b161091720a,Frontiers in Ecology and Evolution
1160,Evidence for the Decay B0s → D(*)sD(*)s and a Measurement of ΔΓCPs/Γs,"We search for the semi-inclusive process B 0 s → D ( * ) s D ( * ) s using 2.8 fb -1 of pp collisions at √s = 1.96 TeV recorded by the DO detector operating at the Fermilab Tevatron Collider. We observe 26.6 ± 8.4 signal events with a significance above background of 3.2 standard deviations yielding a branching ratio of B(B 0 s → D ( * ) s D ( * ) s ) = 0.035 ± 0.010(stat.) ± 0.011(syst.). Under certain theoretical assumptions, these double-charm final states saturate CP-even eigenstates in the B 0 s decays resulting in a width difference of ΔΓ CP s /Γ s = 0.072 ± 0.021(stat.) ± 0.022(syst.).",,https://www.semanticscholar.org/paper/75f3ba46882b88bc2c6a241938cbd6e11a8e7fb5,
1846,Stochastic Block Models of Mixed Membership,"We consider the statistical analysis of a collection of unipartite graphs, i.e., multiple matrices of relations among objects of a single type. Such data arise, for example, in biological settings, collections of author-recipient email, and social networks. In many applications, clustering the objects of study or situating them in a low dimensional space (e.g., a simplex) is only one of the goals of the analysis. Begin able to estimate relational structures among the clusters themselves is often times as important. For example, in biological applications we are interested in estimating how stable protein complexes (i.e., clusters of proteins) interact. To support such integrated data analyses, we develop the family of “stochastic block models of mixed membership”. Our models combine features of mixed-membership models (Erosheva & Fienberg, 2005) and block models for relational data (Holland et al., 1983) in a hierarchical Bayesian framework. We develop a novel “nested” variational inference scheme, which is necessary to successfully perform fast approximate posterior inference in our models of relational data. We present evidence to support our claims, using both synthetic data and biological case study.",,https://www.semanticscholar.org/paper/9b4a7e2d19c531f72bf7d40b4cfa2dbc37496cea,
2011,Manufacturing intelligence for determining machine subgroups to enhance yield in semiconductor manufacturning,"Linewidth control is a critical issue for yield enhancement in semiconductor manufacturing. Most of the existing techniques such as run-to-run control have been developed to control the critical dimension (CD) in photolithography and etching process. However, few studies have addressed the tool behavior that would also affect the result of CD in etching process and the etch bias that is the CD difference between photolithograph and etching process. This study aims to propose a manufacturing intelligence (MI) approach to develop dispatching rules for etching tool in order to reduce the variation of critical dimension measured after etching process and determine the machine subgroups for compensating the etching bias. An empirical study was conducted to estimate the validity of proposed approach and the results showed practical viability of this approach.",2011-12-11,https://www.semanticscholar.org/paper/30208f4b99577c16b6b6dad7d4a25d51808324e8,Online World Conference on Soft Computing in Industrial Applications
1781,Online Learning for Latent Dirichlet Allocation,"We develop an online variational Bayes (VB) algorithm for Latent Dirichlet Allocation (LDA). Online LDA is based on online stochastic optimization with a natural gradient step, which we show converges to a local optimum of the VB objective function. It can handily analyze massive document collections, including those arriving in a stream. We study the performance of online LDA in several ways, including by fitting a 100-topic topic model to 3.3M articles from Wikipedia in a single pass. We demonstrate that online LDA finds topic models as good or better than those found with batch VB, and in a fraction of the time.",2010-12-06,https://www.semanticscholar.org/paper/2d8cbd7370b4ce666edd864e66f83ebf20963516,Neural Information Processing Systems
3192,Body size and digestive system shape resource selection by ungulates: A cross-taxa test of the forage maturation hypothesis.,"The forage maturation hypothesis (FMH) states that energy intake for ungulates is maximised when forage biomass is at intermediate levels. Nevertheless, metabolic allometry and different digestive systems suggest that resource selection should vary across ungulate species. By combining GPS relocations with remotely sensed data on forage characteristics and surface water, we quantified the effect of body size and digestive system in determining movements of 30 populations of hindgut fermenters (equids) and ruminants across biomes. Selection for intermediate forage biomass was negatively related to body size, regardless of digestive system. Selection for proximity to surface water was stronger for equids relative to ruminants, regardless of body size. To be more generalisable, we suggest that the FMH explicitly incorporate contingencies in body size and digestive system, with small-bodied ruminants selecting more strongly for potential energy intake, and hindgut fermenters selecting more strongly for surface water.",2021-07-26,https://www.semanticscholar.org/paper/5386dde0054ad71a7d01a2b30166269a8f35cff2,Ecology Letters
1553,"Causal Inference from Observational Healthcare Data: Implications, Impacts and Innovations",,,https://www.semanticscholar.org/paper/33b7237bd3e9477e2432ce7210e45cfb5866e9f5,American Medical Informatics Association Annual Symposium
926,Properties of acyclic database schemes,"There is a class of database descriptions, involving one “acyclic” join dependency and a collection of functional dependencies, and nothing else, that appears powerful enough to describe most any real-world body of data in relational database terms. Further, this class has many desirable properties. Some properties make operations like updates and the selection of joins to implement a query over a universal relation especially easy. Other properties of interest were studied by other researchers who described the same class in radically different terms, and found desirable properties in their own contexts. It is the purpose of this paper to define the class formally, to give its important properties and the equivalences with the other classes mentioned, and to explain the importance of each property. This paper is intended to summarize the results that will appear in more detail in [FMU] and [BFMY].",1981-05-11,https://www.semanticscholar.org/paper/a758b4bbd0e58f30d18eb8c7cb092e7853c900a3,Symposium on the Theory of Computing
2042,Modeling and a genetic algorithm for semiconductor final test scheduling,"The overall flow of the final test of IC devices can be represented by the job shop model with limited simultaneous multiple resources in which various product mixes, jobs recirculation, uncertain arrival of jobs, and unstable processing times complicate the problem. This study proposes a hybrid approach including a mathematical programming model to optimize the testing job scheduling and an algorithm to specify the machine configuration of each job and allocate specific resources. The results of detailed scheduling can be graphically represented as timetables of testing resources in Gantt charts. Furthermore, a genetic algorithm is also developed to solve the problem in a short time for implementation. The experimental results demonstrated viability of the proposed approach.",,https://www.semanticscholar.org/paper/2ea70a2395791c6fa5202e21f716d24f8185916d,
2389,Cytochrome a620 in Tetrahymena pyriformis. Reactions with carbon monoxide and oxygen at subzero temperatures and photochemical action spectra.,"1. Mitochondria-enriched fractions of the ciliate protozoan Tetrahymena pyriformis ST contained CO-reacting cytochromes b560 and a620. 2. A non-photodissociable oxygen-containing compound of cytochrome a620 was formed in whole cell suspensions at -114 degrees C after photolysis of CO in the presence of 200 microM-O2. 3. Electron transport, indicated by the oxidation of cytochrome a620 and cytochrome c, occurred at temperatures higher than -72 degrees C. 4. Photochemical action spectra for the relief of respiratory inhibition of whole cells by CO obtained by using a liquid dye laser indicate that the only CO-reacting terminal oxidase detectable was cytochrome a620. 5. It is concluded that the alternative electron transport chains in this organism utilize non-cytochrome terminal oxidases.",1982-08-15,https://www.semanticscholar.org/paper/76c74961a7a9c0d93e7b151f4f880df0f6202c78,Biochemical Journal
3218,Contact Calls Facilitate Group Contraction in Free-Ranging Goats (Capra aegagrus hircus),"Many social animal species produce vocalizations believed to facilitate group contraction when one or more group members have become distant. However, the mechanisms underlying this function remain unclear for many species. We examined this question with data on a semi-free ranging group of 16 adult domesticated goats (Capra aegagrus hircus) inhabiting Tsaobis Nature Park, Namibia. All goats wore dataloggers consisting of a GPS and audio recorder for 5-6 hours per day for 10 days, providing continuous data on their geolocations and vocal communication. We found that callers were farther from the group centroid than expected by chance and that call production was associated with the cessation of group expansion and subsequent group contraction. We did not find strong evidence for antiphonal call exchange between distant and core group members. Rather, we found that (i) call production by distant group members is associated with a significant reduction of group movement away from the caller, and (ii) call production by core group members is associated with greater, though not significantly greater, group movement towards the caller. These findings suggest that calls may be used by distant, and potentially core, group members to facilitate the contraction of group spread. Results from our study clarify the mechanisms through which social animals can regulate collective movement behavior and the specific role that vocalizations play in this process.",2019-03-19,https://www.semanticscholar.org/paper/f2162c7cf0a6130d5809d92533264c72bf83faaa,Frontiers in Ecology and Evolution
1511,Posterior Collapse and Latent Variable Non-identifiability,"Variational autoencoders model high-dimensional data by positing low-dimensional latent variables that are mapped through a flexible distribution parametrized by a neural network. Unfortunately, variational autoencoders often suffer from posterior collapse: the posterior of the latent variables is equal to its prior, rendering the variational autoencoder useless as a means to produce meaningful representations. Existing approaches to posterior collapse often attribute it to the use of neural networks or optimization issues due to variational approximation. In this paper, we consider posterior collapse as a problem of latent variable non-identifiability. We prove that the posterior collapses if and only if the latent variables are non-identifiable in the generative model. This fact implies that posterior collapse is not a phenomenon specific to the use of flexible distributions or approximate inference. Rather, it can occur in classical probabilistic models even with exact inference, which we also demonstrate. Based on these results, we propose a class of latent-identifiable variational autoencoders, deep generative models which enforce identifiability without sacrificing flexibility. This model class resolves the problem of latent variable non-identifiability by leveraging bijective Brenier maps and parameterizing them with input convex neural networks, without special variational inference objectives or optimization tricks. Across synthetic and real datasets, latent-identifiable variational autoencoders outperform existing methods in mitigating posterior collapse and providing meaningful representations of the data.",2023-01-02,https://www.semanticscholar.org/paper/0926bffd052d95e54db0ba8b38ca36dd1ec387e8,Neural Information Processing Systems
956,Longitudinal Changes in Layered Retinal Thickness during Axial Elongation in Healthy Myopic Eyes,"서울대학교 의과대학 안과학교실, 서울대학교병원운영 서울특별시보라매병원 안과, 동국대학교 일산병원 안과, 서울대학교병원운영 서울특별시보라매병원 통계학과 Department of Ophthalmology, Seoul National University College of Medicine, Seoul, Korea Department of Ophthalmology, Seoul National University Boramae Medical Center, Seoul, Korea Department of Ophthalmology, Dongguk University Ilsan Hospital, Goyang, Korea Department of Biostatistics, Seoul National University Boramae Medical Center, Seoul, Korea",2021-02-15,https://www.semanticscholar.org/paper/b3f6aa3bbb3ebdba073a4eb918c7727dd2ce617a,
1344,Measurement of the B0s lifetime in the exclusive decay channel B0s-->J/psiphi.,"Using the exclusive decay B0s-->J/psi(mu+mu-)phi(K+K-), we report the most precise single measurement of the B0s lifetime. The data sample corresponds to an integrated luminosity of approximately 220 pb(-1) collected with the D0 detector at the Fermilab Tevatron Collider in 2002-2004. We reconstruct 337 signal candidates, from which we extract the B0s lifetime, tau(B0s)=1.444(+0.098)(-0.090)(stat)+/-0.020(sys) ps. We also report a measurement for the lifetime of the B0 meson using the exclusive decay B0-->J/psi(mu+mu-)K*0(892)(K+pi-). We reconstruct 1370 signal candidates, obtaining tau(B0)=1.473(+0.052)(-0.050)(stat)+/-0.023(sys) ps, and the ratio of lifetimes, tau(B0s)/tau(B0)=0.980(+0.076)(-0.071)(stat)+/-0.003(sys).",,https://www.semanticscholar.org/paper/76abbf33e4a610a0dd467047dd70e24154f46391,Physical Review Letters
1585,Multiple Causes: A Causal Graphical View,"Unobserved confounding is a major hurdle for causal inference from observational data. Confounders---the variables that affect both the causes and the outcome---induce spurious non-causal correlations between the two. Wang & Blei (2018) lower this hurdle with ""the blessings of multiple causes,"" where the correlation structure of multiple causes provides indirect evidence for unobserved confounding. They leverage these blessings with an algorithm, called the deconfounder, that uses probabilistic factor models to correct for the confounders. In this paper, we take a causal graphical view of the deconfounder. In a graph that encodes shared confounding, we show how the multiplicity of causes can help identify intervention distributions. We then justify the deconfounder, showing that it makes valid inferences of the intervention. Finally, we expand the class of graphs, and its theory, to those that include other confounders and selection variables. Our results expand the theory in Wang & Blei (2018), justify the deconfounder for causal graphs, and extend the settings where it can be used.",2019-05-30,https://www.semanticscholar.org/paper/f84ca302bd7ff93fd706c9937676535887a4aef6,arXiv.org
2372,Heavy-metal-induced flavin production by Debaryomyces hansenii and possible connexions with iron metabolism,,1986-12-01,https://www.semanticscholar.org/paper/118524026b9716609c400c6b0f7df4e6d839a880,
3229,Lemur catta- learning and network centrality,,2018-02-23,https://www.semanticscholar.org/paper/a76e3790961f2617ff4c073bab564820895904ae,
1166,Search for Charged Higgs Bosons Decaying into Top and Bott om Quarks in ppCollisions,"We describe a search for production of a charged Higgs boson, qq' → H + , reconstructed in the tb final state in the mass range 180 ≤ M H+ ≤ 300 GeV. The search was undertaken at the Fermilab Tevatron collider with a center-of-mass energy √s = 1.96 TeV and uses 0.9 fb ―1 of data collected with the D0detector. We find no evidence for charged Higgs boson production and set upper limits on the production cross section in the types I, II, and III two-Higgs-doublet models (2HDMs). An excluded region in the (MH + , tanβ) plane for type I 2HDM is presented.",,https://www.semanticscholar.org/paper/8445d66626488277ae635308c1071856b83b254c,
2878,Galectin‐3 expression is induced in cirrhotic liver and hepatocellular carcinoma,"Galectins are a family of β‐galactoside‐binding animal lectins. In particular, a widely studied member galectin‐3, previously designated as ϵBP, CBP35, Mac‐2, L‐29 and L‐34, has been associated with assorted processes such as cell growth, tumor transformation and metastasis. Galectin‐3 is expressed in various tissues and organs but is significantly absent in normal hepatocytes. However, evaluation of patient liver biopsies for galectin‐3 expression resulted in the finding that hepatocellular carcinoma (HCC) frequently expressed significant levels of this lectin (76% immunohistochemically positive). Further investigation revealed that galectin‐3 expression in HCC is independent of whether the patient had prior hepatitis B virus infection: 14 of 18 HCC cases from HBV+ patients, and 5 of 7 cases from HBV− patients demonstrated positive galectin‐3 immunohistochemistry. However, co‐transfection studies using a galectin‐3 promoter construct and an HBV‐X protein (HBV‐X) expression vector demonstrated that galectin‐3 expression can occur through transactivation of the lectin promoter by HBV‐X. Based on presently known properties of this lectin, it is possible that deregulated expression of galectin‐3 can result in tumor transformation and invasiveness, or confer propensity for tumor cell survival. In addition, galectin‐3 was abundantly expressed in cirrhotic liver in peripheral distribution within regenerating nodules. Such galectin‐3 expression in rapidly proliferating hepatocytes in cirrhotic liver may be a result of the high mitotic index. Alternatively, it is possible that proliferating cells expressing galectin‐3 are in the process of being transformed, thus indicating an early neoplastic event. Int. J. Cancer 81:519–526, 1999. © 1999 Wiley‐Liss, Inc.",1999-05-17,https://www.semanticscholar.org/paper/5d5caf6e11b3bc937a674dfb438b1b0c207f30cf,International Journal of Cancer
3727,Listening to Sounds of Silence for Speech Denoising,"We introduce a deep learning model for speech denoising, a long-standing challenge in audio analysis arising in numerous applications. Our approach is based on a key observation about human speech: there is often a short pause between each sentence or word. In a recorded speech signal, those pauses introduce a series of time periods during which only noise is present. We leverage these incidental silent intervals to learn a model for automatic speech denoising given only mono-channel audio. Detected silent intervals over time expose not just pure noise but its time-varying features, allowing the model to learn noise dynamics and suppress it from the speech signal. Experiments on multiple datasets confirm the pivotal role of silent interval detection for speech denoising, and our method outperforms several state-of-the-art denoising methods, including those that accept only audio input (like ours) and those that denoise based on audiovisual input (and hence require more information). We also show that our method enjoys excellent generalization properties, such as denoising spoken languages not seen during training.",2020-10-22,https://www.semanticscholar.org/paper/f1d16d4a122e3a6d6db5e959dad03055e3955444,Neural Information Processing Systems
269,On Learning Algorithms for Nash Equilibria,,2010-10-18,https://www.semanticscholar.org/paper/929988cff413e36c8adec611676cfee0c812fc5f,Algorithmic Game Theory
3347,Resource Acquisition and Alternative Mating Strategies in Water Striders,"Behavioral polymorphisms occur among male and female water striders, Gems remigis , when competing for food and mates. Individuals of both sexes vie for positions in the fastest flowing portions of streams. Here prey capture rates are highest, as are those of swimming and aggression. Only the largest females, and males with the largest first appendages, can regularly maintain positions in these areas. The remaining females are arranged along the flow gradient according to their size with the smallest holding positions in pools of slow moving water. For the remaining males neither overall size, nor the size of the first appendages, appears to determine which males swim near the edge of streams, or which males swim as satellites behind those occupying the fast flowing productive areas. Preliminary data show that mating success of edge and satellite males are about equal, but significantly less than that of the centrally positioned males with the largest first appendages. Thus although it appears that morphological phenotype influences male competitive behavior, when the absolute size of the critical trait is small males adopt behavior after assessing the actions of others. For these “subordinate” males, behavioral assessment appears to produce an “ideal free” spatial distribution.",1984-05-01,https://www.semanticscholar.org/paper/d45f3610bc286b2cbb5a38d4b5292ca3887818eb,
2207,The multifactorial role of neutrophils in rheumatoid arthritis,,2014-10-01,https://www.semanticscholar.org/paper/6f27acb18f2b6c4484740c05fe872e8fa13f1f85,Nature Reviews Rheumatology
1506,Search for single top quark production in pp̄ collisions at √ s = 1 . 96 TeV,We present a search for electroweak production of single top quarks in the s-c annel andt-channel using neural network for signal–background separation. We have analyzed 230 pb −1 of data collected with the DØ detector at the Fermilab Teva Collider at a center-of-mass energy of 1.96 TeV and find no evidence for a single top quark signal. The resulting 95% co level upper limits on the single top quark production cross sections are 6.4 pb in the s-channel and 5.0 pb in the t-channel.  2005 Elsevier B.V. All rights reserved. PACS: 14.65.Ha; 12.15.Ji; 13.85.Qk ltanics diser acn– top dyct,,https://www.semanticscholar.org/paper/bd49093d24d67a2e3a591e3dd6f8c58e0e96d734,
2102,Global Manufacturing Network and Supply Chain Management for the Electronics Industry,"Manufacturing industry is experiencing several fundamental changes. From industrial sector perspectives, in many industries such as home electronics appliance, computer, telecommunication, semiconductor, and even bio-technology, the traditional vertical-integrated company based business model has been dramatically replaced by collaborations between many fragmented but complementary and specialized value stars and value constellations. From geographic perspectives, more and more activities of value creation in manufacturing are reallocated in developing nations, especially in the Far East region where is emerging as a new factory of the world. From business dynamics perspectives, it is interesting to observe that, when some companies are seeking subcontracting or even hollowing-out by positioning themselves to engage with variously final customers directly, at the same time, others are accumulating up the outsourced tasks and sharply focusing on few core capable skills to provide operational service in a very professional way. It is more exciting to understand not only the interactions between original equipment manufacturers (OEMs) and electronics manufacturing service (EMS) providers but also their evolutionary adaptations and even place exchanges. In general, globalization between nations and collaboration between firms are deeply challenging the existing business models and classical concepts such as manufacturing, service, supply chain, and even firm or enterprise. This special issue of the International Journal of Business aims to address the critical issues involved in global manufacturing network by using electronics industry as a reference model. Conceptual models and quantitative analysis methodologies are proposed to deal with wide range of challenges of global manufacturing and supply chain via validation with empirical research and observation in real setting. Within the broad themes, this special issue addresses the following specific topics: * a transformation process from an technology imitator towards a leading innovator, * performance evaluation of research and development, * synchronization of global manufacturing and supply chain, * a new statistical process control methodology for LED industry, and * evaluation of government's semiconductor industry development strategy. This special issue not only covers the different levels of management and decision issues in the global manufacturing network and supply chain but also provides more up-dated management experiences and background from the Far East region where is becoming a more and more important region powering the world economy. The articles provide fresh insights and experiences from the newly developed and developing nations including China, Taiwan, Singapore, and South Korea. From the papers' research and discussions, several key issues and academic agenda have been also arisen. Firstly, global manufacturing network and supply chain is a very complex system. This special issue just explored a very limited part of it. …",2004-09-22,https://www.semanticscholar.org/paper/fd716742726bbab915d4c7bf7d3425e94cd988a4,
2116,A DEA Study to Evaluate the Relative Efficiency and Investigate the District Reorganization of the Taiwan Power Company,In this study data envelopment analysis (DEA) models were applied to evaluate the relative efficiencies of twenty-two electricity distribution districts of the Taiwan Power Company (TPC) in Taiwan. The empirical study showed that the TPC districts have good overall efficiency. We found that eleven districts were inefficient. Most of the inefficient districts suffer from scale inefficiency to a greater degree than technical inefficiency. We suggested the specific improvement directions for the corresponding inefficient districts. This study also investigated district reorganization to increase the efficiency. The proposed district reorganization alternatives have higher efficiency scores than the current one.,2001-02-01,https://www.semanticscholar.org/paper/1a8694264d047279aa0b0ab577935fa38518d1b0,IEEE Power Engineering Review
2298,Activation of Human Neutrophils by Soluble Immune Complexes: Role of FcγRII and FcγRIIIb in Stimulation of the Respiratory Burst and Elevation of Intracellular Ca2+ a,"Activation of control, unprimed neutrophils with soluble immune complexes fails to generate a respiratory burst. However, if the cells are primed with either tumor necrosis factor-alpha or granulocyte-macrophage colony-stimulating factor prior to addition of soluble immune complexes, then a rapid and transient burst of reactive oxidant secretion is observed. In unprimed neutrophils the soluble immune complexes stimulate an intracellular Ca2+ transient that arises from the mobilization of intracellular Ca2+. However, in primed cells, an ""extra"" intracellular Ca2+ signal is observed that arises from Ca2+ influx. After removal of Fc gamma RIIIb by treatment with pronase or PI-PLC, the soluble immune complexes fail to activate a respiratory burst in unprimed neutrophils and the ""extra"" Ca2+ signal is not observed. These results indicate that during priming Fc gamma RIIIb becomes functionally activated and thence its ligation leads to stimulated Ca2+ influx and the generation of intracellular signals that lead to NADPH oxidase activation. Experiments using Fab/F(ab')2 fragments to specifically crosslink either Fc gamma RII or Fc gamma RIIIb and experiments with neutrophils from an individual with Fc gamma RIIIb gene deficiency confirm this important function for Fc gamma RIIIb in neutrophil activation.",1997-12-01,https://www.semanticscholar.org/paper/8b3a2ede6e6c6771312867907338c2c7563dcbaa,
3416,Max-min Fair Rate Allocation and Routing in Energy Harvesting Networks: Algorithmic Analysis,,2014-06-14,https://www.semanticscholar.org/paper/994215e7ebabbb7613b62738fff28c342fb8df14,ACM Interational Symposium on Mobile Ad Hoc Networking and Computing
2404,Oscillations of Respiration and Adenine Nucleotides in Synchronous Cultures of Acanthamoeba castellanii: Mitochondrial Respiratory Control in vivo,"Synchronous cultures of the soil amoeba Acanthamoeba castellanii, prepared by a size selection procedure involving minimum metabolic perturbation, divided with a high degree of synchrony and showed a discrete S-phase of DNA synthesis. Oxygen uptake rates doubled overall during one cell cycle time of 7 to 8 h but rose to seven distinct maxima during this period. Control experiments showed that the selection procedure did not give rise to the oscillations. The maxima of respiration were more sensitive to inhibition by cyanide than were the minima of respiration; the effect of carbonyl cyanide p-trifluoro-methoxyphenylhydrazone (an uncoupler of oxidative phosphorylation) was, however, greater at respiratory minima, than at the maxima. Pool levels of ATP, ADP and AMP also oscillated during the cell cycle with maximum amplitudes (peak-trough, % minimal values) of 108, 194 and 520, respectively. Adenylate charge values varied between 0.63 and 0.88. Respiratory maxima were in phase with maximum ADP levels but out of phase with maxima of ATP/ADP ratios. These results suggest that the overall changes in respiration rates during the cell cycle of A. castellanii are the result of in vivo respiratory control.",1978-10-01,https://www.semanticscholar.org/paper/bd0edd1e24079fcab3ca17a05e25615bc55e1957,
1717,Deep Exponential Families,"We describe \textit{deep exponential families} (DEFs), a class of latent variable models that are inspired by the hidden structures used in deep neural networks. DEFs capture a hierarchy of dependencies between latent variables, and are easily generalized to many settings through exponential families. We perform inference using recent ""black box"" variational inference techniques. We then evaluate various DEFs on text and combine multiple DEFs into a model for pairwise recommendation data. In an extensive study, we show that going beyond one layer improves predictions for DEFs. We demonstrate that DEFs find interesting exploratory structure in large data sets, and give better predictive performance than state-of-the-art models.",2014-11-10,https://www.semanticscholar.org/paper/d6559f35be0679c6b3371a2e44e3be293704b600,International Conference on Artificial Intelligence and Statistics
1279,Lifetime difference and CP-violating phase in the Bs0 system.,"From an analysis of the decay Bs0-->J/psi phi, we obtain the width difference between the light and heavy mass eigenstates DeltaGamma identical with (GammaL-GammaH)=0.17+/-0.09(stat)+/-0.02(syst) ps-1 and the CP-violating phase phis=-0.79+/-0.56(stat)(-0.01)(+0.14)(syst). Under the hypothesis of no CP violation (phis identical with 0), we obtain 1/Gamma=tau(Bs0)=1.52+/-0.08(stat)(-0.03)(+0.01)(syst) ps and DeltaGamma=0.12(-0.10)(+0.08)(stat)+/-0.02(syst) ps-1. The data sample corresponds to an integrated luminosity of about 1.1 fb-1 accumulated with the D0 detector at the Fermilab Tevatron collider. This is the first direct measurement of the CP-violating mixing phase in the Bs0 system.",2007-01-09,https://www.semanticscholar.org/paper/55279c2b8f4813b1f0c617b5cf7fb47978314d63,Physical Review Letters
1872,A Two-stage Multi-population Genetic Algorithm with Heuristics for Workflow Scheduling in Heterogeneous Distributed Computing Environments,"Workflow scheduling in Heterogeneous Distributed Computing Environments (HDCEs) is a NP-hard problem. Although a number of scheduling approaches have been proposed for workflow scheduling in HDCEs, there is still a room and need for improvement. To fill the gaps, this study formulates workflow scheduling problem in HDCEs as a complete, solvable and extensible integer programming mathematical model with precedence and resource constraints that provides a theoretical foundation for developing workflow scheduling strategy. Then, this study develops a novel two-stage multi-population genetic algorithm with heuristics for workflow scheduling. In particular, two-stage multi-population coevolution strategy is employed with designed novel methods for population initialization, genetic operation, individual decoding and improvement. To estimate the validity, extensive experiments are designed and conducted on various scenarios based on real and random workflow applications. The results have shown the practical viability of the proposed algorithm outperforming conventional approaches.",2023-04-01,https://www.semanticscholar.org/paper/df1f1fe84ef007f4c7a1f3d4177c1dd0f2a576fb,IEEE Transactions on Cloud Computing
2128,A recursive computational procedure for container loading,,1998-10-01,https://www.semanticscholar.org/paper/1ea218ef30f3c2665d2e515a65e640081a7a68f0,
2721,AutoVisual: rule-based design of interactive multivariate visualizations,"An extension to the n-Vision visualization system, which provides users with a 3D virtual world within which they can visualize and manipulate representations of multivariate relations is discussed. The extension, AutoVisual, is rule based system that eliminates the difficulty in choosing among the many alternative when designing visualizations. AutoVisual designs interactive virtual worlds for visualizing and exploring multivariate relations. It is guided by user-specified visualization tasks and a rule base of design principles. AutoVisual's visualization techniques and the visualization tasks it handles are described. Example visualizations AutoVisual has generated for two problem domains are discussed.<<ETX>>",1993-07-01,https://www.semanticscholar.org/paper/cbed07b76b3387946ab76c3bce77cab10103bf61,IEEE Computer Graphics and Applications
486,On the Greedy Algorithm for Satisfiability,,1992-08-10,https://www.semanticscholar.org/paper/08addbc01d79d517d44a43bc6cd955d8ef64559e,Information Processing Letters
2022,"A multi-period inventory model to incorporate with inventory age, accounting principle, and product structure: A case study in a make-to-stock semiconductor integrated device manufacturer","Statement of Financial Accounting Standards (SFAS) No.10 has been declared as accounting principle for allowance for reduction of inventory to market in Taiwan since December 31, 2008. It has become more difficult for semiconductor integrated device manufacturers, using make-to-stock manufacturing strategy and possessing inventory accounting for about 14% total costs, to maintain robust records in financial statements. A case company has to write down loss of 2% to 100% of total inventory cost for products with inventory ages of 3 to more than 18 months. However, average cycle times of producing flash memory are about three months. In other words, when system variation and safety stock policy are further taken into account, the company has to write down allowance for reduction of inventory to market for most work-in-process inventory. However, little research has been done with these regards to address practical management of operations according to inventory aging process. Therefore, this study aims to propose a holistic inventory model to incorporate with inventory ages, accounting principles, and product structures (e.g., bill of material) for robust estimation of inventory cost to reduce the impact of carrying value fluctuation of inventory. An empirical study will be conducted in a Taiwanese semiconductor manufacturer.",2010-07-25,https://www.semanticscholar.org/paper/1d55c625917e08250612314a94f0e7d8d8ebe16f,The 40th International Conference on Computers & Indutrial Engineering
227,Simultaneous bayesian auctions and computational complexity,"Bayesian equilibria of simultaneous auctions for individual items have been explored recently [Christodoulou et al. 2008; Bhawalkar and Roughgarden 2011; Hassidim et al. 2011; Feldman et al. 2013] as an alternative to the well-known complexity issues plaguing combinatorial auctions with incomplete information, and some strong positive results have been shown about their performance. We point out some very serious complexity obstacles to this approach: Computing a Bayesian equilibrium in such auctions is hard for PP --- a complexity class between the polynomial hierarchy and PSPACE --- and even finding an approximate such equilibrium is as hard as NP, for some small approximation ratio (additive or multiplicative); therefore, the assumption that such equilibria will be arrived at by rational agents is quite problematic. In fact, even recognizing a Bayesian Nash equilibrium is intractable. Furthermore, these results hold even if bidder valuations are quite benign: Only one bidder valuation in our construction is unit demand or monotone submodular, while all others are additive. We also explore the possibility of favorable price of anarchy results for no-regret dynamics of the Bayesian simultaneous auctions game, and identify complexity obstacles there as well.",2014-06-01,https://www.semanticscholar.org/paper/525477ddf1b6787b816e800d80060871aa776a79,ACM Conference on Economics and Computation
3166,Proceedings of 2000 Usenix Annual Technical Conference Fist: a Language for Stackable File Systems,"Traditional file system development is difficult. Stack-able file systems promise to ease the development of file systems by offering a mechanism for incremental development. Unfortunately, existing methods often require writing complex low-level kernel code that is specific to a single operating system platform and also difficult to port. We propose a new language, FiST, to describe stackable file systems. FiST uses operations common to file system interfaces. From a single description, FiST's compiler produces file system modules for multiple platforms. The generated code handles many kernel details, freeing developers to concentrate on the main issues of their file systems. This paper describes the design, implementation, and evaluation of FiST. We extended file system functionality in a portable way without changing existing kernels. We built several file systems using FiST on Solaris, FreeBSD, and Linux. Our experiences with these examples shows the following benefits of FiST: average code size over other stackable file systems is reduced ten times; average development time is reduced seven times; performance overhead of stacking is 1–2%.",,https://www.semanticscholar.org/paper/ba433e8f1d8672c15196e037c22b549b57ae4079,
3029,"POSIX abstractions in modern operating systems: the old, the new, and the missing","The POSIX standard, developed 25 years ago, comprises a set of operating system (OS) abstractions that aid application portability across UNIX-based OSes. While OSes and applications have evolved tremendously over the last 25 years, POSIX, and the basic set of abstractions it provides, has remained largely unchanged. Little has been done to measure how and to what extent traditional POSIX abstractions are being used in modern OSes, and whether new abstractions are taking form, dethroning traditional ones. We explore these questions through a study of POSIX usage in modern desktop and mobile OSes: Android, OS X, and Ubuntu. Our results show that new abstractions are taking form, replacing several prominent traditional abstractions in POSIX. While the changes are driven by common needs and are conceptually similar across the three OSes, they are not converging on any new standard, increasing fragmentation.",2016-04-18,https://www.semanticscholar.org/paper/33f757edceab3d51979d145b56349f39e99fc2dc,European Conference on Computer Systems
3535,"The C++ Programming Language”, 3rd Edition, Pearson Education, 2007",,2015-01-17,https://www.semanticscholar.org/paper/18e399b8dba7e36e013c6e2d8709845dac55087b,
3289,Immunocontraception in Wild Horses (Equus caballus) Extends Reproductive Cycling Beyond the Normal Breeding Season,"Background Although the physiological effects of immunocontraceptive treatment with porcine zona pellucida (PZP) have been well studied, little is known about PZP's effects on the scheduling of reproductive cycling. Recent behavioral research has suggested that recipients of PZP extend the receptive breeding period into what is normally the non-breeding season. Methodology/Principal Findings To determine if this is the case, we compiled foaling data from wild horses (Equus caballus) living on Shackleford Banks, North Carolina for 4 years pre- and 8 years post-contraception management with PZP (pre-contraception, n = 65 births from 45 mares; post-contraception, n = 97 births from 46 mares). Gestation lasts approximately 11–12 months in wild horses, placing conception at approximately 11.5 months prior to birth. Since the contraception program began in January 2000, foaling has occurred over a significantly broader range than it had before the contraception program. Foaling in PZP recipients (n = 45 births from 27 mares) has consistently occurred over a broader range than has foaling in non-recipients (n = 52 births from 19 mares). In addition, current recipients of PZP foaled later in the year than did prior recipient and non-recipient mares. Females receiving more consecutive PZP applications gave birth later in the season than did females receiving fewer applications. Finally, the efficacy of PZP declined with increasing consecutive applications before reaching 100% after five consecutive applications. Conclusions/Significance For a gregarious species such as the horse, the extension of reproductive cycling into the fall months has important social consequences, including decreased group stability and the extension of male reproductive behavior. In addition, reproductive cycling into the fall months could have long-term effects on foal survivorship. Managers should consider these factors before enacting immunocontraceptive programs in new populations. We suggest minor alterations to management strategies to help alleviate such unintended effects in new populations.",2010-10-26,https://www.semanticscholar.org/paper/2b70ad4e141ba6ef7a8a57a207c25e78bf97e074,PLoS ONE
2751,"Interaction issues in visualization: requirements, techniques, and devices",,1990-10-23,https://www.semanticscholar.org/paper/dd980be7af26fb0336e78c01b4e08329b3b63957,Visual ..
3770,Learning visual biases from human imagination,"Although the human visual system can recognize many concepts under challenging conditions, it still has some biases. In this paper, we investigate whether we can extract these biases and transfer them into a machine recognition system. We introduce a novel method that, inspired by well-known tools in human psychophysics, estimates the biases that the human visual system might use for recognition, but in computer vision feature spaces. Our experiments are surprising, and suggest that classifiers from the human visual system can be transferred into a machine with some success. Since these classifiers seem to capture favorable biases in the human visual system, we further present an SVM formulation that constrains the orientation of the SVM hyperplane to agree with the bias from human visual system. Our results suggest that transferring this human bias into machines may help object recognition systems generalize across datasets and perform better when very little training data is available.",2014-10-17,https://www.semanticscholar.org/paper/480f8aa54b19e7b6b31be09aa2124cb0f159ae9b,Neural Information Processing Systems
106,Evaluating Top-k Selection Queries,"In many applications, users specify target values for certain attributes, without requiring exact matches to these values in return. Instead, the result to such queries is typically a rank of the \top k"" tuples that best match the given attribute values. In this paper, we study the advantages and limitations of processing a top-k query by translating it into a single range query that traditional relational DBMSs can process eciently. In particular, we study how to determine a range query to evaluate a top-k query by exploiting the statistics available to a relational DBMS, and the impact of the quality of these statistics on the retrieval eciency of the resulting scheme.",1999-09-07,https://www.semanticscholar.org/paper/d28cfa4c4d7bf6a86eb754ba6f9f4472cc209418,Very Large Data Bases Conference
347,Selfish caching in distributed systems: a game-theoretic analysis,"We analyze replication of resources by server nodes that act selfishly, using a game-theoretic approach. We refer to this as the selfish caching problem. In our model, nodes incur either cost for replicating resources or cost for access to a remote replica. We show the existence of pure strategy Nash equilibria and investigate the price of anarchy, which is the relative cost of the lack of coordination. The price of anarchy can be high due to undersupply problems, but with certain network topologies it has better bounds. With a payment scheme the game can always implement the social optimum in the best case by giving servers incentive to replicate.",2004-07-25,https://www.semanticscholar.org/paper/a913c03850b031c7b9d5b423a2f1309ff248da1e,ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing
1538,Rationales for Sequential Predictions,"Sequence models are a critical component of modern NLP systems, but their predictions are difficult to explain. We consider model explanations though rationales, subsets of context that can explain individual model predictions. We find sequential rationales by solving a combinatorial optimization: the best rationale is the smallest subset of input tokens that would predict the same output as the full sequence. Enumerating all subsets is intractable, so we propose an efficient greedy algorithm to approximate this objective. The algorithm, which is called greedy rationalization, applies to any model. For this approach to be effective, the model should form compatible conditional distributions when making predictions on incomplete subsets of the context. This condition can be enforced with a short fine-tuning step. We study greedy rationalization on language modeling and machine translation. Compared to existing baselines, greedy rationalization is best at optimizing the sequential objective and provides the most faithful rationales. On a new dataset of annotated sequential rationales, greedy rationales are most similar to human rationales.",2021-09-14,https://www.semanticscholar.org/paper/1c709eef701d933af1383c790c13209f06806b60,Conference on Empirical Methods in Natural Language Processing
741,On the Complexity of Nash Equilibria and Other Fixed Points (Extended Abstract),"We reexamine, what it means to compute Nash equilibria and, more, generally, what it means to compute a fixed point of a given Brouwer function, and we investigate the complexity of the associated problems. Specifically, we study the complexity of the following problem: given a finite game, Gamma, with 3 or more players, and given epsiv > 0, compute a vector x' (a mixed strategy profile) that is within distance e (say in t^) of some (exact) Nash equilibrium. We show that approximation of an (actual) Nash equilibrium for games with 3 players, even to within any non-trivial constant additive factor epsiv < 1/2 in just one desired coordinate, is at least as hard as the long standing square-root sum problem, as well as more general arithmetic circuit decision problems, and thus that even placing the approximation problem in NP would-resolve a major open problem in the complexity of numerical computation. Furthermore, we show that the (exact or approximate) computation of Nash equilibria for 3 or more players is complete for the class of search problems, which we call FIXP, that can be cast as fixed point computation problems for functions represented by algebraic circuits (straight line programs) over basis {+, *, -, /, max, min}, with rational constants. We show that the linear fragment of FIXP equals PPAD. Many problems in game theory, economics, and probability theory, can be cast as fixed point problems for such algebraic functions. We discuss several important such problems: computing the value of Shapley's stochastic games, and the simpler games of Condon, extinction probabilities of branching processes, termination probabilities of stochastic context-free grammars, and of Recursive Markov Chains. We show that for some of them, the approximation, or even exact computation, problem can be placed-in PPAD, while for others, they are at least as hard as the square-root sum and arithmetic circuit decision problems.",2010-03-01,https://www.semanticscholar.org/paper/130eaa0fcdf2c5f27edfb531067fb21602b7dbf4,IEEE Annual Symposium on Foundations of Computer Science
311,Incentive-Compatible Interdomain Routing with Linear Utilities,"We revisit the problem of incentive-compatible interdomain routing, examining the quite realistic special case in which the utilities of autonomous systems (ASes) are linear functions of the traffic in the incident links and the traffic leaving each AS. We show that incentive-compatibility toward maximizing total welfare is achievable efficiently, and in the uncapacitated case, by an algorithm that can be easily implemented by the border gateway protocol (BGP), the standard protocol for interdomain routing.",2007-12-12,https://www.semanticscholar.org/paper/a97409a09d1907235bb8e46524d6ad6fe543978e,Internet Mathematics
2267,Regulation of neutrophil apoptosis.,,2003-05-21,https://www.semanticscholar.org/paper/214ef2528bc1a3ffffac6a2c17e4c484309d8ce5,Chemical Immunology
3322,Leadership in fish shoals,"Leadership is not an inherent quality of animal groups that show directional locomotion. However, there are other factors that may be responsible for the occurrence of leadership in fish shoals, such as individual differences in nutritional state between group members. It appears that front fish have a strong influence on directional shoal movements and that individuals that occupy such positions are often characterised by larger body lengths and lower nutritional state. Potential interactions between the two factors and their importance for positioning within shoals need further attention. Initiation of directional movement in stationary shoals and position preferences in mobile shoals need to be addressed separately because they are potentially subject to different constraints. Individuals that initiate a swimming direction may not necessarily be capable of the sustained high swimming performance required to keep the front position or have the motivation to do so, for that matter. More empirical and theoretical work is necessary to look at the factors controlling positioning behaviour within shoals, as well as overall shoal shape and structure. Tracking of marked individuals whose positioning behaviour is monitored over extended time periods of hours or days would be useful. There is an indication that shoal positions are rotated by individuals according to their nutritional needs, with hungry fish occupying front positions only for as long as necessary to regain their nutritional balance. This suggests that shoal members effectively take turns at being leaders. There is a need for three-dimensional recordings of shoaling behaviour using high-speed video systems that allow a detailed analysis of information transfer in shoals of different size. The relationship between leadership and shoal size might provide an interesting field for future research. Most studies to date have been restricted to shoals of small and medium size and more information on larger shoals would be useful.",2000-03-01,https://www.semanticscholar.org/paper/3aed8c43c463284b3d33d1a58d801cd9fb57a5d3,
1966,Similarity Searching for Defective Wafer Bin Maps in Semiconductor Manufacturing,"Because high-dimensional wafer bin maps (WBMs) cause various features, it is difficult to search the similarity among WBMs via conventional pattern recognition methods. This study develops a novel morphology-based support vector machine for defective wafer detection. The experimental results demonstrate its usefulness in yield improvements on precision and computation cost.",2014-07-01,https://www.semanticscholar.org/paper/9590da007734661cace2b4c6d197a843a92784cc,IEEE Transactions on Automation Science and Engineering
3209,On Multifaceted Definitions of Multilevel Societies: Response to Papageorgiou and Farine.,,2020-11-11,https://www.semanticscholar.org/paper/bda325186cbc2d958334ecff1255a06bcbd96168,Trends in Ecology & Evolution
364,The new problems,"The Brown web site announcing the death of Paris Kanellakis was one of the 90,000 active websites, running on one of 13 million IP servers. Since that time, the Internet and the worldwide web have grown by several orders of magnitude, and they have changed the way the world communicates, learns, expresses itself, and does business. The research agenda in Theory and Databases has also been affected: The Internet and the web are the first computational artefacts that were not designed in any direct, conventional sense, and must therefore be understood by the scientific method: the development and verification of falsifiable theories. There is an emergent field that uses concepts from Game Theory, Graph Theory, and Algorithms and Complexity in order to develop a mathematical methodology appropriate for such study.",2003-06-08,https://www.semanticscholar.org/paper/ea84a732ca2c6086b00cc811bfddbd194d73e7ff,PCK50
2129,Evaluating the desirability of meals: an illustrative multiattribute decision analysis procedure to assess portfolios with interdependent items,"This paper presents an exploratory study designed to address complex scaling problems in applying value/utility theory to measuring preferences over alternative combinations (or portfolios) of multiattributed items. This application considers meals served to nursing home residents as portfolios of food items and seeks to maximize meal appeal. We consider food interrelation and link single food measurements to overall meal measurements in the process of constructing meal desirability scales. We test the resulting scales to capture one expert's professional judgments and discuss issues raised in this specific application in the context of general portfolio evaluation problems. © 1998 John Wiley & Sons, Ltd.",1998-07-01,https://www.semanticscholar.org/paper/e953e52714a689a3ee73e9a683453d4ec759a080,
284,The complexity of nash equilibria,"The Internet owes much of its complexity to the large number of entities that run it and use it. These entities have different and potentially conflicting interests, so their interactions are of a strategic nature. Therefore, to understand these interactions, concepts from Economics and, most importantly, Game Theory are necessary. An important such concept is the notion of Nash equilibrium, which provides us with a rigorous way of predicting the behavior of strategic agents in situations of conflict. But the credibility of the Nash equilibrium as a framework for behavior-prediction depends on whether such equilibria are efficiently computable. After all, why should we expect a group of rational agents to behave in a fashion that requires exponential time to be computed? Motivated by this question, we study the computational complexity of the Nash equilibrium. 
We show that computing a Nash equilibrium is an intractable problem. Since by Nash's theorem a Nash equilibrium always exists, the problem belongs to the family of total search problems in NP, and previous work establishes that it is unlikely that such problems are NP-complete. We show instead that the problem is as hard as solving any Brouwer fixed point computation problem, in a precise complexity-theoretic sense. The corresponding complexity class is called PPAD, for Polynomial Parity Argument in Directed graphs, and our precise result is that computing a Nash equilibrium is a PPAD-complete problem. 
In view of this hardness result, we are motivated to study the complexity of computing approximate Nash equilibria, with arbitrarily close approximation. In this regard, we consider a very natural and important class of games, called anonymous games. These are games in which every player is oblivious to the identities of the other players; examples arise in auction settings, congestion games, and social interactions. We give a polynomial time approximation scheme for anonymous games with a bounded number of strategies.",,https://www.semanticscholar.org/paper/29b27adc01c889854cd0265ab659470f5ec6aa03,
1178,Search for resonant diphoton production with the D0 detector.,"We present a search for a narrow resonance in the inclusive diphoton final state using approximately 2.7 fb(-1) of data collected with the D0 detector at the Fermilab Tevatron pp Collider. We observe good agreement between the data and the background prediction, and set the first 95% C.L. upper limits on the production cross section times the branching ratio for decay into a pair of photons for resonance masses between 100 and 150 GeV. This search is also interpreted in the context of several models of electroweak symmetry breaking with a Higgs boson decaying into two photons.",2009-01-13,https://www.semanticscholar.org/paper/bb537fff7f21784e2c3e5170572280d7fbfb1efb,Physical Review Letters
787,Inference of Message Sequence Charts *,"Software designers draw Message Sequence Charts for early modeling of the individual behaviors they expect from the concurrent system under design. Can they be sure that precisely the behaviors they have described are realizable by some implementation of the components of the concurrent system? If so, can we automatically synthesize concurrent state machines realizing the given MSCs? If, on the other hand, other unspecified and possibly unwanted scenarios are "" implied "" by their MSCs, can the software designer be automatically warned and provided the implied MSCs? In this paper we provide a framework in which all these questions are answered positively. We first describe the formal framework within which one can derive implied MSCs, and then provide polynomial-time algorithms for implication, realizability, and synthesis.",,https://www.semanticscholar.org/paper/dad308eb26c1c7da149ad66618fdfefb8671851c,
3257,Caught between two worlds: genes and environment influence behaviour of plains×Grevy's zebra hybrids in central Kenya,,2015-08-01,https://www.semanticscholar.org/paper/6aeacde99edc9790173abdacab7759c037e852f6,Animal Behaviour
1472,Pion and Kaon multiplicities in heavy quark jets from e+e− annihilation at 29 GeV,,1987-01-29,https://www.semanticscholar.org/paper/37ffad02a4179695b6b0fbddf82edb9ac12b2a11,
295,Selfish Routers and the Price of Anarchy,"We revisit Roughgarden and Tardos’s price of anarchy in network routing, in a new model in which routing decisions are made by the edgesas opposed to the flows. We propose two models: the latency modelin which edges seek to minimize the average latency of the flow through them on the basis of knowledge of latency conditions in the whole network, and the pricing modelin which edges advertise pricing schemes to their neighbors and seek to maximize their profit. We show the counterintuitive result that the price of stability in the latency model is Ω(n 1 60 ), even with linear latencies (as compared with 4 3 for the case in which routing decisions are made by the flows themselves). However, in the pricing modelin which edges advertise pricing schemes — functions dictating how the price varies as a function of the total amount of flow — we show the surprising result that, under a condition ruling out monopolistic situations, all Nash equilibria have societally optimal flows; that is, the price of anarchy in this model isone. ? University of California, Berkeley. Email: christos@cs.berkeley.edu . ?? University of California, Berkeley. Work supported under a National Science Foundation Graduate Research Fellowship. Email: gvaliant@cs.berkeley.edu .",,https://www.semanticscholar.org/paper/b9cb82192e3225866e432136f8c490219c9d370f,
3037,Teaching operating systems using code review,"Learning about operating systems often involves modifying a large and complex code base. Grading student projects can be difficult and time consuming, yet students often do not learn from their programming errors and struggle to understand core operating system concepts. We present GradeBoard, a code review system designed to simplify grading for instructors and enable students to understand and learn from their errors. GradeBoard provides an easy-to-use Web interface that allows instructors to annotate student code submissions with grading comments and scores, and students to discuss the comments and scores with instructors. GradeBoard presents student code changes with syntax highlighting and lets users collapse or expand code sections to provide a desired level of context, making it easier to read and understand student programming project submissions. Comments and scores are easily identifiable by visual cues, improving interaction between instructors and students. We have deployed and used GradeBoard in a large operating systems course involving Linux kernel programming projects. GradeBoard provided robust, easy-to-use functionality for reviewing Linux kernel code changes, improved the instructional staff grading experience, and over 90% of students surveyed indicated that GradeBoard improved their understanding of the kernel programming projects better than other alternatives.",2014-03-05,https://www.semanticscholar.org/paper/419bcc6cde93454cf38d641990b816e3ef075b14,Technical Symposium on Computer Science Education
1064,Measurement of γ + b + X and γ + c + X Production Cross Sections in pp Collisions at √ s = 1 . 96 TeV,,,https://www.semanticscholar.org/paper/d363d5f590f75d0d3b2b992354994fcd87f61e5a,
1215,Measurement of differential Z / γ ∗ + jet + X cross sections in pp̄ collisions at √ s = 1 . 96 TeV,,,https://www.semanticscholar.org/paper/4b52a15f030a29b1212ee7af008d08949c4cd9f0,
1583,Population Predictive Checks,"Bayesian modeling has become a staple for researchers analyzing data. Thanks to recent developments in approximate posterior inference, modern researchers can easily build, use, and revise complicated Bayesian models for large and rich data. These new abilities, however, bring into focus the problem of model assessment. Researchers need tools to diagnose the fitness of their models, to understand where a model falls short, and to guide its revision. In this paper we develop a new method for Bayesian model checking, the population predictive check (Pop-PC). Pop-PCs are built on posterior predictive checks (PPC), a seminal method that checks a model by assessing the posterior predictive distribution on the observed data. Though powerful, PPCs use the data twice---both to calculate the posterior predictive and to evaluate it---which can lead to overconfident assessments. Pop-PCs, in contrast, compare the posterior predictive distribution to the population distribution of the data. This strategy blends Bayesian modeling with frequentist assessment, leading to a robust check that validates the model on its generalization. Of course the population distribution is not usually available; thus we use tools like the bootstrap and cross validation to estimate the Pop-PC. Further, we extend Pop-PCs to hierarchical models. We study Pop-PCs on classical regression and a hierarchical model of text. We show that Pop-PCs are robust to overfitting and can be easily deployed on a broad family of models.",2019-08-02,https://www.semanticscholar.org/paper/eb1b2363fa6cf44dbef9dc3342b3bc0ffac78f46,arXiv.org
1817,Content-Based Musical Similarity Computation using the Hierarchical Dirichlet Process,"We develop a method for discovering the latent structure in MFCC feature data using the Hierarchical Dirichlet Process (HDP). Based on this structure, we compute timbral similarity between recorded songs. The HDP is a nonparametric Bayesian model. Like the Gaussian Mixture Model (GMM), it represents each song as a mixture of some number of multivariate Gaussian distributions However, the number of mixture components is not fixed in the HDP, but is determined as part of the posterior inference process. Moreover, in the HDP the same set of Gaussians is used to model all songs, with only the mixture weights varying from song to song. We compute the similarity of songs based on these weights, which is faster than previous approaches that compare single Gaussian distributions directly. Experimental results on a genre-based retrieval task illustrate that our HDPbased method is both faster and produces better retrieval quality than such previous approaches.",,https://www.semanticscholar.org/paper/e82307b16df5046d166a53f55212dfc70b469f8f,International Society for Music Information Retrieval Conference
2613,Authoring 3D hypermedia for wearable augmented and virtual reality,"Most existing authoring systems for wearable augmentedand virtual reality experiences concentrate oncreating separate media objects and embedding themwithin the user's surroundings. In contrast, designingnarrative multimedia experiences for such environmentsis still largely a tedious manual task. We present an authoringtool for creating and editing 3D hypermedia narrativesthat are interwoven with a wearable computeruser's surrounding environment. Our system is designedfor use by authors who are not programmers, and allowsthem to preview their results on a desktop workstation, aswell as with an augmented or virtual reality system.",2003-10-21,https://www.semanticscholar.org/paper/2c5e9cf18d7eaf6cf250dca6f72f3ee5765106a9,"Seventh IEEE International Symposium on Wearable Computers, 2003. Proceedings."
2581,Cross-dimensional gestural interaction techniques for hybrid immersive environments,"We present a set of cross-dimensional interaction techniques for a hybrid user interface that integrates existing 2D and 3D visualization and interaction devices. Our approach is built around one-and two-handed gestures that support the seamless transition of data between co-located 2D and 3D contexts. Our testbed environment combines a 2D multi-user, multi-touch, projection surface with 3D head-tracked, see-through, head-worn displays and 3D tracked gloves to form a multi-display augmented reality. We address some of the ways in which we can interact with private data in a collaborative, heterogeneous workspace. We also report on a pilot usability study to evaluate the effectiveness and ease of use of the cross-dimensional interactions.",2005-03-12,https://www.semanticscholar.org/paper/31b63946a90c1f61eab0013fe8da18b1af944350,"IEEE Proceedings. VR 2005. Virtual Reality, 2005."
1189,Characterization of SuperCDMS 1‐inch Ge Detectors,"The newly commissioned SuperCDMS Soudan experiment aims to search for WIMP dark matter with a sensitivity to cross sections of 5×10^(−45)cm^2 and larger (90% CL upper limit). This goal is facilitated by a new set of germanium detectors, 2.5 times more massive than the ones used in the CDMS-II experiment, and with a different athermal phonon sensor layout that eliminates radial degeneracy in position reconstruction of high radius events. We present characterization data on these detectors, as well as improved techniques for correcting position-dependent variations in pulse shape across the detector. These improvements provide surface-event discrimination sufficient for a reach of 5×10^(−45)cm^2.",2009-12-16,https://www.semanticscholar.org/paper/e61eb68a247d5e72ea93722a626e9f7e09d852cb,
2099,Using DEA to Evaluate R&D Performance of the Computers and Peripherals Firms in Taiwan,"Research & development (R&D) performance has been a competitive advantage for high-tech industries. This paper presents an empirical study in which we used Data Envelopment Analysis (DEA) to evaluate the R&D performance of 31 computers and peripherals firms located at Hsinchu Science-based Industrial Park in Taiwan. We found that the R&D performance is very different among the evaluated companies, though most of the companies are technically efficient. Moreover, we discussed possible directions for the inefficient companies to improve their R&D performance. In particular, we found that most of the inefficient companies should increase their scales to increase their relative efficiencies of R&D performance.",2004-09-12,https://www.semanticscholar.org/paper/db39dfb580830f21cc1caaf1eaf96dc6086d29fa,
719,Explorer Checking LTL Properties of Recursive Markov Chains,"We present algorithms for the qualitative and quantitative model checking of Linear Temporal Logic (LTL) properties for Recursive Markov Chains (RMCs). Recursive Markov Chains are a natural abstract model of procedural probabilistic programs and related systems involving recursion and probability. For the qualitative problem (“Given a RMC and an LTL formula , do the computations of satisfy almost surely?”) we present an algorithm that runs in polynomial space in and exponential time in . For several classes of RMCs, including RMCs with one exit (a special case that corresponds to well-studied probabilistic systems, e.g., multi-type branching processes and stochastic context-free grammars) the algorithm runs in polynomial time in and exponential time in . On the other hand, we also prove that the problem is EXPTIMEhard, and hence it is EXPTIME-complete. For the quantitative problem (“does the probability that a computation of satisfies exceed a given threshold ?”, or approximate the probability within a desired precision) we present an algorithm that runs in polynomial space in and exponential space in . For linearly-recursive RMCs, we can compute the exact probability in time polynomial in and exponential in . These results improve by one exponential, in both the qualitative and quantitative case, the complexity that one would obtain if one first translated the LTL formula to a Büchi automaton and then applied the model checking algorithm for Büchi automata from [11]. Our results combine techniques developed in [10, 11] for analysis of RMCs, and in [6] for LTL model checking of flat Markov Chains, and extend them with new techniques.",,https://www.semanticscholar.org/paper/1105a454cec09957ef47bc06c5b7c58deab447d3,
356,Cs294-1 Algorithmic Aspects of Game Theory 2.1 Overview 2.2 Sperner's Lemma,"We begin by looking at a set of theorems from various disciplines and how they relate to one another. From combinatorics, we take Sperner’s Lemma which we can use to prove Brouwer’s Fixed Point Theorem from topology. Brouwer’s Fixed Point Theorem can be used to prove the Arrow-Debreu Theorem from economics which states that general equilibria exist, and can also be used to prove Kakutani’s Fixed Point Theorem. Kakutani’s Fixed Point Theorem can be used to prove that Nash Equilibria exist for all games. A graph illustrating how these theorems can be used to prove each other is given in Figure 2.1.",,https://www.semanticscholar.org/paper/9f3b525dc0cceb44ed55952f70c56c8a3502d57e,
1627,Dynamic Bernoulli Embeddings for Language Evolution,"Word embeddings are a powerful approach for unsupervised analysis of language. Recently, Rudolph et al. (2016) developed exponential family embeddings, which cast word embeddings in a probabilistic framework. Here, we develop dynamic embeddings, building on exponential family embeddings to capture how the meanings of words change over time. We use dynamic embeddings to analyze three large collections of historical texts: the U.S. Senate speeches from 1858 to 2009, the history of computer science ACM abstracts from 1951 to 2014, and machine learning papers on the Arxiv from 2007 to 2015. We find dynamic embeddings provide better fits than classical embeddings and capture interesting patterns about how language changes.",2017-03-23,https://www.semanticscholar.org/paper/67c04e949cc98c7dcc48dea0c94043d4ebf542db,arXiv.org
2021,UNISON analysis to model and reduce step-and-scan overlay errors for semiconductor manufacturing,,2011-06-01,https://www.semanticscholar.org/paper/f2e1693592371e7b0c66689d9a7dcb8c111a957a,Journal of Intelligent Manufacturing
2583,Multi-monitor mouse,"Multiple-monitor computer configurations significantly increase the distances that users must traverse with the mouse when interacting with existing applications, resulting in increased time and effort. We introduce the Multi-Monitor Mouse (M3) technique, which virtually simulates having one mouse pointer per monitor when using a single physical mouse device. M3 allows for conventional control of the mouse within each monitor's screen, while permitting immediate warping across monitors when desired to increase mouse traversal speed. We report the results of a user study in which we compared three implementations of M3 and two cursor placement strategies. Our results suggest that using M3 significantly increases interaction speed in a multi-monitor environment. All eight study participants strongly preferred M3 to the regular mouse behavior.",2005-04-02,https://www.semanticscholar.org/paper/49127d30b7f62986b675f905f17ed28de0da4a65,CHI Extended Abstracts
2764,Designing effective pictures: is photographic realism the only answer?,"ion you don't want to do that. Here's the theory of relativity. This is a space-time diagram. Again, no realistic object. We did a sort of two-dimensional cartoon of it and we made it look flat and two-dimensional because when we extrude it in the time dimension we wanted to have only three dimensions to deal with. Again, mathematical abstractions, things for which there is no real thing. The extrusions are made out of transparent polygons, but the lighting and so forth doesn't make them look like they're really made of shiny plastic. It's just something that you can see, that there's a trail left behind on these things. Here's some of my realistic cartoon animation. Again, we've seen a lot of attempts at realistic human faces, which is an interesting research topic, but you can do really interesting cartoons by making them very cartoony. In fact, this is a subject which I",1988-08-01,https://www.semanticscholar.org/paper/62ec999af315f5b6d1b2c3b746a9f466658296a1,International Conference on Computer Graphics and Interactive Techniques
3065,Operating system virtualization: practice and experience,"Operating system (OS) virtualization can provide a number of important benefits, including transparent migration of applications, server consolidation, online OS maintenance, and enhanced system security. However, the construction of such a system presents a myriad of challenges, even for the most cautious developer, that if overlooked may result in a weak, incomplete virtualization. We present a detailed discussion of key implementation issues in providing OS virtualization in a commodity OS, including system call interposition, virtualization state management, and race conditions. We discuss our experiences in implementing such functionality across two major versions of Linux entirely in a loadable kernel module without any kernel modification. We present experimental results on both uniprocessor and multiprocessor systems that demonstrate the ability of our approach to provide fine-grain virtualization with very low overhead.",2010-05-24,https://www.semanticscholar.org/paper/ef0baa52cd817c9f5645c196d51031e67279b90c,Annual Haifa Experimental Systems Conference
3650,Multiple Inheritance for C++,"Multiple Inheritance is the ability of a class to have more than one base class (super class). In a language where multiple inheritance is supported a program can be structured as a set of inheritance lattices instead of (just) as a set of inheritance trees. This is widely believed to be an important structuring tool. It is also widely believed that multiple inheritance complicates a programming language significantly, is hard to implement, and is expensive to run. I will demonstrate that none of these last three conjectures are true.",,https://www.semanticscholar.org/paper/35a501c412162dba797ce75f857ce58bc55d211c,Computing Systems
3768,Anticipating Visual Representations from Unlabeled Video,"Anticipating actions and objects before they start or appear is a difficult problem in computer vision with several real-world applications. This task is challenging partly because it requires leveraging extensive knowledge of the world that is difficult to write down. We believe that a promising resource for efficiently learning this knowledge is through readily available unlabeled video. We present a framework that capitalizes on temporal structure in unlabeled video to learn to anticipate human actions and objects. The key idea behind our approach is that we can train deep networks to predict the visual representation of images in the future. Visual representations are a promising prediction target because they encode images at a higher semantic level than pixels yet are automatic to compute. We then apply recognition algorithms on our predicted representation to anticipate objects and actions. We experimentally validate this idea on two datasets, anticipating actions one second in the future and objects five seconds in the future.",2015-04-29,https://www.semanticscholar.org/paper/932ac3707e1ed84ab67526692a1ef8f064f24ab5,Computer Vision and Pattern Recognition
244,Multiplicative updates in coordination games and the theory of evolution,"In this paper we point out a new and unexpected connection between three fields: Evolution Theory, Game Theory, and Algorithms.
 In particular, we study the standard equations of population genetics for Evolution, in the presence of recombination (sex), focusing on the important special case of weak selection [1,2] in which all fitness values are assumed to be close to one another. Weak selection is the mathematical regime capturing the widely accepted Neutral Theory proposed by Kimura in the 1970s [3], hypothesizing that evolution proceeds for the most part not by substantial increases in fitness but by essentially random drift. We show that in this regime evolution through natural selection and sex is tantamount to a game played through the multiplicative weight updates game dynamics [4]. The players of the game are the genes (genetic loci), the strategies available to each player are the alleles of the gene, and the probabilities whereby a player plays a strategy is the strategy's frequency in the population. The utility to each player/gene of each strategy profile is the fitness of the corresponding genotype (organism). That is, the game is a coordination game between genes, in which the players' interests are perfectly aligned. Importantly, the utility maximized in this game, as well as the amount by which each allele is boosted, is precisely the allele's mixability, or average fitness, a quantity recently proposed in [5] as a novel concept that is crucial in understanding natural selection under sex, thus providing a rigorous demonstration of that insight.
 We also establish a result regarding the maintenance of genetic diversity (multiplicity of alleles per gene). We prove that the equilibria in two-person coordination games are likely to have large supports, and thus genetic diversity need not suffer much at equilibrium. Establishing large supports involves answering through a novel technique the following question: what is the probability that for a random square matrix $A$ (with entries drawn independently from smooth distributions that are symmetric around zero) both systems Ax=1 and ATy=1 have positive solutions? The proof is through a simple potential function argument. Both the question and the technique may be of broader interest.
 It has often seemed astonishing --- even to experienced students of Evolution, Darwin included --- that the crude mechanism of natural selection is responsible for producing the dazzling variety of Life around us. The present mathematical connection of Evolution with the multiplicative weight updates algorithm --- a technique that has surprised our field time and again with its fantastic effectiveness and versatility --- may carry some explanatory force in this regard.",2012-08-15,https://www.semanticscholar.org/paper/3ae474d4ad8ed141cb5d5a3ad48588544496bba1,Information Technology Convergence and Services
2531,SiteLens: situated visualization techniques for urban site visits,"Urban designers and urban planners often conduct site visits prior to a design activity to search for patterns or better understand existing conditions. We introduce SiteLens, an experimental system and set of techniques for supporting site visits by visualizing relevant virtual data directly in the context of the physical site, which we call situated visualization. We address alternative visualization representations and techniques for data collection, curation, discovery, comparison, manipulation, and provenance. A real use scenario is presented and two iterations of evaluation with faculty and students from the Columbia University Graduate School of Architecture, Planning and Preservation provide directions and insight for further investigation.",2009-04-04,https://www.semanticscholar.org/paper/44c9f67c40a6abfdb80b5cdda6de8fe7c939dd4a,International Conference on Human Factors in Computing Systems
818,Principl Finite S,,,https://www.semanticscholar.org/paper/970ff92681ab0e8a227b59214a65b54ecaf37362,
2495,Proceedings of the 15th International Conference on the Foundations of Digital Games,"On behalf of the organizing committee, we welcome you to the 2012 Foundation of Digital Games Conference (FDG 2012) held in Raleigh, North Carolina from May 29-June 1, 2012. FDG is at the forefront, looking at the exciting emerging field of game research from an academic and scientific perspective and providing novel directions and theoretical foundations for emerging advances. We are pleased to welcome you to our growing community and are providing your contributions to feed the development for the future of the field of game research. The diversity and strength of the submissions this year continues to demonstrate that game research is continuously growing and maturing.",2012-05-29,https://www.semanticscholar.org/paper/5d8548480966626832de536a58a08b9e48a86c7b,International Conference on Foundations of Digital Games
2849,Galectin-3 translocates to the immunological synapse and inhibits cytokine production in CD4+ T cells activated by engagement of TCR (88.12),"
 Galectin-3 is induced in CD4+ T cells upon activation by mitogens or TCR engagement, but its function in this cell type has not been determined. We have compared the cytokine responses of gal3−/− and gal3+/+ CD4+ T cells upon activation induced by TCR engagement and found that gal3−/− CD4+ T cells secreted more IFNγ and IL-4 compared to gal3+/+ cells. We also found that serum levels of IFNγ were significantly higher in gal3−/− than gal3+/+ mice after exposure to Staphylococcus enterotoxin B. In addition, gal3−/− CD4+ T cells exhibited higher levels of tyrosine-phosphorylated proteins, as well as enhanced phosphorylation of early signaling molecules, including LAT and Zap70, upon anti-CD3 stimulation. These results suggest that endogenous galectin-3 suppresses T cell responses. Immunofluorescence analysis revealed that galectin-3 was recruited to the immunological synapse in CD4+ T cells after TCR engagement. Our preliminary data suggest that galectin-3 expression in T cells correlates with an enhanced down-regulation of TCR when the cells are activated by engagement of the receptor, in a manner similar to that described for other intracellular proteins that negatively regulate T cell activation. We conclude that galectin-3 is an inhibitory regulator of T cell activation that down-regulates signal transduction, and functions by recruitment to the immunological synapse following activation by TCR engagement.",2007-04-01,https://www.semanticscholar.org/paper/3a0135278b776eaa835dfc8ef449165d9f6bec21,Journal of Immunology
448,On the Value of Information,,,https://www.semanticscholar.org/paper/974dbda6b5aeb73b12c625bd5f8f8482b67a0032,
3602,A rationale for semantically enhanced library languages,"This paper presents the rationale for a novel approach to providing expressive, teachable, maintainable, and cost-effective special-purpose languages: A Semantically Enhanced Library Language (a SEL language or a SELL) is a dialect created by supersetting a language using a library and then subsetting the result using a tool that “understands” the syntax and semantics of both the underlying language and the library. The resulting language can be about as expressive as a specialpurpose language and provide as good semantic guarantees as a special-purpose language. However, a SELL can rely on the tool chain and user community of a major generalpurpose programming language. The examples of SELLs presented here (Safe C++, Parallel C++, and Real-time C++) are based on C++ and the Pivot program analysis and transformation infrastructure. As part of the rationale, the paper discusses practical problems with various popular approaches to providing special-purpose features, such as compiler options and preprocessors.",,https://www.semanticscholar.org/paper/30c59d51a4a610de0df81eee6b4e743c41c3bca2,
2524,Rolling and shooting: two augmented reality games,"We present two fast-paced augmented reality games. One is a single-player game experienced through a head-worn display. The player manipulates a tracked board to guide a virtual ball through a dynamic maze of obstacles. Combining the 3DOF absolute orientation tracker on the head-worn display with 6DOF optical marker tracking allows the system to always account for the correct direction of gravity. The second game is a networked, two-player, first-person-shooter, in which tracked hand-held UMPCs are used to blast virtual dominoes off a table. Players' virtual locations are warped to keep them from physically interfering with each other.",2010-04-09,https://www.semanticscholar.org/paper/bb97200290ef21291dc84975fe7c0256467ea5a1,CHI Extended Abstracts
2456,Keynote speaker: Getting real,"Wide-FOV, 6DOF-tracked, consumer head-worn displays are no longer just dev kits, bimanual 3D input devices can be found at Best Buy, and full-fledged graphics packages are built into web browsers. Meanwhile, augmented reality is poised to make the return trip from hand-held phones and tablets, back to the head-worn displays in which it was born. 3D is here for real. Yet, we all know how difficult it is to create effective 3D user interfaces. In this talk, I will discuss my thoughts about why this is so, and what we can do about it. I will present some of the research directions that my lab has been exploring, and suggest where I think our field may be headed next.",2016-03-19,https://www.semanticscholar.org/paper/594d3cac72485a1e6a594bb3b77e1fa33ed841e7,IEEE Symposium on 3D User Interfaces
2880,Expression of galectin-3 modulates T-cell growth and apoptosis.,"Galectin-3 is a member (if a large family of beta-galactoside-binding animal lectins. It has been shown that the expression of galectin-3 is upregulated in proliferating cells, suggesting a possible role for this lectin in regulation of cell growth. Previously, we have shown that T cells infected with human T-cell leukemia virus type I express high levels of galectin-3, in contrast to uninfected cells, which do not express detectable amounts of this protein. In this study, we examined growth properties of human leukemia T cells transfected with galectin-3 cDNA, and thus constitutively overexpressing this lectin. Transfectants expressing galectin-3 displayed higher growth rates than control transfectants, which do not express this lectin. Furthermore, galectin-3 expression in these cells confers resistance to apoptosis induced by anti-Fas antibody and staurosporine. Galectin-3 was found to have significant sequence similarity with Bcl-2, a well-characterized suppressor of apoptosis. In particular, the lectin contains the NWGR motif that is highly conserved among members of the Bcl-2 family and shown to be critical for the apoptosis-suppressing activity. We further demonstrated that galectin-3 interacts with Bc1-2 in a lactose-inhibitable manner. We conclude that galectin-3 is a regulator of cell growth and apoptosis and it may function through a cell death inhibition pathway that involves Bcl-2.",1996-06-25,https://www.semanticscholar.org/paper/33f780243e1364011d53512bab723e0c78209561,Proceedings of the National Academy of Sciences of the United States of America
380,Selfish behavior and stability of the internet: a game-theoretic analysis of TCP,"For years, the conventional wisdom [7, 22] has been that the continued stability of the Internet depends on the widespread deployment of ""socially responsible"" congestion control. In this paper, we seek to answer the following fundamental question: If network end-points behaved in a selfish manner, would the stability of the Internet be endangered?.We evaluate the impact of greedy end-point behavior through a game-theoretic analysis of TCP. In this ""TCP Game"" each flowattempts to maximize the throughput it achieves by modifying its congestion control behavior. We use a combination of analysis and simulation to determine the Nash Equilibrium of this game. Our question then reduces to whether the network operates efficiently at these Nash equilibria.Our findings are twofold. First, in more traditional environments -- where end-points use TCP Reno-style loss recovery and routers use drop-tail queues -- the Nash Equilibria are reasonably efficient. However, when endpoints use more recent variations of TCP (e.g., SACK) and routers employ either RED or drop-tail queues, the Nash equilibria are very inefficient. This suggests that the Internet of the past could remain stable in the face of greedy end-user behavior, but the Internet of today is vulnerable to such behavior. Second, we find that restoring the efficiency of the Nash equilibria in these settings does not require heavy-weight packet scheduling techniques (e.g., Fair Queuing) but instead can be done with a very simple stateless mechanism based on CHOKe [21].",2002-10-01,https://www.semanticscholar.org/paper/fe856288df47d00bb48748dc43231e7582341045,"Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication"
1568,The Medical Deconfounder: Assessing Treatment Effects with Electronic Health Records,"The treatment effects of medications play a key role in guiding medical prescriptions. They are usually assessed with randomized controlled trials (RCTs), which are expensive. Recently, large-scale electronic health records (EHRs) have become available, opening up new opportunities for more cost-effective assessments. However, assessing a treatment effect from EHRs is challenging: it is biased by unobserved confounders, unmeasured variables that affect both patients' medical prescription and their outcome, e.g. the patients' social economic status. To adjust for unobserved confounders, we develop the medical deconfounder, a machine learning algorithm that unbiasedly estimates treatment effects from EHRs. The medical deconfounder first constructs a substitute confounder by modeling which medications were prescribed to each patient; this substitute confounder is guaranteed to capture all multi-medication confounders, observed or unobserved (arXiv:1805.06826). It then uses this substitute confounder to adjust for the confounding bias in the analysis. We validate the medical deconfounder on two simulated and two real medical data sets. Compared to classical approaches, the medical deconfounder produces closer-to-truth treatment effect estimates; it also identifies effective medications that are more consistent with the findings in the medical literature.",2019-10-28,https://www.semanticscholar.org/paper/10633897910bec410e04406004f14aad90cecbb8,Machine Learning in Health Care
450,Computational Aspacts of Organization Theory (Extended Abstract),,1996-09-25,https://www.semanticscholar.org/paper/e47a8a19d30c3476887a234b085e6a12568011a3,Embedded Systems and Applications
2425,MiXR: A Hybrid AR Sheet Music Interface for Live Performance,"Musicians face a number of issues when performing live, including organizing and annotating sheet music. This can be an unwieldy process, as musicians need to simultaneously read and manipulate sheet music and interact with the conductor and other musicians. Augmented Reality can provide a way to ease some of the more cumbersome aspects of live performance and practice. We present MiXR, a novel interactive system that combines an AR headset, a smartphone, and a tablet to allow performers to intuitively and efficiently manage and annotate virtual sheet music in their physical environment. We discuss our underlying motivation, the interaction techniques supported, and the system architecture.",2020-11-01,https://www.semanticscholar.org/paper/c297da731799cdcae3b5204b6cd8ec2d2e5c7d4c,2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)
2997,"Algorithmic Foundations of Robotics XV - Proceedings of the Fifteenth Workshop on the Algorithmic Foundations of Robotics, WAFR 2022, College Park, MD, USA, 22-24 June, 2022",,,https://www.semanticscholar.org/paper/912c77c0a6fff1119073347c90a6d06b3885f096,Workshop on the Algorithmic Foundations of Robotics
73,Querying text databases for efficient information extraction,"A wealth of information is hidden within unstructured text. This information is often best exploited in structured or relational form, which is suited for sophisticated query processing, for integration with relational databases, and for data mining. Current information extraction techniques extract relations from a text database by examining every document in the database, or use filters to select promising documents for extraction. The exhaustive scanning approach is not practical or even feasible for large databases, and the current filtering techniques require human involvement to maintain and to adapt to new databases and domains. We develop an automatic query-based technique to retrieve documents useful for the extraction of user-defined relations from large text databases, which can be adapted to new domains, databases, or target relations with minimal human effort. We report a thorough experimental evaluation over a large newspaper archive that shows that we significantly improve the efficiency of the extraction process by focusing only on promising documents.",2003-03-05,https://www.semanticscholar.org/paper/dda99e75f4c54db13bb891060c63cb796cb44466,Proceedings / International Conference on Data Engineering
3417,LTCC Course on Graph Theory 2013 / 14 Notes 3 Complexity and Algorithms,"The graph theory textbooks do little or no algorithms, so for these lectures we have to go somewhere else. The default textbook and source for anything algorithmic is : T.H. Cormen, C.E. Leiverson, R.L. Rivest and C. Stein, Introduction to Algorithms ( 2nd edition ), MIT Press, 2001 ( ISBN: 0262531968 ). An alternative ( and lighter in weight ) source is H.S. Wilf, Algorithms and Complexity ( 2nd edition ), Peters, 2003 ( ISBN: 1568811780 ). The first edition ( which is more than enough for us ) can be downloaded for free from www.math.upenn.edu/~wilf/AlgoComp.pdf. The default book for complexity theory is still, after 30 years (!), and still in print, M.R. Garey and D.S. Johnson, Computers and Intractability: A Guide to the Theory of NP-completeness, Freeman, 1979 ( ISBN: 0716710455 ). The only serious alternative I can think of is C.H. Papadimitriou, Computational Complexity, Addison Wesley, 1994 ( ISBN: 0201530821 ).",,https://www.semanticscholar.org/paper/feb8749dec117a2064e14d0c50dd141813bd6bfe,
440,Towards an analysis of indexing schemes,,,https://www.semanticscholar.org/paper/ed4b7703b0ec9fb8edad37ca22055b6c3e5f838a,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
667,"A Neural Network Solves and Generates Mathematics Problems by Program Synthesis: Calculus, Differential Equations, Linear Algebra, and More",,,https://www.semanticscholar.org/paper/6806b0d1e425639a42da4763f170569b86448c87,arXiv.org
1732,Black Box Variational Inference,"Variational inference has become a widely used method to approximate posteriors in complex latent variables models. However, deriving a variational inference algorithm generally requires significant model-specific analysis, and these efforts can hinder and deter us from quickly developing and exploring a variety of models for a problem at hand. In this paper, we present a ""black box"" variational inference algorithm, one that can be quickly applied to many models with little additional derivation. Our method is based on a stochastic optimization of the variational objective where the noisy gradient is computed from Monte Carlo samples from the variational distribution. We develop a number of methods to reduce the variance of the gradient, always maintaining the criterion that we want to avoid difficult model-based derivations. We evaluate our method against the corresponding black box sampling based methods. We find that our method reaches better predictive likelihoods much faster than sampling methods. Finally, we demonstrate that Black Box Variational Inference lets us easily explore a wide space of models by quickly constructing and evaluating several models of longitudinal healthcare data.",2013-12-31,https://www.semanticscholar.org/paper/6a667700100e228cb30a5d884258a0db921603fe,International Conference on Artificial Intelligence and Statistics
3310,Male harassment influences female movements and associations in Grevy's zebra (Equus grevyi),"In traditional models for social organization, female movements and association patterns track resource distribution, whereas males track females. More recently, this model has been expanded to include feedback effects of male behavior, especially sexual harassment, on female decisions. In Grevy's zebra (Equus grevyi), males defend territories containing resources attractive to females, who form unstable groups. Past research has explained female behavior based on resource distribution and needs alone. Lactating females have been found to have restricted movements and fewer male associates than nonlactating females, a pattern we find in our study. This pattern has previously been attributed solely to the higher water needs of lactation. However, in our population, both lactating and nonlactating females are typically close to water. We test the hypothesis that male harassment also influences female ranging and associations with males. This effect is predicted to be greater for lactating females because harassment has higher costs to them. We find that lactating females experience higher harassment rates than those of nonlactating females. Lactating females tend to move faster during harassment periods, whereas nonlactating individuals do not. Lactating females experience lower harassment rates if they spend more time with a particular male, whereas nonlactating females' harassment rates do not depend on their allocation of time to a primary male. We suggest that females concentrate their time with one male in order to reduce male harassment. Even in species such as Grevy's zebra without strong male--female bonds, social interactions may be a significant driver of female distribution. Copyright 2007, Oxford University Press.",2007-09-01,https://www.semanticscholar.org/paper/a88ba4c286abf2821cc5bcdaa6e1481dca83c37a,
1168,Direct measurement of the W boson width.,"We present a direct measurement of the width of the W boson using the shape of the transverse mass distribution of W --> enu candidate events. Data from approximately 1 fb(-1) of integrated luminosity recorded at square root of s = 1.96 TeV by the D0 detector at the Fermilab Tevatron pp collider are analyzed. We use the same methods and data sample that were used for our recently published W boson mass measurement, except for the modeling of the recoil, which is done with a new method based on a recoil library. Our result, 2.028 +/- 0.072 GeV, is in agreement with the predictions of the standard model.",2009-09-25,https://www.semanticscholar.org/paper/8e538330e7a8d93582bf903a71408bfcfa1e9db4,Physical Review Letters
2881,Gene targeted inactivation of galectin-3 results in mice with reduced macrophage survival in culture,,,https://www.semanticscholar.org/paper/5938d1acd88ee5ff685ec008e1ae3f2b304658ce,
1128,Search for Higgs boson production in dilepton and missing energy final states with 5.4 fb(-1) of pp collisions at square root(s) = 1.96 TeV.,"A search for the standard model Higgs boson is presented using events with two charged leptons and large missing transverse energy selected from 5.4 fb(-1) of integrated luminosity in pp collisions at square root(s) = 1.96 TeV collected with the D0 detector at the Fermilab Tevatron collider. No significant excess of events above background predictions is found, and observed (expected) upper limits at 95% confidence level on the rate of Higgs boson production are derived that are a factor of 1.55 (1.36) above the predicted standard model cross section at m(H) = 165 GeV.",,https://www.semanticscholar.org/paper/4d48d4444a497c9f70c9d5e66de19d94cd68e975,Physical Review Letters
2593,Unit: modular development of distributed interaction techniques for highly interactive user interfaces,"The Unit framework uses a dataflow programming language to describe interaction techniques for highly interactive environments, such as augmented, mixed, and virtual reality. Unit places interaction techniques in an abstraction layer between the input devices and the application, which allows the application developer to separate application functionality from interaction techniques and behavior.Unit's modular approach leads to the design of reusable application-independent interaction control components, portions of which can be distributed across different machines. Unit makes it possible at run time to experiment with interaction technique behavior, as well as to switch among different input device configurations. We provide both a visual interface and a programming API for the specification of the dataflow. To demonstrate how Unit works and to show the benefits to the interaction design process, we describe a few interaction techniques implemented using Unit. We also show how Unit's distribution mechanism can offload CPU intensive operations, as well as avoid costly special-purpose hardware in experimental setups.",2004-06-15,https://www.semanticscholar.org/paper/221f4db6e084abaf586a902c5ce6c0ae5057df6e,Conference on Computer Graphics and Interactive Techniques in Australasia and Southeast Asia
3571,Scalable nonblocking concurrent objects for mission critical code,"The high degree of complexity and autonomy of future robotic space missions, such as Mars Science Laboratory (MSL), poses serious challenges in assuring their reliability and efficiency. Providing fast and safe concurrent synchronization is of critical importance to such autonomous embedded software systems. The application of nonblocking synchronization is known to help eliminate the hazards of deadlock, livelock, and priority inversion. The nonblocking programming techniques are notoriously difficult to implement and offer a variety of semantic guarantees and usability and performance trade-offs. The present software development and certification methodologies applied at NASA do not reach the level of detail of providing guidelines for the design of concurrent software. The complex task of engineering reliable and efficient concurrent synchronization is left to the programmer's ingenuity. A number of Software Transactional Memory (STM) approaches gained wide popularity because of their easy to apply interfaces, but currently fail to offer scalable nonblocking transactions. In this work we provide an in-depth analysis of the nonblocking synchronization semantics and their applicability in mission critical code. We describe a generic implementation of a methodology for scalable implementation of concurrent objects. Our performance evaluation demonstrates that our approach is practical and outperforms the application of nonblocking transactions by a large factor. In addition, we apply our Descriptor-based approach to provide a solution to the fundamental ABA problem. Our ABA prevention scheme, called the lambda-delta approach, outperforms by a large factor the use of garbage collection for the safe management of each shared location. It offers speeds comparable to the application of the architecture-specific CAS2 instruction used for version counting. The lambda-delta approach is an ABA prevention technique based on classification of concurrent operations and 3-step execution of a Descriptor object. A practical alternative to the application of CAS2 is particularly important for the engineering of embedded systems.",2009-10-25,https://www.semanticscholar.org/paper/51f9449505dfcd8525e026d5aa345754ff05c526,OOPSLA Companion
2615,AUGMENTED REALITY FOR COLLABORATIVE EXPLORATION OF UNFAMILIAR ENVIRONMENTS,"Understanding an unfamiliar environment can be a difficult and time-consuming task, yet one at which users can be particularly effective when it is accomplished collaboratively. We are investigating techniques that support communication among multiple users within a group to help them explore their surroundings together. Our focus is on determining how each user’s interface is designed, based on their view of the environment and information received both from the environment and from other users. We build on our previous work on view management to assist in the placement of virtual information and to maintain a coherent user interface. We also use a situation-awareness aid, based on a head-controlled 3D World-in-Miniature, to display information on a head-worn display about objects or locations that might not be directly visible to the user.",,https://www.semanticscholar.org/paper/432b41d516acd28c99fe610037f77a0ec8564103,
3726,Globetrotter: Unsupervised Multilingual Translation from Visual Alignment,"Multi-language machine translation without parallel corpora is challenging because there is no explicit supervision between languages. Existing unsupervised methods typically rely on topological properties of the language representations. We introduce a framework that instead uses the visual modality to align multiple languages, using images as the bridge between them. We estimate the cross-modal alignment between language and images, and use this estimate to guide the learning of cross-lingual representations. Our language representations are trained jointly in one model with a single stage. Experiments with fifty-two languages show that our method outperforms baselines on unsupervised word-level and sentence-level translation using retrieval.",2020-12-08,https://www.semanticscholar.org/paper/f1085830042fdc07961f4bf4a7e6ff60cd534fd9,arXiv.org
403,The Complexity of Optimal Queuing Network Control,"We show that several well-known optimization problems related to the optimal control of queues are provably intractable-independently of any unproven conjecture such as P â NP. In particular, we show that several versions of the problem of optimally controlling a simple network of queues with simple arrival and service distributions and multiple customer classes is complete for exponential time. This is perhaps the first such intractability result for a well-known optimization problem. We also show that the restless bandit problem the generalization of the multi-armed bandit problem to the case in which the unselected processes are not quiescent is complete for polynomial space.",1999-05-01,https://www.semanticscholar.org/paper/3808e63d89b6a251f37cb19d7761e3e037e4897b,Mathematics of Operations Research
2033,An efficient computational procedure for determining the container-loading pattern,,2009-04-01,https://www.semanticscholar.org/paper/89b0cfdfc87f2451c286927f646153b05be04468,Computers & industrial engineering
3620,An Overview of the C++ Programming Language,"This overview of C++ presents the key design, programming, and language-technical concepts using examples to give the reader a feel for the language. C ++ is a general-purpose programming language with a bias towards systems programming that supports efficient low-level computation, data abstraction, object-oriented programming, and generic programming.",,https://www.semanticscholar.org/paper/eb331db6ec60d64b9e0d90978ee7398d9e2f0605,
157,Assemblies of neurons learn to classify well-separated distributions,"An assembly is a large population of neurons whose synchronous firing is hypothesized to represent a memory, concept, word, and other cognitive categories. Assemblies are believed to provide a bridge between high-level cognitive phenomena and low-level neural activity. Recently, a computational system called the Assembly Calculus (AC), with a repertoire of biologically plausible operations on assemblies, has been shown capable of simulating arbitrary space-bounded computation, but also of simulating complex cognitive phenomena such as language, reasoning, and planning. However, the mechanism whereby assemblies can mediate learning has not been known. Here we present such a mechanism, and prove rigorously that, for simple classification problems defined on distributions of labeled assemblies, a new assembly representing each class can be reliably formed in response to a few stimuli from the class; this assembly is henceforth reliably recalled in response to new stimuli from the same class. Furthermore, such class assemblies will be distinguishable as long as the respective classes are reasonably separated -- for example, when they are clusters of similar assemblies. To prove these results, we draw on random graph theory with dynamic edge weights to estimate sequences of activated vertices, yielding strong generalizations of previous calculations and theorems in this field over the past five years. These theorems are backed up by experiments demonstrating the successful formation of assemblies which represent concept classes on synthetic data drawn from such distributions, and also on MNIST, which lends itself to classification through one assembly per digit. Seen as a learning algorithm, this mechanism is entirely online, generalizes from very few samples, and requires only mild supervision -- all key attributes of learning in a model of the brain.",2021-10-07,https://www.semanticscholar.org/paper/295e71794653a36385680be74eca63b971bbe258,Annual Conference Computational Learning Theory
1331,Search for techniparticles in e+jets events at D0.,"We search for the technicolor process pp-->rhoT/omegaT-->WpiT in events containing one electron and two jets, in data corresponding to an integrated luminosity of 390 pb(-1), recorded by the D0 experiment at the Fermilab Tevatron. Technicolor predicts that technipions pi(T) decay dominantly into bb, bc, or bc, depending on their charge. In these events b and c quarks are identified by their secondary decay vertices within jets. Two analysis methods based on topological variables are presented. Since no excess above the standard model prediction was found, the result is presented as an exclusion in the pi(T) vs rho(T) mass plane for a given set of model parameters.",2006-12-08,https://www.semanticscholar.org/paper/efa78cab88c0b094e1fec31a4a5cd0ad2d4d3a93,Physical Review Letters
2890,"Biochemical and biophysical characterization of human recombinant IgE-binding protein, an S-type animal lectin.",,1992-07-15,https://www.semanticscholar.org/paper/3dfcc1d5c1465baecf415f85a5d42d0ce1977707,Journal of Biological Chemistry
3025,Optimizing the Design and Implementation of the Linux ARM Hypervisor,"Modern hypervisor designs for both ARM and ×86 virtualization rely on running an operating system kernel, the hypervisor OS kernel, to support hypervisor functionality. While ×86 hypervisors effectively leverage architectural support to run the kernel, existing ARM hypervisors map poorly to the virtualization features of the ARM architecture, resulting in worse performance. We identify the key reason for this problem is the need to multiplex kernel mode state between the hypervisor and virtual machines, which each run their own kernel. To address this problem, we take a fundamentally different approach to hypervisor design that runs the hypervisor together with its OS kernel in a separate CPU mode from kernel mode. Using this approach, we redesign KVM/ARM to leverage a separate ARM CPU mode for running both the hypervisor and its OS kernel. We show what changes are required in Linux to implement this on current ARM hardware as well as how newer ARM architectural support can be used to support this approach without any changes to Linux other than to KVM/ARM itself. We show that our redesign and optimizations can result in an order ofmagnitude performance improvement for KVM/ARM, and can provide faster performance than x86 on key hypervisor operations. As a result, many aspects of our design have been successfully merged into mainline Linux.",2017-07-12,https://www.semanticscholar.org/paper/03a97821f3f77490f1c775501762985f10cd7be8,USENIX Annual Technical Conference
3179,Expert range maps of global mammal distributions harmonised to three taxonomic authorities,"Comprehensive, global information on species' occurrences is an essential biodiversity variable and central to a range of applications in ecology, evolution, biogeography and conservation. Expert range maps often represent a species' only available distributional information and play an increasing role in conservation assessments and macroecology. We provide global range maps for the native ranges of all extant mammal species harmonised to the taxonomy of the Mammal Diversity Database (MDD) mobilised from two sources, the Handbook of the Mammals of the World (HMW) and the Illustrated Checklist of the Mammals of the World (CMW).",2022-03-27,https://www.semanticscholar.org/paper/8782ac121cffd1107567c4e0fc8677fa3b53b1ad,Journal of Biogeography
668,Automated Symbolic Law Discovery: A Computer Vision Approach,"One of the most exciting applications of modern artificial intelligence is to automatically discover scientific laws from experimental data. This is not a trivial problem as it involves searching for a complex mathematical relationship over a large set of explanatory variables and operators that can be combined in an infinite number of ways.

Inspired by the incredible success of deep learning in computer vision, we tackle this problem by adapting various successful network architectures into the symbolic law discovery pipeline. The novelty of our approach is in (1) encoding the input data as an image with super-resolution, (2) developing an appropriate deep network pipeline, and (3) predicting the importance of each mathematical operator from the relationship image. This allows us to prior the exponentially large search with the predicted importance of the symbolic operators, which can significantly accelerate the discovery process.

We apply our model to a variety of plausible relationships---both simulated and from physics and mathematics domains---involving different dimensions and constituents. We show that our model is able to identify the underlying operators from data, achieving a high accuracy and AUC (91% and 0.96 on average resp.) for systems with as many as ten independent variables. Our method significantly outperforms the current state of the art in terms of data fitting (R^2), discovery rate (recovering the true relationship), and succinctness (output formula complexity). The discovered equations can be seen as first drafts of scientific laws that can be helpful to the scientists for (1) hypothesis building, and (2) understanding the complex underlying structure of the studied phenomena. Our approach holds a real promise to help speed up the rate of scientific discovery.",2021-05-18,https://www.semanticscholar.org/paper/8951402483e58f6279266ac836a88ad1e445eda6,AAAI Conference on Artificial Intelligence
2369,CO-reacting haemoproteins of neutrophils: Evidence for cytochrome b-245 and myeloperoxidase as potential oxidases during the respiratory burst,,1987-03-01,https://www.semanticscholar.org/paper/093c736e7c47eea637ad569ed87bb5f0a618ffa8,Bioscience Reports
2913,Single-cell multi-omics defines the cell-type specific impact of splicing aberrations in human hematopoietic clonal outgrowths,"RNA splicing factors are recurrently affected by alteration-of-function mutations in clonal blood disorders, highlighting the importance of splicing regulation in hematopoiesis. However, our understanding of the impact of dysregulated RNA splicing has been hampered by the inability to distinguish mutant and wildtype cells in primary patient samples, the cell-type complexity of the hematopoietic system, and the sparse and biased coverage of splice junctions by short-read sequencing typically used in single-cell RNA sequencing. To overcome these limitations, we developed GoT-Splice by integrating Genotyping of Transcriptomes (GoT) with enhanced efficiency long-read single-cell transcriptome profiling, as well as proteogenomics (with CITE-seq). This allowed for the simultaneous single-cell profiling of gene expression, cell surface protein markers, somatic mutation status, and RNA splicing. We applied GoT-Splice to bone marrow progenitors from patients with myelodysplastic syndrome (MDS) affected by mutations in the most prevalent mutated RNA splicing factor – the core RNA splicing factor SF3B1. High-resolution mapping of SF3B1mut vs. SF3B1wt hematopoietic progenitors revealed a fitness advantage of SF3B1mut cells in the megakaryocytic-erythroid lineage, resulting in an expansion of SF3B1mut erythroid progenitor (EP) cells. SF3B1mut EP cells exhibited upregulation of genes involved in regulation of cell cycle and mRNA translation. Long-read single-cell transcriptomes revealed the previously reported increase of aberrant 3’ splicing site usage in SF3B1mut cells. However, the ability to profile splicing within individual cell populations uncovered distinct cryptic 3’ splice site usage across different progenitor populations, as well as stage-specific aberrant splicing during erythroid maturation. Lastly, as splice factor mutations occur in clonal hematopoiesis (CH) with increased risk of neoplastic transformation, we applied GoT-Splice to CH samples. These data revealed that the erythroid lineage bias, as well as cell-type specific cryptic 3’ splice site usage in SF3B1mut cells, precede overt MDS. Collectively, we present an expanded multi-omics single-cell toolkit to define the cell-type specific impact of somatic mutations on RNA splicing, from the earliest phases of clonal outgrowths to overt neoplasia, directly in human samples.",2022-06-09,https://www.semanticscholar.org/paper/d56cc7ab718dd58733360f83b0e3d2070e786510,bioRxiv
3525,Approximating the Minimum-Cost Maximum Flow is P-Complete,,1992-07-24,https://www.semanticscholar.org/paper/4a2c620056a97f1f7dcd09fdf63223668fbd9723,Information Processing Letters
3780,A large-scale benchmark dataset for event recognition in surveillance video,"We introduce a new large-scale video dataset designed to assess the performance of diverse visual event recognition algorithms with a focus on continuous visual event recognition (CVER) in outdoor areas with wide coverage. Previous datasets for action recognition are unrealistic for real-world surveillance because they consist of short clips showing one action by one individual [15, 8]. Datasets have been developed for movies [11] and sports [12], but, these actions and scene conditions do not apply effectively to surveillance videos. Our dataset consists of many outdoor scenes with actions occurring naturally by non-actors in continuously captured videos of the real world. The dataset includes large numbers of instances for 23 event types distributed throughout 29 hours of video. This data is accompanied by detailed annotations which include both moving object tracks and event examples, which will provide solid basis for large-scale evaluation. Additionally, we propose different types of evaluation modes for visual recognition tasks and evaluation metrics along with our preliminary experimental results. We believe that this dataset will stimulate diverse aspects of computer vision research and help us to advance the CVER tasks in the years ahead.",2011-06-20,https://www.semanticscholar.org/paper/89d80d34bc0cf1cc9f62a76c0ffa5b01f05b9ee7,Computer Vision and Pattern Recognition
1035,Snakeboard motion planning with viscous friction and skidding,"The snakeboard is a well-studied example for mechanical systems analysis, largely because of its simultaneous richness in behavior and simplicity in design. However, few snakeboard models incorporate dissipative friction in the traveling direction and skidding as a violation of the rigid nonholonomic constraints. In this paper we investigate these effects on trajectory planning by evaluating a previously proposed friction model as well as a novel skidding model based on the addition of Rayleigh dissipation functions. We show how these additions change the usual behavior of gaits in the forward planning problem, and incorporate the changes into the solutions of the inverse planning problem by utilizing body coordinates along with a curvature parameterization for trajectories.",2015-05-26,https://www.semanticscholar.org/paper/b890772a9b44fc9f153c63e7046f427067613c6d,IEEE International Conference on Robotics and Automation
264,Optimal deterministic auctions with correlated priors,,2010-11-04,https://www.semanticscholar.org/paper/1265ed2bb9c4a4b1c69f0a709aa029fbf7aa1004,Games Econ. Behav.
569,The throughput of a precedence-based queuing discipline,,1985-11-01,https://www.semanticscholar.org/paper/ffabb9e66d5b4da2d14c113ab0bb2ab55fc2203d,
2649,Virtual reality [Guest Editor],,2000-11-01,https://www.semanticscholar.org/paper/3ffa1802ede391ed3f042d5b39cd29a932a27d47,
2632,"Unit — A modular framework for interaction technique design , development and implementation","This thesis presents the Unit Concept, a framework for the development, design and implementation of interaction techniques. Unit’s main goal is to stimulate the progress of new interfaces that go beyond the traditional keyboard/mouse setup. Virtual, Mixed and Augmented Reality are examples of new technologies that demand advanced interaction techniques with concepts such as proprioception, two-handed interaction and physical Interfaces. These are practically impossible to represent within the traditional human-computer interface and new mechanisms are needed to enable their development. Unit places the interaction techniques in an abstraction layer between the input devices and the application, which allows the application developer to separate application functionality from interaction technique and behavior. Unit’s modular approach leads to the design of reusable interaction control components that are independent of the application. Unit’s nature makes it possible to interactively change, tweak and experiment with the behavior of the interaction techniques, but also to switch among different input device configurations.",,https://www.semanticscholar.org/paper/62c9bafd01dc122db06807d054fcb389718b1d69,
3341,1. Socioecology: Origins and Trends,,1987-01-31,https://www.semanticscholar.org/paper/52755412b981ad768d011f84a39e8d63dd670354,
1886,An inverse-distance weighting genetic algorithm for optimizing the wafer exposure pattern for enhancing OWE for smart manufacturing,,2020-09-01,https://www.semanticscholar.org/paper/8099215fc5b5d3a94ed2692b18013da10d64c68f,Applied Soft Computing
2779,Distinct features of the host-parasite interactions between nonadherent and adherent Trichomonas vaginalis isolates,"Cytoadherence of Trichomonas vaginalis to human vaginal epithelial cells (hVECs) was previously shown to involve surface lipoglycans and several reputed adhesins on the parasite. Herein, we report some new observations on the host-parasite interactions of adherent versus nonadherent T. vaginalis isolates to hVECs. The binding of the TH17 adherent isolate to hVECs exhibited an initial discrete phase followed by an aggregation phase inhibited by lactose. T. vaginalis infection immediately induced surface expression of galectin-1 and -3, with extracellular amounts in the spent medium initially decreasing and then increasing thereafter over the next 60 min. Extracellular galectin-1 and -3 were detected on the parasite surface but only the TH17 adherent isolate could uptake galectin-3 via the lysosomes. Only the adherent isolate could morphologically transform from the round-up flagellate with numerous transient protrusions into a flat amoeboid form on contact with the solid surface. Cytochalasin D challenge revealed that actin organization was essential to parasite morphogenesis and cytoadherence. Real-time microscopy showed that parasite exploring and anchoring on hVECs via the axostyle may be required for initial cytoadherence. Together, the parasite cytoskeleton behaviors may collaborate with cell surface adhesion molecules for cytoadherence. The nonadherent isolate migrated faster than the adherent isolate, with motility transiently increasing in the presence of hVECs. Meanwhile, differential histone acetylation was detected between the two isolates. Also, TH17 without Mycoplasma symbiosis suggests that symbiont might not determine TH17 innate cytoadherence. Our findings regarding distinctive host-parasite interactions of the isolates may provide novel insights into T. vaginalis infection.",2023-01-01,https://www.semanticscholar.org/paper/aa036de029bdfc112d473e0228e087c40f95ccb6,PLoS Neglected Tropical Diseases
3160,"Wall: "" a New Framework for Processor Scheduling, "" in Progress. 5.3 New Timesharing Class 6 Conclusions and Future Work 5.2 Svr4 Timesharing and Realtime Classes 5 Interpretation of Results","addition, when the system is overloaded with continuous media applications, a way of identifying applications of lesser or greater importance to the users can allow the system to automatically perform service trade-offs rather than forcing it to degrade all applications equally at best, or randomly at worst. Armed with such information, the system can manage its resources in such a way as to maximize the total value delivered to the end user. Towards this end, we are creating a new scheduling framework , based on Time-Driven Resource Management [6, 8, 9], that provides the flexible control and delivered performance required for multimedia applications. Finally, note that the existence of the strict-priority realtime scheduling class in standard SVR4 in no way allows a user to effectively deal with these types of problems. In addition, it opens the very real possibility of runaway applications that consume all CPU resources and effectively prevent a user or system administrator from regaining control without rebooting the system. 7 Acknowledgments Monica Lam provided many insightful suggestions, especially during the formative stages of this work. A new timesharing scheduling class was developed in order to correct the problems demonstrated in these experimental runs. In particular, the modified version removes the anomalies of identifying batch jobs as interactive, and vice versa. In addition, it attempts to ensure that each process that can run is given the opportunity to make steady progress in its computation, while retaining a bias in favor of interactive processes. Finally, it reduces the feedback interval over which CPU behavior is monitored and penalties and rewards given. The timesharing scheduling class contained in Sun's Solaris 2.3 operating system is based on this work. The results of the default use of this class for all applications and the window server process are given by Figure 2i. As can be seen, this delivers significantly better results for the continuous media and interactive applications than any combination of the standard SVR4 scheduling classes. It should also be noted that this scheduling policy achieves this level of performance without significantly starving the batch application, which still receives approximately 30% of the available CPU time. Additional tests were performed by adjusting user priorities and by combining this new scheduling class with the SVR4 RT class (as was done with SVR4 TS class). However, with the exception of the cases where there was sufficient load in the RT class to consume …",,https://www.semanticscholar.org/paper/58936b249316c9b64ee77a46e847b828b12b89e9,
120,Optimizing queries over multimedia repositories,"Repositories of multimedia objects having multiple types of attributes (e.g., image, text) are becoming increasingly common. A selection on these attributes will typically produce not just a set of objects, as in the traditional relational query model (filtering), but also a grade of match associated with each object, indicating how well the object matches the selection condition (ranking). Also, multimedia repositories may allow access to the attributes of each object only through indexes. We investigate how to optimize the processing of queries over multimedia repositories. A key issue is the choice of the indexes used to search the repository. We define an execution space that is search-minimal, i.e., the set of indexes searched is minimal. Although the general problem of picking an optimal plan in the search-minimal execution space is NP-hard, we solve the problem efficiently when the predicates in the query are independent. We also show that the problem of optimizing queries that ask for a few top-ranked objects can be viewed, in many cases, as that of evaluating selection conditions. Thus, both problems can be viewed together as an extended filtering problem.",1996-06-01,https://www.semanticscholar.org/paper/1613abd9402dbd7461d652d74071cb91ef7a21b7,ACM SIGMOD Conference
2322,"Priming of the respiratory burst of human neutrophils by the diadenosine polyphosphates, AP4A and AP3A: role of intracellular calcium.","The diadenosine polyphosphates, Ap3A and Ap4A, prime the respiratory burst of human neutrophils after stimulation with fMet-Leu-Phe. Maximal priming of oxidase activity occurred at 600-800 microM Ap3A and Ap4A, compared with maximal priming observed at 200 microM ATP. The time course of priming of the oxidase by all 3 nucleotides was very rapid, being detectable if added within 10 s of fMet-Leu-Phe. All 3 nucleotides also elicited increases in intracellular Ca2+ levels and there was a close concentration-dependency between the extent of priming and the increase in intracellular Ca2+. However, at low concentrations of nucleotides (< 50 microM Ap3A and Ap4A and < 0.1 microM ATP) priming of the oxidase was observed without detectable increases in intracellular Ca2+. These observations indicate that diadenosine polyphosphates may be novel regulators of neutrophil function and that priming of oxidase activity may occur via mechanisms that are either dependent or independent of increases in intracellular Ca2+.",1994-07-15,https://www.semanticscholar.org/paper/47e429d6c9381ecd1bc5efa22e7d2ffa3927eccd,Biochemical and Biophysical Research Communications - BBRC
1347,Measurement of the lifetime difference in the bs system,"V. M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, M. Agelou, J.-L. Agram, S. H. Ahn, M. Ahsan, G. D. Alexeev, G. Alkhazov, A. Alton, G. Alverson, G. A. Alves, M. Anastasoaie, T. Andeen, S. Anderson, B. Andrieu, Y. Arnoud, M. Arov, A. Askew, B. Asman, A. C. S. Assis Jesus, O. Atramentov, C. Autermann, C. Avila, F. Badaud, A. Baden, L. Bagby, B. Baldin, P. W. Balm, P. Banerjee, S. Banerjee, E. Barberis, P. Bargassa, P. Baringer, C. Barnes, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, A. Bean, S. Beauceron, M. Begalli, M. Begel, A. Bellavance, S. B. Beri, G. Bernardi, R. Bernhard,* I. Bertram, M. Besancon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, M. Binder, C. Biscarat, K. M. Black, I. Blackler, G. Blazey, F. Blekman, S. Blessing, D. Bloch, U. Blumenschein, A. Boehnlein, O. Boeriu, T. A. Bolton, F. Borcherding, G. Borissov, K. Bos, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, S. Burdin, S. Burke, T. H. Burnett, E. Busato, C. P. Buszello, J. M. Butler, J. Cammin, S. Caron, W. Carvalho, B. C. K. Casey, N. M. Cason, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K. M. Chan, A. Chandra, D. Chapin, F. Charles, E. Cheu, D. K. Cho, S. Choi, B. Choudhary, T. Christiansen, L. Christofek, D. Claes, B. Clement, C. Clement, Y. Coadou, M. Cooke, W. E. Cooper, D. Coppage, M. Corcoran, A. Cothenet, M.-C. Cousinou, B. Cox, S. Crepe-Renaudin, D. Cutts, H. da Motta, M. Das, B. Davies, G. Davies, G. A. Davis, K. De, P. de Jong, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, S. Dean, J. D. Degenhardt, F. Deliot, M. Demarteau, R. Demina, P. Demine, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, M. Doidge, H. Dong, S. Doulas, L. V. Dudko, L. Duflot, S. R. Dugad, A. Duperrin, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, T. Edwards, J. Ellison, J. Elmsheuser, V. D. Elvira, S. Eno, P. Ermolov, O. V. Eroshin, J. Estrada, H. Evans, A. Evdokimov, V. N. Evdokimov, J. Fast, S. N. Fatakia, L. Feligioni, A. V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, I. Fleck, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, E. Gallas, E. Galyaev, C. Garcia, A. Garcia-Bellido, J. Gardner, V. Gavrilov, A. Gay, P. Gay, D. Gele, R. Gelhaus, K. Genser, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, T. Golling, N. Gollub, B. Gomez, K. Gounder, A. Goussiou, P. D. Grannis, S. Greder, H. Greenlee, Z. D. Greenwood, E. M. Gregores, Ph. Gris, J.-F. Grivaz, L. Groer, S. Grunendahl, M. W. Grunewald, S. N. Gurzhiev, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, S. Hagopian, I. Hall, R. E. Hall, C. Han, L. Han, K. Hanagaki, K. Harder, A. Harel, R. Harrington, J. M. Hauptman, R. Hauser, J. Hays, T. Hebbeker, D. Hedin, J. M. Heinmiller, A. P. Heinson, U. Heintz, C. Hensel, G. Hesketh, M. D. Hildreth, R. Hirosky, J. D. Hobbs, B. Hoeneisen, M. Hohlfeld, S. J. Hong, R. Hooper, P. Houben, Y. Hu, J. Huang, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffre, S. Jain, V. Jain, K. Jakobs, A. Jenkins, R. Jesik, K. Johns, M. Johnson, A. Jonckheere, P. Jonsson, A. Juste, D. Kafer, S. Kahn, E. Kajfasz, A. M. Kalinin, J. Kalk, D. Karmanov, J. Kasper, I. Katsanos, D. Kau, R. Kaur, R. Kehoe, S. Kermiche, S. Kesisoglou, A. Khanov, A. Kharchilava, Y. M. Kharzheev, H. Kim, T. J. Kim, B. Klima, J. M. Kohli, J.-P. Konrath, M. Kopal, V. M. Korablev, J. Kotcher, B. Kothari, A. Koubarovsky, A. V. Kozelov, J. Kozminski, A. Kryemadhi, S. Krzywdzinski, Y. Kulik, A. Kumar, S. Kunori, A. Kupco, T. Kurca, J. Kvita, S. Lager, N. Lahrichi, G. Landsberg, J. Lazoflores, A.-C. Le Bihan, P. Lebrun, W. M. Lee, A. Leflat, F. Lehner,* C. Leonidopoulos, J. Leveque, P. Lewis, J. Li, Q. Z. Li, J. G. R. Lima, D. Lincoln, S. L. Linn, J. Linnemann, V. V. Lipaev, R. Lipton, L. Lobo, A. Lobodenko, M. Lokajicek, A. Lounis, P. Love, H. J. Lubatti, L. Lueking, L. Luo, M. Lynker, A. L. Lyon, A. K. A. Maciel, R. J. Madaras, P. Mattig, C. Magass, A. Magerkurth, A.-M. Magnan, N. Makovec, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, H. S. Mao, Y. Maravin, M. Martens, S. E. K. Mattingly, A. A. Mayorov, R. McCarthy, R. McCroskey, D. Meder, A. Melnitchouk, A. Mendes, D. Mendoza, M. Merkin, K. W. Merritt, A. Meyer, J. Meyer, M. Michaut, H. Miettinen, J. Mitrevski, J. Molina, N. K. Mondal, R. W. Moore, T. Moulik, G. S. Muanza, M. Mulders, L. Mundim, Y. D. Mutaf, E. Nagy, M. Naimuddin, M. Narain, N. A. Naumann, H. A. Neal, J. P. Negret, S. Nelson, P. Neustroev, C. Noeding, A. Nomerotski, S. F. Novaes, T. Nunnemann, E. Nurse, V. O’Dell, D. C. O’Neil, V. Oguri, N. Oliveira, N. Oshima, G. J. Otero y Garzon, P. Padley, N. Parashar, S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, G. Pawloski,",2005-07-19,https://www.semanticscholar.org/paper/859c20199f7afdde3fbac6970bc6c4aeda3fac41,
1241,Observation of the Doubly Strange b Baryon,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, M. Ahsan, G. D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G.A. Alves, M. Anastasoaie, L. S. Ancu, T. Andeen, B. Andrieu, M. S. Anzelc, M. Aoki, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, A. C. S. Assis Jesus, O. Atramentov, C. Avila, F. Badaud, L. Bagby, B. Baldin, D. V. Bandurin, P. Banerjee, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, C. Biscarat, G. Blazey, F. Blekman, S. Blessing, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, E. E. Boos, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, X. B. Bu, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, T. H. Burnett, C. P. Buszello, J.M. Butler, P. Calfayan, S. Calvet, J. Cammin, E. Carrera, W. Carvalho, B. C. K. Casey, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K.M. Chan, A. Chandra, E. Cheu, F. Chevallier, D. K. Cho, S. Choi, B. Choudhary, L. Christofek, T. Christoudias, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, V. Cuplov, D. Cutts, M. Ćwiok, H. da Motta, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, K. DeVaughan, J. D. Degenhardt, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, H. Dong, T. Dorland, A. Dubey, L. V. Dudko, L. Duflot, S. R. Dugad, D. Duggan, A. Duperrin, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V.D. Elvira, Y. Enari, S. Eno, P. Ermolov, H. Evans, A. Evdokimov, V.N. Evdokimov, A.V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, C. Garcia, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, W. Geng, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, N. Gollub, B. Gómez, A. Goussiou, P. D. Grannis, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Harder, A. Harel, J.M. Hauptman, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, A. P. Heinson, U. Heintz, C. Hensel, K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, J. D. Hobbs, B. Hoeneisen, H. Hoeth, M. Hohlfeld, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, C. Jarvis, R. Jesik, K. Johns, C. Johnson, M. Johnson, D. Johnston, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, J.M. Kalk, D. Karmanov, P. A. Kasper, I. Katsanos, D. Kau, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y.M. Kharzheev, D. Khatidze, T. J. Kim, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, E. V. Komissarov, J.-P. Konrath, A.V. Kozelov, J. Kraus, T. Kuhl, A. Kumar, A. Kupco, T. Kurča, V. A. Kuzmin, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, W.M. Lee, A. Leflat, J. Lellouch, J. Li, L. Li, Q. Z. Li, S.M. Lietti, J. K. Lim, J. G. R. Lima, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna, A. L. Lyon, A. K.A. Maciel, D. Mackin, R. J. Madaras, P. Mättig, C. Magass, A. Magerkurth, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, Y. Maravin, B. Martin, R. McCarthy, A. Melnitchouk, L. Mendoza, P. G. Mercadante, Y. P. Merekov, M. Merkin, K.W. Merritt, A. Meyer, J. Meyer, J. Mitrevski, R.K. Mommsen, N. K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, N. A. Naumann, H.A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, V. O’Dell, D. C. O’Neil, G. Obrant, C. Ochando, D. Onoprienko, J. Orduna, N. Oshima, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park, S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, M. Petteni, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma,33,x V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, B. G. Pope, A.V. Popov, C. Potter, W. L. Prado da Silva, H. B. Prosper, S. Protopopescu, J. Qian, A. Quadt, B. Quinn, A. Rakitine, M. S. Rangel, K. Ranjan, P. N. Ratoff, P. Renkel, P. Rich, J. Rieger, M. Rijssenbeek, I. Ripp-Baudot, F. Rizatdinova, S. Robinson, R. F. Rodrigues, PRL 101, 232002 (2008) P HY S I CA L R EV I EW LE T T E R S week ending 5 DECEMBER 2008",,https://www.semanticscholar.org/paper/985b828ede0fe8a4d3a13ccdfe1648459bed8fdb,
3299,Conservation planning on a budget: a “resource light” method for mapping priorities at a landscape scale?,,2009-01-20,https://www.semanticscholar.org/paper/7a7066214cdcc1c30533cab7030bfec83bf9d8ca,Biodiversity and Conservation
2124,A Group Decision Support System for Telecommunication Network Planning,,,https://www.semanticscholar.org/paper/fcc3fd0260d24b2483f289b79df3945b13babc97,
1882,Minimax Optimization for Recipe Management in High-Mixed Semiconductor Lithography Process,"This article addresses the application of minimax optimization in the control design of complex dynamic systems of the semiconductor manufacturing. We highlight the main challenge in the control system of high-mixed wafer fabrication during the photolithography process called overlay control. In the semiconductor photolithography process, the sophisticated and high-mixed setting is generated by multiple recipe adjustments for the single scanner device. The high complexity will be moderated if there is a communication interface among the process variables. We design a communication protocol for the high-mixed photolithography process for overlay control. The proposed system is designed on the basis of the recipe management system for a distinct batches of recipes. The focal point of switching recipes performs as a communication hop, where aligning recipes together make a multihop communication system for recipe management. The proposed multihop communication system is optimized by the minimax decision rule to select the best parameter setting for each recipe and boost the overlay compensation.",2020-08-01,https://www.semanticscholar.org/paper/3832008bdcec73b20b1779faa9d5900981b22375,IEEE Transactions on Industrial Informatics
1011,Retinal Oximetry Based on Nonsimultaneous Image,"To measure the retinal arteriole and venule oxygen saturation using a conventional fundus camera, retinal oximetry based on nonsimultaneous image acquisition was devel- oped andevaluated.Tworetinal images weresequentially acquired using a conventional fundus camera with two bandpass filters (568 nm: isobestic, 600 nm: nonisobestic wavelength), one after another, instead of a built-in green filter. The images were registered to compensate for the differences caused by eye movements during the image acquisition. Retinal was measured using two wave- length oximetry. To evaluate sensitivity of the proposed method, in the arterioles and venules before and after inhalation of 100% were compared, respectively, in 11 healthy subjects. After inhalation of 100% , increased from to in the arterioles and from to in the venules (paired t-test, ). Reproducibility of the method was 2.6% and 5.2% in the arterioles and venules, respectively (average standard deviation of five measurements, ).",,https://www.semanticscholar.org/paper/d321081166a75ac3803d867895111b3dc8d45411,
2520,Physician-driven management of patient progress notes in an intensive care unit,"We describe fieldwork in which we studied hospital ICU physicians and their strategies and documentation aids for composing patient progress notes. We then present a clinical documentation prototype, activeNotes, that supports the creation of these notes, using techniques designed based on our fieldwork. ActiveNotes integrates automated, context-sensitive patient data retrieval, and user control of automated data updates and alerts via tagging, into the documentation process. We performed a qualitative study of activeNotes with 15 physicians at the hospital to explore the utility of our information retrieval and tagging techniques. The physicians indicated their desire to use tags for a number of purposes, some of them extensions to what we intended, and others new to us and unexplored in other systems of which we are aware. We discuss the physicians' responses to our prototype and distill several of their proposed uses of tags: to assist in note content management, communication with other clinicians, and care delivery.",2010-04-10,https://www.semanticscholar.org/paper/656b7bd6457bc04070f750462337ba868e8d72c7,International Conference on Human Factors in Computing Systems
2733,Software Technology for Wireless Mobile Computing Daniel Duchamp,,,https://www.semanticscholar.org/paper/148faeb2514913084f4f0fa6721b849d08f5d504,
1550,A general linear-time inference method for Gaussian Processes on one dimension,"Gaussian Processes (GPs) provide powerful probabilistic frameworks for interpolation, forecasting, and smoothing, but have been hampered by computational scaling issues. Here we investigate data sampled on one dimension (e.g., a scalar or vector time series sampled at arbitrarily-spaced intervals), for which state-space models are popular due to their linearly-scaling computational costs. It has long been conjectured that state-space models are general, able to approximate any one-dimensional GP. We provide the first general proof of this conjecture, showing that any stationary GP on one dimension with vector-valued observations governed by a Lebesgue-integrable continuous kernel can be approximated to any desired precision using a specifically-chosen state-space model: the Latent Exponentially Generated (LEG) family. This new family offers several advantages compared to the general state-space model: it is always stable (no unbounded growth), the covariance can be computed in closed form, and its parameter space is unconstrained (allowing straightforward estimation via gradient descent). The theorem’s proof also draws connections to Spectral Mixture Kernels, providing insight about this popular family of kernels. We develop parallelized algorithms for performing inference and learning in the c ©2021 Jackson Loper, David Blei, John P. Cunningham, Liam Paninski. License: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/. Attribution requirements are provided at http://jmlr.org/papers/v22/21-0072.html. Loper, Blei, Cunningham, and Paninski LEG model, test the algorithm on real and synthetic data, and demonstrate scaling to datasets with billions of samples.",,https://www.semanticscholar.org/paper/bede99a33904742db2abe4f3b93cae70f4fdbe91,Journal of machine learning research
2175,Modified culture protocol for differentiation of human promyelocytic leukaemia PLB-985 cell-line into mature neutrophil-like granulocytes,"
 Neutrophils are considered to be mature and terminally differentiated. They are short-lived, lack proliferation capacity and are impossible to transfect in vitro to express exogenous genes or proteins. These properties have made their ex vivo experimental manipulation and biochemical studies of their signal activation mechanisms and genetic makeup, challenging. Establishment of cell line models capable of differentiating along the myeloid lineage into mature neutrophil-like granulocytes, with similar morphological and functional properties to blood neutrophils would, therefore, be an important tool to enable transfection of key genes and determine the effects of such manipulations on neutrophil functions. PLB-985 is a recently established cell line that has been demonstrated to show greater levels of differentiation into granulocyte in the presence of appropriate differentiation-inducing agents, but the efficiency of differentiation reported so far was very low, and the differentiated cells only partly resembled mature blood neutrophils. This study developed a modified differentiation protocol and an optimised culture conditions that induced the PLB-985 cell line to differentiate into mature, neutrophil-like granulocytes, Terminally-differentiated, neutrophil-like phenotypes of PLB-985 cells that resembled mature blood neutrophil morphology, and which had an appreciably delayed apoptosis have been consistently cultured. This was evident by the acquisition of multi-lobed nucleus, granulated cytoplasm and delayed apoptosis. The differentiated PLB-985 cells may, therefore, provide an excellent neutrophil-model system for in vitro study of neutrophil differentiation, signalling and functions.",2020-05-01,https://www.semanticscholar.org/paper/afd6c5e13e2272a06a141f421a3a4f70259d077b,Journal of Immunology
379,The Joy of Theory,"This talk is meant to be a celebration of theoreticians, thier achievements, and thier unique style, drawing to a large extent on examples from this volume.Theoretical Computer Science has largely succeeded in its core mission, that is, improving a rigorous and productive foundational understanding of the power and limitations of the von Neumann computer and its software. And in the past few years it has strived to extend its reach to the Internet and the worldwide web, the central computational artifact of our times.But theoreticians have achieved much more than this. Our community has identified P vs. NP, arguably the deepest and most important mathematical question of our time -- and it is leading the assault on it. In addition we are developing ""algorithmic mirrors"" through which other sciences (notably Physics and Biology, with Economics and other Social Sciences soon to join) rediscover, fruitfully, themselves. And we have furthered and influenced crucially Combinatorics and Logic, the important mathematical fields from which we have drawn methodologically. The newfound respectability and prestige of our parent field, Computer Science, owes much to these achievements.Theoreticians comprise a microcosm with wonderful characteristics: Great scientific, social, and intellectual openness; responsibility and mutual respect, but also healthy doses of irreverence, mistrust of the establishment, willingness to experiment, and self-critical spirit; and a strong sense of an international community that is remarkably cohesive and tightly knit while celebrating the diversity of its people, of their backgrounds, and of their scientific interests and approaches.We have also developed a fascinating, complex esthetic of our work based on mathematical elegance and depth, relevance and fashion, timeliness and competition -- but also on playfulness and humor. Our esthetic has served us well: Some of our most important results were derived by long chains of contributions, each seemingly guided to a large extent by such esthetic considerations. In fact, this esthetic extends delightfully to the exposition of our work, as evidenced by the unique genre of scientific prose known as ""FOCS/STOC abstract"".",2002-05-19,https://www.semanticscholar.org/paper/f0508d72d767666aae1b925c848a13752ae996a5,Symposium on the Theory of Computing
1740,Exploiting affinities between topic modeling and the sociological perspective on culture: Application to newspaper coverage of U.S. government arts funding,,2013-12-01,https://www.semanticscholar.org/paper/e2f61db561f1bc1c11b031ca33049d70196a6f95,
3555,Exclusive Interview with,,,https://www.semanticscholar.org/paper/47206984317a3b7e7359de0ce0c744dd2009f5e2,
2045,"Tong Lung Metal Industry Co., Ltd.",,2008-09-02,https://www.semanticscholar.org/paper/44d306b245a8098e2a13f240b1e1d0954836f1c1,
1686,The Survival Filter: Joint Survival Analysis with a Latent Time Series,"Survival analysis is a core task in applied statistics, which models time-to-failure or time-to-event data. In the clinical domain, for example, meaningful events are defined as the onset of different diseases for a given patient. Survival analysis is limited, however, for analyzing modern electronic health records. Patients often have a wide range of diseases, and there are complex interactions among the relative risks of different events. To this end, we develop the survival filter model, a time-series model for joint survival analysis that models multiple patients and multiple diseases. We develop a scalable variational inference algorithm and apply our method to a large data set of longitudinal patient records. The survival filter gives good predictive performance when compared to two baselines and identifies clinically meaningful patterns of disease interaction.",2015-07-12,https://www.semanticscholar.org/paper/9f08a5e4360a7823e596ed4567a5f671ec3759a3,Conference on Uncertainty in Artificial Intelligence
2621,The Flexible Pointer: An Interaction Technique for Selection in Augmented and Virtual Reality,"We present a virtual flexible pointer that allows a user in a 3D environment to point more easily to fully or partially obscured objects, and to indicate objects to other users more clearly. The flexible pointer can also reduce the need for disambiguation and can make it possible for the user to point to more objects than currently possible with existing egocentric techniques.",,https://www.semanticscholar.org/paper/8888e8567faad4e2b4071e3365c90aaa727ca460,
130,Adaptive deadlock- and livelock-free routing with all minimal paths in Torus networks,"This paper consists of two parts. In the first part, two new algorithms for deadlock- and livelock-free wormhole routing in the torus network are presented. The first algorithm, called Channels, is for the n-dimensional torus network. This technique is fully-adaptive minimal, that is, all paths with a minimal number of hops from source to destination are available for routing, and needs only five virtual channels per bidirectional link, the lowest channel requirement known in the literature for fully-adaptive minimal worm-hole routing. In addition, this result also yields the lowest buffer requirement known in the literature for packet-switched fully-adaptive minimal routing. The second algorithm, called 4-Classes, is for the bidimensional torus network. This technique is fully-adaptive minimal and requires only eight virtual channels per bidirectional link. Also, it allows for a highly parallel implementation of its associated routing node. In the second part of this paper, four worm-hole routing techniques for the two-dimensional torus are experimentally evaluated using a dynamic message injection model and different traffic patterns and message lengths. >",1992-06-01,https://www.semanticscholar.org/paper/278dd6415f07db4d6ec13096642e4f1cf5189f58,ACM Symposium on Parallelism in Algorithms and Architectures
414,Topological Queries,,1999-07-20,https://www.semanticscholar.org/paper/f8d66dc1509e2da793b6e6df43587537dec00422,"International Multi-Conference on Systems, Signals & Devices"
1386,UvA-DARE ( Digital Academic Repository ) Search for large extra dimensions in the monojet + missing E ( T ) channel at D 0,"Disclaimer/Complaints regulations If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. In case of a legitimate complaint, the Library will make the material inaccessible and/or remove it from the website. Please Ask the Library: http://uba.uva.nl/en/contact, or a letter to: Library of the University of Amsterdam, Secretariat, Singel 425, 1012 WP Amsterdam, The Netherlands. You will be contacted as soon as possible.",,https://www.semanticscholar.org/paper/74154dbe05aad8d9d0800403dc40659c152c4b29,
2382,Restriction enzyme analysis of mitochondrial DNA of members of the genus Acanthamoeba as an aid in taxonomy,"Restriction enzyme analysis of mitochondrial DNA (mtDNA) appears to be a useful technique for the examination of the possible relationship of organisms [1]. Using this method several studies have already been carried out on such groups as Aspergillus [2], Paramecium [3] and rats [4]. In this paper we have used restriction enzyme analysis to compare the mtDNAs of a number of strains of the free-living protozoa belonging to the genus Acanthamoeba. Such a study would be of some value as previous attempts to examine the relationships of these organisms using morphological characters have not been wholly successful.",1983-03-01,https://www.semanticscholar.org/paper/86c8e30cd32e2b7bd23aa1bc750a80c15d040ae3,
325,The complexity of low-distortion embeddings between point sets,We prove that it is NP-hard to approximate by a ratio better than 3 the minimum distortion of a bijection between two given finite three-dimensional sets of points.,2005-01-23,https://www.semanticscholar.org/paper/0e007f56b766cd711c321af344b1156480074933,ACM-SIAM Symposium on Discrete Algorithms
2926,A human lung tumor microenvironment interactome identifies clinically relevant cell-type cross-talk,,2020-05-07,https://www.semanticscholar.org/paper/2d8a5c8740384b4f8f10620597e7e859133249eb,Genome Biology
3138,Inferring client response time at the web server,"As businesses continue to grow their World Wide Web presence, it is becoming increasingly vital for them to have quantitative measures of the client perceived response times of their web services. We present Certes (CliEnt Response Time Estimated by the Server), an online server-based mechanism for web servers to measure client perceived response time, as if measured at the client. Certes is based on a model of TCP that quantifies the effect that connection drops have on perceived client response time, by using three simple server-side measurements: connection drop rate, connection accept rate and connection completion rate. The mechanism does not require modifications to http servers or web pages, does not rely on probing or third party sampling, and does not require client-side modifications or scripting. Certes can be used to measure response times for any web content, not just HTML. We have implemented Certes and compared its response time measurements with those obtained with detailed client instrumentation. Our results demonstrate that Certes provides accurate server-based measurements of client response times in HTTP 1.0/1.1 [14] environments, even with rapidly changing workloads. Certes runs online in constant time with very low overhead. It can be used at web sites and server farms to verify compliance with service level objectives.",2002-06-15,https://www.semanticscholar.org/paper/3fd4dd73277e3c1bb6a5db95eac2108531ceb0f2,Measurement and Modeling of Computer Systems
3454,Vertex Cover Approximations: Experiments and Observations,,2005-05-10,https://www.semanticscholar.org/paper/832e5c3c51cdc75891254af9eaf4141293878d43,Workshop on Engineering Applications
925,Worst-case ration for planar graphs and the method of induction on faces,"The fact that several inlportant combinatorial optimiz.ation problems are NP-colnplete has motivated research on the worst-case analysis of approximation heuristics for these problems [Jol, GIl, Ch). TIlcse inve.stigations have produced some very interesting results"" and considerable insight has been gained by no\v into the power and limitations of existing techniques. The most inlportnnt paradigm in this area is bin packing [JDGGU, J02, Yao, GJ2, GJ3] and its generalizations [GOJY, CGJT). '[his is so because of the elegance and depth of the cOlnbinatorial arguments employed in the proofs of the upper bounds, and the intricate constnlctions of exanlples that achieve them. Despite the presence of the unifying cotlcept of a weighting [unction, the arguments are usually ingenious yet ad hoc, and the construction of worst-case exmnp)es is largely decoupled from the upper bounding process. In this paper we present a fanlily of results concerning certain extrenlal properties of planar graphs. In particular we show the follo\ving: (1) The greedy heuristic (i.e., repeatedly pick the node with smallest degree and delete its neighborhood) applied to a planar graph with n nodes yields an independent set of size at least 4n/21. (2) l'he greedy heuristic yields an independent set at )etlst 23/63 times the optimum. (3) A planar graph with n nodes and minimum degree 3 has ahvays a nzatching with fewer than n/3 free nodes.",1981-10-28,https://www.semanticscholar.org/paper/a00698715ac9afeb85a8e1992bcd4231f809467b,22nd Annual Symposium on Foundations of Computer Science (sfcs 1981)
2893,LDmat: efficiently queryable compression of linkage disequilibrium matrices,"Abstract Motivation Linkage disequilibrium (LD) matrices derived from large populations are widely used in population genetics in fine-mapping, LD score regression, and linear mixed models for Genome-wide Association Studies (GWAS). However, these matrices can reach large sizes when they are derived from millions of individuals; hence, moving, sharing and extracting granular information from this large amount of data can be cumbersome. Results We sought to address the need for compressing and easily querying large LD matrices by developing LDmat. LDmat is a standalone tool to compress large LD matrices in an HDF5 file format and query these compressed matrices. It can extract submatrices corresponding to a sub-region of the genome, a list of select loci, and loci within a minor allele frequency range. LDmat can also rebuild the original file formats from the compressed files. Availability and implementation LDmat is implemented in python, and can be installed on Unix systems with the command ‘pip install ldmat’. It can also be accessed through https://github.com/G2Lab/ldmat and https://pypi.org/project/ldmat/. Supplementary information Supplementary data are available at Bioinformatics online.",2023-02-01,https://www.semanticscholar.org/paper/60688664eef3ab172b8f2c4eaee7bcee2a7806d1,Bioinformatics
879,Embedding Planar Graphs in Four Pages,,,https://www.semanticscholar.org/paper/cdf9707d7e0b46bfa79f60642a3aac665f438cef,Journal of computer and system sciences (Print)
179,Introduction to the Theory of Computation,"Exercise 1. A 2-counter machine (2CM) has a finite state control, and two stacks on which it can push and pop tokens, where these tokens are all alike. The transition function for a 2CM takes as input the current state, and whether the stacks are empty or non-empty. For example, δ(q, >, =) = (q,−, +) means “if in state q where stack 1 is not empty and stack 2 is empty, move into state q, pop a token from stack 1, and push a token on stack 2.” These machines are called counter machines because it’s only the count (number) of tokens in a stack that matters, since the tokens are all alike.",,https://www.semanticscholar.org/paper/52af684205908e42f99b25efede792a40aca5b27,
813,An Efficient Algorithm for Minimizing Real-Time Transition Systems,,1997-08-01,https://www.semanticscholar.org/paper/049ba7d771474cfd3b903230872b5d1c7e130405,Formal Methods Syst. Des.
730,"Explorer Stochastic Context-Free Grammars , Regular Languages , and Newton ' s Method","We study the problem of computing the probability that a given stochastic context-free grammar (SCFG), G, generates a string in a given regular language L(D) (given by a DFA, D). This basic problem has a number of applications in statistical natural language processing, and it is also a key necessary step towards quantitative ω-regular model checking of stochastic context-free processes (equivalently, 1-exit recursive Markov chains, or stateless probabilistic pushdown processes). We show that the probability that G generates a string in L(D) can be computed to within arbitrary desired precision in polynomial time (in the standard Turing model of computation), under a rather mild assumption about the SCFG, G, and with no extra assumption about D. We show that this assumption is satisfied for SCFG’s whose rule probabilities are learned via the well-known inside-outside (EM) algorithm for maximum-likelihood estimation (a standard method for constructing SCFGs in statistical NLP and biological sequence analysis). Thus, for these SCFGs the algorithm always runs in P-time.",,https://www.semanticscholar.org/paper/a2c4b1c40d61a0cc43a53a2d3fadff539c662b41,
2270,Purification of ovine neutrophils and eosinophils: Anaplasma phagocytophilum affects neutrophil density.,"Studies on the functions of ovine granulocytes require pure and functionally active populations of neutrophils and eosinophils. This report describes an improved technique for the separation of neutrophils and eosinophils from the peripheral blood of sheep infected with Anaplasma phagocytophilum and from normal sheep. After centrifugation and discarding the buffy coat layer, which contains the bulk of mononuclear cells, neutrophils with a high degree of purity (94.87 [+/-1.7]%, n=9) and good yield (69 [+/-9]%, n=9) were obtained by density gradient centrifugation on Percoll with a density of 1.09 g/ml (65%). However, this density was not suitable for neutrophils obtained from sheep during the peak period of A. phagocytophilum bacteraemia. Improved purity of infected neutrophils was obtained when the leucocytes were separated on Percoll with a density of 1.08 g/ml (55%). Relatively good purity of eosinophils was obtained when leucocytes from normal sheep were separated on Percoll with a density of 1.10 g/ml (70%). Ovine eosinophils formed a distinct band just below the band of mononuclear cells when a continuous Percoll gradient with a density of 1.10 g/ml was used. The purity of the eosinophils obtained was 87.7 (+/-12.5)% (n=6; range 64.1-97.6%), with a mean recovery rate of 61.9 (+/-20.3)%.",2003-05-01,https://www.semanticscholar.org/paper/5bf0e64e088785dab6b13b75fe9f4dabe3f6f986,Journal of Comparative Pathology
2448,Papers Reviewers,Presents a listing of the papers' reviewers from the 2017 IEEE Virtual Reality Conference (IEEE VR 2017).,,https://www.semanticscholar.org/paper/c504602de222a7c88b3c0c0c5f021edf5d75b4c7,IEEE Transactions on Visualization and Computer Graphics
3719,We Have So Much In Common: Modeling Semantic Relational Set Abstractions in Videos,,2020-08-12,https://www.semanticscholar.org/paper/33c723f096c3fd156e32295325afc2e6081afac4,European Conference on Computer Vision
3487,A 2 2/3 Superstring Approximation Algorithm,,1998-11-09,https://www.semanticscholar.org/paper/02a4e481da458ab6d8e592dd2dd537f1e56a13b6,Discrete Applied Mathematics
195,N C ] 1 1 N ov 2 01 6 Assembly pointers for variable binding in networks of spiking neurons,"We propose a model for binding of variables such as the thematic role of a word in a sentence or episode (e.g., agent or patient), to concrete fillers (e.g., a word or concept). Our model is based on recent experimental data about corresponding processes in the human brain. One source of information are electrode recordings from the human brain, which suggest that concepts are represented in the medial temporal lobe (MTL) through sparse sets of neurons (assemblies). Another source of information are fMRI recordings from the human brain, which suggest that subregions of the temporal cortex are dedicated to the representation of specific roles (e.g., subject or object) of concepts in a sentence or visually presented episode. We propose that quickly recruited assemblies of neurons in these subregions act as pointers to previously created assemblies that represent concepts. We provide a proof of principle that the resulting model for binding through assembly pointers can be implemented in networks of spiking neurons, and supports basic operations of brain computations, such as structured information retrieval and copying of information. We also show that salient features of fMRI data on neural activity during structured information retrieval can be reproduced by the proposed model.",,https://www.semanticscholar.org/paper/3c75117260d8a2152cbe451eac2698517bdd677f,
1507,The DØ Collaboration,"We present a search for electroweak production of single top quarks in ≈90 pb−1 of data collected with the DØ detector at the Fermilab Tevatron collider. Using arrays of neural networks to separate signals from backgrounds, we set upper limits on the cross sections of 17 pb for the s-channel process pp̄ → tb + X , and 22 pb for the t-channel process pp̄ → tqb+ X , both at the 95% confidence level.",,https://www.semanticscholar.org/paper/c0844e0ed5b6c7e2405d220ea8e1337823f5c0a7,
2771,Future Technical Documentation Delivery Systems for Naval Maintenance and Repair.,"Abstract : This report describes the facilities that could be provided by a portable, microcomputer-based system for the delivery of maintenance and repair technical documentation in the Navy of the 1990's. It includes a comparison of existing documentation media (paper, microfiche, and audio-visual materials), emphasizing desirable features that should be preserved, and defects that should be overcome. A technology estimate is presented which extrapolates from presently available technology, indicating where further research needs to be done. The formats currently employed for Navy technical documentation and the maintenance and repair pipelines that are followed in its production and use are reviewed in an appendix. (Author)",1979-09-27,https://www.semanticscholar.org/paper/c2adaf417e491bf34ba40f894c79e5489d031799,
592,On concurrency control by multiple versions,We examine the problem of concurrency control when the database management system supports multiple versions of the data. We characterize the limit of the parallelism achievable by the multiversion approach and demonstrate the resulting space-parallelism tradeoff.,1982-03-29,https://www.semanticscholar.org/paper/801d3314d6e799c89728b33159e1b096773ba296,
2671,A distributed 3D graphics library,"We present Repo-3D, a general-purpose, object-oriented library for developing distributed, interactive 3D graphics applications across a range of heterogeneous workstations. Repo-3D is designed to make it easy for programmers to rapidly build prototypes using a familiar multi-threaded, object-oriented programming paradigm. All data sharing of both graphical and non-graphical data is done via general-purpose remote and replicated objects, presenting the illusion of a single distributed shared memory. Graphical objects are directly distributed, circumventing the “duplicate database” problem and allowing programmers to focus on the application details. Repo-3D is embedded in Repo, an interpreted, lexically-scoped, distributed programming language, allowing entire applications to be rapidly prototyped. We discuss Repo-3D’s design, and introduce the notion of local variations to the graphical objects, which allow local changes to be applied to shared graphical structures. Local variations are needed to support transient local changes, such as highlighting, and responsive local editing operations. Finally, we discuss how our approach could be applied using other programming languages, such as Java.",1998-07-24,https://www.semanticscholar.org/paper/4d8b2b12b9cebe0fead1fde1ff2efb1bff41c2dc,International Conference on Computer Graphics and Interactive Techniques
1878,Taiwan Drought was a Microcosm of Climate Change Adaptation Challenges in Complex Island Economies,,2021-08-31,https://www.semanticscholar.org/paper/3a208df7c868ec7c05f4eea733c6407a8bdf3282,Process Integration and Optimization for Sustainability
877,Optimal Scheduling of Products with Two Subassemblies on a Single Machine,We consider a single machine job shop in which subassemblies of two different types are made and then assembled into products. The time required for each type is known. A fixed changeover cost is incurred whenever the machine is switched over from one type to the other. We describe and analyze an efficient algorithm for minimizing the total flow time of the products. Applications to the automated manufacture of circuit boards are noted.,1989-06-01,https://www.semanticscholar.org/paper/3106ac3e78ef35dd2a94acb343ea06929101e369,Operational Research
1444,Installation of the cryogenic dark matter search (CDMS),,1996-02-11,https://www.semanticscholar.org/paper/f78427f6cf34e9062e2905d28512add104ed4c37,
2547,Opportunistic controls: leveraging natural affordances as tangible user interfaces for augmented reality,"We present Opportunistic Controls, a class of user interaction techniques for augmented reality (AR) applications that support gesturing on, and receiving feedback from, otherwise unused affordances already present in the domain environment. Opportunistic Controls leverage characteristics of these affordances to provide passive haptics that ease gesture input, simplify gesture recognition, and provide tangible feedback to the user. 3D widgets are tightly coupled with affordances to provide visual feedback and hints about the functionality of the control. For example, a set of buttons is mapped to existing tactile features on domain objects. We describe examples of Opportunistic Controls that we have designed and implemented using optical marker tracking, combined with appearance-based gesture recognition. We present the results of a user study in which participants performed a simulated maintenance inspection of an aircraft engine using a set of virtual buttons implemented both as Opportunistic Controls and using simpler passive haptics. Opportunistic Controls allowed participants to complete their tasks significantly faster and were preferred over the baseline technique.",2008-10-27,https://www.semanticscholar.org/paper/9fbfa193b1f2bf3ce6e2612a1ba715d7e7538e68,Virtual Reality Software and Technology
365,On a model of indexability and its bounds for range queries,"We develop a theoretical framework to characterize the hardness of indexing data sets on block-access memory devices like hard disks. We define an indexing workload by a data set and a set of potential queries. For a workload, we can construct an indexing scheme, which is a collection of fixed-sized subsets of the data. We identify two measures of efficiency for an indexing scheme on a workload: storage redundancy, r (how many times each item in the data set is stored), and access overhead, A (how many times more blocks than necessary does a query retrieve).For many interesting families of workloads, there exists a trade-off between storage redundancy and access overhead. Given a desired access overhead A, there is a minimum redundancy that any indexing scheme must exhibit. We prove a lower-bound theorem for deriving the minimum redundancy. By applying this theorem, we show interesting upper and lower bounds and trade-offs between A and r in the case of multidimensional range queries and set queries.",,https://www.semanticscholar.org/paper/0249cfd6464a78eeb1dac5f67f67c939624f5d02,JACM
2473,"WeARHand: Head-worn, RGB-D camera-based, bare-hand user interface with visually enhanced depth perception","We introduce WeARHand, which allows a user to manipulate virtual 3D objects with a bare hand in a wearable augmented reality (AR) environment. Our method uses no environmentally tethered tracking devices and localizes a pair of near-range and far-range RGB-D cameras mounted on a head-worn display and a moving bare hand in 3D space by exploiting depth input data. Depth perception is enhanced through egocentric visual feedback, including a semi-transparent proxy hand. We implement a virtual hand interaction technique and feedback approaches, and evaluate their performance and usability. The proposed method can apply to many 3D interaction scenarios using hands in a wearable AR environment, such as AR information browsing, maintenance, design, and games.",2014-11-06,https://www.semanticscholar.org/paper/58b5fea06a70ec4acacc3d2f7e36f9a5b9120270,International Symposium on Mixed and Augmented Reality
2679,A grid-based approach to automating display layout,"A research testbed is described for exploring the automated layout of graphical displays. We address the problem of determining the size and position of the objects displayed to a user. Our approach is based on the graphic design concept of a design grid. A design grid is a set of proportionally-spaced vertical and horizontal lines that control the position and size of the objects being laid out. The system first generates a grid intended for a set of possible displays, based on information about the kind of material to be displayed, the user, and the display hardware. The grid is next used, in conjunction with further information about the kinds of objects to be presented, to create a prototype display layout. This prototype display layout determines how each actual set of objects will be sized and positioned in the displays presented to the user.",1998-06-01,https://www.semanticscholar.org/paper/cfa7f09e585a098beba3c4bc55b04f2d74ed2c1b,
3030,POSIX Has Become Outdated,,,https://www.semanticscholar.org/paper/8984bf438d496a6861098bae613aa838a83aff0a,Login: The Usenix Magazine
847,On the approximation of maximum satisfiability,"We present a 3/4 polynomial time approximation algorithm for the Maximum Satisfiability problem: Given a set of clauses, find a truth assignment that satisfies the maximum number of clauses. The algorithm applies to the weighted case as well, and involves nontrival application of network flow techniques.",1992-09-01,https://www.semanticscholar.org/paper/3a078ce26e2105fffb7f58fd1a58334184f4f84a,ACM-SIAM Symposium on Discrete Algorithms
1528,Title Serendipity based recommender system for perovskites material discovery: balancing exploration and exploitation across multiple models [short] Serendipity recommender for perovskites discovery,"Machine learning is a useful tool for accelerating materials discovery, however it is a challenge to develop accurate methods that successfully transfer between domains while also broadening the scope of reaction conditions considered. In this paper, we consider how active-and transfer-learning methods can be used as building blocks for predicting reaction outcomes of metal halide perovskite synthesis. We then introduce a serendipity-based recommendation system that guides these methods to balance novelty and accuracy. The model-agnostic recommendation system is tested across active-and transfer-learning algorithms, using laboratory experiments for training and testing and a time-separated hold out that includes four different chemical systems. The serendipity recommendation system achieves high accuracy while increasing the scope of the synthesis conditions explored. Teaser",,https://www.semanticscholar.org/paper/b0f268385132c92db78e137256523904bb234166,
12,Predicting the impact of scientific concepts using full‐text features,"New scientific concepts, interpreted broadly, are continuously introduced in the literature, but relatively few concepts have a long‐term impact on society. The identification of such concepts is a challenging prediction task that would help multiple parties—including researchers and the general public—focus their attention within the vast scientific literature. In this paper we present a system that predicts the future impact of a scientific concept, represented as a technical term, based on the information available from recently published research articles. We analyze the usefulness of rich features derived from the full text of the articles through a variety of approaches, including rhetorical sentence analysis, information extraction, and time‐series analysis. The results from two large‐scale experiments with 3.8 million full‐text articles and 48 million metadata records support the conclusion that full‐text features are significantly more useful for prediction than metadata‐only features and that the most accurate predictions result from combining the metadata and full‐text features. Surprisingly, these results hold even when the metadata features are available for a much larger number of documents than are available for the full‐text features.",2016-11-01,https://www.semanticscholar.org/paper/52b58e71ca56ae725fd40b88c411a58a8322b872,J. Assoc. Inf. Sci. Technol.
3045,"The Design, Implementation, and Evaluation of Cells: A Virtual Smartphone Architecture","Smartphones are increasingly ubiquitous, and many users carry multiple phones to accommodate work, personal, and geographic mobility needs. We present Cells, a virtualization architecture for enabling multiple virtual smartphones to run simultaneously on the same physical cellphone in an isolated, secure manner. Cells introduces a usage model of having one foreground virtual phone and multiple background virtual phones. This model enables a new device namespace mechanism and novel device proxies that integrate with lightweight operating system virtualization to multiplex phone hardware across multiple virtual phones while providing native hardware device performance. Cells virtual phone features include fully accelerated 3D graphics, complete power management features, and full telephony functionality with separately assignable telephone numbers and caller ID support. We have implemented a prototype of Cells that supports multiple Android virtual phones on the same phone. Our performance results demonstrate that Cells imposes only modest runtime and memory overhead, works seamlessly across multiple hardware devices including Google Nexus 1 and Nexus S phones, and transparently runs Android applications at native speed without any modifications.",2012-08-01,https://www.semanticscholar.org/paper/d73fde4fae0c32e574b4950a8e0ee6d7324831d5,TOCS
2842,Galectin-3 Is a Negative Regulator of Lipopolysaccharide-Mediated Inflammation1,"Galectin-3 is a β-galactoside-binding lectin that plays an important role in inflammatory diseases. It also interacts with the surface carbohydrates of many pathogens, including LPS. However, its role in infection is not fully understood. Data presented herein demonstrate for the first time that galectin-3 is a negative regulator of LPS-induced inflammation. Galectin-3 is constitutively produced by macrophages and directly binds to LPS. Galectin-3-deficient macrophages had markedly elevated LPS-induced signaling and inflammatory cytokine production compared with wild-type cells, which was specifically inhibited by the addition of recombinant galectin-3 protein. In contrast, blocking galectin-3 binding sites by using a neutralizing Ab or its ligand, β-lactose, enhanced LPS-induced inflammatory cytokine expression by wild-type macrophages. In vivo, mice lacking galectin-3 were more susceptible to LPS shock associated with excessive induction of inflammatory cytokines and NO production. However, these changes conferred greater resistance to Salmonella infection. Thus, galectin-3 is a previously unrecognized, naturally occurring, negative regulator of LPS function, which protects the host from endotoxin shock but, conversely, favors Salmonella survival.",2008-08-15,https://www.semanticscholar.org/paper/8a5a8e701c5a64c790b4b42166a75a6856f65170,Journal of Immunology
1088,Dark Sectors 2016 Workshop: Community Report,"This report, based on the Dark Sectors workshop at SLAC in April 2016, summarizes the scientific importance of searches for dark sector dark matter and forces at masses beneath the weak-scale, the status of this broad international field, the important milestones motivating future exploration, and promising experimental opportunities to reach these milestones over the next 5-10 years.",2016-08-30,https://www.semanticscholar.org/paper/807f98b6c0abc2483a28e0d55289092762ce874a,
31,Building query optimizers for information extraction: the SQoUT project,"Text documents often embed data that is structured in nature. This structured data is increasingly exposed using information extraction systems, which generate structured relations from documents, introducing an opportunity to process expressive, structured queries over text databases. This paper discusses our SQoUT1 project, which focuses on processing structured queries over relations extracted from text databases. We show how, in our extraction-based scenario, query processing can be decomposed into a sequence of basic steps: retrieving relevant text documents, extracting relations from the documents, and joining extracted relations for queries involving multiple relations. Each of these steps presents different alternatives and together they form a rich space of possible query execution strategies. We identify execution efficiency and output quality as the two critical properties of a query execution, and argue that an optimization approach needs to consider both properties. To this end, we take into account the userspecified requirements for execution efficiency and output quality, and choose an execution strategy for each query based on a principled, cost-based comparison of the alternative execution strategies.",2009-03-20,https://www.semanticscholar.org/paper/7acdfa6c26662376079d924e731fa795597122f0,SGMD
894,How Easy Is Local Search? (Extended Abstract),,,https://www.semanticscholar.org/paper/285711d00040658337aa0ae7abe5ff0c05d70d43,IEEE Annual Symposium on Foundations of Computer Science
1052,Design and characterization of a phonon-mediated cryogenic particle detector with an eV-scale threshold and 100 keV-scale dynamic range,"We present the design and characterization of a cryogenic phonon-sensitive 1-gram Si detector exploiting the Neganov-Trofimov-Luke effect to detect single-charge excitations. This device achieved 2.65(2)~eV phonon energy resolution when operated without a voltage bias across the crystal and a corresponding charge resolution of 0.03 electron-hole pairs at 100~V bias. With a continuous-readout data acquisition system and an offline optimum-filter trigger, we obtain a 9.2~eV threshold with a trigger rate of the order of 20~Hz. The detector's energy scale is calibrated up to 120~keV using an energy estimator based on the pulse area. The high performance of this device allows its application to different fields where excellent energy resolution, low threshold, and large dynamic range are required, including dark matter searches, precision measurements of coherent neutrino-nucleus scattering, and ionization yield measurements.",2020-12-23,https://www.semanticscholar.org/paper/728f3be5889c6c038095f7abeee8a71ef729bb4d,Physical Review D
2768,Apex: An Experiment in the Automated Creation of Pictorial Explanations,How might we automate the design of pictures that are intended to show the viewer how to perform a series of tasks?,1985-11-01,https://www.semanticscholar.org/paper/21132fc605f9326efbcdf47149a9ab7fb157473d,IEEE Computer Graphics and Applications
3236,Consistent individual variation across interaction networks indicates social personalities in lemurs,,2017-12-01,https://www.semanticscholar.org/paper/1ff498e835e28a105e8afe741f03aa55e8a2c984,Animal Behaviour
3731,Learning to Learn Words from Narrated Video,"When we travel, we often encounter new scenarios we have never experienced before, with new sights and new words that describe them. We can use our language-learning ability to quickly learn these new words and correlate them with the visual world. In contrast, language models often do not robustly generalize to novel words and compositions. We propose a framework that learns how to learn text representations from visual context. Experiments show that our approach significantly outperforms the state-of-the-art in visual language modeling for acquiring new words and predicting new compositions. Model ablations and visualizations suggest that the visual modality helps our approach more robustly generalize at these tasks. Project webpage is available at https://expert.cs.columbia.edu/",2019-11-25,https://www.semanticscholar.org/paper/1178245776864b2c5286992e61822e50bf772220,arXiv.org
1912,An empirical study of demand forecasting of non-volatile memory for smart production of semiconductor manufacturing,"As high-speed computing is crucial to empower intelligent manufacturing for Industry 4.0, non-volatile memory (NVM) is critical semiconductor component of the cloud and data centre for the infrastructures. The NVM manufacturing is capital intensive, in which capacity utilisation significantly affects the capital effectiveness and profitability of semiconductor companies. Since capacity migration and expansion involve long lead times, demand forecasting plays a critical role for smart production of NVM manufacturers for revenue management. However, the shortening product life cycles of integrated circuits (IC), the fluctuations of semiconductor supply chains, and uncertainty involved in demand forecasting make the present problem increasingly difficult in the consumer electronics era. Focusing on the realistic needs of NVM demand forecasting, this study aims to develop a decision framework that integrates an improved technology diffusion model and a proposed adjustment mechanism to incorporate domain insights. An empirical study was conducted in a leading semiconductor company for validation. A comparison of alternative approaches is also provided. The results have shown the practical viability of the proposed approach.",2018-01-09,https://www.semanticscholar.org/paper/810c89a120886d8781bab6788603f35ce622f8be,International Journal of Production Research
173,Reductions in PPP,,2019-05-01,https://www.semanticscholar.org/paper/9040aef172a9a0af63a835b73f9c8fe5033f6929,Information Processing Letters
673,Model-Agnostic Meta-Learning using Runge-Kutta Methods,"Meta-learning has emerged as an important framework for learning new tasks from just a few examples. The success of any meta-learning model depends on (i) its fast adaptation to new tasks, as well as (ii) having a shared representation across similar tasks. Here we extend the model-agnostic meta-learning (MAML) framework introduced by Finn et al. (2017) to achieve improved performance by analyzing the temporal dynamics of the optimization procedure via the Runge-Kutta method. This method enables us to gain fine-grained control over the optimization and helps us achieve both the adaptation and representation goals across tasks. By leveraging this refined control, we demonstrate that there are multiple principled ways to update MAML and show that the classic MAML optimization is simply a special case of second-order Runge-Kutta method that mainly focuses on fast-adaptation. Experiments on benchmark classification, regression and reinforcement learning tasks show that this refined control helps attain improved results.",2019-10-16,https://www.semanticscholar.org/paper/b2fe8068465a01c9d030869ad3576a2760b6110f,arXiv.org
747,"Survey Equilibria , fixed points , and complexity classes","Many models from a variety of areas involve the computation of an equilibrium or fixed point of some kind. Examples include Nash equilibria in games; market equilibria; computing optimal strategies and the values of competitive games (stochastic and other games); stable configurations of neural networks; analysing basic stochastic models for evolution like branching processes and for language like stochastic context-free grammars; and models that incorporate the basic primitives of probability and recursion like recursive Markov chains. It is not known whether these problems can be solved in polynomial time. There are certain common computational principles underlying different types of equilibria, which are captured by the complexity classes PLS, PPAD, and FIXP. Representative complete problems for these classes are, respectively, pure Nash equilibria in games where they are guaranteed to exist, (mixed) Nash equilibria in two-player normal form games, and (mixed) Nash equilibria in normal form games with three (or more) players. This paper reviews the underlying computational principles and the corresponding classes. c © 2009 Elsevier Inc. All rights reserved.",,https://www.semanticscholar.org/paper/d8c7aecf6cac6f3b068956d57a901a80e2974d91,
155,Bayesian Online Matching: Approximating the Optimal Online Algorithm,"The rich literature on online Bayesian selection problems has long focused on so-called prophet inequalities, which compare the gain of an online algorithm to that of a “prophet” who knows the future. An equally-natural, though significantly less well-studied benchmark is the optimum online algorithm, which may be omnipotent (i.e., computationally-unbounded), but not omniscient. What is the computational complexity of the optimum online? How well can a polynomial-time algorithm approximate it? Motivated by applications in ride hailing, we study the above questions for the online stochastic maximum-weight matching problem under vertex arrivals. This problem was recently introduced by Ezra, Feldman, Gravin and Tang (EC’20), who gave a 1/2-competitive algorithm for it. This is the best possible ratio, as this problem is a generalization of the original single-item prophet inequality. We present a polynomial-time algorithm which approximates optimal online within a factor of 0.51—beating the best-possible prophet inequality. At the core of our result are a new linear program formulation, an algorithm that tries to match the arriving vertices in two attempts, and an analysis that bounds the correlation resulting from the second attempts. In contrast, we show that it is PSPACE-hard to approximate this problem within some constant α < 1. Research supported in part by NSF Awards CCF1763970, CCF191070, CCF1812919, ONR award N000141912550, and a gift from Cisco Research.",,https://www.semanticscholar.org/paper/1c4efe8f527c6cd7d6afb66788db773b352b9d84,
2799,Galectin-3 translocates to virological synapse and promotes HIV-1 transfer (VIR1P.1000),"
 Galectin-3 contains β-galactoside-binding domain and is mainly expressed in immune cells and epithelial cells. Galectin-3 is known to play regulatory roles in the immune system to defend against pathogens. Previous studies showed that Alix is a host factor employed by HIV-1 for its replication. Here, we report that galectin-3 is another such factor. We have reported that galectin-3 is translocated to the immunological synapse and affects T cell cytokine production. We have now studied the role of galectin-3 in the virological synapse (VS). Our data showed that HIV-1 infection induces galectin-3 expression in primary CD4 T cells. Immunofluorescence imaging showed that galectin-3 is translocted to the virological synapse and co-localized with Gag and Env at the cell-to-cell junction of HIV-1-infected cells. We have studied the effects of galectin-3 in the VS by using fluorescent-tagged HIV-1 and incubation of fluorescent-labeled T cells with galectin-3 knockeddown (KD). Our analysis indicates that HIV-1 transmission efficacy is significantly attenuated in galectin-3 KD cells comparing to galectin-3-expressing wild type cells. Our analysis also shows that Alix plays a role in promoting cell-to-cell transfer of HIV-1. Further analysis indicate that effects of galectin-3 in effector cells is likely more important than expression of galectin-3 in target cells. We conclude that endogenous galectin-3 translocates to VS and promotes cell-to-cell viral transfer upon HIV-1 infection.",2014-05-01,https://www.semanticscholar.org/paper/59c814ab1436c93e5287ea8e82dbd76a0b6f15c3,Journal of Immunology
2063,Data mining for yield enhancement in semiconductor manufacturing and an empirical study,,2007-07-01,https://www.semanticscholar.org/paper/219748927fa306d6a8d667869ac1c90e86ec68db,Expert systems with applications
424,Algorithmic Approaches to Information Retrieval and Data Mining (Abstract),,1998-08-12,https://www.semanticscholar.org/paper/764f5ab98e6e75485da09e4607cfcccb129e4a25,International Computing and Combinatorics Conference
176,α-Rank: Multi-Agent Evaluation by Evolution,,2019-03-04,https://www.semanticscholar.org/paper/af49ccf5add1c4b6a9a4b2e403bbe0fb25f9925f,Scientific Reports
2089,Demand Forecasting Using Bayesian Experiment with Non-homogenous Poisson Process Model,"This study presents a novel mathematical model using Bayesian model for demand forecasting with non-homogenous Poisson process model. This study aims to construct a framework to minimize the overproduction and underproduction costs by using the time-dependent uncertainty of accumulative demand curve. Specific models were derived as the fundamentals of this approach. Furthermore, this study also proposed a method to evaluate demand forecasting using Bayesian experiment with non-homogenous Poisson process model.",,https://www.semanticscholar.org/paper/d45536a157cbd6b3087e770004a0614c6c3d1774,
2098,新竹科學園區藥品網路訂購系統之建置與實證研究; Constructing the Network Medicine Order Systemfor Hsinchu Science Park and An Empirical Study,,,https://www.semanticscholar.org/paper/d2217c6daccef0bef9e780562965db936bfc50fa,
1965,A Multiobjective Hybrid Genetic Algorithm for TFT-LCD Module Assembly Scheduling,"The thin-film transistor-liquid crystal display (TFT-LCD) module assembly production is a flexible job-shop scheduling problem that is critical to satisfy the customer demands on time. On the module assembly shop floor, each workstation has identical and non-identical parallel machines that access the jobs at various processing velocities depending on the product families. To satisfy the various jobs, the machines need to be set up as the numerous tools to conduct consecutive products. This study aims to propose a novel approach to address the TFT-LCD module assembly scheduling problem by simultaneously considering the following multiple and often conflicting objectives such as the makespan, the weighted number of tardy jobs, and the total machine setup time, subject to the constraints of product families, non-identical parallel machines, and sequence-dependent setup times. In particular, we developed a multiobjective hybrid genetic algorithm (MO-HGA) that hybridizes with the variable neighborhood descent (VND) algorithm as a local search and TOPSIS evaluation technique to derive the best compromised solution. To estimate the validity of the proposed MO-HGA, experiments based on empirical data were conducted to compare the results with conventional approaches. The results have shown the validity of this approach. This study concludes with a discussion of future research directions.",2014-05-06,https://www.semanticscholar.org/paper/8e7a4f1648ced4338260c4c0147e56ac3444a7fa,IEEE Transactions on Automation Science and Engineering
3354,INDIVIDUAL VARIATION AND COMPETITION IN THE EVERGLADES PYGMY SUNFISH,"SUMMARY (1) Populations of Everglades pygmy sunfish (Elassoma evergladei, family Centrachidae) were manipulated in both the laboratory and the field to determine how individuals responded to changes in the intensity of competition. (2) In laboratory experiments, individually identifiable fish were raised at different densities (sixteen, eight, four, and one fish per tank) and each individual's competitive ability was measured by its growth rate and reproductive condition. For females, estimates of reproductive potential were ovary weight and egg number. For males, reproductive ability was estimated by recording the frequency of occurrence of bobbing, a sexual behaviour. In field experiments fish were raised at the same densities but in screened enclosures to evaluate the realism of the laboratory experiments. (3) Individual fish differed in their growth rates, and these differences were magnified under competitive conditions. Increased density also increased the variation among females within a population with respect to ovary size and egg number. (4) Increased population density markedly decreased the growth rate of the 'average' fish in the population, but only slightly the growth of the 'best' competitors. In each density there were always some fish who grew as quickly as the 'average' fish of a population half as large. (5) Increases in population size also produced non-linear reductions in estimates of both male and female potential reproductive success. For females these reductions could be attributed in part to density-induced reductions in growth rate. But density also had a direct effect on female reproductive success: for females of similar size or growing at a similar rate, those raised at higher densities had larger ovaries and more eggs.",1981-06-01,https://www.semanticscholar.org/paper/0e26a7519e5af8e900844e621c7c84f0f05a9d14,
1774,Hierarchical Dirichlet Processes Author ( s ) :,"JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.. American Statistical Association is collaborating with JSTOR to digitize, preserve and extend access to Journal of the American Statistical Association. We consider problems involving groups of data where each observation within a group is a draw from a mixture model and where it is desirable to share mixture components between groups. We assume that the number of mixture components is unknown a priori and is to be inferred from the data. In this setting it is natural to consider sets of Dirichlet processes, one for each group, where the well-known clustering property of the Dirichlet process provides a nonparametric prior for the number of mixture components within each group. Given our desire to tie the mixture models in the various groups, we consider a hierarchical model, specifically one in which the base measure for the child Dirichlet processes is itself distributed according to a Dirichlet process. Such a base measure being discrete, the child Dirichlet processes necessarily share atoms. Thus, as desired, the mixture models in the different groups necessarily share mixture components. We discuss representations of hierarchical Dirichlet processes in terms of a stick-breaking process, and a generalization of the Chinese restaurant process that we refer to as the ""Chinese restaurant franchise."" We present Markov chain Monte Carlo algorithms for posterior inference in hierarchical Dirichlet process mixtures and describe applications to problems in information retrieval and text modeling.",,https://www.semanticscholar.org/paper/93da6dee4834b424af81065a0a1720e8d0463802,
2949,RNA splicing is a primary link between genetic variation and disease,"RNA splicing links genetics to disease Many genetic variants associated with disease have no apparent effect on any specific protein coding sequence. Li et al. systematically analyzed the effects of DNA variants on the main steps of gene regulation, from the chromatin state through protein function. One-third of expression quantitative train loci (QTLs) are mediated through transcriptional processes, not chromatin. Splice QTLs and expression QTLs are about comparable in their complex disease risk. Posttranscriptional mechanisms therefore play a large role in translating genotype to phenotype. Science, this issue p. 600 Phenotype is most affected by genetic variants that influence gene expression and transcript splicing. Noncoding variants play a central role in the genetics of complex traits, but we still lack a full understanding of the molecular pathways through which they act. We quantified the contribution of cis-acting genetic effects at all major stages of gene regulation from chromatin to proteins, in Yoruba lymphoblastoid cell lines (LCLs). About ~65% of expression quantitative trait loci (eQTLs) have primary effects on chromatin, whereas the remaining eQTLs are enriched in transcribed regions. Using a novel method, we also detected 2893 splicing QTLs, most of which have little or no effect on gene-level expression. These splicing QTLs are major contributors to complex traits, roughly on a par with variants that affect gene expression levels. Our study provides a comprehensive view of the mechanisms linking genetic variation to variation in human gene regulation.",2016-04-29,https://www.semanticscholar.org/paper/726c847bcddca4d1be6cde804c35eb5af14999fa,Science
2194,Human neutrophils in auto-immunity.,,2016-04-01,https://www.semanticscholar.org/paper/84651a2aa6278cbf0b7b6151d7ac5d2e1133ae4b,Seminars in Immunology
2458,Evaluating Positional Head-Tracking in Immersive VR for 3D Designers,"With the ongoing introduction of wide-FOV VR head-worn displays into the consumer market, the application of VR 3D UIs to professional work environments is attracting increasing attention. One of the most conspicuous concepts is immersive 3D modeling and content creation. In spite of the long research history, there have been very few analyses of the effect of 3D UIs on productivity in 3D design. In this work, we explore the effect of positional head-tracking on task performance in 3D design. Previous studies have come to different conclusions on the importance of headtracking and did not investigate professional 3D modeling tools. In contrast, we performed a user study with design students using professional software on a task that closely emulates their work. Surprisingly, we did not find a significant effect of head-tracking on task-completion time, neither when using a traditional 2D mouse nor when using a pinch glove as a 3D input device.",2016-09-01,https://www.semanticscholar.org/paper/81ccb0aca2ab0d2b5c5b3844b4dfd96fdc899586,2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)
188,Towards a Unified Complexity Theory of Total Functions,"Abstract The class TFNP, of NP search problems where all instances have solutions, appears not to have complete problems. However, TFNP contains various syntactic subclasses and important problems. We introduce a syntactic class of problems that contains these known subclasses, for the purpose of understanding and classifying TFNP problems. This class is defined in terms of the search for an error in a concisely-represented formal proof. Finally, the known complexity subclasses are based on existence theorems that hold for finite structures; from Herbrand's Theorem, we note that such theorems must apply specifically to finite structures, and not infinite ones.",2017-12-01,https://www.semanticscholar.org/paper/40a8b56f5afe8b9ba82cfa855f9f87f148fca980,Information Technology Convergence and Services
2545,Toward Automated Visual Management and Presentation of Content Recommendations for Patient Note Generation,"INTRODUCTION A patient note is a clinical document, written by a physician, describing a patient under his or her care. Various kinds of notes document the patient’s status over time, and comprise the official medical record for legal and billing purposes. Composing these notes encompasses several disparate, but interdependent subtasks. Physicians gather and review previous and current patient data, such as lab results, physical exams, medications, and hospital events, to determine patient progress; select and input relevant information for the current note; and form appropriate assessments and plans for each patient. Currently, most of these subtasks are not supported by domain-informed assistance. While sophisticated systems exist for retrieving and visualizing clinical patient data (e.g., [1, 3, 5, 7, 9]), support for inserting this data into a patient note is limited, less flexible, and more complicated to use than editing notes manually in a generic word processing application. In practice, physicians often edit each current note by hand— manually searching through previous notes and copying and modifying material written for previous notes—a time-consuming and error-prone process. We are working with physicians in the New York Presbyterian Hospital (NYPH) Cardiothoracic Intensive Care Unit (CTICU) to design a user interface for patient note creation. We are developing new presentation techniques through which appropriate content can be recommended, and new interaction techniques for effectively browsing, selecting, and inserting these recommendations directly into the notes, as they are edited.",,https://www.semanticscholar.org/paper/885759f27317a8556d035064c849cd444ca3ace0,
843,On limited nondeterminism and the complexity of the V-C dimension,"The complexity of several natural computational problems in NP, which have been proposed but not categorized satisfactorily in the literature is characterized precisely. These problems can be solved in n/sup O(logn)/ time, and thus they are probably not NP-complete. Two new complexity classes between P and NP, very much in the spirit of MAXNP and MAXSNP, are defined. It is shown that computing the V-C dimension is complete for the more general class, whereas the other two problems are complete for the weaker class.<<ETX>>",1993-05-18,https://www.semanticscholar.org/paper/d74f8e664e461340ffcbdad9c38d6e619378f024,[1993] Proceedings of the Eigth Annual Structure in Complexity Theory Conference
453,Editorial on the Electronic Notes in Theoretical Computer Science,,1995-12-01,https://www.semanticscholar.org/paper/6258f192663eec40a3ac99cdc13c4638b9c1891f,
1316,using secondary vertex b tagging,,,https://www.semanticscholar.org/paper/6075d05d64d82d52a9e92ff64f70d80249aa15a2,
998,The risk of newly developed visual impairment in treated normal‐tension glaucoma: 10‐year follow‐up,To investigate the risk and risk factors for newly developed visual impairment in treated patients with normal‐tension glaucoma (NTG) followed up on for 10 years.,2014-12-01,https://www.semanticscholar.org/paper/8a269749eb57d7232756b629316169d604bef5b2,Acta ophthalmologica
1258,Study of direct CP violation in B(+/-)-->J/psiK(+/-)(pi(+/-)) decays.,"We present a search for direct CP violation in B(+/-)-->J/psiK(+/-)(pi(+/-)) decays. The event sample is selected from 2.8 fb(-1) of pp collisions recorded by D0 experiment in run II of the Fermilab Tevatron Collider. The charge asymmetry A_(CP)(B(+)-->J/psiK(+))= + 0.0075 +/- 0.0061(stat)+/-0.0030(syst) is obtained using a sample of approximately 40, 000 B(+/-)-->J/psiK(+/-) decays. The achieved precision is of the same level as the expected deviation predicted by some extensions of the standard model. We also measured the charge asymmetry A(CP)(B(+)-->J/psipi(+))=-0.09+/-0.08(stat)+/-0.03(syst).",,https://www.semanticscholar.org/paper/dbefd8ed8837a9e07cb17720044a71ae7562fdff,Physical Review Letters
2956,Relational Learning and Network Modelling Using Infinite Latent Attribute Models,"Latent variable models for network data extract a summary of the relational structure underlying an observed network. The simplest possible models subdivide nodes of the network into clusters; the probability of a link between any two nodes then depends only on their cluster assignment. Currently available models can be classified by whether clusters are disjoint or are allowed to overlap. These models can explain a “flat” clustering structure. Hierarchical Bayesian models provide a natural approach to capture more complex dependencies. We propose a model in which objects are characterised by a latent feature vector. Each feature is itself partitioned into disjoint groups (subclusters), corresponding to a second layer of hierarchy. In experimental comparisons, the model achieves significantly improved predictive performance on social and biological link prediction tasks. The results indicate that models with a single layer hierarchy over-simplify real networks.",2015-02-01,https://www.semanticscholar.org/paper/2f458534cd1fdf467888b599b961566ba59a3401,IEEE Transactions on Pattern Analysis and Machine Intelligence
360,Games and Networks,,2003-08-12,https://www.semanticscholar.org/paper/bd82c62a19a07b42a8f515fdad1037f22f77b0e4,International Symposium on Fundamentals of Computation Theory
2464,Interim Results of a Randomized Controlled Trial on Inpatient Engagement,,,https://www.semanticscholar.org/paper/33eb4a2de6feaf91c5e8ecca8ef76a2449d04489,American Medical Informatics Association Annual Symposium
3626,A history of C++: 1979--1991,"This paper outlines the history of the C++ programming language. The emphasis is on the ideas, constraints, and people that shaped the language, rather than the minutiae of language features. Key design decisions relating to language features are discussed, but the focus is one the overall design goals and practical constraints. The evolution of C++ is traced from C with Classes to the current ANSI and ISO standards work and the explosion of use, interest, commercial activity, compilers, tools, environments, and libraries.",,https://www.semanticscholar.org/paper/0ea96714ac76cfbb500ffb1de4db038744dabc47,
4,Weakly Supervised Attention Networks for Fine-Grained Opinion Mining and Public Health,"In many review classification applications, a fine-grained analysis of the reviews is desirable, because different segments (e.g., sentences) of a review may focus on different aspects of the entity in question. However, training supervised models for segment-level classification requires segment labels, which may be more difficult or expensive to obtain than review labels. In this paper, we employ Multiple Instance Learning (MIL) and use only weak supervision in the form of a single label per review. First, we show that when inappropriate MIL aggregation functions are used, then MIL-based networks are outperformed by simpler baselines. Second, we propose a new aggregation function based on the sigmoid attention mechanism and show that our proposed model outperforms the state-of-the-art models for segment-level sentiment classification (by up to 9.8% in F1). Finally, we highlight the importance of fine-grained predictions in an important public-health application: finding actionable reports of foodborne illness. We show that our model achieves 48.6% higher recall compared to previous models, thus increasing the chance of identifying previously unknown foodborne outbreaks.",2019-09-30,https://www.semanticscholar.org/paper/217be3119fe32cdfda39cec4af00ce646317d153,Conference on Empirical Methods in Natural Language Processing
3219,Revealing life‐history traits by contrasting genetic estimations with predictions of effective population size,"Effective population size, a central concept in conservation biology, is now routinely estimated from genetic surveys and can also be theoretically predicted from demographic, life‐history, and mating‐system data. By evaluating the consistency of theoretical predictions with empirically estimated effective size, insights can be gained regarding life‐history characteristics and the relative impact of different life‐history traits on genetic drift. These insights can be used to design and inform management strategies aimed at increasing effective population size. We demonstrated this approach by addressing the conservation of a reintroduced population of Asiatic wild ass (Equus hemionus). We estimated the variance effective size (Nev) from genetic data ( N ev =24.3 ) and formulated predictions for the impacts on Nev of demography, polygyny, female variance in lifetime reproductive success (RS), and heritability of female RS. By contrasting the genetic estimation with theoretical predictions, we found that polygyny was the strongest factor affecting genetic drift because only when accounting for polygyny were predictions consistent with the genetically measured Nev. The comparison of effective‐size estimation and predictions indicated that 10.6% of the males mated per generation when heritability of female RS was unaccounted for (polygyny responsible for 81% decrease in Nev) and 19.5% mated when female RS was accounted for (polygyny responsible for 67% decrease in Nev). Heritability of female RS also affected Nev; hf2=0.91 (heritability responsible for 41% decrease in Nev). The low effective size is of concern, and we suggest that management actions focus on factors identified as strongly affecting Nev , namely, increasing the availability of artificial water sources to increase number of dominant males contributing to the gene pool. This approach, evaluating life‐history hypotheses in light of their impact on effective population size, and contrasting predictions with genetic measurements, is a general, applicable strategy that can be used to inform conservation practice.",2018-08-01,https://www.semanticscholar.org/paper/168dbe3fb90c9d47fb94f361791aec2db8e744b1,Conservation Biology
3284,Reciprocal insurance among Kenyan pastoralists,,2012-08-25,https://www.semanticscholar.org/paper/ce77a6e9ec27eb78d47ce415ddeaf7c5767070e3,Theoretical Ecology
3479,"Introduction to Algorithms, Second Edition","problems To understand the class of polynomial-time solvable problems, we must first have a formal notion of what a ""problem"" is. We define an abstract problem Q to be a binary relation on a set I of problem instances and a set S of problem solutions. For example, an instance for SHORTEST-PATH is a triple consisting of a graph and two vertices. A solution is a sequence of vertices in the graph, with perhaps the empty sequence denoting that no path exists. The problem SHORTEST-PATH itself is the relation that associates each instance of a graph and two vertices with a shortest path in the graph that connects the two vertices. Since shortest paths are not necessarily unique, a given problem instance may have more than one solution. This formulation of an abstract problem is more general than is required for our purposes. As we saw above, the theory of NP-completeness restricts attention to decision problems: those having a yes/no solution. In this case, we can view an abstract decision problem as a function that maps the instance set I to the solution set {0, 1}. For example, a decision problem related to SHORTEST-PATH is the problem PATH that we saw earlier. If i = G, u, v, k is an instance of the decision problem PATH, then PATH(i) = 1 (yes) if a shortest path from u to v has at most k edges, and PATH(i) = 0 (no) otherwise. Many abstract problems are not decision problems, but rather optimization problems, in which some value must be minimized or maximized. As we saw above, however, it is usually a simple matter to recast an optimization problem as a decision problem that is no harder. Encodings If a computer program is to solve an abstract problem, problem instances must be represented in a way that the program understands. An encoding of a set S of abstract objects is a mapping e from S to the set of binary strings. For example, we are all familiar with encoding the natural numbers N = {0, 1, 2, 3, 4,...} as the strings {0, 1, 10, 11, 100,...}. Using this encoding, e(17) = 10001. Anyone who has looked at computer representations of keyboard characters is familiar with either the ASCII or EBCDIC codes. In the ASCII code, the encoding of A is 1000001. Even a compound object can be encoded as a binary string by combining the representations of its constituent parts. Polygons, graphs, functions, ordered pairs, programs-all can be encoded as binary strings. Thus, a computer algorithm that ""solves"" some abstract decision problem actually takes an encoding of a problem instance as input. We call a problem whose instance set is the set of binary strings a concrete problem. We say that an algorithm solves a concrete problem in time O(T (n)) if, when it is provided a problem instance i of length n = |i|, the algorithm can produce the solution in O(T (n)) time. A concrete problem is polynomial-time solvable, therefore, if there exists an algorithm to solve it in time O(n) for some constant k. We can now formally define the complexity class P as the set of concrete decision problems that are polynomial-time solvable. We can use encodings to map abstract problems to concrete problems. Given an abstract decision problem Q mapping an instance set I to {0, 1}, an encoding e : I → {0, 1}* can be used to induce a related concrete decision problem, which we denote by e(Q). If the solution to an abstract-problem instance i I is Q(i) {0, 1}, then the solution to the concreteproblem instance e(i) {0, 1}* is also Q(i). As a technicality, there may be some binary strings that represent no meaningful abstract-problem instance. For convenience, we shall assume that any such string is mapped arbitrarily to 0. Thus, the concrete problem produces the same solutions as the abstract problem on binary-string instances that represent the encodings of abstract-problem instances. We would like to extend the definition of polynomial-time solvability from concrete problems to abstract problems by using encodings as the bridge, but we would like the definition to be independent of any particular encoding. That is, the efficiency of solving a problem should not depend on how the problem is encoded. Unfortunately, it depends quite heavily on the encoding. For example, suppose that an integer k is to be provided as the sole input to an algorithm, and suppose that the running time of the algorithm is Θ(k). If the integer k is provided in unary-a string of k 1's-then the running time of the algorithm is O(n) on length-n inputs, which is polynomial time. If we use the more natural binary representation of the integer k, however, then the input length is n = ⌊lg k⌋ + 1. In this case, the running time of the algorithm is Θ (k) = Θ(2), which is exponential in the size of the input. Thus, depending on the encoding, the algorithm runs in either polynomial or superpolynomial time. The encoding of an abstract problem is therefore quite important to our under-standing of polynomial time. We cannot really talk about solving an abstract problem without first specifying an encoding. Nevertheless, in practice, if we rule out ""expensive"" encodings such as unary ones, the actual encoding of a problem makes little difference to whether the problem can be solved in polynomial time. For example, representing integers in base 3 instead of binary has no effect on whether a problem is solvable in polynomial time, since an integer represented in base 3 can be converted to an integer represented in base 2 in polynomial time. We say that a function f : {0, 1}* → {0,1}* is polynomial-time computable if there exists a polynomial-time algorithm A that, given any input x {0, 1}*, produces as output f (x). For some set I of problem instances, we say that two encodings e1 and e2 are polynomially related if there exist two polynomial-time computable functions f12 and f21 such that for any i I , we have f12(e1(i)) = e2(i) and f21(e2(i)) = e1(i). That is, the encoding e2(i) can be computed from the encoding e1(i) by a polynomial-time algorithm, and vice versa. If two encodings e1 and e2 of an abstract problem are polynomially related, whether the problem is polynomial-time solvable or not is independent of which encoding we use, as the following lemma shows. Lemma 34.1 Let Q be an abstract decision problem on an instance set I , and let e1 and e2 be polynomially related encodings on I . Then, e1(Q) P if and only if e2(Q) P. Proof We need only prove the forward direction, since the backward direction is symmetric. Suppose, therefore, that e1(Q) can be solved in time O(nk) for some constant k. Further, suppose that for any problem instance i, the encoding e1(i) can be computed from the encoding e2(i) in time O(n) for some constant c, where n = |e2(i)|. To solve problem e2(Q), on input e2(i), we first compute e1(i) and then run the algorithm for e1(Q) on e1(i). How long does this take? The conversion of encodings takes time O(n), and therefore |e1(i)| = O(n), since the output of a serial computer cannot be longer than its running time. Solving the problem on e1(i) takes time O(|e1(i)|) = O(n), which is polynomial since both c and k are constants. Thus, whether an abstract problem has its instances encoded in binary or base 3 does not affect its ""complexity,"" that is, whether it is polynomial-time solvable or not, but if instances are encoded in unary, its complexity may change. In order to be able to converse in an encoding-independent fashion, we shall generally assume that problem instances are encoded in any reasonable, concise fashion, unless we specifically say otherwise. To be precise, we shall assume that the encoding of an integer is polynomially related to its binary representation, and that the encoding of a finite set is polynomially related to its encoding as a list of its elements, enclosed in braces and separated by commas. (ASCII is one such encoding scheme.) With such a ""standard"" encoding in hand, we can derive reasonable encodings of other mathematical objects, such as tuples, graphs, and formulas. To denote the standard encoding of an object, we shall enclose the object in angle braces. Thus, G denotes the standard encoding of a graph G. As long as we implicitly use an encoding that is polynomially related to this standard encoding, we can talk directly about abstract problems without reference to any particular encoding, knowing that the choice of encoding has no effect on whether the abstract problem is polynomial-time solvable. Henceforth, we shall generally assume that all problem instances are binary strings encoded using the standard encoding, unless we explicitly specify the contrary. We shall also typically neglect the distinction between abstract and concrete problems. The reader should watch out for problems that arise in practice, however, in which a standard encoding is not obvious and the encoding does make a difference. A formal-language framework One of the convenient aspects of focusing on decision problems is that they make it easy to use the machinery of formal-language theory. It is worthwhile at this point to review some definitions from that theory. An alphabet Σ is a finite set of symbols. A language L over Σ is any set of strings made up of symbols from Σ. For example, if Σ = {0, 1}, the set L = {10, 11, 101, 111, 1011, 1101, 10001,...} is the language of binary representations of prime numbers. We denote the empty string by ε, and the empty language by Ø. The language of all strings over Σ is denoted Σ*. For example, if Σ = {0, 1}, then Σ* = {ε, 0, 1, 00, 01, 10, 11, 000,...} is the set of all binary strings. Every language L over Σ is a subset of Σ*. There are a variety of operations on languages. Set-theoretic operations, such as union and intersection, follow directly from the set-theoretic definitions. We define the complement of L by . The concatenation of two languages L1 and L2 is the language L = {x1x2 : x1 L1 and x2 L2}. The closure or Kleene star of a language L is the language L*= {ε} L L L ···, where Lk is the language obtained by",,https://www.semanticscholar.org/paper/f0177ff2ee4e6b1c001465fdb96429b02541089b,
3355,"Population density, resource patterning, and territoriality in the Everglades pygmy sunfish",,1981-02-01,https://www.semanticscholar.org/paper/40484c6735cab8d05676c656c5e7cdacb17dc96d,Animal Behaviour
651,Length of hospital stay and complications after percutaneous transluminal coronary angioplasty. Clinical and procedural predictors. Heparin Registry Investigators.,"BACKGROUND
Although several studies have established that the complications of percutaneous transluminal coronary angioplasty (PTCA) are related to clinical and angiographic variables such as advanced age and lesion complexity, it is uncertain whether the use of hospital resources after PTCA also depends on the same baseline variables. The purpose of this study was to identify the factors responsible for prolonged hospital stay after PTCA.


METHODS AND RESULTS
The study cohort included 591 consecutive patients undergoing conventional balloon angioplasty at nine medical centers in North America. Major or minor complications occurred in 91 patients (15.4%) and were observed to be related to several baseline characteristics, including unstable angina, multivessel coronary artery disease, patient age, and lesion complexity. Compared with a median length of hospital stay of 2.0 days after PTCA (25th, 75th percentiles: 2.0, 4.0) for the entire cohort of patients, the length of stay was increased in patients with unstable angina (3.0 days [2.0, 5.0]; P = .002), multivessel coronary artery disease (3.0 [2.0, 5.5]; P = .001), age > 65 years (3.0 [2.0, 5.5]; P = .02), complex lesions (3.0 [2.0, 6.0]; P = .001), and filling defects (6.0 [2.0, 11.0]; P < .001). The length of stay was more strikingly increased, however, in patients who experienced major or minor PTCA complications, such as emergency bypass surgery (9.0 days [8.0, 18.0]; P < .001), Q-wave or non-Q-wave myocardial infarction (8.0 [6.0, 15.5]; P < .001), transfusion unrelated to bypass surgery (8.0 [4.0, 12.0]; P < .001), or abrupt vessel closure (6.0 [3.0, 10.5]; P < .001). On stepwise multiple linear regression, PTCA complications appeared to be the strongest predictors of length of hospital stay (all P < .001) and overwhelmed the weaker relation between length of stay and several individual baseline variables. Inclusion of a composite clinical risk score (reflecting the presence of unstable angina, multivessel disease, advanced age, complex lesions, or filling defects) in the regression model confirmed that patients with several high-risk baseline variables had a significant increase in length of stay after PTCA (P = .003), but PTCA complications remained the strongest predictors of length of stay.


CONCLUSIONS
Although PTCA complications were correlated with baseline variables such as unstable angina, multivessel disease, advanced age, complex lesions, and filling defects, excess length of stay after PTCA was most strongly influenced by the development of minor and major PTCA complications. Because patients with several baseline risk factors experienced significantly prolonged hospitalizations, improved selection of patients may contribute to reductions in length of stay after PTCA. A greater reduction in resource use after PTCA, however, would be expected from developing new treatments to decrease PTCA complications rather than limiting the access of patients with unstable angina, advanced age, or complex lesions to PTCA.",1995-08-01,https://www.semanticscholar.org/paper/00cf52ce59123c6259257d77e1a2fe9e0a748407,Circulation
3655,Pointers to Class Members in C++,,,https://www.semanticscholar.org/paper/5b4326d758d326c81c3ac84f2a1a155f8b348793,C++ Conference
3381,Estimating the Longest Increasing Subsequence in Nearly Optimal Time,"Longest Increasing Subsequence (LIS) is a fundamental statistic of a sequence, and has been studied for decades. While the LIS of a sequence of length n can be computed exactly in time $O(n\log n)$, the complexity of estimating the (length of the) LIS in sublinear time, especially when LIS $\ll n$, is still open. We show that for any $n\in\mathbb{N}$ and $\lambda=o(1)$, there exists a (randomized) non-adaptive algorithm that, given a sequence of length n with LIS $\geq\lambda n$, approximates the LIS up to a factor of $1/\lambda^{o(1)}$ in $ n^{o(1)}/\lambda$ time. Our algorithm improves upon prior work substantially in terms of both approximation and run-time: (i) we provide the first sub-polynomial approximation for LIS in sub-linear time; and (ii) our run-time complexity essentially matches the trivial sample complexity lower bound of $\Omega(1/\lambda)$, which is required to obtain any non-trivial approximation of the LIS. As part of our solution, we develop two novel ideas which may be of independent interest. First, we define a new Genuine-LIS problem, in which each sequence element may be either genuine or corrupted. In this model, the user receives unrestricted access to the actual sequence, but does not know a priori which elements are genuine. The goal is to estimate the LIS using genuine elements only, with the minimal number of tests for genuineness. The second idea, Precision Tree, enables accurate estimations for composition of general functions from “coarse” (sub-)estimates. Precision Tree essentially generalizes classical precision sampling, which works only for summations. As a central tool, the Precision Tree is pre-processed on a set of samples, which thereafter is repeatedly used by multiple components of the algorithm, improving their amortized complexity.",2021-12-09,https://www.semanticscholar.org/paper/475af2fc6bb7b11e3853f8587c5fc3378e614f41,IEEE Annual Symposium on Foundations of Computer Science
353,Geographic routing without location information,"For many years, scalable routing for wireless communication systems was a compelling but elusive goal. Recently, several routing algorithms that exploit geographic information (e.g. GPSR) have been proposed to achieve this goal. These algorithms refer to nodes by their location, not address, and use those coordinates to route greedily, when possible, towards the destination. However, there are many situations where location information is not available at the nodes, and so geographic methods cannot be used. In this paper we define a scalable coordinate-based routing algorithm that does not rely on location information, and thus can be used in a wide variety of ad hoc and sensornet environments.",2003-09-14,https://www.semanticscholar.org/paper/2209d6da6d473a7720509b8500781a85e8151670,ACM/IEEE International Conference on Mobile Computing and Networking
45,SQL Queries Over Unstructured Text Databases,"Text documents often embed data that is structured in nature. By processing a text database with information extraction systems, we can define a variety of structured ""relations"" over which we can then issue SQL queries. Processing SQL queries in this text-based scenario presents multiple challenges. One key challenge is efficiency: information extraction is a time-consuming process, so query processing strategies should pick efficient extraction systems whenever possible, and also minimize the number of documents that they process. Another key challenge is result quality: extraction systems might output erroneous information or miss information that they should capture; also, efficiency-related query processing decisions (e.g., to avoid processing large numbers of useless documents) may compromise result completeness. To address these challenges, we characterize SQL query processing strategies in terms of their efficiency and result quality, and discuss the (user-specific) tradeoff between these two properties.",2007-04-15,https://www.semanticscholar.org/paper/560877311db77387ce1e822e3374f43eb41be692,IEEE International Conference on Data Engineering
2196,Differential changes in gene expression in human neutrophils following TNF‐α stimulation: Up‐regulation of anti‐apoptotic proteins and down‐regulation of proteins involved in death receptor signaling,"Responses of human neutrophils to TNF‐α are complex and multifactorial. Exposure of human neutrophils to TNF‐α in vitro primes the respiratory burst, delays apoptosis and induces the expression of several genes including chemokines, and TNF‐α itself. This study aimed to determine the impact of TNF‐α exposure on the expression of neutrophil genes and proteins that regulate apoptosis. Quantitative PCR and RNA‐Seq, identified changes in expression of several apoptosis regulating genes in response to TNF‐α exposure. Up‐regulated genes included TNF‐α itself, and several anti‐apoptotic genes, including BCL2A1, CFLAR (cFLIP) and TNFAIP3, whose mRNA levels increased above control values by between 4‐20 fold (n = 3, P < 0.05). In contrast, the expression of pro‐apoptotic genes, including CASP8, FADD and TNFRSF1A and TNFRSF1B, were significantly down‐regulated following TNF‐α treatment. These changes in mRNA levels were paralleled by decreases in protein levels of caspases 8 and 10, TRADD, FADD, TNFRSF1A and TNFRSF1B, and increased cFLIP protein levels, as detected by western blotting. These data indicate that when neutrophils are triggered by TNF‐α exposure, they undergo molecular changes in transcriptional expression to up‐regulate expression of specific anti‐apoptotic proteins and concomitantly decrease expression of specific proteins involved in death receptor signaling which will alter their function in TNF‐α rich environments.",2015-12-02,https://www.semanticscholar.org/paper/2cd0e96a43285a5fce422ebed195f67d8833f8e4,"Immunity, Inflammation and Disease"
2421,Line Drawing Algorithm on an Interleaved Grid,,,https://www.semanticscholar.org/paper/8cc283ee1020e0c00b4d6e288df5c7a427791077,
3390,Parallel approximate undirected shortest paths via low hop emulators,"We present a (1+ε)-approximate parallel algorithm for computing shortest paths in undirected graphs, achieving poly(logn) depth and m poly(logn) work for n-nodes m-edges graphs. Although sequential algorithms with (nearly) optimal running time have been known for several decades, near-optimal parallel algorithms have turned out to be a much tougher challenge. For (1+ε)-approximation, all prior algorithms with poly(logn) depth perform at least Ω(mn c ) work for some constant c>0. Improving this long-standing upper bound obtained by Cohen (STOC’94) has been open for 25 years. We develop several new tools of independent interest. One of them is a new notion beyond hopsets — low hop emulator — a poly(logn)-approximate emulator graph in which every shortest path has at most O(loglogn) hops (edges). Direct applications of the low hop emulators are parallel algorithms for poly(logn)-approximate single source shortest path (SSSP), Bourgain’s embedding, metric tree embedding, and low diameter decomposition, all with poly(logn) depth and m poly(logn) work. To boost the approximation ratio to (1+ε), we introduce compressible preconditioners and apply it inside Sherman’s framework (SODA’17) to solve the more general problem of uncapacitated minimum cost flow (a.k.a., transshipment problem). Our algorithm computes a (1+ε)-approximate uncapacitated minimum cost flow in poly(logn) depth using m poly(logn) work. As a consequence, it also improves the state-of-the-art sequential running time from m· 2 O(√logn) to m poly(logn).",2019-11-05,https://www.semanticscholar.org/paper/50a9be89c2206c68f031b88b5c2cc7f27bc9b08b,Symposium on the Theory of Computing
698,Epinoia: Intent Checker for Stateful Networks,"Intent-Based Networking (IBN) has been increasingly deployed in production enterprise networks. Automated network configuration in IBN lets operators focus on intents- i.e., the end to end business objectives-rather than spelling out details of the configurations that implement these objectives. Automation brings its own concerns as the administrators cannot rely on traditional network troubleshooting tools. This situation is further exacerbated in the case of stateful Network Functions (NFs) whose packet processing behavior depends on previously observed traffic patterns. To ensure that the network configuration and state derived from network automation matches the administrator’s specified intent, we propose, Epinoia, a network intent checker for stateful networks. Epinoia relies on a unified model for NFs by leveraging the causal precedence relationships that exist between NF packet I/Os and states. Scalability of Epinoia is achieved by decomposing intents into sub-checking tasks and maintaining a causality graph between checked invariants. Epinoia checks for network-wide intent violations incrementally to reduce overhead in the event of network changes. Our evaluation results using real-world network topologies show that Epinoia can perform comprehensive checking within a few seconds per network with intent updates.",2021-07-01,https://www.semanticscholar.org/paper/93adbd0fcd79f4d1efe86f0b5fa9c0cd0cade3d9,International Conference on Computer Communications and Networks
2792,IL-10 is overexpressed in human cutaneous T-cell lymphoma and is required for maximal tumor growth in a mouse model,"Abstract A crucial question pertains to a role of IL-10 as a tumorigenic factor, or just a marker of advanced disease in cutaneous T-cell lymphoma (CTCL). Herein, we measured significantly elevated IL-10 mRNA in a cohort of skin samples of patients with CTCL. Increased IL-10 was also detected in the tumor microenvironment of an established inflammation-dependent murine model of using MBL2 T lymphoma cells. Conditioned media from MBL2 cells was able to stimulate IL-10 production in bone marrow-derived macrophages in an IL-4-dependent manner. Implanted MBL2 T-cell lymphomas in IL-10KO mice were 50% smaller, accompanied by decreased numbers of infiltrating macrophages and reduced efficiency of M2-polarization compared with wild-type mice. With anti-IL-10R mAb treatment, both wild-type tumor-bearing mice and IL-10KO mice exhibited a further growth inhibition. Our data indicate that targeting IL-10 signaling with neutralizing antibodies to IL-10 or its receptor may have a great potential for advanced CTCL therapy.",2018-10-02,https://www.semanticscholar.org/paper/95747452c8cff59dde8b737fd33fd70dc12f4617,Leukemia and Lymphoma
3509,A 2-2/3 Approximation for the Shortest Superstring Problem,"Given a collection of strings S={s_1, ..., s_n} over an alphabet \Sigma, a superstring \alpha of S is a string containing each s_i as a substring; that is, for each i, 1>=i>=n, \alpha contains a block of |s_i| consecutive characters that match s_i exactly. The shortest superstring problem is the problem of finding a superstring \alpha of minimum length. The shortest superstring problem has applications in both data compression and computational biology. In data compression, the problem is a part of a general model of string compression proposed by Gallant, Maier and Storer (JCSS ''80). Much of the recent interest in the problem is due to its application to DNA sequence assembly. The problem has been shown to be NP-hard; in fact, it was shown by Blum et al.(JACM ''94) to be MAX SNP-hard. The first O(1)-approximation was also due to Blum et al., who gave an algorithm that always returns a superstring no more than 3 times the length of an optimal solution. Several researchers have published results that improve on the approximation ratio; of these, the best previous result is our algorithm ShortString, which achieves a 2 3/4-approximation (WADS ''95). We present our new algorithm, G-ShortString, which achieves a ratio of 2 2/3. It generalizes the ShortString algorithm, but the analysis differs substantially from that of ShortString. Our previous work identified classes of strings that have a nested periodic structure, and which must be present in the worst case for our algorithms. We introduced machinery to descibe these strings and proved strong structural properties about them. In this paper we extend this study to strings that exhibit a more relaxed form of the same structure, and we use this understanding to obtain our improved result.",1995-06-01,https://www.semanticscholar.org/paper/126a9c671e10fc5b74574e72ce7d836156efe1f9,
2791,Cytosolic galectin-3 and -8 regulate antibacterial autophagy through differential recognition of host glycans on damaged phagosomes,"While glycans are generally displayed on the cell surface or confined within the lumen of organelles, they can become exposed to the cytosolic milieu upon disruption of organelle membrane by various stresses or pathogens. Galectins are a family of β-galactoside-binding animal lectins synthesized and predominantly localized in the cytosol. Recent research indicates that some galectins may act as ""danger signal sensors"" by detecting unusual exposure of glycans to the cytosol. Galectin-8 was shown to promote antibacterial autophagy by recognizing host glycans on ruptured vacuolar membranes and interacting with the autophagy adaptor protein NDP52. Galectin-3 also accumulates at damaged phagosomes containing bacteria; however, its functional consequence remains obscure. By studying mouse macrophages infected with Listeria monocytogenes (LM), we showed that endogenous galectin-3 protects intracellular LM by suppressing the autophagic response through a host N-glycan-dependent mechanism. Knock out of the galectin-3 gene resulted in enhanced LC3 recruitment to LM and decreased bacterial replication, a phenotype recapitulated when Galectin-8-deficient macrophages were depleted of N-glycans. Moreover, we explored the concept that alterations in cell surface glycosylation by extracellular factors can be deciphered by cytosolic galectins during the process of phagocytosis/endocytosis, followed by rupture of phagosomal/endosomal membrane. Notably, treatment of cells with sialidase, which removes sialic acid from glycans, resulted in increased galectin-3 accumulation and decreased galectin-8 recruitment at damaged phagosomes, and led to a stronger anti-autophagic response. Our findings demonstrate that cytosolic galectins may sense changes in glycosylation at the cell surface and modulate cellular response through differential recognition of glycans on ruptured phagosomal membranes.",2018-06-01,https://www.semanticscholar.org/paper/7d1520c9447ac7331209524172be6d6d3128c66e,Glycobiology
2219,Children exposed to metals mixtures demonstrate dysregulation of infectious disease response,,2012-08-30,https://www.semanticscholar.org/paper/1251e81c612e6d6ad7f44554c8fd58d3567a1a7e,
1417,High-p T jets in p p collisions at As˜630 and 1800 GeV,,,https://www.semanticscholar.org/paper/f6dea10a2664b4c074eb2771c6208b00ad39e89b,
2444,Evaluating the effect of positional head-tracking on task performance in 3D modeling user interfaces,,2017-06-01,https://www.semanticscholar.org/paper/25a7748cdf18cd535b97e0528b30ef666778fa2d,Computers & graphics
540,The Complexity of Markov Decision Processes,"We investigate the complexity of the classical problem of optimal policy computation in Markov decision processes. All three variants of the problem finite horizon, infinite horizon discounted, and infinite horizon average cost were known to be solvable in polynomial time by dynamic programming finite horizon problems, linear programming, or successive approximation techniques infinite horizon. We show that they are complete for P, and therefore most likely cannot be solved by highly parallel algorithms. We also show that, in contrast, the deterministic cases of all three problems can be solved very fast in parallel. The version with partially observed states is shown to be PSPACE-complete, and thus even less likely to be solved in polynomial time than the NP-complete problems; in fact, we show that, most likely, it is not possible to have an efficient on-line implementation involving polynomial time on-line computations and memory of an optimal policy, even if an arbitrary amount of precomputation is allowed. Finally, the variant of the problem in which there are no observations is shown to be NP-complete.",1987-08-01,https://www.semanticscholar.org/paper/d51eb16dfed68bf6e16b8b4516d607370b91189a,Mathematics of Operations Research
3614,C and C + + : Case Studies in Compatibility,"This article gives examples of how one might go about increasing the degree of compatibility of C and C++. The ideal is full compatibility. Topics covered includes, variadic functions, v o i d *, b o o l , f (v o i d ), c o n s t , i n l i n e , and variable length arrays. These topics allows a demonstration of concerns that must be taken into account when trying to increase C/C++ compatibility. A companion paper [Stroustrup,2002a] provides a ‘‘philosophical’’ view of the C/C++ relationship, and another companion paper presents a case for significantly increased C/C++ compatibility and proposed full compatibility as the ideal. [Stroustrup,2002b].",,https://www.semanticscholar.org/paper/8793484686efe697023106434eccc732151d0563,
2374,Temperature‐compensated ultradian rhythms in lower eukaryotes: Periodic turnover coupled to a timer for cell division,"Abstract During the cell cycles of synchronous cultures of several different yeasts and protozoa, oscillations in the rate of respiration and of total cellular protein content have been demonstrated. Energy supply (from mitochondrial oxidative phosphorlation) and energy demand (biosynthetic reactions, especially protein accumulation) are closely coupled oscillating systems. Phase correspondence between O2 consumption rates, intracellular ADP pool size, and total cellular protein indicates that it is energetic demand that determines mitochondrial activity (respiratory control in vivo). The dynamics of the coupled oscillators indicate that the rate‐determining control circuit operates on a time scale expected of epigenetic reactions (transcription and translation). Thus the energy‐yielding reactions are enslaved to the slower time constants of biosynthesis. Temperature compensation indicates a timing function, and a common phase reference point makes subcycles commensurate with the cell cycle. It is suggest...",1986-12-01,https://www.semanticscholar.org/paper/770b780922db0b46a5f81ff62f76a37f22b4ecc1,
3052,Proceedings of the 2011 USENIX conference on USENIX annual technical conference,,2011-06-15,https://www.semanticscholar.org/paper/6b0cf61cc33d1b0c3f9605c5bea2f02ad8868096,
3645,The C++ programming language (2nd ed.),,1991-08-01,https://www.semanticscholar.org/paper/8ba2e16569ca174d07aff48c24bc2f567016592b,
1578,The Medical Deconfounder: Assessing Treatment Effect with Electronic Health Records (EHRs),"Causal estimation of treatment effect has an important role in guiding physicians' decision process for drug prescription. While treatment effect is classically assessed with randomized controlled trials (RCTs), the availability of electronic health records (EHRs) bring an unprecedented opportunity for more efficient estimation. However, the presence of unobserved confounders makes treatment effect assessment from EHRs a challenging task. Confounders are the variables that affect both drug prescription and the patient's outcome; examples include a patient's gender, race, social economic status and comorbidities. When these confounders are unobserved, they bias the estimation. To adjust for unobserved confounders, we develop the medical deconfounder, a machine learning algorithm that unbiasedly estimates treatment effect from EHRs. The medical deconfounder first constructs a substitute confounder by modeling which drugs were prescribed to each patient; this substitute confounder is guaranteed to capture all multi-drug confounders, observed or unobserved (Wang and Blei, 2018). It then uses this substitute confounder to adjust for the confounding bias in the analysis. We validate the medical deconfounder on simulations and two medical data sets. The medical deconfounder produces closer-to-truth estimates in simulations and identifies effective medications that are more consistent with the findings reported in the medical literature compared to classical approaches.",2019-04-03,https://www.semanticscholar.org/paper/b352c244259c17eecea8dc50a53ca1d694357e4c,arXiv.org
1289,Search for B0S → μ+μ-decays at DO,"We report results from a search for the decay B 0 s → μ + μ - using 1.3 fb -1 of pp collisions at √s = 1.96 TeV collected by the DO experiment at the Fermilab Tevatron Collider. We find two candidate events, consistent with the expected background of 1.24 ± 0.99, and set an upper limit on the branching fraction of B(B 0 s → μ + μ - ) < 1.2 × 10 -7 at the 95% C.L.",,https://www.semanticscholar.org/paper/b07023f05988ffa729bced84616f43543568c848,
2430,ICthroughVR: Illuminating Cataracts through Virtual Reality,"Vision impairments, such as cataracts, affect the way many people interact with their environment, yet are rarely considered by architects and lighting designers because of a lack of design tools. To address this, we present a method to simulate vision impairments, in particular cataracts, graphically in virtual reality (VR), using eye tracking for gaze-dependent effects. We also conduct a VR user study to investigate the effects of lighting on visual perception for users with cataracts. In contrast to existing approaches, which mostly provide only simplified simulations and are primarily targeted at educational or demonstrative purposes, we account for the user's vision and the hardware constraints of the VR headset. This makes it possible to calibrate our cataract simulation to the same level of degraded vision for all participants. Our study results show that we are able to calibrate the vision of all our participants to a similar level of impairment, that maximum recognition distances for escape route signs with simulated cataracts are significantly smaller than without, and that luminaires visible in the field of view are perceived as especially disturbing due to the glare effects they create. In addition, the results show that our realistic simulation increases the understanding of how people with cataracts see and could therefore also be informative for health care personnel or relatives of cataract patients.",2019-03-23,https://www.semanticscholar.org/paper/fef502774ed48df19536f5d9e239d1ee365fd4a9,IEEE Conference on Virtual Reality and 3D User Interfaces
2041,A Data Mining and Time Series Integrated Approach for Analyzing Semiconductor MES and FDC Data to Enhance Overall Usage Effectiveness,,,https://www.semanticscholar.org/paper/29b80228321acc1bbb0535b658ac842ed572b7b5,
1628,Evaluating Bayesian Models with Posterior Dispersion Indices,"Probabilistic modeling is cyclical: we specify a model, infer its posterior, and evaluate its performance. Evaluation drives the cycle, as we revise our model based on how it performs. This requires a metric. Traditionally, predictive accuracy prevails. Yet, predictive accuracy does not tell the whole story. We propose to evaluate a model through posterior dispersion. The idea is to analyze how each datapoint fares in relation to posterior uncertainty around the hidden structure. This highlights datapoints the model struggles to explain and provides complimentary insight to datapoints with low predictive accuracy. We present a family of posterior dispersion indices (PDI) that capture this idea. We show how a PDI identifies patterns of model mismatch in three real data examples: voting preferences, supermarket shopping, and population genetics.",2017-07-17,https://www.semanticscholar.org/paper/7d520c022397773ab25feef5c5c6492bf1900999,International Conference on Machine Learning
2892,Grain Size and Shape Dependent Crystal Plasticity Finite Element Model and its Application to Electron Beam Welded Ss316l,,2023-06-01,https://www.semanticscholar.org/paper/3f40540c07bc543ee4a4aac46ac8b1f133c87582,Social Science Research Network
3069,Guest Editors' Introduction: Virtual Machines,A system virtual machine is a software implementation of a real computer that can execute unmodified applications and an operating system. This issue contains articles and interviews that explore virtual machine use in pervasive computing.,2009-10-01,https://www.semanticscholar.org/paper/1aa77b746e2b7dbb128bffe564ebb02e49b9ce5b,IEEE pervasive computing
3268,Individual recognition through olfactory–auditory matching in lemurs,"Individual recognition can be facilitated by creating representations of familiar individuals, whereby information from signals in multiple sensory modalities become linked. Many vertebrate species use auditory–visual matching to recognize familiar conspecifics and heterospecifics, but we currently do not know whether representations of familiar individuals incorporate information from other modalities. Ring-tailed lemurs (Lemur catta) are highly visual, but also communicate via scents and vocalizations. To investigate the role of olfactory signals in multisensory recognition, we tested whether lemurs can recognize familiar individuals through matching scents and vocalizations. We presented lemurs with female scents that were paired with the contact call either of the female whose scent was presented or of another familiar female from the same social group. When the scent and the vocalization came from the same individual versus from different individuals, females showed greater interest in the scents, and males showed greater interest in both the scents and the vocalizations, suggesting that lemurs can recognize familiar females via olfactory–auditory matching. Because identity signals in lemur scents and vocalizations are produced by different effectors and often encountered at different times (uncoupled in space and time), this matching suggests lemurs form multisensory representations through a newly recognized sensory integration underlying individual recognition.",2014-06-07,https://www.semanticscholar.org/paper/128ee4887ea51f263852fc803fb4b29e23b7a02a,Proceedings of the Royal Society B: Biological Sciences
2082,Segmented WIP Control for Cycle Time Reduction,"In semiconductor manufacturing, it is difficult for engineers to control complicated and often imbanlanced heavily loaded production routes well. This study aims to propose a framework of segmented WIP control for the production routes to control and reduce cycle time effectively. Furthermore, Starvation Avoidance (SA) method is employed to maintain high utilization of the Capacity Constrained Resources (CCR) in light of low WIP situations. A simulation is designed and validated with a small-scale model based on real data collected in a wafer fab in Taiwan. The results demonstrated its qualified viability.",2006-09-01,https://www.semanticscholar.org/paper/fba059d90442c8c15d9efaf10299e6068bd5ac52,2006 IEEE International Symposium on Semiconductor Manufacturing
1896,Electronic Design Automation (EDA) Scheduling System in IC Design Industry,"With the global competition and short life cycle in semiconductor industry, the IC design companies try to keep their competitiveness. Besides the human resources and advanced technology, enhancing the speed of the development is an important method to enhance market share. IC designers usually use electronic design automation tool to shorten the development. However, the EDA tools and resources are expensive and limited. Hence, it becomes a critical problem to allocate the resources and schedule the jobs. This study aimed to develop an IC design job scheduling decision support system framework. The framework enhances the throughput and reduces the idle. This study implements the proposed framework in practice. The empirical study conducted in IC design company to validate the developed solution and model implementation.",2019-04-01,https://www.semanticscholar.org/paper/74500f3a8dd0b456b9dea3111abc29fc69de1777,3D Structure from Multiple Images of Large-Scale Environments
2204,"ABSENCE OF ASSOCIATION FOR DDAH 1 POLYMORPHISM , RS 17384213 , WITH SCLERODERMA RENAL CRISIS HIGHLIGHTS DIVERSITY IN RENAL COMPLICATIONS OF CONNECTIVE TISSUE DISEASE","cell lines induced 5-10 fold greater expression of the Th17 transcription factor RORgt. Overall a mean of 57.2% of all IL-23Rþ CD4þ T cells expressed KIR3DL2 in SpA patients, compared with 37%, 53.7% and 24.5% of IL-23Rþ CD4þ T cells in HLA-B27healthy controls, HLA-B27þ healthy controls and RA patients respectively. KIR3DL2þ CD4þ T cells comprised a mean of 40% of all OX40-expressing CD4þ T cells in SpA patients compared with 30% and 17% of B27þ and B27controls and 19% of RA controls. KIR3DL2þCD4 T cells also comprised a greater proportion of IL1Rþ and CCR9þ CD4 T cells in SpA patients. By contrast we did not observe changes in the expression of these markers within the KIR3DL2 negative CD4 T cell compartment. Conclusion: Our results support a central role for B27 KIR3DL2 interactions in the development of Th17 immune responses in SpA patients and suggest that the development of reagents that target this interaction could be of therapeutic benefit. Disclosure statement: S.K. has received grants/research support from Arthritis Research UK and NIHR. A.R. has received grants/ research support from NIHR. I.W.-B. has received grants/research support from ConaCyt. H.H. has received grants/research support from JSPS. J.S. has received grants/research support from Arthritis Research UK. H.A.-M. hs received grants/research support from the Welcome Trust. The other author has declared no conflicts of interest.",,https://www.semanticscholar.org/paper/26ec9f043347ed3f9a7fdc7acedb6277622c9029,
2420,Augmented Reality Guidance for Configuring an Anesthesia Machine to Serve as a Ventilator for COVID-19 Patients,"When there is a shortage of ventilators in a hospital, an anesthesia machine can be used as a ventilator. However, using an anesthesia machine as a ventilator requires that it be set up in a way that would not be familiar to medical personnel who normally work with ventilators. To teach medical staff how to do this, we developed a smartphone augmented reality app that allows a user to interact with a life-size virtual anesthesia machine, and leads them through the necessary steps. This makes it possible for the user to practice the setup procedures in a way that preserves the 3D spatial layout of the tasks without requiring access to the physical machine.",2021-03-01,https://www.semanticscholar.org/paper/824adff7b0c0a2f1aa204ef5f5fb7a4c9c0abcf3,2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)
2542,Computer Graphics in C#: Principles and Practices,,2008-08-31,https://www.semanticscholar.org/paper/0f0e56df9becd3c56a7fb07b6ec7eb8cef43210d,
2670,An Experimental Hybrid User Interface for Collaboration,"Abstract : We present EMMIE (Environment Management for Multiuser Information Environments), an experimental user interface to a collaborative augmented environment. Users share a 3D virtual space and manipulate virtual objects representing information to be discussed. This approach not only allows for cooperation in a shared physical space, but also addresses telecollaboration in physically separate but virtually shared spaces. We refer to EMMIE as a hybrid user interface because it combines a variety of different technologies and techniques, including virtual elements such as 3D widgets, and physical objects such as tracked displays and input devices. See through head worn displays overlay the virtual environment on the physical environment. Our research prototype includes additional 2D and 3D displays, ranging from palmsized to wallsized, allowing the most appropriate one to be used for any task. Objects can be moved among displays (including across dimensionalities) through drag & drop. In analogy to 2D window managers, we describe a prototype implementation of a shared 3D environment manager that is distributed across displays, machines, and operating systems. We also discuss two methods we are exploring for handling information privacy in such an environment.",,https://www.semanticscholar.org/paper/f8f2bd1a07bcf640a33291064226703065fd796a,
2176,AB0115 SECUKINUMAB THERAPY DOES NOT AFFECT NEUTROPHIL HOST DEFENCE IN PSORIATIC ARTHRITIS,"Biologic therapies have revolutionised therapy in inflammatory diseases such as psoriatic arthritis (PsA), driving major improvements in outcomes. Th17 cells appear to play a key role in the pathogenesis of PsA, and IL-17 can trigger the release of chemoattractants such as CXCL8 and CCL20, leading to the further infiltration of other immune cells including neutrophils. Infiltrating activated neutrophils can themselves generate a range of chemoattractants which may amplify and sustain the inflammatory response. Therapeutic targeting of IL-17 with biologics such as secukinumab offers great benefit in PsA by blocking this inflammatory cycle: however the interaction of this agent with neutrophils, key components of host defence as well as potential mediators of this disease, is not known.This study aimed to measure key aspects of neutrophil function to determine: a) changes in the functions of circulating neutrophils in PsA patients pre-therapy, compared to age- and sex-matched healthy controls and b) if these functions changed in PsA patients 12-weeks post-secukinumab therapy.Neutrophils were isolated from venous blood of 16 PsA patients and 10 healthy controls. Key neutrophil functions were measured at baseline and 12 weeks: reactive oxygen species (ROS) production, apoptosis (+/- TNF and GM-CSF), phagocytosis, receptor expression and chemotaxis. Changes in gene expression pre- and 12-weeks post-therapy (n=5 PsA) were measured using RNAseq.PsARC response was observed in 70.6% of participants on secukinumab therapy at 12 weeks. There were no significant differences in ROS production, phagocytosis or chemotaxis in PsA patients at baseline (compared to healthy controls) or during therapy. Chemotaxis towards IL-8 in PsA patients at baseline was decreased compared to that of healthy controls, but this difference did not reach statistical significance. Surface levels of activation markers CD11b/CD18 and CD63 were increased in PsA patients at 12-weeks compared to baseline, while surface levels of CD16 decreased. RNA-seq analysis indicated down-regulation of pathways mediated by IL-17A, oncostatin M, TWEAK (TNFSF12) and CCL2 during therapy, but up-regulated expression of pathways involvingde novoprotein biosynthesis.Therapy with secukimumab in PsA did not significantly affect neutrophil host defence functions. The changes that were seen in circulating neutrophils indicate selective up- and down-regulation of functions that may reflect potential alterations in local or systemic cytokines, and/or an increase in the circulating pool of activated neutrophils that are no longer recruited into sites of inflammation because of the down-regulation of the local IL-17/CXCL8 signalling network.Andrew Cross: None declared, Jennifer Hawkes: None declared, Helen Frankland: None declared, Ayren Mediana: None declared, Helen Wright Grant/research support from: Novartis supporting this study, Nicola Goodson Grant/research support from: Novartis supporting this research, Steven Edwards Grant/research support from: Novartis supporting this work, Robert Moots Grant/research support from: Novartis supporting this work, Consultant of: a variety of companies including Novartis, Speakers bureau: a variety of companies including Novartis",2020-06-01,https://www.semanticscholar.org/paper/c1b6742f0ed8d109a246c8cf9eeaf6004a4a4a0c,Annals of the Rheumatic Diseases
3670,An experiment with the interchangeability of processes and monitors,"Two styles of operating system implementation based on the use of monitors and processes, respectively, are identified, and arguments for a basic equivalence of these systems despite large stylistic differences are presented. The ‘Lauer‐Needham Duality Hypothesis’ states that the two styles are equivalent, both in terms of ease of programming and in efficiency of the resulting systems. A domain for which the first part of this claim holds is outlined, and data affirming the essential equivalence of performance within that domain are presented. An operating system based on the Cambridge CAP system, called SIMOS, was simulated for a wide range of hardware configurations and job loads. SIMOS is written using a module concept that allows an individual module to be interpreted as a monitor in one run and as a process in another. Runs using a monitor to control access to some data can be compared with runs using a process to control access to the same data. The throughput and response time for the two styles of system were found to be identical in most cases. However, a degradation in response time occurred in a process‐based system when the job load and the low level scheduling policy were poorly matched.",1982-11-01,https://www.semanticscholar.org/paper/251b04c0a7aea5655f7cc4f868d3e2e7ac8edc7e,"Software, Practice & Experience"
57,Learning to find answers to questions on the Web,"We introduce a method for learning to find documents on the Web that contain answers to a given natural language question. In our approach, questions are transformed into new queries aimed at maximizing the probability of retrieving answers from existing information retrieval systems. The method involves automatically learning phrase features for classifying questions into different types, automatically generating candidate query transformations from a training set of question/answer pairs, and automatically evaluating the candidate transformations on target information retrieval systems such as real-world general purpose search engines. At run-time, questions are transformed into a set of queries, and reranking is performed on the documents retrieved. We present a prototype search engine, Tritus, that applies the method to Web search engines. Blind evaluation on a set of real queries from a Web search engine log shows that the method significantly outperforms the underlying search engines, and outperforms a commercial search engine specializing in question answering. Our methodology cleanly supports combining documents retrieved from different search engines, resulting in additional improvement with a system that combines search results from multiple Web search engines.",2004-05-01,https://www.semanticscholar.org/paper/4d2d2e3d02ba66be54be5170099ee4ba0d923958,TOIT
1378,SuperCDMS Development Project,"This document introduces the ""SuperCDMS"" project, a phased experimental program which builds on the success of the CDMS II project and extends the direct-detection reach for WIMP dark matter by an additional two orders of magnitude over the next decade. To take full advantage ofthelarger, cleaner detectors we develop for this project, we reduce the cosmogenic neutron level by moving to SNOLab starting in 2009. The increase in sensitivity greatly expands our discovery potential and complements the study of supersymmetry at the Large Hadron Collider. This proposal to NSF and DOE covers the 4-year development phase of this exciting program, from April 2005 to March 2009. This SuperCDMS Development Project will combine the technical preparation for the SNOLab experiment with continued running of CDMS detectors at our Soudan facility together with six new SuperCDMS detectors. Our technical development will include the fabrication of detectors which are 2.5 times more massive than the CDMS II detectors with improved rejection capability and decreased surface backgrounds. We will also develop more efficient detector production methods and design the necessary cryogenic, electronic and data acquisition systems. This work will lay the foundation for SuperCDMS Phase A and SuperCDMS Phase B, experiments at SNOLab deploying 25-kg and 150-kg of Ge target masses, and running in 2009-2011 and 2012-2014, respectively. The SuperCDMS Development Project deliverables include the Conceptual and Technical Design Reports for these two phases. basis for their eventual approval.",2004-10-01,https://www.semanticscholar.org/paper/d7ae0a4656c766a104b1954f7d96187694e7ad13,
29,Session details: Special section on managing information extraction,,,https://www.semanticscholar.org/paper/42ddfcde1bb3d71550318ee79988cb4a9c77e66e,SGMD
2732,Virtual worlds for visualizing information,"Virtual worlds are computer-generated environments created by coupling 3-D displays and interaction devices to powerful graphics workstations. The author describes work in the design of virtual worlds being carried out by Columbia's Computer Graphics and User Interfaces Group Two of the main themes of this group's research are exploiting true 3-D interaction and display devices to visualize and manipulate rich information spaces, and using artificial-intelligence techniques to automate the generation of effective graphics. The projects discussed address virtual worlds for visualizing multivariate data, hybrid user interfaces that merge 2-D and 3-D displays and interaction devices, and augmented realities in which the surrounding physical world is annotated with knowledge-based 3-D graphics.<<ETX>>",1992-12-01,https://www.semanticscholar.org/paper/de518d72d7577a09feacd0dda3d222d7e14830d2,Proceedings Supercomputing '92
2640,Unsolved problems in mobile computer graphics and interaction,"With the number of mobile devices exceeding PCs, research is required in many areas with respect to graphics and interaction. There are problems with interaction, streaming, graphics algorithms, bandwidth with current and future devices. This panel examines the state of the art from both an industrial and research point of view, and provides directions for future work in this area.",2002-07-21,https://www.semanticscholar.org/paper/f88c3da92a676be25d182d2990cc2f39e494d5ac,International Conference on Computer Graphics and Interactive Techniques
1416,Search for New Physics Using Quaero: A General Interface to D0 Event Data,"We describe Quaero, a method that i) enables the automatic optimization of searches for physics beyond the standard model, and ii) provides a mechanism for making high energy collider data generally available. We apply Quaero to searches for standard model WW, ZZ, and ttbar production, and to searches for these objects produced through a new heavy resonance. Through this interface, we make three data sets collected by the D0 experiment at sqrt(s)=1.8 TeV publicly available.",2001-06-07,https://www.semanticscholar.org/paper/f382477b40a061076e57643473605337adafb656,
1514,Density Uncertainty Layers for Reliable Uncertainty Estimation,"Assessing the predictive uncertainty of deep neural networks is crucial for safety-related applications of deep learning. Although Bayesian deep learning offers a principled framework for estimating model uncertainty, the approaches that are commonly used to approximate the posterior often fail to deliver reliable estimates of predictive uncertainty. In this paper we propose a novel criterion for predictive uncertainty, that a model's predictive variance should be grounded in the empirical density of the input. It should produce higher uncertainty for inputs that are improbable in the training data and lower uncertainty for those inputs that are more probable. To operationalize this criterion, we develop the density uncertainty layer, an architectural element for a stochastic neural network that guarantees that the density uncertain criterion is satisfied. We study neural networks with density uncertainty layers on the CIFAR-10 and CIFAR-100 uncertainty benchmarks. Compared to existing approaches, we find that density uncertainty layers provide reliable uncertainty estimates and robust out-of-distribution detection performance.",2023-06-21,https://www.semanticscholar.org/paper/3cb746ee9ab49920ead4bd832d94ca0bc1ee5d3b,arXiv.org
2839,Galectins in Regulation of Inflammation and Immunity,,2008-01-29,https://www.semanticscholar.org/paper/3be93dea6b0800e853382fc29035b7c90d30b0d8,
1476,"Measurement of the photon structure function F(2) (gamma) (X, Q**2) between 10-GEV**2 < Q**2 < 60-GEV**2",,,https://www.semanticscholar.org/paper/55271de1025a09d5dffc125fa40180ea13c31260,
3678,Humans as Light Bulbs: 3D Human Reconstruction from Thermal Reflection,"The relatively hot temperature of the human body causes people to turn into long-wave infrared light sources. Since this emitted light has a larger wavelength than visible light, many surfaces in typical scenes act as infrared mirrors with strong specular reflections. We exploit the thermal reflections of a person onto objects in order to locate their position and reconstruct their pose, even if they are not visible to a normal camera. We propose an analysis-by-synthesis framework that jointly models the objects, people, and their thermal reflections, which combines generative models with differentiable rendering of reflections. Quantitative and qualitative experiments show our approach works in highly challenging cases, such as with curved mirrors or when the person is completely unseen by a normal camera.",2023-05-02,https://www.semanticscholar.org/paper/16a122b84bab5e61775869967b1822b71dd453a9,Computer Vision and Pattern Recognition
2829,Role of galectin-3 in macrophage response to Listeria monocytogenes infection,,2009-04-01,https://www.semanticscholar.org/paper/044038ed8bba11f8b3a8f7b1959fa2923f09439b,
2277,Cultivation of an ovine strain of Ehrlichia phagocytophila in tick cell cultures.,"Ehrlichia phagocytophila (previously known as Cytoecetes phagocytophila) which causes tick-borne fever (TBF) in sheep and pasture fever in cattle in the UK and mainland Europe is transmitted by the temperate hard tick Ixodes ricinus. The disease in sheep is characterized by fever, leucopenia and immunosuppression. Studies on the pathogenesis and other aspects of the disease have been hampered because the organism has not been cultivated in continuous or primary cell culture systems. This paper describes the first successful cultivation of a European isolate of E. phagocytophila in two continuous cell lines, IDE8 and ISE6, derived from the temperate hard tick Ixodes scapularis. Once adapted to tick cell cultures the organism was serially sub-cultured in new cells by transferring small portions of infected cell suspension every 2 to 3 weeks. The identity of the organism was confirmed by polymerase chain reaction (PCR), with primers specific to the granulocytic ehrlichiae. Sequence analysis of the PCR products amplified from infected tick cells were shown to be identical with those amplified from the blood of sheep infected with the same strain of E. phagocytophila. A susceptible sheep inoculated with a third passage of the tick cell-adapted E. phagocytophila reacted with fever and rickettsiaemia 5 days later, thus satisfying Koch's postulates.",2002-10-01,https://www.semanticscholar.org/paper/1bcbef85536d10b2a400684dc4c1aadcd04889c0,Journal of Comparative Pathology
3389,Fully Dynamic Maximal Independent Set with Polylogarithmic Update Time,"We present the first algorithm for maintaining a maximal independent set (MIS) of a fully dynamic graph---which undergoes both edge insertions and deletions---in polylogarithmic time. Our algorithm is randomized and, per update, takes O(log^2 Δ log^2 n) expected time. Furthermore, the algorithm can be adjusted to have O(log^2 Δ log^4 n) worst-case update-time with high probability. Here, n denotes the number of vertices and Δ is the maximum degree in the graph. The MIS problem in fully dynamic graphs has attracted significant attention after a breakthrough result of Assadi, Onak, Schieber, and Solomon [STOC'18] who presented an algorithm with O(m^3/4) update-time (and thus broke the natural Ω(m) barrier) where m denotes the number of edges in the graph. This result was improved in a series of subsequent papers, though, the update-time remained polynomial. In particular, the fastest algorithm prior to our work had Õ (min{√n, m^1/3}) update-time [Assadi et al. SODA'19]. Our algorithm maintains the lexicographically first MIS over a random order of the vertices. As a result, the same algorithm also maintains a 3-approximation of correlation clustering. We also show that a simpler variant of our algorithm can be used to maintain a random-order lexicographically first maximal matching in the same update-time.",2019-09-08,https://www.semanticscholar.org/paper/502140641ab77c45002bfed620d064253a699a9a,IEEE Annual Symposium on Foundations of Computer Science
144,View planning for automated site modeling,"We present a systematic method for constructing 3-D models of large outdoor sites. The method is designed for a mobile robot platform and incorporates automated acquisition of scanned data as well as automated view planning and model construction. In our modeling process, we first use a preliminary view or set of preplanned views to yield an initial, approximate, 3-D model of the target structure. Then, we update this model by using a voxel-based procedure to plan and acquire the next best view. This updating is repeated sequentially until an accurate and complete 3-D model is finally obtained. The method was successfully tested on a portion of the Columbia University campus",2006-05-15,https://www.semanticscholar.org/paper/1f2b869e8f8a9985ab1f8e0dd4fabf4c629371e7,"Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006."
3077,Two-Person Control Administation: Preventing Administation Faults through Duplication,"Modern computing systems are complex and difficult to administer, making them more prone to system administration faults. Faults can occur simply due to mistakes in the process of administering a complex system. These mistakes can make the system insecure or unavailable. Faults can also occur due to a malicious act of the system administrator. Systems provide little protection against system administrators who install a backdoor or otherwise hide their actions. To prevent these types of system administration faults, we created ISE-T (I See Everything Twice), a system that applies the two-person control model to system administration. ISE-T requires two separate system administrators to perform each administration task. ISE-T then compares the results of the two administrators' actions for equivalence. ISE-T only applies the results of the actions to the real system if they are equivalent. This provides a higher level of assurance that administration tasks are completed in a manner that will not introduce faults into the system. While the two-person control model is expensive, it is a natural fit for many financial, government, and military systems that require higher levels of assurance. We implemented a prototype ISE-T system for Linux using virtual machines and a unioning file system. Using this system, we conducted a real user study to test its ability to capture changes performed by seperate system administrators and compare them for equivalence. Our results show that ISE-T is effective at determining equivalence for many common administration tasks, even when administrators perform those tasks in different ways.",2009-11-01,https://www.semanticscholar.org/paper/d7e88f2dcbdae94addf108bd67f09f02126512e1,LiSA
1682,Variational inference with copula augmentation,"We develop a general methodology for variational inference which preserves dependency among the latent variables. This is done by augmenting the families of distributions used in mean-field and structured approximation with copulas. Copulas allow one to separately model the dependency given a factorization of the variational distribution, and can guarantee us better approximations to the posterior as measured by KL divergence. We show that inference on the augmented distribution is highly scalable using stochastic optimization. Furthermore, the addition of a copula is generic and can be applied straightforwardly to any inference procedure using the original meanfield or structured approach. This reduces bias, sensitivity to local optima, sensitivity to hyperparameters, and significantly helps characterize and interpret the dependency among the latent variables.",2015-06-10,https://www.semanticscholar.org/paper/7f50ccd131867f65f3044d20db0a90d6374f7a12,arXiv.org
2300,GTPgammaS-stimulated phospholipase D activation in human neutrophils occurs by protein kinase C-dependent and -independent pathways but not tyrosine kinases.,"Addition of GTPgammaS to saponin-permeabilised human neutrophils activated both the NADPH oxidase and phospholipase D (PLD). This PLD activation was hardly affected by staurosporine or Ro31-8220 (at concentrations which inhibited PMA stimulated PLD activity), indicating that it was largely independent of protein kinase C (PKC). This GTPgammaS stimulated PLD activity was enhanced by 1 mM ATP, but this ATP-enhanced activity was blocked by inhibitors of PKC. Addition of GTPgammaS resulted in very low levels of phosphorylation on tyrosine residues, but higher levels of phosphorylation on serine/threonine residues. Addition of pervanadate hydroperoxides stimulated phosphorylation on tyrosine residues and activated PLD which was blocked by addition of inhibitors of tyrosine kinases. Thus, GTPgammaS can stimulate PKC-dependent and -independent pathways of PLD activation. Whilst phosphorylation on tyrosine residues can result in activation of PLD, this is regulated independently of activation via G-proteins.",,https://www.semanticscholar.org/paper/145ba8b37a4c68962b22d72ffcd5887d20b95ba3,Biochemical and Biophysical Research Communications - BBRC
3362,"On Predation, Competition, and the Advantages of Group Living",,,https://www.semanticscholar.org/paper/31a958fe666e733bc09cf2dbeb030cf9d70ae6fc,
872,High-probability parallel transitive closure algorithms,"There is a straightforward algorithm for computing the transitive closure of an n-node directed graph in O(log2 n) time on an EREW-PRAM, using n3/log n processors, or indeed with M(n)/ logn processors if one can do serial matrix multiplication in time M(n). Th is algorithm is within a log factor of optimal in work (processor-time product), for solving the all-pairs transitive-closure problem for dense graphs. However, this algorithm is far from optimal when either (a) the graph is sparse, or (b) we want to solve the single-source transitive closure problem. Ideally, we would like an AfC algorithm for transitive closure that took about e processors for the single-source problem on a graph with n nodes and e 2 n arcs, or about en processors for the all-pairs problem on the same graph. While we cannot offer an algorithm that good, we can offer algorithms_with the following performance. (1) For single-source, O(nc) time with O(enlm2’) processors,1 provided e > n2-3c, and (2) for all-pairs, @no time and d(enlvc) processors, provided e 2 n2-2c. Each of these claims assumes 0 < E 5 l/2. Importantly, the algorithms are (only) high-probability algorithms; that is, if they find a path, then a path exists, but they may fail to find a path that exists with probability at most 2-ac, where Q is some positive constant, and c is a multiplier for the time taken by the algorithm. However, we show that incorrect results can be detected, thus putting the algorithm in the “Las Vegas” class. Finally, t Work partially supported by ONR contract N00014-88-K0166 and a Guggenheim fellowship. 1 6 is the notation, proposed by Luks and furthered by A. Bhnn for “within some number of log factors of.” That is, we say f(n) is s(g(n)) if for some constants c and k, and all sufficiently large n, we have j(n) 5 clogk ng(n). we show how to do “breadth-first-search” with the same performance as we are able to achieve for single-source transitive closure.",1990-05-01,https://www.semanticscholar.org/paper/96b5f6dc10022ccad5e61a51b20cd0aea7862617,ACM Symposium on Parallelism in Algorithms and Architectures
1261,Observation of the doubly strange b baryon Omegab-.,"We report the observation of the doubly strange b baryon Omegab- in the decay channel Omegab(-)-->J/psiOmega-, with J/psi-->mu+mu(-) and Omega(-)-->LambdaK(-)-->(ppi-)K-, in pp collisions at sqrt[s]=1.96 TeV. Using approximately 1.3 fb(-1) of data collected with the D0 detector at the Fermilab Tevatron Collider, we observe 17.8+/-4.9(stat)+/-0.8(syst) Omegab- signal events at a mass of 6.165+/-0.010(stat)+/-0.013(syst) GeV. The significance of the observed signal is 5.4sigma, corresponding to a probability of 6.7 x 10(-8) of it arising from a background fluctuation.",2008-08-29,https://www.semanticscholar.org/paper/dca4159b180a91e820986c72251934613e5b757f,Physical Review Letters
2519,Opportunistic Tangible User Interfaces for Augmented Reality,"Opportunistic Controls are a class of user interaction techniques that we have developed for augmented reality (AR) applications to support gesturing on, and receiving feedback from, otherwise unused affordances already present in the domain environment. By leveraging characteristics of these affordances to provide passive haptics that ease gesture input, Opportunistic Controls simplify gesture recognition, and provide tangible feedback to the user. In this approach, 3D widgets are tightly coupled with affordances to provide visual feedback and hints about the functionality of the control. For example, a set of buttons can be mapped to existing tactile features on domain objects. We describe examples of Opportunistic Controls that we have designed and implemented using optical marker tracking, combined with appearance-based gesture recognition. We present the results of two user studies. In the first, participants performed a simulated maintenance inspection of an aircraft engine using a set of virtual buttons implemented both as Opportunistic Controls and using simpler passive haptics. Opportunistic Controls allowed participants to complete their tasks significantly faster and were preferred over the baseline technique. In the second, participants proposed and demonstrated user interfaces incorporating Opportunistic Controls for two domains, allowing us to gain additional insights into how user interfaces featuring Opportunistic Controls might be designed.",,https://www.semanticscholar.org/paper/522ffc35a5dba800e055275d4242e2e51f8a2a51,IEEE Transactions on Visualization and Computer Graphics
2278,"Differential role of neutrophil Fcgamma receptor IIIB (CD16) in phagocytosis, bacterial killing, and responses to immune complexes.","OBJECTIVE
To determine the roles played by the neutrophil Fcgamma receptor type II (FcgammaRII) (CD32) and FcgammaRIIIb (CD16) in phagocytosis, bacterial killing, and activation by immune complexes (ICs) and to test the hypothesis that inhibition of pathologic effector neutrophil function is possible without compromising host defense.


METHODS
Receptor function was probed by enzymic removal of FcgammaRIIIb from the cell surface and by use of Fab/F(ab')(2) fragments of monoclonal antibodies to block receptor-ligand binding. Cells were challenged with (a) serum-opsonized Staphylococcus aureus, (b) serum- and IgG-opsonized latex particles, and (c) synthetic soluble and insoluble ICs to mimic bacterial and inflammatory stimuli.


RESULTS
Phosphatidylinositol-phospholipase C treatment removed >97% of surface FcgammaRIIIb from neutrophils previously treated with tumor necrosis factor alpha to mobilize intracellular stores of receptor. This treatment profoundly inhibited activation of primed neutrophils by soluble ICs of the type found in diseased rheumatoid joints, but had no effect on phagocytosis and killing of serum-opsonized S aureus.


CONCLUSION
FcgammaRIIIb plays a major role in the secretion of toxic products in response to ICs, but little or no role in the phagocytosis and killing of serum-opsonized bacteria. The selective suppression of effector neutrophil function is therefore possible. FcgammaRIIIb, or its intracellular signaling pathway, is a potential therapeutic target in inflammatory diseases such as rheumatoid arthritis, because disruption of its function should decrease inflammatory tissue damage, but not jeopardize host protection against infection.",2002-05-01,https://www.semanticscholar.org/paper/548a2bb4fd5d2ab36ef5864ae69e0366d9d1fbc5,Arthritis & Rheumatism
1251,Search for anomalous top-quark couplings with the D0 detector.,Anomalous Wtb couplings modify the angular correlations of the top-quark decay products and change the single top-quark production cross section. We present limits on anomalous top-quark couplings by combining information from W boson helicity measurements in top-quark decays and anomalous coupling searches in the single top-quark final state. We set limits on right-handed vector couplings as well as left-handed and right-handed tensor couplings based on about 1 fb(-1) of data collected by the D0 experiment.,2008-12-31,https://www.semanticscholar.org/paper/bce163495cde2142a8122e0d071353b81c0a98e7,Physical Review Letters
3690,Private Multiparty Perception for Navigation,"We introduce a framework for navigating through cluttered environments by connecting multiple cameras together while simultaneously preserving privacy. Occlusions and obstacles in large environments are often challenging situations for navigation agents because the environment is not fully observable from a single camera view. Given multiple camera views of an environment, our approach learns to produce a multiview scene representation that can only be used for navigation, provably preventing one party from inferring anything beyond the output task. On a new navigation dataset that we will publicly release, experiments show that private multiparty representations allow navigation through complex scenes and around obstacles while jointly preserving privacy. Our approach scales to an arbitrary number of camera viewpoints. We believe developing visual representations that preserve privacy is increasingly important for many applications such as navigation.",2022-12-02,https://www.semanticscholar.org/paper/17aaad12138347e3f1a40b6be69b892ad455a00c,Neural Information Processing Systems
2658,Engineering information abstract (Part I)Standard reference model for intelligent multimedia presentation systems,,1999-03-01,https://www.semanticscholar.org/paper/0f20fdefb0b62d97d79d83e354518d11cc5b87d8,
734,Model Checking of Recursive Probabilistic Systems,"Recursive Markov Chains (RMCs) are a natural abstract model of procedural probabilistic programs and related systems involving recursion and probability. They succinctly define a class of denumerable Markov chains that generalize several other stochastic models, and they are equivalent in a precise sense to probabilistic Pushdown Systems. In this article, we study the problem of model checking an RMC against an ω-regular specification, given in terms of a Büchi automaton or a Linear Temporal Logic (LTL) formula. Namely, given an RMC A and a property, we wish to know the probability that an execution of A satisfies the property. We establish a number of strong upper bounds, as well as lower bounds, both for qualitative problems (is the probability = 1, or = 0?), and for quantitative problems (is the probability ≥ p?, or, approximate the probability to within a desired precision). The complexity upper bounds we obtain for automata and LTL properties are similar, although the algorithms are different.
 We present algorithms for the qualitative model checking problem that run in polynomial space in the size |A| of the RMC and exponential time in the size of the property (the automaton or the LTL formula). For several classes of RMCs, including single-exit RMCs (a class that encompasses some well-studied stochastic models, for instance, stochastic context-free grammars) the algorithm runs in polynomial time in |A|. For the quantitative model checking problem, we present algorithms that run in polynomial space in the RMC and exponential space in the property. For the class of linearly recursive RMCs we can compute the exact probability in time polynomial in the RMC and exponential in the property. For deterministic automata specifications, all our complexities in the specification come down by one exponential.
 For lower bounds, we show that the qualitative model checking problem, even for a fixed RMC, is already EXPTIME-complete. On the other hand, even for simple reachability analysis, we know from our prior work that our PSPACE upper bounds in A can not be improved substantially without a breakthrough on a well-known open problem in the complexity of numerical computation.",2012-04-01,https://www.semanticscholar.org/paper/5c8117e4b3a6c0002d9ac45e70d7f2faf07a5595,TOCL
2518,Focus and Context in Mixed Reality by Modulating First Order Salient Features,"We present a technique for dynamically directing a viewer's attention to a focus object by analyzing and modulating bottom-up salient features of a video feed. Rather than applying a static modulation strategy, we inspect the original image's saliency map, and modify the image automatically to favor the focus object. Image fragments are adaptively darkened, lightened and manipulated in hue according to local contrast information rather than global parameters. The goal is to suggest rather than force the attention of the user towards a specific location. The technique's goal is to apply only minimal changes to an image, while achieving a desired difference of saliency between focus and context regions of the image. Our technique exhibits temporal and spatial coherence and runs at interactive frame rates using GPU shaders. We present several application examples from the field of Mixed Reality, or more precisely Mediated Reality.",2010-06-24,https://www.semanticscholar.org/paper/273182f7df098bbb979d19905ab60823b41d241d,International Symposium on Smart Graphics
2965,On Using Control Variates with Stochastic Approximation for Variational Bayes and its Connection to Stochastic Linear Regression,"Recently, we and several other authors have written about the possibilities of using stochastic approximation techniques for fitting variational approximations to intractable Bayesian posterior distributions. Naive implementations of stochastic approximation suffer from high variance in this setting. Several authors have therefore suggested using control variates to reduce this variance, while we have taken a different but analogous approach to reducing the variance which we call stochastic linear regression. In this note we take the former perspective and derive the ideal set of control variates for stochastic approximation variational Bayes under a certain set of assumptions. We then show that using these control variates is closely related to using the stochastic linear regression approximation technique we proposed earlier. A simple example shows that our method for constructing control variates leads to stochastic estimators with much lower variance compared to other approaches.",2014-01-06,https://www.semanticscholar.org/paper/98d764b59e26338aaeffaf40db303d079ffcd07c,
3252,Disruption of a protective ant-plant mutualism by an invasive ant increases elephant damage to savanna trees.,"Invasive species can indirectly affect ecosystem processes via the disruption of mutualisms. The mutualism between the whistling thorn acacia (Acacia drepanolobium) and four species of symbiotic ants is an ecologically important one; ants strongly defend trees against elephants, which can otherwise have dramatic impacts on tree cover. In Laikipia, Kenya, the invasive big-headed ant (Pheidole megacephala) has established itself at numerous locations within the last 10-15 years. In invaded areas on five properties, we found that three species of symbiotic Crematogaster ants were virtually extirpated, whereas Tetraponera penzigi co-occurred with P. megacephala. T. penzigi appears to persist because of its nonaggressive behavior; in a whole-tree translocation experiment, Crematogaster defended host trees against P. megacephala, but were extirpated from trees within hours. In contrast, T. penzigi retreated into domatia and withstood invading ants for >30 days. In the field, the loss of defensive Crematogaster ants in invaded areas led to a five- to sevenfold increase in the number of trees catastrophically damaged by elephants compared to uninvaded areas. In savannas, tree cover drives many ecosystem processes and provides essential forage for many large mammal species; thus, the invasion of big-headed ants may strongly alter the dynamics and diversity of East Africa's whistling thorn savannas by disrupting this system's keystone acaciaant mutualism.",2015-03-01,https://www.semanticscholar.org/paper/162ac08f323a5af5e83975751be8caac932282d3,Ecology
373,Learning the Internet,,2002-07-08,https://www.semanticscholar.org/paper/8379729ba4fc0c07834bf9834d73d16175b27f66,Annual Conference Computational Learning Theory
51,Extracting relations from large text collections,"A wealth of information is hidden within unstructured text. Often, this information can be beat exploited in structured or relational form, which is well suited for sophisticated query processing, for integration with relational database management systems, and for data mining. This thesis addresses two fundamental problems in extracting relations from large text collections: (1) portability: tuning extraction systems for new domains and (2) scalability: scaling up information extraction to large collections of documents. To address the first problem, we developed the Snowball information extraction system, a domain-independent system that learns to extract relations from unstructured text based on only a handful of user-provided example relation instances. Snowball can then be adapted to extract new relations with minimum human effort. Snowball improves the extraction accuracy by automatically evaluating the quality of both the acquired extraction patterns and the extracted relation instances. To address the second problem, we developed the QXtract system, which learns search engine queries that retrieve the documents that are relevant to a given information extraction system and extraction task. QXtract can dramatically improve the efficiency of the information extraction process, and provides a building block for extracting structured information and text data mining from the web at large.",,https://www.semanticscholar.org/paper/2adfbbd25f971c2a6fc5ed0bddcb62a9f2abbb6f,
2025,A conceptual methodology of “industrial engineering” for “the industry as a whole”: Semiconductor industry as illustration,"The discipline of industrial engineering has been declining in many countries in light of the changes of industry structures in developed countries, in which the competition is no longer among individual companies while the collaboration among horizontally specialized value providers are critical for the success of the individual companies as well as the whole supply chain. There should be a systematic methodology of “industrial engineering” that focuses on “industry as a whole” as the subject of study to differentiate our discipline from others such as electrical engineering or chemical engineering. Focusing on semiconductor industry as the specific subject, this study aims to propose a conceptual methodology of industrial engineering to investigate semiconductor industry. In particular, semiconductor industry is one of the most complicated and capital-intensive industries. Driven by Moore's Law, semiconductor industry has a clock speed faster than other industries and thus can provide an important benchmark for other industries. In the presentation, we propose a framework to explain the evolution of the semiconductor industry from the point of view of modularity and integration driven by technical and economical considerations to simplify complex production problems. Several case studies of the companies in different positions of the semiconductor value chain are illustrated to discuss some of the challenges and ongoing changes. TSMC established a pure wafer foundry business model in 1987 that assumes all the costs of capital expenditure and expenses in wafer fabrication never competes with its clients of fabless design houses and IDMs. The pure foundry can easily scale up or down its production capacity according to an individual customer's needs, while maximizing fab utilization with a portfolio of various customers. Such a business model freed fabless and IDM designers from the burden of capital investment for advanced technology capacity. Thus, IC designers can concentrate on chip design for various applications including PC and consumer electronics. Meanwhile, the semiconductor industry is moving to more narrow specialization such as Ardentec that focuses on the middle layer of wafer sort between front-end of IC design and wafer fabrication and backend of IC packaging and final testing. Nevertheless, Global Unichip Corporation that positions itself as a design foundry focusing on SoC (System on a Chip) is trying to virtually integrate the supply chain to deal with technical challenges driven by Moore's Law and technological inseparability involved in SoC and SiP (System in Package). This talk will conclude with discussions of the implications of semiconductor industry evolution to computers and industrial engineering research.",2010-07-25,https://www.semanticscholar.org/paper/5bec55d7da3bc89fdb3c5e6316f4408ea1604a50,The 40th International Conference on Computers & Indutrial Engineering
3286,Facilitation between bovids and equids on an African savanna,"Background: Equids, especially zebras and donkeys, and cattle (bovids) share habitats in many savanna ecosystems in Africa. The issue of competition for food between these ungulate guilds remains largely unresolved. Resolving it will provide insights into how wild zebra are likely to interact with cattle on shared landscapes and suggest best practices for cattle owners who must decide whether to tolerate wild ungulates, some of which are severely threatened (e.g. Grevy’s zebra, Equus grevyi). Aim: Determine whether an equid and a bovid compete in a semi-arid savanna in Kenya. Organisms: Boran cattle (Bos indicus) and donkeys (Equus africanus asinus) – the latter as surrogates for zebras. Methodology: Experiments to measure performance (weight gains), bite rates, diet quality (digestible organic matter and crude protein), and gastrointestinal worm burdens (parasite egg count per unit weight of faeces) of the two ungulate species when herded separately (single species) or together (mixed species). We used two stocking levels: low-density (one animal per 7 ha), a level typical of commercial ranchers; and high-density (one animal per 2 ha), a level typical of pastoral herders. Principal findings: When herded together, both species gained more weight, had higher bite rates (especially at low stocking density), and selected diets with a more favourable balance between digestible organic matter and crude protein, than when herded separately. In addition, parasite egg output in faeces of donkeys was reduced by 14–35% following shared foraging with cattle. Conclusion: Cattle (a ruminant) and donkeys (hindgut fermenters, closely related to zebras) showed no evidence of competion with each other. Rather, our results show a facilitative, rather than a competitive, interaction between them.",2011-08-19,https://www.semanticscholar.org/paper/629d5286f64cf80f2aff3d75c0361920b1bb37dc,
1925,An empirical study for smart production for TFT-LCD to empower Industry 3.5,"Abstract With increasing technological advancements, manufacturing intelligence has become a crucial issue for maintaining competitive advantages. Industry 4.0, proposed by Germany, is one of the large-scale projects to achieve manufacturing intelligence and smart production. Others include the Advanced Manufacturing Partnership 2.0 (AMP2.0) from the United States, Industry 4.1J of Japan and Made in China 2025. On the other hand, most of the emerging countries may not be ready for the migration of Industry 4.0 directly since their industrial infrastructures are different with the leading countries. This study aims to propose Industry 3.5 as a hybrid strategy between existing Industry 3.0 and to-be Industry 4.0, in which digital decision-making, big data analytics, and manufacturing intelligence are integrated to empower smart production with disruptive innovations that can be realized in existing industrial infrastructure. To estimate the validity of the proposed Industry 3.5, an empirical study was conducted in a thin film transistor liquid crystal display (TFT-LCD) manufacturing factory in Taiwan. A smart daily planning and scheduling (DPS) system is developed to enhance manufacturing intelligence for smart production without a fully automation facility as the Cyber-Physical System proposed in Industry 4.0. This study concludes with discussions of development directions for industrial revolution.",2017-10-03,https://www.semanticscholar.org/paper/d4bd57a5743d5ea9de2dbe492755fe2a56dc2bfb,
3293,The effects of immunocontraception on harem fidelity in a feral horse (Equus caballus) population,,2010-12-01,https://www.semanticscholar.org/paper/905d479436cc5453f588a83d3649259bc2667351,
1850,Combining Stochastic Block Models and Mixed Membership for Statistical Network Analysis,,2006-06-29,https://www.semanticscholar.org/paper/b82c2c26c44358e140b6e2eb5537563939cd3ab9,SNA@ICML
307,The Computation of Equilibria,,2007-12-12,https://www.semanticscholar.org/paper/6d1002c294e86e92c0ef6fb47ac242ba73a59a2d,Workshop on Internet and Network Economics
1443,The Cryogenic Dark Matter Search (CDMS),,,https://www.semanticscholar.org/paper/e14ffbc76db45914d6bdaca9828b026f087860cd,
2446,PXEL COLORWALUES AT THE FLASH CORRUPTED PXELLOCATIONS,"4,978,989 : 12/1990 Nakano et al. ...................... 396/177 5,130,789 * 7/1992 Dobbs et al. ..... ... 358/500 5,748,764 * 5/1998 Benati et al. ..... ... 382/117 5.990,973 * 11/1999 Sakamoto ...... ... 382/117 6,009.209 * 12/1999 Acker et al. .. ... 382/275 6,016,354 * 1/2000 Lin et al. ...... ... 382/117 6,072,893 * 6/2000 Luo et al. .. ... 382/117 6,085,195 * 7/2000 Hoyt et al. . ... 396/2 6,151,403 11/2000 Luo ...................................... 347/117",,https://www.semanticscholar.org/paper/59239daf3d4eb4e65a9e9ae8bfdee4a4c84adc01,
3249,Effects of traditional pastoralism on grasshopper (Caelifera) assemblages in East Africa,"In East Africa, traditional pastoralists increase landscape heterogeneity by creating traditional livestock corrals (bomas). When these bomas are abandoned, they serve as long-term hot spots of increased nutrients and unique vegetation. However, the effect of bomas on insect populations is unclear. Grasshopper (Suborder Caelifera) assemblages are thought to reflect vegetation, and within Caelifera, the subfamily Oedipodinae is known to be associated with degraded areas. We sampled vegetation and collected grasshoppers inside of abandoned bomas, 50 m from abandoned bomas and 250 m from abandoned bomas. Bomas had significantly lower grass abundance than background vegetation. Total grasshopper abundance was positively correlated with grass and forb abundance, while the proportion of grasshoppers in the subfamily Oedipodinae was negatively correlated with grass abundance. Grasshopper abundance was significantly lower inside of bomas than outside of them, but the proportion of grasshoppers in the subfamily Oedipodinae was significantly higher inside of bomas than outside of them. This suggests that the decreased vegetation in abandoned bomas supports fewer grasshoppers, but a higher fraction of the grasshopper assemblage in abandoned bomas is composed of Oedipodinae. Thus, traditional pastoralists can have long-term effects on the size and composition of grasshopper assemblages through the use of bomas. 
 
Resume 
 
En Afrique de l'Est, les eleveurs traditionnels augmentent l'heterogeneite des paysages en creant des enclos traditionnels (bomas) pour leur betail. Lorsque ces bomas sont abandonnes, ils restent longtemps des lieux speciaux, plus riches en nutriments, ou la vegetation est unique. Pourtant les effets des bomas sur les populations d'insectes ne sont pas clairs. L'on estime que les assemblages de sauterelles (du sous-ordre des Caelifera) refletent la vegetation et, parmi eux, la sous-famille des Oedipodinae est connue comme etant liee aux endroits degrades. Nous avons collecte des echantillons de vegetation et de sauterelles a l'interieur de bomas abandonnes, a 50 m de la et a 250 m. Les bomas presentaient des graminees en abondance de significativement plus faible que la vegetation environnante. L'abondance totale des sauterelles etait positivement liee a celle des graminees et des dicotyledones, mais la proportion de sauterelles de la sous-famille des Oedipodinae etait liee negativement a celle des graminees. L'abondance des sauterelles etait significativement plus faible a l'interieur des anciens bomas qu'a l'exterieur, mais la proportion de sauterelles de la sous-famille des Oedipodinae y etait significativement plus elevee qu'a l'exterieur. Ceci suggere que la vegetation rarefiee des bomas abandonnes supporte un nombre plus faible de sauterelles mais qu'une plus grande fraction de l'assemblage de sauterelles dans les bomas abandonnes se compose d'Oedipodinae. Les eleveurs traditionnels ont donc un effet a long terme sur la taille et la composition des assemblages de sauterelles par la frequentation de leurs bomas.",2016-03-01,https://www.semanticscholar.org/paper/d4dfe520d5ca6163861337b614d6467d814048ef,
2017,Multi-objective GA for Selecting and Scheduling R&D Project Portfolio,,,https://www.semanticscholar.org/paper/c0ae828657f52e20affdb89d107dafc14fe5b6d9,
898,Deleting completed transactions,We derive necessary and suflicient conditions on when it is safe to forget (and remove) a completed transaction in several versions of conflict-graph-based schedulers. We show that the conditions can be applied repeatedly and analyze their complexity.,1985-06-01,https://www.semanticscholar.org/paper/bd10d8321209fc74fb3cc68ff277f82b4efa75a3,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
2676,IMPROVISE: Automated Generation of Animated Graphics for Coordinated Multimedia Presentations,,1998-01-28,https://www.semanticscholar.org/paper/782114bf4b816bc98da4c511a4babe5971e43743,Cooperative Multimodal Communication
3729,Formalizing Novelty,"Managing inputs that are novel, unknown, or out-ofdistribution is critical as an agent moves from the lab to the open world. Novelty-related problems include being tolerant to novel perturbations of the normal input, detecting when the input includes novel items, and adapting to novel inputs. While significant research has been undertaken in these areas, a noticeable gap exists in the lack of a formalized definition of novelty that transcends problem domains. As a team of researchers spanning multiple research groups and different domains, we have seen, first hand, the difficulties that arise from ill-specified novelty problems, as well as inconsistent definitions and terminology. Therefore, we present the first unified framework for formal theories of novelty and use the framework to formally define a family of novelty types. Our framework can be applied across a wide range of domains, from symbolic AI to reinforcement learning, and beyond to open world image recognition. Thus, it can be used to help kick-start new research efforts and accelerate ongoing work on these important novelty-related problems.",,https://www.semanticscholar.org/paper/fb1166ada6c98d4c6abed81d9995eb515c95f341,
3239,GPS tracking cattle as a monitoring tool for conservation and management,"The emergence of GPS technology has resulted in significant advances in the ease and flexibility of studying animal movement patterns, yet barriers remain to the widespread use of GPS units for animal tracking. Here, we developed a low-cost, logistically simple approach, deploying small and inexpensive GPS units to monitor cattle movements and habitat use and to assess the impact of cattle grazing on vegetation. Cattle were collared with i-gotU loggers to track fine-scale and broad-scale movements within an integrated ecosystem (cattle and wildlife) in Laikipia, central Kenya. At the fine scale, cattle exerted a significant impact on vegetation quantity and quality; increasing grazing intensity showed a negative relationship to grass height, but a positive correlation to green-up after rain. At the broad scale, cattle movement density varied notably by herd type and habitat availability, with acacia woodland and savanna grassland habitats used most predominantly. Overall, these small GPS loggers provided a flexible and relatively cheap method of tracking cattle movements, and demonstrated potential for collaring of cattle as a tool for monitoring ecosystem health and assisting management decisions.",2017-07-03,https://www.semanticscholar.org/paper/8305810d57909e7b293d5c8b10ee4b93f7c58626,
3548,Open and efficient type switch for C++,"Selecting operations based on the run-time type of an object is key to many object-oriented and functional programming techniques. We present a technique for implementing open and efficient type switching on hierarchical extensible data types. The technique is general and copes well with C++ multiple inheritance. To simplify experimentation and gain realistic performance using production-quality compilers and tool chains, we implement a type switch construct as an ISO C++11 library, called Mach7. This library-only implementation provides concise notation and outperforms the visitor design pattern, commonly used for case analysis on types in object-oriented programming. For closed sets of types, its performance roughly equals equivalent code in functional languages, such as OCaml and Haskell. The type-switching code is easier to use and is more expressive than hand-coded visitors are. The library is non-intrusive and circumvents most of the extensibility restrictions typical of the visitor design pattern. It was motivated by applications involving large, typed, abstract syntax trees.",2012-10-19,https://www.semanticscholar.org/paper/3ee45f31a74d34ec99da29c1d6ef5d987075c917,"Conference on Object-Oriented Programming Systems, Languages, and Applications"
2135,A note on the calculation of sound propagation along an impedance surface,,1980-03-01,https://www.semanticscholar.org/paper/213f8503dce310ba610e76bc4309d1ac3f7fefcc,
2377,The tetrahymena rRNA intron self-splices in E. coli: In vivo evidence for the importance of key base-paired regions of RNA for RNA enzyme function,,1985-02-01,https://www.semanticscholar.org/paper/586cf250606a9203062c02e2a22c48eae954884f,Cell
3211,The behavioural challenge of the COVID-19 pandemic: indirect measurements and personalized attitude changing treatments (IMPACT),"Following the outbreak of COVID-19 pandemic, governments around the globe coerced their citizens to adhere to preventive health behaviours, aiming to reduce the effective reproduction numbers of the virus. Driven by game theoretic considerations and inspired by the work of US National Research Council's Committee on Food Habits (1943) during WWII, and the post-WWII Yale Communication Research Program, the present research shows how to achieve enhanced adherence to health regulations without coercion. To this aim, we combine three elements: (i) indirect measurements, (ii) personalized interventions, and (iii) attitude changing treatments (IMPACT). We find that a cluster of short interventions, such as elaboration on possible consequences, induction of cognitive dissonance, addressing next of kin and similar others and receiving advice following severity judgements, improves individuals' health-preserving attitudes. We propose extending the use of IMPACT under closure periods and during the resumption of social and economic activities under COVID-19 pandemic, since efficient and lasting adherence should rely on personal attitudes rather than on coercion alone. Finally, we point to the opportunity of international cooperation generated by the pandemic.",2020-08-01,https://www.semanticscholar.org/paper/dd07776f1d6cc9b1d0e960058ab4dbeffeffcece,Royal Society Open Science
91,Using q-grams in a DBMS for Approximate String Processing,"String data is ubiquitous, and its management has taken on particular importance in the past few years. Approximate queries are very important on string data. This is due, for example, to the prevalence of typographical errors in data, and multiple conventions for recording attributes such as name and address. Commercial databases do not support approximate string queries directly, and it is a challenge to implement this functionality efficiently with user-defined functions (UDFs). In this paper, we develop a technique for building approximate string processing capabilities on top of commercial databases by exploiting facilities already available in them. At the core, our technique relies on generating short substrings of length q, called q-grams, and processing them using standard methods available in the DBMS. The proposed technique enables various approximate string processing methods in a DBMS, for example approximate (sub)string selections and joins, and can even be used with a variety of possible edit distance functions. The approximate string match predicate, with a suitable edit distance threshold, can be mapped into a vanilla relational expression and optimized by conventional relational optimizers.",,https://www.semanticscholar.org/paper/72d116438a2e7ab0902e3b5fe9fa4cf37c18f5a5,IEEE Data Engineering Bulletin
2899,"Vector Embeddings by Sequence Similarity and Context for Improved Compression, Similarity Search, Clustering, Organization, and Manipulation of cDNA Libraries","This paper demonstrates the utility of organized numerical representations of genes in research involving flat string gene formats (i.e., FASTA/FASTQ5). FASTA/FASTQ files have several current limitations, such as their large file sizes, slow processing speeds for mapping and alignment, and contextual dependencies. These challenges significantly hinder investigations and tasks that involve finding similar sequences. The solution lies in transforming sequences into an alternative representation that facilitates easier clustering into similar groups compared to the raw sequences themselves. By assigning a unique vector embedding to each short sequence, it is possible to more efficiently cluster and improve upon compression performance for the string representations of cDNA libraries. Furthermore, through learning alternative coordinate vector embeddings based on the contexts of codon triplets, we can demonstrate clustering based on amino acid properties. Finally, using this sequence embedding method to encode barcodes and cDNA sequences, we can improve the time complexity of the similarity search by coupling vector embeddings with an algorithm that determines the proximity of vectors in Euclidean space; this allows us to perform sequence similarity searches in a quicker and more modular fashion.",2023-08-08,https://www.semanticscholar.org/paper/e9e31939ec1f183cf2e512112f6768decf8fb7b9,arXiv.org
3471,Revised Papers from the 4th International Workshop on Algorithm Engineering and Experiments,,2002-01-04,https://www.semanticscholar.org/paper/e98620c8a998b7be08832aea8a258d0b39f18103,
1616,Noise-Based Regularizers for Recurrent Neural Networks,"Recurrent neural networks (RNNs) are powerful models for sequential data. They can approximate arbitrary computations, and have been used successfully in domains such as text and speech. However, the flexibility of RNNs makes them susceptible to overfitting and regularization is important. We develop a noise-based regularization method for RNNs. The idea is simple and easy to implement: we inject noise in the hidden units of the RNN and then maximize the original RNN's likelihood averaged over the injected noise. On a language modeling benchmark, our method achieves better performance than the deterministic RNN and the variational dropout.",2018-02-15,https://www.semanticscholar.org/paper/fa5ed34d2576b4ad3ada354d6ad571f61d08482f,
2980,Message passing algorithms for dirichlet diffusion trees,"We demonstrate efficient approximate inference for the Dirichlet Diffusion Tree (Neal, 2003), a Bayesian nonparametric prior over tree structures. Although DDTs provide a powerful and elegant approach for modeling hierarchies they haven't seen much use to date. One problem is the computational cost of MCMC inference. We provide the first deterministic approximate inference methods for DDT models and show excellent performance compared to the MCMC alternative. We present message passing algorithms to approximate the Bayesian model evidence for a specific tree. This is used to drive sequential tree building and greedy search to find optimal tree structures, corresponding to hierarchical clusterings of the data. We demonstrate appropriate observation models for continuous and binary data. The empirical performance of our method is very close to the computationally expensive MCMC alternative on a density estimation problem, and significantly outperforms kernel density estimators.",2011-06-28,https://www.semanticscholar.org/paper/53ea725425d01dc3ebb884537783f68f8bc724d8,International Conference on Machine Learning
2898,Multiset correlation and factor analysis enables exploration of multi-omics data,,2023-07-01,https://www.semanticscholar.org/paper/e85b97c06a76184f4066362809598cdb1770d928,Cell Genomics
1214,Search for pair production of doubly charged Higgs bosons in the H++H- - -->mu+ mu+ mu- mu- final state.,"We report the results of a search for pair production of doubly charged Higgs bosons via pp over-->H++H - - X-->mu+ mu+ mu- mu- X at sqrt s=1.96 TeV. We use a data set corresponding to an integrated luminosity of 1.1 fb(-1) collected from 2002 to 2006 by the D0 detector at the Fermilab Tevatron Collider. In the absence of an excess above the standard model background, lower mass limits of M(H L +/- +/-) >150 GeV/c2 and M(H R+/- +/-) >127 GeV/c2 at 95% C.L. are set, respectively, for left-handed and right-handed doubly charged Higgs bosons assuming a 100% branching ratio into muons.",,https://www.semanticscholar.org/paper/4a79fcfd9742c97378bb207e75a85e5e6bef6e6b,Physical Review Letters
1338,Search for third-generation leptoquarks in $p \bar{p}$ collisions at $\sqrt{s}$ = 1.96-TeV,"We report on a search for charge-1/3 third-generation leptoquarks (LQ) produced in p{bar p} collisions at {radical}(s)=1.96 TeV using the D0 detector at Fermilab. Third-generation leptoquarks are assumed to be produced in pairs and to decay to a tau neutrino and a b quark with branching fraction B. We place upper limits on {sigma}(p{bar p}{yields}LQ{ovr LQ})B{sup 2} as a function of the leptoquark mass M{sub LQ}. Assuming B=1, we exclude at the 95% confidence level third-generation scalar leptoquarks with M{sub LQ}<229 GeV.",2005-04-29,https://www.semanticscholar.org/paper/2d0608b43403c534c7b6c5b9961ecf3902c731ea,
2567,First steps toward an electronic field guide for plants,"We describe an ongoing project to digitize information about plant specimens and make it available to botanists in the field. This first requires digital images and models, and then effective retrieval and mobile computing mechanisms for accessing this information. We have almost completed a digital archive of the collection of type specimens at the Smithsonian Institution Department of Botany. Using these and additional images, we have also constructed prototype electronic field guides for the flora of Plummers Island. Our guides use a novel computer vision algorithm to compute leaf similarity. This algorithm is integrated into image browsers that assist a user in navigating a large collection of images to identify the species of a new specimen. For example, our systems allow a user to photograph a leaf and use this image to retrieve a set of leaves with similar shapes. We measured the effectiveness of one of these systems with recognition experiments on a large dataset of images, and with user studies of the complete retrieval system. In addition, we describe future directions for acquiring models of more complex, 3D specimens, and for using new methods in wearable computing to interact with data in the 3D environment in which it is acquired.",2006-08-01,https://www.semanticscholar.org/paper/2eee76566a818e0077160f0d44a51c0cd74c62ea,
3093,Improving Virtual Appliances through Virtual Layered File Systems,"The problem of managing computers is growing in complexity due to the increasing amount of physical and virtual computers that one has to administer as well as the varying roles that those computers fill. As each machine is effectively fully independent, the amount of work an administrator does scales linearly with the amount of machines. In order to solve this problem, we introduce Strata, a system that enables new ways of managing these many distinct installations. Strata enables many systems to be easily managed by introducing a virtual layered file system that composes individual software layers together into a single file system view. By providing the ability to share layers between installations, Strata eases the creation of independent systems and opens up new ways to use computers. We have implemented Strata on Linux without requiring any application or operating system kernel changes. Our measurements on real world applications demonstrate that Strata imposes little overhead.",,https://www.semanticscholar.org/paper/e252cdda5cae631f7b9510a76e5ff69aebc2d967,
875,Memory-efficient algorithms for the verification of temporal properties,,1990-06-18,https://www.semanticscholar.org/paper/e3a34614264c3bd9cdccc4c6ea163ff09934a019,Formal Methods Syst. Des.
2261,arthritis . synovial fluid of patients with rheumatoid immunoglobulin aggregates isolated from the of neutrophils by soluble and insoluble Role of Fc gamma receptors in the activation,"Objectives-Synovial fluid from patients with rheumatoid arthritis contains both soluble and insoluble immunoglobulin aggregates which activate reactive oxidant production in human neutrophils. The objectives were to determine the roles played by Fc-y receptors in activation of neutrophils by these complexes. Methods-Pronase treatment was used to remove Fc-yRIII from the neutrophil surface and blocking monoclonal antibodies were used to prevent the binding of complexes to Fc-yRII and FcyRIII. Results-When FcyRIII was removed from the cell surface by pronase treatment, activation by the soluble aggregates did not occur [mean (SD) inhibition 89 (16)%, n = 6] whereas activation via the insoluble aggregates was less affected [34 (16)%, n = 6]. Blocking the binding to Fc-yRIII with antibodies decreased activation in response to the soluble aggregates [mean (SD) inhibition 71 (22)%, n =8] but again had a lower effect on activation by the insoluble aggregates [40 (17)%, n = 9]. When binding to FcyRII was blocked, activation via the soluble aggregates was substantially inhibited [mean (SD) 93 (13)%, n = 8] whereas that via the insoluble aggregates was inhibited to a much lesser extent [28 (38)%, n = 9]. When Fc-yRII and III were simultaneously blocked, activation by the insoluble aggregates was only inhibited by 450/o [(19), n = 5]. Conclusion-These data thus indicate that activation ofhuman neutrophils by soluble immunoglobulin aggregates from rheumatoid synovial fluid occurs via cooperative occupancy of both Fc-yRII and III: perturbation of binding to either of these receptor classes will abrogate activation. (Ann Rheum Dis 1994; 53: 515-520) In addition to their crucial role in host defence, it is appreciated that inappropriate infiltration and activation of neutrophils into tissues can result in tissue damage in inflammatory conditions such as rheumatoid arthritis. Much evidence now exists in previous reports to suggest that neutrophil activation has occurred within synovial joints'7and hence it is of potential pharmacological interest to understand the molecular processes which activate and regulate neutrophil function within such diseased joints. The major neutrophilactivating factors within synovial fluid appear to be immune complexes/immunoglobulin aggregates8-12 which are capable of activating neutrophils via interactions with their plasma membrane Fc receptors. Neutrophils possess receptors recognising the Fc portions ofIgG and IgA`3 '4 and of these the Fcy receptors are the most clearly defined. Three types of FcyR can be present.'5 Fc-yRI (CD64) is not present on blood neutrophils but its expression is up-regulated upon exposure to cytokines such as -y-interferon'6; this receptor is also detected at low levels on neutrophils isolated from the synovial fluid of some patients with rheumatoid arthritis.5 FcyRII (CD32) and Fc-yRIII (CD 16) are both present on the surface of blood neutrophils at levels of about 7-15 000 and 100-200 000 per cell, respectively.'7 There is much debate as to the role of Fc-yRII and FcyRIII in neutrophil function. Neither of these bind monomeric IgG, but they bind dimers, trimers, immune complexes and opsonised particles. It is currently believed that FcyRIII binds complexes, but this binding does not activate phagocytosis, degranulation or the respiratory burst: Fc-yRII occupancy, however, is believed to result in neutrophil activation.'8 '9 Unlike Fc,yRII, Fc-yRIII is held on the neutrophil plasma membrane via a glycerophosphoinositol anchor which is cleaved upon activation,20 and may also be released experimentally via treatment of neutrophils with pronase, elastase and phospholipase C. We have recently shown that synovial fluid from patients with rheumatoid arthritis contains both soluble and insoluble immunoglobulin aggregates which are capable of activating reactive oxidant production by neutrophils.9 However, several lines of evidence indicate that these aggregates activate neutrophils via distinct mechanisms. Firstly, the soluble aggregates only activate neutrophils that have been primed in vivo or in vitro by GM-CSF or -y-interferon. Secondly, the soluble aggregates activate a transient (2-4 minutes) burst of oxidase function in primed cells whereas the insoluble aggregates stimulate a slower (15-20 minutes) activation in primed Department of Biochemistry, University of Liverpool, Liverpool, United Kingdom J J Robinson F Watson S W Edwards Rheumatic Diseases Unit, Royal Liverpool Hospital, Liverpool, United Kingdom R C Bucknall Correspondence to: Dr S W Edwards, Department of Biochemistry, University of Liverpool, PO Box 147, Liverpool LG9 3BX, United Kingdom. Accepted for publication 26 April 1994 515 group.bmj.com on June 29, 2017 Published by http://ard.bmj.com/ Downloaded from",,https://www.semanticscholar.org/paper/077cae4561599db9557818e98d6c5477834e8355,
68,Text joins in an RDBMS for web data integration,"The integration of data produced and collected across autonomous, heterogeneous web services is an increasingly important and challenging problem. Due to the lack of global identifiers, the same entity (e.g., a product) might have different textual representations across databases. Textual data is also often noisy because of transcription errors, incomplete information, and lack of standard formats. A fundamental task during data integration is matching of strings that refer to the same entity. In this paper, we adopt the widely used and established cosine similarity metric from the information retrieval field in order to identify potential string matches across web sources. We then use this similarity metric to characterize this key aspect of data integration as a join between relations on textual attributes, where the similarity of matches exceeds a specified threshold. Computing an exact answer to the text join can be expensive. For query processing efficiency, we propose a sampling-based join approximation strategy for execution in a standard, unmodified relational database management system (RDBMS), since more and more web sites are powered by RDBMSs with a web-based front end. We implement the join inside an RDBMS, using SQL queries, for scalability and robustness reasons. Finally, we present a detailed performance evaluation of an implementation of our algorithm within a commercial RDBMS, using real-life data sets. Our experimental results demonstrate the efficiency and accuracy of our techniques.",2003-05-20,https://www.semanticscholar.org/paper/78b729049a0135dc75a021ce5bbc127902253fde,The Web Conference
3118,Move: mobility with persistent network connections,"The combined force behind ubiquitous mobile computing and storage devices and universal network access has created a unique era of mobile network computing, in which computation units ranging from a single process to an entire host can move while communicating with each other across the network. A key problem therefore is how to preserve the ongoing network communication between two computation units when they move from one place to another; because current network infrastructure and protocols are designed to support stationary communication endpoints only. 
We have developed MOVE, a fine-grain end-to-end connection migration architecture, to address the problem. The most distinguishing characteristic of MOVE is that MOVE achieves, in a single system, several essential goals of a mobile communication architecture including: (1) entirely end system only without any infrastructure demand, transport protocol independence, and backward compatibility; (2) fine-grain connection migration and unlimited mobility scope; (3) secure migration with both handoff and suspension/resumption support; and (4) very low performance overhead both before and after migration. 
We first analyze the key technical problems of end-to-end network communication caused by mobility: state inconsistency, conflict, and synchronization; and we develop a simple and elegant namespace abstraction called CELL to resolve these problems. CELL provides a virtual, private, and labeled namespace for individual connection states so that they can be transparently migrated anywhere free of the problems mentioned above. We then develop a unique handoff signaling protocol called H2O, which can handoff a connection securely in a single one-way end-to-end trip with minimal impact on the connection characteristics perceived by the transport protocols. H2O achieves this by combining the simple connection redirection mechanism afforded by the CELL abstraction with a low-overhead security mechanism, which is based on Diffie-Hellman protocol but computes session keys only at migration time. We finally integrate MOVE seamlessly with a process migration mechanism to fully exploit MOVE's fine-grain connection migration capability and enable support for new application scenarios. For example, we show how the integration can provide high service availability in proxy-based server clusters by allowing server applications and their persistent connections to be migrated during a server maintenance to avoid service disruption. (Abstract shortened by UMI.)",,https://www.semanticscholar.org/paper/1df1ac4b7641771f0d543e184c151d29cf32260a,
899,"Simple Linear-Time Algorithms to Test Chordality of Graphs, Test Acyclicity of Hypergraphs, and Selectively Reduce Acyclic Hypergraphs","An article of golfing equipment has a golf tee attached to a spring-biassed reel by a length of string. The reel is mounted in a casing which receives the tee when the spring rotates the reel to wind the spring onto it. The reel is normally locked by a one-way ratchet but is released to wind in the string by a push-button which has a spike and is detachable from the casing so as to be usable as a ball marker. When practising, the cord can be aligned with the green or hole and used as an aid in swinging the club face in the correct direction. The casing has a spring-clip so that the article can be clipped into the golfer's pocker when he is not using it.",1984-07-27,https://www.semanticscholar.org/paper/1ffc977d82798cfab971e4abdb46ae7b707c57c0,SIAM journal on computing (Print)
1478,EXPERIMENTAL LIMIT ON THE DECAY-TAU--]VTK-KO,,,https://www.semanticscholar.org/paper/56368669e386e7268807db3b1d9e1ac16921df86,
1749,A Split-Merge MCMC Algorithm for the Hierarchical Dirichlet Process,"The hierarchical Dirichlet process (HDP) has become an important Bayesian nonparametric model for grouped data, such as document collections. The HDP is used to construct a flexible mixed-membership model where the number of components is determined by the data. As for most Bayesian nonparametric models, exact posterior inference is intractable---practitioners use Markov chain Monte Carlo (MCMC) or variational inference. Inspired by the split-merge MCMC algorithm for the Dirichlet process (DP) mixture model, we describe a novel split-merge MCMC sampling algorithm for posterior inference in the HDP. We study its properties on both synthetic data and text corpora. We find that split-merge MCMC for the HDP can provide significant improvements over traditional Gibbs sampling, and we give some understanding of the data properties that give rise to larger improvements.",2012-01-08,https://www.semanticscholar.org/paper/6a4a39c40e2e54395ab69977331ccfcff11afa87,arXiv.org
669,An analysis of document graph construction methods for AMR summarization,"Meaning Representation (AMR) is a graph-based semantic representation for sentences, composed of collections of concepts linked by semantic relations. AMR-based approaches have found success in a variety of applications, but a challenge to using it in tasks that require document-level context is that it only represents individual sentences. Prior work in AMR-based summarization has automatically merged the individual sentence graphs into a document graph, but the method of merging and its effects on summary content selection have not been independently evaluated. In this paper, we present a novel dataset consisting of human-annotated alignments between the nodes of paired documents and summaries which may be used to evaluate (1) merge strategies; and (2) the performance of content selection methods over nodes of a merged or unmerged AMR graph. We apply these two forms of evaluation to prior work as well as a new method for node merging and show that our new method has significantly better performance than prior work.",2021-11-27,https://www.semanticscholar.org/paper/a6d91db7ec0c3c4c48e66dbf679f7f98386349a4,arXiv.org
2618,Collaborative Visualization of an Archaeological Excavation,"We are developing a collaborative system for offsite visualization of an archaeological dig site through both virtual and augmented reality. Multiple users, wearing tracked, head-worn, see-through displays, can interact with the environment using tracked, instrumented gloves, a multi-user, multi-touch, projected table surface, large wall displays and tracked hand-held displays. We take advantage of our ongoing work on 3D multimodal interaction [14,20] to allow users to combine speech with head, hand, and arm gestures to aid them in their tasks. Although the dig site can be visualized as a purely virtual environment, when users collaborate using the projected table, their see-through head-worn displays allow them to see personalized overlaid material in context with the shared, projected table surface.",,https://www.semanticscholar.org/paper/63e9c5104cf6ee5d2ca1ddfbc137b1fc84d5e3b1,
2216,Correlation With Cell Survival Mcl-1 Expression in Human Neutrophils: Regulation by Cytokines and,,,https://www.semanticscholar.org/paper/e998353aa38fd577171acd039e4e000e5de5c8f6,
803,Near-optimal hardness results and approximation algorithms for edge-disjoint paths and related problems,"We study the approximability of edge-disjoint paths and related problems. In the edge-disjoint paths (EDP) problem, we are given a network G with source-sink pairs (si, ti), 1 ≤i≤k, and the goal is to find a largest subset of source-sink pairs that can be simultaneously connected in an edge-disjoint manner. We show that in directed networks, for any e>0, EDP is NP-hard to approximate within m1/2-e. We also design simple approximation algorithms that achieve essentially matching approximation guarantees for some generalizations of EDP. Another related class of routing problems that we study concerns EDP with the additional constraint that the routing paths be of bounded length. We show that, for any e > 0, bounded length EDP is hard to approximate within m1/2-e even in undirected networks, and give an O(√m)-approximation algorithm for it. For directed networks, we show that even the single source-sink pair case (i.e. find the maximum number of paths of bounded length between a given source-sink pair) is hard to approximate within m1/2-e, for any e > 0.",1999-05-01,https://www.semanticscholar.org/paper/62eb3948683c5aae8f66736ed79e0675edef9d3f,Symposium on the Theory of Computing
1964,Special Issue on Artificial Intelligence & Industrial Engineering,,2014-07-22,https://www.semanticscholar.org/paper/83f3a272af717b932a5aba35c18b815e543e5ad2,International Journal of Computational Intelligence Systems
2409,"Mitochondrial adenosine triphosphatase of the fission yeast, Schizosaccharomyces pombe 972h-. Changes in activity and oligomycin-sensitivity during the cell cycle of catabolite-repressed and -de-repressed cells.","1. Changes in activity of ATPase (adenosine triphosphatase) during the cell cycle of Schizosaccharomyces pombe were analysed in cell-free extracts of cells harvested from different stages of growth of synchronous cultures and also after cell-cycle fractionation. 2. Oligomycin-sensitive ATPase oscillates in both glucose-repressed synchronous cultures and shows four maxima of activity approximately equally spaced through the cell cycle. The amplitude of the oscillations accounts for between 13 and 80% of the total activity at different times in the cell cycle. 3. Oligomycin sensitivity varies over a fourfold range at different stages of the cell cycle. 4. The periodicity of maximum oligomycin sensitivity is one-quarter of a cell cycle. 5. These results were confirmed for the first three-quarters of the cell cycle by cell-cycle fractionation. 6. In cells growing synchronously with glycerol, ATPase activity increases in a stepwise pattern, with two steps per cell cycle; the first of these occurs at 0.54 of the cell cycle and the second at 0.95. 7. These results are discussed in relation to previously obtained data on the development of mitochondrial activities during the cell cycle.",1977-01-15,https://www.semanticscholar.org/paper/a139aa6da9360dac63ee6aa14eb83b0aaeab50cb,Biochemical Journal
1692,A Probabilistic Model for Using Social Networks in Personalized Item Recommendation,"Preference-based recommendation systems have transformed how we consume media. By analyzing usage data, these methods uncover our latent preferences for items (such as articles or movies) and form recommendations based on the behavior of others with similar tastes. But traditional preference-based recommendations do not account for the social aspect of consumption, where a trusted friend might point us to an interesting item that does not match our typical preferences. In this work, we aim to bridge the gap between preference- and social-based recommendations. We develop social Poisson factorization (SPF), a probabilistic model that incorporates social network information into a traditional factorization method; SPF introduces the social aspect to algorithmic recommendation. We develop a scalable algorithm for analyzing data with SPF, and demonstrate that it outperforms competing methods on six real-world datasets; data sources include a social reader and Etsy.",2015-09-16,https://www.semanticscholar.org/paper/f4a5660fc68339b69289fda1dc4c546d9084748c,ACM Conference on Recommender Systems
2172,Defective Neutrophil Function in Patients with Sepsis Is Mostly Restored by ex vivo Ascorbate Incubation,"Background Neutrophil function is essential for effective defence against bacterial infections but is defective in patients with sepsis. Ascorbate or vitamin C, which is low in the plasma of patients with sepsis, is stored inside human neutrophils and is essential for their normal function. Objective This study aimed to determine if ascorbate treatment ex vivo improved neutrophil function in patients with sepsis. Patients and Methods Human blood neutrophils were isolated from 20 patients with sepsis and 20 healthy age-matched controls. Neutrophils were incubated with or without ascorbate (1, 5, 10, 20 and 40 mM) for periods up to 2h. Chemotaxis was evaluated using a chemotactic chamber in response to the chemoattractant, fMLP. Phagocytosis (uptake of pHrodo red stained S. aureus) and apoptosis (annexin-V/propidium iodide staining) were measured by flow cytometry. Neutrophil extracellular trap (NET) formation was detected and quantified using DAPI, anti-myeloperoxidase and anti-neutrophil elastase immuno-fluorescence staining. Quantifluor detected the amount of dsDNA in NET supernatants, while quantitative PCR identified changes in expression of PADI4 gene. Results Chemotactic and phagocytic activities were decreased in patients with sepsis but increased after treatment with the high concentrations of ascorbate. Apoptosis was increased in the sepsis patients but not altered by ascorbate treatment. Spontaneous NET formation was observed in patients with sepsis. A quantity of 1mM ascorbate decreased spontaneous NETosis to that of normal, healthy neutrophils, while high concentrations of ascorbate (>10mM) further promoted NET formation. Conclusion Dysregulated neutrophil function was observed in patients with sepsis which could contribute to disease pathology and outcomes. Exposure to ascorbate could reverse some of these changes in function. These novel discoveries raise the possibility that ascorbate treatment could be used as an adjunctive therapy that could result in improved neutrophil function during sepsis.",2020-06-01,https://www.semanticscholar.org/paper/6dbce917dd546b770fd985e8aec1edf17051020e,Journal of Inflammation Research
1144,Measurement of trilinear gauge boson couplings from at {\boldmath$\sqrt{s}=1.96$} TeV,"We present a direct measurement of trilinear gauge boson couplings at $\gamma WW$ and $ZWW$ vertices in $WW$ and $WZ$ events produced in \pp collisions at \tevE. We consider events with one electron or muon, missing transverse energy, and at least two jets. The data were collected using the D0 detector and correspond to 1.1 \ifb of integrated luminosity. Considering two different relations between the couplings at the $\gamma WW $ and $ZWW$ vertices, we measure these couplings at 68% C.L. to be $\kappa_{\gamma}=1.07^{+0.26}_{-0.29}$, $\lambda =0.00^{+0.06}_{-0.06}$ and $g_{1}^{Z}=1.04^{+0.09}_{-0.09}$ in a scenario respecting $SU(2)_L\otimes U(1)_Y$ gauge symmetry and $\kappa =1.04^{+0.11}_{-0.11} $ and $\lambda =0.00^{+0.06}_{-0.06}$ in an ""equal couplings"" scenario.",2009-07-01,https://www.semanticscholar.org/paper/232c861a291c2dacec650a0da2ab5d72f9d9baa0,
2010,Manufacturing intelligence for class prediction and rule generation to support human capital decisions for high-tech industries,,2011-01-04,https://www.semanticscholar.org/paper/1a811c8297f3cdbccce225bf63448bb051338a37,
3737,Metric Learning for Adversarial Robustness,"Deep networks are well-known to be fragile to adversarial attacks. We conduct an empirical analysis of deep representations under the state-of-the-art attack method called PGD, and find that the attack causes the internal representation to shift closer to the ``false'' class. Motivated by this observation, we propose to regularize the representation space under attack with metric learning to produce more robust classifiers. By carefully sampling examples for metric learning, our learned representation not only increases robustness, but also detects previously unseen adversarial samples. Quantitative experiments show improvement of robustness accuracy by up to 4% and detection efficiency by up to 6% according to Area Under Curve score over prior work. The code of our work is available at https://github.com/columbia/Metric_Learning_Adversarial_Robustness.",2019-09-01,https://www.semanticscholar.org/paper/e1dea4c733ee7c98aaa42972452f545821b5d3b5,Neural Information Processing Systems
1325,Evidence for production of single top quarks and first direct measurement of |Vtb|.,"The D0 Collaboration presents first evidence for the production of single top quarks at the Fermilab Tevatron pp[over ] collider. Using a 0.9 fb(-1) dataset, we apply a multivariate analysis to separate signal from background and measure sigma(pp[over ]-->tb+X,tqb+X)=4.9+/-1.4 pb. The probability to measure a cross section at this value or higher in the absence of a signal is 0.035%, corresponding to a 3.4 standard deviation significance. We use the cross section measurement to directly determine the Cabibbo-Kobayashi-Maskawa matrix element that describes the Wtb coupling and find 0.68<|V(tb)|</=1 at 95% C.L. within the standard model.",2006-12-21,https://www.semanticscholar.org/paper/b9f70a7645c276372882b05e580a780ba7637e3c,Physical Review Letters
2465,Collaboration in Mediated and Augmented Reality (CiMAR) Summary,"Summary form only given. The world is becoming more complex everyday, so problem solving often requires global teams of experts working together. To do this effectively there is a need for collaborative tools, and so a variety of teleconferencing and telepresence technologies have been developed. However, most of them involve some variation of traditional video conferencing, which has limitations, such as not being able to effectively convey spatial cues. This workshop focuses on how Augmented Reality (AR) [1] and Mediated Reality (MR) [2] technology can be used to overcome these limitations and develop radically new types of collaborative experiences. In combination, AR and MR technologies could be used to merge the shared perceived realities of different users, as well as enrich each user's own individual experience in a collaborative task. Several studies have explored the effectiveness of using AR and MR for complex tasks. For example, AR has been shown to improve the effectiveness of individual manual assembly tasks [3], while MR systems have been shown to improve the performance time and mental effort in collaborative design tasks [4]. Recent research on using MR for collaboration among crime scene investigators indicates that using shared visual feedback promotes mutual understanding, leads to consensus, and supports hypothesis testing [5]. There are many examples of collaborative AR applications. The Studierstube system [6] targets face-to-face presentations and allows users to walk around virtual 3D scientific data. WearCom [7] enables users to see remote users as virtual avatars in real space. Höllerer et al. [8] allow indoor AR users to visualize the locations and paths of outdoor AR users, and all users to create shared annotations. Poelman et al. [5] present an AR system that allows remote experts to collaborate with local investigators on a crime scene investigation in order to secure evidence. Datcu et al. [9] present an AR system that supports the distributed situational awareness of cross-organisational teams in the security domain. Gauglitz et al. [10] introduce a tablet-based system that incorporates a touchscreen interface through which a remote user can navigate a physical environment and create world-aligned annotations for supporting remote maintenance. In summary, MR and AR technology is becoming mature enough to support a variety of collaboration scenarios. However, there are still a number of open issues that need further research. One major issue concerns the presence of remote users and how they can interact with the system and each other. Partial answers can be found in the areas of human-computer interaction, social interaction, affective computing, and task domain analysis. This workshop brings together researchers who are developing or interested in creating collaborative systems using AR and MR technologies. Starting with a keynote from Prof. Tetsuro Ogi from Keio University, Japan, workshop participants will discuss open research issues in relation to: Case studies using MR/AR for collaboration; Tools for building collaborative MR/AR systems; Effects of MR/AR on trust, presence, and coordination; Interaction models for collaboration in MR/AR; Tools for collaboration in MR/AR; Collaboration awareness in MR/AR. The goal is to build a picture of current and prior research on collaboration in AR and MR, as well as set up a common research agenda for work going forward. This, in turn, can be used to grow the research community.",2015-09-29,https://www.semanticscholar.org/paper/3ab469a41adb5399a34057bca304197a2214b335,2015 IEEE International Symposium on Mixed and Augmented Reality Workshops
1023,Geometric Motion Planning for a Three-Link Swimmer in a Three-Dimensional low Reynolds-Number Regime,"Purcell's three-link, two-joint planar swimmer is an iconic model of a simple mechanism that can locomote in the low-Reynolds number regime. In this paper, we consider a modification to the design of the planar swimmer by allowing yaw-pitch movements at the two actuated joints as opposed to the conventional yaw-yaw movements. We demonstrate that this design with only two active inputs is capable of swimming in three dimensions unlike the planar swimmer. Using analytical and visual tools from geometric mechanics, we design motion primitives that enable the swimmer to reorient itself and swim along canonical directions in the inertial frame. We also provide experimental results on a hardware testbed to show a comparison between the trajectories derived from simulated gaits and trajectory of the robot executing those gaits.",2018-06-01,https://www.semanticscholar.org/paper/40265ddc4300cd24656d92941e1ce277d0574b9f,American Control Conference
2758,Real-time 4D animation on a 3D graphics workstation,,1989-12-01,https://www.semanticscholar.org/paper/d112d51784f3da2d05bb63702c47fee90355d9d2,
297,Proceedings of the 4th International Workshop on Internet and Network Economics,,2008-12-17,https://www.semanticscholar.org/paper/d625d6bf4199f8b5949ee364f45f7ca0a0da3fab,
1299,Search for $W'$ boson production in the $W' \to t\bar{b}$ decay channel,,,https://www.semanticscholar.org/paper/06bde8db87da306ff8910e89fda0c6f7f2a6c254,
1986,Feature extraction for defect classification and yield enhancement in color filter and micro-lens manufacturing: An empirical study,"Yield improvement is an important issue in semiconductor-manufacturing supply chains, including color filter and micro-lens manufacturing. In the color filter and micro-lens processes, it is critical to quickly identify the defect pattern through the defect pictures and then take corrective actions to avoid greater yield loss. Until now, defect pattern recognition heavily relies on domain experts’ knowledge, which easily causes inconsistent classification results from person to person and unsatisfactory performance. In this study, a framework is proposed to achieve automatic defect detection and classification in color filter and micro-lens manufacturing to enhance the decision quality of pattern recognition. In particular, the proposed framework integrates Canny edge detection and classification and regression tree methodology. To validate the viability of the proposed framework in real settings, an empirical study was conducted in collaboration with a leading complementary metal oxide semiconductor image sensor foundry in Taiwan. The results not only showed the effectiveness of the proposed framework but also demonstrated the practical values.",2013-12-01,https://www.semanticscholar.org/paper/deaeec97b1ef7be8ce8361984e78fd6d305a0ff7,
3431,"Introduction to Algorithms, third edition","If you had to buy just one text on algorithms, Introduction to Algorithms is a magnificent choice. The book begins by considering the mathematical foundations of the analysis of algorithms and maintains this mathematical rigor throughout the work. The tools developed in these opening sections are then applied to sorting, data structures, graphs, and a variety of selected algorithms including computational geometry, string algorithms, parallel models of computation, fast Fourier transforms (FFTs), and more. This book's strength lies in its encyclopedic range, clear exposition, and powerful analysis. Pseudo-code explanation of the algorithms coupled with proof of their accuracy makes this book is a great resource on the basic tools used to analyze the performance of algorithms.",2009-07-31,https://www.semanticscholar.org/paper/611c2c20f6566946694d832e58bfd7b7cb58b66e,
146,Automating the 3 D Modeling Pipeline,"We describe advances in automating the 3D modeling pipeline to create rich 3D textured models. Our work is aimed at large scale site modeling, where much manual effort is often needed to create complete models. We present i) an automatic 2D-3D registration method for texture using cast shadows as a cue to refine the registration parameters, ii) methods for change detection in an acquired model, and iii) a new mobile robot that can be used to automatically acquire data for modeling.",,https://www.semanticscholar.org/paper/214fde2424eafd634d5846d32f8c26bdedae2d40,
468,On the Random Walk Method for Protocol Testing,,1994-06-21,https://www.semanticscholar.org/paper/73bd5c59a5955e5b464a5c54706332953fdfec19,International Conference on Computer Aided Verification
2156,An Experimental Evaluation of a Monte-Carlo Algorithm for Singular Value Decomposition,,2001-11-08,https://www.semanticscholar.org/paper/6700cbf389ae198190e672a3e5995b32f7a6d7c9,Panhellenic Conference on Informatics
2630,Data Integration and Access - The Digital Government Research Center's Energy Data Collection (EDC) Project,,,https://www.semanticscholar.org/paper/3d6c0991420130c94efecace92e99233ad0e8683,Advances in Digital Government
333,... The Interaction Between Algorithms and Game Theory,,2005-05-10,https://www.semanticscholar.org/paper/78fcc69adea888eea0e82626d83ce37d60c671e6,Workshop on Engineering Applications
1135,Search for CP violation in $B_s^0 \to \mu^+ D_s^- X$ decays in $p\bar{p}$ collisions at $\sqrt{s}=1.96$ TeV,"We have performed a search for CP violation in a sample of Bs0→μ+Ds-X decays corresponding to 5 fb-1 of proton-antiproton collisions collected by the D0 detector in Run II at the Fermilab Tevatron Collider. New physics in Bs0 mixing could contribute a significant CP violating weak phase, which would be observed as a difference in the decay-time distribution for Bs0→B s0 oscillated states versus that for B s0→Bs0. A fit to the decay-time distributions of the Bs0/B s0 candidates yields the flavor-specific asymmetry afss=[-1.7±9.1(stat)-1.5+1.4(syst)]×10-3, which excludes CP violation due to new physics within the experimental sensitivity.",2010-07-26,https://www.semanticscholar.org/paper/ec828c953ffe93f4ef23d49a845463f7a6fd4d22,
630,The Concurrency Control Mechanism of SDD-1: A System for Distributed Databases (The Fully Redundant Case),"SDD-1, A System for Distributed Databases, is a distributed database system being developed by Computer Corporation of America (CCA), Cambridge, MA. SDD-1 permits data to be stored redundantly at several database sites in order to enhance the reliability and responsiveness of the system and to facilitate upward scaling of system capacity. This paper describes the method used by SDD-1 for updating data that are stored redundantly.",1978-05-01,https://www.semanticscholar.org/paper/12317714a66256b993558c72dc4ab685a9432638,IEEE Transactions on Software Engineering
2461,Patient Experiences Using an Inpatient Personal Health Record,"Summary Objective To investigate patients’ experience using an inpatient personal health record (PHR) on a tablet computer to increase engagement in their hospital care. Methods We performed observations and conducted semi-structured interviews with 14 post-operative cardiac surgical patients and their family members who received an inpatient PHR. Themes were identified using an inductive coding scheme. Results All participants responded favorably to having access to view their clinical information. A majority (85.7%) of participants used the application following an initial training session. Patients reported high satisfaction with being able to view their hospital medications and access educational materials related to their medical conditions. Patients reported a desire to view daily progress reports about their hospital stay and have access to educational information about their postacute recovery. In addition, patients expressed a common desire to view their diagnoses, laboratory test results, radiology reports, and procedure notes in language that is patient-friendly. Conclusion Patients have unmet information needs in the hospital setting. Our findings suggest that for some inpatients and their family members, providing personalized health information through a tablet computer may improve satisfaction, decrease anxiety, increase understanding of their health conditions, and improve safety and quality of care.",2016-04-01,https://www.semanticscholar.org/paper/beed87bdd7f68523c3d57623267d25bd34da3bb4,Applied Clinical Informatics
2115,Optimization of Wafer Exposure Patterns Using a Two‐Dimensional Cutting Algorithm,"The semiconductor industry plays an integral role in Taiwan's manufacturing sector. Although defect reduction has received considerable attention to improve the yield rate, the problem of optimizing wafer exposure patterns has seldom been addressed. This study formulates the wafer exposure-patterning problem into a cutting and packing problem by adopting an innovative approach. We developed a two-dimensional cutting algorithm to maximize the number of dies that can be produced from a wafer to increase the gross die yield. The proposed algorithm is successfully implemented in a wafer fabrication factory. Experimental results validate the effectiveness of the proposed algorithm.",2001-09-01,https://www.semanticscholar.org/paper/046632db9b44c1ce85af79953a33c6c006cfe2c6,
3033,Synapse: a microservices architecture for heterogeneous-database web applications,"The growing demand for data-driven features in today's Web applications -- such as targeting, recommendations, or predictions -- has transformed those applications into complex conglomerates of services operating on each others' data without a coherent, manageable architecture. We present Synapse, an easy-to-use, strong-semantic system for large-scale, data-driven Web service integration. Synapse lets independent services cleanly share data with each other in an isolated and scalable way. The services run on top of their own databases, whose layouts and engines can be completely different, and incorporate read-only views of each others' shared data. Synapse synchronizes these views in real-time using a new scalable, consistent replication mechanism that leverages the high-level data models in popular MVC-based Web applications to replicate data across heterogeneous databases. We have developed Synapse on top of the popular Web framework Ruby-on-Rails. It supports data replication among a wide variety of SQL and NoSQL databases, including MySQL, Oracle, PostgreSQL, MongoDB, Cassandra, Neo4j, and Elasticsearch. We and others have built over a dozen microservices using Synapse with great ease, some of which are running in production with over 450,000 users.",2015-04-17,https://www.semanticscholar.org/paper/3438469a51e02a22ed7f92335ce5a04e7b2fdb66,European Conference on Computer Systems
3427,"Introduction to Algorithms, 3rd Edition",,,https://www.semanticscholar.org/paper/31181e73befea410e25de462eccd0e74ba8fea0b,
3511,Short Superstrings and the Structure of Overlapping Strings,"Given a collection of strings S = [s1,...,sn] over an alphabet sigma, a superstring alpha of S is a string containing each si as a substring, that is, for each i, 1 < or = i < or = n, alpha contains a block of magnitude of si consecutive characters that match si exactly. The shortest superstring problem is the problem of finding a superstring alpha of minimum length. The shortest superstring problem has applications in both computational biology and data compression. The shortest superstring problem is NP-hard (Gallant et al., 1980); in fact, it was recently shown to be MAX SNP-hard (Blum et al., 1994). Given the importance of the applications, several heuristics and approximation algorithms have been proposed. Constant factor approximation algorithms have been given in Blum et al. (1994) (factor of 3), Teng and Yao (1993) (factor of 2 8/9), Czumaj et al. (1994) (factor of 2 5/6), and Kosaraju et al. (1994) (factor of 2 50/63). Informally, the key to any algorithm for the shortest superstring problem is to identify sets of strings with large amounts of similarity, or overlap. Although the previous algorithms and their analyses have grown increasingly sophisticated, they reveal remarkably little about the structure of strings with large amounts of overlap. In this sense, they are solving a more general problem than the one at hand. In this paper, we study the structure of strings with large amounts of overlap and use our understanding to give an algorithm that finds a superstring whose length is no more than 2 3/4 times that of the optimal superstring. Our algorithm runs in O(magnitude of S + n3) time, which matches that of previous algorithms. We prove several interesting properties about short periodic strings, allowing us to answer questions of the following form: Given a string with some periodic structure, characterize all the possible periodic strings that can have a large amount of overlap with the first string.",,https://www.semanticscholar.org/paper/d72513c2783daa0d289ed04c4bec9e877df0678b,J. Comput. Biol.
1825,Nonparametric Bayes Pachinko Allocation,"Recent advances in topic models have explored complicated structured distributions to represent topic correlation. For example, the pachinko allocation model (PAM) captures arbitrary, nested, and possibly sparse correlations between topics using a directed acyclic graph (DAG). While PAM provides more flexibility and greater expressive power than previous models like latent Dirichlet allocation (LDA), it is also more difficult to determine the appropriate topic structure for a specific dataset. In this paper, we propose a nonparametric Bayesian prior for PAM based on a variant of the hierarchical Dirichlet process (HDP). Although the HDP can capture topic correlations defined by nested data structure, it does not automatically discover such correlations from unstructured data. By assuming an HDP-based prior for PAM, we are able to learn both the number of topics and how the topics are correlated. We evaluate our model on synthetic and real-world text datasets, and show that nonparametric PAM achieves performance matching the best of PAM without manually tuning the number of topics.",2007-07-19,https://www.semanticscholar.org/paper/87ce59b72873d2b77ab29611a8b448dd571f40ed,Conference on Uncertainty in Artificial Intelligence
793,Multiobjective query optimization,"The optimization of queries in distributed database systems is known to be subject to delicate trade-offs. For example, the Mariposa database system allows users to specify a desired delay-cost tradeoff (that is, to supply a decreasing function u(d), specifying how much the user is willing to pay in order to receive the query results within time d); Mariposa divides a query graph into horizontal “strides,” analyzes each stride, and uses a greedy heuristic to find the “best” plan for all strides. We show that Mariposa's greedy heuristic can be arbitrarily far from the desired optimum. Applying a recent approach in multiobjective optimization algorithms to this problem, we show that the optimum cost-delay trade-off (Pareto) curve in Mariposa's framework can be approximated fast within any desired accuracy. We also present a polynomial algorithm for the general multiobjective query optimization problem, which approximates arbirarily well the optimum cost-delay tradeoff (without the restriction of Mariposa's heuristic stride subdivision).",2001-05-01,https://www.semanticscholar.org/paper/e11dbdb31f93e968f401f9f0786a738153aee5d4,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
1748,Visualizing Topic Models,"
 
 Managing large collections of documents is an important problem for many areas of science, industry, and culture. Probabilistic topic modeling offers a promising solution. Topic modeling is an unsupervised machine learning method that learns the underlying themes in a large collection of otherwise unorganized documents. This discovered structure summarizes and organizes the documents. However, topic models are high-level statistical tools—a user must scrutinize numerical distributions to understand and explore their results. In this paper, we present a method for visualizing topic models. Our method creates a navigator of the documents, allowing users to explore the hidden structure that a topic model discovers. These browsing interfaces reveal meaningful patterns in a collection, helping end-users explore and understand its contents in new ways. We provide open source software of our method.
 
",2012-05-20,https://www.semanticscholar.org/paper/59d7d8415dacd300eb4d98b0da3cb32d27503b36,International Conference on Web and Social Media
1014,Electrophysiological effects of phencyclidine and the sigma agonist ditolylguanidine in the cerebellum of the rat,,1992-01-31,https://www.semanticscholar.org/paper/4c8e4c401da08b25129888d3992897f744ee5ee5,Neuropharmacology
1812,Easy As CBA: A Simple Probabilistic Model for Tagging Music,"Many songs in large music databases are not labeled with semantic tags that could help users sort out the songs they want to listen to from those they do not. If the words that apply to a song can be predicted from audio, then those predictions can be used both to automatically annotate a song with tags, allowing users to get a sense of what qualities characterize a song at a glance. Automatic tag prediction can also drive retrieval by allowing users to search for the songs most strongly characterized by a particular word. We present a probabilistic model that learns to predict the probability that a word applies to a song from audio. Our model is simple to implement, fast to train, predicts tags for new songs quickly, and achieves state-of-the-art performance on annotation and retrieval tasks.",,https://www.semanticscholar.org/paper/c34898a44917a0f6f1018c5db6e534deec58aea5,International Society for Music Information Retrieval Conference
2703,Computer Graphics SRGP/SPHIGS for Macintosh,,1995-06-01,https://www.semanticscholar.org/paper/cc8b38679a0f0210041aa5b0de884f376f97769d,
3434,Adding Trust to P2P Distribution of Paid Content,,2009-09-04,https://www.semanticscholar.org/paper/d5116f7cc5ec69502d02459ccf83ba6427067c1c,Information Security Conference
339,Games Other People Play,,2005-08-23,https://www.semanticscholar.org/paper/e0a4360d0882507a7e2b95b9131813141a9be12c,International Conference on Concurrency Theory
3513,Scheduling in a Ring with Unit Capacity Links,We consider the problem of scheduling unit-sized jobs on a ring of processors with the objective of minimizing the completion time of the last job. Unlike much previous work we place restrictions on the capacity of the network links connecting processors. We give a polynomial time centralized algorithm that produces optimal length schedules. We also give a simple distributed 2-approximation algorithm.,,https://www.semanticscholar.org/paper/899ec811df218ce4987824d091113e15c7af90d8,
148,TopBot: automated network topology detection with a mobile robot,"We have demonstrated that a properly-equipped mobile robot can easily construct a detailed map of the wireless coverage of an urban environment. The Autonomous Vehicle for Exploration and Navigation of Urban Environments (AVENUE) mobile robot was successfully used to generate such maps in both manual and autonomous modes of operation. The resulting database contained a wealth of information for many different positions in the region, with a list of all access points viewable from each location together with a quality measure (the signal-to-noise ratio) of every detected signal. At a later time, the AVENUE system effectively used the data in this map to determine the approximate position of the robot as it traveled through the urban area.",2003-11-10,https://www.semanticscholar.org/paper/dfe0bac75cd0ca1c5c3d04c91f4e006cc9eca41f,IEEE International Conference on Robotics and Automation
1122,Measurement of the tt cross section using high-multiplicity jet events,"We present a measurement of the ttbar cross section using high-multiplicity jet events produced in ppbar collisions at sqrt{s}=1.96 TeV. These data were recorded at the Fermilab Tevatron collider with the D0 detector. Events with at least six jets, two of them identified as b jets, were selected from a 1 fb-1 data set. The measured cross section, assuming a top quark mass of 175 GeV/c^2, is 6.9 \pm 2.0 pb, in agreement with theoretical expectations.",2010-08-20,https://www.semanticscholar.org/paper/1de00090be53d6eea568acd9e16bd6d3a5195e06,
2745,Integration of Knowledge Bases into an Environment of Portable Electronic Notebooks,,,https://www.semanticscholar.org/paper/2aa5793c91df4dc417c255f3cc0512ed4a9aab28,
3185,Structural change in agriculture and farmers' social contacts: Insights from a Swiss mountain region,,2022-06-01,https://www.semanticscholar.org/paper/eba03ab1a7cd63e07aecc361e6fd1b82abb31ae4,Agricultural Systems
2246,icrobial Mannan Inhibits Bacterial Killing by Macrophages : A Possible athogenic Mechanism for Crohn ’ s Disease,"A LI M EN TA R Y TR A C T ackground & Aims: Crohn’s disease (CD) is mimcked by inherited phagocyte disorders and is associated ith circulating antibodies against yeast mannan (antiaccharomyces cerevisiae antibody; ASCA). We specuated that mannans might impair phagocyte funcion. Methods: S cerevisiae mannan was assessed for its ffects on human peripheral blood neutrophils, adhernt monocytes, and monocyte-derived macrophages MDM). Results: Mannan caused dose-related inreased survival of CD Escherichia coli HM605 within dherent monocytes from 24% 10.5% (control) to 14% 22.7% with mannan 1 mg/mL at 2 hours (mean SEM, n 9; P .0002). Electron microscopy showed coli HM605 surviving and probably replicating within acrophage vesicles. Mannan (1 mg/mL) inhibited the espiratory burst in neutrophils and monocytes (both .002) and bacterial killing within MDM (P < .001). coli survival was increased within macrophages from LR4 / (126% 3.5% survival at 2 hours) and yD88 / (134.8% 6.5%) mice compared with wildype mice (both P < .0001). Mannan had no additional ffect, showing that TLR4 and MyD88 are involved in acterial killing by macrophages and its inhibition by annan. Putative CD-associated micro-organisms were creened for the ASCA mannan epitope by Galanthus nivalis ectin (GNA) blotting. ASCA epitope was expressed by andida albicans and Mycobacterium paratuberculosis but ot by Mycobacterium tuberculosis or E coli. Supernatants rom M paratuberculosis culture inhibited killing of E coli M605 by adherent human monocytes and murine acrophages. The inhibitory activity was removed by NA-affinity chromatography. Conclusions: Suppresion of mucosal phagocyte function by microbial manans, possibly of Mycobacterial origin, may contribute o CD pathogenesis.",,https://www.semanticscholar.org/paper/3188d7fb33a4fa0d3b22da5e6b0c6d1bb908511a,
993,"Cross-Modal and Intra-Modal Characteristics of Visual Function and Speech Perception Performance in Postlingually Deafened, Cochlear Implant Users","Evidence of visual-auditory cross-modal plasticity in deaf individuals has been widely reported. Superior visual abilities of deaf individuals have been shown to result in enhanced reactivity to visual events and/or enhanced peripheral spatial attention. The goal of this study was to investigate the association between visual-auditory cross-modal plasticity and speech perception in post-lingually deafened, adult cochlear implant (CI) users. Post-lingually deafened adults with CIs (N = 14) and a group of normal hearing, adult controls (N = 12) participated in this study. The CI participants were divided into a good performer group (good CI, N = 7) and a poor performer group (poor CI, N = 7) based on word recognition scores. Visual evoked potentials (VEP) were recorded from the temporal and occipital cortex to assess reactivity. Visual field (VF) testing was used to assess spatial attention and Goldmann perimetry measures were analyzed to identify differences across groups in the VF. The association of the amplitude of the P1 VEP response over the right temporal or occipital cortex among three groups (control, good CI, poor CI) was analyzed. In addition, the association between VF by different stimuli and word perception score was evaluated. The P1 VEP amplitude recorded from the right temporal cortex was larger in the group of poorly performing CI users than the group of good performers. The P1 amplitude recorded from electrodes near the occipital cortex was smaller for the poor performing group. P1 VEP amplitude in right temporal lobe was negatively correlated with speech perception outcomes for the CI participants (r = -0.736, P = 0.003). However, P1 VEP amplitude measures recorded from near the occipital cortex had a positive correlation with speech perception outcome in the CI participants (r = 0.775, P = 0.001). In VF analysis, CI users showed narrowed central VF (VF to low intensity stimuli). However, their far peripheral VF (VF to high intensity stimuli) was not different from the controls. In addition, the extent of their central VF was positively correlated with speech perception outcome (r = 0.669, P = 0.009). Persistent visual activation in right temporal cortex even after CI causes negative effect on outcome in post-lingual deaf adults. We interpret these results to suggest that insufficient intra-modal (visual) compensation by the occipital cortex may cause negative effects on outcome. Based on our results, it appears that a narrowed central VF could help identify CI users with poor outcomes with their device.",2016-02-05,https://www.semanticscholar.org/paper/8db654c7045b06ad97b6763f3a308bcaf58adaa4,PLoS ONE
1815,Syntactic Topic Models,"We develop the syntactic topic model (STM), a nonparametric Bayesian model of parsed documents. The STM generates words that are both thematically and syntactically constrained, which combines the semantic insights of topic models with the syntactic information available from parse trees. Each word of a sentence is generated by a distribution that combines document-specific topic weights and parse-tree-specific syntactic transitions. Words are assumed to be generated in an order that respects the parse tree. We derive an approximate posterior inference method based on variational methods for hierarchical Dirichlet processes, and we report qualitative and quantitative results on both synthetic data and hand-parsed documents.",2008-12-08,https://www.semanticscholar.org/paper/457628a1c232bb48acc2db8440571e289cc80e15,Neural Information Processing Systems
70,Statistics on query expressions in relational database management systems,"The query optimizer is the component in a relational database system that identifies efficient execution plans for input queries. Modern optimizers generally explore many alternative query plans in a cost-based manner. Specifically, the resource consumption and associated cost of each candidate plan is estimated, and the plan with the least expected cost is chosen for execution. The cost estimation for a plan depends on several factors, including resource availability during execution, the specific operators that compose the plan, and the size of intermediate results that would be generated during the plan execution. Among these factors, the intermediate-result size (or cardinality) estimation is the main source of inaccuracies during optimization: cardinality estimation typically relies on several simplifying assumptions that often do not hold in practice. Optimizers then sometimes base their decisions on inaccurate information and produce low-quality execution plans. To address this limitation, in this thesis we introduce the concept of SITS, which are statistics built on query expressions. SITS directly and accurately model intermediate results in a query execution plan, and therefore avoid error-prone simplifying assumptions during cardinality estimation. If optimizers have appropriate SITS available during optimization, the resulting query plans can be dramatically better than otherwise. Although SITs are a fairly simple concept, challenging problems need to be addressed before SITs can be seamlessly integrated into modern relational database systems. In this thesis we study three important challenges associated with SITS. First, we show how to modify query optimizers to exploit the additional statistical information provided by SITs without significantly increasing optimization time. Second, we study a spectrum of alternatives to create SITs, which balance efficiency of construction and accuracy of the resulting estimators. Third, we present techniques to recommend a small but highly beneficial set of SITs to materialize in a database system for a given query workload. In summary, we address the main obstacles for enabling SITs for optimization, namely which SITs to build, how to build them, and how to exploit them during optimization. Overall, SITs constitute a well-founded approach for dealing with complex data correlations, and positively impact the efficiency of relational database systems.",,https://www.semanticscholar.org/paper/9cc3da2719436dfae9f76ae494aa0af0de4b16a7,
3376,Modeling fisheries as multiscalar human-natural systems,"<p>Marine fisheries are social-ecological systems important for human health and livelihoods. However, research approaches that consider human&#8211;nature interactions within as well as between adjacent and distant fisheries are scarce. As such, we measured and modeled marine fisheries catches at local and regional scales over 65 years (1950&#8211;2014), assessed cross-scalar interactions among fishing types (artisanal, subsistence, industrial, recreational), and predicted future catches using the metacoupling framework, a new approach for evaluating human-nature interactions within and across adjacent and distant fisheries (metacouplings). Across taxa examined (mahi-mahi [<em>Coryphaena hippurus</em>], Atlantic bluefin tuna [<em>Thunnus thynnus</em>], cods [Gadidae]), 75% of catches (8.5 million metric tons [MMT]) were made by nations in their own exclusive economic zones (EEZs; Type 1 fishing). However, catches in adjacent EEZs (Type 2 fishing, 1.0 MMT) and distant EEZs and the high seas (Type 3 fishing, 1.9 MMT) increased substantially for all taxa at certain times, becoming consistently important for tuna and cods after 1980. Moreover, Types 1&#8211;3 fishing interacted in ways that affect humans differentially across fisheries. For instance, tuna artisanal and subsistence catches (Type 1) decreased with increasing Type 2 and Type 3 industrial fishing, respectively. Cod subsistence catches declined with increasing Type 2/3 industrial fishing and Type 1 artisanal fishing, whereas fishing-type interactions were largely positive for mahi-mahi, causing catches to increase across sectors. Overall, metacouplings affect humans in positive and negative ways that vary across scales and fisheries systems, galvanizing the need for metacoupling-informed fisheries research, policy, and management programs. We&#8217;ve since extended this research approach to include Atlantic herring (<em>Clupea harengus</em>), the subject of a journal article in press.</p>",,https://www.semanticscholar.org/paper/ea144cca040c16cf32acc0a8fadd0db331449f6a,
2884,"Evidence for IgG autoantibodies to galectin-3, a β-galactoside-binding lectin (Mac-2, ε binding protein, or carbohydrate binding protein 35) in human serum",,1995-11-01,https://www.semanticscholar.org/paper/a0521d22c49890c210b6224f67837ee9b7310ba1,Journal of Clinical Immunology
491,On Inefficient Proofs of Existence and Complexity Classes,,,https://www.semanticscholar.org/paper/5e4f0078da6de0d972ad5f8558900042bf2cfe6e,
2845,Galectin-3 protects keratinocytes from UVB-induced apoptosis by enhancing AKT activation and suppressing ERK activation.,,2008-10-01,https://www.semanticscholar.org/paper/fde83c08779971b1b2abe8ceb25a6811d9303c95,Journal of Investigative Dermatology
1526,A Bayesian model of dose-response for cancer drug studies,"Exploratory cancer drug studies test multiple tumor cell lines against multiple candidate drugs. The goal in each paired (cell line, drug) experiment is to map out the dose-response curve of the cell line as the dose level of the drug increases. We propose Bayesian tensor ﬁltering (BTF), a hierarchical Bayesian model for dose-response modeling in multisample, mul-titreatment cancer drug studies. BTF uses low-dimensional embeddings to share statistical strength between similar drugs and similar cell lines. Structured shrinkage priors in BTF encourage smoothness in the dose-response curves while remaining adaptive to sharp jumps when the data call for it. We focus on a pair of cancer drug studies exhibiting a particular pathol-ogy in their experimental design, leading us to a nonconjugate monotone mixture-of-gammas likelihood. To perform posterior inference, we develop a variant of the elliptical slice sampling algorithm for sampling from linearly-constrained multivariate normal priors with nonconjugate likelihoods. In benchmarks, BTF outperforms state-of-the-art methods for covariance regression and dynamic Poisson matrix factorization. On the two cancer drug studies, BTF outperforms the current standard approach in biology and reveals potential new biomarkers of drug sensitivity in cancer. Code is available at https://github.com/tansey/functionalmf. a Bayesian trend ﬁltering prior (Faulkner and Minin on top of a linear dynamical system with Pólya-gamma augmentation and Windle for binomial observations. and develop Poisson-gamma dynamical systems (PGDS), a dynamic matrix factorization model speciﬁcally for Poisson-distributed observations; we compare BTF with a tensor extension of PGDS in Section 6.",2022-06-01,https://www.semanticscholar.org/paper/79d4464f1b0244e0527f10c290767152067ea5ca,Annals of Applied Statistics
2731,Automated design of virtual worlds for visualizing multivariate relations,"Interactive visualization systems provide a powerful means to explore complex data, especially when coupled with 3-D interaction and display devices to produce virtual worlds. While designing a quality static 2-D visualization is already a difficult task for most users, designing an interactive 3-D one is even more challenging. To address this problem, AutoVisual, a research system that designs interactive virtual worlds for visualizing and exploring multivariate relations of arbitrary arity, is being developed. AutoVisual uses worlds within worlds, an interactive visualization technique that exploits nested, heterogeneous coordinate systems to map multiple variables onto each spatial dimension. AutoVisual's designs are guided by user-specified visualization tasks, and by a catalog of design principles encoded using a rule-based language.<<ETX>>",1992-10-19,https://www.semanticscholar.org/paper/dcca8078ce4aafa9588b98c84a34214a7a3d0ee2,Proceedings Visualization '92
912,A Theory of Safe Locking Policies in Database Systems,"When several transacuons access (read and update) the same database concurrently, there must be some kind of coordmauon to ensure that all transacuons receive a consistent view of the data Such coordination is usually achieved by locking the transactions according to some locking policy A locking policy that guarantees the preservation of consistency of the database is called safe Necessary and sufficient conditions are found for a locking pohcy to be safe, but it is shown that in general it is NPcomplete to test for these conditions. However, when the database has a given structure, a simple set of rules which is sufficient for safety and, moreover, necessary for a wide class of natural locking pohcles is developed Categories and SubJect Descriptors DA I [Operating Systems] Process Management--concurrency, H 2 2 [Database Management] Physical Design--deadlock avoMance General Terms. Theory AddlUonal",1982-07-01,https://www.semanticscholar.org/paper/42ee83fad69c823fb7d462014fe00b4a7e10ed6d,JACM
2645,"PERSIVAL, a system for personalized search and summarization over multimedia healthcare information","In healthcare settings, patients need access to online information tha t can help them understand their medical situation. Physicians need information that is clinically relevant to an individual patient. In this paper, we present our progress on developing a system, PERSIVAL, that is designed to provide personalized access to a distributed patient care digital library. Using the secure, online patient records at New York Presbyterian Hospital as a user model, PERSIVAL's components tailor search, presentation and summarization of online multimedia information to both patients and healthcare providers.",,https://www.semanticscholar.org/paper/6ceda089cbc5ad2a31264b75b2c84edbaaa58950,ACM/IEEE Joint Conference on Digital Libraries
3032,Flux: multi-surface computing in Android,"With the continued proliferation of mobile devices, apps will increasingly become multi-surface, running seamlessly across multiple user devices (e.g., phone, tablet, etc.). Yet general systems support for multi-surface app is limited to (1) screencasting, which relies on a single master device's computing power and battery life or (2) cloud backing, which is unsuitable in the face of disconnected operation or untrusted cloud providers. We present an alternative approach: Flux, an Android-based system that enables any app to become multi-surface through app migration. Flux overcomes device heterogeneity and residual dependencies through two key mechanisms. Selective Record/Adaptive Replay records just those device-agnostic app calls that lead to the generation of app-specific device-dependent state in system services and replays them on the target. Checkpoint/Restore in Android (CRIA) transitions an app into a state in which device-specific information can be safely discarded before checkpointing and restoring the app. Our implementation of Flux can migrate many popular, unmodified Android apps---including those with extensive device interactions like 3D accelerated graphics---across heterogeneous devices and is fast enough for interactive use.",2015-04-17,https://www.semanticscholar.org/paper/2dbd0bca3fb1a57f441f1867ac0fa7dfc245ae66,European Conference on Computer Systems
3733,Oops! Predicting Unintentional Action in Video,"From just a short glance at a video, we can often tell whether a person's action is intentional or not. Can we train a model to recognize this? We introduce a dataset of in-the-wild videos of unintentional action, as well as a suite of tasks for recognizing, localizing, and anticipating its onset. We train a supervised neural network as a baseline and analyze its performance compared to human consistency on the tasks. We also investigate self-supervised representations that leverage natural signals in our dataset, and show the effectiveness of an approach that uses the intrinsic speed of video to perform competitively with highly-supervised pretraining. However, a significant gap between machine and human performance remains.",2019-11-25,https://www.semanticscholar.org/paper/2324d55ec54b9a12c4ac5353c51bcfa8440f7b6a,Computer Vision and Pattern Recognition
467,On the Complexity of the Parity Argument and Other Inefficient Proofs of Existence,,1994-06-01,https://www.semanticscholar.org/paper/72acce082bdf547d4a2687a30a62e17ae76e475e,Journal of computer and system sciences (Print)
2990,Statistical tools for ultra-deep pyrosequecing of fast evolving viruses,"We aim to detect minor variant Hepatitis B viruses (HBV) in 38 pyrosequencing samples from infected individuals. Errors involved in the amplification and ultra deep pyrosequencing (UDPS) of these samples are characterised using HBV plasmid controls. Homopolymeric regions and quality scores are found to be significant covariates in determining insertion and deletion (indel) error rates, but not mismatch rates which depend on the nucleotide transition matrix. This knowledge is used to derive two methods for classifying genuine mutations: a hypothesis testing framework and a mixture model. Using an approximate “ground truth” from a limiting dilution Sanger sequencing run, these methods are shown to outperform the naive percentage threshold approach. The possibility of early stage PCR errors becoming significant is investigated by simulation, which underlines the importance of the initial copy number.",,https://www.semanticscholar.org/paper/3acc3b723fd4cab5914d304dca43b45c96b67465,
2891,Using epigenomics to understand cellular responses to environmental influences in diseases,"It is a generally accepted model that environmental influences can exert their effects, at least in part, by changing the molecular regulators of transcription that are described as epigenetic. As there is biochemical evidence that some epigenetic regulators of transcription can maintain their states long term and through cell division, an epigenetic model encompasses the idea of maintenance of the effect of an exposure long after it is no longer present. The evidence supporting this model is mostly from the observation of alterations of molecular regulators of transcription following exposures. With the understanding that the interpretation of these associations is more complex than originally recognised, this model may be oversimplistic; therefore, adopting novel perspectives and experimental approaches when examining how environmental exposures are linked to phenotypes may prove worthwhile. In this review, we have chosen to use the example of nonalcoholic fatty liver disease (NAFLD), a common, complex human disease with strong environmental and genetic influences. We describe how epigenomic approaches combined with emerging functional genetic and single-cell genomic techniques are poised to generate new insights into the pathogenesis of environmentally influenced human disease phenotypes exemplified by NAFLD.",2023-01-01,https://www.semanticscholar.org/paper/27513e9e7c3b7ba2222da2689b39de05fe799f62,PLoS Genetics
790,Model checking of hierarchical state machines,"Model checking is emerging as a practical tool for detecting logical errors in early stages of system design. We investigate the model checking of hierarchical (nested) systems, i.e. finite state machines whose states themselves can be other machines. This nesting ability is common in various software design methodologies and is available in several commercial modeling tools. The straightforward way to analyze a hierarchical machine is to flatten it (thus, incurring an exponential blow up) and apply a model checking tool on the resulting ordinary FSM. We show that this flattening can be avoided. We develop algorithms for verifying linear time requirements whose complexity is polynomial in the size of the hierarchical machine. We address also the verification of branching time requirements and provide efficient algorithms and matching lower bounds.",2001-05-01,https://www.semanticscholar.org/paper/339b38e9e70ed9a0b55cc3c38385fc3c6f606080,SIGSOFT '98/FSE-6
1393,Demonstration of the CDMS II ZIP technology at a shallow underground site,"The most recent CDMS data run (Run 20) was the first run in which multiple ZIP detectors were deployed. Three Si (0.100 kg each) and 3 Ge (0.250 kg each) ZIPs were run with the goals of fully testing such a configuration as well as measuring the γ, β, and n rates simultaneously with Ge and Si detectors. Calibration with γ and n sources established the bulk electron recoil leakage into the neutron band to be less than 0.2%. Low background data taken during the summer of 2000 produced a simultaneous measurement of the muon coincident neutron background with Si and Ge detectors.",2002-03-08,https://www.semanticscholar.org/paper/4889c0426bfa9815d17494e53ace7e08bfb98243,
1937,Big data analytics for modeling WAT parameter variation induced by process tool in semiconductor manufacturing and empirical study,"With the feature size shrinkage in advanced technology nodes, the modeling of process variations has become more critical for troubleshooting and yield enhancement. Misalignment among equipment tools or chambers in process stages is a major source of process variations. Because a process flow contains hundreds of stages during semiconductor fabrication, tool/chamber misalignment may more significantly affect the variation of transistor parameters in a wafer acceptance test. This study proposes a big data analytic framework that simultaneously considers the mean difference between tools and wafer-to-wafer variation and identifies possible root causes for yield enhancement. An empirical study was conducted to demonstrate the effectiveness of proposed approach and obtained promising results.",2016-12-11,https://www.semanticscholar.org/paper/8f14c1a2a713309262d3914faa57370e30aa78da,Online World Conference on Soft Computing in Industrial Applications
308,Congestion games with malicious players,"We study the equilibria of non-atomic congestion games in which there are two types of players: rational players, who seek to minimize their own delay, and malicious players, who seek to maximize the average delay experienced by the rational players. We study the existence of pure and mixed Nash equilibria for these games, and we seek to quantify the impact of the malicious players on the equilibrium. One counter intuitive phenomenon which we demonstrate is the ""windfall of malice"": paradoxically, when a myopically malicious player gains control of a fraction of the flow, a fraction of the players change from rational to malicious, the new equilibrium may be more favorable for the remaining rational players than the previous equilibrium.",2007-06-11,https://www.semanticscholar.org/paper/907f522bd7eb3bae09bcf9bcb508328f4441d6e1,ACM Conference on Economics and Computation
2435,3:54 PM Abstract No. 29 Augmented reality guidance for cerebral angiography,,2018-04-01,https://www.semanticscholar.org/paper/5e45f7df412235c853544626dba07503c40ffcdd,
881,"Proceedings of the Seventh ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, March 21-23, 1988, Austin, Texas, USA",,1988-03-01,https://www.semanticscholar.org/paper/21ea1e67b96ebef895a6b89dd0c76b4619af0aaf,ACM SIGMOD Conference
291,A mixability theory for the role of sex in evolution,"The question of what role sex plays in evolution is still open despite decades of research. It has often been assumed that sex should facilitate the increase in fitness. Hence, the fact that it may break down highly favorable genetic combinations has been seen as a problem. Here, we consider an alternative approach. We define a measure that represents the ability of alleles to perform well across different combinations and, using numerical iterations within a classical population-genetic framework, show that selection in the presence of sex favors this ability in a highly robust manner. We also show that the mechanism responsible for this effect has been out of the purview of previous theory, because it operates during the evolutionary transient, and that the breaking down of favorable genetic combinations is an integral part of it. Implications of these results and more to evolutionary theory are discussed.",2008-12-16,https://www.semanticscholar.org/paper/7be7d4c57d8b7ff865ff53217e30cc82655de9fd,Proceedings of the National Academy of Sciences of the United States of America
3455,An optimal online algorithm for packet scheduling with agreeable deadlines,"An important issue in IP-based QoS networks is the effective management of packets at the router level. Specifically, if the arriving packets cannot all be stored in a buffer, or if the packets have deadlines by which they must be delivered, the router needs to identify the packets that should be dropped. In recent work, Kesselman et al. [6] propose a model, called <i>buffer management with bounded delay</i>, which can be thought of as an online scheduling problem on a single machine: packets arrive at a network switch and are stored in a buffer of size <i>B.</i> Each packet has a positive weight and a deadline, with the weight representing the value of transmitting the packet by its deadline. At each integer time step, exactly one packet can be transmitted, and the objective is to maximize the total weight of the transmitted packets. If <i>B</i> = ∞, this is the online version of the scheduling problem 1| <i>p<inf>j</inf></i> = 1, <i>r<inf>j</inf></i>, <i>d<inf>j</inf></i> |Σ <i>w<inf>j</inf> U<inf>j</inf></i>. (We assume that <i>r<inf>j</inf></i> and <i>d<inf>j</inf></i> are integers.)",2005-01-23,https://www.semanticscholar.org/paper/85a75cd582cb662b275b35908315dff17ecb4ecf,ACM-SIAM Symposium on Discrete Algorithms
2589,A Web-based curriculum development on nontraditional manufacturing with interactive features,"Y. LAWRENCE YAO, GARY J. CHENGy, STEVE FEINER and WENWU ZHANGColumbia University, New York, NY, USAK. P. RAJURKARUniversity of Nebraska, Industrial and Management Systems, Lincoln, NE, USARADOVAN KOVACEVICDepartment of Mechanical Engineering, Southern Methodist University, Dallas, TX, USA.E-mail: cheng1@wsu.edu",,https://www.semanticscholar.org/paper/d35d884ebb87c3dc2415575d290fe47f31f4b48e,
3605,"The Design of C++0x Reinforcing C++'s proven strengths, while moving into the future",,,https://www.semanticscholar.org/paper/eeee39677fcc72a5a37273a40a4a6914a48adda4,
3368,A system for evaluating social welfare programs and allocating contributed resources based on citizen input,,,https://www.semanticscholar.org/paper/a0ebca9e59b1fc544da9b106ee00be3414b55a4a,
2318,Biochemistry and Physiology of the Neutrophil: Neutrophil priming: Regulation of neutrophil function during inflammatory activation,,,https://www.semanticscholar.org/paper/0c9306551add9de5a7a07789667235ef41a3280c,
941,Modeling communications protocols by automata,"Using a pair of finite-state automata to model the transmitter-receiver protocol in a data communications system, we derive lower bounds on the size of automata needed to achieve reliable communication across an error-phone channel. We also show that, at the cost of increasing the size of the automata, a transmission rate close to the theoretical maximum can be achieved.",1979-10-29,https://www.semanticscholar.org/paper/c6df09c5e61c006237ab487584d148ab6fbadde7,20th Annual Symposium on Foundations of Computer Science (sfcs 1979)
329,Approximately dominating representatives,,2005-01-05,https://www.semanticscholar.org/paper/2def02ffe888c52cbfe1a02ab143b856fdcf6033,Theoretical Computer Science
1001,Intraocular pressure reduction with topical medications and progression of normal‐tension glaucoma: a 12‐year mean follow‐up study,Purpose:  To investigate whether the amount of intraocular pressure (IOP) reduction with topical medications is associated with the progression of normal‐tension glaucoma (NTG) and to identify risk factors for NTG progression.,2013-06-01,https://www.semanticscholar.org/paper/9a6cbd6f379a683cf66dfa16e496181b18346210,Acta ophthalmologica
3040,Transparent mutable replay for multicore debugging and patch validation,"We present Dora, a mutable record-replay system which allows a recorded execution of an application to be replayed with a modified version of the application. This feature, not available in previous record-replay systems, enables powerful new functionality. In particular, Dora can help reproduce, diagnose, and fix software bugs by replaying a version of a recorded application that is recompiled with debugging information, reconfigured to produce verbose log output, modified to include additional print statements, or patched to fix a bug.
 Dora uses lightweight operating system mechanisms to record an application execution by capturing nondeterministic events to a log without imposing unnecessary timing and ordering constraints. It replays the log using a modified version of the application even in the presence of added, deleted, or modified operations that do not match events in the log. Dora searches for a replay that minimizes differences between the log and the replayed execution of the modified program. If there are no modifications, Dora provides deterministic replay of the unmodified program.
 We have implemented a Linux prototype which provides transparent mutable replay without recompiling or relinking applications. We show that Dora is useful for reproducing, diagnosing, and fixing software bugs in real-world applications, including Apache and MySQL. Our results show that Dora (1) captures bugs and replays them with applications modified or reconfigured to produce additional debugging output for root cause diagnosis, (2) captures exploits and replays them with patched applications to validate that the patches successfully eliminate vulnerabilities, (3) records production workloads and replays them with patched applications to validate patches with realistic workloads, and (4) maintains low recording overhead on commodity multicore hardware, making it suitable for production systems.",2013-03-16,https://www.semanticscholar.org/paper/33623a9fec52e01e92c6ba1ae4d67b01f0c76fe5,International Conference on Architectural Support for Programming Languages and Operating Systems
2577,Maintaining Visibility Constraints for View Management in 3D User Interfaces,,,https://www.semanticscholar.org/paper/01a52949b2fa840525d75eddd8356b517d3966fc,
3657,The Evolution of C++ 1985 to 1987,,,https://www.semanticscholar.org/paper/197ad3a0ac052dea3423a8186c9af6cf60a5f130,C++ Workshop
645,"Delis Dynamically Evolving, Large-scale Information Systems Approximating the Distortion Approximating the Distortion","Kenyon et al. (STOC 04) compute the distortion between one-dimensional finite point sets when the distortion is small; Papadim-itriou and Safra (SODA 05) show that the problem is NP-hard to approximate within a factor of 3, albeit in 3 dimensions. We solve an open problem in these two papers by demonstrating that, when the distortion is large, it is hard to approximate within large factors, even for 1-dimensional point sets. We also introduce additive distortion, and show that it can be easily approximated within a factor of two.",,https://www.semanticscholar.org/paper/e5a6e8942d29b817005e1f0bd1ab4a672e036d5a,
2685,Negotiation for automated generation of temporal multimedia presentations,"Creating high-quality multimedia presentations requires much skill, time, and effort. This is particularly true when temporal media, such as speech and animation, are involved. We describe the design and implementation of a knowledge-based system that generates customized temporal multimedia presentations. We provide an overview of the system’s architecture, and explain how speech, written text, and graphics are generated and coordinated. Our emphasis is on how temporal media are coordinated by the system through a multi-stage negotiation process. In negotiation, media-specific generation components interact with a novel coordination component that solves temporal constraints provided by the generators. We illustrate our work with a set of examples generated by the system in a testbed application intended to update hospital caregivers on the status of patients who have undergone a cardiac bypass operation.",1997-02-01,https://www.semanticscholar.org/paper/2297f1fef37313a79800b2783315bf8c63263c1b,MULTIMEDIA '96
856,Simple Local Search Problems That are Hard to Solve,"Many algorithms for NP-hard optimization problems find solutions that are locally optimal, in the sense that the solutions cannot be improved by a polynomially computable perturbation. Very little is known about the complexity of finding locally optimal solutions, either by local search algorithms or using other indirect methods. Johnson, Papadimitriou, and Yannakakis [J. Comput. System Sci., 37 (1988), pp. 79–100] studied this question by defining a complexity class PLS that captures local search problems. It was proved that finding a partition of a graph that is locally optimal into equal parts with respect to the acclaimed Kernighan-Lin algorithm is PLS-complete. It is shown here that several natural, simple local search problems are PLS-complete, and thus just as hard. Two examples are: finding a partition that cannot be improved by a single swap of two vertices, and finding a stable configuration for an undirected connectionist network.When edges or other objects are unweighted, then a local optimum ...",1991-02-01,https://www.semanticscholar.org/paper/3be5c11282e645343e780322ec2c2b626ee5a4fe,SIAM journal on computing (Print)
3370,"Starvation, Energy Reserves, and Aggression in the Crayfish Orconectes Virilis (Hagen, 1870) (Decapoda, Cambaridae)",Der Einfluss von Nahrungsentzug auf das aggressive Verhalten des Krebses Orconectes virilis wurde im Labor untersucht. Nach einer Woche Nahrungsentzug kampften die Versuchstiere ofter und langer und gewannen ofter als Kontrolltiere. Nach zwei Wochen Hungern waren diese Unterschiede nicht mehr zu beobachten.,,https://www.semanticscholar.org/paper/7a5362513bb02857549f7a91f280f49230107d3e,
2709,"Virtual reality software & technology:proceedings of the VRST'94 conference 23-26 August 1994, Singapore","Virtual reality software & technology:proceedings of the VRST'94 conference 23-26 August 1994, Singapore , Virtual reality software & technology:proceedings of the VRST'94 conference 23-26 August 1994, Singa... , مرکز فناوری اطلاعات و اطلاع رسانی کشاورزی",,https://www.semanticscholar.org/paper/c5ff8558c28d5daf4f48b4fa42c3faec5279de10,
38,Faceted searching and browsing over large collections of textual and text-annotated objects,"The vast majority of Internet users utilize search functionality to navigate the text and text-annotated collections of a variety of web sites. Users of sites such as The New York Times archive, YouTube, and others often face long lists of results for their queries due to the large size of the collections. Processing numerous items is also a hurdle for ""exploratory"" users who have no specific query in mind, such as a new shopper in an online store or a researcher accessing a news archive. In this thesis, we attempt to address this problem. We investigate faceted searching and browsing to provide users with access methods that are useful for discovering the content and the structure of long search results or large collections. Hierarchies that organize items based on their topics are common for browsing a large set of items. For example, Yahoo! uses a topic-based hierarchy to guide users to their web pages of interest. Google News and Newsblaster enable news readers to quickly navigate the daily news based on a hierarchy of topics and related events. We first present a technique for summarization-aware topic faceted searching and browsing, which integrates clustering and summarization so that users can browse a list of summarized clusters in the query results instead of individual documents. We have built a fully functional summarization-aware search system for daily news. In addition to the topic facet, time can be used as an alternative facet for browsing search results. We explore time as an important dimension and suggest a general framework for time-based language models to incorporate time into the retrieval task. In fact, many facets, other than topic and time, can be useful for faceted searching and browsing. As a result, we propose supervised and unsupervised methods to identify and extract multiple relevant facets from collections. Yet incorporating such facets in searching or browsing is not an easy task. A typical approach to utilize facets in searching and browsing is to build individual hierarchies for each facet. Unfortunately, these hierarchies are currently manually or semi-manually constructed and populated, which prevents deploying such hierarchies for large collections due to the cost of manually annotating each item in the collections. To solve this problem, we propose a system to automate the construction of hierarchies for the extracted facets, and show its effectiveness through appropriate user studies. We apply the faceted hierarchies to a range of large data sets, including collections of annotated images, television programming schedules, and web pages.",,https://www.semanticscholar.org/paper/87ecb3fd0071f0c58904cab78c8b18a7c821f7af,
814,Primal-dual approximation algorithms for integral flow and multicut in trees,,1997-05-01,https://www.semanticscholar.org/paper/9ec089c12e76a55a2c00cb63b394b05fc070c1f0,Algorithmica
1665,Variational Inference via \chi Upper Bound Minimization,"Variational inference (VI) is widely used as an efficient alternative to Markov chain Monte Carlo. It posits a family of approximating distributions $q$ and finds the closest member to the exact posterior $p$. Closeness is usually measured via a divergence $D(q || p)$ from $q$ to $p$. While successful, this approach also has problems. Notably, it typically leads to underestimation of the posterior variance. In this paper we propose CHIVI, a black-box variational inference algorithm that minimizes $D_{\chi}(p || q)$, the $\chi$-divergence from $p$ to $q$. CHIVI minimizes an upper bound of the model evidence, which we term the $\chi$ upper bound (CUBO). Minimizing the CUBO leads to improved posterior uncertainty, and it can also be used with the classical VI lower bound (ELBO) to provide a sandwich estimate of the model evidence. We study CHIVI on three models: probit regression, Gaussian process classification, and a Cox process model of basketball plays. When compared to expectation propagation and classical VI, CHIVI produces better error rates and more accurate estimates of posterior variance.",2016-11-01,https://www.semanticscholar.org/paper/d56117c84a559670f5c4e6e2993a2f117dc34be9,Neural Information Processing Systems
2284,Fcgamma receptors in autoimmune diseases.,"Fcgamma-receptors (Fcgamma-R) recognise the Fc portion of IgG and thus form a link between humoral and cellular immunity. These receptors are expressed by a variety of immune cells, and they function in the binding of immune complexes or IgG-opsonised particles, such as microbial pathogens. The are three major types of Fcgamma-R, namely Fcgamma-RI (CD64), Fcgamma-RII (CD32) and Fcgamma-RIII (CD16), and these differ in their ability to bind IgG and complexes. There are many isoforms of these receptors and a number of recently identified polymorphisms in their structure. This review describes the structure and function of these Fcgamma-Rs, and highlights how gene deficiencies and polymorphisms may contribute to the pathology of human diseases.",,https://www.semanticscholar.org/paper/5507a98d6d12cd96bf5b3bb78d42691f852e4ab4,European Journal of Clinical Investigation
3568,Source Code Rejuvenation Is Not Refactoring,,2009-12-08,https://www.semanticscholar.org/paper/18968c4b1879ff1a84fcb64b0619264c00fb2f75,Conference on Current Trends in Theory and Practice of Informatics
2016,Semiconductor manufacturing intelligence and key factor control mechanism for managing production cycle time,"▓ Semiconductor wafer fabrication plays a central role in electronics supply chain. Two characteristics of electronic products contribute to making the demand volatile: high variety and short life cycle. Semiconductor wafer manufacturers confront the challenges of reducing the lengthy cycle times as a means to deal with the highly variable demand in the supply chain. ▓ Cycle time reduction thus becomes a critical issue for semiconductor wafer fabrication companies to attain competitive advantages. ▓ Semiconductor manufacturing has long time been recognized as one of the most complicated manufacturing process owing to unrelated parallel machine environment, dynamic job arrival, general precedence constraint, and job re-circulation. These characteristics lead to longer mean and variance of cycle times. ▓ In order to manage cycle time, we developed a framework considering the factors that can be used to control production line status such as WIP, availability, utilization, etc, and analyzed the impacts of these factors on the production cycle time.",2011-11-28,https://www.semanticscholar.org/paper/be6c6e7a2f0ed7e0fb48c0ea0b1b2de89d34ec43,2011 e-Manufacturing & Design Collaboration Symposium & International Symposium on Semiconductor Manufacturing (eMDC & ISSM)
167,Brain Computation: A Computer Science Perspective,,2019-10-05,https://www.semanticscholar.org/paper/2086dc4dca34965c944ca4833230d2e0b5b88ef0,Computing and Software Science
2875,Targeted disruption of the galectin-3 gene results in attenuated peritoneal inflammatory responses.,,2000-03-01,https://www.semanticscholar.org/paper/35d5a034133755ab85672a3c1e995113c743ae80,American Journal of Pathology
3721,Analogical Reasoning for Visually Grounded Language Acquisition,"Children acquire language subconsciously by observing the surrounding world and listening to descriptions. They can discover the meaning of words even without explicit language knowledge, and generalize to novel compositions effortlessly. In this paper, we bring this ability to AI, by studying the task of Visually grounded Language Acquisition (VLA). We propose a multimodal transformer model augmented with a novel mechanism for analogical reasoning, which approximates novel compositions by learning semantic mapping and reasoning operations from previously seen compositions. Our proposed method, Analogical Reasoning Transformer Networks (ARTNet), is trained on raw multimedia data (video frames and transcripts), and after observing a set of compositions such as ""washing apple"" or ""cutting carrot"", it can generalize and recognize new compositions in new video frames, such as ""washing carrot"" or ""cutting apple"". To this end, ARTNet refers to relevant instances in the training data and uses their visual features and captions to establish analogies with the query image. Then it chooses the suitable verb and noun to create a new composition that describes the new image best. Extensive experiments on an instructional video dataset demonstrate that the proposed method achieves significantly better generalization capability and recognition accuracy compared to state-of-the-art transformer models.",2020-07-22,https://www.semanticscholar.org/paper/8320ea909c38a616f9daccff4e5a49cfce4d9735,arXiv.org
3570,Semantically Enhanced Containers for Concurrent Real-Time Systems,"Future space missions, such as Mars Science Laboratory, are built upon computing platforms providing a high degree of autonomy and diverse functionality. The increased sophistication of robotic spacecraft has skyrocketed the complexity and cost of its software development and validation. The engineering of autonomous spacecraft software relies on the availability and application of advanced methods and tools that deliver safe concurrent synchronization as well as enable the validation of domain-specific semantic invariants. The software design and certification methodologies applied at NASA do not reach the level of detail of providing guidelines for the development of reliable concurrent software. To achieve effective and safe concurrent interactions as well as guarantee critical domain-specific properties in code, we introduce the notion of a Semantically Enhanced Container (SEC). A SEC is a data structure engineered to deliver the flexibility and usability of the popular ISO C++ Standard Template Library containers, while at the same time it is hand-crafted to guarantee domain-specific policies. We demonstrate the SEC proof-of-concept by presenting a shared nonblocking SEC vector. To eliminate the hazards of the ABA problem (a fundamental problem in lock-free programming), we introduce an innovative library for querying C++ semantic information. Our SEC design aims at providing an effective model for shared data access within the JPL's Mission Data System. Our test results show that the SEC vector delivers significant performance gains (a factor of 3 or more) in contrast to the application of nonblocking synchronization amended with the traditional ABA avoidance scheme.",2009-04-14,https://www.semanticscholar.org/paper/4cd6b68ec9a2ffd18834b1750e64c670bc7b01da,European Conference on the Engineering of Computer-Based Systems
435,Planar Topological Queries,,1997-01-11,https://www.semanticscholar.org/paper/61869bed4e5749fef6ed6a363625cb74811eb55c,International Symposium on the Applications of Constraint Databases
2523,SnapAR: Storing snapshots for quick viewpoint switching in hand-held augmented reality,"Many tasks require a user to move between various locations within an environment to get different perspectives. This can take significant time and effort, especially when the user must switch among those viewpoints repeatedly. We explore augmented reality interaction techniques that involve taking still pictures of a physical scene using a tracked hand-held magic lens and seamlessly switching between augmenting either the live view or one of the still views, without needing to physically revisit the snapshot locations. We describe our optical-marker-tracking-based implementation and how we represent and switch among snapshots. To determine the effectiveness of our techniques, we developed a test application that lets its user view physical and virtual objects from different viewpoints.",2010-11-22,https://www.semanticscholar.org/paper/bb211aa7d23581d001ef9941eee8fe0433871181,2010 IEEE International Symposium on Mixed and Augmented Reality
2775,Interactive Multimedia Explanation for Equipment Maintenance and Repair,,,https://www.semanticscholar.org/paper/aa3147683126d5f033fa727f90b764ff86fba43d,Human Language Technology - The Baltic Perspectiv
2157,Variations on Random Graph Models for the Web,,,https://www.semanticscholar.org/paper/848b05952f5d9b6d5f8c364d82b84ac536dce753,
3764,Do We Need More Training Data?,,2015-03-01,https://www.semanticscholar.org/paper/36961e595e31dea127bfa49124b5cc4f2100710f,International Journal of Computer Vision
1943,An Algorithm of Multi-Subpopulation Parameters With Hybrid Estimation of Distribution for Semiconductor Scheduling With Constrained Waiting Time,"Scheduling for wafer fabrication of advanced technology nodes entails complicated constraints such as limited waiting times. Focusing on real settings, this paper aims to develop a novel genetic algorithm of multi-subpopulation parameters with hybrid estimation of distribution (MSPHEDA) to solve the present problem effectively and efficiently. To estimate the validity of this approach, ten scenarios were simulated on the basis of empirical data as the basis to compare the performance of MSPHEDA and other heuristic methods for minimizing makespan and reducing the total exceeded limited waiting time. The results have shown practical viability of the proposed approach.",2015-06-01,https://www.semanticscholar.org/paper/13a80ee9203dc54be0473e07957a2da82f116ac1,IEEE transactions on semiconductor manufacturing
1977,Beyond make-or-buy: cross-company short-term capacity backup in semiconductor industry ecosystem,,2013-09-01,https://www.semanticscholar.org/paper/4d32e8fe8674e5abecf33d7eaf2fa324e664ce62,
2612,"1 Computational Tools for Modeling , Visualizing and Analyzing Historic and Archaeological Sites","We are proposing to develop computational tools for researchers and students to model, visualize, and analyze historic and ancient sites. This proposal addresses four major scientific components to support this research. First, we are proposing new methods of creating complex, 3-D, photorealistic models of large sites. This includes a mobile robot sensing system that can be used as an intelligent sensing device over a large scale. Second, we are proposing to develop new methods to image below-ground data accurately and efficiently. These methods are especially suited to modeling the wealth of subsurface information at archaeological sites. Third, we will be developing new database technology to catalog and access a site’s structures, artifacts, objects, and historical references. This will significantly improve a user’s ability to query and analyze a site’s information. Fourth, we have created a wearable augmented reality system for presenting georegistered information to mobile users, using overlaid graphics and sound. We will extend this system to create a new class of information visualization systems that integrate 3D aboveand below-ground models, 2D images, text and other web-based resources to annotate the physical environment We will apply this system to support scientists in the field, as well to allow on-site and remote tours of historic and ancient sites. We are intrigued by the possibility of an historic site serving as the nexus for introducing complex ideas from a variety of disciplines: mathematics, earth sciences, economics, geography, literature, languages, politics, and history. Our ability to model, visualize and analyze the site is at the center of this endeavor. We have assembled a team of seasoned researchers from the Columbia community with scientific and historical preservation backgrounds who will work together to achieve our goal. Prof. Peter Allen provides experience in 3D modeling, computer vision and robotics. Prof. Roelof Versteeg specializes in below-ground and noninvasive sensing. Prof. Kenneth Ross is an expert on databases and new methods of accessing data. Prof. Steven Feiner is at the forefront of user interface design and augmented reality. Prof. Lynn Meskell is an authority on Ancient Egyptian Archaeology and Field Director of the Columbia Excavations at Amheida, Egypt [16]. Prof. Stephen Murray is a leader in bringing the ancient and historic world alive through his use of new technology. This includes visualization techniques for historic sites as demonstrated in his successful Amiens Cathedral project [46, 4] and the Medieval Architecture Digital Teaching Project that recruits a dozen international scholar/teachers to construct a course dealing with one thousand years of medieval architecture. Dr. Maurice Luker has collaborated extensively with Profs. Murray and Meskell on both ancient cathedral projects and Egyptian Archaeology. As part of the scientific research proposed above, we want to explore the integration and system building issues of merging these disparate technologies into a powerful set of computational tools that can be extended to other historic and ancient sites and related applications. The focus of archaeological research has progressively shifted from being object-centered to one that uses methodologies that recover larger and more diverse sets of data. Archaeological information can now be accessed through an increasing number of techniques: scientific, computerized and digital. This project explores new possibilities for acquiring, organizing, analyzing, and visualizing this information. Developing these computational tools is a complex project that requires integration efforts between groups of researchers and technologies. We will be testing these tools at a unique site in Egypt’s Western Desert, but it is important that we refine our methods locally and create known working systems before we begin our work in Egypt. Accordingly, we have selected the Cathedral of St. John the Divine in New York, adjacent to the Columbia campus, to serve as an initial testbed. The Cathedral of St. John the Divine offers both a compelling and complex history and an extraordinarily complete set of visual and textual documentation. The photographic archive is particularly rich, including a remarkable collection of images from 1892 to 1940 during the main period of construction. We will model this building and map the documentary evidence to it so that the user can follow",,https://www.semanticscholar.org/paper/fad78f947359dcb4e6e868683c30a3cbb4545da1,
1996,Advanced decision and intelligence technologies for manufacturing and logistics,,2012-12-01,https://www.semanticscholar.org/paper/2855b8de620e32fa39ecd42df222a667ab6a4538,Journal of Intelligent Manufacturing
3153,A Comparison of Thin-Client Computing Architectures,"Thin-client computing offers the promise of easier-to-maintain computational services with reduced total cost of ownership. The recent and growing popularity of thin-client systems makes it important to develop techniques for analyzing and comparing their performance, to assess the general feasibility of the thin-client computing model, and to determine the factors that govern the performance of these architectures. To assess the viability of the thin-client computing model, we measured the performance of five popular thin-client platforms running over a wide range of network access bandwidths. Our results show that current thin-client solutions generally work well in a LAN environment, but their performance degrades significantly when they are used in today’s broadband environments. We also find that the efficiency of the thin-client protocols varies widely. In some cases, the efficiency of the thin client protocol for web applications is within a factor of two of standard web protocols, while others are 30 times more inefficient. We analyze the differences in the various approaches and explain the impact of the underlying remote display protocols on overall performance.",,https://www.semanticscholar.org/paper/d0113d1ab647be8250018f370e9e56d0a7392c97,
2348,Superoxide generation during phagocytosis by Acanthamoeba castellanii: similarities to the respiratory burst of immune phagocytes,"Starved cultures of the soil amoeba Acanthamoeba castellanii suspended in phosphate-buffered saline exhibit stimulated O2 uptake in response to phagocytosis of either heat-killed yeast or latex beads. This phagocytosis-dependent (cyanide-insensitive) oxidative activity was observed when cells were isolated from either cyanide-stimulated or -inhibited cultures, and was therefore independent of the relative activities of the alternative mitochondrial oxidases known to exist in this organism. The extra O2 consumed during phagocytosis was stoichiometrically converted into O-
2 as detected by the rate of superoxide dismutase-inhibitable cytochrome c reduction. Phagolysosomal membranes isolated after uptake of latex beads were enriched in a b-type cytochrome which was spectrally similar to that present in immune phagocytes. Thus, the biochemical events during phagocytosis by either A. castellanii or immune phagocytes appear similar, suggesting that the ‘respiratory burst’ enzyme(s) responsible for O-
2 generation in these two cell types is structurally related.",1991-03-01,https://www.semanticscholar.org/paper/fcc97ef6ed0b6da9cc1af1941c8f9fe813566624,
3147,Virtual-Time Round-Robin: An O(1) Proportional Share Scheduler,"Proportional share resource management provides a flexible and useful abstraction for multiplexing timeshared resources. However, previous proportional share mechanisms have either weak proportional sharing accuracy or high scheduling overhead. We present VirtualTime Round-Robin (VTRR), a proportional share scheduler that can provide good proportional sharing accuracy with O(1) scheduling overhead. VTRR achieves this by combining the benefits of fair queueing algorithms with a round-robin scheduling mechanism. Unlike many other schedulers, VTRR is simple to implement. We have implemented a VTRR CPU scheduler in Linux in less than 100 lines of code. Our performance results demonstrate that VTRR provides accurate proportional share allocation with constant, sub-microsecond scheduling overhead. The scheduling overhead using VTRR is two orders of magnitude less than the standard Linux scheduler for large numbers of clients.",2001-06-25,https://www.semanticscholar.org/paper/9d5705cfaec7002218c09c808a6ffc26d34bc192,"USENIX Annual Technical Conference, General Track"
1802,Distance dependent Chinese restaurant processes,"We develop the distance dependent Chinese restaurant process (CRP), a flexible class of distributions over partitions that allows for non-exchangeability. This class can be used to model dependencies between data in infinite clustering models, including dependencies across time or space. We examine the properties of the distance dependent CRP, discuss its connections to Bayesian nonparametric mixture models, and derive a Gibbs sampler for both observed and mixture settings. We study its performance with time-dependent models and three text corpora. We show that relaxing the assumption of exchangeability with distance dependent CRPs can provide a better fit to sequential data. We also show its alternative formulation of the traditional CRP leads to a faster-mixing Gibbs sampling algorithm than the one based on the original formulation.",2009-10-06,https://www.semanticscholar.org/paper/72cc610bcdaf4166839eeff04776adcea225439f,International Conference on Machine Learning
3248,Conservation Behavior: Anthropogenic impacts on behavior: the pros and cons of plasticity,"Many threatened and endangered species inhabit environments where people have altered the landscape and have created novel and powerful selective pressures. These often disrupt “bottom-up” factors associated with resource acquisition, change “top-down” factors involving predation or disease transmission or alter “side-ways” factors involving competitive or mutualistic interactions happening at the same trophic level. Since one of the basic precepts of behavioral ecology is that environmental conditions shape behavior, such changes should lead to changing responses by the species experiencing them. But this pre-supposes that there is enough plasticity in a species’ behavioral repertoire to cope with the environmental change. If there is, then contingent responses displayed in the past may help species cope with a changing present. If the degree of environmental change is so great or the species has a limited ability to adjust its behavior, then the species could be pushed beyond its limits to adapt, with the stress it experiences lowering its fecundity or survival, leading to its demise (Chapter 4). Alternatively, the species could be pushed into new behavioral space, revealing novel responses. These might be sufficient to cope with the environmental changes, creating new evolutionary potential, or they could be pathological, creating unintended negative consequences that may at first appear benign, but in the long run may impact the species’ viability or involve cascading effects on other species. Recent reviews by Rubenstein (2010) and Caro and Sherman (2011, 2013) have provided insights into many dimensions of this problem. Caro and Sherman (2011) argue that species exhibit remarkable degrees of plasticity and that behavioral diversity per se should be added to the traditional list of attributes to be conserved – genes, species and ecosystems. If behaviors are not conserved, then many behavioral variants will remain latent and unexpressed, and if given enough time, will vanish from a species’ repertoire forever. This could potentially change a species’ evolutionary trajectory by reducing a species’ ability to escape from new stressors or by eliminating the possibility of conservationists seeding threatened populations with corrective behavioral variants. Such a doom and gloom scenario need not be cast in stone since dramatic changes in the past have often disrupted communities and altered selective pressures. Adaptations in the past have led to successful coping strategies and they can do so again going forward.",2016-05-01,https://www.semanticscholar.org/paper/6fa3fe2e7f69542cd03663211233cac6b213ee6d,
3132,A holistic approach to service survivability,"We present SABER (Survivability Architecture: Block, Evade, React), a proposed survivability architecture that blocks, evades and reacts to a variety of attacks by using several security and survivability mechanisms in an automated and coordinated fashion. Contrary to the ad hoc manner in which contemporary survivable systems are built-using isolated, independent security mechanisms such as firewalls, intrusion detection systems and software sandboxes-SABER integrates several different technologies in an attempt to provide a unified framework for responding to the wide range of attacks malicious insiders and outsiders can launch.
 This coordinated multi-layer approach will be capable of defending against attacks targeted at various levels of the network stack, such as congestion-based DoS attacks, software-based DoS or code-injection attacks, and others. Our fundamental insight is that while multiple lines of defense are useful, most conventional, uncoordinated approaches fail to exploit the full range of available responses to incidents. By coordinating the response, the ability to survive successful security breaches increases substantially.
 We discuss the key components of SABER, how they will be integrated together, and how we can leverage on the promising results of the individual components to improve survivability in a variety of coordinated attack scenarios. SABER is currently in the prototyping stages, with several interesting open research topics.",2003-10-31,https://www.semanticscholar.org/paper/669675ece7a64db4305d9c68aac860db7ebd5e4b,SSRS '03
1592,Word2net: Deep Representations of Language,"Word embeddings extract semantic features of words from large datasets of text. Most embedding methods rely on a log-bilinear model to predict the occurrence of a word in a context of other words. Here we propose word2net, a method that replaces their linear parametrization with neural networks. For each term in the vocabulary, word2net posits a neural network that takes the context as input and outputs a probability of occurrence. Further, word2net can use the hierarchical organization of its word networks to incorporate additional meta-data, such as syntactic features, into the embedding model. For example, we show how to share parameters across word networks to develop an embedding model that includes part-of-speech information. We study word2net with two datasets, a collection of Wikipedia articles and a corpus of U.S. Senate speeches. Quantitatively, we found that word2net outperforms popular embedding methods on predicting held- out words and that sharing parameters based on part of speech further boosts performance. Qualitatively, word2net learns interpretable semantic representations and, compared to vector-based methods, better incorporates syntactic information.",2018-02-15,https://www.semanticscholar.org/paper/36399406816e1cbd6c9ebed30714f140bbe59d1d,
2879,Role of the carboxyl-terminal lectin domain in self-association of galectin-3.,"Galectin-3 is a member of a large family of beta-galactoside-binding animal lectins and is composed of a carboxyl-terminal lectin domain connected to an amino-terminal nonlectin part. Previous experimental results suggest that, when bound to multivalent glycoconjugates, galectin-3 self-associates through intermolecular interactions involving the amino-terminal domain. In this study, we obtained evidence suggesting that the protein self-associates in the absence of its saccharide ligands, in a manner that is dependent on the carboxyl-terminal domain. This mode of self-association is inhibitable by the lectin's saccharide ligands. Specifically, recombinant human galectin-3 was found to bind to galectin-3C (the carboxyl-terminal domain fragment) conjugated to Sepharose 4B and the binding was inhibitable by lactose. In addition, biotinylated galectin-3 bound to galectin-3 immobilized on plastic surfaces and the binding could also be inhibited by various saccharide ligands of the lectin. A mutant with a tryptophan to leucine replacement in the carboxyl-terminal domain, which exhibited diminished carbohydrate-binding activity, did not bind to galectin-3C-Sepharose 4B. Furthermore, galectin-3C formed covalent homodimers when it was treated with a chemical cross-linker and the dimer formation was completely inhibited by lactose. Therefore, galectin-3 can self-associate through intermolecular interactions involving both the amino- and the carboxyl-terminal domains and the relative contribution of each depends on whether the lectin is bound to its saccharide ligands.",1998-03-05,https://www.semanticscholar.org/paper/6fd7ef1aca7d472d622ff5df2cfbd8734b47bab6,Biochemistry
3262,"Similar but Different: Dynamic Social Network Analysis Highlights Fundamental Differences between the Fission-Fusion Societies of Two Equid Species, the Onager and Grevy’s Zebra","Understanding why animal societies take on the form that they do has benefited from insights gained by applying social network analysis to patterns of individual associations. Such analyses typically aggregate data over long time periods even though most selective forces that shape sociality have strong temporal elements. By explicitly incorporating the temporal signal in social interaction data we re-examine the network dynamics of the social systems of the evolutionarily closely-related Grevy’s zebras and wild asses that show broadly similar social organizations. By identifying dynamic communities, previously hidden differences emerge: Grevy’s zebras show more modularity than wild asses and in wild asses most communities consist of solitary individuals; and in Grevy’s zebras, lactating females show a greater propensity to switch communities than non-lactating females and males. Both patterns were missed by static network analyses and in general, adding a temporal dimension provides insights into differences associated with the size and persistence of communities as well as the frequency and synchrony of their formation. Dynamic network analysis provides insights into the functional significance of these social differences and highlights the way dynamic community analysis can be applied to other species.",2015-10-21,https://www.semanticscholar.org/paper/e848221956677ab924417b9de721bda93d6aa826,PLoS ONE
563,"Correction to ""A Theorem in Database Concurrency Control""",,,https://www.semanticscholar.org/paper/bc636f317b59675609e69586d29522b87f68068a,Journal of the ACM
81,Evaluating top-k queries over Web-accessible databases,"A query to a Web search engine usually consists of a list of keywords, to which the search engine responds with the best or ""top"" k pages for the query. This top-k query model is prevalent over multimedia collections in general, but also over plain relational data for certain applications. For example, consider a relation with information on available restaurants, including their location, price range for one diner, and overall food rating. A user who queries such a relation might simply specify the user's location and target price range, and expect in return the best 10 restaurants in terms of some combination-of proximity to the user, closeness of match to the target price range, and overall food rating. Processing such top-k queries efficiently is challenging for a number of reasons. One critical such reason is that, in many Web applications, the relation attributes might not be available other than through external Web-accessible form interfaces, which we will have to query repeatedly for a potentially large set of candidate objects. In this paper, we study how to process top-k queries efficiently in this setting, where the attributes for which users specify target values might be handled by external, autonomous sources with a variety of access interfaces. We present several algorithms for processing such queries, and evaluate them thoroughly using both synthetic and real Web-accessible data.",2002-02-26,https://www.semanticscholar.org/paper/c6e3d4a8fba3cd5d592d62f533ff95bde84a8f22,Proceedings / International Conference on Data Engineering
2490,Session details: Games: community + communication,,2012-05-05,https://www.semanticscholar.org/paper/0431a1e58e44b063772389a51d85f301abed54a6,International Conference on Human Factors in Computing Systems
3005,Antitrust Enforcement and Big Tech: After the Remedy Is Ordered,"Each of us—one an attorney and the other two software experts—has substantial experience monitoring the implementation of court-ordered remedies in two leading hi-tech cases: United States v. Microsoft Corp. and United States v. Bazaarvoice, Inc. We discuss challenges that attorney and expert monitors confront in overseeing company compliance with antitrust remedial decrees in cases against hi-tech companies. We first summarize the legal principles applicable to antitrust remedies. Thereafter, we discuss oversight in the Microsoft and Bazaarvoice cases. Finally, we offer takeaways on effective antitrust decree monitoring. Two takeaways are particularly noteworthy. First, expect the unexpected. During monitoring oversight, implementing the court decree’s relatively general relief provisions will likely uncover unanticipated issues that prove challenging to resolve and may often require hi-tech expertise to do so. Second—and relatedly—be skeptical of company resistance. Court-ordered relief is unlikely to align with company business interests; if it did, the company probably would have adopted the practice without being ordered to do so. Accordingly, company incentives probably will militate toward a cramped view of decree implementation. Monitors therefore should refrain from taking company protestations at face value and should be prepared to leverage hi-tech expertise to probe company systems, data, and personnel for verification or refutation of company positions. Finally, with artificial intelligence and computational law (including antitrust) continuing to develop, we call attention to opportunities to use computer-automated processes to inform compliance oversight.",2021-05-31,https://www.semanticscholar.org/paper/1caf87b6df36c049acae3568f5d37cdbd7647cc4,
1664,"Edward: A library for probabilistic modeling, inference, and criticism","Probabilistic modeling is a powerful approach for analyzing empirical information. We describe Edward, a library for probabilistic modeling. Edward's design reflects an iterative process pioneered by George Box: build a model of a phenomenon, make inferences about the model given data, and criticize the model's fit to the data. Edward supports a broad class of probabilistic models, efficient algorithms for inference, and many techniques for model criticism. The library builds on top of TensorFlow to support distributed training and hardware such as GPUs. Edward enables the development of complex probabilistic models and their algorithms at a massive scale.",2016-10-31,https://www.semanticscholar.org/paper/d51fefa58ceafe9bebddf03f2379842068dae3bc,arXiv.org
1085,pp̄ collisions at A s Ä 1 . 8 TeV,,,https://www.semanticscholar.org/paper/beb8d6391190a582025d0c321a666357e2774d99,
3011,Formally Verified Memory Protection for a Commodity Multiprocessor Hypervisor,"Hypervisors are widely deployed by cloud computing providers to support virtual machines, but their growing complexity poses a security risk, as large codebases contain many vulnerabilities. We present SeKVM, a layered Linux KVM hypervisor architecture that has been formally verified on multiprocessor hardware. Using layers, we isolate KVM’s trusted computing base into a small core such that only the core needs to be verified to ensure KVM’s security guarantees. Using layers, we model hardware features at different levels of abstraction tailored to each layer of software. Lower hypervisor layers that configure and control hardware are verified using a novel machine model that includes multiprocessor memory management hardware such as multi-level shared page tables, tagged TLBs, and a coherent cache hierarchy with cache bypass support. Higher hypervisor layers that build on the lower layers are then verified using a more abstract and simplified model, taking advantage of layer encapsulation to reduce proof burden. Furthermore, layers provide modularity to reduce verification effort across multiple implementation versions. We have retrofitted and verified multiple versions of KVM on Arm multiprocessor hardware, proving the correctness of the implementations and that they contain no vulnerabilities that can affect KVM’s security guarantees. Our work is the first machine-checked proof for a commodity hypervisor using multiprocessor memory management hardware. SeKVM requires only modest KVM modifications and incurs only modest performance overhead versus unmodified KVM on real application workloads.",,https://www.semanticscholar.org/paper/ad320d4d95c9a0f92271d7adc0babd81735a9c85,USENIX Security Symposium
3079,Automatic User Interaction Detection and Scheduling with RSIO,"Response time is one of the most important factors for the overall usability of a computer system. We present RSIO, a processor scheduling framework for improving the response time of latency-sensitive applications by monitoring accesses to I/O channels and inferring when user interactions occur. RSIO provides a general mechanism for all user interactions, including direct interactions via local HCI devices such as mouse and keyboard, indirect interactions through middleware, and remote interactions through networks. It automatically and dynamically identifies processes involved in a user interaction and boosts their priorities at the time the interaction occurs to improve system response time. RSIO detects processes that directly handle a user interaction as well as those indirectly involved in processing the interaction, automatically accounting for dependencies and boosting their priorities accordingly. RSIO works with existing schedulers, processes that may mix interactive and batch activities, and requires no application modifications to identify periods of latency-sensitive application activity. We have implemented RSIO in Linux and measured its effectiveness on microbenchmarks and real applications. Our results show that RSIO is easy to use and can provide substantial improvements in system performance for latency-sensitive applications.",,https://www.semanticscholar.org/paper/4733864fbd53f569ed1d4dac7fa7301d764334d1,
1807,A Bayesian Analysis of Dynamics in Free Recall,"We develop a probabilistic model of human memory performance in free recall experiments. In these experiments, a subject first studies a list of words and then tries to recall them. To model these data, we draw on both previous psychological research and statistical topic models of text documents. We assume that memories are formed by assimilating the semantic meaning of studied words (represented as a distribution over topics) into a slowly changing latent context (represented in the same space). During recall, this context is reinstated and used as a cue for retrieving studied words. By conceptualizing memory retrieval as a dynamic latent variable model, we are able to use Bayesian inference to represent uncertainty and reason about the cognitive processes underlying memory. We present a particle filter algorithm for performing approximate posterior inference, and evaluate our model on the prediction of recalled words in experimental data. By specifying the model hierarchically, we are also able to capture inter-subject variability.",2009-12-07,https://www.semanticscholar.org/paper/9dfcaad0c019a67c46e0156bc8da52e32628d446,Neural Information Processing Systems
3082,Proceedings of the 1st ACM workshop on Virtual machine security,"Welcome to the 1st Workshop on Virtual Machine Security (VMSec)! 
 
In these proceedings, you will find the 7 papers presented at VMSec Workshop, held on October 31st at George Mason University in conjunction with the ACM Conference on Computer & Communications Security. This workshop aims to bring together leading researchers and practitioners in the fields of virtualization and security to present the latest work on these topics. This year we had 20 submissions and we decided to accept six (6) full papers and one (1) short paper. A program committee of 11 experts reviewed and discussed the papers. Each paper received at least 3 reviews from the PC members with most of the papers having 4 reviews in total. Some of the papers were very controversial and were discussed in detail by the PC members after the end of the review process. The final decisions were made based on those discussions. 
 
VMSec is the first workshop to deal exclusively with virtual machine security. Virtualization has seen an explosion in growth in deployment, implementations, and applications. In addition, it seems that virtualization holds unique properties that make it attractive for security including isolation, compartmentalization, live state capture, and replay. In the past, virtualization has been used to study malicious software as well as to prevent malicious software infection. We believe that the large-scale use of virtualization offers new opportunities and challenges regarding security. We hope that this workshop will provoke fruitful discussions for researchers and practitioners, from both industry and academia.",2008-10-27,https://www.semanticscholar.org/paper/b533831773ccadaaf4d92fdc2328064891ef7b4a,Conference on Computer and Communications Security
1949,A back-propagation neural network with a distributed lag model for semiconductor vendor-managed inventory,"Variations in customer demands directly affect the total quantity of customer orders processed in semiconductor fabrication. This causes variability in wafer start input, affecting the work-in-process bubble and cycle time. The finished goods stored in fab warehouse are called semiconductor vendor-managed inventory. The increase of inventory leads to low inventory turnover ratio. In this study, a back-propagation neural network model with a distributed lag structure is developed to predict customer demands based on customer order behaviors, and to extract useful information for supporting the production plan for VMI based on uncertain demand and market fluctuation. An empirical study was conducted at a leading fab to validate the method. The results have shown the practical viability of the proposed approach. The derived empirical rules can assist decision-makers in making timely production decisions, given various order situations, ensuring that adequate fab utilization and cycle times are maintained.",2015-03-30,https://www.semanticscholar.org/paper/e8d117e18694c4f3445613309a34181f6b67fca3,
1204,A search for the standard model Higgs boson in the missing energy and acoplanar b-jet topology at sqrt(s) = 1.96 TeV,"We report a search for the standard model Higgs boson in the missing energy and acoplanar b-jet topology, using an integrated luminosity of 0.93 inverse femtobarn recorded by the D0 detector at the Fermilab Tevatron Collider. The analysis includes signal contributions from pp->ZH->nu nu b b, as well as from WH production in which the charged lepton from the W boson decay is undetected. Neural networks are used to separate signal from background. In the absence of a signal, we set limits on the cross section of pp->VH times the branching ratio of H->bb at the 95% C.L. of 2.6 - 2.3 pb, for Higgs boson masses in the range 105 - 135 GeV, where V=W,Z. The corresponding expected limits range from 2.8 pb - 2.0 pb.",2008-08-08,https://www.semanticscholar.org/paper/1da4ce6f19322264aca757f119d3fb211095033d,
2335,The effects of GM-CSF on myeloperoxidase release in normal and myelodysplastic neutrophils.,,1993-12-01,https://www.semanticscholar.org/paper/2a7a46abc3d36d5d048e7d2d0ee8014cd89181df,Leukemia research : a Forum for Studies on Leukemia and Normal Hemopoiesis
3205,Communication is key: Mother-offspring signaling can affect behavioral responses and offspring survival in feral horses (Equus caballus),"Acoustic signaling plays an important role in mother-offspring recognition and subsequent bond-formation. It remains unclear, however, if mothers and offspring use acoustic signaling in the same ways and for the same reasons throughout the juvenile stage, particularly after mutual recognition has been adequately established. Moreover, despite its critical role in mother-offspring bond formation, research explicitly linking mother-infant communication strategies to offspring survival are lacking. We examined the communicative patterns of mothers and offspring in the feral horse (Equus caballus) to better understand 1) the nature of mother-offspring communication throughout the first year of development; 2) the function(s) of mother- vs. offspring-initiated communication and; 3) the importance of mare and foal communication to offspring survival. We found that 1) mares and foals differ in when and how they initiate communication; 2) the outcomes of mare- vs. foal-initiated communication events consistently differ; and 3) the communicative patterns between mares and their foals can be important for offspring survival to one year of age. Moreover, given the importance of maternal activity to offspring behavior and subsequent survival, we submit that our data are uniquely positioned to address the long-debated question: do the behaviors exhibited during the juvenile stage (by both mothers and their young) confer delayed or immediate benefits to offspring? In summary, we aimed to better understand 1) the dynamics of mother-offspring communication, 2) whether mother-offspring communicative patterns were important to offspring survival, and 3) the implications of our research regarding the function of the mammalian juvenile stage. Our results demonstrate that we have achieved those aims.",2020-04-17,https://www.semanticscholar.org/paper/2fd9f055d121ed1021b613eff96a6d63d265f849,PLoS ONE
1303,Limits on WIMP-nucleon interactions from the Cryogenic Dark Matter Search at the Soudan Underground Laboratory,,2006-04-15,https://www.semanticscholar.org/paper/151cb65da3369c2c8844a58274587c0bc8e97fc0,
1571,Comment: Variational Autoencoders as Empirical Bayes,"We thank Professor Efron for his informative and unifying review of empirical Bayes. In this comment, we discuss the connection between empirical Bayes and the variational autoencoder (VAE), a popular statistical inference framework in the machine learning community. We hope this connection motivates new algorithmic approaches for empirical Bayesians and gives new perspectives on VAEs for machine learners.",2019-05-01,https://www.semanticscholar.org/paper/6a079726a8377b76b5b85a4695492035a77cd8d2,Statistical Science
1227,Search for large extra dimensions in the mono-photon final state at sqrt(s) = 1.96 TeV,We report on a search for large extra dimensions in a data sample of approximately 1 fb^{-1} of p pbar collisions at sqrt(s) = 1.96 TeV. We investigate Kaluza-Klein graviton production with a photon and missing transverse energy in the final state. At the 95% C.L. we set limits on the fundamental mass scale M_{D} from 884 GeV to 778 GeV for 2 to 8 extra dimensions.,2008-03-14,https://www.semanticscholar.org/paper/78ce666bbe307a9e0380d122edce16d489420e15,
362,An approximate truthful mechanism for combinatorial auctions with single parameter agents,"Mechanism design seeks algorithms whose inputs are provided by selfish agents who would lie if advantageous. Incentive compatible mechanisms compel the agents to tell the truth by making it in their self-interest to do so. Often, as in combinatorial auctions, such mechanisms involve the solution of NP-hard problems. Unfortunately, approximation algorithms typically destroy incentive compatibility. Randomized rounding is a commonly used technique for designing approximation algorithms. We devise a version of randomized rounding that is incentive compatible, giving a truthful mechanism for combinatorial auctions with single parameter agents (e.g., ""single minded bidders"") that approximately maximizes the social value of the auction. We discuss two orthogonal notions of truthfulness for a randomized mechanism, truthfulness with high probability and in expectation, and give a mechanism that achieves both simultaneously.We consider combinatorial auctions where multiple copies of many different items are on sale, and each bidder i desires a subset Si. Given a set of bids, the problem of finding the allocation of items that maximizes total valuation is the well-known SETPACKING problem. This problem is NP-hard, but for the case of items with many identical copies the optimum can be approximated very well. To turn this approximation algorithm into a truthful auction mechanism we overcome two problems: we show how to make the allocation algorithm monotone, and give a method to compute the appropriate payments efficiently.",2003-01-12,https://www.semanticscholar.org/paper/e4558be04e6655b5a68bb736f0d35a4952d80a58,ACM-SIAM Symposium on Discrete Algorithms
1173,SuperCDMS Detector Readout Cryogenic Hardware,"SuperCDMS employs 1‐inch thick germanium crystals operated below 50mK in a dilution cryostat. Each detector produces ionization and phonon signals. Ionization signals are amplified by JFETs operating at 150K within an assembly mounted on the 4K cryostat stage. These high impedance signals are carried to the FETs by superconducting “vacuum coaxes” which minimize thermal conductivity, stray capacitance, and microphonics. Transition edge sensors produce low‐impedance phonon signals, amplified by SQUID arrays mounted on a 600mK stage. Detectors are mounted in a six‐sided wiring configuration called a “tower”, which carries signals from 40mK to 4K. A flex circuit 3 meters in length carries amplified signals for each detector from 4K to a vacuum bulkhead. We describe the methods used to support the detectors, wiring and amplifier elements at various thermal stages, minimizing electrical noise and thermal loads.",2009-12-16,https://www.semanticscholar.org/paper/a6e1a27f94a68aab2ff16d957155c0161844a275,
2184,A robust intracellular metabolite extraction protocol for human neutrophil metabolic profiling,"Neutrophils are phagocytic innate immune cells that play essential roles in host defence, but are also implicated in inflammatory diseases such as rheumatoid arthritis (RA) where they contribute to systemic inflammation and joint damage. Transcriptomic analysis of neutrophils has revealed significant changes in gene expression in neutrophils activated in vitro by cytokines and in vivo during inflammation in RA. However, there are no reports on the global metabolomic changes that occur as a consequence of this activation. The aim of this study was to establish protocols for the study of changes in the metabolome of human neutrophils using 1H NMR spectroscopy. Sample preparation and spectral analysis protocols were optimised using neutrophils isolated by Ficoll-Paque, with decreased washing steps and inclusion of a heat-shock step to quench metabolite turnover. Cells were incubated ± PMA for 15 min in HEPES-free media and samples were analysed by NMR using a 700 MHz NMR Avance IIIHD Bruker NMR spectrometer equipped with a TCI cryoprobe. Chenomx, Bruker TopSpin and AMIX software were used to process spectra and identify metabolites. Principal Component Analysis (PCA) and signalling pathway analysis was carried out using Metaboanalyst. Cell number and number of scans (NS) were optimised as >3.6 million cells and 512 NS. 327 spectral bins were defined in the neutrophil spectra, of which 287 (87.7%) were assigned to 110 metabolites that included: amino acids, peptides and analogues; carbohydrates, carbonyls and alcohols; nucleotides, nucleosides and analogues; lipids and lipid-like molecules; benzenoids; and other organic compounds. 43 metabolites changed at least 1.5 fold (increase or decrease) after the addition of PMA for 5 or 15 min. Pathway analysis revealed that PMA affected nicotinate and nicotinamide metabolism, aminoacyl-tRNA biosynthesis and glycolysis, suggesting a redirection of glucose metabolism from glycolysis to the pentose phosphate pathway and production of NADPH for activation of the NADPH oxidase and subsequent respiratory burst. We have developed protocols for the study of human neutrophils by 1H NMR spectroscopy. Importantly, this methodology has sufficient sensitivity and reproducibility to detect changes in metabolite abundance from cell numbers typically collected from clinical samples or experiments with multiple assay conditions.",2018-12-20,https://www.semanticscholar.org/paper/495c10b25a26f1f3b864b32d55699d072657535b,PLoS ONE
411,Proceedings of the eighteenth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,,1999-05-01,https://www.semanticscholar.org/paper/950e5917cb176b72015d8f64f837601b2740642e,ACM SIGMOD Conference
558,Interval graphs and seatching,,1985-07-01,https://www.semanticscholar.org/paper/7b89479af8243dbadb4bc514fdf9692a1b0391c8,Discrete Mathematics
2224,Concise report Neutrophil-derived reactive oxygen species in SSc,"Objective. Reactive oxygen species (ROS) are implicated in the pathogenesis of SSc. Neutrophils constitute a major source of ROS during inflammation. Here, we examined endogenous and stimulated ex vivo ROS production of SSc neutrophils compared with control neutrophils with and without prior priming with TNF-a. Methods. ROS generation was measured using luminol-enhanced chemiluminescence. Neutrophils isolated from SSc patients and healthy controls were unprimed or were primed with TNF-a. ROS production was stimulated in vitro with phorbol 12-myristate 13-acetate (PMA) and formyl-met-leu-phe (fMLP). To examine the effects of serum mediators on ROS generation, control neutrophils were also stimulated with SSc or control serum. Results. Neutrophil stimulation with PMA and fMLP resulted in a greater increase in ROS generation in SSc neutrophils compared with controls. However, unstimulated SSc neutrophils generated lower levels of ROS than controls. SSc neutrophils demonstrated an increased response to fMLP in the absence of in vitro TNF-a priming indicating priming of SSc neutrophils in vivo. SSc serum did not stimulate neutrophil ROS generation in vitro. Conclusion. SSc neutrophils are primed for ROS generation. Neutrophils binding to activated endothelium in SSc, may induce local production of ROS, perpetuating endothelial dysfunction and mediating fibrosis.",,https://www.semanticscholar.org/paper/65518eee61e867231e580056db864596fb54d9cc,
1916,Tool allocation to smooth work-in-process for cycle time reduction and an empirical study,,2018-09-01,https://www.semanticscholar.org/paper/c1d12a9116c695d61f8027e313a0d5ec33ae38e1,Annals of Operations Research
156,Online Stochastic Max-Weight Bipartite Matching: Beyond Prophet Inequalities,"The rich literature on online Bayesian selection problems has long focused on so-called prophet inequalities, which compare the gain of an online algorithm to that of a ""prophet"" who knows the future. An equally-natural, though significantly less well-studied benchmark is the optimum online algorithm, which may be omnipotent (i.e., computationally-unbounded), but not omniscient. What is the computational complexity of the optimum online? How well can a polynomial-time algorithm approximate it? Motivated by applications in ride hailing, we study the above questions for the online stochastic maximum-weight matching problem under vertex arrivals. This problem was recently introduced by Ezra, Feldman, Gravin and Tang (EC'20), who gave a 1/2-competitive algorithm for it. This is the best possible ratio, as this problem is a generalization of the original single-item prophet inequality. We present a polynomial-time algorithm which approximates optimal online within a factor of 0.51---beating the best-possible prophet inequality. At the core of our result are a new linear program formulation, an algorithm that tries to match the arriving vertices in two attempts, and an analysis that bounds the correlation resulting from the second attempts. In contrast, we show that it is PSPACE-hard to approximate this problem within some constant α < 1.",2021-02-20,https://www.semanticscholar.org/paper/1c8a05b5f15067d5c40c933539239c5d1c304e8b,ACM Conference on Economics and Computation
2503,Directing attention and influencing memory with visual saliency modulation,"In augmented reality, it is often necessary to draw the user's attention to particular objects in the real world without distracting her from her task. We explore the effectiveness of directing a user's attention by imperceptibly modifying existing features of a video. We present three user studies of the effects of applying a saliency modulation technique to video; evaluating modulation awareness, attention, and memory. Our results validate the saliency modulation technique as an alternative means to convey information to the user, suggesting attention shifts and influencing recall of selected regions without perceptible changes to visual input.",2011-05-07,https://www.semanticscholar.org/paper/0ca83c9f0ff452cbd72cb4d18d24d300022c8414,International Conference on Human Factors in Computing Systems
930,Algorithms for Acyclic Database Schemes,"Many real-world situations can be captured by a set of functional dependencies and a single join dependency of a particular form called acyclic [B..]. The join dependency corresponds to a natural decomposition into meaningfull objects (an acyclic database scheme). Our purpose in this paper is to describe efficient algorithms in this setting for various problems, such as computing projections, minimizing joins, inferring dependencies, and testing for dependency satisfaction.",1981-09-09,https://www.semanticscholar.org/paper/fe0b45175713c4637486956f63f9234685a88c1c,Very Large Data Bases Conference
676,Stochastic Neighbor Embedding under f-divergences,"The t-distributed Stochastic Neighbor Embedding (t-SNE) is a powerful and popular method for visualizing high-dimensional data. It minimizes the Kullback-Leibler (KL) divergence between the original and embedded data distributions. In this work, we propose extending this method to other f-divergences. We analytically and empirically evaluate the types of latent structure-manifold, cluster, and hierarchical-that are well-captured using both the original KL-divergence as well as the proposed f-divergence generalization, and find that different divergences perform better for different types of structure. 
A common concern with $t$-SNE criterion is that it is optimized using gradient descent, and can become stuck in poor local minima. We propose optimizing the f-divergence based loss criteria by minimizing a variational bound. This typically performs better than optimizing the primal form, and our experiments show that it can improve upon the embedding results obtained from the original $t$-SNE criterion as well.",2018-11-03,https://www.semanticscholar.org/paper/c15038da6acbc23df3c21ccf7f890c2c46b25322,arXiv.org
2541,Searching the World's Herbaria: A System for Visual Identification of Plant Species,,2008-10-12,https://www.semanticscholar.org/paper/090d99b041023c1f4af445122906baa41e41372a,European Conference on Computer Vision
3334,Parasites and Social Behavior of Island Feral Horses,,,https://www.semanticscholar.org/paper/1523966d309a118eee33fd03e68d146e9cf6e3e5,
2755,"A Visual Language for Browsing, Undoing, and Redoing Graphical Interface Commands","We present the concept of an editable graphical history that allows the user to review and modify the actions performed with a graphical user interface. Using a pictorial metaphor borrowed from comic strips, an editable graphical history consists of a series of panels that depict in chronological order the important events in the history of a user’s session. We discuss the visual language used in editable graphical histories, and describe Chimera, a graphical editor that generates these histories automatically. The user may scroll through the sequence of panels, reviewing actions at different levels of detail, and selectively undoing, modifying, and redoing previous actions. Chimera’s editable graphical histories are constructed from parts of the editor window, the editor control panel, and the editor’s pop up menus. Panels indicate both the objects that are modified and the actions performed on them. We describe the heuristics used to determine the objects depicted in each panel, the style in which they are drawn, and how actions are distributed among panels.",,https://www.semanticscholar.org/paper/757ad0b8bc19a441b4a05642f773676a7df2aa0d,
3676,SURFSUP: Learning Fluid Simulation for Novel Surfaces,"Modeling the mechanics of fluid in complex scenes is vital to applications in design, graphics, and robotics. Learning-based methods provide fast and differentiable fluid simulators, however most prior work is unable to accurately model how fluids interact with genuinely novel surfaces not seen during training. We introduce SURFSUP, a framework that represents objects implicitly using signed distance functions (SDFs), rather than an explicit representation of meshes or particles. This continuous representation of geometry enables more accurate simulation of fluid-object interactions over long time periods while simultaneously making computation more efficient. Moreover, SURFSUP trained on simple shape primitives generalizes considerably out-of-distribution, even to complex real-world scenes and objects. Finally, we show we can invert our model to design simple objects to manipulate fluid flow.",2023-04-13,https://www.semanticscholar.org/paper/0c1a64d547a93b206f0488366ca765ee2a711593,arXiv.org
1362,Search for the flavor-changing neutral current decay B0s → μ+ μ- in pp collisions at √s = 1.96 TeV with the DO detector,,,https://www.semanticscholar.org/paper/e2a8976a95fb36bcdd8356660eb3b175d8ca7319,
3189,The gastrointestinal nematodes of plains and Grevy's zebras: Phylogenetic relationships and host specificity,,2021-10-01,https://www.semanticscholar.org/paper/1ee13f528e15fd694856a9629bd36b134fee1967,International Journal for Parasitology: Parasites and Wildlife
165,Energy Equilibria in Proof-of-Work Mining,"The Bitcoin protocol induces miners, through monetary rewards, to expend energy in order to add blocks to the chain. We show that, when energy costs are substantial and taken into account, counterintuitive and unintended strategic behavior results: In a simple bounded-horizon setting with two identical miners there is a unique pure symmetric equilibrium in which both miners first ""slow down"" in order to decrease the crypto complexity and then take advantage of this decrease. If miners have different energy efficiencies and are restricted to choose the same hash rate for many epochs, there is a unique pure equilibrium in which miners either participate at low levels that depend in intricate ways on all the other miners' efficiencies, or choose to abstain from mining if their efficiency is too low. In the general setting in which miners can adapt their hash rates over time, we show that, unless the number of miners is very small, the only possible pure equilibria are rather chaotic, with miners quitting and starting again periodically --- or there is no pure equilibrium at all. We discuss the implications of these results for the stability of proof-of-work protocols.",2019-06-17,https://www.semanticscholar.org/paper/041a0308b938fd151f92a25c2f7cefabd2c31648,ACM Conference on Economics and Computation
2514,Enabling large-scale outdoor mixed reality and augmented reality,"While there is significant recent progress in technologies supporting augmented reality for small indoor environments, there is still much work to be done for large outdoor environments. This workshop focuses primarily on research that enables high-quality outdoor Mixed Reality (MR) and Augmented Reality (AR) applications. These research topics include, but are not restricted to: — 3D geo-referenced data (images, point clouds, and models) — Algorithms for object recognition from large databases of geo-referenced data — Algorithms for object tracking in outdoor environment — Multi-cue fusion to achieve improved performance of object detection and tracking — Novel representation schemes to facilitate large-scale content distribution — 3D reasoning to support intelligent augmentation — Novel and improved mobile capabilities for data capture (device sensors), processing, and display — Applications, experiences, and user interface techniques. The workshop will also showcase existing prototypes of applications enabled by these technologies: mirror worlds, high-fidelity virtual environments, applications of panoramic imagery, and user studies relating to these media types. This workshop aims to bring together academic and industrial researchers and to foster discussion amongst participants on the current state of the art and future directions for technologies that enable large-scale outdoor MR and AR applications. The workshop will start with a session in which position statements and overviews of the state of the art are presented. In the afternoon, we will follow up with discussion sessions and a short closing session.",,https://www.semanticscholar.org/paper/dfc4eac460e342bdccbe543d8f1f4a45450fd26c,2011 10th IEEE International Symposium on Mixed and Augmented Reality
1790,Exploiting Covariate Similarity in Sparse Regression via the Pairwise Elastic Net,"A new approach to regression regularization called the Pairwise Elastic Net is proposed. Like the Elastic Net, it simultaneously performs automatic variable selection and continuous shrinkage. In addition, the Pairwise Elastic Net encourages the grouping of strongly correlated predictors based on a pairwise similarity measure. We give examples of how the approach can be used to achieve the objectives of Ridge regression, the Lasso, the Elastic Net, and Group Lasso. Finally, we present a coordinate descent algorithm to solve the Pairwise Elastic Net.",2010-03-31,https://www.semanticscholar.org/paper/d82d35c96fb2aa5980b34a6312c7caf3b772ec7c,International Conference on Artificial Intelligence and Statistics
1078,A ug 2 00 1 A Search for the Scalar Top Quark in pp̄ Collisions at √ s = 1 . 8 TeV,"We have performed a search for scalar top quark (stop) pair production in the inclusive electron-muonmissing transverse energy final state, using a sample of pp̄ events corresponding to 108.3 pb of data collected with the DØ detector at Fermilab. The search is done in the framework of the minimal supersymmetric standard model assuming that the sneutrino is the lightest supersymmetric particle. For the dominant decays of the lightest stop, t̃ → bχ̃+1 and t̃ → blν̃, no evidence for signal is found. We derive cross-section limits as a function of stop (t̃), chargino (χ̃+1 ), and sneutrino (ν̃) masses.",,https://www.semanticscholar.org/paper/3227c603c47cf9caee7cc528343ebf5979f9e327,
1488,Pion and kaon pair production in photon-photon collisions.,"We report measurements of the two-photon processes e-italic/sup +/e/sup -/..-->..e/sup +/e/sup -/..pi../sup +/..pi../sup -/ and e-italic/sup +/e/sup -/..-->..e/sup +/e/sup -/K/sup +/K/sup -/, at an e-italic/sup +/e/sup -/ center-of-mass energy of 29 GeV. In the ..pi../sup +/..pi../sup -/ data a high-statistics analysis of the f-italic(1270) results in a ..gamma gamma.. width GAMMA(..gamma gamma -->..f-italic) = 3.2 +- 0.4 keV. The ..pi../sup +/..pi../sup -/ continuum below the f-italic mass is well described by a QED Born approximation, whereas above the f-italic mass it is consistent with a QCD-model calculation if a large contribution from the f-italic is assumed. For the K-italic/sup +/K/sup -/ data we find agreement of high-mass continuum with the QCD prediction; limits on f-italic'(1520) and t-italich-italice-italict-italica-italic(1720) formation are presented.",1986-07-28,https://www.semanticscholar.org/paper/116d85e7bc8ea1690264329fa8dc044e47db2254,Physical Review Letters
2202,Heparin derivatives for the targeting of multiple activities in the inflammatory response.,,2015-03-06,https://www.semanticscholar.org/paper/ed2c34ed843411b08525a33ad8333fbc40eb16fa,Carbohydrate Polymers
2597,Evaluation of visual balance for automated layout,"Layout refers to the process of determining the size and position of the visual objects in an information presentation. We introduce the WeightMap, a bitmap representation of the visual weight of a presentation. In addition, we present algorithms that use WeightMaps to allow an automated layout system to evaluate the effectiveness of its layouts. Our approach is based on the concepts of visual weight and visual balance, which are fundamental to the visual arts. The objects in the layout are each assigned a visual weight, and a WeightMap is created that encodes the visual weight of the layout. Image-processing techniques, including pyramids and edge detection, are then used to efficiently analyze the WeightMap for balance. In addition, derivatives of the sums of the rows and columns are used to generate suggestions for how to improve the layout.",2004-01-13,https://www.semanticscholar.org/paper/3cd2864741cb892194b249de980b799bd6e91d75,International Conference on Intelligent User Interfaces
42,Query processing over relations extracted from text databases,"Text documents often embed data that is structured in nature, and this structured data is increasingly exposed using information extraction systems. Information extraction systems generate structured relations from documents, thus enabling expressive, structured queries over text databases. This dissertation studies the problem of processing structured queries over relations extracted from text databases. 
To process structured queries over text databases, we face multiple challenges. One key challenge is efficiency: information extraction is a time-consuming process, so query processing strategies should minimize the number of documents that they process. Another key challenge is output quality: information extraction systems are often far from perfect, and might output erroneous information or miss information that they should capture, hence hurting output accuracy and completeness. At the same time, query processing decisions, such as the choice of information extraction systems or document retrieval strategies, also impact the output quality. Finally, depending on the nature of the information need, users may have varying preferences regarding the execution efficiency and quality expected from the querying process. This dissertation builds on the critical observation that, in addition to efficiency, which is important just as in traditional relational query optimization, the output quality of an execution is critical. 
In our extraction-based scenario, query processing can be decomposed into a sequence of basic steps: retrieving relevant text documents, extracting relations from the documents, and joining extracted relations for queries involving multiple relations. Each of these steps presents different alternatives and together they form a space of possible query execution strategies. Our goal is to consider the user-specified requirements for execution efficiency and quality, and choose an execution strategy for each query based on a principled, cost-based comparison of the alternative execution strategies. We first introduce a simple, integrative optimization approach for processing queries involving single as well as multiple extracted relations. This approach considers each execution strategy as a whole and exploits database-specific statistics to predict the execution strategy characteristics. We then move towards an in-depth understanding of the impact of each component of an execution strategy on the overall execution. With this in mind, we rigorously analyze the critical components of an execution strategy and build statistically robust representations for information extraction systems, as well as statistical models for document retrieval strategies and join processing algorithms. These models help predict the efficiency and output quality of a variety of query execution strategies. Finally, we also consider the common scenario where information extraction systems report the extracted tuple together with scores that reflect the confidence in the correctness of the extracted tuples. Specifically, we present query processing algorithms that leverage these confidence scores and efficiently produce the high-confidence tuples, in turn discarding extracted tuples that are likely to be incorrect. 
In summary, this thesis presents a principled query optimization approach for processing structured queries over text databases, taking into consideration both the efficiency and the output quality of the query execution strategies. Our hope is that the contributions of this work will help shrink the gap between structured databases and text databases, by enabling the seamless and expressive querying of all available information, regardless of whether it is in structured databases or embedded in natural language text.",,https://www.semanticscholar.org/paper/d3fdaff1414ddc65196545cb8f4918f773e5d401,
3574,Axioms : Semantics Aspects of C + + Concepts,"This paper clarifies the semantics of “axioms” in the C++ concept proposal and provides standard wording, following the C++ committee vote and resolution at the Spring 2009 meeting at Summit, NJ.",,https://www.semanticscholar.org/paper/92b1b92973fabc863f14a51e0c6e36c150173c2e,
2942,Determining the genetic basis of anthracycline-cardiotoxicity by molecular response QTL mapping in induced cardiomyocytes,"Anthracycline-induced cardiotoxicity (ACT) is a key limiting factor in setting optimal chemotherapy regimes for cancer patients, with almost half of patients expected to ultimately develop congestive heart failure given high drug doses. However, the genetic basis of sensitivity to anthracyclines such as doxorubicin remains unclear. To begin addressing this, we created a panel of iPSC-derived cardiomyocytes from 45 individuals and performed RNA-seq after 24h exposure to varying levels of doxorubicin. The transcriptomic response to doxorubicin is substantial, with the majority of genes being differentially expressed across treatments of different concentrations and over 6000 genes showing evidence of differential splicing. Overall, our observations indicate that splicing fidelity decreases in the presence of doxorubicin. We detect 376 response-expression QTLs and 42 response-splicing QTLs, i.e. genetic variants that modulate the individual transcriptomic response to doxorubicin in terms of expression and splicing changes respectively. We show that inter-individual variation in transcriptional response is predictive of cell damage measured in vitro using a cardiac troponin assay, which in turn is shown to be associated with in vivo ACT risk. Finally, the molecular QTLs we detected are enriched in lower ACT GWAS p-values, further supporting the in vivo relevance of our map of genetic regulation of cellular response to anthracyclines.",2017-11-02,https://www.semanticscholar.org/paper/782ad77f88c99deb082727e7b8e6e6c10bf2ba65,bioRxiv
1165,Measurement of the Z ! Production Cross Section and Limits on Anomalous ZZ and Z Couplings in p p Collisions at ffiffi s p 1⁄4 1 : 96 TeV,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, M. Ahsan, G. D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G.A. Alves, M. Anastasoaie, L. S. Ancu, T. Andeen, M. S. Anzelc, M. Aoki, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, O. Atramentov, C. Avila, J. BackusMayes, F. Badaud, L. Bagby, B. Baldin, D. V. Bandurin, P. Banerjee, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, G. Blazey, S. Blessing, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, E. E. Boos, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, X. B. Bu, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, T. H. Burnett, C. P. Buszello, P. Calfayan, B. Calpas, S. Calvet, J. Cammin, M.A. Carrasco-Lizarraga, E. Carrera, W. Carvalho, B. C. K. Casey, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K.M. Chan, A. Chandra, E. Cheu, D.K. Cho, S. Choi, B. Choudhary, L. Christofek, T. Christoudias, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, V. Cuplov, D. Cutts, M. Ćwiok, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, K. DeVaughan, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, T. Dorland, A. Dubey, L. V. Dudko, L. Duflot, D. Duggan, A. Duperrin, S. Dutt, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V. D. Elvira, Y. Enari, S. Eno, P. Ermolov,38,xx M. Escalier, H. Evans, A. Evdokimov, V.N. Evdokimov, A. V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, W. Geng, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, B. Gómez, A. Goussiou, P. D. Grannis, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Harder, A. Harel, J.M. Hauptman, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, A. P. Heinson, U. Heintz, C. Hensel,22,x K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, T. Hoang, J. D. Hobbs, B. Hoeneisen, M. Hohlfeld, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, N. Huske, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, D. Jamin, C. Jarvis, R. Jesik, K. Johns, C. Johnson, M. Johnson, D. Johnston, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, D. Karmanov, P. A. Kasper, I. Katsanos, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y. N. Kharzheev, D. Khatidze, T. J. Kim, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, J.-P. Konrath, A.V. Kozelov, J. Kraus, T. Kuhl, A. Kumar, A. Kupco, T. Kurča, V. A. Kuzmin, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, W.M. Lee, A. Leflat, J. Lellouch, J. Li,77,xx L. Li, Q. Z. Li, S.M. Lietti, J. K. Lim, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna-Garcia,33,k A.L. Lyon, A.K.A. Maciel, D. Mackin, P. Mättig, A. Magerkurth, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, Y. Maravin, B. Martin, R. McCarthy, M.M. Meijer, A. Melnitchouk, L. Mendoza, P. G. Mercadante, M. Merkin, K.W. Merritt, A. Meyer, J. Meyer,22,x J. Mitrevski, R.K. Mommsen, N.K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, H. A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, D. C. O’Neil, G. Obrant, C. Ochando, D. Onoprienko, J. Orduna, N. Oshima, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, M. Padilla, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park,22,x S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma,33,{ V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, A.V. Popov, C. Potter, W. L. Prado da Silva, S. Protopopescu, J. Qian, A. Quadt,22,x B. Quinn, A. Rakitine, M. S. Rangel, K. Ranjan, P. N. Ratoff, P. Renkel, P. Rich, M. Rijssenbeek, I. Ripp-Baudot, F. Rizatdinova, S. Robinson, R. F. Rodrigues, M. Rominsky, C. Royon, P. Rubinov, R. Ruchti, G. Safronov, G. Sajot, PRL 102, 201802 (2009) P HY S I CA L R EV I EW LE T T E R S week ending 22 MAY 2009",,https://www.semanticscholar.org/paper/8314b89a4c229ebdafa70e63832d937983e79326,
1876,Industry 3.5 for Sustainable Migration and Total Resource Management,,2021-06-01,https://www.semanticscholar.org/paper/1815a4ae897a1ae8f670f43d51437c07dbb6d933,
1866,Deep learning?,"Unsupervised multilayered (""deep"") models are considered for imagery. The model is represented using a hierarchical convolutional factor-analysis construction, with sparse factor loadings and scores. The computation of layer-dependent model parameters is implemented within a Bayesian setting, employing a Gibbs sampler and variational Bayesian (VB) analysis that explicitly exploit the convolutional nature of the expansion. To address large-scale and streaming data, an online version of VB is also developed. The number of dictionary elements at each layer is inferred from the data, based on a beta-Bernoulli implementation of the Indian buffet process. Example results are presented for several image-processing applications, with comparisons to related models in the literature. Index Terms—Bayesian, deep learning, convolutional, dictionary learning, factor analysis",1999-08-28,https://www.semanticscholar.org/paper/1ababac0c6c3f3858c2d34e3ad486c9a4f388a8d,
2937,Opportunities and challenges for transcriptome-wide association studies,,2019-03-29,https://www.semanticscholar.org/paper/e7db05c36efd6aabb0bd793fda02e6f82d5a0d1d,Nature Genetics
2496,"Proceedings of 2012 IEEE Virtual Reality, VR 2012",,2012-03-04,https://www.semanticscholar.org/paper/5f1f68a854e20b63cdb8e49008bcf31d62405136,
2508,Session details: 3D,,2011-10-16,https://www.semanticscholar.org/paper/7884a516ac023687fac021242c51129cf9a20da6,Proceedings of the 24th annual ACM symposium on User interface software and technology
3170,Emergent Network Patterns of Internal Displacement in Somalia Driven by Natural Disasters and Conflicts,,,https://www.semanticscholar.org/paper/edc96599f2c3846b0d05ad1335d1f7d3e7b779ee,Social Science Research Network
745,Small Approximate Pareto Sets for Biobjective Shortest Paths and Other Problems,"We investigate the problem of computing a minimum set of solutions that approximates within a specified accuracy $\epsilon$ the Pareto curve of a multiobjective optimization problem. We show that for a broad class of biobjective problems (containing many important widely studied problems such as shortest paths, spanning tree, matching, and many others), we can compute in polynomial time an $\epsilon$-Pareto set that contains at most twice as many solutions as the minimum set. Furthermore we show that the factor of 2 is tight for these problems; i.e., it is NP-hard to do better. We present upper and lower bounds for three or more objectives, as well as for the dual problem of computing a specified number $k$ of solutions which provide a good approximation to the Pareto curve.",2009-09-01,https://www.semanticscholar.org/paper/5430943cf37c3ffbba41198ebeca45db2c99064b,SIAM journal on computing (Print)
1318,Search for the Standard Model Higgs Boson in the p p ! ZH ! b b Channel,,,https://www.semanticscholar.org/paper/62284bbfab524c5a4bf2693af1433196f1860be2,
1034,Robot-inspired biology: The compound-wave control template,"Biologically inspired robots perform many interesting and useful behaviors, but to effectively emulate their biological counterparts, robots often need to possess many degrees of freedom, complicating their mechanical design and making it difficult to apply standard control and motion planning strategies. To address this complexity, the robotics community has derived low-dimensional parameter-based controllers that naturally coordinate many degrees of freedom such as the serpenoid curves used to control snake robots. Controllers utilizing this parameterization for snake robots have been able to induce behaviors similar to that of the robots' biological counterparts. A similar concept, called a control template, is used in the study of animal movements. However, much of the prior work on control templates has been limited to in-plane motion. In this work, we extend the usage of control templates to three dimensions to both better model and understand biology, as well as to help us gain better intuition into how we can use pre-existing control paradigms to create new behaviors for biologically inspired robots.",2015-05-26,https://www.semanticscholar.org/paper/1e1a233341ae887598f352ca328e9db2531dafa7,IEEE International Conference on Robotics and Automation
2055,Thermosensitive and control release behavior of poly(N-isopropylacrylamide-co-acrylic acid)/nano-Fe3O4 magnetic composite latex particle that is synthesized by a novel method,,2008-09-01,https://www.semanticscholar.org/paper/96899eaa5372fa76cb6392cb365e3174d60e7ab5,
2292,"Stimulation of primed neutrophils by soluble immune complexes: priming leads to enhanced intracellular Ca2+ elevations, activation of phospholipase D, and activation of the NADPH oxidase.","Soluble immune complexes activate a rapid burst of reactive oxidant secretion from neutrophils that have previously been primed with GM-CSF. Binding of these complexes to the cell surface of unprimed neutrophils results in the generation of intracellular Ca2+ transients, but the NADPH oxidase fails to become activated. No phospholipase D activity was observed following the addition of soluble immune complexes to unprimed cells. Upon priming with GM-CSF, the intracellular Ca2+ signal generated following soluble complex binding was greatly extended and phospholipase D was activated: there was also increased phosphorylation of proteins on tyrosine residues and the NADPH oxidase was activated. When Ca2+ influx was prevented, this phospholipase D activity was not observed. This primed oxidase activity was completely inhibited by erbstatin. Treatment of unprimed neutrophils with pervanadate (to inhibit protein tyrosine phosphatases) mimicked the effects of priming in that pervanadate-treated neutrophils secreted reactive oxidants in response to soluble immune complexes. The data indicate that during priming a new signaling pathway is activated that involves Ca2+ influx, phosphorylation on tyrosine residues, phospholipase D activity, and NADPH oxidase activation.",1998-06-29,https://www.semanticscholar.org/paper/65b5dba8816b57993072c210fd7f968056050b39,Biochemical and Biophysical Research Communications - BBRC
1046,Measurement of the W boson mass,,2021-09-02,https://www.semanticscholar.org/paper/58f51391b829be6594a4485e8cc20879972f8454,Journal of High Energy Physics
2762,An Architecture for Knowledge-Based Graphical Interfaces,"The construction of intelligent interfaces can be greatly facilitated by classifying the information that users and programs communicate, and by separating the user interface from the functionality of a program. This paper presents a scheme for classifying this information, and show how, by structuring the interface around this scheme, the user interface and functionality of a program can be separated, and tools can be built that provide assistance to both users and developers of user interfaces.",1988-07-01,https://www.semanticscholar.org/paper/16e5b48f3b0d612643dbebaf1ab3181479a44824,SGCH
1423,High-p{sub t} jets in pbarp collisions at {radical}s = 630 and 1800 Gev,,2000-12-21,https://www.semanticscholar.org/paper/993df92cf5f6fe3d5f1856dff4980d4579fe20d1,
861,Batch sizing and job sequencing on a single machine,,1991-01-02,https://www.semanticscholar.org/paper/6bf92269b669e3a91a3f9c68256221cd7c1575ea,
2281,Insoluble and soluble immune complexes activate neutrophils by distinct activation mechanisms: changes in functional responses induced by priming with cytokines,"Background: Rheumatoid synovial fluid contains both soluble and insoluble immune complexes that can activate infiltrating immune cells such as neutrophils. Objectives: To determine if these different complexes activate neutrophils through similar or different receptor signalling pathways. In particular, to determine the circumstances which result in the secretion of tissue damaging reactive oxygen metabolites and granule enzymes. Methods: Blood neutrophils were incubated with synthetic soluble and insoluble immune complexes and the ability to generate reactive oxidants tested by luminescence or spectrophotometric assays that distinguished between intracellular and extracellular production. Degranulation of myeloperoxidase and lactoferrin was determined by western blotting. The roles of FcγRII (CD32) and FcγRIIIb (CD16) were determined by incubation with Fab/F(ab`)2 fragments before activation. The effect of cytokine priming was determined by incubation with GM-CSF. Results: Insoluble immune complexes activated unprimed neutrophils, but most of the oxidants produced were intracellular. This activation required FcγRIIIb, but not FcγRII function. Soluble complexes failed to activate unprimed neutrophils but generated a rapid and extensive secretion of reactive oxygen metabolites when the cells were primed with granulocyte-macrophage colony stimulating factor (GM-CSF). This activity required both FcγRII and FcγRIIIb function. Insoluble immune complexes activated the release of granule enzymes from primed or unprimed neutrophils, but the kinetics of release did not parallel those of secretion of reactive oxygen metabolites. Only primed neutrophils released enzymes in response to soluble complexes. Conclusions: Soluble and insoluble immune complexes activate neutrophils by separate receptor signalling pathways. Profound changes in neutrophil responsiveness to these complexes occur after cytokine priming.",2002-01-01,https://www.semanticscholar.org/paper/cb0e2af4ca3e48dc9d1be6c49ec99b30b0c033fa,Annals of the Rheumatic Diseases
986,Safety of Nonporous Silica Nanoparticles in Human Corneal Endothelial Cells,,2017-11-06,https://www.semanticscholar.org/paper/574d89f32f6d089c702b775973da63ba5c45bc50,Scientific Reports
1681,Risk prediction for chronic kidney disease progression using heterogeneous electronic health record data and time series analysis,"Abstract Background As adoption of electronic health records continues to increase, there is an opportunity to incorporate clinical documentation as well as laboratory values and demographics into risk prediction modeling. Objective The authors develop a risk prediction model for chronic kidney disease (CKD) progression from stage III to stage IV that includes longitudinal data and features drawn from clinical documentation. Methods The study cohort consisted of 2908 primary-care clinic patients who had at least three visits prior to January 1, 2013 and developed CKD stage III during their documented history. Development and validation cohorts were randomly selected from this cohort and the study datasets included longitudinal inpatient and outpatient data from these populations. Time series analysis (Kalman filter) and survival analysis (Cox proportional hazards) were combined to produce a range of risk models. These models were evaluated using concordance, a discriminatory statistic. Results A risk model incorporating longitudinal data on clinical documentation and laboratory test results (concordance 0.849) predicts progression from state III CKD to stage IV CKD more accurately when compared to a similar model without laboratory test results (concordance 0.733, P<.001), a model that only considers the most recent laboratory test results (concordance 0.819, P < .031) and a model based on estimated glomerular filtration rate (concordance 0.779, P < .001). Conclusions A risk prediction model that takes longitudinal laboratory test results and clinical documentation into consideration can predict CKD progression from stage III to stage IV more accurately than three models that do not take all of these variables into consideration.",2015-04-20,https://www.semanticscholar.org/paper/6fc46455b6294aa2dd5e25d206a259aecdf7065b,J. Am. Medical Informatics Assoc.
2916,Influence of Microstructure on Synchrotron X-ray Diffraction Lattice Strain Measurement Uncertainty,"Accurate residual lattice strain measurements are highly dependent upon the precision of the diffraction peak location and the underlying microstructure suitability. The suitability of the microstructure is related to the requirement for valid powder diffraction sampling statistics and the associated number of appropriately orientated illuminated. In this work, these two sources of uncertainty are separated, and a method given for both the quantification of errors associated with insufficient grain sampling statistics and minimization of the total lattice strain measurement uncertainty. It is possible to reduce the total lattice strain measurement uncertainty by leveraging diffraction peak measurements made at multiple azimuthal angles. Lattice strain measurement data acquired during eight synchrotron X-ray diffraction experiments, monochromatic and energy dispersive, has been assessed as per this approach, with microstructural suitability being seen to dominate total measurement uncertainty when the number of illuminated grains was <106. More than half of the studied experimental data fell into this category, with a severe underestimation of total strain measurement uncertainty being possible when microstructural suitability is not considered. To achieve a strain measurement uncertainty under 10−4, approximately 3×105 grains must be within the sampled gauge volume, with this value varying with the multiplicity of the family of lattice planes under study. Where additional azimuthally arrayed data are available an in-plane lattice strain tensor can be extracted. This improves overall strain measurement accuracy and an uncertainty under 10−4 can then be achieved with just 4×104 grains.",2021-05-09,https://www.semanticscholar.org/paper/50c2af35e2abc3070b203faf01fda465beebc9bc,Metals
1552,Identifiable Variational Autoencoders via Sparse Decoding,"We develop the Sparse VAE, a deep generative model for unsupervised representation learning on high-dimensional data. Given a dataset of observations, the Sparse VAE learns a set of latent factors that captures its distribution. The model is sparse in the sense that each feature of the dataset (i.e., each dimension) depends on a small subset of the latent factors. As examples, in ratings data each movie is only described by a few genres; in text data each word is only applicable to a few topics; in genomics, each gene is active in only a few biological processes. We first show that the Sparse VAE is identifiable: given data drawn from the model, there exists a uniquely optimal set of factors. (In contrast, most VAE-based models are not identifiable.) The key assumption behind Sparse-VAE identifiability is the existence of “anchor features”, where for each factor there exists a feature that depends only on that factor. Importantly, the anchor features do not need to be known in advance. We then show how to fit the Sparse VAE with variational EM. Finally, we empirically study the Sparse VAE with both simulated and real data. We find that it recovers meaningful latent factors and has smaller heldout reconstruction error than related methods.",,https://www.semanticscholar.org/paper/fdb74161249e7d787c9b641afcacd248af71c48d,arXiv.org
1762,An Approach to Discovery and Re-ranking of Educational content from the World Wide Web using Latent Dirichlet Allocation,"With tremendous increase in the amount of digital data available educators are forced to author content for learning and teaching for use in their classes. With that there has emerged a need to facilitate automatic discovery of learning resources from the World Wide Web. In this work, we present a novel approach for discovering content from the web for e-learning. We argue that for an e-learning scenario, retrieval of the redundant content from the web is a serious problem to be addressed as it does not satisfy the requirements of a typical learner. Furthermore, the content retrieved should cover all topics as in his syllabus. Sense-disambiguation should be performed during information retrieval from the web so that it corresponds to the learner‟s actual domain of interest. This work presents a domain ontology based re-querying approach for query expansion to discover content from open corpus sources. We use the Latent Dirichlet Allocation Model for unsupervised classification of document segments to aid students and educators. Having identified the topics at the granularity of document segments in an unsupervised fashion, we state that internal topic transitions in a resource retrieved from the web can be exploited for providing relevant and personalized content. In addition to this, we propose a re-ranking scheme for ordering results from search engines to maximize topic coverage and minimize redundancy among retrieved results. We also evaluate the effectiveness of our proposed method for information retrieval and show that our work results in greater coverage of topics from the web without redundancy.",2011-06-15,https://www.semanticscholar.org/paper/19a40edd529a857db684843f738de13f7be6b09c,
2643,Recent Advances in Augmented Reality,"In 1997, Azuma published a survey on augmented reality (AR). Our goal is to complement, rather than replace, the original survey by presenting representative examples of the new advances. We refer one to the original survey for descriptions of potential applications (such as medical visualization, maintenance and repair of complex equipment, annotation, and path planning); summaries of AR system characteristics (such as the advantages and disadvantages of optical and video approaches to blending virtual and real, problems in display focus and contrast, and system portability); and an introduction to the crucial problem of registration, including sources of registration error and error-reduction strategies.",2001-11-01,https://www.semanticscholar.org/paper/408b6295e901e3e6d96b55a69ca6f6eda762891e,IEEE Computer Graphics and Applications
3265,Coping with transition: offspring risk and maternal behavioural changes at the end of the hiding phase,,2015-11-01,https://www.semanticscholar.org/paper/fcd51857b0b426b2f6a7bd995d8dce0730f4916d,Animal Behaviour
1460,Test of spin dependence in charm-quark fragmentation to D*,"We have measured the polarization of {ital D}{sup *}, the energy dependence of the polarization, and the spin-density matrix of {ital D}{sup *} in {ital e}{sup +}{ital e{minus}} annihilation at a center-of-mass energy of 29 GeV using the Time Projection Chamber detector at the SLAC storage ring PEP. In 147 pb{sup {minus}1} of data we see no strong evidence for polarization, alignment, or final-state interactions in this fragmentation process.",,https://www.semanticscholar.org/paper/11375838762daec290b9c8c70c71fcf5501241d0,"Physical Review D, Particles and fields"
1666,Posterior Dispersion Indices,"Probabilistic modeling is cyclical: we specify a model, infer its posterior, and evaluate its performance. Evaluation drives the cycle, as we revise our model based on how it performs. This requires a metric. Traditionally, predictive accuracy prevails. Yet, predictive accuracy does not tell the whole story. We propose to evaluate a model through posterior dispersion. The idea is to analyze how each datapoint fares in relation to posterior uncertainty around the hidden structure. We propose a family of posterior dispersion indices (PDI) that capture this idea. A PDI identifies rich patterns of model mismatch in three real data examples: voting preferences, supermarket shopping, and population genetics.",2016-05-24,https://www.semanticscholar.org/paper/d952453fc406a13ddac04c8d408a556c37f7baa1,arXiv.org
1512,Evaluating the Moral Beliefs Encoded in LLMs,"This paper presents a case study on the design, administration, post-processing, and evaluation of surveys on large language models (LLMs). It comprises two components: (1) A statistical method for eliciting beliefs encoded in LLMs. We introduce statistical measures and evaluation metrics that quantify the probability of an LLM""making a choice"", the associated uncertainty, and the consistency of that choice. (2) We apply this method to study what moral beliefs are encoded in different LLMs, especially in ambiguous cases where the right choice is not obvious. We design a large-scale survey comprising 680 high-ambiguity moral scenarios (e.g.,""Should I tell a white lie?"") and 687 low-ambiguity moral scenarios (e.g.,""Should I stop for a pedestrian on the road?""). Each scenario includes a description, two possible actions, and auxiliary labels indicating violated rules (e.g.,""do not kill""). We administer the survey to 28 open- and closed-source LLMs. We find that (a) in unambiguous scenarios, most models""choose""actions that align with commonsense. In ambiguous cases, most models express uncertainty. (b) Some models are uncertain about choosing the commonsense action because their responses are sensitive to the question-wording. (c) Some models reflect clear preferences in ambiguous scenarios. Specifically, closed-source models tend to agree with each other.",2023-07-26,https://www.semanticscholar.org/paper/12acdfc7e32e9d603dc108008bb15e65439e7c79,arXiv.org
2734,Hybrid user interfaces: breeding virtually bigger interfaces for physically smaller computers,"While virtual worlds offer a compelling alternative to conventional interfaces, the technologies these systems currently use do not provide sufficient resolution and accuracy to support detailed work such as text editing. We describe a pragmatic approach to interface design that provides users with a large virtual world in which such high-resolution work can be performed. Our approach is based on combining heterogeneous display and interaction device technologies to produce a hybrid user interface. Display and interaction technologies that have relatively low resolution, but which cover a wide (visual and interactive) field are used to form an information surround. Display and interaction technologies that have relatively high resolution over a limited visual and interaction range are used to present concentrated information in one or more selected portions of the surround. These high-resolution fields are embedded within the low-resolution surround by choosing and coordinating complementary devices that permit the user to see and interact with both simultaneously. This allows each embedded high-resolution interface to serve as a “sweet spot” within which intonation may be preferentially processed, We have developed a preliminary implementation, described in this paper, that uses a Reflection Technology Private Eye display and a Polhemus sensor to provide the secondary low-resohttion surround, and a flat-panel display and mouse to provide the primary high-resolution interface.",1991-11-11,https://www.semanticscholar.org/paper/1ae17e45e8b32969a3127400eb6525d2ccd93c3a,ACM Symposium on User Interface Software and Technology
3710,Full-Body Visual Self-Modeling of Robot Morphologies,"Internal computational models of physical bodies are fundamental to the ability of robots and animals alike to plan and control their actions. These""self-models""allow robots to consider outcomes of multiple possible future actions, without trying them out in physical reality. Recent progress in fully data-driven self-modeling has enabled machines to learn their own forward kinematics directly from task-agnostic interaction data. However, forward-kinema\-tics models can only predict limited aspects of the morphology, such as the position of end effectors or velocity of joints and masses. A key challenge is to model the entire morphology and kinematics, without prior knowledge of what aspects of the morphology will be relevant to future tasks. Here, we propose that instead of directly modeling forward-kinematics, a more useful form of self-modeling is one that could answer space occupancy queries, conditioned on the robot's state. Such query-driven self models are continuous in the spatial domain, memory efficient, fully differentiable and kinematic aware. In physical experiments, we demonstrate how a visual self-model is accurate to about one percent of the workspace, enabling the robot to perform various motion planning and control tasks. Visual self-modeling can also allow the robot to detect, localize and recover from real-world damage, leading to improved machine resiliency. Our project website is at: https://robot-morphology.cs.columbia.edu/",2021-11-11,https://www.semanticscholar.org/paper/42908b31098fd6760fc35e23e77c9c6d3b03e4f9,arXiv.org
2848,Kinetics of mobilization and differentiation of lymphohematopoietic cells during experimental murine schistosomiasis in galectin‐3−/− mice,"Galectin‐3 (gal‐3), a β‐galactoside‐binding animal lectin, plays a role in cell‐cell and cell‐extracellular matrix interactions. Extracellular gal‐3 modulates cell migration and adhesion in several physiological and pathological processes. Gal‐3 is highly expressed in activated macrophages. Schistosoma mansoni eggs display a large amount of gal‐3 ligands on their surface and elicit a well‐characterized, macrophage‐dependent, granulomatous, inflammatory reaction. Here, we have investigated the acute and chronic phases of S. mansoni infection in wild‐type and gal‐3−/− mice. In the absence of gal‐3, chronic‐phase granulomas were smaller in diameter, displaying thinner collagen fibers with a loose orientation. Schistosoma‐infected gal‐3−/− mice had remarkable changes in the monocyte/macrophage, eosinophil, and B lymphocyte subpopulations as compared with the infected wild‐type mice. We observed a reduction of macrophage number, an increase in eosinophil absolute number, and a decrease in B lymphocyte subpopulation (B220+/high cells) in the periphery during the evolution of the disease in gal‐3−/− mice. B lymphopenia was followed by an increase of plasma cell number in bone marrow, spleen, and mesenteric lymph nodes of the infected gal‐3−/− mice. The plasma IgG and IgE levels also increased in these mice. Gal‐3 plays a role in the organization, collagen distribution, and mobilization of inflammatory cells to chronic‐phase granulomas, niches for extramedullary myelopoiesis, besides interfering with monocyte‐to‐macrophage and B cell‐to‐plasma cell differentiation.",2007-08-01,https://www.semanticscholar.org/paper/34bcb9acea990f5c50fda2281fd96064c0ae1717,Journal of Leukocyte Biology
2258,Turnover of Mcl-1 Caspase-DependentApoptosis by Stimulating Sodium Salicylate Promotes Neutrophil,"Mcl-1 is an antiapoptotic member of the Bcl-2 family of proteins that plays a central role in cell survival of neutrophils and other cells. The protein is unusual among family members in that it has a very short half-life of 2–3 h. In this report, we show that sodium salicylate (at 10 mM) greatly enhances the rate at which neutrophils undergo apoptosis and, in parallel, greatly accelerates the turnover rate of Mcl-1, decreasing its half-life to only 90 min. Whereas constitutive and GM-CSF-modiﬁed Mcl-1 turnover is regulated by the proteasome, the accelerated sodium salicylate-induced Mcl-1 turnover is mediated largely via caspases. Sodium salicylate resulted in rapid activation of caspase-3, -8, -9, and -10, and salicylate-accelerated Mcl-1 turnover was partly blocked by caspase inhibitors. Sodium salicylate also induced dramatic changes in the activities of members of the MAPK family implicated in Mcl-1 turnover and apoptosis. For example, sodium salicylate blocked GM-CSF-stimulated Erk and Akt activation, but resulted in rapid and sustained activation of p38-MAPK, an event mimicked by okadaic acid that also accelerates Mcl-1 turnover and neutrophil apoptosis. These data thus shed important new insights into the dynamic and highly regulated control of neutrophil apoptosis that is effected by modiﬁcation in the rate of Mcl-1 turnover. The Journal of Immunology, 2006, 176: 957–965.",,https://www.semanticscholar.org/paper/c21cc32e49021ebf0c43421873258a7fbade1d7b,
1930,Exploit the Value of Production Data to Discover Opportunities for Saving Power Consumption of Production Tools,"Semiconductor industry is both technology and energy intensive. There is a critical need to develop effective ways for energy saving to support smart and green production. This paper aims to develop data mining approach based on neural networks to exploit the value of production data and derive improvement directions for energy saving. In particular, the power consumption per wafer processed step (kilowatt hour per move, kwh/move) of individual production tool sets can be estimated, in which the relationships between kwh/move and 19 individual input factors, including “lot size,” “process time,” “uptime,” “usable machine,” “Q-time constrain,” and “sampling rate” are derived. An empirical study was conducted in a leading wafer fab and the results have shown practical viability of the proposed approach to discover effective opportunities for saving 17.21% power consumption by production tool sets.",2016-12-01,https://www.semanticscholar.org/paper/0b9a274631707af50afa0088e6a97eb28db8939b,IEEE transactions on semiconductor manufacturing
1323,Search for pair production of second generation scalar leptoquarks in pp̄ collisions at √ s = 1 . 96 TeV,"We report on a search for the pair production of second generation scalar leptoquarks (LQ2) in pp̄ collisions at the center-of-mass energy √ s = 1.96 TeV, using data corresponding to an integrated luminosity of 294 ± 19 pb−1 recorded with the DØ detector. No evidence for a leptoquark signal in the LQ2LQ2 → μqμq channel has been observed, and upper bounds on the product of cross section times branching fraction were set. This yields lower mass limits of mLQ2 > 247 GeV/c 2 for β = B(LQ2 → μq) = 1 and mLQ2 > 182 GeV/c2 for β = 1/2. Combining these limits with previous DØ results, the lower limits on the mass of a second generation scalar leptoquark are mLQ2 > 251 GeV/c 2 and mLQ2 > 204 GeV/c 2 for β = 1 and β = 1/2, respectively. © 2006 Elsevier B.V. PACS: 14.80.-j; 13.85.Rm",,https://www.semanticscholar.org/paper/aa54e5ae7f203260b296dba7c50dcc7304d6fe77,
2616,Using Prosodic Features of Speech and Audio Localization in Graphical User Interfaces,"We describe several approaches for using prosodic features of speech and audio localization to control interactive applications. This information can be used for parameter control, as well as for disambiguating speech recognition. We discuss how characteristics of the spoken sentences can be exploited in the user interface; for example, by considering the speed with which the sentence was spoken and the presence of extraneous utterances. We also show how coarse audio localization can be used for low-fidelity gesture tracking, by inferring the speaker's head position.",,https://www.semanticscholar.org/paper/4beed9063e45dc4f6f3c48ea84f8431689e86510,
1238,Measurement of the Forward‐Backward Charge Asymmetry in Top‐Quark Pair Production in Proton‐Antiproton Collisions at DO/,"A measurement of the forward‐backward charge asymmetry in top‐antitop (tt) pair production in proton‐antiproton (pp) collisions is presented. The asymmetry is measured for different jet multiplicities in the lepton+jets final state on 0.9 fb−1 of data collected by the DO/ experiment at the Fermilab Tevatron Collider. The result is sensitive to new physics, which is demonstrated by setting an upper limit on tt production via heavy neutral gauge bosons (Z′).",2008-10-27,https://www.semanticscholar.org/paper/8c0396f1e3fa0bbac57b705a834ffc1c4dd53314,
1836,"Index of authors, volume 170, 2007",,2007-10-01,https://www.semanticscholar.org/paper/f6990f3cfe5828cbcd6c431b24f921e20f83a57c,
2088,Cycle time prediction and control based on production line status and manufacturing data mining,"This study aims to develop a methodology for predicting cycle time based on domain knowledge and data mining algorithms given production status including WIP, throughput. The proposed model and derived rules were validated with real data and demonstrated its practical viability for supporting production planning decisions",2005-10-03,https://www.semanticscholar.org/paper/c712e24165e0c84351292357d1e2c7e8e22a0a46,"ISSM 2005, IEEE International Symposium on Semiconductor Manufacturing, 2005."
2991,Infinite Sparse Factor Analysis and Infinite Independent Components Analysis,,2007-09-09,https://www.semanticscholar.org/paper/76e171e8de3fe77d4532ed235e0a0669e420b782,International Conference on Agents
632,The complexity of the capacitated tree problem,"We examine the complexity of a classical problem related to the design of centralized computer networks. Under very broad assumptions the problem is shown to be NP-complete, and hence most probably intractable. The same result holds for the “Euclidean” case of the problem; however, in the latter case a simple algorithm produces solutions with relative error almost certainly arbitrarily close to zero.",1978-09-01,https://www.semanticscholar.org/paper/44119d4db050c65e4156ec1b43cb6c7a85d531a6,Networks
2265,arthritis . neutrophils from patients with rheumatoid Receptor expression in synovial fluid,"Objectives-The aim of this study was to determine if neutrophils isolated from the blood and synovial fluid of patients with rheumatoid arthritis had patterns of receptor expression resembling those of blood neutrophils from controls which had been activated and primed in vitro. Methods-Fluorescence activated cell sorting was used to measure receptor expression in paired blood and synovial fluid neutrophils from patients and in control neutrophils exposed to phorbol myristate acetate and granulocytemacrophage colony stimulating factor. Results-There was no significant difference in the patterns of receptor expression in blood neutrophils from patients and healthy controls, but neutrophils in the synovial fluid had been primed and activated within the joint. About 50% of rheumatoid synovial fluid neutrophil samples expressed Fcy RI, a high affinity receptor for monomeric IgG, which is only expressed in neutrophils exposed to cytokines. Conclusions-Synovial fluid neutrophils are activated and primed within the inflamed joint and hence their ability to respond to activating factors such as immune complexes will be modulated. As the expression of Fcy RI requires active biosynthesis, this work indicates that selective gene activation occurs when neutrophils are recruited into rheumatoid joints. (Ann Rheum Dis 1993; 52: 354-359) Department of Biochemistry, University of Liverpool, PO Box 147, Liverpool L69 3BX, United Kingdom F Watson J J Robinson S W Edwards Rheumatic Diseases Unit, Royal Liverpool Hospital, Prescott Road, Liverpool L69 3BX, United Kingdom M Phelan R C Bucknall Correspondence to: Dr Edwards. Accepted for publication 30 December 1992 During the active phase of rheumatoid arthritis (RA), neutrophils constitute between 60 and 80% of the total cell population of synovial fluid.' Neutrophils are cells of considerable cytotoxic potential and their inappropriate activation has been implicated in the pathogenesis of RA, perhaps through the generation of reactive oxygen metabolites such as hydrogen peroxide.2 Tissue damage may be promoted indirectly by the extracellular leakage of toxic products from accumulated neutrophils.3 Indeed, oxidant damaged products are present in synovial fluid4 and the oxidase function of neutrophils isolated from synovial fluid has been downregulated, indicating that reactive oxidant generation has been activated in vivo.5 Furthermore, synovial fluid from patients with RA contains myeloperoxidase in a molecular form indicating that it has been co-secreted from neutrophils concomitant with reactive oxidants.6 The mechanisms by which neutrophils are activated within rheumatoid joints and the synovial fluid factors which result in such activation are incompletely defined. The function of neutrophils in vivo is regulated by the levels of expression of specific plasma membrane receptors including those for complement components (CR1 and CR3) and IgG molecules (Fc RI, II, and III). On cellular activation the complement receptors are upregulated whereas Fc RIII is shed from the surface of the cell7 8: Fc RII expression remains constant after cell activation whereas Fc RI is only expressed after in vitro culture of the neutrophils with interferon y.' Neutrophil function is also regulated by the activities of cytokines such as granulocyte-macrophage colony stimulating factor (GM-CSF), tumour necrosis factor, and interferon y which prime the cells into a state of enhanced responsiveness. On priming, reactive oxidant production is increased together with the levels of expression of several surface receptors.'0-12 As such cytokines have been found in the synovial fluid of patients with RA,'3 it is likely that these or other similarly acting agents will upregulate neutrophil function in situ within inflamed joints. In this work we studied the expression of neutrophil plasma membrane receptors using monoclonal antibodies and fluorescence activated cell sorting (FACS) analysis in paired bloodstream and synovial fluid neutrophils from patients with RA. We propose that the changes in membrane expression observed in synovial fluid neutrophils may be caused by the presence of activating factors, perhaps functioning in combination with cytokines within the synovial fluid, to modulate neutrophil responsiveness. Subjects and methods",,https://www.semanticscholar.org/paper/d79709e5baae838c17535a52d3db3f978ff152db,
2359,Gene expression in human neutrophils,,1989-08-01,https://www.semanticscholar.org/paper/887bd23c4fceb0fe7ae6169f66d037a3c993cbf5,
2901,2: Comparison of Factor Products for Treatment of Bleeding Related to Cardiac Surgery,,2022-12-15,https://www.semanticscholar.org/paper/0b2993bc879c74afdb866f6632e4b646b34ff2d8,Critical Care Medicine
1917,Soft computing for smart production to empower industry 4.0,,2018-07-01,https://www.semanticscholar.org/paper/da180a0159e7bf7860fefc23ff036ed5c912f888,Applied Soft Computing
3452,A Case for P2P Delivery of Paid Content,"P2P file sharing provides a powerful content distribution model by leveraging users’ computing and bandwidth resources. However, companies have been reluctant to rely on P2P systems for paid content distribution due to their inability to limit the exploitation of these systems for free file sharing. We present TP2, a system that combines the more cost-effective and scalable distribution capabilities of P2P systems with a level of trust and control over content distribution similar to direct download content delivery networks. TP2 uses two key mechanisms that can be layered on top of existing P2P systems. First, it provides strong authentication to prevent free file sharing in the system. Second, it introduces a new notion of trusted auditors to detect and limit malicious attempts to gain information about participants in the system to facilitate additional out-of-band free file sharing. We analyze TP2 by modeling it as a novel game between malicious users who try to form free file sharing clusters and trusted auditors who curb the growth of such clusters. Our analysis shows that a small fraction of trusted auditors is sufficient to protect the P2P system against unauthorized file sharing. Using a simple economic model, we further show that TP2 provides a more cost-effective content distribution solution, resulting in higher profits for a content provider even in the presence of a large percentage of malicious users. Finally, we implemented TP2 on top of BitTorrent and use PlanetLab to show that our system can provide trusted P2P file sharing with negligible performance overhead.",,https://www.semanticscholar.org/paper/fa5f774097555dd29f7cbb8b47003e239b1d9375,
2233,Endothelial activation and apoptosis mediated by neutrophil-dependent interleukin 6 trans-signalling: a novel target for systemic sclerosis?,"Objectives Systemic sclerosis (SSc) is a connective tissue disease associated with significant morbidity and mortality and generally inadequate treatment. Endothelial cell activation and apoptosis are thought to be pivotal in the pathogenesis of this disease, but the mechanisms that mediate this remain unknown. Methods Human dermal microvascular endothelial cells were cultured with healthy control neutrophils in the presence of 25% healthy control or SSc serum for 24 h. Apoptosis was measured by annexin V-FITC binding and endothelial cell activation was measured using an allophycocyanin-conjugated E-selectin antibody. Fluorescence was quantified and localised using confocal microscopy. Results SSc serum resulted in significantly increased apoptosis (p=0.006) and E-selectin expression (p=0.00004) in endothelial cells compared with control serum, effects that were critically dependent on the presence of neutrophils. Recombinant interleukin 6 (IL-6) reproduced these findings. Immunodepletion of IL-6 and the use of an IL-6 neutralising antibody decreased the effect of SSc serum on E-selectin expression. Soluble gp130, which specifically blocks IL-6 trans-signalling, negated the effect of SSc serum on both E-selectin expression and apoptosis. Conclusions SSc serum induces endothelial cell activation and apoptosis in endothelial cell-neutrophil co-cultures, mediated largely by IL-6 and dependent on the presence of neutrophils. Together with other pathologically relevant effects of IL-6, these data justify further exploration of IL-6 as a therapeutic target in SSc.",2010-11-10,https://www.semanticscholar.org/paper/cd75421afe179f795b6653e4d2726af8be79b410,Annals of the Rheumatic Diseases
386,Deciding stability and mortality of piecewise affine dynamical systems,,2001-03-28,https://www.semanticscholar.org/paper/67ff0a9fa5a1973d7f37178461d47acfd857c35a,Theoretical Computer Science
3577,Model-Based Product-Oriented Certification,"Future space missions such as the Mars Science Laboratory and Project Constellation suggest the engineering of some of the most complex man-rated software systems. The present process-oriented certification methodologies employed by NASA are becoming prohibitively expensive when applied to systems of such complexity. The process of software certification establishes the level of confidence in a software system in the context of its functional and safety requirements. Providing such certification evidence may require the application of a number of software development, analysis, and validation techniques. We define product-oriented certification as the process of measuring the system's reliability and efficiency based on the analysis of its design (expressed in models) and implementation (expressed in source code). In this work we introduce a framework for model-based product-oriented certification founded on the concept of source code enhancement and analysis. We describe a classification of the certification artifact types, the development and validation tools and techniques, the application domain-specific factors, and the levels of abstraction. We demonstrate the application of our certification platform by analyzing the process of model-based development of the parallel autonomic goals network, a critical component of the Jet Propulsion Laboratory's Mission Data System (MDS). We describe how we identify and satisfy seven critical certification artifacts in the process of model-driven development and validation of the MDS goal network. In the analysis of this process, we establish the relationship among the seven certification artifacts, the applied development and validation techniques and tools, and the level of abstraction of system design and development.",2009-04-14,https://www.semanticscholar.org/paper/e2e096fad3938c426a886c32853e04f24fbcdf55,European Conference on the Engineering of Computer-Based Systems
3230,Moving in the Anthropocene: Global reductions in terrestrial mammalian movements,"Restrictions on roaming Until the past century or so, the movement of wild animals was relatively unrestricted, and their travels contributed substantially to ecological processes. As humans have increasingly altered natural habitats, natural animal movements have been restricted. Tucker et al. examined GPS locations for more than 50 species. In general, animal movements were shorter in areas with high human impact, likely owing to changed behaviors and physical limitations. Besides affecting the species themselves, such changes could have wider effects by limiting the movement of nutrients and altering ecological interactions. Science, this issue p. 466 Human alterations of the landscape shorten the distances traveled by individual animals. Animal movement is fundamental for ecosystem functioning and species survival, yet the effects of the anthropogenic footprint on animal movements have not been estimated across species. Using a unique GPS-tracking database of 803 individuals across 57 species, we found that movements of mammals in areas with a comparatively high human footprint were on average one-half to one-third the extent of their movements in areas with a low human footprint. We attribute this reduction to behavioral changes of individual animals and to the exclusion of species with long-range movements from areas with higher human impact. Global loss of vagility alters a key ecological trait of animals that affects not only population persistence but also ecosystem processes such as predator-prey interactions, nutrient cycling, and disease transmission.",2018-01-26,https://www.semanticscholar.org/paper/b61897cfc5e3ae33ed81b3f961417347626125dc,Science
1894,Big Data Analytics for Tool Health Monitoring in Panel Industry,"Tool health monitoring and maintenance has become a more challenge issue for big data recently and is extremely essential in today's highly competitive environment in industry. Good monitoring approach and right maintenance strategy will be a great benefit to the company for reducing the cost and prolong the useful life of machines. Related researches have been studied based on different methods and approaches for investigating the health status of machines in many fields. In this study, we provide a data mining framework for monitoring the tool heal status under the partial least squares approach as we as the control chart construction. A real data from panel industry is applied to demonstrate our proposed research.",2019-04-01,https://www.semanticscholar.org/paper/558c25fd8798211737f776dfdffc1c2e78b71fb7,3D Structure from Multiple Images of Large-Scale Environments
1163,Search for associated W and Higgs Boson production in pp[over ] collisions at sqrt[s]=1.96 TeV.,"We present results of a search for WH-->lnubb[over ] production in pp[over ] collisions based on the analysis of 1.05 fb;{-1} of data collected by the D0 experiment at the Fermilab Tevatron, using a neural network for separating the signal from backgrounds. No signal-like excess is observed, and we set 95% C.L. upper limits on the WH production cross section multiplied by the branching ratio for H-->bb[over ] for Higgs boson masses between 100 and 150 GeV. For a mass of 115 GeV, we obtain an observed (expected) limit of 1.5 (1.4) pb, a factor of 11.4 (10.7) times larger than the standard model prediction.",,https://www.semanticscholar.org/paper/81a3201a97071bf492a880aa49bd34b155cc5f53,Physical Review Letters
2598,Personalized Digital Television,,,https://www.semanticscholar.org/paper/3f8f98c12a335c25c7a0ce434efca47490018aed,Human-Computer Interaction Series
3445,Vertex Cover Approximations on Random Graphs,,2007-06-06,https://www.semanticscholar.org/paper/d7819eedee684d961669d7623a6b81ab247653be,Workshop on Engineering Applications
3633,Library design using C,,1996-05-01,https://www.semanticscholar.org/paper/bce8510c9abb787ba0d7f1f8ec009318604aea54,
2951,Small RNA Sequencing in Cells and Exosomes Identifies eQTLs and 14q32 as a Region of Active Export,"Exosomes are small extracellular vesicles that carry heterogeneous cargo, including RNA, between cells. Increasing evidence suggests that exosomes are important mediators of intercellular communication and biomarkers of disease. Despite this, the variability of exosomal RNA between individuals has not been well quantified. To assess this variability, we sequenced the small RNA of cells and exosomes from a 17-member family. Across individuals, we show that selective export of miRNAs occurs not only at the level of specific transcripts, but that a cluster of 74 mature miRNAs on chromosome 14q32 is massively exported in exosomes while mostly absent from cells. We also observe more interindividual variability between exosomal samples than between cellular ones and identify four miRNA expression quantitative trait loci shared between cells and exosomes. Our findings indicate that genomically colocated miRNAs can be exported together and highlight the variability in exosomal miRNA levels between individuals as relevant for exosome use as diagnostics.",2016-10-31,https://www.semanticscholar.org/paper/c83b96bac22d0c89857e80e38f69aa8bdad370c8,"G3: Genes, Genomes, Genetics"
3190,A new classification of mammalian uni-male multi-female groups based on the fundamental principles governing inter- and intrasexual relationships,,2021-11-01,https://www.semanticscholar.org/paper/4a1be45eacc753291d3153ac04b1d0772da623a1,Behavioral Ecology and Sociobiology
3046,Teaching operating systems using android,"The computing landscape is shifting towards mobile devices. To learn about operating systems, it is increasingly important for students to gain hands-on kernel programming experience in these environments, which are quite different from traditional desktops and servers. We present our work at Columbia University to teach operating systems using Android, an open, commercially supported software platform increasingly used on mobile and embedded devices. We introduce a series of five Android kernel programming projects suitable for a one semester introductory operating systems course. Each project teaches a core operating system concept infused with Android or mobile device specific context, such as Android specific process relationships, use of sensors, and design considerations for resource constrained mobile devices. We also introduce an Android virtual laboratory based on virtual appliances, distributed version control, and live demonstrations which gives students hands-on Android experience, with minimal computing infrastructure. We have used these Android kernel programming projects and the Android virtual lab to teach an introductory operating systems course. Although this was our first time teaching the course using Android, over 80% of students surveyed enjoyed using Android and the majority of students preferred Android to traditional desktop development.",2012-02-29,https://www.semanticscholar.org/paper/f9a2301ba2cb93e2abb012ee9ac511cbe82169dd,Technical Symposium on Computer Science Education
1145,Measurement of trilinear gauge boson couplings from WW þ WZ ! l jj events in p p collisions at ffiffi s p 1⁄4 1 : 96 TeV,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, M. Ahsan, G.D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G. A. Alves, L. S. Ancu, M. S. Anzelc, M. Aoki, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, O. Atramentov, C. Avila, J. BackusMayes, F. Badaud, L. Bagby, B. Baldin, D. V. Bandurin, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V.A. Bezzubov, P. C. Bhat, V. Bhatnagar, G. Blazey, S. Blessing, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, E. E. Boos, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, X. B. Bu, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, T. H. Burnett, C. P. Buszello, P. Calfayan, B. Calpas, S. Calvet, J. Cammin, M.A. Carrasco-Lizarraga, E. Carrera, W. Carvalho, B. C. K. Casey, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K.M. Chan, A. Chandra, E. Cheu, D. K. Cho, S.W. Cho, S. Choi, B. Choudhary, T. Christoudias, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, D. Cutts, M. Ćwiok, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, K. DeVaughan, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, T. Dorland, A. Dubey, L. V. Dudko, L. Duflot, D. Duggan, A. Duperrin, S. Dutt, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V. D. Elvira, Y. Enari, S. Eno, M. Escalier, H. Evans, A. Evdokimov, V.N. Evdokimov, G. Facini, A. V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, W. Geng, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, B. Gómez, A. Goussiou, P. D. Grannis, S. Greder, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Harder, A. Harel, J.M. Hauptman, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, A. P. Heinson, U. Heintz, C. Hensel, I. Heredia-De La Cruz, K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, T. Hoang, J. D. Hobbs, B. Hoeneisen, M. Hohlfeld, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, N. Huske, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, D. Jamin, R. Jesik, K. Johns, C. Johnson, M. Johnson, D. Johnston, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, D. Karmanov, P. A. Kasper, I. Katsanos, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y. N. Kharzheev, D. Khatidze, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, J.-P. Konrath, A.V. Kozelov, J. Kraus, T. Kuhl, A. Kumar, A. Kupco, T. Kurča, V. A. Kuzmin, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, H. S. Lee, W.M. Lee, A. Leflat, J. Lellouch, L. Li, Q. Z. Li, S.M. Lietti, J. K. Lim, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna-Garcia,34,x A.L. Lyon, A.K.A. Maciel, D. Mackin, P. Mättig, R. Magaña-Villalba, P. K. Mal, S. Malik, V. L. Malyshev, Y. Maravin, B. Martin, R. McCarthy, C. L. McGivern, M.M. Meijer, A. Melnitchouk, L. Mendoza, D. Menezes, P. G. Mercadante, M. Merkin, K.W. Merritt, A. Meyer, J. Meyer, N.K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, H. A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, G. Obrant, C. Ochando, D. Onoprienko, J. Orduna, N. Oshima, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, M. Padilla, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park, S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma,34,k V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, A.V. Popov, M. Prewitt, S. Protopopescu, J. Qian, A. Quadt, B. Quinn, A. Rakitine, M. S. Rangel, K. Ranjan, P. N. Ratoff, P. Renkel, P. Rich, M. Rijssenbeek, I. Ripp-Baudot, F. Rizatdinova, S. Robinson, M. Rominsky, C. Royon, P. Rubinov, R. Ruchti, G. Safronov, G. Sajot, A. Sánchez-Hernández, M. P. Sanders, B. Sanghi, G. Savage, L. Sawyer, T. Scanlon, D. Schaile, R. D. Schamberger, Y. Scheglov, H. Schellman, T. Schliephake, S. Schlobohm, C. Schwanenberger, R. Schwienhorst, J. Sekaric, H. Severini, E. Shabalina, M. Shamim, PHYSICAL REVIEW D 80, 053012 (2009)",,https://www.semanticscholar.org/paper/24aea97be43903a1419e02146b2c7368a91e7495,
3141,Low-complexity interpolation coding for server-based computing,"Summary form only given. The growing total cost of ownership has resulted in a shift away from the distributed model of desktop computing toward a more centralized server-based computing (SBC) model. In SBC, all application logic is executed on the server while clients simply process the resulting screen updates sent from the server. To provide good performance, SBC systems employ various techniques to encode the screen updates to minimize the bandwidth and processing requirements of sending the screen updates. However, existing SBC encoding techniques are not able to effectively support multimedia applications. To address this problem, we have developed a family of linear interpolation algorithms for encoding SBC screen updates. We first present an overview of an optimal linear interpolation (OLI) algorithm. Given a rectangular region of pixels to be encoded, OLI represents the region as a one-dimensional function, mapping from the cardinal number of each pixel to the color value of the pixel. To reduce encoding complexity, we developed two linear interpolation algorithms with linear encoding and decoding computational complexity. The algorithms are near optimal linear interpolation (NOLI) and 2-D lossless linear interpolation (2DLI). We have implemented our linear interpolation algorithms and compared their performance with other approaches on discrete-toned and smoothed-toned images.",2002-04-02,https://www.semanticscholar.org/paper/65b8b122c05e7563c6af353e66230ab5495dfc08,Proceedings DCC 2002. Data Compression Conference
137,1 2000 : Project Report to NSF Energy Data Collection Project Year 1,"The massive amount of statistical and text data available from Federal Agencies has created a set of daunting challenges to both research and analysis communities. These problems include heterogeneity, size, distribution, and control of terminology. At the Digital Government Research Center we are investigating solutions to three key problems, namely, (1) ontological mappings for terminology standardization; (2) data integration across data bases with high speed query processing; and (3) interfaces for query input and presentation of results. This collaboration between researchers California employs technology developed at both locations, in particular the SENSUS ontology, the SIMS multi-database access planner, the LKB automated dictionary and terminology analysis system, and others. The pilot application targets gasoline data from BLS, EIA, Census, and other agencies. As access to the web becomes a household commodity, the Government (and in particular Federal Agencies such as the Census Bureau, the Bureau of Labor Statistics, and others) has a mandate to make its information available to the public. But the massive amount of statistical and text data available from such agencies has created a set of daunting challenges to the research and analysis communities. These challenges stem from the heterogeneity, size, distribution, and disparity of terminology of the data. Equally, they stem from the need to provide broad and easy access to (and support proper understanding of) complex data.",,https://www.semanticscholar.org/paper/931db0ebdc70ec875807974b850925211ff3a3f9,
3016,Making It Easier to Encrypt Your Emails,"Steven M. Bellovin is Professor of Computer Science at Columbia University and affiliate faculty at its law school. His research specializes in security, privacy, and related legal and policy issues. He co-authored Firewalls and Internet Security, the first book on the subject. He is a member of the National Academy of Engineering and received the USENIX “Flame” award for co-inventing Netnews. smb@cs.columbia.edu",,https://www.semanticscholar.org/paper/4a8d7cf7c9fa8bde3e9ab79bb0b2ab62afef074f,Login: The Usenix Magazine
348,Free-riding and whitewashing in peer-to-peer systems,"We devise a model to study the phenomenon of free-riding and free-identities in peer-to-peer systems. At the heart of our model is a user of a certain type, an intrinsic and private parameter that reflects the user's willingness to contribute resources to the system. A user decides whether to contribute or free-ride based on how the current contribution cost in the system compares to her type. We study the impact of mechanisms that exclude low type users or, more realistically, penalize free-riders with degraded service. We also consider dynamic scenarios with arrivals and departures of users, and with whitewashers -users who leave the system and rejoin with new identities to avoid reputational penalties. We find that imposing penalty on all users that join the system is effective under many scenarios. In particular, system performance degrades significantly only when the turnover rate among users is high. Finally, we show that the optimal exclusion or penalty level differs significantly from the level that optimizes the performance of contributors only for a limited range of societal generosity levels.",2004-09-03,https://www.semanticscholar.org/paper/e2108dba8487ebcd8689f1ed7b261feed654e65d,IEEE Journal on Selected Areas in Communications
1462,Inclusive D*+- production in photon-photon collisions,,1990-12-20,https://www.semanticscholar.org/paper/d70a437ef6718993c5e29a448bb19c7ae0e4e574,
1958,Overlay Error Compensation Using Advanced Process Control With Dynamically Adjusted Proportional-Integral R2R Controller,"As semiconductor manufacturing reaching nanotechnology, to obtain high resolution and alignment accuracy via minimizing overlay errors within the tolerance is crucial. To address the needs of changing production and process conditions, this study aims to propose a novel dynamically adjusted proportional-integral (DAPI) run-to-run (R2R) controller to adapt equipment parameters to enhance the overlay control performance. This study evaluates the performance of controllers via the variation of each overlay factor and the variation of maximum overlay errors in real settings. To validate the effectiveness of the proposed approach, an empirical study was conducted in a leading semiconductor company in Taiwan and the results showed practical viability of the proposed DAPI controller to reduce overlay errors effectively than conventional exponentially weighted moving average controller used in this company.",2014-04-01,https://www.semanticscholar.org/paper/484c348a458c0fddf7d66baba8ffa01c5f337812,IEEE Transactions on Automation Science and Engineering
1602,The Holdout Randomization Test: Principled and Easy Black Box Feature Selection,"We consider the problem of feature selection using black box predictive models. For example, high-throughput devices in science are routinely used to gather thousands of features for each sample in an experiment. The scientist must then sift through the many candidate features to find explanatory signals in the data, such as which genes are associated with sensitivity to a prospective therapy. Often, predictive models are used for this task: the model is fit, error on held out data is measured, and strong performing models are assumed to have discovered some fundamental properties of the system. A model-specific heuristic is then used to inspect the model parameters and rank important features, with top features reported as ""discoveries."" However, such heuristics provide no statistical guarantees and can produce unreliable results. We propose the holdout randomization test (HRT) as a principled approach to feature selection using black box predictive models. The HRT is model agnostic and produces a valid p-value for each feature, enabling control over the false discovery rate (or Type I error) for any predictive model. Further, the HRT is computationally efficient and, in simulations, has greater power than a competing knockoffs-based approach. Code is available at this https URL.",2018-11-01,https://www.semanticscholar.org/paper/850e3676a1288939ad299d69a5f02ac8d596cb91,
3437,Mitigating the Effect of Free-Riders in BitTorrent using Trusted Agents,"Even though Peer-to-Peer (P2P) systems present a cost-effective and scalable solution to content distribution, most entertainment, media and software, content providers continue to rely on expensive, centralized solutions such as Content Delivery Networks. One of the main reasons is that the current P2P systems cannot guarantee reasonable performance as they depend on the willingness of users to contribute bandwidth. Moreover, even systems like BitTorrent, which employ a tit-for-tat protocol to encourage fair bandwidth exchange between users, are prone to free-riding (i.e. peers that do not upload). Our experiments on PlanetLab extend previous research [14, 12, 11] demonstrating that such selfish behavior can seriously degrade the performance of regular users in many more scenarios beyond simple free-riding: we observed an overhead of upto 430% for 80% of free-riding identities easily generated by a small set of selfish users. To mitigate the effects of selfish users, we propose a new P2P architecture that classifies peers with the help of a small number of trusted nodes that we call Trusted Auditors (TAs). TAs participate in P2P download like regular clients and detect free-riding identities by observing their neighbors’ behavior. Using TAs, we can separate compliant users into a separate service pool resulting in better performance. Furthermore, we show that TAs are more effective ensuring the performance of the system than a mere increase in bandwidth capacity: for 80% of freeriding identities a single-TA system has a 6% download time overhead while without the TA and three times the bandwidth capacity we measure a 100% overhead.",,https://www.semanticscholar.org/paper/9540e5232a206ac6fb66d90d975e088b2356ac64,
2536,"Session details: Interacting with hands, eyes, and images",,2009-07-27,https://www.semanticscholar.org/paper/9c6fe6a1ab13f2a3267475d2336b04c3213a3485,
2309,Regulation of neutrophil apoptosis by sodium butyrate.,"Neutrophils have a very short half life because they constitutively undergo apoptosis. Granulocyte-macrophage colony-stimulating factor (GM-CSF) can delay apoptosis, but this agent also primes functions such as the respiratory burst and receptor upregulation. Here, we show that sodium butyrate, which has been shown to increase gene expression and differentiation in a variety of cell types, is more effective than GM-CSF in delaying neutrophil apoptosis. Thus, sodium butyrate preserves cell morphology and function, and butyrate-treated cells express high levels of CD16 after overnight culture. However, neither GM-CSF nor sodium butyrate appear to affect mRNA levels for CD16.",1996-12-01,https://www.semanticscholar.org/paper/bc0ea61e6519e443569b5b2127eccf6dc95dfb46,Biologicals (Print)
2820,"Ablation of a galectin preferentially expressed in adipocytes increases lipolysis, reduces adiposity, and improves insulin sensitivity in mice","The breakdown of triglycerides, or lipolysis, is a tightly controlled process that regulates fat mobilization in accord with an animal's energy needs. It is well established that lipolysis is stimulated by hormones that signal energy demand and is suppressed by the antilipolytic hormone insulin. However, much still remains to be learned about regulation of lipolysis by intracellular signaling pathways in adipocytes. Here we show that galectin-12, a member of a β-galactoside–binding lectin family preferentially expressed by adipocytes, functions as an intrinsic negative regulator of lipolysis. Galectin-12 is primarily localized on lipid droplets and regulates lipolytic protein kinase A signaling by acting upstream of phosphodiesterase activity to control cAMP levels. Ablation of galectin-12 in mice results in increased adipocyte mitochondrial respiration, reduced adiposity, and ameliorated insulin resistance/glucose intolerance. This study identifies unique properties of this intracellular galectin that is localized to an organelle and performs a critical function in lipid metabolism. These findings add to the significant functions exhibited by intracellular galectins, and have important therapeutic implications for human metabolic disorders.",2011-10-03,https://www.semanticscholar.org/paper/6d12b82abbcaf131b48078946682aadd4a57ccf3,Proceedings of the National Academy of Sciences of the United States of America
566,The complexity of facets resolved,Abstract We show that recognizing the facets of the traveling salesman problem polytope is Dp-complete.,1985-10-21,https://www.semanticscholar.org/paper/e68af98db70190f1e0adfb3bf9026d513df312c7,26th Annual Symposium on Foundations of Computer Science (sfcs 1985)
2923,A novel methodology for estimating tensile properties in a small punch test employing in-situ DIC based deflection mapping,,2020-09-01,https://www.semanticscholar.org/paper/02c12d42ae5c110a7b3e5415d2943b810f18017e,Journal of Nuclear Materials
2177,The clinical significance of fungi in atopic dermatitis,"Atopic dermatitis (AD) is one of the most common chronic inflammatory skin diseases and is caused by multiple factors including genetic factors, skin barrier defects, host immune responses, allergen sensitivity, environmental effects, and infections. Commonly, bacterial and viral infections are present in the eczematous lesions of AD patients and clearly aggravate the symptoms. However, studies of fungal infections in AD are limited in spite of the fact that there are reports showing that Malassezia, Candida, and some dermatophytes can affect the symptoms of AD. Moreover, certain fungal infections are sometimes overlooked and need to be considered particularly in AD patients with treatment failure as clinical features of those fungal infections could mimic eczematous lesions in AD. Here, we review the epidemiology, pathogenesis, clinical manifestations, and overlooked features of fungal infections associated with the symptoms of AD including the diagnosis and effectiveness of fungal treatments in AD patients.",2020-05-22,https://www.semanticscholar.org/paper/e04457891260a48b9918a0a9cc60b3cf6d1f8bad,International Journal of Dermatology
1563,Skill Rating for Multiplayer Games. Introducing Hypernode Graphs and their Spectral Theory,"We consider the skill rating problem for multiplayer games, that is how to infer player skills from game outcomes in multiplayer games. We formulate the problem as a minimization problem arg min s s T ∆s where ∆ is a positive semidefinite matrix and s a real-valued function, of which some entries are the skill values to be inferred and other entries are constrained by the game outcomes. We leverage graph-based semi-supervised learning (SSL) algorithms for this problem. We apply our algorithms on several data sets of multiplayer games and obtain very promising results compared to Elo Duelling (see Elo, 1978) and TrueSkill (see Herbrich et al., 2006). As we leverage graph-based SSL algorithms and because games can be seen as relations between sets of players, we then generalize the approach. For this aim, we introduce a new finite model, called hypernode graph, defined to be a set of weighted binary relations between sets of nodes. We define Laplacians of hy-pernode graphs. Then, we show that the skill rating problem for multiplayer games can be formulated as arg min s s T ∆s where ∆ is the Laplacian of a hypernode graph constructed from a set of games. From a fundamental perspective, we show that hypernode graph Laplacians are symmetric positive semidefinite matrices with constant functions in their null space. We show that problems on hypernode graphs can not be solved with graph constructions and graph kernels. We relate hypernode graphs to signed graphs showing that positive relations between groups can lead to negative relations between individuals.",,https://www.semanticscholar.org/paper/e9ca8923abf66839bbf212262ab371f34b809380,Journal of machine learning research
746,Computational Aspects of Equilibria,,2009-10-13,https://www.semanticscholar.org/paper/6c1bb7d143b71b61ee6abf49583fddb25e9b8818,Algorithmic Game Theory
2512,Session details: Gestures,,2011-05-07,https://www.semanticscholar.org/paper/b6e676f786a2e28760c23097f70354797e4badb0,CHI '11 Extended Abstracts on Human Factors in Computing Systems
1107,27 Complementarity of Dark Matter Experiments,"Despite being five times as abundant as normal matter in the Universe, the identify of dark matter is unknown. Its existence, however, implies that our inventory of the basic building blocks of nature is incomplete, and uncertainty about its properties clouds attempts to fully understand how the Universe evolved to its present state and how it will evolve in the future. Uncovering the identity of dark matter is therefore a central and grand challenge for both fundamental physics and astronomy. Fortunately, a very promising array of groundbreaking experiments are positioned to transform the field of dark matter in the coming decade. The prospect that dark matter particles might be observed in the near future has drawn many new researchers to the field, which is now characterized by an extraordinary diversity of approaches unified by the common goal of discovering the identity of dark matter.",,https://www.semanticscholar.org/paper/9c92e90ee86d5708870c281d4a824b22983e1cc5,
1059,DigitalCommons@University of Nebraska - Lincoln DigitalCommons@University of Nebraska - Lincoln ZZZZ → ll ++ ll -- vv ++ vv -- production in production in pppp collisions at √ collisions at ss = 1.96 TeV = 1.96 TeV,We describe a search for Z boson pair production in p (cid:1) p collisions at ﬃﬃﬃ s p ¼ 1 : 96 TeV with the D0 detector at the Fermilab Tevatron Collider using a data sample corresponding to an integrated luminosity of 2 : 7 fb (cid:1) 1 . Using the ﬁnal state decay ZZ ! ‘ þ ‘ (cid:1) (cid:1) (cid:1) (cid:1) (where ‘ ¼ e or (cid:2) ) we ﬁnd a signal with a 2.6 standard deviations signiﬁcance (2.0 expected) corresponding to a cross section of (cid:3) ð p (cid:1) p ! ZZ þ X Þ ¼ 2 : 01 (cid:2) 0 : 93 ð stat Þ (cid:2) 0 : 29 ð sys Þ pb .,,https://www.semanticscholar.org/paper/6aec6fd43c1a33ae16ff05bc9e9a57a23a1bf26b,
758,Explorer Multi-Objective Model Checking of Markov Decision Processes,"We study and provide efficient algorithms for multi-objective model checking problems for Markov Decision Processes (MDPs). Given an MDP, M , and given multiple linear-time (ω-regular or LTL) properties φi, and probabilities ri ∈ [0, 1], i = 1, . . . , k, we ask whether there exists a strategy σ for the controller such that, for all i, the probability that a trajectory of M controlled by σ satisfies φi is at least ri. We provide an algorithm that decides whether there exists such a strategy and if so produces it, and which runs in time polynomial in the size of the MDP. Such a strategy may require the use of both randomization and memory. We also consider more general multi-objective ω-regular queries, which we motivate with an application to assume-guarantee compositional reasoning for probabilistic systems. Note that there can be trade-offs between different properties: satisfying property φ1 with high probability may necessitate satisfying φ2 with low probability. Viewing this as a multi-objective optimization problem, we want information about the “trade-off curve” or Pareto curve for maximizing the probabilities of different properties. We show that one can compute an approximate Pareto curve with respect to a set of ωregular properties in time polynomial in the size of the MDP. Our quantitative upper bounds use LP methods. We also study qualitative multi-objective model checking problems, and we show that these can be analysed by purely graph-theoretic methods, even though the strategies may still require both randomization and memory.",,https://www.semanticscholar.org/paper/75ba8925662a8475e9d1e7067d3985707e6d6394,
1253,Search for scalar top quarks in the acoplanar charm jets and missing transverse energy final state in pp collisions at â‹ıs = 1.96 TeV,In most cases authors are permitted to post their version of the article (e.g. in Word or Tex form) to their personal website or institutional repository. Authors requiring further information regarding Elsevier's archiving and manuscript policies are encouraged to visit:,,https://www.semanticscholar.org/paper/c8adbe44e79dc3ac6beea88afbfa3c73ff53e421,
800,Model Checking of Message Sequence Charts,,1999-08-24,https://www.semanticscholar.org/paper/38505f1e1b063724a6c23c11ebeee2ec1d81ff95,International Conference on Concurrency Theory
22,Quality Impact of Value Matching and Scoring in Top-k Entity Attribute Extraction,"The entity attribute extraction problem, or how to extract entities and their attribute values from natural language Web documents, is of critical importance for Web search and information access in general. Unfortunately, because of the noisy nature of the Web and its scale, entity attribute extraction is notoriously challenging in terms of both extraction efficiency and quality. In our earlier work [24], we proposed a top-k extraction processing approach that addressed the efficiency challenge: Our approach leveraged a popularitybased scoring function to rank Web pages according to their entity-specific importance, and focused the extraction effort over the highly ranked pages for each entity of interest. The extraction quality resulting from this efficiency-motivated extraction approach, however, has not been studied and is the focus of this paper. Specifically, we make progress toward addressing the quality challenge through an in-depth analysis of two critical components of the extraction process, namely, matching and scoring of extracted attribute values. The design choices for these components can substantially impact the quality of the entity attribute extraction process, as we demonstrate with experiments with a state-of-the-art extraction system and entities from two domains of interest.",,https://www.semanticscholar.org/paper/4a51879c9e7af33b3e3599f1168f93e42a624ad7,
3728,"A Unifying Framework for Formal Theories of Novelty: Framework, Examples and Discussion","Managing inputs that are novel, unknown, or out-of-distribution is critical as an agent moves from the lab to the open world. Novelty-related problems include being tolerant to novel perturbations of the normal input, detecting when the input includes novel items, and adapting to novel inputs. While significant research has been undertaken in these areas, a noticeable gap exists in the lack of a formalized definition of novelty that transcends problem domains. As a team of researchers spanning multiple research groups and different domains, we have seen, first hand, the difficulties that arise from ill-specified novelty problems, as well as inconsistent definitions and terminology. Therefore, we present the first unified framework for formal theories of novelty and use the framework to formally define a family of novelty types. Our framework can be applied across a wide range of domains, from symbolic AI to reinforcement learning, and beyond to open world image recognition. Thus, it can be used to help kick-start new research efforts and accelerate ongoing work on these important novelty-related problems. This extended version of our AAAI 2021 paper included more details and examples in multiple domains.",2020-12-08,https://www.semanticscholar.org/paper/f2d1cbb25b1c58b89b6a8140f775493817f73752,arXiv.org
2557,Balloon Selection: A Multi-Finger Technique for Accurate Low-Fatigue 3D Selection,"Balloon selection is a 3D interaction technique that is modeled after the real world metaphor of manipulating a helium balloon attached to a string. Balloon selection allows for precise 3D selection in the volume above a tabletop surface by using multiple fingers on a multi-touch-sensitive surface. The 3DOF selection tasks is decomposed in part into a 2DOF positioning task performed by one finger on the tabletop in an absolute 2D Cartesian coordinate system and a 1DOF positioning task performed by another finger on the tabletop in a relative 2D polar coordinate system. We have evaluated balloon selection in a formal user study that compared it to two well-known interaction techniques for selecting a static 3D target: a 3DOF tracked wand and keyboard cursor keys. We found that balloon selection was significantly faster than using cursor keys and had a significantly lower error rate than the wand. The lower error rate appeared to result from the user's hands being supported by the tabletop surface, resulting in significantly reduced hand tremor and arm fatigue.",2007-03-10,https://www.semanticscholar.org/paper/6caec67a2c4320d89aabda06be93617c4bfa7d41,IEEE Symposium on 3D User Interfaces
1742,Truncation-free Online Variational Inference for Bayesian Nonparametric Models,"We present a truncation-free online variational inference algorithm for Bayesian nonparametric models. Unlike traditional (online) variational inference algorithms that require truncations for the model or the variational distribution, our method adapts model complexity on the fly. Our experiments for Dirichlet process mixture models and hierarchical Dirichlet process topic models on two large-scale data sets show better performance than previous online variational inference algorithms.",,https://www.semanticscholar.org/paper/05a55d4d3935c9517c91deef8df76447cb93b7f4,Neural Information Processing Systems
889,Linear and Book Embeddings of Graphs,,1986-08-01,https://www.semanticscholar.org/paper/08a27b0336173d0844ce365345b0f8b6d6b5a13f,Aegean Workshop on Computing
3275,Reciprocal insurance among Kenyan pastoralists,,2013-05-01,https://www.semanticscholar.org/paper/0038c26dabb61e926bd18d59502b0a3e845ebbad,Theoretical Ecology
3647,Exception Handling for C++,"This paper outlines a design for an exception handling mechanism for C ++. It presents the reasoning behind the major design decisions and considers their implications for implementation alternatives. The mechanism is flexible, comparatively safe and easy to use, works in a mixed language execution environment, and can be implemented to run efficiently. Two implementation strategies are described in some detail.",1990-06-01,https://www.semanticscholar.org/paper/1955673684ccef4551543c9d6c819bbb7347df32,C++ Conference
2562,Designing a mobile user interface for automated species identification,"Biological research in the field is constrained by the speed and difficulty of species determination, as well as by access to relevant information about the species encountered. However, recent work on vision-based algorithms raises the promise of rapid botanical species identification. The potential for mobile vision-based identification provides opportunities for new user interface techniques. To explore these issues, we present LeafView, a Tablet-PC-based user interface for an electronic field guide that supports automated identification of botanical species in the field. We describe a user interface design based on an ethnographic study of botanists, field tests of working prototypes by botanists at the Smithsonian Institution on Plummers Island, Maryland, and observations at an internal exhibition at the Smithsonian at which other staff members tried the prototypes. We present functionality specific to mobile identification and collection in the electronic field guide and use this to motivate discussion of mobile identification in general.",2007-04-29,https://www.semanticscholar.org/paper/b6c5cf1b7544ed141bdcf19a6c452d6345988d75,International Conference on Human Factors in Computing Systems
1056,Constraints on dark photons and axion-like particles from SuperCDMS Soudan,"We present an analysis of electron recoils in cryogenic germanium detectors operated during the SuperCDMS Soudan experiment. The data are used to set new constraints on the axioelectric coupling of axion-like particles and the kinetic mixing parameter of dark photons, assuming the respective species constitutes all of the galactic dark matter. This study covers the mass range from 40 eV/$c^2$ to 500 eV/$c^2$ for both candidates, excluding previously untested parameter space for masses below ~1 keV/$c^2$. For the kinetic mixing of dark photons, values below $10^{-15}$ are reached for particle masses around 100 eV/$c^2$; for the axioelectric coupling of axion-like particles, values below $10^{-12}$ are reached for particles with masses in the range of a few-hundred eV/$c^2$.",2019-11-27,https://www.semanticscholar.org/paper/0a156b494f40b67856bf946047003d1d58b1cdf5,
900,Serializability by Locking,"The power of locking as a primitive for controlling concurrency in database systems is examined. It is accepted that the concurrent execution (or schedule) of different transactions must be serializable; that is, it must behave like a serial schedule, one in which the transactions run one at a time. It is shown that locking cannot achieve the full power of serializability. An exact characterization of the schedules that can be produced if locking is used to control concurrency is given for two versions of serializability. In the first one, state serializability, only the effect of the schedule on the database is taken into account. In the second one, view serializability, the view of the data received by the transactions is also taken into account. The author shows that it is possible to determine efficiently whether the transactions in a given set can be permitted to run safely by themselves without the need of any control while ensuring view serializability, although the problem is np-complete in the case of state serializability. 20 references.",1984-03-30,https://www.semanticscholar.org/paper/27b37c7073a241a4071c29bff5a43f73d6388086,JACM
2061,Editorial e-Manufacturing in the Semiconductor Industry,The 11 papers in this special issue focus on e-manufacturing in the semiconductor industry.,2007-10-01,https://www.semanticscholar.org/paper/1dc52187db9b992016e15e1822bca36d7581557b,IEEE Transactions on Automation Science and Engineering
501,"On Total Functions, Existence Theorems and Computational Complexity",,1991-04-30,https://www.semanticscholar.org/paper/96c51fb7999f560e8f28db772603fb6541560d25,Theoretical Computer Science
1176,Evidence for the Decayand a Measurement of,,2009-03-03,https://www.semanticscholar.org/paper/b4a2e2cefa2eaed5470a814c7cb364eccbfb4b42,
2134,Effect of differences between day and night temperatures on early fruit drop in satsuma mandarins,,1987-05-08,https://www.semanticscholar.org/paper/a08c50a2318f44a4063f3e9a6d1b6356fac40e74,
2343,Sequential phospholipase activation in the stimulation of the neutrophil NADPH oxidase.,"Stimulation of human neutrophils with the chemotactic peptide fMet-Leu-Phe results in activation of a rapid, transient burst of oxidant secretion, which reaches a maximal rate by about 1 min after stimulation. This phase of oxidant secretion is then followed by intracellular oxidant production, which is detected by luminol chemiluminescence but not by assays such as cytochrome c reduction or scopoletin oxidation. The rapid phase of oxidant secretion requires increases in intracellular free Ca2+ and phospholipase A2 activity, but not the activities of phospholipase D or protein kinase C. In contrast, intracellular oxidant production requires the activities of phospholipase D and protein kinase C. A model is thus proposed suggesting the sequential activation of different phospholipases which activate oxidase molecules on the plasma membrane or else from the membranes of specific granules.",1992-12-01,https://www.semanticscholar.org/paper/e6ac3dae7a1750361d7845e8db4935c0dd39bcba,FEMS Microbiology Immunology
366,The complexity of massive data set computations,"Numerous massive data sets, ranging from flows of Internet traffic to logs of supermarket transactions, have emerged during the past few years. Their overwhelming size and the typically restricted access to them call for new computational models. This thesis studies three such models: sampling computations, data stream computations, and sketch computations. 
While most of the previous work focused on designing algorithms in the new models, this thesis revolves around the limitations of the models. We develop a suite of lower bound techniques that characterize the complexity of functions in these models, indicating which problems can be solved efficiently in them. We derive specific bounds for a multitude of practical problems, arising from applications in database, networking, and information retrieval, such as frequency statistics, selection functions, statistical moments, and distance estimation. 
We present general, powerful, and easy to use lower bound techniques for the sampling model. The techniques apply to all functions and address both oblivious and adaptive sampling. They frequently produce optimal bounds for a wide range of functions. They are stated in terms of new combinatorial and statistical properties of functions, which are easy to calculate. 
We obtain lower bounds for the data stream and sketch models through one-way and simultaneous communication complexity. We develop lower bounds for the latter via a new information-theoretic view of communication complexity. A highlight of this work is an optimal simultaneous communication complexity lower bound for the important multi-party set-disjointness problem. 
Finally, we present a powerful method for proving lower bounds for general communication complexity. The method is based on a direct sum property of a new measure of complexity for communication complexity protocols and on a novel statistical view of communication complexity. We use the technique to obtain improved communication complexity and data stream lower bounds for several problems, including multi-party set-disjointness, frequency moments, and Lp distance estimation. These results solve open problems of Alon, Matias, and Szegedy and of Saks and Sun.",,https://www.semanticscholar.org/paper/0fb92a7687986ad52cfa2b2ffd6ea4e7994a613b,
1649,Robust Probabilistic Modeling with Bayesian Data Reweighting,"Probabilistic models analyze data by relying on a set of assumptions. Data that exhibit deviations from these assumptions can undermine inference and prediction quality. Robust models offer protection against mismatch between a model's assumptions and reality. We propose a way to systematically detect and mitigate mismatch of a large class of probabilistic models. The idea is to raise the likelihood of each observation to a weight and then to infer both the latent variables and the weights from data. Inferring the weights allows a model to identify observations that match its assumptions and down-weight others. This enables robust inference and improves predictive accuracy. We study four different forms of mismatch with reality, ranging from missing latent groups to structure misspecification. A Poisson factorization analysis of the Movielens 1M dataset shows the benefits of this approach in a practical scenario.",2016-06-13,https://www.semanticscholar.org/paper/434954d40776c87d8b354677ac393cb121f5c80b,International Conference on Machine Learning
950,Evaluation of moxifloxacin-induced cytotoxicity on human corneal endothelial cells,,2021-03-18,https://www.semanticscholar.org/paper/0ef7639aed47d8344938085055db9c0f71377deb,Scientific Reports
1607,Empirical Risk Minimization and Stochastic Gradient Descent for Relational Data,"Empirical risk minimization is the main tool for prediction problems, but its extension to relational data remains unsolved. We solve this problem using recent ideas from graph sampling theory to (i) define an empirical risk for relational data and (ii) obtain stochastic gradients for this empirical risk that are automatically unbiased. This is achieved by considering the method by which data is sampled from a graph as an explicit component of model design. By integrating fast implementations of graph sampling schemes with standard automatic differentiation tools, we provide an efficient turnkey solver for the risk minimization problem. We establish basic theoretical properties of the procedure. Finally, we demonstrate relational ERM with application to two non-standard problems: one-stage training for semi-supervised node classification, and learning embedding vectors for vertex attributes. Experiments confirm that the turnkey inference procedure is effective in practice, and that the sampling scheme used for model specification has a strong effect on model performance. Code is available at this https URL.",2018-06-27,https://www.semanticscholar.org/paper/a6b62f412e74edb5daccfbb1c46db887ad9b5ea4,International Conference on Artificial Intelligence and Statistics
2702,8 Conclusions,"Existing ray tracers, once given the rendering specifications, are not controllable by the user. The priority-driven ray tracing provides a mechanism to steer rendering and deliver intermediate images amid processing. We have demonstrated the utility of five priority schemes and shown that they require reasonable amounts of memory and consume negligible amount of overhead time. Priority-driven ray tracing can be extended to support other priority schemes, and mixtures of several priority criteria. In our current implementation, once a priority has been assigned to a ray it cannot be changed. The ability to demote or promote queued rays will provide us the support needed for dynamic steering. In addition, various other priority schemes can be explored. Examples include priority assigned to rays based on cache performance optimization [GREE89] or priority assigned to shadow feelers according to light source intensity or distance. Finally, we have used numerical methods to show the faster convergence of the priority based method. One could employ some perceptual metric [RUSH89] to better control our priority ray tracer to achieve even faster effective image comprehension.",,https://www.semanticscholar.org/paper/cb29d7899724f78900b8361a00c273061ced02f8,
3558,General constant expressions for system programming languages,"Most mainstream system programming languages provide support for builtin types, and extension mechanisms through userdefined types. They also come with a notion of constant expressions whereby some expressions (such as array bounds) can be evaluated at compile time. However, they require constant expressions to be written in an impoverished language with minimal support from the type system; this is tedious and error-prone. This paper presents a framework for generalizing the notion of constant expressions in modern system programming languages. It extends compile time evaluation to functions and variables of user-defined types, thereby including formerly ad hoc notions of Read Only Memory (ROM) objects into a general and type safe framework. It allows a programmer to specify that an operation must be evaluated at compile time. Furthermore, it provides more direct support for key meta programming and generative programming techniques. The framework is formalized as an extension of underlying type system with a binding time analysis. It was designed to meet real-world requirements. In particular, key design decisions relate to balancing expressive power to implementability in industrial compilers and teachability. It has been implemented for C++ in the GNU Compiler Collection, and is part of the next ISO C++ standard.",2010-03-22,https://www.semanticscholar.org/paper/048aa35d1ca049b612c71aa6a702b4e954b1077c,ACM Symposium on Applied Computing
208,Does Information Revelation Improve Revenue?,"We study the problem of optimal auction design in a valuation model, explicitly motivated by online ad auctions, in which there is two-way informational asymmetry, in the sense that private information is available to both the seller (the item type) and the bidders (their type), and the value of each bidder for the item depends both on his own and the item's type. Importantly, we allow arbitrary auction formats involving, potentially, several rounds of signaling from the seller and decisions by the bidders, and seek to find the optimum co-design of signaling and auction (we call this optimum the ""optimum augmented auction""). We characterize exactly the optimum augmented auction for our valuation model by establishing its equivalence with a multi-item Bayesian auction with additive bidders. Surprisingly, in the optimum augmented auction there is no signaling whatsoever, and in fact the seller need not access the available information about the item type until after the bidder chooses his bid. Suboptimal solutions to this problem, which have appeared in the recent literature, are shown to correspond to well-studied ways to approximate multi-item auctions by simpler formats, such as grand-bundling (this corresponds to Myerson's auction without any information revelation), selling items separately (this corresponds to Myerson's auction preceded by full information revelation as in [Fu et al. 2012]), and fractional partitioning (this corresponds to Myerson's auction preceded by optimal signaling). Consequently, all these solutions are separated by large approximation gaps from the optimum revenue.",2016-07-21,https://www.semanticscholar.org/paper/bad79181ff909385a33f6f11b7116e12ea9ce469,ACM Conference on Economics and Computation
1724,Topographic Factor Analysis: A Bayesian Model for Inferring Brain Networks from Neural Data,"The neural patterns recorded during a neuroscientific experiment reflect complex interactions between many brain regions, each comprising millions of neurons. However, the measurements themselves are typically abstracted from that underlying structure. For example, functional magnetic resonance imaging (fMRI) datasets comprise a time series of three-dimensional images, where each voxel in an image (roughly) reflects the activity of the brain structure(s)–located at the corresponding point in space–at the time the image was collected. FMRI data often exhibit strong spatial correlations, whereby nearby voxels behave similarly over time as the underlying brain structure modulates its activity. Here we develop topographic factor analysis (TFA), a technique that exploits spatial correlations in fMRI data to recover the underlying structure that the images reflect. Specifically, TFA casts each brain image as a weighted sum of spatial functions. The parameters of those spatial functions, which may be learned by applying TFA to an fMRI dataset, reveal the locations and sizes of the brain structures activated while the data were collected, as well as the interactions between those structures.",2014-05-07,https://www.semanticscholar.org/paper/f479505354f332f692c4775dc91d90758e8379f4,PLoS ONE
927,Edge-Deletion Problems,"If $\pi $ is a property on graphs or digraphs, the edge-deletion problem can be stated as follows: find the minimum number of edges whose deletion results in a subgraph (or subdigraph) satisfying property $\pi $. Several well-studied graph problems can be formulated as edge-deletion problems.In this paper we show that the edge-deletion problem is NP-complete for the following properties: (1) without cycles of specified length l, or of any length $ \leqq l$, (2) connected and degree-constrained, (3) outerplanar, (4) transitive digraph, (5) line-invertible, (6) bipartite, (7) transitively orientable. For problems (5), (6), (7) we determine the best possible bounds on the node-degrees for which the problems remain NP-complete.",1981-05-01,https://www.semanticscholar.org/paper/b59a2ae98053a756b08b67815c3a5afa2d5ac7f3,SIAM journal on computing (Print)
948,Hemisphere opposite to central retinal vascular trunk deviation is earlier affected by glaucomatous damage in primary angle‐closure glaucoma,"The purpose of the study was to investigate whether the position of the central retinal vascular trunk (CRVT), as a surrogate for lamina cribrosa (LC) offset, is associated with the dominant hemisphere of visual field defect in primary angle‐closure glaucoma (PACG) eyes.",2022-09-22,https://www.semanticscholar.org/paper/33d6f6085b72312db8b5753bfd0831b7ade302d6,Acta ophthalmologica
1185,Search for Resonant Pair Production of long-lived particles decaying to b anti-b in p anti-p collisions at s**(1/2) = 1.96-TeV,"We report on a first search for production of Higgs bosons decaying into neutral long-lived particles (NLLP) which each decay to a b{bar b} pair, using 3.6 fb{sup -1} of data recorded with the D0 detector at the Fermilab Tevatron collider. We search for pairs of displaced vertices in the tracking detector at radii in the range 1.6-20 cm from the beam axis. No significant excess is observed above background, and upper limits are set on the production rate in a hidden-valley benchmark model for a range of Higgs boson masses and NLLP masses and lifetimes.",2009-06-01,https://www.semanticscholar.org/paper/d45e955f8f5f57af3fc416c624721dd44086a98f,
2103,Data value development to enhance competitive advantage: a retrospective study of EDA systems for semiconductor fabrication,"In semiconductor manufacturing, reducing cycle time, producing high quality products, on-time delivery, continual reduction of costs and improving efficiency are the most direct and effective ways to create value for customers. However, the semiconductor manufacturing process is extremely complex. Without good support from fab engineers, creating value for customers is difficult. An Engineering Data Analysis (EDA) system is a very important off-line analysis-oriented system that can be used to support yield analysis and quality improvement for semiconductor fabrication. However, due to the data integration, system design, and requirement for cooperation among domain experts, IT specialists, and statisticians, to develop and deploy an in-house EDA system is difficult. A retrospective study of a semiconductor manufacturing company is presented; the company has more than ten years' experience of developing the in-house EDA system. In particular, the process of developing the system is reviewed, including design thinking and information design. An EDA system that is currently used in an 8-inch fab is introduced. This study identifies several hidden factors that may affect the successful development of an EDA system. Prescriptions for overcoming these difficulties are also given in this study.",,https://www.semanticscholar.org/paper/089666921f9db1f755e14a0ac47291e296da6de2,International Journal of Services Technology and Management
3228,Above- and below-ground allocation and functional trait response to soil water inputs and drying rates of two common savanna grasses,,2018-10-01,https://www.semanticscholar.org/paper/9a7284430c6d6c3fd965b8b7f0e2ddcd6c047ca5,Journal of Arid Environments
1142,Search for axions with the CDMS experiment.,We report on the first axion search results from the Cryogenic Dark Matter Search (CDMS) experiment at the Soudan Underground Laboratory. An energy threshold of 2 keV for electron-recoil events allows a search for possible solar axion conversion into photons or local galactic axion conversion into electrons in the germanium crystal detectors. The solar axion search sets an upper limit on the Primakov coupling g(agammagamma) of 2.4x10(-9) GeV-1 at the 95% confidence level for an axion mass less than 0.1 keV/c2. This limit benefits from the first precise measurement of the absolute crystal plane orientations in this type of experiment. The galactic axion search analysis sets a world-leading experimental upper limit on the axioelectric coupling g(aee) of 1.4x10(-12) at the 90% confidence level for an axion mass of 2.5 keV/c2.,2009-10-02,https://www.semanticscholar.org/paper/082a681571a4e2da71b8b9ba008c8fd880a32ab2,Physical Review Letters
1407,LIMITS ON THE WIMP-NUCLEON CROSS-SECTION FROM THE CRYOGENIC DARK MATTER SEARCH,,2001-05-01,https://www.semanticscholar.org/paper/285abb5dd54f5b4c06e640a58012572a26c02a2c,
1540,On the Assumptions of Synthetic Control Methods,"Synthetic control (SC) methods have been widely applied to estimate the causal effect of large-scale interventions, e.g., the state-wide effect of a change in policy. The idea of synthetic controls is to approximate one unit's counterfactual outcomes using a weighted combination of some other units' observed outcomes. The motivating question of this paper is: how does the SC strategy lead to valid causal inferences? We address this question by re-formulating the causal inference problem targeted by SC with a more fine-grained model, where we change the unit of the analysis from""large units""(e.g., states) to""small units""(e.g., individuals in states). Under this re-formulation, we derive sufficient conditions for the non-parametric causal identification of the causal effect. We highlight two implications of the reformulation: (1) it clarifies where""linearity""comes from, and how it falls naturally out of the more fine-grained and flexible model, and (2) it suggests new ways of using available data with SC methods for valid causal inference, in particular, new ways of selecting observations from which to estimate the counterfactual.",2021-12-10,https://www.semanticscholar.org/paper/466abebd6519c16f952c4633c10c0b693e240e3e,International Conference on Artificial Intelligence and Statistics
963,Central Retinal Vascular Trunk Deviation in Unilateral Open-angle Glaucoma,"
 Patients with unilateral open-angle glaucoma (OAG) have suffered glaucomatous optic neuropathy in one eye only despite shared systemic factors between two eyes. It suggests a locoregional susceptibility factor associated with glaucoma development. In this study, we measured the distance of the central retinal vascular trunk from the Bruch’s membrane opening (BMO) center relative to that of the BMO margin: the shift index, since it can be used as a surrogate of lamina cribrosa (LC) shift caused by different growth between retinal and scleral layers during eyeball expansion. The shift index was compared between OAG and fellow control eyes within individuals (129 OAG patients). Although OAG eyes also had higher baseline IOP, a larger β-zone parapapillary atrophy area, a larger shift index was the only risk factor of OAG diagnosis in a generalized linear mixed-effects model. Further, a generalized estimating equation regression model revealed that the shift index was larger in the OAG eyes than in the control eyes for all ranges of axial length, while it was the smallest for the axial length of 23.7 mm. Thus, a larger shift index and LC shift may act as a locoregional susceptibility factor for unilateral OAG eyes.",2020-12-23,https://www.semanticscholar.org/paper/338969b4d7bf19d04f25f8696865c3016cce24e1,
159,Public Goods Games in Directed Networks,"Public goods games in undirected networks are generally known to have pure Nash equilibria, which are easy to find. In contrast, we prove that, in directed networks, a broad range of public goods games have intractable equilibrium problems: The existence of pure Nash equilibria is NP-hard to decide, and mixed Nash equilibria are PPAD-hard to find. We define general utility public goods games, and prove a complexity dichotomy result for finding pure equilibria, and a PPAD-completeness proof for mixed Nash equilibria. Even in the divisible goods variant of the problem, where existence is easy to prove, finding the equilibrium is PPAD-complete. Finally, when the treewidth of the directed network is appropriately bounded, we prove that polynomial-time algorithms are possible.",2021-06-01,https://www.semanticscholar.org/paper/a0393765e5559d482c7098e242fa750c56003ea0,ACM Conference on Economics and Computation
2931,Variational Variance: Simple and Reliable Predictive Variance Parameterization,"An often overlooked sleight of hand performed with variational autoencoders (VAEs), which has proliferated the literature, is to misrepresent the posterior predictive (decoder) distribution's expectation as a sample from that distribution. Jointly modeling the mean and variance for a normal predictive distribution can result in fragile optimization where the ultimately learned parameters can be ineffective at generating realistic samples. The two most common principled methods to avoid this problem are to either fix the variance or use the single-parameter Bernoulli distribution--both have drawbacks, however. Unfortunately, the problem of jointly optimizing mean and variance networks affects not only unsupervised modeling of continuous data (a taxonomy for many VAE applications) but also regression tasks. To date, only a handful of papers have attempted to resolve these difficulties. In this article, we propose an alternative and attractively simple solution: treat predictive variance variationally. Our approach synergizes with existing VAE-specific theoretical results and, being probabilistically principled, provides access to Empirical Bayes and other such techniques that utilize the observed data to construct well-informed priors. We extend the VAMP prior, which assumes a uniform mixture, by inferring mixture proportions and assignments. This extension amplifies our ability to accurately capture heteroscedastic variance. Notably, our methods experimentally outperform existing techniques on supervised and unsupervised modeling of continuous data.",2020-06-08,https://www.semanticscholar.org/paper/ff8bae876668407fcd9ffc4e042dfc9104821a86,arXiv.org
186,Wealth Inequality and the Price of Anarchy,"Price of anarchy quantifies the degradation of social welfare in games due to the lack of a centralized authority that can enforce the optimal outcome. At its antipodes, mechanism design studies how to ameliorate these effects by incentivizing socially desirable behavior and implementing the optimal state as equilibrium. In practice, the responsiveness to such measures depends on the wealth of each individual. This leads to a natural, but largely unexplored, question. Does optimal mechanism design entrench, or maybe even exacerbate, social inequality? 
We study this question in nonatomic congestion games, arguably one of the most thoroughly studied settings from the perspectives of price of anarchy as well as mechanism design. We introduce a new model that incorporates the wealth distribution of the population and captures the income elasticity of travel time. This allows us to argue about the equality of wealth distribution both before and after employing a mechanism. We start our analysis by establishing a broad qualitative result, showing that tolls always increase inequality in symmetric congestion games under any reasonable metric of inequality, e.g., the Gini index. Next, we introduce the iniquity index, a novel measure for quantifying the magnitude of these forces towards a more unbalanced wealth distribution and show it has good normative properties (robustness to scaling of income, no-regret learning). We analyze iniquity both in theoretical settings (Pigou's network under various wealth distributions) as well as experimental ones (based on a large scale field experiment in Singapore). Finally, we provide an algorithm for computing optimal tolls for any point of the trade-off of relative importance of efficiency and equality. We conclude with a discussion of our findings in the context of theories of justice as developed in contemporary social sciences.",2018-02-01,https://www.semanticscholar.org/paper/d6ed4e428412d6dfd54c9552366c507cd1a66bd5,Symposium on Theoretical Aspects of Computer Science
2673,Generating Multimedia Briefings: Coordinating Language and Illustration,,1998-08-01,https://www.semanticscholar.org/paper/5919978adf560fff98ffc3d1be0e0dfa8b8c016b,Artificial Intelligence
1074,COMET Phase-I technical design report,"The Technical Design for the COMET Phase-I experiment is presented in this paper. COMET is an experiment at J-PARC, Japan, which will search for neutrinoless conversion of muons into electrons in the field of an aluminium nucleus ($\mu-e$ conversion, $\mu^- N \to e^- N$); a lepton flavor violating process. The experimental sensitivity goal for this process in the Phase-I experiment is $3.1\times10^{-15}$, or 90 % upper limit of branching ratio of $7\times 10^{-15}$, which is a factor of 100 improvement over the existing limit. The expected number of background events is 0.032. To achieve the target sensitivity and background level, the 3.2 kW 8 GeV proton beam from J-PARC will be used. Two types of detectors, CyDet and StrECAL, will be used for detecting the \mue conversion events, and for measuring the beam-related background events in view of the Phase-II experiment, respectively. Results from simulation on signal and background estimations are also described.",2018-12-21,https://www.semanticscholar.org/paper/ac9429b1f8200eaef03467c0e3a4fab744382162,
3345,Animal behaviour: The serpent's seductive scent,,1985-12-01,https://www.semanticscholar.org/paper/0a0508e25a53dc060fd727e220f59b209dc0bed8,Nature
1860,1 Matching Words and Pictures,"We present a new and very rich approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text. Learning the joint distribution of image regions and words has many applications. We consider in detail predicting words associated with whole images (auto-annotation) and corresponding to particular image regions (region naming). Auto-annotation might help organize and access large collections of images. Region naming is a model of object recognition as a process of translating image regions to words, much as one might translate from one language to another. Learning the relationships between image regions and semantic correlates (words) is an interesting example of multi-modal data mining, particularly because it is typically hard to apply data mining techniques to collections of images. We develop a number of models for the joint distribution of image regions and words, including several which explicitly learn the correspondence between regions and words. We study multi-modal and correspondence extensions to Hofmann’s hierarchical clustering/aspect model, a translation model adapted from statistical machine translation (Brown et al.), and a multi-modal extension to latent dirichlet allocation (LDA). All models are assessed using a large collection of annotated images of real scenes. We study in depth the difficult problem of measuring performance. For the annotation task, we look at prediction performance on held out data. We present three alternative measures, oriented toward different types of task. Measuring the performance of correspondence methods is harder, because one must determine whether a word has been placed on the right region of an image. We can use annotation performance as a proxy measure, but accurate measurement requires hand labeled data, and thus must occur on a smaller scale. We show results using both an annotation proxy, and manually labeled data.",,https://www.semanticscholar.org/paper/68338de07d3a097920ac74118c00539b9c411a69,
471,On the k-server conjecture,,1994-05-23,https://www.semanticscholar.org/paper/8137870c0007aefddb92366c2eadcd8dff582567,Symposium on the Theory of Computing
20,A Protocol and Toolkit for Metasearching,"This paper describes how SDLIP and STARTS, two complementary protocols for searching over distributed document collections, were combined. The resulting protocol, called SDARTS, is simple yet expressible enough to enable building sophisticated metasearch engines. SDARTS can be viewed as an instantiation of SDLIP with metasearch-specific elements from STARTS. The paper also reports on the experience of building three SDARTS-compliant wrappers: for locally available plain-text document collections, for locally available XML document collections, and for external Web-accessible collections. These wrappers were developed to be easily customizable for new collections. This work was developed as part of Columbia University's Digital Libraries Initiative-Phase 2 (DLI2) project, which involves the departments of Computer Science, Medical Informatics, and Electrical Engineering, the Columbia University libraries, and a large number of industrial partners. The main goal of the project is to provide personalized access to a distributed patient-care digital library. (Contains 24 references.) (Author/AEF) Reproductions supplied by EDRS are the best that can be made from the original document. PERMISSION TO REPRODUCE AND DISSEMINATE THIS MATERIAL HAS BEEN GRANTED BY",,https://www.semanticscholar.org/paper/7d30a3891840a188bea22dba8d6ebd0ac1a59bd7,
2319,Role of Fc gamma receptors in the activation of neutrophils by soluble and insoluble immunoglobulin aggregates isolated from the synovial fluid of patients with rheumatoid arthritis.,"OBJECTIVES--Synovial fluid from patients with rheumatoid arthritis contains both soluble and insoluble immunoglobulin aggregates which activate reactive oxidant production in human neutrophils. The objectives were to determine the roles played by Fc gamma receptors in activation of neutrophils by these complexes. METHODS--Pronase treatment was used to remove Fc gamma RIII from the neutrophil surface and blocking monoclonal antibodies were used to prevent the binding of complexes to Fc gamma RII and Fc gamma RIII. RESULTS--When Fc gamma RIII was removed from the cell surface by pronase treatment, activation by the soluble aggregates did not occur [mean (SD) inhibition 89 (16)%, n = 6] whereas activation via the insoluble aggregates was less affected [34 (16)%, n = 6]. Blocking the binding to Fc gamma RIII with antibodies decreased activation in response to the soluble aggregates [mean (SD) inhibition 71 (22)%, n = 8] but again had a lower effect on activation by the insoluble aggregates [40 (17)%, n = 9]. When binding to Fc gamma RII was blocked, activation via the soluble aggregates was substantially inhibited [mean (SD) 93 (13)%, n = 8] whereas that via the insoluble aggregates was inhibited to a much lesser extent [28 (38)%, n = 9]. When Fc gamma RII and III were simultaneously blocked, activation by the insoluble aggregates was only inhibited by 45% [(19), n = 5]. CONCLUSION--These data thus indicate that activation of human neutrophils by soluble immunoglobulin aggregates from rheumatoid synovial fluid occurs via cooperative occupancy of both Fc gamma RII and III: perturbation of binding to either of these receptor classes will abrogate activation.",1994-08-01,https://www.semanticscholar.org/paper/2358b0357a1c04a33b634fa26a2f545a7fb3ac33,Annals of the Rheumatic Diseases
71,QProber,"The contents of many valuable Web-accessible databases are only available through search interfaces and are hence invisible to traditional Web ""crawlers."" Recently, commercial Web sites have started to manually organize Web-accessible databases into Yahoo!-like hierarchical classification schemes. Here we introduce QProber, a modular system that automates this classification process by using a small number of query probes, generated by document classifiers. QProber can use a variety of types of classifiers to generate the probes. To classify a database, QProber does not retrieve or inspect any documents or pages from the database, but rather just exploits the number of matches that each query probe generates at the database in question. We have conducted an extensive experimental evaluation of QProber over collections of real documents, experimenting with different types of document classifiers and retrieval models. We have also tested our system with over one hundred Web-accessible databases. Our experiments show that our system has low overhead and achieves high classification accuracy across a variety of databases.",2003-01-01,https://www.semanticscholar.org/paper/9fb27fb5d86ece45b7e0529de70c446d4c37041d,ACM Transactions on Information Systems
9,Fast and Accurate Time-Series Clustering,"The proliferation and ubiquity of temporal data across many disciplines has generated substantial interest in the analysis and mining of time series. Clustering is one of the most popular data-mining methods, not only due to its exploratory power but also because it is often a preprocessing step or subroutine for other techniques. In this article, we present k-Shape and k-MultiShapes (k-MS), two novel algorithms for time-series clustering. k-Shape and k-MS rely on a scalable iterative refinement procedure. As their distance measure, k-Shape and k-MS use shape-based distance (SBD), a normalized version of the cross-correlation measure, to consider the shapes of time series while comparing them. Based on the properties of SBD, we develop two new methods, namely ShapeExtraction (SE) and MultiShapesExtraction (MSE), to compute cluster centroids that are used in every iteration to update the assignment of time series to clusters. k-Shape relies on SE to compute a single centroid per cluster based on all time series in each cluster. In contrast, k-MS relies on MSE to compute multiple centroids per cluster to account for the proximity and spatial distribution of time series in each cluster. To demonstrate the robustness of SBD, k-Shape, and k-MS, we perform an extensive experimental evaluation on 85 datasets against state-of-the-art distance measures and clustering methods for time series using rigorous statistical analysis. SBD, our efficient and parameter-free distance measure, achieves similar accuracy to Dynamic Time Warping (DTW), a highly accurate but computationally expensive distance measure that requires parameter tuning. For clustering, we compare k-Shape and k-MS against scalable and non-scalable partitional, hierarchical, spectral, density-based, and shapelet-based methods, with combinations of the most competitive distance measures. k-Shape outperforms all scalable methods in terms of accuracy. Furthermore, k-Shape also outperforms all non-scalable approaches, with one exception, namely k-medoids with DTW, which achieves similar accuracy. However, unlike k-Shape, this approach requires tuning of its distance measure and is significantly slower than k-Shape. k-MS performs similarly to k-Shape in comparison to rival methods, but k-MS is significantly more accurate than k-Shape. Beyond clustering, we demonstrate the effectiveness of k-Shape to reduce the search space of one-nearest-neighbor classifiers for time series. Overall, SBD, k-Shape, and k-MS emerge as domain-independent, highly accurate, and efficient methods for time-series comparison and clustering with broad applications.",2017-06-01,https://www.semanticscholar.org/paper/5242b843cd4543b575bd093d63711ef6cc8a9bad,ACM Transactions on Database Systems
533,A note on strategy elimination in bimatrix games,,1988-06-01,https://www.semanticscholar.org/paper/e216e702d05c8b53c1a0dca4fc40bb612bd769e1,
3523,An Õ(n2) algorithm for minimum cuts,"A minimum cut is a set of edges of minimum weight whose removal disconnects a given graph. Minimum cut algorithms historically applied duality with maximum flows and thus had the same 0 (inn) running time as maximum flow algorithms. More recent algorithms which are not based on maximum flows also require fl (inn) time. In this paper, we present the first algorithm that breaks the tl(mn) “max-flow barrier” for finding minimum cuts in weighted undirected graphs. We give a strongly polynomial randomized algorithm which finds a minimum cut with high probability in 0(n2 log3 n) time. This suggests that the rein-cut problem might be fundamentally easier to solve than the maximum flow problem. Our algorithm can be implemented in 72JUC using only nz processors—this is the first efficient 7UfC algorithm for the rein-cut problem. Our algorithm is simple and uses no complicated data structures.",1993-06-01,https://www.semanticscholar.org/paper/b4a4877c1bd4e514440dbbb877384b71fdc3c52b,Symposium on the Theory of Computing
994,Lamina depth and thickness correlate with glaucoma severity,"Purpose: To evaluate the correlation between lamina cribrosa (LC) morphology and glaucoma severity in patients with primary forms of open-angle glaucoma (OAG) using enhanced depth imaging spectral-domain optical coherence tomography (SD-OCT) and Humphrey visual field test (HVF). Subjects and Methods: Patients with OAG (n = 166), divided into normal-tension glaucoma (NTG) and high-tension glaucoma (HTG) groups (n = 66 and n = 100), were imaged using SD-OCT to obtain horizontal B-scan images of the optic nerve head (ONH). Laminar depth (LD) and laminar thickness (LT) were measured at the center of ONH. Results: The mean (±standard deviation) values of LD, LT, and visual field mean deviation (MD) were 555.4 ± 142.3 μm, 179.9 ± 49.7 μm, and − 5.7 ± 6.4 dB, respectively. In the multivariate linear regression analysis, LD, LT, and intraocular pressure (IOP) were significantly correlated with MD (P = 0.007, P = 0.037, and P = 0.004, respectively). In the subgroup analyses, only LD was associated with MD in the NTG group (n = 66), whereas LT and IOP were correlated with MD in the HTG group (n = 100). Neither axial length nor central corneal thickness was associated with LD or LT. Conclusions: Glaucoma severity, as measured by HVF MD, shows significant correlations with LD and LT, with greater severity associated with increasing LD and decreasing LT. Normal- and high-tension OAG patients have different associations with LD and LT, which implies that the pathogenesis of these two entities might be different.",2016-05-01,https://www.semanticscholar.org/paper/d202f2d4ae93b8afa2b7f82131b8f311819e5b86,Indian Journal of Ophthalmology
1871,Advanced quality control for probe precision forming to empower virtual vertical integration for semiconductor manufacturing,,2023-07-01,https://www.semanticscholar.org/paper/7cdb583b78ecf19f8c766822387b1747102e0dde,Computers & industrial engineering
3024,Easy Email Encryption with Easy Key Management CUCS-004-18,"Email privacy is of crucial importance. Existing email encryption approaches are comprehensive but seldom used due to their complexity and inconvenience. We take a new approach to simplify email encryption and improve its usability by implementing receiver-controlled encryption: newly received messages are transparently downloaded and encrypted to a locally-generated key; the original message is then replaced. To avoid the problem of users having to move a single private key between devices, we implement per-device key pairs: only public keys need be synchronized to a single device. Compromising an email account or server only provides access to encrypted emails. We have implemented this scheme for both Android and as a standalone daemon; we show that it works with both PGP and S/MIME, is compatible with widely used mail clients and email services including Gmail and Yahoo! Mail, has acceptable overhead, and that users consider it intuitive and easy to use. CCS Concepts •Security and privacy→ Key management; Public key encryption; Usability in security and privacy; Web application security;",,https://www.semanticscholar.org/paper/b1ad5871feec5f040d9ad098f79d6bed3cebc42c,
484,On Horn Envelopes and Hypergraph Transversals,,1993-12-15,https://www.semanticscholar.org/paper/eb16b514a506159032277e045f8bd906db88cb00,International Symposium on Algorithms and Computation
1280,Properties of L=1 B(1) and B(2)* mesons.,"This Letter presents the first strong evidence for the resolution of the excited B mesons B(1) and B(2)* as two separate states in fully reconstructed decays to B(+)(*)pi(-). The mass of B(1) is measured to be 5720.6+/-2.4+/-1.4 MeV/c(2) and the mass difference DeltaM between B(2)* and B(1) is 26.2+/-3.1+/-0.9 MeV/c;{2}, giving the mass of the B(2)* as 5746.8+/-2.4+/-1.7 MeV/c(2). The production rate for B(1) and B(2)* mesons is determined to be a fraction (13.9+/-1.9+/-3.2)% of the production rate of the B+ meson.",2007-05-01,https://www.semanticscholar.org/paper/65945c04eb3333a8993a10bda4a2b185cca376b5,Physical Review Letters
2604,Visual end user configuration of hybrid user interfaces,"Hybrid user interfaces are a promising paradigm for human-computer interaction, employing a range of displays and devices. However, most experimental hybrid user interfaces use a relatively rigid configuation. Our demo explores the possibilities of end users configuring the setup of a hybrid user interface, using novel interaction techniques and visualizations, based on a shared augmented reality.",2004-10-15,https://www.semanticscholar.org/paper/a64a05dd8f3854b5d5d2c3331ff49da0b17a99dc,ACM SIGMM workshop on Experiential Telepresence
3712,Discrete Representations Strengthen Vision Transformer Robustness,"Vision Transformer (ViT) is emerging as the state-of-the-art architecture for image recognition. While recent studies suggest that ViTs are more robust than their convolutional counterparts, our experiments find that ViTs trained on ImageNet are overly reliant on local textures and fail to make adequate use of shape information. ViTs thus have difficulties generalizing to out-of-distribution, real-world data. To address this deficiency, we present a simple and effective architecture modification to ViT's input layer by adding discrete tokens produced by a vector-quantized encoder. Different from the standard continuous pixel tokens, discrete tokens are invariant under small perturbations and contain less information individually, which promote ViTs to learn global information that is invariant. Experimental results demonstrate that adding discrete representation on four architecture variants strengthens ViT robustness by up to 12% across seven ImageNet robustness benchmarks while maintaining the performance on ImageNet.",2021-11-20,https://www.semanticscholar.org/paper/601ab36b6f077ff57472f4a0cf2e061dd05b9b85,International Conference on Learning Representations
3503,Improved Scheduling Algorithms for Minsum Criteria,,1996-07-08,https://www.semanticscholar.org/paper/1b45bdcb7cb3a51dd3fc952fc1795270a9b176b1,"International Colloquium on Automata, Languages and Programming"
263,"Sex, mixability, and modularity","The assumption that different genetic elements can make separate contributions to the same quantitative trait was originally made in order to reconcile biometry and Mendelism and ever since has been used in population genetics, specifically for the trait of fitness. Here we show that sex is responsible for the existence of separate genetic effects on fitness and, more generally, for the existence of a hierarchy of genetic evolutionary modules. Using the tools developed in the process, we also demonstrate that in terms of their fitness effects, separation and fusion of genes are associated with the increase and decrease of the recombination rate between them, respectively. Implications for sex and evolution theory are discussed.",2010-01-08,https://www.semanticscholar.org/paper/116b678d7a155845956de2204f6ee5151f8dd98b,Proceedings of the National Academy of Sciences of the United States of America
3350,The benefits of old age : social-welfare policy for the elderly,,1983-03-01,https://www.semanticscholar.org/paper/75063f4ce666eb6538aea2f5791f6f8489832414,
2728,Interactive constraint-based search and replace,"We describe enhancements to graphical search and replace that allow users to extend the capabilities of a graphical editor. Interactive constraint-based search and replace can search for objects that obey user-specified sets of constraints and automatically apply other constraints to modify these objects. We show how an interactive tool that employs this technique makes it possible for users to define sets of constraints graphically that modify existing illustrations or control the creation of new illustrations. The interace uses the same visual language as the editor and allows users to understand and create powerful rules without conventional programming. Rules can be saved and retrieved for use alone or in combination. Examples, generated with a working implementation, demonstrate applications to drawing beautification and transformation.",1992-06-01,https://www.semanticscholar.org/paper/ad78505acffdd64e206f27c19f93e20140622a65,International Conference on Human Factors in Computing Systems
3134,A SMART scheduler for multimedia applications,"Real-time applications such as multimedia audio and video are increasingly populating the workstation desktop. To support the execution of these applications in conjunction with traditional non-real-time applications, we have created SMART, a Scheduler for Multimedia And Real-Time applications. SMART supports applications with time constraints, and provides dynamic feedback to applications to allow them to adapt to the current load. In addition, the support for real-time applications is integrated with the support for conventional computations. This allows the user to prioritize across real-time and conventional computations, and dictate how the processor is to be shared among applications of the same priority. As the system load changes, SMART adjusts the allocation of resources dynamically and seamlessly. It can dynamically shed real-time computations and regulate the execution rates of real-time tasks when the system is overloaded, while providing better value in underloaded conditions than previously proposed schemes.We have implemented SMART in the Solaris UNIX operating system and measured its performance against other schedulers commonly used in research and practice in executing real-time, interactive, and batch applications. Our experimental results demonstrate SMART's superior performance over fair queueing and UNIX SVR4 schedulers in supporting multimedia applications.",2003-05-01,https://www.semanticscholar.org/paper/f06a958a1e03b1166f9877c746504941ec7b6758,TOCS
1100,Working Group Report: WIMP Dark Matter Direct Detection,"As part of the Snowmass process, the Cosmic Frontier WIMP Direct Detection subgroup (CF1) has drawn on input from the Cosmic Frontier and the broader Particle Physics community to produce this document. The charge to CF1 was (a) to summarize the current status and projected sensitivity of WIMP direct detection experiments worldwide, (b) motivate WIMP dark matter searches over a broad parameter space by examining a spectrum of WIMP models, (c) establish a community consensus on the type of experimental program required to explore that parameter space, and (d) identify the common infrastructure required to practically meet those goals.",2013-10-30,https://www.semanticscholar.org/paper/1c132df61a474f67700c6e6b59b2c04e382cfc7e,
2651,Guest Editors' Introduction: Virtual Reality,,,https://www.semanticscholar.org/paper/475aa90ce96d93c726805b5c4e04cafe35c0cc8e,IEEE Computer Graphics and Applications
2371,Protein synthesis is activated in primed neutrophils: a possible role in inflammation,,1987-11-01,https://www.semanticscholar.org/paper/cff0b72c32b69f38df8107f75e7104330ccab58b,Bioscience Reports
3493,Task Scheduling in Networks,"Scheduling a set of tasks on a set of machines so as to yield an efficient schedule is a basic problem in computer science and operations research. Most of the research on this problem incorporates the potentially unrealistic assumption that communication between the different machines is instantaneous. In this paper we remove this assumption and study the problem of network scheduling, where each job originates at some node of a network, and in order to be processed at another node must take the time to travel through the network to that node. 
Our main contribution is to give approximation algorithms and hardness proofs for fully general forms of the fundamental problems in network scheduling. We consider two basic scheduling objectives: minimizing the makespan and minimizing the average completion time. For the makespan, we prove small constant factor hardness-to-approximate and approximation results. For the average completion time, we give a log-squared approximation algorithm for the most general form of the problem. The techniques used in this approximation are fairly general and have several other applications. For example, we give the first nontrivial approximation algorithm to minimize the average weighted completion time of a set of jobs on related or unrelated machines, with or without a network.",1997-08-01,https://www.semanticscholar.org/paper/13ae8c0c690b6f4ec3441c696536f2a103f6e733,SIAM Journal on Discrete Mathematics
3107,AutoPod: Unscheduled System Updates with Zero Data Loss,"Patching, upgrading, and maintaining operating system software is a growing management complexity problem that can result in unacceptable system downtime. We introduce AutoPod, a system that enables unscheduled operating system updates while preserving application service availability. AutoPod provides a group of processes and associated users with an isolated machine-independent virtualized environment that is decoupled from the underlying operating system instance. This virtualized environment is integrated with a novel checkpoint-restart mechanism which allows processes to be suspended, resumed, and migrated across operating system kernel versions with different security and maintenance patches. AutoPod incorporates a system status service to determine when operating system patches need to be applied to the current host, then automatically migrates application services to another host to preserve their availability while the current host is updated and rebooted",2005-06-13,https://www.semanticscholar.org/paper/465c79de132a7179d8a0098908d0cc66b3be9494,International Conference on Automation and Computing
2205,236. Microparticle Micrornas Correlate with Disease Activity in Rheumatoid Arthritis and May Play a Significant Role in Pathogenesis,,2014-04-01,https://www.semanticscholar.org/paper/273281d456239b92889d208310553c1051b447ff,
1824,The nested chinese restaurant process and bayesian nonparametric inference of topic hierarchies,"We present the nested Chinese restaurant process (nCRP), a stochastic process that assigns probability distributions to ensembles of infinitely deep, infinitely branching trees. We show how this stochastic process can be used as a prior distribution in a Bayesian nonparametric model of document collections. Specifically, we present an application to information retrieval in which documents are modeled as paths down a random tree, and the preferential attachment dynamics of the nCRP leads to clustering of documents according to sharing of topics at multiple levels of abstraction. Given a corpus of documents, a posterior inference algorithm finds an approximation to a posterior distribution over trees, topics and allocations of words to levels of the tree. We demonstrate this algorithm on collections of scientific abstracts from several journals. This model exemplifies a recent trend in statistical machine learning—the use of Bayesian nonparametric methods to infer distributions on flexible data structures.",2007-10-03,https://www.semanticscholar.org/paper/6d296b269991f165b650a6360254a7413e966d27,JACM
1783,Introduction to Probabilistic Topic Models,"Probabilistic topic models are a suite of algorithms whose aim is to discover the hidden thematic structure in large archives of documents. In this article, we review the main ideas of this ﬁeld, survey the current state-of-the-art, and describe some promising future directions. We ﬁrst describe latent Dirichlet allocation (LDA) [8], which is the simplest kind of topic model. We discuss its connections to probabilistic modeling, and describe two kinds of algorithms for topic discovery. We then survey the growing body of research that extends and applies topic models in interesting ways. These extensions have been developed by relaxing some of the statistical assumptions of LDA, incorporating meta-data into the analysis of the documents, and using similar kinds of models on a diversity of data types such as social networks, images and genetics. Finally, we give our thoughts as to some of the important unexplored directions for topic modeling. These include rigorous methods for checking models built for data exploration, new approaches to visualizing text and other high dimensional data, and moving beyond traditional information engineering applications towards using topic models for more scientiﬁc ends.",,https://www.semanticscholar.org/paper/5f1038ad42ed8a4428e395c96d57f83d201ef3b3,
2911,A crystal plasticity model that accounts for grain size effects and slip system interactions on the deformation of austenitic stainless steels,,2022-02-01,https://www.semanticscholar.org/paper/952738cac8c557ed5b2eb5af1e9ac7eb3bd87d68,International journal of plasticity
2321,Disorders of neutrophil function,,,https://www.semanticscholar.org/paper/3d6296bdbe8ddbb52e02efdb37a83ba715d2c399,
1561,A Digital Field Experiment Reveals Large Effects of Friend-to-Friend Texting on Voter Turnout,"Two decades of field experiments on get-out-the-vote tactics suggest that impersonal tactics, like mass emails, have only a modest or negligible effect on voter turnout, while more personal tactics, like door-to-door canvassing, are more effective. However, the COVID-19 pandemic threatens to upend the vast face-to-face voter mobilization efforts that have figured prominently in recent presidential election campaigns. If campaigns can no longer send canvassers to voters' doors, what tactics can they turn to in order to mobilize their supporters? This paper evaluates a promising alternative to face-to-face get-out-the-vote tactics: mobile app technology that enables millions of people to message their friends to urge them to vote. Prior to the most recent US midterm elections in 2018, the mobile app Outvote randomized an aspect of their system, hoping to unobtrusively assess the causal effect of their users' messages on voter turnout. We develop a statistical methodology to address the challenges of such data, and then analyze the Outvote study. Our analysis reveals evidence of very large and statistically significant treatment effects from friend-to-friend mobilization efforts ($\widehat{\textrm{CACE}}$= 8.3, $\textrm{CI}$ = (1.2, 15.3)). Further, the statistical methodology can be used to study other friend-to-friend messaging efforts. These results suggest that friend-to-friend texting, which is a personal voter mobilization effort that does not require face-to-face contact, is an effective alternative to conventional voter mobilization tactics.",2020-09-21,https://www.semanticscholar.org/paper/a75c9e46d5d5d84fb5b089186af123a20e22d8e6,Social Science Research Network
2521,Exploring interfaces to botanical species classification,"We have developed several prototype user interfaces for botanical species identification and data collection across a diversity of platforms including Tablet PC, Ultra Mobile PC (UMPC), Apple iPhone, Augmented Reality, and Microsoft Surface. In our demonstration, we show UMPC and iPhone user interfaces, discuss the commonalities and distinctions across the different interfaces, and invite visitors to explore these differences. Our prototypes address several issues of interest to the CHI community including mobile interfaces, interfaces to object recognition, and visualization.",2010-04-09,https://www.semanticscholar.org/paper/7e5ef85047567f9f86fb6a19e79b750abb78d136,CHI Extended Abstracts
3068,Proceedings of the eleventh international joint conference on Measurement and modeling of computer systems,"It is our great pleasure to welcome you to SIGMETRICS/Performance 2009. SIGMETRICS is the flagship conference of the ACM special interest group for the computer systems performance evaluation community. Performance is the flagship conference of the IFIP working group on performance modeling and analysis. Every three years, the two conferences are held jointly, and this is the eleventh joint conference. 
 
This year, we will continue with several of the innovations introduced at last year's SIGMETRICS program. The main conference will again be a full three days, featuring 27 papers, 21 posters, and three invited talks from computer science luminaries, both academic and industrial. We will also reprise the demo competition and student thesis panel that were so well received last year. We are introducing an industrial information seminar, to provide an opportunity for students and academics to hear from representatives in industrial research about performance-related projects and their impact on deployed products and services. 
 
Supplementing the main conference are four interesting workshops, ranging from the venerable to the avant-garde. The workshop on MAthematical performance Modeling and Analysis (MAMA) continues its eleventh year as a forum for talks on early research in the more mathematical areas of computer performance analysis. The workshop on Hot Topics in Metrics (HotMetrics), which had a stellar inauguration last year, will reprise its role in helping to identify ""big"" and ""hard"" problems in performance evaluation and to develop innovative approaches to solving them. We also introduce two new workshops this year: GreenMetrics will explore how improvements to or new uses of Information and Communication Technology (ICT) can contribute towards efforts to minimize global climate change, a problem of increasing importance in modern society. The Learning for Networking workshop will investigate the use of machine learning techniques to tackle the increasingly complex architecture and control features in telecommunications and computer networks. 
 
This year also features a splendid series of tutorials, on topics ranging from social networks to data-center networks, from data-flow programming to packet-flow configuration, and from internet measurement to internet service construction.",2009-06-15,https://www.semanticscholar.org/paper/16d38d2d0ceeb3f909fea66e514fb397232888a5,Measurement and Modeling of Computer Systems
3611,C and C + + : a Case for Compatibility,"This article presents a case for significantly increasing the degree of compatibility between C and C++. The ideal proposed is full compatibility. This ideal is not trivially obvious nor technically easy to achieve. Therefore, arguments against full compatibility are presented as well as arguments for. A companion paper [Stroustrup,2002a] provides a ‘‘philosophical’’ view of the C/C++ relationship, and a follow-up article will present some examples of how incompatibilities might be resolved [Stroustrup,2002c]. 1 Languages and Communities Modern C [C89] [C99] and C++ [C++98] are sibling languages [Stroustrup,2002] [Stroustrup,2002a] descended from Classic C [Kernighan,1978]. In many people’s minds they are (wrongly, but understandably) fused into the mythical C/C++ programming language. There is no C/C++ language, but there is a C/C++ community. The primary aim of this article is to examine how the future evolution of C and C++ can best serve that community. My claim is that a significant increase in the degree of C/C++ compatibility best serves the interests of the C/C++ community and that the ideal is full C/C++ compatibility. What is the C/C++ community? Millions of programmers use C and/or C++ so any individual and any organization necessarily has an incomplete picture of the situation and often a biased one. Consider for a moment three groups: [1] programmers who use C only [2] programmers who use C++ only [3] programmers who use both C and C++ Within each group, we can again look at a multitude of classifications. For example, students, teachers, occasional programmers, games programmers, builders of large systems, embedded systems programmers, scientific/numeric programmers, builders of small commercial applications, programmers with a great need for portability, builders of applications embedded in large commercial frameworks, software tool builders, programmers of large infrastructure applications, etc. It is hard to place an individual in a single category. Importantly, many programmers belong to several of these groups and subgroups during a career, even if they are currently comfortable in some single category. Are there people who use C++ and never C? Of course there are many C++ programmers who never compiled a C source file, but how many C++ programs don’t call a C library? If a C library is used directly, the programmer must understand the constructs appearing in its header files. Even if C code is used only indirectly, some aspects of C must often be taken into account, such as C’s use of m a l l o c () rather than n e w , the use of arrays rather than C++ standard library containers, and the absence of exception handling. The use a C in one part of a program often affects other parts of the program, so that a C++ programmer must be aware of C. And of course, the C++ standard library includes the C89 standard library. It is only a slight exaggeration to say that all C++ programmers are C programmers. On the other hand, there are C programmers who never use C++. This is obviously true for programmers who – especially in the embedded systems community – work on a platform for which no C++ compiler exist. There are fewer such platforms than there used to be, though, and not all of those support ISO Part of a three-article series from ""The C/C++ Users Journal"" July, August, and September 2002",,https://www.semanticscholar.org/paper/1468f4d31934c08b56637f557bdad5ffc6639482,
3632,A perspective on ISO C,This paper offers a personal view of C++ as it stands after the release of the first public draft of the ANSI/ISO C++ standard. It reviews the aims of the language and discuss how the standards process has helped achieve them. The language as it is currently defined is illustrated through two example: one focussing on language features and one focussing on the standard library.,1996-05-01,https://www.semanticscholar.org/paper/9344b3e607566e8e11ef7bb2a37aa6af4d82b849,
3688,There’s a Time and Place for Reasoning Beyond the Image,"Images are often more significant than only the pixels to human eyes, as we can infer, associate, and reason with contextual information from other sources to establish a more complete picture. For example, in Figure 1, we can find a way to identify the news articles related to the picture through segment-wise understandings of the signs, the buildings, the crowds, and more. This reasoning could provide the time and place the image was taken, which will help us in subsequent tasks, such as automatic storyline construction, correction of image source in intended effect photographs, and upper-stream processing such as image clustering for certain location or time.In this work, we formulate this problem and introduce TARA: a dataset with 16k images with their associated news, time, and location, automatically extracted from New York Times, and an additional 61k examples as distant supervision from WIT. On top of the extractions, we present a crowdsourced subset in which we believe it is possible to find the images’ spatio-temporal information for evaluation purpose. We show that there exists a 70% gap between a state-of-the-art joint model and human performance, which is slightly filled by our proposed model that uses segment-wise reasoning, motivating higher-level vision-language joint models that can conduct open-ended reasoning with world knowledge.The data and code are publicly available at https://github.com/zeyofu/TARA.",2022-03-01,https://www.semanticscholar.org/paper/02fff38be9c6caa03a0bfb0de61090971fe2c072,Annual Meeting of the Association for Computational Linguistics
1405,Table 5 ; Inclusive jet production in $p\bar{p}$ collisions,,,https://www.semanticscholar.org/paper/042393f81d0dc7e6d612dfc534755eafaa0683a0,
36,Introduction to the Special Issue on Man aging Information Extraction,"The field of information extraction (IE) focuses on extracting structured data, such as person names and organizations, from unstructured text. This field has had a long history. It attracted steady attention in the 80s and 90s, largely in the AI community. In the past decade, however, spurred on by the explosion of unstructured data on the World-Wide Web, this attention has turned into a torrent, gathering the efforts of researchers in the AI, DB, WWW, KDD, Semantic Web and IR communities. New IE problems have been identified, new IE techniques developed, many workshops organized, tutorials presented, companies founded, academic and industrial products deployed, and opensource prototypes developed (e.g., [5, 4, 3, 1, 2]; see [5] for the latest survey). The next few years are poised to witness even more accelerated activities in these areas. It is against this vibrant backdrop that we assemble this special issue. Our objective is threefold. First, we want to provide a glimpse into the current state of the field, highlighting in particular the wide range of IE problems. Second, we want to show that many IE problems can significantly benefit from the wealth of work on managing structured data in the database community. We believe therefore that our community can make a substantial contribution to the IE field. Finally, we hope that examining IE problems can in turn help us gain valuable insights into managing data in this Internet-centric world, a long-term goal of our community. Keeping in mind the above goals, we end this introduction by briefly describing the nine papers assembled for the issue. These papers fall into four broad categories.",,https://www.semanticscholar.org/paper/24a28b80b45b5e2f1eaeeefd7702701211f42b8f,
2140,Automotive Piston-Engine Noise And Its Reduction - A Literature Survey,,1969-02-01,https://www.semanticscholar.org/paper/41c6cc4b2803fcca8c8dd7f79a4e001919ddd103,
2076,"Vice President, Industrial Activities",,,https://www.semanticscholar.org/paper/348aa827824d0f30aa1d1b9b75a82666fe954eb7,
824,"Proceedings of the Fourteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, May 22-25, 1995, San Jose, California, USA",,1995-05-22,https://www.semanticscholar.org/paper/39cc47184bd378c934bf021dc181c032514a9e94,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
404,Worst-case Equilibria,,1999-03-04,https://www.semanticscholar.org/paper/3ae866f55cebbffe18d07c27d7d5fd1b7dea6e14,Symposium on Theoretical Aspects of Computer Science
1098,SuperCDMS status from Soudan and plans for SNOLab.,"Matter, as we know it, makes up less than 5% of the Universe. Various astrophysical observations have confirmed that one quarter of the Universe and most of the matter content in the Universe is made up of Dark Matter. The nature of Dark Matter is yet to be discovered and is one of the biggest questions in Physics. Particle Physics combined with astrophysical measurements of the abundance gives rise to a Dark Matter candidate called Weakly Interacting Massive Particle (WIMP). The low density of WIMPs in the galaxies and the extremely weak nature of the interaction with ordinary matter make detection of the WIMP an extraordinarily challenging task, with abundant fakes from various radioactive and cosmogenic backgrounds with much stronger electromagnetic interaction. The extremely weak nature of the WIMP interaction dictates detectors that have extremely low naturally occurring radioactive background, a large active volume (mass) of sensitive detector material to maximize statistics, a highly efficient detector based rejection mechanism for the dominant electromagnetic background and sophisticated analysis techniques to reject any residual background. This paper describes the status of the SuperCDMS experiment.",2013-05-23,https://www.semanticscholar.org/paper/0e81fba751544cb6bd7b988ddc1e65d583e19d6c,
3085,DejaView: a personal virtual computer recorder,"As users interact with the world and their peers through their computers, it is becoming important to archive and later search the information that they have viewed. We present DejaView, a personal virtual computer recorder that provides a complete record of a desktop computing experience that a user can playback, browse, search, and revive seamlessly. DejaView records visual output, checkpoints corresponding application and file system state, and captures displayed text with contextual information to index the record. A user can then browse and search the record for any visual information that has been displayed on the desktop, and revive and interact with the desktop computing state corresponding to any point in the record. DejaView combines display, operating system, and file system virtualization to provide its functionality transparently without any modifications to applications, window systems, or operating system kernels. We have implemented DejaView and evaluated its performance on real-world desktop applications. Our results demonstrate that DejaView can provide continuous low-overhead recording without any user noticeable performance degradation, and allows browsing, search and playback of records fast enough for interactive use.",2007-10-14,https://www.semanticscholar.org/paper/18efc6ae1f845e710b256bdcc39ffd1fa6a79661,Symposium on Operating Systems Principles
361,Congestion Games : Allocating Bandwidth,"We continue the discussion from last time, on Shenker’s paper. Recall the setting of the bandwidth allocation, in which we have a switch that is shared among n users. Each user presents to the switch a rate ri, and is serviced, acording to the service discipline Ā, reflected in an expected queue length qi = Ai(r̄). This is represented in the diagram of Figure 4.1. We observe that the game created in this setting, by setting the payoffs to be equal to the utilities of each user, pi(r̄) = Ui(ri, Ai(r̄)), actually depends on the Ai chosen. This leads to the following question, which is central to Mechanism Design: can we create a game, by cleverly choosing the service discipline (and therefore the allocation function), such that the Nash equilibria are of ‘high quality’? The following theorem is an impossibility result in this direction, answering this question negatively if we consider all possible sets of utility functions.",,https://www.semanticscholar.org/paper/d641014ef614763b4ae49135e5914030a091a08d,
1835,A correlated topic model of Science,"Topic models, such as latent Dirichlet allocation (LDA), can be useful tools for the statistical analysis of document collections and other discrete data. The LDA model assumes that the words of each document arise from a mixture of topics, each of which is a distribution over the vocabulary. A limitation of LDA is the inability to model topic correlation even though, for example, a document about genetics is more likely to also be about disease than X-ray astronomy. This limitation stems from the use of the Dirichlet distribution to model the variability among the topic proportions. In this paper we develop the correlated topic model (CTM), where the topic proportions exhibit correlation via the logistic normal distribution [J. Roy. Statist. Soc. Ser. B 44 (1982) 139--177]. We derive a fast variational inference algorithm for approximate posterior inference in this model, which is complicated by the fact that the logistic normal is not conjugate to the multinomial. We apply the CTM to the articles from Science published from 1990--1999, a data set that comprises 57M words. The CTM gives a better fit of the data than LDA, and we demonstrate its use as an exploratory tool of large document collections.",2007-06-01,https://www.semanticscholar.org/paper/e981f16fde9185373634b53d94baa1f9185ff890,
1906,An Integrated Approach for IC Design R&D Portfolio Decision and Project Scheduling and a Case Study,"Research and development (R&D) projects are crucial for semiconductor companies to maintain growth, profitability, and competitiveness. Integrated circuit (IC) design is capital intensive and continuously migrates to new technologies to meet various market demands. Moreover, the scheduling of selected R&D projects that enables technology roadmap involving complicated interrelationships, while competing for similar resources. Focusing on realistic needs, this paper aims to propose an integrated approach for selecting IC design projects for R&D portfolios and scheduling the selected projects simultaneously. In particular, a hybrid autotuning multiobjective genetic algorithm was developed to solve large sized problem instances. An empirical study was conducted at a leading IC design service company in Taiwan to test the validity of the proposed approach. The proposed algorithm was compared with conventional approaches for both convergence and diversity. The results have shown the practical viability of this approach in efficiently and effectively generating near-optimal portfolio alternatives for portfolio selection. The approach also enables the scheduling of the selected projects to achieve R&D portfolio objectives. The developed solution was fully implemented and adopted by the company.",2018-01-12,https://www.semanticscholar.org/paper/6a9664cbd7d3e41c746ae1dc2fb0925489bbb2c0,IEEE transactions on semiconductor manufacturing
1532,CAREER: Transfer Learning for Economic Prediction of Labor Sequence Data,"Labor economists regularly analyze employment data by fitting predictive models to small, carefully constructed longitudinal survey datasets. Although modern machine learning methods offer promise for such problems, these survey datasets are too small to take advantage of them. In recent years large datasets of online resumes have also become available, providing data about the career trajectories of millions of individuals. However, standard econometric models cannot take advantage of their scale or incorporate them into the analysis of survey data. To this end we develop CAREER, a transformer-based model that uses transfer learning to learn representations of job sequences. CAREER is first fit to large, passively-collected resume data and then fine-tuned to smaller, better-curated datasets for economic inferences. We fit CAREER to a dataset of 24 million job sequences from resumes, and fine-tune its representations on longitudinal survey datasets. We find that CAREER forms accurate predictions of job sequences on three widely-used economics datasets. We further find that CAREER can be used to form good predictions of other downstream variables; incorporating CAREER into a wage model provides better predictions than the econometric models currently in use.",2022-02-16,https://www.semanticscholar.org/paper/e8f170e3eee1fce6c9e9d6ca7b7f56f97a40e02b,
67,Text joins for data cleansing and integration in an RDBMS,"An organization's data records are often noisy because of transcription errors, incomplete information, lack of standard formats for textual data or combinations thereof. A fundamental task in a data cleaning system is matching textual attributes that refer to the same entity (e.g., organization name or address). This matching is effectively performed via the cosine similarity metric from the information retrieval field. For robustness and scalability, these ""text joins"" are best done inside an RDBMS, which is where the data is likely to reside. Unfortunately, computing an exact answer to a text join can be expensive. We propose an approximate, sampling-based text join execution strategy that can be robustly executed in a standard, unmodified RDBMS.",2003-03-05,https://www.semanticscholar.org/paper/667f5206d5afab49f830a24849bf14d5a6ad5564,Proceedings / International Conference on Data Engineering
2014,Constructing a Comprehensive Modular Fuzzy Ranking Framework and Illustrations,"This study aims to develop a modular fuzzy ranking framework that can systematically decompose the fuzzy ranking methods into specific modules. Thus, the decision maker can examine various fuzzy ranking methods based on the proposed framework with the corresponding objectives. We used two fuzzy ranking methods for illustration to estimate the feasibility and validity of the proposed framework. Furthermore, we proposed eight desirable characteristics of a fuzzy ranking method, in which the logical relationships between the proposed framework and these desirable characteristics are discussed. Based on the modular fuzzy ranking framework and the desirable characteristics, effective strategies are proposed for improving fuzzy ranking methods to enhance decision quality.",2011-08-31,https://www.semanticscholar.org/paper/78a42762434ec0fbfdb1827dd358858fad5038e7,
599,The complexity of distributed concurrency control,"We present a formal framework for distributed databases, and we study the complexity of the concurrency control problem in this framework. Our transactions are partially ordered sets, of actions, as opposed to the straight-line programs of the centralized case. The concurrency control algorithm, or scheduler, is itself a distributed program. Three notions of performance of the scheduler are studied and interrelated: (i) its parallelism, (ii) the computational complexity of the problems it needs to solve, and (iii) the cost of communication between the various parts of the scheduler. We show that the number of messages necessary and sufficient to support a given level of parallelism is equal to the minmax value of a combinatorial game. We show that this game is PSPACE-complete. It follows that, unless NP=PSPACE, a scheduler cannot simultaneously minimize communication and be computationally efficient. This result, we argue, captures the quantum jump in complexity of the transition from centralized to distributed concurrency control problems.",1981-10-28,https://www.semanticscholar.org/paper/0de37de50ce23ae2851bc05ee1fb1be27aeb42bd,22nd Annual Symposium on Foundations of Computer Science (sfcs 1981)
3515,A 2-3/4-Approximation Algorithm for the Shortest Superstring Problem,"Given a collection of strings S={s_1,...,s_n} over an alphabet Sigma, a superstring alpha of S is a string containing each s_i as a substring, that is, for each i, 1>=i>=n, alpha contains a block of |s_i| consecutive characters that match s_i exactly. The shortest superstring problem is the problem of finding a superstring alpha of minimum length. The shortest superstring problem has applications in both computational biology and data compression. The problem is NP-hard [GallantMS80]; in fact, it was recently shown to be MAX SNP-hard [BlumJLTY91]. Given the importance of the applications, several heuristics and approximation algorithms have been proposed. Constant factor approximation algorithms have been given in [BlumJLTY91] (factor of 3), [TengY93] (factor of 2-8/9), [CzumajGPR94] (factor of 2-5/6) and [KosarajuPS94] (factor of 2-50/63). Informally, the key to any algorithm for the shortest superstring problem is to identify sets of strings with large amounts of similarity, or overlap. While the previous algorithms and their analyses have grown increasingly sophisticated, they reveal remarkably little about the structure of strings with large amounts of overlap. In this sense, they are solving a more general problem than the one at hand. In this paper, we study the structure of strings with large amounts of overlap and use our understanding to give an algorithm that finds a superstring whose length is no more than 2-3/4 times that of the optimal superstring. We prove several interesting properties about short periodic strings, allowing us to answer questions of the following form: given a string with some periodic structure, characterize all the possible periodic strings that can have a large amount of overlap with the first string.",,https://www.semanticscholar.org/paper/92dacca58875a582df11eee357216c5c7108ad0d,
2142,Real-time delay with network coding and feedback,,2013-03-01,https://www.semanticscholar.org/paper/eb3b4f85af38bc9f855cea4d67dae5cfcd8fe5a2,Physical Communication
123,Precision and recall of GlOSS estimators for database discovery,"Online information vendors and the Internet together offer thousands of text databases from which a user may choose for a given information need. This paper presents a framework for and analyses a solution to this problem, which we call the text-database discovery problem. Our solution is to build a service that can suggest potentially good databases to search. A user's query goes through two steps: first, the query is presented to the GlOSS server (Glossary-Of-Servers Server) to select a set of promising databases to search. Secondly, the query is actually evaluated in the chosen databases. GlOSS gives a hint of what databases might be useful for the user's query, based on word-frequency information for each database. This information indicates how many documents in each database actually contain a keyword, for each field designator. To evaluate the set of databases that GlOSS returns for a given query, we present a framework based on the precision and recall metrics of information retrieval theory. We define metrics for the text-database discovery problem. We further extend our framework by offering different definitions for a ""relevant database"". We have performed experiments using query traces from the FOLIO library information retrieval system, involving six databases available through FOLIO. The results obtained for different variants of GlOSS are very promising. Even though GlOSS keeps a small amount of information about the contents of the available databases, this information proved to be sufficient to produce very useful hints on where to search.<<ETX>>",1994-10-01,https://www.semanticscholar.org/paper/3c0c8394cbbc2fd71e3de082b2f676f45ee3f95d,Proceedings of 3rd International Conference on Parallel and Distributed Information Systems
969,Effect of Ubiquinol on Glaucomatous Neurodegeneration and Oxidative Stress: Studies for Retinal Ganglion Cell Survival and/or Visual Function,"Oxidative stress is one of major causal factors in glaucomatous neurodegeneration. Ubiquinol promotes retinal ganglion cell (RGC) survival against glaucomatous insults such as oxidative stress. Here we investigated the effect of ubiquinol on RGC survival and/or visual function in mouse models of glaucoma and oxidative stress. DBA/2J and age-matched DBA/2J-Gpnmb+ (D2-Gpnmb+), which do not develop intraocular pressure elevation, or C57BL/6J mice were fed with ubiquinol (1%) or control diet daily for 5 or 2 months. We assessed RGC survival by Brn3a immunohistochemistry and measured expression levels of active and total BAX, peroxisome proliferator-activated receptor-gamma coactivator 1α, transcription factor A (TFAM) and oxidative phosphorylation (OXPHOS) complex protein. Following induction of oxidative stress by paraquat injection, we also assessed visual function. In glaucomatous retina, ubiquinol supplementation significantly promoted RGC survival, blocked BAX activation and increased TFAM and OXPHOS complex II protein expression. Also, ubiquinol supplementation ameliorated oxidative stress-induced visual dysfunction. These findings indicate that ubiquinol promotes RGC survival by increasing TFAM expression and OXPHOS complex II activity in glaucomatous neurodegeneration, and that ubiquinol enhances RGC survival and preserves visual function against oxidative stress. We propose that ubiquinol has a therapeutic potential for treating oxidative stress-associated glaucomatous neurodegeneration.",2020-10-01,https://www.semanticscholar.org/paper/f134e2b5450fbce65c7ce6dd4ae934a774f35b11,Antioxidants
2054,An evolutionary approach to rehabilitation patient scheduling: A case study,,2008-09-16,https://www.semanticscholar.org/paper/86e6415148a5703252086032c11dcead3d9ad713,European Journal of Operational Research
1588,Exponential Families,"Surprisingly many of the distributions we use in statistics for random variables X taking value in some space X (often R or N0 but sometimes R n, Z, or some other space), indexed by a parameter θ from some parameter set Θ, can be written in exponential family form, with pdf or pmf f(x | θ) = exp [η(θ)t(x) −B(θ)] h(x) for some statistic t : X → R, natural parameter η : Θ → R, and functions B : Θ → R and h : X → R+. The likelihood function for a random sample of size n from the exponential family is",2018-11-19,https://www.semanticscholar.org/paper/077cacdc9754c7dc2c7fa072ee57417cb7d61218,Graduate Studies in Mathematics
1689,Copula variational inference,"We develop a general variational inference method that preserves dependency among the latent variables. Our method uses copulas to augment the families of distributions used in mean-field and structured approximations. Copulas model the dependency that is not captured by the original variational distribution, and thus the augmented variational family guarantees better approximations to the posterior. With stochastic optimization, inference on the augmented distribution is scalable. Furthermore, our strategy is generic: it can be applied to any inference procedure that currently uses the mean-field or structured approach. Copula variational inference has many advantages: it reduces bias; it is less sensitive to local optima; it is less sensitive to hyperparameters; and it helps characterize and interpret the dependency among the latent variables.",2015-06-10,https://www.semanticscholar.org/paper/c8d44c88691ec27e37038db9cbea15d96b06d3af,Neural Information Processing Systems
1775,Nonparametric Mixed Membership Modelling Using the IBP Compound Dirichlet Process,,2011-04-24,https://www.semanticscholar.org/paper/9b652a613bf96fdcd04137270e12d0a7cf15519f,
2587,Immersive mixed-reality configuration of hybrid user interfaces,"Information in hybrid user interfaces can be spread over a variety of different, but complementary, displays, with which users interact through a potentially equally varied range of interaction devices. Since the exact configuration of these displays and devices may not be known in advance, it is desirable for users to be able to reconfigure at runtime the dataflow between interaction devices and objects on the displays. To make this possible, we present the design and implementation of a prototype mixed reality system that allows users to immersively reconfigure a running hybrid user interface.",2005-10-05,https://www.semanticscholar.org/paper/b32c07456c748aa7e234e48b04cff58b1ce8e2b0,International Symposium on Mixed and Augmented Reality
1870,Equal Opportunity and Afﬁrmative Action via Counterfactual Predictions,"Machine learning ( ML ) can automate decision-making by learning to predict decisions from historical data. However, these predictors may inherit discriminatory policies from past decisions and reproduce unfair decisions. In this paper, we propose two algorithms that adjust ﬁtted ML predictors to make them fair. We focus on two legal notions of fairness: (a) providing equal opportunities ( EO ) to individuals regardless of sensitive attributes and (b) repairing historical disadvantages through afﬁrmative action ( AA ). More technically, we produce fair EO and AA predictors by positing a causal model and considering counterfactual decisions. We prove that the resulting predictors are theoretically optimal in predictive performance while satisfying fairness. We evaluate the algorithms, and the trade-offs between accuracy and fairness, on datasets about admissions, income, credit, and recidivism.",,https://www.semanticscholar.org/paper/e12d5afc5f2b193788a865f4a9afed7b335f00ec,
3159,SMART: a processor scheduler for multimedia applications,"Applications that manipulate digital audio and video represent a growing class of computations executed by workstation users. This class of computations is known as continuous media. Their distinguishing characteristic is that they must process and transport media samples within application-specific time constraints. To support these real-time activities, the operating system must manage resources so that their time constraints can be satisfied whenever possible.",1995-12-03,https://www.semanticscholar.org/paper/d31ace6a28ebbb10d09db1a0868f1d6596f15f49,Symposium on Operating Systems Principles
1646,A Variational Analysis of Stochastic Gradient Algorithms,"Stochastic Gradient Descent (SGD) is an important algorithm in machine learning. With constant learning rates, it is a stochastic process that, after an initial phase of convergence, generates samples from a stationary distribution. We show that SGD with constant rates can be effectively used as an approximate posterior inference algorithm for probabilistic modeling. Specifically, we show how to adjust the tuning parameters of SGD such as to match the resulting stationary distribution to the posterior. This analysis rests on interpreting SGD as a continuous-time stochastic process and then minimizing the Kullback-Leibler divergence between its stationary distribution and the target posterior. (This is in the spirit of variational inference.) In more detail, we model SGD as a multivariate Ornstein-Uhlenbeck process and then use properties of this process to derive the optimal parameters. This theoretical framework also connects SGD to modern scalable inference algorithms; we analyze the recently proposed stochastic gradient Fisher scoring under this perspective. We demonstrate that SGD with properly chosen constant rates gives a new way to optimize hyperparameters in probabilistic models.",2016-02-08,https://www.semanticscholar.org/paper/2a91c778288f67c856041447f350a1a022fc6554,International Conference on Machine Learning
2871,Association of a macrophage galactoside‐binding protein with Mycobacterium‐containing phagosomes,"Mycobacteria reside intracellularly in a vacuole that allows it to circumvent the antimicrobial environment of the host macrophage. Although the mycobacterial phagosome exhibits selective fusion with vesicles of the endosomal system, identification of host and bacterial factors associated with phagosome bio‐genesis is limited. To identify these potential factors, mAbs were generated to a membrane preparation of mycobacterial phagosomes isolated from M. tuberculosis‐infected macrophages. A mAb recognizing a 32–35 kDa macrophage protein associated with the phagosomal membrane of Mycobacterium was identified. N‐terminal sequence analysis identified this protein as Mac‐2 or galectin‐3, a galactoside‐binding protein of macrophages. Galectin‐3 (gal‐3) was shown to accumulate in Mycobacterium‐containing phagosomes during the course of infection. This accumu‐lation was specific for phagosomes containing live mycobacteria and occurred primarily at the cytosolic face of the phagosome membrane. In addition, bind‐ing of gal‐3 to mycobacterial phosphatidylinositol mannosides (PIMs) demonstrated a novel interaction between host carbohydrate‐binding proteins and released mycobacterial glycolipids. Infection of macrophages from gal‐3‐deficient mice indicated that the protein did not play a role in infection in vitro. In contrast, infection of gal‐3‐deficient mice revealed a reduced capacity to clear late but not early infection.",2002-03-01,https://www.semanticscholar.org/paper/8024de6479d2caff1b87e30c6ae459620e902cfe,Cellular Microbiology
3527,Fast approximation algorithms for multicommodity flow problems,"All previously known algorithms for solving the multicommodity flow problem with capacities are based on linear programming. The best of these algorithms uses a fast matrix multiplication algorithm and takes O(k3.5n3m0.5 log(nDU)) time for the multicommodity flow problem with integer demands and at least O(k2.5n2m0.5 log(n��1DU)) time to find an approximate solution, where k is the number of commodities, n and m denote the number of nodes and edges in the network, D is the largest demand, and U is the largest edge capacity. As a consequence, even multicommodity flow problems with just a few commodities are believed to be much harder than single-commodity maximum-flow or minimum-cost flow problems. In this paper, we describe the first polynomial-time combinatorial algorithms for approximately solving the multicommodity flow problem. The running time of our randomized algorithm is (up to log factors) the same as the time needed to solve k single-commodity flow problems, thus giving the surprising result that approximately computing a k-commodity maximum-flow is not much harder than computing about k single-commodity maximum-flows in isolation. In fact, we prove that a (simple) k-commodity flow problem can be approximately solved by approximately solving O(k log2n) single-commodity minimum-cost flow problems. Our k-commodity algorithm runs in O (knm log4n) time with high probability. We also describe a deterministic algorithm that uses an O(k)-factor more time. Given any multicommodity flow problem as input, both algorithms are guaranteed to provide a feasible solution to a modified flow problem in which all capacities are increased by a (1 + �)-factor, or to provide a proof that there is no feasible solution to the original problem. We also describe faster approximation algorithms for multicommodity flow problems with a special structure, such as those that arise in ""sparsest cut"" problems and uniform concurrent flow problems.",1991-01-03,https://www.semanticscholar.org/paper/32307dd1f82f26b0ee13fb4e417a98e86d18bb62,Symposium on the Theory of Computing
1070,Searching for Dark Matter,,,https://www.semanticscholar.org/paper/31b76a97bffe1833dd44aea154b692e59db7db5f,
965,Angular Location of Retinal Nerve Fiber Layer Defect: Association With Myopia and Open-Angle Glaucoma,"Purpose To compare retinal nerve fiber layer (RNFL) defects’ angle measurements determined from the center of the optic disc and Bruch's membrane opening (BMO), as a function of myopia and open-angle glaucoma (OAG) subtypes. Methods In total, 118 patients with OAG were grouped by axial length (AL; high myopia, AL >26 mm; mild to moderate myopia, 24 ≤ AL ≤26 mm; nonmyopia, AL <24 mm) and OAG subtype (normal-tension glaucoma [NTG], high-tension glaucoma [HTG]). The disc and BMO centers were determined by a merged image of red-free fundus photography and spectral-domain optical coherence tomography. The angular location of the RNFL defect close to the fovea (angle α) was measured from the disc center and BMO center, respectively (angle αdisc and angle αBMO). The difference between angle αdisc and αBMO (Δα), as well as the RNFL defect width (angle γ), was evaluated. Results Angle αdisc was smaller in myopic eyes and correlated significantly with AL (P = 0.001), whereas it did not differ among OAG subgroups. Angle αBMO and angle γ were not different in the myopic and OAG subgroups. The Δ α was larger for eyes with higher degree of myopia and had significant correlation with AL (P < 0.001) and was larger in NTG eyes than in HTG eyes (P = 0.023). Conclusions The angular location of the RNFL defect measured from the disc center, but not from the BMO center, was closer to the fovea for glaucomatous eyes with higher values of AL. The present study may facilitate understanding of the characteristic locational pattern of the RNFL defect in myopic glaucomatous eyes.",2020-09-01,https://www.semanticscholar.org/paper/3bf60b64d46409a6ff149bf89004dcdd58753120,Investigative Ophthalmology and Visual Science
1902,Industry Applications of Computational Intelligence: Preface,,,https://www.semanticscholar.org/paper/53844058751531751a9442d670e8cd5c377781ca,International Journal of Computational Intelligence Systems
2693,"Augmented Reality in Architectural Construction, Inspection, and Renovation","We present our preliminary work in developing augmented reality systems to improve methods for the construction, inspection, and renovation of architectural structures. Augmented reality systems add virtual computer-generated material to the surrounding physical world. Our augmented reality systems use see-through headworn displays to overlay graphics and sounds on a person’s naturally occurring vision and hearing. As the person moves about, the position and orientation of his or her head is tracked, allowing the overlaid material to remain tied to the physical world. We describe an experimental augmented reality system that shows the location of columns behind a finished wall, the location of re-bars inside one of the columns, and a structural analysis of the column. We also discuss our preliminary work in developing an augmented reality system for improving the construction of spaceframes. Potential uses of more advanced augmented reality systems are presented.",,https://www.semanticscholar.org/paper/6eb16ab489c284dfbc265b9576de2bea1628399a,
3126,Remote Display Performance for Wireless Healthcare Computing,"Organizations are beginning to recognize that health care providers are highly mobile and optimal care requires providing access to a large and dynamic body of information wherever the provider and patient are. Remote display protocols (RDP) are one way that organizations are using to deliver healthcare applications to mobile users. While many organizations have begun to use RDPs to deliver real-time access to health care information to clinicians, little formal work has been done to evaluate the performance or the effectiveness of thin-client computing with health care applications. This study examines the performance of wireless thin-client tablets with two web-based clinical applications, a text-centric, graphics-poor EMR and a graphic-rich image analysis program. The study compares the performance of two popular RDP implementations, Citrix and Microsoft Remote Desktop, with the performance of a traditional web browser in a wireless environment. For both applications, the RDPs demonstrated both higher speed and reduced bandwidth requirements than the web browser.",,https://www.semanticscholar.org/paper/d47995e4ce282c8a90e6ff7a32d1bf091ed63636,Medinfo
2331,Biochemistry and Physiology of the Neutrophil: The development and structure of mature neutrophils,,,https://www.semanticscholar.org/paper/a8948f0b7d03a7d425d6c126a3590897c238e93e,
3430,Solving Maximum Flow Problems on Real World Bipartite Graphs,,,https://www.semanticscholar.org/paper/609e482fc114ccbf6eb27842197e290326ff4d38,Workshop on Algorithm Engineering and Experimentation
3019,Why Joanie Can Encrypt: Easy Email Encryption with Easy Key Management,"Email privacy is of crucial importance. Existing email encryption approaches are comprehensive but seldom used due to their complexity and inconvenience. We take a new approach to simplify email encryption and improve its usability by implementing receiver-controlled encryption: newly received messages are transparently downloaded and encrypted to a locally-generated key; the original message is then replaced. To avoid the problem of moving a single private key between devices, we implement per-device key pairs: only public keys need be synchronized via a simple verification step. Compromising an email account or server only provides access to encrypted emails. We implemented this scheme on several platforms, showing it works with PGP and S/MIME, is compatible with widely used mail clients and email services including Gmail, has acceptable overhead, and that users consider it intuitive and easy to use.",2019-03-25,https://www.semanticscholar.org/paper/7111f34fa4210b117a379eb49ed9d539a6837923,European Conference on Computer Systems
2454,VITA: Visual Interaction Tool for Archaeology,,2016-12-07,https://www.semanticscholar.org/paper/4971a1f972bb5514192f9c106f6f010928a562ec,
419,How to learn an unknown environment. I: the rectilinear case,"We consider the problem faced by a robot that must explore and learn an unknown room with obstacles in it. We seek algorithms that achieve a bounded ratio of the worst-case distance traversed in order to see all visible points of the environment (thus creating a map), divided by the optimum distance needed to verify the map, if we had it in the beginning. The situation is complicated by the fact that the latter off-line problem (the problem of optimally verifying a map) is NP-hard. Although we show that there is no such “competitive” algorithm for general obstacle courses, we give a competitive algorithm for the case of a polygonal room with a bounded number of obstacles in it. We restrict ourselves to the rectilinear case, where each side of the obstacles and the room is parallel to one of the coordinates, and the robot must also move either parallel or perpendicular to the sides. (In a subsequent paper, we will discuss the extension to polygons of general shapes.)
We also discuss the off-line problem for simple rectilinear polygons and find an optimal solution (in the L1 metric) in polynomial time, in the case where the entry and the exit are different points.",1998-03-01,https://www.semanticscholar.org/paper/4b408ec4ab1828d7b9ed9a5ccccd32e998671a72,JACM
3723,Video Representations of Goals Emerge from Watching Failure,"We introduce a video representation learning framework that models the latent goals behind observable human action. Motivated by how children learn to reason about goals and intentions by experiencing failure, we leverage unconstrained video of unintentional action to learn without direct supervision. Our approach models videos as contextual trajectories that represent both low-level motion and high-level action features. Experiments and visualizations show the model is able to predict underlying goals, detect when action switches from intentional to unintentional, and automatically correct unintentional action. Although the model is trained with minimal supervision, it is competitive with highly-supervised baselines, underscoring the role of failure examples for learning goal-oriented video representations. The project website is available at this https URL",2020-06-28,https://www.semanticscholar.org/paper/9a6dd28c5449ddcad7b079c0dca6ea6a518c3eb0,arXiv.org
1051,Light Dark Matter Search with a High-Resolution Athermal Phonon Detector Operated above Ground.,"We present limits on spin-independent dark matter-nucleon interactions using a 10.6 g Si athermal phonon detector with a baseline energy resolution of σ_{E}=3.86±0.04(stat)_{-0.00}^{+0.19}(syst)  eV. This exclusion analysis sets the most stringent dark matter-nucleon scattering cross-section limits achieved by a cryogenic detector for dark matter particle masses from 93 to 140  MeV/c^{2}, with a raw exposure of 9.9 g d acquired at an above-ground facility. This work illustrates the scientific potential of detectors with athermal phonon sensors with eV-scale energy resolution for future dark matter searches.",2020-07-21,https://www.semanticscholar.org/paper/51ed2acc72a065eff0d6a81cf28443032dcb08ee,Physical Review Letters
1564,General linear-time inference for Gaussian Processes on one dimension,"Gaussian Processes (GPs) provide a powerful probabilistic framework for interpolation, forecasting, and smoothing, but have been hampered by computational scaling issues. Here we prove that for data sampled on one dimension (e.g., a time series sampled at arbitrarily-spaced intervals), approximate GP inference at any desired level of accuracy requires computational effort that scales linearly with the number of observations; this new theorem enables inference on much larger datasets than was previously feasible. To achieve this improved scaling we propose a new family of stationary covariance kernels: the Latent Exponentially Generated (LEG) family, which admits a convenient stable state-space representation that allows linear-time inference. We prove that any continuous integrable stationary kernel can be approximated arbitrarily well by some member of the LEG family. The proof draws connections to Spectral Mixture Kernels, providing new insight about the flexibility of this popular family of kernels. We propose parallelized algorithms for performing inference and learning in the LEG model, test the algorithm on real and synthetic data, and demonstrate scaling to datasets with billions of samples.",2020-03-11,https://www.semanticscholar.org/paper/ee56f900dcfea827590a4fa9d50df4db03c7c551,arXiv.org
1753,Truncation-free stochastic variational inference for Bayesian nonparametric models,"We present a truncation-free stochastic variational inference algorithm for Bayesian nonparametric models. While traditional variational inference algorithms require truncations for the model or the variational distribution, our method adapts model complexity on the fly. We studied our method with Dirichlet process mixture models and hierarchical Dirichlet process topic models on two large data sets. Our method performs better than previous stochastic variational inference algorithms.",2012-12-03,https://www.semanticscholar.org/paper/8f302be0d4f9914dc21769c8b1f1aa36bb4cb7f3,Neural Information Processing Systems
1337,Search for large extra spatial dimensions in dimuon production with the d0 detector.,"We present the results of a search for the effects of large extra spatial dimensions in pp collisions at sqrt[s] = 1.96 TeV in events containing a pair of energetic muons. The data correspond to 246 pb(-1) of integrated luminosity collected by the D0 experiment at the Fermilab Tevatron Collider. Good agreement with the expected background was found, yielding no evidence for large extra dimensions. We set 95% C.L. lower limits on the fundamental Planck scale between 0.85 and 1.27 TeV within several formalisms. These are the most stringent limits achieved in the dimuon channel to date.",2005-06-25,https://www.semanticscholar.org/paper/2a860eeb1357a73869642616b20777c6aa9b582d,Physical Review Letters
3463,LP Decoding Corrects a Constant Fraction of Errors,"We show that for low-density parity-check (LDPC) codes whose Tanner graphs have sufficient expansion, the linear programming (LP) decoder of Feldman, Karger, and Wainwright can correct a constant fraction of errors. A random graph will have sufficient expansion with high probability, and recent work shows that such graphs can be constructed efficiently. A key element of our method is the use of a dual witness: a zero-valued dual solution to the decoding linear program whose existence proves decoding success. We show that as long as no more than a certain constant fraction of the bits are flipped by the channel, we can find a dual witness. This new method can be used for proving bounds on the performance of any LP decoder, even in a probabilistic setting. Our result implies that the word error rate of the LP decoder decreases exponentially in the code length under the binary-symmetric channel (BSC). This is the first such error bound for LDPC codes using an analysis based on ""pseudocodewords."" Recent work by Koetter and Vontobel shows that LP decoding and min-sum decoding of LDPC codes are closely related by the ""graph cover"" structure of their pseudocodewords; in their terminology, our result implies that that there exist families of LDPC codes where the minimum BSC pseudoweight grows linearly in the block length",2004-06-27,https://www.semanticscholar.org/paper/1e45a001f9d3c044efc680611a0394c1b89157fb,IEEE Transactions on Information Theory
798,"Bin Packing with Discrete Item Sizes, Part I: Perfect Packing Theorems and the Average Case Behavior of Optimal Packings","We consider the one-dimensional bin packing problem with unit-capacity bins and item sizes chosen according to the discrete uniform distribution U{j,k}, $1 < j \leq k,$ where each item size in {1/k,2/k,. . .,j/k} has probability 1/j of being chosen. Note that for fixed j,k as $m\rightarrow\infty$ the discrete distributions U{mj,mk} approach the continuous distribution U(0,j/k], where the item sizes are chosen uniformly from the interval (0,j/k]. We show that average-case behavior can differ substantially between the two types of distributions. In particular, for all j,k with j<k-1, there exist on-line algorithms that have constant expected wasted space under U{j,k}, whereas no on-line algorithm has even o(n1/2) expected waste under U(0,u] for any $0 < u \leq 1$. Our U{j,k} result is an application of a general theorem of Courcoubetis and Weber [C. Courcoubetis and R. R. Weber, Probab. Engrg. Inform. Sci., 4 (1990), pp. 447--460] that covers all discrete distributions. Under each such distribution, the optimal expected waste for a random list of n items must be either $\Theta (n)$, $\Theta (n^{1/2} )$, or O(1), depending on whether certain ""perfect"" packings exist. The perfect packing theorem needed for the U{j,k} distributions is an intriguing result of independent combinatorial interest, and its proof is a cornerstone of the paper.",2000-05-01,https://www.semanticscholar.org/paper/93cafcd104cbc206b259e60a1b799e4632b9dfaf,SIAM Journal on Discrete Mathematics
837,Approximate Max--ow Min-(multi)cut Theorems and Their Applications,"Consider the multicommodity ow problem in which the object is to maximize the sum of commodities routed. We prove the following approximate max-ow min-multicut theorem: min multicut O(log k) max ow min multicut; where k is the number of commodities. Our proof is constructive; it enables us to nd a multicut within O(log k) of the max ow (and hence also the optimal multicut). In addition, the proof technique provides a uniied framework in which one can also analyse the case of ows with speciied demands, of Leighton-Rao and Klein et.al., and thereby obtain an improved bound for the latter problem.",,https://www.semanticscholar.org/paper/475b1f9936e5f89283113a1245d9e6f30fd942cd,
2894,The Inclusion and Role of Micro Mechanical Residual Stress on Deformation of Stainless Steel Type 316l at Grain Level,,2023-05-01,https://www.semanticscholar.org/paper/cb005c5b65b1f1cb6d7bde1688673e497b6acfe9,Social Science Research Network
315,The Game World Is Flat: The Complexity of Nash Equilibria in Succinct Games,,2006-07-10,https://www.semanticscholar.org/paper/1438521df22b070002759b72cb5f6c31fc028b38,"International Colloquium on Automata, Languages and Programming"
1455,Study of χc2 production in photon-photon collisions,,1993-03-25,https://www.semanticscholar.org/paper/ea4f8524d7e0f54fd86755ed2a0c1bbffd3c52e8,
3410,54 : 2 A Fast Distributed Stateless Algorithm for α-Fair Packing Problems,"We study weighted α-fair packing problems, that is, the problems of maximizing the objective functions (i) ∑ j wjx 1−α j /(1−α) when α > 0, α 6= 1 and (ii) ∑ j wj ln xj when α = 1, over linear constraints Ax ≤ b, x ≥ 0, where wj are positive weights and A and b are non-negative. We consider the distributed computation model that was used for packing linear programs and network utility maximization problems. Under this model, we provide a distributed algorithm for general α that converges to an ε−approximate solution in time (number of distributed iterations) that has an inverse polynomial dependence on the approximation parameter ε and poly-logarithmic dependence on the problem size. This is the first distributed algorithm for weighted α-fair packing with poly-logarithmic convergence in the input size. The algorithm uses simple local update rules and is stateless (namely, it allows asynchronous updates, is self-stabilizing, and allows incremental and local adjustments). We also obtain a number of structural results that characterize α-fair allocations as the value of α is varied. These results deepen our understanding of fairness guarantees in α-fair packing allocations, and also provide insight into the behavior of α-fair allocations in the asymptotic cases α→ 0, α→ 1, and α→∞. 1998 ACM Subject Classification F.2.1 [Theory of Computation] Analysis of Algorithms and Problem Complexity – Numerical Algorithms and Problems, G.1.6 [Mathematics of Computing] Numerical Analysis – Optimization, Convex programming, Gradient methods",,https://www.semanticscholar.org/paper/83e1d95dec0f74fcacb5e96e347d33ff7ec55b95,
3705,Finding Spuriously Correlated Visual Attributes,"Deep neural models often learn to use spurious features in image datasets, which raises concerns when the models are deployed to critical applications, such as medical imaging. Identifying spurious features is essential to developing robust models. Existing methods to find spurious features do not give semantic meaning to the features and rely on human interpretation to decide if they are spurious or not. In this paper, we propose to find spurious visual attributes in the dataset. We first linearly transform the latent features into visual attributes and then learn correlations between the attributes and object classes by training a simple linear classifier. Correlated visual attributes are easily interpretable because they are in natural language having well defined meanings which makes it easier to find if they are spurious or not. Through visualizations and experiments, we show how to find spurious visual attributes, their ex-tent in existing dataset and failure mode examples showing negative impact of learned spurious correlations on out-of-distribution generalization.",,https://www.semanticscholar.org/paper/ea6d6c92458bebb3adc39cf48dc976b462ee0794,
3309,Rewilding rebuttal [1],,2007-10-01,https://www.semanticscholar.org/paper/923be9539344c3373e074b309a5acd536d58037c,
1426,Differential cross section for W boson production as a function of transverse momentum in proton-antiproton collisions at 1.8 TeV,,2000-10-12,https://www.semanticscholar.org/paper/d3b47f2b6f15759fc88254e945603c4d3e72dc33,
2455,Wireless wearables for virtual and augmented reality,"Virtual Reality (VR) and Augmented Reality (AR) have been explored by researchers for nearly a half century. Over the past few years, however, VR has experienced a renaissance, as head-worn display developer kits have metamorphosed into early consumer products, all far superior to what most VR researchers previously had available. Meanwhile, AR head-worn display developer kits are being released, even as Pokémon Go has caused public awareness of hand-held AR to skyrocket. What role will wireless computing play in the future of wearable VR and AR systems? I will suggest some of the ways in which future wearable hardware, software, and user interfaces could benefit from wireless technology, and describe some of the performance constraints that wireless systems must meet for this to be possible. For example, in the quest to develop lightweight eyewear, it will be advantageous to move as much technology as possible off the head, to other parts of the body or to the nearby environment. This will demand reliably low latency and high throughput for the asymmetric round trip from head-worn sensors, to off-head processors, back to head-worn displays. Furthermore, when AR eyewear becomes commonplace, so will multi-user AR collaboration, and that means handling intricate interactions between users, both co-located and remote.",2016-10-03,https://www.semanticscholar.org/paper/498a8b4399463bc82a514f313040eec751074216,HotWireless@MobiCom
1961,The train fueling cost minimization problem with fuzzy fuel prices,,2014-06-01,https://www.semanticscholar.org/paper/70958a7df8f0af860aabb1b4c2a3681cc79581f0,
2488,Poster: 3D referencing for remote task assistance in augmented reality,"We present a 3D referencing technique tailored for remote maintenance tasks in augmented reality. The goal is to improve the accuracy and efficiency with which a remote expert can point out a real physical object at a local site to a technician at that site. In a typical referencing task, the remote expert instructs the local technician to navigate to a location from which a target object can be viewed, and then to attend to that object. The expert and technician both wear head-tracked, stereo, see-through, head-worn displays, and the expert's hands are tracked by a set of depth cameras. The remote expert first selects one of a set of prerecorded viewpoints of the local site, and a representation of that viewpoint is presented to the technician to help them navigate to the correct position and orientation. The expert then uses hand gestures to indicate the target.",2013-03-16,https://www.semanticscholar.org/paper/c710881910cd118575f8a5f303417a5a46e40628,IEEE Symposium on 3D User Interfaces
2299,"Neutrophils from the synovial fluid of patients with rheumatoid arthritis express the high affinity immunoglobulin G receptor, FcγRI (CD64): role of immune complexes and cytokines in induction of receptor expression","Neutrophils isolated from the synovial fluid of 16/24 patients with rheumatoid arthritis expressed FcγRI (CD64), the high‐affinity receptor for monomeric immunoglobulin G (IgG), on their cell surface. Receptor expression ranged from 17% to 168% of the level of expression obtained after incubation of control blood neutrophils with 100 U/ml interferon‐γ (IFN‐γ) for 24 hr in vitro. Similarly, mRNA for FcγRI was detected in synovial fluid neutrophils from 12/15 patients and transcript levels ranged from 5% to 200% of the values obtained after treatment of blood neutrophils with IFN‐γ for 4 hr in vitro. No surface expression nor mRNA were detected in freshly isolated blood neutrophils from either patients or from healthy controls. Addition of cell‐free synovial fluid to control blood neutrophils induced both mRNA and surface expression of FcγRI to levels that were comparable to those achieved after addition of IFN‐γ. Neither soluble nor insoluble immune complexes appeared to be involved in induction of FcγRI expression in spite of the ability of these complexes to induce protein biosynthesis. Synovial fluid‐induced expression of FcγRI was partially blocked by incubation with neutralizing IFN‐γ antibodies, whilst neutralizing interleukin (IL)‐6 antibodies had little effect. Levels of IFN‐γ measured within these synovial fluids ranged from 0 to 2·7 U/ml, well within the range known to induce neutrophil FcγRI expression. These data thus indicate that gene expression in synovial fluid neutrophils is selectively activated as the cells enter the diseased joint. Furthermore, these data indicate that induced expression of FcγRI may alter the ability of infiltrating neutrophils to respond to IgG‐containing immune complexes present in these joints.",1997-06-01,https://www.semanticscholar.org/paper/8fc14c3ddf3bd1d58b75e213bf67164b318cb458,Immunology
1928,"2 Supply Chain Management Planning for the Production of Semiconductor Based Packaged Goods Tasks , Purpose , Challenges , and a bit of History A Perspective from Agents of Change in the Trenches","In February 2016 the Dagstuhl Seminar 16062 explored the needs of the semiconductor industry for better planning and scheduling approaches at the supply chain level and the requirements for information systems to support the approaches. The seminar participants also spent time identifying the core elements of a conceptual reference model for planning and control of semiconductor manufacturing supply chains. This Executive Summary describes the process of the seminar and discusses key findings and areas for future research regarding these topics. Abstracts of presentations given during the seminar and the output of breakout sessions are collected in appendices. Seminar February 7–12, 2016 – http://www.dagstuhl.de/16062 1998 ACM Subject Classification B.2.2 Performance Analysis and Design Aids (Simulation), F.2.2 Nonnumerical Algorithms and Problems (Scheduling and Sequencing), H.4.2 Types of Systems (Decision Support, Logistics), I.2.8 Problem Solving, Control Methods, and Search (Heuristic methods, Plan execution, formation, and generation, Scheduling)",,https://www.semanticscholar.org/paper/000489d4fe70ce5b65d4857fc5cb6a86f686789d,
3402,Minimizing Maximum Flow Time on Related Machines via Dynamic Posted Pricing,"We consider a setting where selfish agents want to schedule jobs on related machines. The agent submitting a job picks a server that minimizes a linear combination of the server price and the resulting response time for that job on the selected server. The manager’s task is to maintain server prices to (approximately) optimize the maximum response time, which is a measure of social good. We show that the existence of a pricing scheme with certain competitiveness is equivalent to the existence of a monotone immediate-dispatch algorithm. Our main result is a monotone immediate-dispatch algorithm that is O(1)-competitive with respect to the maximum response time. 1998 ACM Subject Classification F.2.2 [Nonnumerical Algorithms and Problem]: Sequencing",,https://www.semanticscholar.org/paper/5368e327f1f41557c69651458c8547c77311c410,Embedded Systems and Applications
1096,Detector Fabrication Yield for SuperCDMS Soudan,,2014-02-01,https://www.semanticscholar.org/paper/dd20b4122d87b587d7cbed30dc57680792a831bb,
1027,Locomotion of a Multi-Link Nonholonomic Snake Robot,,2017-10-11,https://www.semanticscholar.org/paper/cee070fb6c9dbe0b1d6fb8caa519f2a8945d02c4,
1629,Comment,"Stan Development Team (2016), “Stan: A C++ Library for Probability and Sampling, (version 2.9.0),” available at http://mc-stan.org. [138,149,151,153] Tan, L. S. L., and Nott, D. J. (2013), “Variational Inference for Generalized Linear Mixed Models Using Partially Noncentered Parametrizations,” Statistical Science, 28, 168–188. [151] Uhler, C., Lenkoski, A., and Richards, D. (2014), “Exact Formulas for the Normalizing Constants of Wishart Distributions for Graphical Models,” unpublished manuscript (arXiv:1406.490). [147] Verbyla, A. P., Cullis, B. R., Kenward, M. G., andWelham, S. J. (1999), “The Analysis of Designed Experiments and Longitudinal Data by Using Smoothing Splines” (with discussion), Applied Statistics, 48, 269–312. [149] Wainwright, M. J., and Jordan, M. I. (2008), “Graphical Models, Exponential Families and Variational Inference,” Foundations and Trends in Machine Learning, 1, 1–305. [141] Wand, M. P. (2009), “Semiparametric Regression and Graphical Models,” Australian and New Zealand Journal of Statistics, 51, 9–41. [137,140] Wand, M. P. (2014), “Fully Simplified multivariate normal updates in NonConjugate Variational Message Passing,” Journal of Machine Learning Research, 15, 1351–1369. [151] Wand, M. P., and Ormerod, J. T. (2008), “On Semiparametric Regression with O’sullivan Penalized Splines,”Australian and New Zealand Journal of Statistics, 50, 179–198. [140] Wand, M. P., and Ormerod, J. T. (2011), “Penalized Wavelets: Embedding Wavelets into Semiparametric Regression,” Electronic Journal of Statistics, 5, 1654–1717. [137,140] Wang, S. S. J., andWand,M. P. (2011), “Using Infer.NET for Statistical Analyses,” The American Statistician, 65, 115–126. [149] Winn, J., and Bishop, C. M. (2005), “Variational Message Passing,” Journal of Machine Learning Research, 6, 661–694. [137,138,140] Wood, S. N. (2006), Generalized Additive Models: An Introduction with R, Boca Raton, FL: CRC Press. [149] Wood, S. N., Scheipl, F., and Faraway, F. F. (2013), “Straightforward Intermediate Rank Tensor Product Smoothing in Mixed Models,” Statistics and Computing, 23, 341–3601. [149]",2017-01-02,https://www.semanticscholar.org/paper/836b6b502c1891efece1046c36a6142ef677c197,
306,Nash Equilibria: Where We Stand,,2007-10-08,https://www.semanticscholar.org/paper/46f72c3c054632256428d41ad240517b5107d336,Embedded Systems and Applications
742,Computation of Equilibria and Stable Solutions,,2010-09-20,https://www.semanticscholar.org/paper/5642a3a2c86063b99b4599039b00404f146599fe,Safety-critical Systems Symposium
561,On the stochastic scheduling of a tree,,,https://www.semanticscholar.org/paper/91683edcc1b9b5ed9856eb3bca196413ef3da561,
2914,Stress Triaxiality and Lode Angle Parameter Characterization of Flat Metal Specimen with Inclined Notch,"The stress state has an important effect on the deformation and failure of metals. While the stress states of the axisymmetric notched bars specimens are studied in the literature, the studies on the flat metal specimen with inclined notch are very limited and the stress state is not clearly characterized in them. In this paper, digital image correlation and finite element simulations are used to study the distribution of strain and stress state, that is stress triaxiality and Lode angle parameter. Flat specimen with inclined notch was tested to extract the full field strain evolution and calculate stress state parameters at three locations: specimen centre, notch root and failure starting point. It is found that compared with the centre point and the notch root, the failure initiation point can better characterize the influence of the notch angle on the strain evolution. Conversely, the centre point can more clearly characterize the effect of the notch angle on stress state, since the stress states at the failure point and the notch root change greatly during the plastic deformation. Then the calculated stress state parameters of the flat metal specimen with inclined notch at the centre point are used in Wierzbicki stress state diagram to establish a relationship between failure mode and stress state.",2021-10-13,https://www.semanticscholar.org/paper/2c1f6f9d12713e14f5f5df4d47101e7f3fe284c6,Metals
1952,A simulation analysis for evaluating TFT-LCD fab capacity expansion with a distant transportation problem,"Capacity planning for large-scale high-tech manufacturing processes such as semiconductor manufacturing and thin film transistor-liquid crystal display (TFT-LCD) using simulation of an entire fabrication facility (fab) requires a large computational effort and thus few studies have been in real settings. To address the needs of a realistic problem, this study aimed to develop an effective approach based on a discrete-event simulation model for evaluating the throughput, cycle time and utilisation in an integrated fab to integrate manufacturing and transportation resources. In particular, we conducted an empirical study in a real TFT-LCD fab expansion facing a difficult capacity planning problem arising from the expectation that one or more bottlenecks may shift to different sites, including the transportation system between the incumbent and the expansion fabs. Different product-mix alternatives and feeding policies are investigated to determine the best fab configuration. The results have shown practical viability of the proposed simulation technique to significantly reduce the computational effort associated with the capacity planning process and derive useful alternatives for supporting capacity expansion decisions.",2014-02-11,https://www.semanticscholar.org/paper/16415d1dcac067d30bb6c979fa2b6235f8914d47,
3307,Habitat use and movements of plains zebra (Equus burchelli) in response to predation danger from lions,"Prey species must adapt their behavior to avoid predation. As a key prey item for lions (Panthera leo), plains zebras (Equus burchelli) were expected to respond to immediate threats posed by lions in their area. In addition, zebras were predicted to exhibit behavior tuned to reduce the potential for encounters with lions, by modifying their movement patterns in the times of day and habitats of greatest lion danger. We studied a population of approximately 600 plains zebra living in Ol Pejeta Conservancy, Kenya. We found that zebra abundance on or near a grassland patch was lower if lions had also been observed on that patch during the same day. Predation danger was highest in grassland habitat during the night, when lions were more active. Zebra sightings and global positioning system radio collar data indicated that zebras also reduced their use of grassland at night, instead using more woodland habitat. Zebras moved faster and took sharper turns in grassland at night. It is hypothesized that these more erratic movements assist zebras in avoiding detection or capture by lions. Copyright 2007, Oxford University Press.",2007-07-01,https://www.semanticscholar.org/paper/4f75e0880286908abd09f705b7ae15ada17f7509,
1769,Variational Inference for Stick-Breaking Beta Process Priors,"We present a variational Bayesian inference algorithm for the stick-breaking construction of the beta process. We derive an alternate representation of the beta process that is amenable to variational inference, and present a bound relating the truncated beta process to its infinite counterpart. We assess performance on two matrix factorization problems, using a non-negative factorization model and a linear-Gaussian model.",2011-06-28,https://www.semanticscholar.org/paper/7bbd25e76044e3bb7c3a9dfe4dba5ebeb4e95925,International Conference on Machine Learning
2687,UIST'007 (panel): where will we be ten years from now?,"The conference this year is the tenth anniversary of UIST. The keynote talk discusses the history of UIST over the last ten years; this panel looks into the future of the field over the next ten. Each of the panelists will describe a scenario for what life will be like when we meet for UIST’O’I, ten years from now. They will also have a chance to challenge or question each others’ scenarios and to participate in open discussion with the audience.",1997-10-01,https://www.semanticscholar.org/paper/42e4e1fca978ed983694978da3e154abca1ef7dd,ACM Symposium on User Interface Software and Technology
477,Computational complexity,,1993-11-30,https://www.semanticscholar.org/paper/18ef30fe2a84e358b97e6733fab8bba911a88d85,
334,Revenue maximization in online auctions,"In the modern information economy, markets are proliferating, and in such an environment, automated market mechanisms, such as auctions, are becoming more important than ever. Economists have long studied the problem of maximizing the revenue obtained by the seller from an auction. In this dissertation, we study the same problem, but from the computer scientist's perspective: where the economist generally assumes that inputs are independently drawn from a preexisting population, we take the assumption that inputs are controlled by an adversary. At the same time, we adopt the economist's assumption that inputs are held as private information by individuals, who will only reveal information when it is in their best interest to do so. 
In this model, we study auctions with a novel combination of two properties. First, we assume that the seller has available an unlimited supply of the good to be sold, as would be the case in auctions for digital goods such as music or movies. Second, we assume that the auction is online, in the sense that it proceeds over time, with the seller forced to make a sequence of decisions, each based only on information received up to that point. 
In analyzing the revenue properties of such auctions, we show a connection between this problem and that of online learning with expert advice. We demonstrate how to use learning algorithms to design auctions that are asymptotically optimal. In this context, we focus on learning algorithms that use polynomial weight functions to adapt to new information. We show how such algorithms can have a useful combination of worst-case and average-case properties, suggesting that they might be used in place of more commonly studied algorithms based on exponential weight functions. Finally, we extend our results to the study of posted price mechanisms, in which buyers react to dynamically adjusted posted prices, rather than submitting bids to the seller.",,https://www.semanticscholar.org/paper/908f4d926c30a639beb076cbe0b2cf6d4e426e60,
1209,Measurement of differential Z/γ∗+jet+X cross sections in collisions at,,2008-11-27,https://www.semanticscholar.org/paper/400f8b1850884aeb196acc1c903cfad932c2442f,
1715,PUTOP : Turning Predominant Senses into a Topic Model for Word Sense Disambiguation,"We extend on McCarthy et al.’s predominant sense method to create an unsupervised method of word sense disambiguation that uses automatically derived topics using Latent Dirichlet allocation. Using topicspecific synset similarity measures, we create predictions for each word in each document using only word frequency information. It is hoped that this procedure can improve upon the method for larger numbers of topics by providing more relevant training corpora for the individual topics. This method is evaluated on SemEval-2007 Task 1 and Task 17. 1 Generative Model of WSD Word Sense Disambiguation (WSD) is the problem of labeling text with the appropriate semantic labels automatically. Although WSD is claimed to be an essential step in information retrieval and machine translation, it has not seen effective practical application because the dearth of labeled data has prevented the use of established supervised statistical methods that have been successfully applied to other natural language problems. Unsupervised methods have been developed for WSD, but despite modest success have not always been well understood statistically (Abney, 2004). Unsupervised methods are particularly appealing because they do not require expensive senseannotated data and can use the ever-increasing amount of raw text freely available. This paper expands on an effective unsupervised method for WSD and embeds it into a topic model, thus allowing an algorithm trained on a single, monolithic corpora to instead hand-pick relevant documents in choosing a disambiguation. After developing this generative statistical model, we present its performance on a number of tasks. 1.1 The Intersection of Syntactic and Semantic Similarity McCarthy et al. (2004) outlined a method for learning a word’s most-used sense given an untagged corpus that ranks each sense wsi using a distributional syntactic similarity γ and a WORDNET-derived semantic similarity α. This process for a word w uses its distributional neighbors Nw, the possible senses of not only the word in question, Sw, and also those of the distributionally similar words, Snj . Thus, P (wsi) =",,https://www.semanticscholar.org/paper/c8a9b0b5612b3d733203e03ce2aae3c7f7eacdb4,
1674,Modeling User Exposure in Recommendation,"Collaborative filtering analyzes user preferences for items (e.g., books, movies, restaurants, academic papers) by exploiting the similarity patterns across users. In implicit feedback settings, all the items, including the ones that a user did not consume, are taken into consideration. But this assumption does not accord with the common sense understanding that users have a limited scope and awareness of items. For example, a user might not have heard of a certain paper, or might live too far away from a restaurant to experience it. In the language of causal analysis (Imbens & Rubin, 2015), the assignment mechanism (i.e., the items that a user is exposed to) is a latent variable that may change for various user/item combinations. In this paper, we propose a new probabilistic approach that directly incorporates user exposure to items into collaborative filtering. The exposure is modeled as a latent variable and the model infers its value from data. In doing so, we recover one of the most successful state-of-the-art approaches as a special case of our model (Hu et al. 2008), and provide a plug-in method for conditioning exposure on various forms of exposure covariates (e.g., topics in text, venue locations). We show that our scalable inference algorithm outperforms existing benchmarks in four different domains both with and without exposure covariates.",2015-10-23,https://www.semanticscholar.org/paper/3b93f37e5af2f6f66af33720dc8d0e4de7dc4e65,The Web Conference
3779,Video Annotation and Tracking with Active Learning,"We introduce a novel active learning framework for video annotation. By judiciously choosing which frames a user should annotate, we can obtain highly accurate tracks with minimal user effort. We cast this problem as one of active learning, and show that we can obtain excellent performance by querying frames that, if annotated, would produce a large expected change in the estimated object track. We implement a constrained tracker and compute the expected change for putative annotations with efficient dynamic programming algorithms. We demonstrate our framework on four datasets, including two benchmark datasets constructed with key frame annotations obtained by Amazon Mechanical Turk. Our results indicate that we could obtain equivalent labels for a small fraction of the original cost.",2011-12-12,https://www.semanticscholar.org/paper/5f5d107016990cb297c26fbd7bee083c6df3aa62,Neural Information Processing Systems
438,"Panarity, Revisited (Extended Abstract)",,1997-08-06,https://www.semanticscholar.org/paper/ba925b0e259de3d3fdd38df72a42c7682144a91c,Workshop on Algorithms and Data Structures
1117,Status of CDMS Search for Dark Matter,"We report on the latest results from the CDMS (cryogenic dark matter search) experiment. The experiment uses superconducting particle detectors, operated below 100 mK, to search for dark matter in the form of weakly interacting massive elementary particles or WIMPs. These detectors are either Si or Ge crystals, where the electron-hole production and the phonon production are measured for each event, allowing the discrimination of electron recoils (most backgrounds due to gammas and betas) from nuclear recoils (due to WIMPs and neutrons). We have recently reported new limits from the Stanford shallow site experiment (CDMS-I) which explore supersymmetric models where the lightest supersymmetric particle is often an excellent WIMP candidate. We will also report on the Soudan deep site facility for the CDMS-II experiment which is under construction, and on the status of the CDMS-II detector fabrication. CP586, Relativistic Astrophysics: 20 Texas Symposium, edited by J. C. Wheeler and H. Mattel © 2001 American Institute of Physics 0-73 54-0026-1/017$ 18.00",,https://www.semanticscholar.org/paper/871beba1e437697cba1e3c17eb43efb16ec9978f,
1159,Evidence ofandProduction withFinal States inCollisions at,,2009-04-21,https://www.semanticscholar.org/paper/75ced60972c419e8635b329b9f720ff8234af7db,
3247,Between-gender differences in vigilance do not necessarily lead to differences in foraging-vigilance tradeoffs,,2016-03-26,https://www.semanticscholar.org/paper/3554cf5f7f71ce5b972bcae7d2ccc20b69e181e0,Oecologia
2638,Information at a Glance,"What if we could visualize and interact with information directly in the context of our surroundings? Our research group is exploring how augmented reality (AR) could someday make this possible. AR integrates a complementary virtual world with the physical world-for example, by using head-tracked see-through head-worn displays to overlay graphics on what we see. Instead of looking back and forth between the real world and a PDA, we look directly at the real world and the virtual information overlaid on it. At the heart of this approach is context-aware computing, computing systems that are sensitive to the context in which they operate, ranging from human relationships to physical location. For example, information might be tied to specific locations within a global, Earth-centered, coordinate system. How can we design effective mobile AR user interfaces? We've been trying to answer this question in part by developing experimental AR research prototypes. In AR, as in work on information visualization using desktop technologies, the amount of information available can far exceed what a system can legibly display at a given time, necessitating information filtering. Julier et al. (2000) have developed information filtering techniques for AR that depend on the user's goals, object importance, and proximity. We assume that a system can accomplish information filtering of this sort and that our system is displaying everything it should.",2002-07-01,https://www.semanticscholar.org/paper/e1e3adef54e596a766db14eba657eda388c89437,IEEE Computer Graphics and Applications
2981,Pitman-Yor Diffusion Trees,"We introduce the Pitman Yor Diffusion Tree (PYDT) for hierarchical clustering, a generalization of the Dirichlet Diffusion Tree (Neal, 2001) which removes the restriction to binary branching structure. The generative process is described and shown to result in an exchangeable distribution over data points. We prove some theoretical properties of the model and then present two inference methods: a collapsed MCMC sampler which allows us to model uncertainty over tree structures, and a computationally efficient greedy Bayesian EM search algorithm. Both algorithms use message passing on the tree structure. The utility of the model and algorithms is demonstrated on synthetic and real world data, both continuous and binary.",2011-06-13,https://www.semanticscholar.org/paper/57156f73746d295f5ed73948c8a43dd024048392,Conference on Uncertainty in Artificial Intelligence
1631,Deep Probabilistic Programming,"We propose Edward, a Turing-complete probabilistic programming language. Edward defines two compositional representations---random variables and inference. By treating inference as a first class citizen, on a par with modeling, we show that probabilistic programming can be as flexible and computationally efficient as traditional deep learning. For flexibility, Edward makes it easy to fit the same model using a variety of composable inference methods, ranging from point estimation to variational inference to MCMC. In addition, Edward can reuse the modeling representation as part of inference, facilitating the design of rich variational models and generative adversarial networks. For efficiency, Edward is integrated into TensorFlow, providing significant speedups over existing probabilistic systems. For example, we show on a benchmark logistic regression task that Edward is at least 35x faster than Stan and 6x faster than PyMC3. Further, Edward incurs no runtime overhead: it is as fast as handwritten TensorFlow.",2017-01-13,https://www.semanticscholar.org/paper/8e9532262bb862c62d2d011a93da014da2d97ee9,International Conference on Learning Representations
1915,A two-phase decoding genetic algorithm for TFT-LCD array photolithography stage scheduling problem with constrained waiting time,,2018-11-01,https://www.semanticscholar.org/paper/ae6a070fdc0ffec311d2b045b2f1f3abf7edbd72,Computers & industrial engineering
3108,Experiences teaching operating systems using virtual platforms and Linux,"Operating system courses teach students much more when they provide hands-on kernel-level project experience with a real operating system. However, enabling a large class of students to do kernel development can be difficult. To address this problem, we created a virtual kernel development environment in which operating systems can be developed, debugged, and rebooted in a shared computer facility without affecting other users. Using virtual machines and remote display technology, our virtual kernel development laboratory enables even distance learning students at remote locations to participate in kernel development projects with on-campus students. We have successfully deployed and used our virtual kernel development environment together with the open-source Linux kernel to provide kernel-level project experiences for over nine hundred students in the introductory operating system course at Columbia University.",2005-02-23,https://www.semanticscholar.org/paper/967a4a1d8bf1ef13051c6aa75d4c2348fe60b7d2,OPSR
3446,Aequitas: A Trusted P2P System for Paid Content Delivery,"P2P file-sharing has been recognized as a powerful and efficient distribution model due to its ability to leverage users’ upload bandwidth. However, companies that sell digital content on-line are hesitant to rely on P2P models for paid content distribution due to the free file-sharing inherent in P2P models. In this paper we present Aequitas, a P2P system in which users share paid content anonymously via a layer of intermediate nodes. We argue that with the extra anonymity in Aequitas, vendors could leverage P2P bandwidth while effectively maintaining the same level of trust towards their customers as in traditional models of paid content distribution. As a result, a content provider could reduce its infrastructure costs and subsequently lower the costs for the end-users. The intermediate nodes are incentivized to contribute their bandwidth via electronic micropayments. We also introduce techniques that prevent the intermediate nodes from learning the content of the files they help transmit. In this paper we present the design of our system, an analysis of its properties and an implementation and experimental evaluation. We quantify the value of the intermediate nodes, both in terms of efficiency and their effect on anonoymity. We argue in support of the economic and technological merits of the system.",,https://www.semanticscholar.org/paper/e0f1f6b08def2b7e74c5269c6fe8cc00f38bc61d,
3742,Tracking Emerges by Colorizing Videos,,2018-06-25,https://www.semanticscholar.org/paper/360ef12906a531733b66e7e15c3d51771e7126d3,European Conference on Computer Vision
819,Optimization problems from feature testing of communication protocols,"In feature testing of communication protocols, we want to construct a minimal number of tests with a desirable fault coverage. We model the protocols by extended finite state machines and reduce the test generation process to optimization problems on graphs. We study efficient algorithms and their complexity. We report experimental results on real systems, including Personal HandyPhone System, a 5ESS based ISDN wireless system, and 5ESS Intelligent Network Application Protocol.",1996-10-29,https://www.semanticscholar.org/paper/a648028dd16367cd196e5863c44e50880c841ab1,Proceedings of 1996 International Conference on Network Protocols (ICNP-96)
2995,Spoq: Scaling Machine-Checkable Systems Verification in Coq,"System software is often large and complex, resulting in many vulnerabilities that can potentially be exploited to compromise the security of a system. Formal verification offers a potential solution to creating bug-free software, but a key impediment to its adoption remains proof cost. We present Spoq, a highly automated verification framework to construct machine-checkable proofs in Coq for system software with much less proof cost. Spoq introduces a novel program structure reconstruction technique to leverage LLVM to translate C code into Coq, supporting full C semantics, including C macros, inline assembly, and compiler directives, so that source code no longer has to be manually modified to be verified. Spoq leverages a layering proof strategy and introduces novel Coq tactics and transformation rules to automatically generate layer specifications and refinement proofs to simplify verification of concurrent system software. Spoq also supports easy integration of manually written layer specifications and refinement proofs. We use Spoq to verify a multiprocessor KVM hypervisor implementation. Verification using Spoq required 70% less proof effort than the manually written specifications and proofs to verify an older implementation. Furthermore, the proofs using Spoq hold for the unmodified implementation that is directly compiled and executed.",,https://www.semanticscholar.org/paper/0421c0442d6efc5ff4a84ba1711e2bf2f2f3e259,USENIX Symposium on Operating Systems Design and Implementation
1425,EXPERIMENTAL SEARCHES FOR DARK MATTER,,2000-08-01,https://www.semanticscholar.org/paper/c751babeaa4f37a1de18bff4a6afbfbb5a1cc51e,
172,A Calculus for Brain Computation,"Do brains compute? How do brains learn? How are intelligence and language achieved in the human brain? In this pursuit, we develop a formal calculus and associated programming language for brain computation, based on the assembly hypothesis, first proposed by Hebb: the basic unit of memory and computation in the brain is an assembly, a sparse distribution over neurons. We show that assemblies can be realized efficiently and neuroplausibly by using random projection, inhibition, and plasticity. Repeated applications of this RP&C primitive (random projection and cap) lead to (1) stable assembly creation through projection; (2) association and pattern completion; and finally (3) merge, where two assemblies form a higher-level assembly and, eventually, hierarchies. Further, these operations are composable, allowing the creation of stable computational circuits and structures. We argue that this functionality, in the presence of merge in particular, might underlie language and syntax in humans.",,https://www.semanticscholar.org/paper/7f72f54b447d7da093789c22bf815f050bdabe61,2019 Conference on Cognitive Computational Neuroscience
937,Locking policies: Safety and freedom from deadlock,"A database consists of ellliflc.\' yvhich reLlte to each other in certain ways, i,e., they satisfy cerltlin cOllsistency constraints. Many tinles, when a user updates the database, he nlay have to update tcnlporarily these constraints in orde r tC) eventuaII y t I'an s1'0 I' 111 the database in to a new, consis ten t stat C . For this I'eas 0 n, at 0 nl ic act ion s by the sa nlC user arc grou ped toget her into un its of consistency called transactiolls. In practice. a transaction nlay be either an interactive session, or the execution of a user update progranl. When, however, nlan y' transactions access and update the SanlC database cOI1curTently, there rnust he sonle kind of coordination to ensure that the resulting sequence of interleaved atonlic actions (or schedule) is correct. This TlleanS that all transactions have a consistent view of the data. and furthernlore the database is Icft at the end in sonle consistent state, This required coordination is achic\cd via the COIlcurrency cOlltrol,nechalllsfn ()f the database. ('onsiderahle research effort has heen devoted recently to the theoretical aspects or the design of such a systenl !ECiLTl. SLR, SK, KS, Pa, PBR, KPI. The theory of databasc concurrency control bears a superficial silllilarity to the () pe ra ting systenl Sinspi I'ed con cLI rrency 1he 0 I'Y [K [vI, (' [) 1. The difference is lhtl{ in operating systeIllS \\le have cooperating, Ill0nitoring. dnd 1110n itored. processes, and the goal is to prevent had cooperation or Tllanagenlent (e.g. indetcrnlinacy. deadlocks) In databases, we have a population of' users that arc una\\'are of each other's pres-",1979-10-01,https://www.semanticscholar.org/paper/05f213d51dc7ea3fadbb4794256ec24d774b5533,20th Annual Symposium on Foundations of Computer Science (sfcs 1979)
997,Segmental analysis of the retinal single-layers in de novo drug-naïve Parkinson’s disease,,2015-06-11,https://www.semanticscholar.org/paper/1c80f7e15996398887ccea10f5b2c7272fc06fc0,
1230,First study of the radiation-amplitude zero in Wgamma production and limits on anomalous WWgamma couplings at sqrt[s]=1.96 TeV.,We present results from a study of pp-->Wgamma+X events utilizing data corresponding to 0.7 fb{-1} of integrated luminosity at sqrt[s]=1.96 TeV collected by the D0 detector at the Fermilab Tevatron Collider. We set limits on anomalous WWgamma couplings at the 95% C.L. The one-dimensional 95% C.L. limits are 0.49<kappa{gamma}<1.51 and -0.12<lambda{gamma}<0.13. We make the first study of the charge-signed rapidity difference between the lepton and the photon and find it to be indicative of the standard model radiation-amplitude zero in the Wgamma system.,2008-02-29,https://www.semanticscholar.org/paper/7d086fc55dd04dc905f68997cca6dd1b441968c1,Physical Review Letters
575,On Two Geometric Problems Related to the Traveling Salesman Problem,,1984-06-01,https://www.semanticscholar.org/paper/6ca8df6bb1f5b54b6889f4c003c0ece405b3d573,J. Algorithms
552,The Theory of Database Concurrency Control,"A solution to get the problem off, have you found it? Really? What kind of solution do you resolve the problem? From what sources? Well, there are so many questions that we utter every day. No matter how you will get the solution, it will mean better. You can take the reference from some books. And the the theory of database concurrency control is one book that we really recommend you to read, to get more solutions in solving this problem.",1986-07-01,https://www.semanticscholar.org/paper/a02ee370e88d9fce0f19339012ffa31b175d60cb,
1833,PU-BCD: Exponential Family Models for the Coarse- and Fine-Grained All-Words Tasks,,,https://www.semanticscholar.org/paper/dc6107c5507d252e10a28ae68405c7f64bf8c089,International Workshop on Semantic Evaluation
2249,Haemophilus influenzae induces neutrophil necrosis: a role in chronic obstructive pulmonary disease?,"Noncapsulate Haemophilus influenzae is commonly found in the airways of patients with chronic obstructive pulmonary disease (COPD), both during stable disease and during exacerbations. Neutrophils are also found in large numbers in sputum from patients with COPD, which also contains released neutrophil products such as elastase. Why H. influenzae colonizes the lungs of patients with COPD in the presence of such large numbers of infiltrating neutrophils is not known. We set out to determine if abnormal interactions between H. influenzae and neutrophils could impact on COPD pathology. Noncapsulate H. influenzae clinical isolates were incubated in vitro with neutrophils from healthy volunteers, and respiratory burst activity, cytokine and chemokine production, phagocytosis and killing of bacteria, and neutrophil apoptosis and necrosis were measured. Neutrophil morphology was determined in sputum samples. H. influenzae were phagocytosed by neutrophils, thereby activating a respiratory burst and the secretion of the neutrophil chemoattractant IL-8. However, rather than kill the bacteria, the neutrophils themselves were killed (largely via necrosis) and released their granule contents into the extracellular environment. Neutrophil-derived IL-8, generated after the interaction of H. influenzae with neutrophils, may result in the further infiltration of neutrophils into the lungs, thereby amplifying the inflammatory response. However, the infiltrating neutrophils fail to kill the bacteria and instead release tissue-damaging products into the lung as they undergo necrosis. These results may help to explain the clinical picture in COPD.",2007-03-15,https://www.semanticscholar.org/paper/b2a3bcd2f50ebf6b72905099a5d41e0915e44ad0,American Journal of Respiratory Cell and Molecular Biology
2416,A Location-Triggered Augmented Reality Walking Tour Using Snap Spectacles 2021,"We present an on-site 3D-animated audiovisual tour guide augmented reality application developed for Snap Spectacles 2021. The primary goal of this project is to explore how to use this experimental product to create an augmented reality tour guide. In addition, we present the design considerations for the user interface and the underlying system architecture. We illustrate the workflow of the tour application and discuss our experience working with Spectacles 2021 and its experimental API. We also present our design choices and directions for future work.",2022-03-01,https://www.semanticscholar.org/paper/d40786857480255b5b1cb8d57a5d486dad8e6f9b,2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)
2344,"Calcium, Oxygen Radicals and Cellular Damage: Regulation of neutrophil oxidant production",,,https://www.semanticscholar.org/paper/16da742115acfd6cb8a0f504ed8b99f19ed0a3c8,
1818,Mixed membership analysis of high-throughput interaction studies: Relational data,"In this paper, we consider the statistical analysis of a protein interaction network. We propose a Bayesian model that uses a hierarchy of probabilistic assumptions about the way proteins interact with one another in order to: (i) identify the number of non-observable functional modules; (ii) estimate the degree of membership of proteins to modules; and (iii) estimate typical interaction patterns among the functional modules themselves. Our model describes large amount of (relational) data using a relatively small set of parameters that we can reliably estimate with an efficient inference algorithm. We apply our methodology to data on protein-to-protein interactions in saccharomyces cerevisiae to reveal proteins' diverse functional roles. The case study provides the basis for an overview of which scientific questions can be addressed using our methods, and for a discussion of technical issues.",2007-06-03,https://www.semanticscholar.org/paper/0af8d3bc3f2d8ac3171dd3114af0b69a4d488cd1,
2584,A Survey of Automated Layout Techniques for Information Presentations,Layout refers to the process of determining the sizes and positions of the visual objects that are part of an information presentation. Automated layout refers to the use of a computer program to automate either all or part of the layout process. This field of research lies at the crossroads between artificial intelligence and human computer interaction. Automated layout of presentations is becoming increasingly important as the amount of data that we need to present rapidly overtakes our ability to present it manually. We survey and analyze the techniques used by research systems that have automated layout components and suggest possible areas of future work.,,https://www.semanticscholar.org/paper/555abe6272784f0013c2c31d4ed3b371be6d9c14,
250,Kurt Gödel and the Foundations of Mathematics: Preface,,,https://www.semanticscholar.org/paper/36cdc553fa782e34b9b4db7dfb88fd8488f3cf04,
1595,A Probabilistic Model of Cardiac Physiology and Electrocardiograms,"An electrocardiogram (EKG) is a common, non-invasive test that measures the electrical activity of a patient's heart. EKGs contain useful diagnostic information about patient health that may be absent from other electronic health record (EHR) data. As multi-dimensional waveforms, they could be modeled using generic machine learning tools, such as a linear factor model or a variational autoencoder. We take a different approach:~we specify a model that directly represents the underlying electrophysiology of the heart and the EKG measurement process. We apply our model to two datasets, including a sample of emergency department EKG reports with missing data. We show that our model can more accurately reconstruct missing data (measured by test reconstruction error) than a standard baseline when there is significant missing data. More broadly, this physiological representation of heart function may be useful in a variety of settings, including prediction, causal analysis, and discovery.",2018-12-01,https://www.semanticscholar.org/paper/40da199f9a377b8f041574d2ded87e085975a75b,arXiv.org
1656,The Generalized Reparameterization Gradient,"The reparameterization gradient has become a widely used method to obtain Monte Carlo gradients to optimize the variational objective. However, this technique does not easily apply to commonly used distributions such as beta or gamma without further approximations, and most practical applications of the reparameterization gradient fit Gaussian distributions. In this paper, we introduce the generalized reparameterization gradient, a method that extends the reparameterization gradient to a wider class of variational distributions. Generalized reparameterizations use invertible transformations of the latent variables which lead to transformed distributions that weakly depend on the variational parameters. This results in new Monte Carlo gradients that combine reparameterization gradients and score function gradients. We demonstrate our approach on variational inference for two complex probabilistic models. The generalized reparameterization is effective: even a single sample from the variational distribution is enough to obtain a low-variance gradient.",2016-10-07,https://www.semanticscholar.org/paper/787ffb182e0555691d1c90047e16b8f3ff49bf0b,Neural Information Processing Systems
1235,Search for excited electrons incollisions at,,2008-05-12,https://www.semanticscholar.org/paper/8535e7703bba159535db691c5052f8b335ef22c0,
573,A Communication-Time Tradeoff,"We show a nontrivial tradeoff between the communication c and time t required to compute a collection of values whose dependencies form a grid, i.e., value (i,j) depends on the values (i-1,j) and (i,j-1). No matter how we share the responsibility for computing the nodes of the n x n grid among processors, the law ct = /spl Omega/(n/sup 3/) must hold. Further, there must be a single path through the grid along which there are d communication steps, where dt = /spl Omega/(n/sup 2/). Depending on the machine organization, either law may be the more significant.",1984-10-24,https://www.semanticscholar.org/paper/388bcb3650a15ed973a6ad5c38d6fcda593d70bc,SIAM journal on computing (Print)
2478,Augmented reality tower technology flight test,"Augmented reality technology adapted for air traffic control tower applications was used to track an OH-58C helicopter in proximity to an airport. A camera and 'see-through' display system was used to measure the registration error of static airport features and dynamic test aircraft. The observed registration errors of the test aircraft were largely attributable to two terms of error: 1) aircraft surveillance transport latency, and 2) registration error (from all sources) of the static environment. Compensating for registration errors of static objects and modeling aircraft movement reduces registration errors for dynamic (aircraft) objects to ≤2° of error for aircraft-surveillance transport latency ≤ 5 seconds, and to ≤1° of error for transport latency ≤ 2 seconds.",2014-07-30,https://www.semanticscholar.org/paper/7cd88c943fca35c49c6252d52fa918a93b609985,
3617,The C++ Programming Language: Special Edition,"Noise detection apparatus included in a peripheral controller operates to detect automatically when a noise record has been stored in the controller buffer storage unit. The detection apparatus includes control apparatus associated with the buffer storage unit which keeps track of the number of storage locations into which data characters have been stored during a transfer operation. Also included are means for selectively establishing one or more counts corresponding to a minimum number of data characters which must be stored in the buffer storage unit before the controller starts to transfer any data characters to a data processing unit. Each time a minimum number of characters has not been previously stored in the buffer unit when the controller receives a signal indicating the completion of the transfer, the controller clears the buffer storage unit of data characters and continues the transfer.",2000-02-11,https://www.semanticscholar.org/paper/661c59295685125df80f6afca5ec0486b55d665e,
357,MythematiCS: in praise of storytelling in the teaching of computer science and math,"t is usefully humbling to remember that cultural transmission via formal education at universities and schools is a very recent experiment. During almost all of the history of Humankind, cultural knowledge on all subjects (morality, religion, civics, technology, agriculture, etc.) has been passed on by storytelling. We do use storytelling in the contemporary teaching of technical subjects, even though I believe that much more is possible and needed. My purpose here is to identify, justify, salute, dissect, and propagandize such use.",2003-12-01,https://www.semanticscholar.org/paper/a1c3b5f42e907f1efdc428098f290e28395504d0,SGCS
118,STARTS: Stanford Proposal for Internet Meta-Searching (Experience Paper),,,https://www.semanticscholar.org/paper/e23529a0bf1a475db93951c93524b6af427cec4c,SIGMOD Conference
1237,ZZ → l+l-vv production in pp collisions at √s = 1.96 TeV,We describe a search for Z boson pair production in pp collisions at √s = 1.96 TeV with the DO detector at the Fermilab Tevatron Collider using a data sample corresponding to an integrated luminosity of 2.7 fb -1 . Using the final state decay ZZ → l + l - vv (where l = e or μ) we find a signal with a 2.6 standard deviations significance (2.0 expected) corresponding to a cross section of σ(pp → ZZ + X) = 2.01 ± 0.93(stat) ± 0.29(sys) pb.,2008-10-06,https://www.semanticscholar.org/paper/8af063b6fba05dbc6d37f120aa3cae1aee098971,
902,On Monotone Formulae with Restricted Depth (Preliminary Version),,,https://www.semanticscholar.org/paper/bbf97217be5b73ca76f1f71e3af51279facef311,Symposium on the Theory of Computing
2393,Temperature-Compensated Epigenetic Oscillations: Timing of Cell Division Cycles and Circadian Rhythms?,,,https://www.semanticscholar.org/paper/8325f922f4aba9bcd3873090e99b7b8aadf4f6a6,
2919,The effects of internal stresses on the creep deformation investigated using in-situ synchrotron diffraction and crystal plasticity modelling,,2021-06-10,https://www.semanticscholar.org/paper/cee58ae8f11e444810f499e0112ac823fd1e7c14,
3618,Exception Safety: Concepts and Techniques,,,https://www.semanticscholar.org/paper/d43340c4b07b7f15b81ebae919a9daa86fa800d5,Advances in Exception Handling Techniques
1113,Search for annual modulation in low-energy CDMS-II data,"We report limits on annual modulation of the low-energy event rate from the Cryogenic Dark Matter Search (CDMS II) experiment at the Soudan Underground Laboratory. Such a modulation could be produced by interactions from Weakly Interacting Massive Particles (WIMPs) with masses ~10 GeV/c^2. We find no evidence for annual modulation in the event rate of veto-anticoincident single-detector interactions consistent with nuclear recoils, and constrain the magnitude of any modulation to 98% confidence. For events consistent with electron recoils, no significant modulation is observed for either single- or multiple-detector interactions in the 3.0-7.4 keVee range.",2012-03-06,https://www.semanticscholar.org/paper/52a4c6d51a86270bcc2b857e57d11520e8fd3a95,
1358,Measurement of the Ratio of Inclusive Cross Sections p p ! Z b jet,"V. M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, M. Agelou, J.-L. Agram, S. H. Ahn, M. Ahsan, G. D. Alexeev, G. Alkhazov, A. Alton, G. Alverson, G. A. Alves, M. Anastasoaie, S. Anderson, B. Andrieu, Y. Arnoud, A. Askew, B. Åsman, O. Atramentov, C. Autermann, C. Avila, F. Badaud, A. Baden, B. Baldin, P. W. Balm, S. Banerjee, E. Barberis, P. Bargassa, P. Baringer, C. Barnes, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, A. Bean, S. Beauceron, M. Begel, A. Bellavance, S. B. Beri, G. Bernardi, R. Bernhard,* I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, M. Binder, K. M. Black, I. Blackler, G. Blazey, F. Blekman, S. Blessing, D. Bloch, U. Blumenschein, A. Boehnlein, O. Boeriu, T. A. Bolton, F. Borcherding, G. Borissov, K. Bos, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, S. Burdin, T. H. Burnett, E. Busato, J. M. Butler, J. Bystricky, W. Carvalho, B. C. K. Casey, N. M. Cason, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K. M. Chan, A. Chandra, D. Chapin, F. Charles, E. Cheu, L. Chevalier, D. K. Cho, S. Choi, T. Christiansen, L. Christofek, D. Claes, B. Clément, C. Clément, Y. Coadou, M. Cooke, W. E. Cooper, D. Coppage, M. Corcoran, J. Coss, A. Cothenet, M.-C. Cousinou, S. Crépé-Renaudin, M. Cristetiu, M. A. C. Cummings, D. Cutts, H. da Motta, B. Davies, G. Davies, G. A. Davis, K. De, P. de Jong, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, S. Dean, F. Déliot, P. A. Delsart, M. Demarteau, R. Demina, P. Demine, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, M. Doidge, H. Dong, S. Doulas, L. Duflot, S. R. Dugad, A. Duperrin, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, T. Edwards, J. Ellison, J. Elmsheuser, J. T. Eltzroth, V. D. Elvira, S. Eno, P. Ermolov, O. V. Eroshin, J. Estrada, D. Evans, H. Evans, A. Evdokimov, V. N. Evdokimov, J. Fast, S. N. Fatakia, L. Feligioni, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, W. Freeman, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, E. Gallas, E. Galyaev, C. Garcia, A. Garcia-Bellido, J. Gardner, V. Gavrilov, P. Gay, D. Gelé, R. Gelhaus, K. Genser, C. E. Gerber, Y. Gershtein, G. Ginther, T. Golling, B. Gómez, K. Gounder, A. Goussiou, P. D. Grannis, S. Greder, H. Greenlee, Z. D. Greenwood, E. M. Gregores, Ph. Gris, J.-F. Grivaz, L. Groer, S. Grünendahl, M. W. Grünewald, S. N. Gurzhiev, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, S. Hagopian, I. Hall, R. E. Hall, C. Han, L. Han, K. Hanagaki, K. Harder, R. Harrington, J. M. Hauptman, R. Hauser, J. Hays, T. Hebbeker, D. Hedin, J. M. Heinmiller, A. P. Heinson, U. Heintz, C. Hensel, G. Hesketh, M. D. Hildreth, R. Hirosky, J. D. Hobbs, B. Hoeneisen, M. Hohlfeld, S. J. Hong, R. Hooper, P. Houben, Y. Hu, J. Huang, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, V. Jain, K. Jakobs, A. Jenkins, R. Jesik, K. Johns, M. Johnson, A. Jonckheere, P. Jonsson, H. Jöstlein, A. Juste, M. M. Kado, D. Käfer, W. Kahl, S. Kahn, E. Kajfasz, A. M. Kalinin, J. Kalk, D. Karmanov, J. Kasper, D. Kau, R. Kehoe, S. Kermiche, S. Kesisoglou, A. Khanov, A. Kharchilava, Y. M. Kharzheev, K. H. Kim, B. Klima, M. Klute, J. M. Kohli, M. Kopal, V. M. Korablev, J. Kotcher, B. Kothari, A. Koubarovsky, A. V. Kozelov, J. Kozminski, S. Krzywdzinski, S. Kuleshov, Y. Kulik, S. Kunori, A. Kupco, T. Kurča, S. Lager, N. Lahrichi, G. Landsberg, J. Lazoflores, A.-C. Le Bihan, P. Lebrun, S. W. Lee, W. M. Lee, A. Leflat, F. Lehner,* C. Leonidopoulos, P. Lewis, J. Li, Q. Z. Li, J. G. R. Lima, D. Lincoln, S. L. Linn, J. Linnemann, V. V. Lipaev, R. Lipton, L. Lobo, A. Lobodenko, M. Lokajicek, A. Lounis, H. J. Lubatti, L. Lueking, M. Lynker, A. L. Lyon, A. K. A. Maciel, R. J. Madaras, P. Mättig, A. Magerkurth, A.-M. Magnan, N. Makovec, P. K. Mal, S. Malik, V. L. Malyshev, H. S. Mao, Y. Maravin, M. Martens, S. E. K. Mattingly, A. A. Mayorov, R. McCarthy, R. McCroskey, D. Meder, H. L. Melanson, A. Melnitchouk, M. Merkin, K. W. Merritt, A. Meyer, H. Miettinen, D. Mihalcea, J. Mitrevski, N. Mokhov, J. Molina, N. K. Mondal, H. E. Montgomery, R. W. Moore, G. S. Muanza, M. Mulders, Y. D. Mutaf, E. Nagy, M. Narain, N. A. Naumann, H. A. Neal, J. P. Negret, S. Nelson, P. Neustroev, C. Noeding, A. Nomerotski, S. F. Novaes, T. Nunnemann, E. Nurse, V. O’Dell, D. C. O’Neil, V. Oguri, N. Oliveira, N. Oshima, G. J. Otero y Garzón, P. Padley, N. Parashar, J. Park, S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, P. M. Perea, E. Perez, O. Peters, P. Pétroff, M. Petteni, L. Phaf, R. Piegaia, P. L. M. Podesta-Lerma, V. M. Podstavkov, Y. Pogorelov, B. G. Pope, W. L. Prado da Silva, H. B. Prosper, S. Protopopescu, M. B. Przybycien, J. Qian,",,https://www.semanticscholar.org/paper/cd4368638b2da0a88371abd7fec90873594a965c,
780,ON-LINE MINIMIZATION OF TRANSITION SYSTEMS ( Extended Abstract ),"We are given a transition system implicitly through a compact representation and wish to perform simultaneously reachability analysis and minimization without constructing first the whole system graph. We present an algorithm for this problem that applies to general systems, provided we have appropriate primitive operations for manipulating blocks of states and we can determine termination; the number of operations needed to construct the minimal reachable graph is quadratic in the size of this graph. We specialize the method to obtain efficient algorithms for extended finite state machines that apply separable affine transformations on the variables.",,https://www.semanticscholar.org/paper/6b9f35a6f48c478b47368b676af7b1c87aeb53f1,
1223,O ct 2 00 8 FERMILAB-PUB-08-279-E Observation of ZZ production in pp̄ collisions at √ s = 1 . 96 TeV,,,https://www.semanticscholar.org/paper/5f527537d6ff90c13ec821c6fab81fdd3415257b,
323,"Geometric embeddings, geometric algorithms, and combinatorial optimization","Geometric spaces arise in computer science through a number of avenues. The most obvious of these occurs when the input data for our problem possesses an inherent geometric structure, e.g. the hop-distance between nodes in a network, or the similarity distance between two genomic sequences. Certainly these ""geometries"" may be far afield from the classical setting where one is concerned, for instance, with Euclidean spaces or Riemannian manifolds, and thus we require new techniques for the design of efficient algorithms on these spaces, and new models for the kind of geometries we should expect. 
On the other hand, geometry often presents itself in a less straightforward manner in the setting of combinatorial optimization. A classical example of this is the use of Linear Programming in the solution---exact or approximate---to a variety of combinatorial problems. The most exciting connections occur when a problem with an a priori purely combinatorial structure is shown to involve rich geometric phenomena. 
The present thesis is divided into two parts which address questions of both types (i.e. combinatorial data and geometric data, respectively), leading to new algorithms for a variety of well-known combinatorial problems, new connections between geometry and computer science, and new geometric and analytic information about some classical mathematical objects. 
In Part I, we employ geometric embeddings in order to provide near-optimal solutions to a number of NP-hard optimization problems. Given a combinatorial object, e.g. a graph, we develop new ways of embedding the object into a geometric space in a way which approximately preserves its structure. We then use geometric tools to produce a solution to the original optimization problem whose quality is within some (ideally small) factor of the optimal solution. This approach is most fruitful when applied to graph separator-type problems where the goal is to divide a graph into two large pieces while minimizing the size of the ""interface"" between them. Algorithms for such tasks are then used as primitives in divide-and-conquer approaches to a number of other optimization problems. 
In Part II, we examine the relationship between dimension, volume growth, and algorithmic tractability. The so-called curse of dimensionality is well-known; in many settings, the difficulty of solving a geometric problem increases exponentially with the dimension of the input. We study notions of the intrinsic dimension of a data set, and show that in many cases, very efficient algorithms and data structures can be designed for high-dimensional data which is nevertheless ""low-dimensional"" from an intrinsic viewpoint.",,https://www.semanticscholar.org/paper/e8be203afa8cf2cc6e70a9a335159f59d83b0300,
238,[1] S. Edelkamp. Symbolic exploration in two-player games: Preliminary results. In International Conference on AI Planning and Scheduling International Conference on AI Planning and Scheduling (AIPS'02) Workshop on Model,"We investigate cost-sharing algorithms for multicast transmission. Economic considerations point to two distinct mechanisms, marginal cost and Shapley value, as the two solutions most appropriate in this context. We prove that the former has a natural algorithm that uses only two messages per link of the multicast tree, while we give evidence that the latter requires a quadratic total number of messages. We also show that the welfare value achieved by an optimal multicast tree is NP-hard to approximate within any constant factor, even for bounded-degree networks. The lower-bound proof for the Shapley value uses a novel algebraic technique for bounding from below the number of messages exchanged in a distributed computation; this technique may prove useful in other contexts as well.",,https://www.semanticscholar.org/paper/5fb550299fd5517fb7770bb02731f142bc5e88ff,
1081,Title Projected sensitivity of the SuperCDMS SNOLAB experiment,,,https://www.semanticscholar.org/paper/8f85ff4cb82d02d041ff7828711a80cd972da723,
3367,The Mechanisms of Filter Feeding: Some Theoretical Considerations,"We enumerate the five basic mechanisms by which any biological or manmade filter can remove particles from a fluid. These mechanisms are: (1) direct interception, (2) inertial impaction, (3) gravitational deposition, (4) motile-particle deposition, and (5) electrostatic attraction. For these mechanisms we present dimensionless indexes that indicate which measurable characteristics of the filter, the particles, and the flow affect the intensity of particle capture. By comparing the magnitudes of these indexes it is possible to determine the main mechanism a filter is using to capture particles. Awareness of these mechanisms and their interrelationships will provide insights for those investigating the efficiency of various modes of filter feeding and the mechanisms of size-selective suspension feeding.",1977-09-01,https://www.semanticscholar.org/paper/af135bbec3b2ee9efe5972e253f8ed525a219dff,American Naturalist
662,A Dataset for Learning University STEM Courses at Scale and Generating Questions at a Human Level,"We present a new dataset for learning to solve, explain, and generate university-level STEM questions from 27 courses across a dozen departments in seven universities. We scale up previous approaches to questions from courses in the departments of Mechanical Engineering, Materials Science and Engineering, Chemistry, Electrical Engineering, Computer Science, Physics, Earth Atmospheric and Planetary Sciences, Economics, Mathematics, Biological Engineering, Data Systems, and Society, and Statistics. We visualize similarities and differences between questions across courses. We demonstrate that a large foundation model is able to generate questions that are as appropriate and at the same difficulty level as human-written questions.",2023-06-26,https://www.semanticscholar.org/paper/58d225fc5c13db9328c573209b51a2a7bf1340c8,AAAI Conference on Artificial Intelligence
534,Some computational aspects of circumscription,"The effects of circumscribing first-order formulas are explored from a computational standpoint. First, extending work of V. Lifschitz, it is Shown that the circumscription of any existential first-order formula is equivalent to a first-order formula. After this, it is established that a set of universal Horn clauses has a first-order circumscription if and only if it is bounded (when considered as a logic program); thus it is undecidable to tell whether such formulas have first-order circumscription. Finally, it is shown that there arefirst-order formulas whode circumscription has a coNP-complete model-checking problem.",1988-08-21,https://www.semanticscholar.org/paper/fe36f876880c23a429608a70fdd08433f4d8d116,JACM
3258,"Herd Size-Dependent Effects of Restricted Foraging Time Allowance on Cattle Behavior, Nutrition, and Performance☆,☆☆",,2015-07-01,https://www.semanticscholar.org/paper/7a36f0023165b7c6f67cc21e64595a5ab9c066ce,
1408,Recent Results from the Cryogenic Dark Matter Search for Weakly Interacting Massive Particles,,,https://www.semanticscholar.org/paper/4a38b7fa6c83badc4899d4e3688cfa527ab06d38,
2847,The role of galectin-3 in promotion of the inflammatory response.,"Galectin-3 is a member of a family of beta-galactoside-binding animal lectins and is distinct from other members by the presence of tandem repeats in its N-terminal region. Like other members, galectin-3 lacks a classical signal sequence, but the protein is secreted by a nonclassical secretary pathway and can function extracellularly in an autocrine or paracrine fashion. Galectin-3 is able to oligomerize and participate in multivalent interactions with cell surface and extracellular matrix glycans, through lectin-carbohydrate interactions, thus affecting cellular functions. Galectin-3 is detectable in the cytosol and nucleus and the intracellular protein may bind to other cytoplasmic and nuclear proteins by protein-protein interactions. In this manner, galectin-3 is able to influence intracellular signaling pathways and exert various functions. Galectin-3 is expressed by virtually all immune and inflammatory cell types, either constitutively or in a inducible fashion. A large body of work has demonstrated the role of galectin-3 in regulation of the functions of these cells. The use of galectin-3-deficient mice has provided additional evidence for this protein's contribution to the inflammatory response. Thus, galectin-3 may be a therapeutic target for various inflammatory diseases.",2007-09-01,https://www.semanticscholar.org/paper/2e4de81443f0f3241b115c769fed770880baa8b2,Drug News and Perspectives
3343,Alternative reproductive tactics in the spider Meta segmentata,,1987-04-01,https://www.semanticscholar.org/paper/f7b6464ba032af3204ac987f2f7d505b74ca6f66,Behavioral Ecology and Sociobiology
88,Snowball: a prototype system for extracting relations from large text collections,"Text documents often hide valuable structured data. For example, a collection of newspaper articles might contain information on the location of the headquarters of a number of organizations. If we need to nd the location of the headquarters of, say, Microsoft, we could try and use traditional information-retrieval techniques for nding documents that contain the answer to our query. Alternatively, we could answer such a query more precisely if we somehow had available a table listing all the organization-location pairs that are mentioned in our document collection. One could view the extraction process as automatically building a materialized view over the unstructured text data. In this demo we present an interactive prototype of our Snowball system for extracting relations from collections of plain-text documents with minimal human participation. Our method builds on the DIPRE idea introduced by Brin [3]. Our system and techniques were presented in detail in [2] and [1].",2001-05-01,https://www.semanticscholar.org/paper/5d26d446c7e809bd4e1ee6e696a17764521618c7,ACM SIGMOD Conference
1773,Online Variational Inference for the Hierarchical Dirichlet Process,"The hierarchical Dirichlet process (HDP) is a Bayesian nonparametric model that can be used to model mixed-membership data with a potentially infinite number of components. It has been applied widely in probabilistic topic modeling, where the data are documents and the components are distributions of terms that reflect recurring patterns (or “topics”) in the collection. Given a document collection, posterior inference is used to determine the number of topics needed and to characterize their distributions. One limitation of HDP analysis is that existing posterior inference algorithms require multiple passes through all the data—these algorithms are intractable for very large scale applications. We propose an online variational inference algorithm for the HDP, an algorithm that is easily applicable to massive and streaming data. Our algorithm is significantly faster than traditional inference algorithms for the HDP, and lets us analyze much larger data sets. We illustrate the approach on two large collections of text, showing improved performance over online LDA, the finite counterpart to the HDP topic model.",2011-06-14,https://www.semanticscholar.org/paper/93792105974f4d42c83172c4fc9f24be77fe781b,International Conference on Artificial Intelligence and Statistics
1428,Determination of the Strong Coupling Constant from the Inclusive Jet Cross Section in Deep-Inelastic Positron-Proton Collisions at HERA H 1 Collaboration,"We have measured the inclusive jet cross section in the Breit frame in deep-inelastic scattering at large four momentum transfers squared Q2 and large transverse jet energies ET using the inclusivek? jet algorithm. The analysis is based on data corresponding t o an integrated luminosity ofL ' 33 pb 1 taken in the years 1995-1997 with the H1 detector at the positron-proton collider HERA at a center-of-mas s energy psep = 300GeV. The inclusive jet cross section is presented double differe ntially as a function ofET and Q2 in the range49 < E2 T < 2500GeV2 and 150 < Q2 < 5000GeV2. In a QCD analysis of the data we have determined the strong coupling c o stant s. Setting the renormalization scale equal to the transverse jet energy, we inve stigate the running of s(ET ). We present comprehensive studies of the dependence of the re sults on the parton distributions used in the fit. Finally we have performed a combined fi t to the data over the whole range ofET andQ2 and obtain a preliminary result of s(MZ) = 0:1181 0:0030(exp)+0:0039 0:0046(theo)+0:0036 0:0015(parton density functions ). We have repeated the analysis setting the renormalization scale to the four momentum t ransfer r = Q and obtain a preliminary result of s(MZ) = 0:1221 0:0034(exp:)+0:0054 0:0059(theo:)+0:0033 0:0016(pdf) with an increased theoretical uncertainty resulting from a larg er enormalization scale dependence. Abstract: 157 Parallel sessions: 1 Plenary sessions: 1 Electronic Access: http://www-h1.desy.de/publications / 157 Parallel sessions: 1 Plenary sessions: 1 Electronic Access: http://www-h1.desy.de/publications /",,https://www.semanticscholar.org/paper/29de86aaf1d7579335f640a70e1929cbf14f8352,
1489,CHARGED-D-STAR-MESON PRODUCTION IN E+E- ANNIHILATION AT SQUARE-ROOT-S '29 GEV,,,https://www.semanticscholar.org/paper/44dbafdcccf58b5d335d23a2d5a9e35eeb22ef37,
1980,Special issue on recent advance in Intelligent Manufacturing Systems,,2013-05-01,https://www.semanticscholar.org/paper/8e09a0536e3a5a6dcb78bccc17db2dc4e911d956,Computers & industrial engineering
2053,Economic efficiency analysis of wafer fabrication facilities,"Semiconductor industry is capital intensive and competitive, and thus efficiently utilizing resources to provide products and services is essential for maintaining competitive advantages. Knowing whether the resource is properly utilized is the foundation for future improvements and/or decision making. This study investigates the economic efficiency of fabrication facility (fab) operations. We develop a two-stage overall efficiency model, which clearly defines and explains the ¿real¿ performance of fab production operations and the non-production issues. The model provides an overall performance index while considering different aspects. A single performance index can be used to evaluate and rank the performance for period review. Factors affecting performance can be identified. Furthermore, according to a real case, an ex post relative efficiency analysis is conducted and the initial results are reported. The case study can help providing diagnosis for inefficient production facilities and identifying best practices of efficient production units.",2008-12-01,https://www.semanticscholar.org/paper/7d33fb68842a826097a604d7092081e2a207fbc3,Online World Conference on Soft Computing in Industrial Applications
3061,Cpu scheduling with automatic interactivity and dependency detection,"Recent trends in virtualization and server consolidation have expanded the number of applications with different resource requirements and quality-of-service demands being run on the same system. Users expect computers not only to run these different applications, but to be able to run them all at the same time. A key challenge is how to ensure that the system provides acceptable interactive responsiveness to users while multiplexing resources among a diverse collection of applications. However, identifying interactive processes and scheduling them promptly are not easy because the latency sensitivity of a process in modern computer systems may vary dynamically based on the user request it is processing and the user requests that depend on this process directly and indirectly. Most commodity operating systems either allow users to specify the latency sensitivity of a process or try to detect interactive latency-sensitive, processes based on processor resource usage and sleeping behavior. These are generally ineffective. 
This dissertation introduces RSIO. It detects latency-sensitive processes by monitoring accesses to I/O channels and inferring when user interactions occur. RSIO provides a general mechanism for all user interactions, including direct interactions via local HCI devices such as mouse and keyboard, indirect interactions through middleware, and remote interactions through networks. It automatically and dynamically identifies processes involved in a user interaction and boosts their priorities at the time the interaction occurs to improve system response time. RSIO detects processes that directly handle a user interaction as well as those indirectly involved in processing the interaction, automatically accounting for dependencies and boosting their priorities accordingly. RSIO works with existing schedulers, processes that may mix interactive and batch activities, and requires no application modifications to identify periods of latency-sensitive application activity. 
Even when a process is detected as latency-sensitive and its priority is boosted, the process may still not be scheduled promptly because of a problem known as priority inversion, which happens when a high priority process blocks waiting for the response from a low priority process. Without knowing the dependency among the processes, the CPU scheduler may schedule a medium priority process to run, and thus effectively delay the execution of the high priority process. We have developed SWAP to address the priority inversion problems caused by inter-process dependencies. SWAP can automatically determine possible resource dependencies among processes based on process system call history. Because some dependencies cannot be precisely determined, SWAP associates confidence levels with dependency information that are dynamically adjusted using feedback from process blocking behavior. SWAP can schedule processes using this imprecise dependency information in a manner that is compatible with existing scheduling mechanisms and ensures that actual scheduling behavior corresponds to the desired scheduling policy in the presence of process dependencies. Our results show that SWAP can provide substantial improvements in system performance in scheduling processes with dependencies. 
As CPU schedulers are complicated to develop and increasingly important with the introduction of multi-core systems, we also introduce WARP, which is a new scheduler development and evaluation platform which facilitated our solutions. WARP is a trace-driven virtualized CPU scheduler execution environment that can dramatically simplify and speed the development and evaluation of CPU schedulers, including SWAP and RSIO. It is easy to use as it can run unmodified kernel scheduling code in user-space and can be used with standard user-space debugging and performance monitoring tools. We have implemented a WARP Linux prototype. Our results show that it can use application traces captured from its toolkit to accurately reflect the scheduling behavior of the real Linux operating system. Executing an application trace using WARP can be two orders of magnitude faster than running real applications.",,https://www.semanticscholar.org/paper/77fb4dd55ea80ebd0a295809983bf1152face2a0,
2479,Patient-centered tools for medication information search,"Recent research focused on online health information seeking highlights a heavy reliance on general-purpose search engines. However, current general-purpose search interfaces do not necessarily provide adequate support for non-experts in identifying suitable sources of health information. Popular search engines have recently introduced search tools in their user interfaces for a range of topics. In this work, we explore how such tools can support non-expert, patient-centered health information search. Scoping the current work to medication-related search, we report on findings from a formative study focused on the design of patient-centered, medication-information search tools. Our study included qualitative interviews with patients, family members, and domain experts, as well as observations of their use of Remedy, a technology probe embodying a set of search tools. Post-operative cardio-thoracic surgery patients and their visiting family members used the tools to find information about their hospital medications and were interviewed before and after their use. Domain experts conducted similar search tasks and provided qualitative feedback on their preferences and recommendations for designing these tools. Findings from our study suggest the importance of four valuation principles underlying our tools: credibility, readability, consumer perspective, and topical relevance.",2014-05-20,https://www.semanticscholar.org/paper/979531b9232895705c45f4b151f945678b953545,International Conference on Pervasive Computing Technologies for Healthcare
2757,Scope: automated generation of graphical interfaces,"We describe the design and prototype implementation of Scope, a system that generates graphical user interfaces for applications programmed in C++. The programmer chooses application data objects and functions that define the capabilities of the interface. At runtime, an interface design component, implemented as a set of production system rules, transforms this semantic specification into an interface built using a window system, an associated user interface toolkit, and the hardware input devices available on the system. The rules match application requirements against a semantic description of the toolkit, selecting virtual devices for input, output, and layout. Thus, Scope uses design rules to create interfaces from high-level programming semantics that are customized both for the application and the run-time environment.",1989-11-13,https://www.semanticscholar.org/paper/b93bb0aa7ca65714261ae254e012b8f6360fa44a,ACM Symposium on User Interface Software and Technology
623,An optimality theory of concurrency control for databases,,1979-05-30,https://www.semanticscholar.org/paper/42cf741f1b38315c3376c301601cfee74571c6b6,ACM SIGMOD Conference
1006,Risk factors for primary open-angle glaucoma in South Korea: the Namil study,,2012-06-05,https://www.semanticscholar.org/paper/c37bea7aa947f20b13459fe47f78e9afbab61487,Japanese Journal of Ophthalmology
1751,Probabilistic topic models,Surveying a suite of algorithms that offer a solution to managing large document archives.,2012-04-01,https://www.semanticscholar.org/paper/7314be5cd836c8f06bd1ecab565b00b65259eac6,Communications of the ACM
2870,"Galectins-3 and -7, but not Galectin-1, Play a Role in Re-epithelialization of Wounds*","Disorders of wound healing characterized by impaired or delayed re-epithelialization are a serious medical problem. These conditions affect many tissues, are painful, and are difficult to treat. In this study, using cornea as a model, we demonstrate for the first time the importance of carbohydrate-binding proteins galectins-3 and -7 in re-epithelialization of wounds. In two different models of corneal wound healing, re-epithelialization of wounds was significantly slower in galectin-3-deficient (gal3−/−) mice compared with wild-type (gal3+/+) mice. In contrast, there was no difference in corneal epithelial wound closure rates between galectin-1-deficient and wild-type mice. Quantitation of the bromodeoxyuridine-labeled cells in gal3+/+ and gal3−/− corneas revealed that corneal epithelial cell proliferation rate is not perturbed in gal3−/− corneas. Exogenous galectin-3 accelerated re-epithelialization of wounds in gal3+/+ mice but, surprisingly, not in the gal3−/− mice. Gene expression analysis using cDNA microarrays revealed that healing corneas of gal3−/− mice contain markedly reduced levels of galectin-7 compared with those of gal3+/+ mice. More importantly, unlike galectin-3, galectin-7 accelerated re-epithelialization of wounds in both gal3−/− and gal3+/+ mice. In corresponding experiments, recombinant galectin-1 did not stimulate the corneal epithelial wound closure rate. The extent of acceleration of re-epithelialization of wounds with both galectin-3 and galectin-7 was greater than that observed in most of the published studies using growth factors. These findings have broad implications for developing novel therapeutic strategies for treating nonhealing wounds.",2002-11-01,https://www.semanticscholar.org/paper/6264124fdfd598b5564747e43f70e04478af042b,Journal of Biological Chemistry
3561,Design and evaluation of C++ open multi-methods,,2010-07-01,https://www.semanticscholar.org/paper/50a1234bd6992539e231a7809bb802ff6424b20d,Science of Computer Programming
2028,Shanzai! Mediatek and the 'White Box' Handset Market,"The term ""White Box"" is often used to describe products without a brand name. Such products are assembled from standardized parts, and they became a very popular category of desktop PCs. Hsinchu, Taiwan based MediaTek is a fabless semiconductor company that unleashed a white box market in mobile phone handsets by offering an innovative ""complete solution"" for 2.5G and 2.7G handset manufacturers, dramatically lowering the barriers to entry into the business. Besides enabling many Chinese branded manufacturers to enter the business, the grey market in components unleashed a complementary market of ""Shanzhai"" makers. Together these firms captured a significant fraction of the China market, as well as exports (both legal and grey) to 102 countries. CEO Ming-Kai Tsai is faced with the question of the best growth path. While multiple tier one handset makers are dismissive of MediaTek, perhaps because of its role in enabling the Shanzhai, the company's offerings have enabled an ""army of ants"" to challenge the leaders. Can MediaTek move up-market to sell its chipsets to the likes of Nokia? Under what terms?Learning Objective:Ask students to use the lenses of disruptive innovations, modularity, and jobs-based segmentation to understanding the opportunities and challenges in emerging markets like China.",2010-12-22,https://www.semanticscholar.org/paper/e1c7b860a183e239e3441af1d6b542dec92ef0ad,
3745,Learning from Noisy Demonstration Sets via Meta-Learned Suitability Assessor,,2018-09-27,https://www.semanticscholar.org/paper/a990eee6c47ded320f8f85f54febba8ea11ee908,
3636,Why C++ is not just an object-oriented programming language,"C++ directly supports a variety of programming styles. In this, C ++ deliberately differs from languages designed to support a single way of writing programs. This paper briefly presents key programming styles directly supported by C++ and argues that the support for multiple styles is one of its major strengths. The styles presented include: traditional C-style, concrete classes, abstract classes, traditional class hierarchies, abstract classes and class hierarchies, and generic programming. To provide a context for this overview, I discuss criteria for a reasonable and useful definition of ‘‘object-oriented programming.’’",1995-10-01,https://www.semanticscholar.org/paper/fd8464521c5b6471ec9db25068a6513a6760c46a,OOPSLA Addendum
2255,Microbial mannan suppresses killing of Crohn's disease mucosa-associated E coli by macrophages: A possible pathogenic mechanism for Crohn's disease,,,https://www.semanticscholar.org/paper/32f5221a07a0ddb6d55f4a2125e1350ad75cf4bc,
1908,A Hybrid Forecasting Framework with Neural Network and Time-Series Method for Intermittent Demand in Semiconductor Supply Chain,,2018-08-26,https://www.semanticscholar.org/paper/75b4df2b12f2b547c414498d668c5ab9aef30c5c,Advances in Production Management Systems
3342,Ecological Aspects of Social Evolution: Birds and Mammals,"Seeking common principles of social evolution in different taxonomic groups, the contributors to this volume discuss eighteen groups of birds and mammals for which long-term field studies have been carried out. They examine how social organization is shaped by the interaction between proximate ecological pressures and culture""--the social traditions already in place and shaped by local and phylogenetic history.Originally published in 1987.The Princeton Legacy Library uses the latest print-on-demand technology to again make available previously out-of-print books from the distinguished backlist of Princeton University Press. These paperback editions preserve the original texts of these important books while presenting them in durable paperback editions. The goal of the Princeton Legacy Library is to vastly increase access to the rich scholarly heritage found in the thousands of books published by Princeton University Press since its founding in 1905.",1987-01-31,https://www.semanticscholar.org/paper/8d8bc1d746642a1c9f883a766fb17c8d55636e43,
1905,Constructing a Metrology Sampling Framework for In-line Inspection in Semiconductor Fabrication,,2018-08-26,https://www.semanticscholar.org/paper/62b2e35b655de5f173bf85c3a8cd4db56c69fd57,Advances in Production Management Systems
1212,Observation of the Bc meson in the exclusive decay Bc-->J/psipi.,"A fully reconstructed Bc-->J/psipi signal is observed with the D0 detector at the Fermilab Tevatron pp[over] collider using 1.3 fb(-1) of integrated luminosity. The signal consists of 54+/-12 candidates with a significance that exceeds 5 standard deviations, and confirms earlier observations of this decay. The measured mass of the Bc meson is 6300+/-14(stat)+/-5(syst) MeV/c2.",2008-02-01,https://www.semanticscholar.org/paper/495f40ba5f865e68758250b0d6586bb9e15bacac,Physical Review Letters
301,Algorithmic Game Theory: Foreword,,,https://www.semanticscholar.org/paper/03d39ff77bf6ee6c3b27299100c24f46af1d5055,
2927,"Variational Variance: Simple, Reliable, Calibrated Heteroscedastic Noise Variance Parameterization","Brittle optimization has been observed to adversely impact model likelihoods for regression and VAEs when simultaneously fitting neural network mappings from a (random) variable onto the mean and variance of a dependent Gaussian variable. Previous works have bolstered optimization and improved likelihoods, but fail other basic posterior predictive checks (PPCs). Under the PPC framework, we propose critiques to test predictive mean and variance calibration and the predictive distribution's ability to generate sensible data. We find that our attractively simple solution, to treat heteroscedastic variance variationally, sufficiently regularizes variance to pass these PPCs. We consider a diverse gamut of existing and novel priors and find our methods preserve or outperform existing model likelihoods while significantly improving parameter calibration and sample quality for regression and VAEs.",2020-06-08,https://www.semanticscholar.org/paper/3b22a0f76bb5b644c5707e25e7140366ecd99e8a,
2804,The role of Galectin-3 in stellate cell activation and liver fibrosis,,2012-12-18,https://www.semanticscholar.org/paper/4b42c5a63839d1e871631fe8ce5603ba27839d39,
1767,A topographic latent source model for fMRI data,,2011-07-01,https://www.semanticscholar.org/paper/5d311ef363f831a903ead8997c493be51609346a,NeuroImage
3681,Zero-1-to-3: Zero-shot One Image to 3D Object,"We introduce Zero-1-to-3, a framework for changing the camera viewpoint of an object given just a single RGB image. To perform novel view synthesis in this under-constrained setting, we capitalize on the geometric priors that large-scale diffusion models learn about natural images. Our conditional diffusion model uses a synthetic dataset to learn controls of the relative camera viewpoint, which allow new images to be generated of the same object under a specified camera transformation. Even though it is trained on a synthetic dataset, our model retains a strong zero-shot generalization ability to out-of-distribution datasets as well as in-the-wild images, including impressionist paintings. Our viewpoint-conditioned diffusion approach can further be used for the task of 3D reconstruction from a single image. Qualitative and quantitative experiments show that our method significantly outperforms state-of-the-art single-view 3D reconstruction and novel view synthesis models by leveraging Internet-scale pre-training.",2023-03-20,https://www.semanticscholar.org/paper/2c70684973bc4d7b6f8404a647b8031c4d3c8383,arXiv.org
2313,Impaired neutrophil phagocytosis in preterm neonates: lack of correlation with expression of immunoglobulin or complement receptors.,"Preterm neonates are vulnerable to infection as a result of a compromised immune system. The function of neutrophils from 'well', 'stressed', and 'maturing' preterm neonates was compared with term neonate and adult neutrophils using a whole-blood phagocytosis assay. Cell surface expression of complement receptors and immunoglobulin G receptors was measured on neutrophils in whole blood from the same samples. Fewer actively phagocytosing neutrophils were found in all preterm neonate samples, especially in maturing neonates. Phagocytic rates were slower, and the number of Escherichia coli ingested was smaller in preterm neonate than in term neonate neutrophils. Expression of immunoglobulin G receptors and complement receptor 3 on neutrophils was not directly related to phagocytic activity.",,https://www.semanticscholar.org/paper/70898756d530b223f16e9378db4f1b8070907379,Biology of the Neonate
2590,View management for distributed user interfaces,"We present a new approach to designing user interfaces based on view management. View management refers to layout decisions that determine spatial relationships between objects, taking into account visibility constraints that allow applications to man age what users see. Our techniques are used to satisfy these constraints by controlling what is seen in a wide range of user interfaces: from 2D desktops to 3D immersive environments, from view-only presentations to interactive techniques, and from single user to collaborative situations. 
Screen space is a difficult resource to utilize properly in user interfaces. Poorly designed user interfaces, consisting of overlapping windows, unwanted popups, and unused screen space, occur on many different types of displays, such as PDAs, laptops, cell phones, and wall-sized displays. We avoid these problems by providing techniques for representing and managing unused screen space to avoid overlapping when possible. Applying these techniques to 3D user interfaces imposes visual constraints on the placement of objects, such as labels and annotations, relative to the 2D visible projections of 3D objects on the view plane. We develop techniques to handle issues such as performance and temporal stabilization, and we create guidelines to help ensure that labels and annotations behave well across a wide range of situations. 
We have applied our techniques to augmented reality, in which information is visualized directly within the context of the real world by overlaying graphics onto what is seen. We develop tools, including an annotated situation-awareness aid based on a world in miniature , that make it easy to visualize information about the environment, including parts of the environment that might not be completely visible from their current location. 
We extend these ideas further into distributed interactive environments. In a world encompassing a wide range of display technologies, we are interested in how people will access, use, and interact with information and each other. All of this work presented has been developed (or redeveloped) using an efficient rule-based programming technique we call Data Programming , which is designed for standalone and distributed development and has given us the flexibility to investigate a wide range of scenarios in these environments.",,https://www.semanticscholar.org/paper/fd664471d8778fec237548bc177d15362c75ffae,
299,A Game-Theoretic Analysis of Games with a Purpose,". We present a simple game-theoretic model for the ESP game, an interactive game devised to label images on the web, and characterize the equilibrium behavior of the model. We show that a simple change in the incentive structure can lead to diﬀerent equilibrium structure and suggest the possibility of formal incentive design in achieving desirable system-wide outcomes, complementing existing considerations of robust-ness against cheating and human factors.",,https://www.semanticscholar.org/paper/f1fa5ebbec9fa4b41272651cd1877076def8271f,
3542,Open pattern matching for C++,"Pattern matching is an abstraction mechanism that can greatly simplify source code. We present functional-style pattern matching for C++ implemented as a library, called Mach7. All the patterns are user-definable, can be stored in variables, passed among functions, and allow the use of open class hierarchies. As an example, we implement common patterns used in functional languages.",2013-10-26,https://www.semanticscholar.org/paper/6d5d774581a74ded889569249b0fa62f07ad2e7b,"ACM SIGPLAN International Conference on Systems, Programming, Languages and Applications: Software for Humanity"
1075,Nuclear-recoil energy scale in CDMS II silicon dark-matter detectors,,2018-03-07,https://www.semanticscholar.org/paper/c5e52a8c04b1636375263c9bf74e90a4789ea80f,"Nuclear Instruments and Methods in Physics Research Section A : Accelerators, Spectrometers, Detectors and Associated Equipment"
1747,Sparse stochastic inference for latent Dirichlet allocation,We present a hybrid algorithm for Bayesian topic models that combines the efficiency of sparse Gibbs sampling with the scalability of online stochastic inference. We used our algorithm to analyze a corpus of 1.2 million books (33 billion words) with thousands of topics. Our approach reduces the bias of variational inference and generalizes to many Bayesian hidden-variable models.,2012-06-26,https://www.semanticscholar.org/paper/481eb978677eaae4e01639f03212fd81d1a5a448,International Conference on Machine Learning
2466,"Wearable Computing, 3D Aug* Reality, Photographic/Videographic Gesture Sensing, and Veillance","Wearable computers and Generation-5 Digital Eye Glass easily recognize a user's own gestures, forming the basis for shared AR (Augmediated Reality). This Studio-workshop presents the latest in wearable AR, plus an historical perspective with new insights. Participants will sculpt 3D objects using hand gestures and create Unity 3D art+game objects using computational lightpainting. Participants will also learn how to use 3D gesture-based AR to visualize and understand real-world phenomena, including being able to see sound waves, see radio waves, and see sight itself, through abakographic user-interfaces that interact with ""sightfields"" (time-reversed lightfields). Participants will also surveilluminescent devices that change color when watched by a camera. Long exposure photographs made with such devices generate ""sightpaintings"" that show what a camera can ""see"".",2015-01-15,https://www.semanticscholar.org/paper/43128f8578f8641e70fe967347befa561f191768,"International Conference on Tangible, Embedded, and Embodied Interaction"
2988,Modeling skin and ageing phenotypes using latent variable models in Infer.NET,"We demonstrate and compare three unsupervised Bayesian latent variable models implemented in Infer.NET [2] for biomedical data modeling of 42 skin and aging phenotypes measured on the 12,000 female twins in the Twins UK study [7]. We address various data modeling problems include high missingness, heterogeneous data, and repeat observations. We compare the proposed models in terms of their performance at predicting disease labels and symptoms from available explanatory variables, concluding that factor analysis type models have the strongest statistical performance in this setting. We show that such models can be combined with regression components for improved interpretability. This work is being performed in collaboration with the Department of Twin Research and Genetic Epidemiology (DTR) at King’s College London. The DTR manages the largest UK adult twin registry of around 12,000 female monozygotic and dizygotic twins, established in 1992 [7]. The data has characteristics common to many biomedical applications, each of which we our able to address using our modeling framework. 1. High missingness. Many variables have up to 80% missing, and the level of overlap between phenotypes varies considerably. This level of missingness motivates Bayesian methods which are able to naturally deal with missingness, rather than attempting crude imputation procedures. 2. Heterogeneous data. The data contains continuous, categorical (including binary), ordinal and count data. We show in simulation experiments that using appropriate likelihood functions for each of these data types improves statistical power. 3. Multiple observations. Often the same underlying phenotype is recorded as multiple measurements, and the measurements may not be consistent. Allowing the model to combine these measurements into a single phenotype aids interpretability, improves statistical power and helps deal with the missingness problem. 4. High dimensional. The Twins UK database contains over 6000 phenotype and exposure variables, measured at multiple time points. Modern healthcare records are of the same nature. For a subset of 800 individuals we have 10,000 gene expression measurements in three different tissues, and the genotype of 600k Single Nucleotide Polymorphisms (SNPs). Our modeling framework allows these issues to be straightforwardly and rigorously addressed, and provides an efficient inference platform using Variational Message Passing under the Infer.NET framework. Although the models we use all provide some form of dimensionality reduction, which is essential for the high dimensional nature of the data, we currently only analysis around 40 phenotypes of particular relevance to skin and aging. Scaling these models to handle the full dataset, including gene expression and genotype data, is ongoing research. An attribute of the data that we have not fully explored how to model at this stage is that it is time series data. Most individuals in the study group have made multiple visits to be medically",,https://www.semanticscholar.org/paper/fcf131bb41fbf01fcb3d745d78aabede2033187c,NIPS 2010
634,The Efficiency of Algorithms.,,,https://www.semanticscholar.org/paper/8fab1ed52c1f1f4a5fc5c5819080793c96a7d3bb,
3750,Predictive vision,,,https://www.semanticscholar.org/paper/4b95428093db0021a19d6b47751dcc7dd2978717,
2092,A container packing support system for determining and visualizing container packing patterns,,2004-04-01,https://www.semanticscholar.org/paper/019bf14116cdf17f1a609f8818a34393d716db48,Decision Support Systems
26,Hip andTrendy: Characterizing EmergingTrends onTwitter,"Twitter, Facebook, and other related systems that we call social awareness streams are rapidly changing the information and communication dynamics of our society.These systems, where hundreds of millions of users share short messages in real time, expose the aggregate interests and attention of global and local communities. In particular, emerging temporal trends in these systems, especially those related to a single geographic area, are a significant and revealing source of information for, and about, a local community. This study makestwoessentialcontributionsforinterpretingemerging temporal trends in these information systems. First, based on a large dataset of Twitter messages from one geographic area, we develop a taxonomy of the trends present in the data. Second,we identify important dimensions according to which trends can be categorized, as well as the key distinguishing features of trends that can be derived from their associated messages. We quantitatively examine the computed features for different categories of trends, and establish that significant differences can be detected across categories. Our study advances the understanding of trends on Twitter and other social awareness streams, which will enable powerful applications and activities, including user-driven real-time information services for local communities.",,https://www.semanticscholar.org/paper/f80385633d6e95aa3e9c2e7091a56f6407914fa3,
1164,SuperCDMS Detector Fabrication Advances,"For its dark matter search the SuperCDMS collaboration has developed new Ge detectors using the same athermal phonon sensors and ionization measurement technology of CDMS II but with larger mass, superior sensor performance and increased fabrication efficiency. The improvements in fabrication are described, a comparison of CDMS II and SuperCDMS detector production yield is reported, and future scalability addressed.",2009-12-16,https://www.semanticscholar.org/paper/81b8d436ea475ec3ad1f521ba592c481d6f8f9b1,
49,To search or to crawl?: towards a query optimizer for text-centric tasks,"Text is ubiquitous and, not surprisingly, many important applications rely on textual data for a variety of tasks. As a notable example, information extraction applications derive structured relations from unstructured text; as another example, focused crawlers explore the web to locate pages about specific topics. Execution plans for text-centric tasks follow two general paradigms for processing a text database: either we can scan, or 'crawl,"" the text database or, alternatively, we can exploit search engine indexes and retrieve the documents of interest via carefully crafted queries constructed in task-specific ways. The choice between crawl- and query-based execution plans can have a substantial impact on both execution time and output ""completeness"" (e.g., in terms of recall). Nevertheless, this choice is typically ad-hoc and based on heuristics or plain intuition. In this paper, we present fundamental building blocks to make the choice of execution plans for text-centric tasks in an informed, cost-based way. Towards this goal, we show how to analyze query- and crawl-based plans in terms of both execution time and output completeness. We adapt results from random-graph theory and statistics to develop a rigorous cost model for the execution plans. Our cost model reflects the fact that the performance of the plans depends on fundamental task-specific properties of the underlying text databases. We identify these properties and present efficient techniques for estimating the associated cost-model parameters. Overall, our approach helps predict the most appropriate execution plans for a task, resulting in significant efficiency and output completeness benefits. We complement our results with a large-scale experimental evaluation for three important text-centric tasks and over multiple real-life data sets.",2006-06-27,https://www.semanticscholar.org/paper/f934522657189b4accc47317af2770029999d0eb,SIGMOD Conference
2062,Economic Efficiency Analysis of Wafer Fabrication,"Economic efficiency analysis of semiconductor fabrication facilities (fabs) involves tradeoffs among cost, yield, and cycle time. Due to the disparate units involved, direct evaluation and comparison is difficult. This article employs data envelopment analysis (DEA) to determine relative efficiencies among fabs over time on the basis of empirical data, whereby cycle time performance is transformed into monetary value according to an estimated price decline rate. Two alternative DEA models are formulated to evaluate the influence of cycle time and other performance attributes. The results show that cycle time and yield follow increasing returns to scale, just as do cost and resource utilization. Statistical analyses are performed to investigate the DEA results, leading to specific improvement directions and opportunities for relatively inefficient fabs. Note to Practitioners-Speed of manufacturing is an important metric of factory performance, yet it has long been a challenge to integrate its value into overall performance evaluation. However, for many semiconductor products, a predictable rate of decline in selling prices makes it possible to transform time value into monetary value. This study employs a novel method to incorporate a speed metric into economic efficiency evaluation and thereby provide a guideline for improving fab efficiency in manufacturing practice. Furthermore, this study integrates factory productivity and cycle time into a relative efficiency analysis model that jointly evaluates the impact of these two factors in manufacturing performance. In particular, we validate this approach with data from ten leading wafer fabs obtained by the Competitive Semiconductor Manufacturing Program and we discuss managerial implications.",2007-10-08,https://www.semanticscholar.org/paper/1e7f3ac68c32fb3cb80a615bdfd49102206fa006,IEEE Transactions on Automation Science and Engineering
1832,Mixed Membership Stochastic Blockmodels,"Observations consisting of measurements on relationships for pairs of objects arise in many settings, such as protein interaction and gene regulatory networks, collections of author-recipient email, and social networks. Analyzing such data with probabilisic models can be delicate because the simple exchangeability assumptions underlying many boilerplate models no longer hold. In this paper, we describe a latent variable model of such data called the mixed membership stochastic blockmodel. This model extends blockmodels for relational data to ones which capture mixed membership latent relational structure, thus providing an object-specific low-dimensional representation. We develop a general variational inference algorithm for fast approximate posterior inference. We explore applications to social and protein interaction networks.",2007-05-30,https://www.semanticscholar.org/paper/d9b9fb207013bf8afb064f23f3dffc7edd005f73,Neural Information Processing Systems
3051,Cells: a virtual mobile smartphone architecture,"Smartphones are increasingly ubiquitous, and many users carry multiple phones to accommodate work, personal, and geographic mobility needs. We present Cells, a virtualization architecture for enabling multiple virtual smartphones to run simultaneously on the same physical cellphone in an isolated, secure manner. Cells introduces a usage model of having one foreground virtual phone and multiple background virtual phones. This model enables a new device namespace mechanism and novel device proxies that integrate with lightweight operating system virtualization to multiplex phone hardware across multiple virtual phones while providing native hardware device performance. Cells virtual phone features include fully accelerated 3D graphics, complete power, management features, and full telephony functionality with separately assignable telephone numbers and caller ID support. We have implemented a prototype of Cells that supports multiple Android virtual phones on the same phone. Our performance results demonstrate that Cells imposes only modest runtime and memory overhead, works seamlessly across multiple hardware devices including Google Nexus 1 and Nexus S phones, and transparently runs Android applications at native speed without any modifications.",2011-10-23,https://www.semanticscholar.org/paper/60278c1f10bf1138f7f387e76e160cf88e599d2f,Symposium on Operating Systems Principles
2989,Large Scale Nonparametric Bayesian Inference: Data Parallelisation in the Indian Buffet Process,"Nonparametric Bayesian models provide a framework for flexible probabilistic modelling of complex datasets. Unfortunately, the high-dimensional averages required for Bayesian methods can be slow, especially with the unbounded representations used by nonparametric models. We address the challenge of scaling Bayesian inference to the increasingly large datasets found in real-world applications. We focus on parallelisation of inference in the Indian Buffet Process (IBP), which allows data points to have an unbounded number of sparse latent features. Our novel MCMC sampler divides a large data set between multiple processors and uses message passing to compute the global likelihoods and posteriors. This algorithm, the first parallel inference scheme for IBP-based models, scales to datasets orders of magnitude larger than have previously been possible.",2009-12-07,https://www.semanticscholar.org/paper/8e20c700d413278e06affa930e21e1aa04f27aca,Neural Information Processing Systems
661,Intracoronary stenting as an adjunct to angioplasty in acute myocardial infarction.,,1991-11-01,https://www.semanticscholar.org/paper/ea332dcd5369b8b97cead38b98a3075352cc560b,The Journal of invasive cardiology
801,On the Complexity of Database Queries,"We revisit the issue of the complexity of database queries, in the light of the recent parametric refinement of complexity theory. We show that, if the query size (or the number of variables in the query) is considered as a parameter, then the relational calculus and its fragments (conjunctive queries, positive queries) are classified at appropriate levels of the so-called W hierarchy of Downey and Fellows. These results strongly suggest that the query size is inherently in the exponent of the data complexity of any query evaluation algorithm, with the implication becoming stronger as the expressibility of the query language increases. On the positive side, we show that this exponential dependence can be avoided for the extension of acyclic queries with ? (but not <) inequalities.",1999-06-01,https://www.semanticscholar.org/paper/4f077ff4b673cd6695a2ad5e60fa5fc46f6f843f,Journal of computer and system sciences (Print)
1650,Bayesian Nonparametrics I,"We begin by discussing the central problem of model selection, and quickly illustrate how Bayesian nonparametrics can help us with that problem and a lot more. We briefly introduce the notion of random measures, before reviewing the Chinese restaurant process (CRP) and infinite mixture models. We then formally define the Dirichlet process, demonstrate its properties as a random measure, and then derive the CRP from the definition of a Dirichlet process. We conclude with the stick-breaking process, another construction of the Dirichlet process, but did not have time to derive it.",,https://www.semanticscholar.org/paper/4e88a9e28c4a4a4804700809df13ab822ac6a6ad,
1520,Reconstructing the universe with variational self-boosted sampling,"Forward modeling approaches in cosmology have made it possible to reconstruct the initial conditions at the beginning of the Universe from the observed survey data. However the high dimensionality of the parameter space still poses a challenge to explore the full posterior, with traditional algorithms such as Hamiltonian Monte Carlo (HMC) being computationally inefficient due to generating correlated samples and the performance of variational inference being highly dependent on the choice of divergence (loss) function. Here we develop a hybrid scheme, called variational self-boosted sampling (VBS) to mitigate the drawbacks of both these algorithms by learning a variational approximation for the proposal distribution of Monte Carlo sampling and combine it with HMC. The variational distribution is parameterized as a normalizing flow and learnt with samples generated on the fly, while proposals drawn from it reduce auto-correlation length in MCMC chains. Our normalizing flow uses Fourier space convolutions and element-wise operations to scale to high dimensions. We show that after a short initial warm-up and training phase, VBS generates better quality of samples than simple VI approaches and in the hybrid sampling phase, reduces the correlation length in the sampling phase by a factor of 10–50 over using only HMC to explore the posterior of initial conditions in 643 and 1283 dimensional problems, with larger gains for high signal-to-noise data observations. Hybrid sampling with online training of the variational distribution violates Markov property, and to retain the asymptotic guarantees of HMC, in the final phase we use a fixed variational distribution as proposal distribution and propagate these samples to the posterior distribution.",2022-06-28,https://www.semanticscholar.org/paper/41aead90e62b111616e21b4e4eb3af38faa1310e,Journal of Cosmology and Astroparticle Physics
2183,"APPA, a potential new therapy for osteoarthritis, inhibits neutrophil pro-inflammatory functions without impairing host defence",,2019-04-01,https://www.semanticscholar.org/paper/e685173ebfc997c9ea7586c7b1f21ed74f3dee45,Osteoarthritis and Cartilage
2139,Sound propagation along an impedance plane,,1975-11-08,https://www.semanticscholar.org/paper/3639a382020eaea3621842785e5227d3795da918,
3009,Encrypted cloud photo storage using Google photos,"Cloud photo services are widely used for persistent, convenient, and often free photo storage, which is especially useful for mobile devices. As users store more and more photos in the cloud, significant privacy concerns arise because even a single compromise of a user's credentials give attackers unfettered access to all of the user's photos. We have created Easy Secure Photos (ESP) to enable users to protect their photos on cloud photo services such as Google Photos. ESP introduces a new client-side encryption architecture that includes a novel format-preserving image encryption algorithm, an encrypted thumbnail display mechanism, and a usable key management system. ESP encrypts image data such that the result is still a standard format image like JPEG that is compatible with cloud photo services. ESP efficiently generates and displays encrypted thumbnails for fast and easy browsing of photo galleries from trusted user devices. ESP's key management makes it simple to authorize multiple user devices to view encrypted image content via a process similar to device pairing, but using the cloud photo service as a QR code communication channel. We have implemented ESP in a popular Android photos app for use with Google Photos and demonstrate that it is easy to use and provides encryption functionality transparently to users, maintains good interactive performance and image quality while providing strong privacy guarantees, and retains the sharing and storage benefits of Google Photos without any changes to the cloud service.",2021-06-24,https://www.semanticscholar.org/paper/73d77e49560e637fe6bb6d82a965bd149a5e47d4,"ACM SIGMOBILE International Conference on Mobile Systems, Applications, and Services"
3256,Lemurs groom-at-a-distance through vocal networks,,2015-12-01,https://www.semanticscholar.org/paper/4e0292248163d0cad3273208f0d1730b75941ea2,Animal Behaviour
966,Relationship between Ocular Fatigue and Use of a Virtual Reality Device,"Purpose: To investigate ocular fatigue after the use of a head-mounted display (HMD)-type virtual reality device. Methods: Healthy adult volunteers were examined for ocular fatigue before and after watching videos for 10 min with an HMD-type virtual reality device. Subjective ocular fatigue was measured using a questionnaire. Objective fatigue was measured using the critical flicker fusion frequency (CFF), high frequency component of accommodative microfluctuation, and accommodation amplitude. The accommodation amplitude was measured using the push-up method and the dynamic measurement mode of the autorefractometer. Changes in the spherical equivalent were also measured. Results: The questionnaire-based subjective ocular fatigue increased ( p = 0.020) after use of the HMD device. In the dominant eye, the high frequency component of accommodative microfluctuation increased ( p < 0.05). The accommodation amplitude using the push-up method was decreased in the nondominant eye ( p = 0.007), and temporary myopia was observed ( p < 0.05). However, there was no increase in ocular fatigue in the CFF or the accommodation amplitude using the dynamic measurement mode, which showed no significant difference before and after using the HMD device ( p > 0.05). Conclusions: A subjective test and some objective tests suggested that use of the HMD-type virtual reality display increased ocular fatigue. However, no increase in ocular fatigue was measured using CFF nor in the accommodation amplitude using the dynamic measurement mode which was a limitation of the study. More studies with the aim to alleviate ocular fatigue after using HMD-type virtual reality devices are therefore needed.",2020-02-15,https://www.semanticscholar.org/paper/866dcd57b8fbeef33b67d77ad05a018dbfe5bac8,Journal of the Korean Ophthalmological Society
854,Expressing combinatorial optimization problems by linear programs,"Many combinatorial optimization problems call for the optimization of a linear function over a certain polytope. Typically, these polytopes have an exponential number of facets. We explore the problem of finding small linear programming formulations when one may use any new variables and constraints. We show that expressing the matching and the Traveling Salesman Problem by a symmetric linear program requires exponential size. We relate the minimum size needed by a LP to express a polytope to a combinatorial parameter, point out some connections with communication complexity theory, and examine the vertex packing polytope for some classes of graphs.",1991-12-01,https://www.semanticscholar.org/paper/0a6219ca8fef322c6bf7b1ff439635cfcf096282,Symposium on the Theory of Computing
2969,A dependent partition-valued process for multitask clustering and time evolving network modelling,"The fundamental aim of clustering algorithms is to partition data points. We consider tasks where the discovered partition is allowed to vary with some covariate such as space or time. One approach would be to use fragmentation-coagulation processes, but these, being Markov processes, are restricted to linear or tree structured covariate spaces. We define a partition-valued process on an arbitrary covariate space using Gaussian processes. We use the process to construct a multitask clustering model which partitions datapoints in a similar way across multiple data sources, and a time series model of network data which allows cluster assignments to vary over time. We describe sampling algorithms for inference and apply our method to defining cancer subtypes based on different types of cellular characteristics, finding regulatory modules from gene expression data from multiple human populations, and discovering time varying community structure in a social network.",2013-03-13,https://www.semanticscholar.org/paper/002206a436d059153c1794fa32a588c8f026399b,
3053,Improving Virtual Appliance Management through Virtual Layered File Systems,"Managing many computers is difficult. Recent virtualization trends exacerbate this problem by making it easy to create and deploy multiple virtual appliances per physical machine, each of which can be configured with different applications and utilities. This results in a huge scaling problem for large organizations as management overhead grows linearly with the number of appliances. 
 
To address this problem, we introduce Strata, a system that combines unioning file system and package management semantics to enable more efficient creation, provisioning and management of virtual appliances. Unlike traditional systems that depend on monolithic file systems, Strata uses a collection of individual sotware layers that are composed together into the Virtual Layered File System (VLFS) to provide the traditional file system view. Individual layers are maintained in a central repository and shared across all file systems that use them. Layer changes and upgrades only need to be done once in the repository and are then automatically propagated to all virtual appliances, resulting in management overhead independent of the number of appliances. Our Strata Linux prototype requires only a single loadable kernel module providing the VLFS support and doesn't require any application or source code level kernel modifications. Using this prototype, we demonstrate how Strata enables fast system provisioning, simplifies system maintenance and upgrades, speeds system recovery from security exploits, and incurs only modest performance overhead.",2011-12-04,https://www.semanticscholar.org/paper/78d339b7801f593d5739cf55dde3337bbe2de7ab,LiSA
842,"Primal-Dual Approximation Algorithms for Integral Flow and Multicut in Trees, with Applications to Matching and Set Cover",,1993-07-05,https://www.semanticscholar.org/paper/b78bac7d428451e77641f3f727b7df04aa4faea2,"International Colloquium on Automata, Languages and Programming"
1448,"Measurement of the reaction C12(?,-)X near threshold","Using the decay‐in‐flight νμ beam from the Los Alamos Meson Physics Facility and a massive liquid scintillator neutrino detector (LSND), the reaction C(νμ,μ−)X has been studied near threshold. Preliminary results for the visible energy distribution of the final state and the flux integrated cross section are presented and compared with the results of several nuclear model calculations.",1995-07-10,https://www.semanticscholar.org/paper/f7aca61fc13f827ac46dfe46aff278b5fe856459,
1865,Latent Dirichlet Allocation,,2001-01-03,https://www.semanticscholar.org/paper/f198043a866e9187925a8d8db9a55e3bfdd47f2c,Journal of machine learning research
2122,服務系統服務品質滿意度之硏究--以某大學圖書館爲實證硏究,摘要 本文之目的係研究服務系統之服務品質滿意度衡量。本文回顧相關文獻，硏究服務系統之構建與服務品質之衡量構面。然後以某大學圖書館爲個案，建立圆書館服務系統，依據衡量構面，參考圖書館專家的意見來設計問卷，透過抽樣調査以衡量服務滿意度，作爲改善服務系統之依據。本硏究成果除了可供圖書館改善服務之依據外，本研究架構亦可做爲分析服務系統及改善服務品質之有效工具。,2000-01-01,https://www.semanticscholar.org/paper/6711bedf8fc3ec0db568a59efdcdaacbc72aaf1b,
2716,A virtual world for network management,"Existing network management systems typically use a combination of textual displays and 2-D directed graph representations of network topology. A network management system is being designed that uses a virtual world presented through a 3-D stereo display and manipulated with a 3-D mouse. The goal is to allow the user to better understand and control the structure and behavior of a large, complex network. In the current prototype, the user interacts with a 3-D representation of a network whose topology and behavior are specified by a separate network emulator. The user can choose from among a set of different views of the network. For example, one view shows a selected virtual path as a series of logical links contained within a physical path. The system will serve as a testbed for the knowledge-based design of network visualizations.<<ETX>>",1993-09-18,https://www.semanticscholar.org/paper/69e4ddd32ed71f59779940eca699035d9a9c1c6c,Proceedings of IEEE Virtual Reality Annual International Symposium
3311,Herbivore-initiated interaction cascades and their modulation by productivity in an African savanna,"Despite conceptual recognition that indirect effects initiated by large herbivores are likely to have profound impacts on ecological community structure and function, the existing literature on indirect effects focuses largely on the role of predators. As a result, we know neither the frequency and extent of herbivore-initiated indirect effects nor the mechanisms that regulate their strength. We examined the effects of ungulates on taxa (plants, arthropods, and an insectivorous lizard) representing several trophic levels, using a series of large, long-term, ungulate-exclusion plots that span a landscape-scale productivity gradient in an African savanna. At each of six sites, lizards, trees, and the numerically dominant order of arthropods (Coleoptera) were more abundant in the absence of ungulates. The effect of ungulates on arthropods was mediated by herbaceous vegetation cover. The effect on lizards was simultaneously mediated by both tree density (lizard microhabitat) and arthropod abundance (lizard food). The magnitudes of the experimental effects on all response variables (trees, arthropods, and lizards) were negatively correlated with two distinct measures of primary productivity. These results demonstrate strong cascading effects of ungulates, both trophic and nontrophic, and support the hypothesis that productivity regulates the strength of these effects. Hence, the strongest indirect effects (and thus, the greatest risks to ecosystem integrity after large mammals are extirpated) are likely to occur in low-productivity habitats.",2007-01-02,https://www.semanticscholar.org/paper/c739ed724b8a43409ac3acedc31dd1a7786e7872,Proceedings of the National Academy of Sciences of the United States of America
3109,Web Content Delivery Using Thin-Client Computing,,,https://www.semanticscholar.org/paper/98c65de3be218534fdf7a3eb9a1a936c3a5f147a,
2400,Properties of mitochondria isolated from cyanide-sensitive and cyanide-stimulated cultures of Acanthamoeba castellanii.,"1. Mitochondria isolated from cultures of Acanthamoeba castellanii exhibit respiratory control and oxidize alpha-oxoglutarate, succinate and NADH with ADP:O ratios of about 2.4, 1.4 and 1.25 respectively. 2. Mitochondria from cultures of which the respiration was stimulated up to 50% by 1mm-cyanide (type-A mitochondria) and from cyanide-sensitive cultures (type-B mitochondria) had similar respiratory-control ratios and ADP:O ratios. 3. State-3 rates of respiration were generally more cyanide-sensitive than State-4 rates, and the respiration of type-A mitochondria was more cyanide-resistant than that of type-B mitochondria. 4. Salicylhydroxamic acid alone had little effect on respiratory activities of either type of mitochondria, but when added together with cyanide, irrespective of the order of addition, inhibition was almost complete. 5. Oxidation of externally added NADH by type-A mitochondria was mainly via an oxidase with a low affinity for oxygen (K(m)[unk]15mum), which was largely cyanide-sensitive and partially antimycin A-sensitive; this electron-transport pathway was inhibited by ADP. 6. Cyanide-insensitive but salicylhydroxamic acid-sensitive respiration was stimulated by AMP and ADP, and by ATP after incubation in the presence of MgCl(2). 7. Addition of rotenone to mitochondria oxidizing alpha-oxoglutarate lowered the ADP:O ratios by about one-third and rendered inhibition by cyanide more complete. 8. The results suggest that mitochondria of A. castellanii possess branched pathways of electron transport which terminate in three separate oxidases; the proportions of electron fluxes via these pathways vary at different stages of growth.",1978-07-15,https://www.semanticscholar.org/paper/12a0781a89bb7eaf1f7223b6fb3c202c3c8f2c11,Biochemical Journal
3028,NEVE: Nested Virtualization Extensions for ARM,"Nested virtualization, the ability to run a virtual machine inside another virtual machine, is increasingly important because of the need to deploy virtual machines running software stacks on top of virtualized cloud infrastructure. As ARM servers make inroads in cloud infrastructure deployments, supporting nested virtualization on ARM is a key requirement, which has been met recently with the introduction of nested virtualization support to the ARM architecture. We build the first hypervisor to use ARM nested virtualization support and show that despite similarities between ARM and x86 nested virtualization support, performance on ARM is much worse than on x86. This is due to excessive traps to the hypervisor caused by differences in non-nested virtualization support. To address this problem, we introduce a novel paravirtualization technique to rapidly prototype architectural changes for virtualization and evaluate their performance impact using existing hardware. Using this technique, we propose Nested Virtualization Extensions for ARM (NEVE), a set of simple architectural changes to ARM that can be used by software to coalesce and defer traps by logging the results of hypervisor instructions until the results are actually needed by the hypervisor or virtual machines. We show that NEVE allows hypervisors running real application workloads to provide an order of magnitude better performance than current ARM nested virtualization support and up to three times less overhead than x86 nested virtualization. NEVE will be included in ARMv8.4, the next version of the ARM architecture.",2017-10-14,https://www.semanticscholar.org/paper/8b5916fcf0e655815007588caf2d007e378bc1d0,Symposium on Operating Systems Principles
1880,Energy-Efficient Unmanned Aerial Vehicle (UAV) Surveillance Utilizing Artificial Intelligence (AI),"Recently, unmanned aerial vehicles (UAVs) enhance connectivity and accessibility for civilian and military applications. A group of UAVs with on-board cameras usually monitors or collects information about designated areas. The UAVs can build a distributed network to share/exchange and to process collected sensing data before sending to a data processing center. A huge data transmission among them may cause latency and high-energy consumption. This paper deploys artificial intelligent (AI) techniques to process the video data streaming among the UAVs. Thus, each distributed UAV only needs to send a certain required information to each other. Each UAV processes data utilizing AI and only sends the data that matters to the others. The UAVs, formed as a connected network, communicate within a short communication range and share their own data to each other. Convolution neural network (CNN) technique extracts feature from images automatically that the UAVs only send the moving objects instead of the whole frames. This significantly reduces redundant information for either each UAV or the whole network and saves a huge energy consumption for the network. The UAVs can also save energy for their motion in the sensing field. In addition, a flocking control algorithm is deployed to lead the group of UAVs in the working fields and to avoid obstacles if needed. Simulation and experimental results are provided to verify the proposed algorithms in either AI-based data processing or controlling the UAVs. The results show promising points to save energy for the networks.",2021-10-13,https://www.semanticscholar.org/paper/9406d652e434772e5e451b931526e90e386449c3,Wireless Communications and Mobile Computing
3276,"Habitat use by the Persian onager, Equus hemionus onager (Perissodactyla: Equidae) in Qatrouyeh National Park, Fars, Iran","Iran’s Persian onager populations are critically endangered. This study of their natural history in Qatrouyeh National Park provides insights for enhancing their conservation. The population as a whole is greatly affected by weather. Wind, rain and cold drive populations from the plains to the valleys of hill-valley habitats. Vegetation features and water also influence habitat use, but differently for different sex and reproductive classes. Females with juveniles use plains with high-quality vegetation, whereas females without young and solitary territorial males choose those of intermediate quality. Females with young foals are also found closest to watering points. Future translocation of Persian onagers will only succeed if prospective habitats have sufficient hill-valley refuges and enough plains with winds to moderately hot conditions. Sufficient plains supporting high-quality vegetation near water for lactating females must co-exist with plains of moderate-quality vegetation that attract females without young, so reducing crowding and competition.",2013-11-01,https://www.semanticscholar.org/paper/1eb5e0c56f2722d2d609b0de739309ed11d9b7d3,
3596,Concepts: linguistic support for generic programming in C++,"Generic programming has emerged as an important technique for the development of highly reusable and efficient software libraries. In C++, generic programming is enabled by the flexibility of templates, the C++ type parametrization mechanism. However, the power of templates comes with a price: generic (template) libraries can be more difficult to use and develop than non-template libraries and their misuse results in notoriously confusing error messages. As currently defined in C++98, templates are unconstrained, and type-checking of templates is performed late in the compilation process, i.e., after the use of a template has been combined with its definition. To improve the support for generic programming in C++, we introduce concepts to express the syntactic and semantic behavior of types and to constrain the type parameters in a C++ template. Using concepts, type-checking of template definitions is separated from their uses, thereby making templates easier to use and easier to compile. These improvements are achieved without limiting the flexibility of templates or decreasing their performance - in fact their expressive power is increased. This paper describes the language extensions supporting concepts, their use in the expression of the C++ Standard Template Library, and their implementation in the ConceptGCC compiler. Concepts are candidates for inclusion in the upcoming revision of the ISO C++ standard, C++0x.",2006-10-16,https://www.semanticscholar.org/paper/43913a70c2226c853b1e0a45bcb87c7b711d7212,"Conference on Object-Oriented Programming Systems, Languages, and Applications"
821,Principles and methods of testing finite state machines-a survey,"With advanced computer technology, systems are getting larger to fulfill more complicated tasks: however, they are also becoming less reliable. Consequently, testing is an indispensable part of system design and implementation; yet it has proved to be a formidable task for complex systems. This motivates the study of testing finite stare machines to ensure the correct functioning of systems and to discover aspects of their behavior. A finite state machine contains a finite number of states and produces outputs on state transitions after receiving inputs. Finite state machines are widely used to model systems in diverse areas, including sequential circuits, certain types of programs, and, more recently, communication protocols. In a testing problem we have a machine about which we lack some information; we would like to deduce this information by providing a sequence of inputs to the machine and observing the outputs produced. Because of its practical importance and theoretical interest, the problem of testing finite state machines has been studied in different areas and at various times. The earliest published literature on this topic dates back to the 1950's. Activities in the 1960's mid early 1970's were motivated mainly by automata theory and sequential circuit testing. The area seemed to have mostly died down until a few years ago when the testing problem was resurrected and is now being studied anew due to its applications to conformance testing of communication protocols. While some old problems which had been open for decades were resolved recently, new concepts and more intriguing problems from new applications emerge. We review the fundamental problems in testing finite state machines and techniques for solving these problems, tracing progress in the area from its inception to the present and the stare of the art. In addition, we discuss extensions of finite state machines and some other topics related to testing.",1996-08-01,https://www.semanticscholar.org/paper/d7790181ae4a6af8c0418f3bc0f4850ddffbc3f8,Proceedings of the IEEE
2260,Regulation of neutrophil apoptosis by Mcl-1.,"Neutrophils rapidly undergo spontaneous apoptosis, but this process can be considerably delayed by exposure to a variety of agents such as pro-inflammatory cytokines. The anti-apoptotic protein of the Bcl-2 family, Mcl-1, plays a key role in the regulation of neutrophil apoptosis. The protein has some unusual properties compared with other family members, including an extremely high turnover rate. Many factors, such as cytokines and local oxygen concentrations, can regulate cellular levels of Mcl-1 via transcription and post-transcriptional modification, control the survival time of neutrophils within tissues and thereby influence the inflammatory response.",2004-06-01,https://www.semanticscholar.org/paper/0144e1339b5701c70e07bd9d63385c893b0fb60d,Biochemical Society Transactions
2915,The role of grain boundary ferrite evolution and thermal aging on creep cavitation of type 316H austenitic stainless steel,,2021-03-11,https://www.semanticscholar.org/paper/47702d1f5f78ac4751e6d32e617a7d9d13ee1922,Materials Science & Engineering: A
1058,Observation of Single Top-Quark Production,,,https://www.semanticscholar.org/paper/445b8d53ce652344e51086641c8721114e4dfba9,
2701,Introduction to the special issue on virtual reality software and technology,"We are delighted to present this special issue containing extended versions of four papers selected from the 1994 Virtual Reality Software & Technology (VRST) conference, held August 23-26, 1994, in Singapore. Techniques and tools for interacting with virtual environments are at the core of research and development efforts around the world, and these articles provide a sampling of the latest advances. (A companion issue of Communications of the ACM, containing articles that address a broader-based audience, is also being edited.) This issue begins with Alan Wexelblat’s article on the use of gestures in multimodal applications, “An Approach to Natural Gesture in Virtual Environments.” His work uses empty-hand, continuous gestures, much like the gestures we use in our everyday communication with people, for interaction with virtual worlds. These gestures are decomposed into feature-based descriptions that serve as an intermediate language for gestural input. Wexelblat’s prototype system uses several tracking devices attached to various parts of the user’s body to collect raw data about body movement. The data are filtered and converted into body-relative information and sent to a gesture analyzer. The analyzer converts the input to a higher-level description and forwards it to the gesture interpreter, which assigns meaning to gestures based on the application and the interaction context. “Taking Steps: The Influence of a Walking Technique on Presence in Virtual Reality,” by Mel Slater, Martin Usoh, and Anthony Steed, presents an interactive technique for moving through immersive virtual worlds. When within the range of the electromagnetic tracking device used, the user moves around by actually walking. To cover a virtual distance that is larger than the tracker’s physical range, the user walks in place. Walking in place causes the user to move forward in the direction of gaze. The authors also apply a modified version of this interaction technique to climbing up and down steps and ladders. The implementation uses a feed-forward neural network to construct a pattern recognize that detects whether the user is walking in place or doing something else. User trials show that the walking technique leads to a greater sense of presence, even though the users preferred pointing-based navigation techniques. In “HoloSketch: A Virtual Reality Sketching/Animation Tool,” Michael Deering discusses the user interface of a true 3D drawing system based on a “fish-tank VR” model: a high-resolution CRT, head-tracked, liquid-crystal stereo eyewear and a hand-held 3D wand interaction device. Unlike the majority of virtual environments, Deering’s software and hardware infrastructure allows virtual objects to be positioned with subcentimeter accuracy, which is maintained even as the user’s head moves. This makes it possible for the 3D wand to be used as a direct pointer, rather than as an indirect 3D",1995-09-01,https://www.semanticscholar.org/paper/9581b6e532ca8f59a1c71f5f0ab84d63e098a71f,TCHI
3333,Social Side of Biogeography for Specialists@@@Ecological Aspects of Social Evolution.,,1990-11-01,https://www.semanticscholar.org/paper/adff768b1c783cb20141674f4c8d8b264d9f628a,
1101,WIMP Dark Matter Direct Detection Convenors :,"D. Bauer, A. Borgland, B. Cabrera, F. Calaprice, J. Cooley, P. Cushman, T. Empl, R. Essig, E. Figueroa-Feliciano, R. Gaitskell, C. Galbiati, S. Golwala, J. Hall, R. Hill, A. Hime, E. Hoppe, L. Hsu, E. Hungerford, R. Jacobsen, M. Kelsey, R. F. Lang, W. H. Lippincott, B. Loer, S. Luitz, V. Mandic, J. Mardon, J. Maricic, R. Maruyama, D. N. McKinsey, R. Mahapatra, H. Nelson, J. Orrell, K. Palladino, E. Pantic, R. Partridge, H. Robertson, A. Ryd, T. Saab, B. Sadoulet, R. Schnee, W. Shepherd, A. Sonnenschein, P. Sorensen, M. Szydagis, T. M. P. Tait, T. Volansky, M. Witherell, D. Wright, K. Zurek.",,https://www.semanticscholar.org/paper/1e6776c42da9b9b0fb89f6476a0ee87e1d58e986,
2326,Identification of a subgroup of myelodysplastic patients with a neutrophil stimulation‐signalling defect,"Summary. f‐Met‐Leu‐Phe‐stimulated luminol‐enhanced chemiluminescence was found to be repeatedly defective in some MDS patients. This defect was not attributed to myeloperoxidase deficiency, nor to a defect in NADPH oxidase function, because PMA chemiluminescence was found to be normal in these individuals. An arbitrary value of 7 mV (half the mean control value) was chosen to subdivide the group: MDS patients with values <7 mV had a mean f‐Met‐Leu‐Phe chemiluminescence response of 2·5±0·5 compared to MDS patients with values <7 mV who had a mean response of 15·6±1·6mV, P<0·01 (healthy controls 14±2 mV). The characteristics of the f‐Met‐Leu‐Phe receptor and initial calcium flux results suggested that the receptor itself was normal in number and function in low f‐Met‐Leu‐Phe responders. The rate of superoxide generation, which is calcium‐dependent, was also found to be in the normal range in low f‐Met‐Leu‐Phe responders, although total superoxide production was reduced in some of these patients.",1994-04-01,https://www.semanticscholar.org/paper/8baadb7929f6e6ebef1706026240028618ee38be,British Journal of Haematology
2,Detecting Foodborne Illness Complaints in Multiple Languages Using English Annotations Only,"Health departments have been deploying text classification systems for the early detection of foodborne illness complaints in social media documents such as Yelp restaurant reviews. Current systems have been successfully applied for documents in English and, as a result, a promising direction is to increase coverage and recall by considering documents in additional languages, such as Spanish or Chinese. Training previous systems for more languages, however, would be expensive, as it would require the manual annotation of many documents for each new target language. To address this challenge, we consider cross-lingual learning and train multilingual classifiers using only the annotations for English-language reviews. Recent zero-shot approaches based on pre-trained multi-lingual BERT (mBERT) have been shown to effectively align languages for aspects such as sentiment. Interestingly, we show that those approaches are less effective for capturing the nuances of foodborne illness, our public health application of interest. To improve performance without extra annotations, we create artificial training documents in the target language through machine translation and train mBERT jointly for the source (English) and target language. Furthermore, we show that translating labeled documents to multiple languages leads to additional performance improvements for some target languages. We demonstrate the benefits of our approach through extensive experiments with Yelp restaurant reviews in seven languages. Our classifiers identify foodborne illness complaints in multilingual reviews from the Yelp Challenge dataset, which highlights the potential of our general approach for deployment in health departments.",2020-10-11,https://www.semanticscholar.org/paper/10b7e11424bd8778d4def8f0a4b2c5f2eff9a632,International Workshop on Health Text Mining and Information Analysis
1936,A Novel Route Selection and Resource Allocation Approach to Improve the Efficiency of Manual Material Handling System in 200-mm Wafer Fabs for Industry 3.5,"Motivated by realistic needs to enhance the productivity for 200-mm wafer fabs, this paper aims to propose a novel approach for manual material handling system (MMHS) to mimic functionalities of the automated material handling system in the advanced fabs without intensive capital investment to deliver the wafer lots manually and systematically. In particular, a mathematical model is developed to optimize the routing plan with two objectives that minimize the total traveling distance in all routes or minimize the number of manpower needed in all routes. Furthermore, a route planning approach is proposed to utilize the routes that reduce the technician traveling distance and transportation time for implementation. Also, a manpower loading index was developed for evaluating the number of needed technicians in the proposed MMHS. To estimate the validity of the proposed MMHS, we developed a simulation environment based on empirical data with different transportation requirement scenarios for comparison. The results have shown practical viability of the proposed approach.",2016-07-19,https://www.semanticscholar.org/paper/892701e35b21a935ed76b10a69f12b9c340cc9db,IEEE Transactions on Automation Science and Engineering
3285,Landscape-Scale Conservation Planning of the Ewaso Nyiro: A Model for Land Use Planning in Kenya?,"The unique wildlife of the Ewaso Nyiro and valuable services that the ecosystem provides for humans (e.g., clean water and productive grasslands) cannot be conserved by working solely on traditional conservation strongholds such as the national reserves and private ranches of central Laikipia. To reach objectives for conserving wildlife, stakeholders must work to preserve wildlife habitat and corridors in the surrounding human-dominated landscape—a daunting task considering the complexity of working at large spatial scales (e.g., many landowners, competing land uses) and limited conservation resources available. Systematic, landscape-scale conservation planning helps stakeholders set meaningful and transparent objectives, identify where to work to meet those objectives, and prioritize areas for immediate investment. We describe results and implications of an initial landscape-scale planning exercise for the Ewaso Nyiro that culminated in a workshop in January 2006. Forty participants selected nine focal features, set quantitative objectives for four of them (elephants, Grevy’s zebra, lions, wild dogs), and set spatial conservation priorities for the entire landscape on the basis of complementary needs of critical species. The modest objectives for these species (e.g., maintaining a population of 300 wild dogs) cannot be met by conservation focused solely on traditional strongholds. The exercise indicated that nearly 84% of the landscape needs conservation investment, and it identified three near-term priorities: (1) maintain current investments in conservation strongholds, (2) increase investment to secure the narrow corridor between Samburu and Laikipia Districts, and (3) increase investment to secure portions of Samburu District, including the Matthews Range. The results we describe represent the initiation of a land use planning process that, if continued, can help meet both biodiversity and livelihood development objectives. We recommend this process be carried forward in the Ewaso Nyiro and then in similar ecosystems in Kenya and eastern Africa. Karl A. Didier, Global Conservation Programs, Wildlife Conservation Society, Gainesville, FL, USA. Alayne Cotterill, Living with Lions and the Wildlife Conservation Research Unit, University of Oxford, Nanyuki, Kenya. Iain DouglasHamilton, Save the Elephants and Department of Zoology, University of Oxford, Nairobi, Kenya. Laurence Frank, Living with Lions, Panthera, New York, NY, USA; and Museum of Vertebrate Zoology, University of California, Berkeley, CA, USA. Nicholas J. Georgiadis, Property and Environment Research Center, Bozeman, MT, USA. Max Graham, Department of Geography, University of Cambridge, Cambridge, UK. Festus Ihwagi, Save the Elephants, Nairobi, Kenya. Juliet King, Northern Rangelands Trust, Isiolo, Kenya. Delphine MalleretKing, Laikipia Wildlife Forum, Nanyuki, Kenya. Dan Rubenstein, Department of Ecology and Evolutionary Biology, Princeton University, Princeton, NJ, USA. David Wilkie, Global Conservation Programs, Wildlife Conservation Society, Waltham, MA, USA. Rosie Woodroffe, Department of Wildlife, Fish, and Conservation Biology, University of California, Davis, CA, USA. Correspondence: K. A. Didier, kdidier@wcs.org. Expanded author information follows the Acknowledgments section. Manuscript received 7 January 2009; accepted 18 May 2010. 1 0 6 • S M I T H S O N I A N C O N T R I B U T I O N S T O Z O O L O G Y",,https://www.semanticscholar.org/paper/25284d6b4cf942af96ddb75a151ac12b5ee30b5f,
3296,Immunocontraception decreases group fidelity in a feral horse population during the non-breeding season,,2009-02-01,https://www.semanticscholar.org/paper/0a46073fdbaa91f977d2bb060ffd375b5c3e4148,
1702,Multicanonical Stochastic Variational Inference,"Stochastic variational inference (SVI) enables approximate posterior inference with large data sets for otherwise intractable models, but like all variational inference algorithms it suffers from local optima. Deterministic annealing, which we formulate here for the generic class of conditionally conjugate exponential family models, uses a temperature parameter that deterministically deforms the objective, and reduce this parameter over the course of the optimization to recover the original variational set-up. A well-known drawback in annealing approaches is the choice of the annealing schedule. We therefore introduce multicanonical variational inference (MVI), a variational algorithm that operates at several annealing temperatures simultaneously. This algorithm gives us adaptive annealing schedules. Compared to the traditional SVI algorithm, both approaches find improved predictive likelihoods on held-out data, with MVI being close to the best-tuned annealing schedule.",2014-11-07,https://www.semanticscholar.org/paper/7a7d9cf8a6e28da11b71057948975fd179ef34be,
1205,Evidence for production of single top quarks,"We present first evidence for the production of single top quarks in the D0 detector at the Fermilab Tevatron ppbar collider. The standard model predicts that the electroweak interaction can produce a top quark together with an antibottom quark or light quark, without the antiparticle top quark partner that is always produced from strong coupling processes. Top quarks were first observed in pair production in 1995, and since then, single top quark production has been searched for in ever larger datasets. In this analysis, we select events from a 0.9 fb-1 dataset that have an electron or muon and missing transverse energy from the decay of a W boson from the top quark decay, and two, three, or four jets, with one or two of the jets identified as originating from a b hadron decay. The selected events are mostly backgrounds such as W+jets and ttbar events, which we separate from the expected signals using three multivariate analysis techniques: boosted decision trees, Bayesian neural networks, and matrix element calculations. A binned likelihood fit of the signal cross section plus background to the data from the combination of the results from the three analysis methods gives a cross section for single top quark production of 4.7 +- 1.3 pb. The probability to measure a cross section at this value or higher in the absence of signal is 0.014%, corresponding to a 3.6 standard deviation significance. The measured cross section value is compatible at the 10% level with the standard model prediction for electroweak top quark production.",2008-07-14,https://www.semanticscholar.org/paper/2c0075685f3382443497f3f031fa2ee6da557718,
1547,The Posterior Predictive Null,". Bayesian model criticism is an important part of the practice of Bayesian statistics. Traditionally, model criticism methods have been based on the predictive check, an adaptation of goodness-of-ﬁt testing to Bayesian modeling and an eﬀective method to understand how well a model captures the distribution of the data. In modern practice, however, researchers iteratively build and develop many models, exploring a space of models to help solve the problem at hand. While classical predictive checks can help assess each one, they cannot help the researcher understand how the models relate to each other. This paper introduces the posterior predictive null check (PPN), a method for Bayesian model criticism that helps characterize the relationships between models. The idea behind the PPN is to check whether data from one model’s predictive distribution can pass a predictive check designed for another model. This form of criticism complements the classical predictive check by providing a comparative tool. A collection of PPNs, which we call a PPN study, can help us understand which models are equivalent and which models provide diﬀerent perspectives on the data. With mixture models, we demonstrate how a PPN study, along with traditional predictive checks, can help select the number of components by the principle of parsimony. With probabilistic factor models, we demonstrate how a PPN study can help understand relationships between diﬀerent classes of models, such as linear models and models based on neural networks. Finally, we analyze data from the literature on predictive checks to show how a PPN study can improve the practice of Bayesian model criticism. Code to replicate the results in this paper is available at https://github.com/gemoran/ppn-code .",2021-12-06,https://www.semanticscholar.org/paper/ab830a6e9fd3319e75e3b871a6e2f0f0a9168751,Bayesian Analysis
664,Improving Model Training via Self-learned Label Representations,"Modern neural network architectures have shown remarkable success in several large-scale classification and prediction tasks. Part of the success of these architectures is their flexibility to transform the data from the raw input representations (e.g. pixels for vision tasks, or text for natural language processing tasks) to one-hot output encoding. While much of the work has focused on studying how the input gets transformed to the one-hot encoding, very little work has examined the effectiveness of these one-hot labels. In this work, we demonstrate that more sophisticated label representations are better for classification than the usual one-hot encoding. We propose Learning with Adaptive Labels (LwAL) algorithm, which simultaneously learns the label representation while training for the classification task. These learned labels can significantly cut down on the training time (usually by more than 50%) while often achieving better test accuracies. Our algorithm introduces negligible additional parameters and has a minimal computational overhead. Along with improved training times, our learned labels are semantically meaningful and can reveal hierarchical relationships that may be present in the data.",2022-09-09,https://www.semanticscholar.org/paper/bf2755f9014befbc3c02262f6770ab7605aac86d,arXiv.org
1983,Cluster policies and industry development in the Hsinchu Science Park: A retrospective review after 30 years,"Abstract In 1980, Taiwan established the Hsinchu Science Park (HSP). The HSP accounted for the creation of 1.43 million jobs and extraordinary contributions to the economic growth of the nation. This development also placed Taiwan on top of the innovation index. This study provides a systematic review of the applied policy tools and the industrial cluster evolution of HSP over four stages. The Boston Consulting Group framework is used to delineate the strategic position and movement of industries in each stage. After 30 years, HSP has become oversaturated, with two Cash Cow and four Dog industries left. Facing such a bottleneck, this paper recommends the HSP 2.0 strategy for policymakers to improve the added-value and sustainable competitiveness of HSP.",2013-12-01,https://www.semanticscholar.org/paper/cebe72bfdc7e53437615242a9be72df0d9885d1a,
1978,A method for estimating the cycle time of business processes with many-to-many relationships among the resources and activities based on individual worklists,,2013-06-01,https://www.semanticscholar.org/paper/70d59bd941a83e89964d74626231424b2bb0172b,Computers & industrial engineering
579,Updaies of relational views,"We study the problem of translating updates of database views. View updates are disambiguated by requning that a specified view complement (i.e. a second view which contnms all the information omitted from the given view) remains constant during the translation. We study some of the computational problems related to the application of this general methodology in the context of relational databases. We restrict our attention to projective views of databases which consist of a single relation and satisfy functional dependencies. We first characterize complementary views and show that finding a minimum complement of a given view is NP-complete. We then study in detail the problem of translating the insertion of a tuple into a view and extend our results to the cases of deletion and replacement of a tuple. Finally we define and study a new kind of dependencies the explicit functional dependencies, which intuitively state that some part of the database information can be computed from the rest.",1983-03-21,https://www.semanticscholar.org/paper/2128bd7851a0303a86f1ae8660eac005a734a7b2,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
2428,The Effect of Narrow Field of View and Information Density on Visual Search Performance in Augmented Reality,"Many optical-see-through displays have a relatively narrow field of view. However, a limited field of view can constrain how information can be presented and searched through. To understand these constraints, we present a series of experiments that address the interrelationships between field of view, information density, and search performance. We do so by simulating various fields of view using two approaches: limiting the field of view presented on a Microsoft HoloLens optical-see-through head-worn display and dynamically changing the portion of a large tiled-display wall on which information is presented, for head-tracked users in both cases. Our results indicate a significant effect of information density and field of view on search performance, with potential search performance benefits of using a larger FOV between ca. 7-28%. Furthermore, while grids guided visual search, they did not significantly affect performance.",2019-03-01,https://www.semanticscholar.org/paper/98f4ffb6b0c5d79e0e735f1f061db025a50c9bdd,IEEE Conference on Virtual Reality and 3D User Interfaces
3171,Discovering Novel Biological Traits From Images Using Phylogeny-Guided Neural Networks,"Discovering evolutionary traits that are heritable across species on the tree of life (also referred to as a phylogenetic tree) is of great interest to biologists to understand how organisms diversify and evolve. However, the measurement of traits is often a subjective and labor-intensive process, making trait discovery a highly label-scarce problem. We present a novel approach for discovering evolutionary traits directly from images without relying on trait labels. Our proposed approach, Phylo-NN, encodes the image of an organism into a sequence of quantized feature vectors -or codes- where different segments of the sequence capture evolutionary signals at varying ancestry levels in the phylogeny. We demonstrate the effectiveness of our approach in producing biologically meaningful results in a number of downstream tasks including species image generation and species-to-species image translation, using fish species as a target example",2023-06-05,https://www.semanticscholar.org/paper/f40e9ee118fa4c1d6ea7ba1aad56c250e2902030,Knowledge Discovery and Data Mining
3591,Evolving a language in and for the real world: C++ 1991-2006,"This paper outlines the history of the C++ programming language from the early days of its ISO standardization (1991), through the 1998 ISO standard, to the later stages of the C++0x revision of that standard (2006). The emphasis is on the ideals, constraints, programming techniques, and people that shaped the language, rather than the minutiae of language features. Among the major themes are the emergence of generic programming and the STL (the C++ standard library's algorithms and containers). Specific topics include separate compilation of templates, exception handling, and support for embedded systems programming. During most of the period covered here, C++ was a mature language with millions of users. Consequently, this paper discusses various uses of C++ and the technical and commercial pressures that provided the background for its continuing evolution.",2007-06-09,https://www.semanticscholar.org/paper/ba49c311278c079272484bfb5cb01ac8d023a6d9,History of Programming Languages
390,Theoretical Problems Related to the Internet,,2000-07-26,https://www.semanticscholar.org/paper/2112dd2d9f125e3d987b91f0dfde76f6f4bc5f7c,International Computing and Combinatorics Conference
1611,use a Gaussian random walk to capture drift in the underlying language model ; for example,"Word embeddings are a powerful approach for unsupervised analysis of language. Recently, Rudolph et al. [35] developed exponential family embeddings, which cast word embeddings in a probabilistic framework. Here, we develop dynamic embeddings, building on exponential family embeddings to capture how the meanings of words change over time. We use dynamic embeddings to analyze three large collections of historical texts: the U.S. Senate speeches from 1858 to 2009, the history of computer science ACM abstracts from 1951 to 2014, and machine learning papers on the ArXiv from 2007 to 2015. We find dynamic embeddings provide better fits than classical embeddings and capture interesting patterns about how language changes.",,https://www.semanticscholar.org/paper/c4e72c764266d85ce0ade71fa812bda43bdd6437,
712,The complexity of optimal multidimensional pricing for a unit-demand buyer,,2018-07-01,https://www.semanticscholar.org/paper/9ce476d5a1fa6b85b041d826f949acc2286f5c09,Games Econ. Behav.
317,Reducibility among equilibrium problems,"We address the fundamental question of whether the Nash equilibria of a game can be computed in polynomial time. We describe certain efficient reductions between this problem for normal form games with a fixed number of players and graphical games with fixed degree. Our main result is that the problem of solving a game for any constant number of players, is reducible to solving a 4-player game.",2006-05-21,https://www.semanticscholar.org/paper/46064f88324ec2504692389e38dabf900906c2c5,Symposium on the Theory of Computing
3259,From Pleistocene to trophic rewilding: A wolf in sheep’s clothing,"Nearly 10 y ago, we (1) critiqued the idea of Pleistocene rewilding (2), a misguided attempt to resurrect bygone ecosystems. Much has happened to the Earth’s biodiversity over the decade since the term “Pleistocene rewilding” was coined, most of it bad. More than half a billion people have been added to the world’s population, and ecosystems continue to be degraded at an alarming rate. A sixth mass extinction is underway, and poaching of megafauna has increased across sub-Saharan Africa. Unfortunately, one thing that has not happened is any serious attempt to scientifically study Pleistocene rewilding. Despite a number of publicized Pleistocene rewilding projects (Oostvaardersplassen in The Netherlands and Pleistocene Park in Siberia), we have yet to see any quantitative data concerning the impacts of megafauna reintroductions.",2015-12-16,https://www.semanticscholar.org/paper/8803ad1b73328267d1b087f4af48fa5ef7c2baba,Proceedings of the National Academy of Sciences of the United States of America
567,Convergence of sideways query evaluation,"Sets of Horn clauses with no function symbols and negation can be considered as a query language (sometimes called DATALOG) that generalizes relational algebra. For example, the following clauses define the transitive closure relation of a binary relation A (not definable in relational algebra): Rule 1: T(z, y) : -A(z, y). Rule 2: T(z, y) : -A(z, z),T(z, y). Here A is a database relation, (it does not appear on the left-hand side of any rule), whereas T is a non-database relation. A typical query would be T(5, CC)?, asking for all items reachable from item 5.",1985-06-01,https://www.semanticscholar.org/paper/ea2b03020bfb04e80444354293346f0f4ab30ea0,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
2941,Therapeutic reduction of ataxin 2 extends lifespan and reduces pathology in TDP-43 mice,,2017-03-17,https://www.semanticscholar.org/paper/65ad7bddc0133047cc9f830eeb5b97b8bcbf9e8e,Nature
135,"Fully-adaptive minimal deadlock-free packet routing in hypercubes, meshes, and other networks","This paper deals with the problem of packet-switched routing in parallel machines. Several new routing algorithms for different interconnection networks are presented. While the new techniques apply to a wide variety of networks, routing algorithms will be shown for the bypercube, the 2-dinleusional mesh, and the shuffleexchange. The techniques presented for hypercubes and meshes are fully-adaptive and minimal. A similar technique can be devised for tori. A fully-adaptive and millimal routing is one in which all possible minimal paths bet,ween a source and a destination are of potential use at the time a message is injected into the network. Minimal paths followed by messages ultimately depend on the local congestion encountered in each node of the network. In the shuffle-exchange network, the routing scheme also exhibits adaptivity but paths could be up to 3 log N long for an N node machine. The shuflleexchange algorithm is the first adaptive and deadlockfree method that requires a small (and independent of N) number of buffers and queues in the routing nodes for that network. * ESLAI, Escuela Superior Latino Americana de Informitica, CC 3193,(1000) Buenos Aires, Argentina. t Computer Research and Advanced Applications Group, IBM Argentina, Ing. E. Bntti 275, (1300) Buenos Aires, Argentina. + Computer Science Dept., IBh’1 Almadeu Research Center, San",1991-06-01,https://www.semanticscholar.org/paper/63c0e3b785d8d6c379eefa505525f8d354ceb831,ACM Symposium on Parallelism in Algorithms and Architectures
572,The even-path problem for graphs and digraphs,On donne un simple algorithme en temps lineaire pour trouver des chemins de meme longueur entre deux nœuds specifie d'un graphe donne. On montre que le meme probleme pour des graphes orientes est NP complet,1984-12-01,https://www.semanticscholar.org/paper/2dcf9dea64f3ea4ac630fe616ee7d789755babed,Networks
368,Understanding the Internet,,2002-04-11,https://www.semanticscholar.org/paper/3bd83c8e7884150adff21831e93ca09357269b61,Hellenic Conference on Artificial Intelligence
744,Buy-at-bulk-related problems in network design,"We study a number of graph-theoretic optimization problems arising in network design. In general, the objective is to determine a network with minimum total cost that can support given traffic demands, possibly subject to additional constraints. Due to economies of scale, the cost of network components is typically sub-additive as a function of the capacity they provide, so these problems have a so-called buy-at-bulk character. Network dimensioning, which represents a high-level phase within the long process of telecommunications network planning, is a primary motivation for this work. We remark that although buy-at-bulk network design has received a lot of attention from researchers in theoretical computer science for more than a decade, these efforts were concentrated on investigating a rather simple version of the problem with minimal constraints, under a broad range of cost models that fall within the buy-at-bulk framework. By contrast, herein we initiate the study of several more involved problem variants, inspired by real-life situations. 
First, we analyze directed buy-at-bulk network design, which includes cases where network links allow only one-way traffic, or more generally where the cost of installing capacity on a link is asymmetric with respect to the direction of the traffic. We furthermore consider buy-at-bulk network design with protection, in which we are required to ensure robustness against the failure of any single component, by allocating capacity for each traffic demand along two disjoint routes in the network. Finally, we also investigate the traffic grooming problem, which arises when demands requesting small amounts of bandwidth must be accommodated in an optical network offering high-capacity transmission channels. 
Our main contributions are approximation algorithms with non-trivial worst-case guarantees for each of the above problems; moreover, from the experimental perspective, we present efficient heuristics that perform very well on realistic problem instances.",,https://www.semanticscholar.org/paper/14374fd5c7d86510ef372888a002cb6ac352aceb,
50,Modeling and managing content changes in text databases,"Large amounts of (often valuable) information are stored in Web-accessible text databases. ""Metasearchers"" provide unified interfaces to query multiple such databases at once. For efficiency, metasearchers rely on succinct statistical summaries of the database contents to select the best databases for each query. So far, database selection research has largely assumed that databases are static, so the associated statistical summaries do not need to change over time. However, databases are rarely static and the statistical summaries that describe their contents need to be updated periodically to reflect content changes. In this paper, we first report the results of a study showing how the content summaries of 152 real Web databases evolved over a period of 52 weeks. Then, we show how to use ""survival analysis"" techniques in general, and Cox's proportional hazards regression in particular, to model database changes over time and predict when we should update each content summary. Finally, we exploit our change model to devise update schedules that keep the summaries up to date by contacting databases only when needed, and then we evaluate the quality of our schedules experimentally over real Web databases.",2005-04-05,https://www.semanticscholar.org/paper/09c86f8704518f3cf1d6e559128167be0cfbd6ac,IEEE International Conference on Data Engineering
198,On Satisfiability Problems with a Linear Structure,"It was recently shown \cite{STV} that satisfiability is polynomially solvable when the incidence graph is an interval bipartite graph (an interval graph turned into a bipartite graph by omitting all edges within each partite set). Here we relax this condition in several directions: First, we show that it holds for $k$-interval bigraphs, bipartite graphs which can be converted to interval bipartite graphs by adding to each node of one side at most $k$ edges; the same result holds for the counting and the weighted maximization version of satisfiability. Second, given two linear orders, one for the variables and one for the clauses, we show how to find, in polynomial time, the smallest $k$ such that there is a $k$-interval bigraph compatible with these two orders. On the negative side we prove that, barring complexity collapses, no such extensions are possible for CSPs more general than satisfiability. We also show NP-hardness of recognizing 1-interval bigraphs.",2016-02-01,https://www.semanticscholar.org/paper/5b3c339a2c9a3ce11c34d119bcab940f6c56842d,International Symposium on Parameterized and Exact Computation
1504,Measurement of the tt̄ production cross section and top quark mass extraction using dilepton events in pp̄ collisions,Measurement of the t ¯ t production cross section and top quark mass extraction using dilepton events in p ¯ p collisions,,https://www.semanticscholar.org/paper/7a9e32fc81755228f82f557918c2ca48b23f291a,
1913,「工業工程與系統管理之回顧與展望」特刊：序言,,2018-07-01,https://www.semanticscholar.org/paper/a38f155d8722a7b301bc027864b985762fbe0451,
2610,Single-handed interaction techniques for multiple pressure-sensitive strips,"We present a set of interaction techniques that make novel use of a small pressure-sensitive pad to allow one-handed direct control of a large number of parameters. The surface of the pressure-sensitive pad is logically divided into four linear strips which simulate traditional interaction metaphors and the functions of which may be modified dynamically under software control. No homing of the hand or fingers in needed once the fingers are placed above their corresponding strips. We show how the number of strips on the pad can be virtually extended from four to fourteen by detecting contact pressure differences and dual-finger motions. Due to the compact size of the device and the method of interaction, which does not rely on on-screen widgets or the 2D navigation of a cursor, the versatile input system may be used in applications, where it is advantageous to minimize the amount of visual feedback required for interaction.",2004-04-24,https://www.semanticscholar.org/paper/dead52eeb4da3a06ee471de3b9dce7f763c1eda9,CHI EA '04
1855,Variational methods for the Dirichlet process,"Variational inference methods, including mean field methods and loopy belief propagation, have been widely used for approximate probabilistic inference in graphical models. While often less accurate than MCMC, variational methods provide a fast deterministic approximation to marginal and conditional probabilities. Such approximations can be particularly useful in high dimensional problems where sampling methods are too slow to be effective. A limitation of current methods, however, is that they are restricted to parametric probabilistic models. MCMC does not have such a limitation; indeed, MCMC samplers have been developed for the Dirichlet process (DP), a nonparametric distribution on distributions (Ferguson, 1973) that is the cornerstone of Bayesian nonparametric statistics (Escobar & West, 1995; Neal, 2000). In this paper, we develop a mean-field variational approach to approximate inference for the Dirichlet process, where the approximate posterior is based on the truncated stick-breaking construction (Ishwaran & James, 2001). We compare our approach to DP samplers for Gaussian DP mixture models.",2004-07-04,https://www.semanticscholar.org/paper/42fddb742959e80cefe3932475a3c2cad97cba8d,International Conference on Machine Learning
2358,Roleofmyeloperoxidase inintracellular and extracellular chemiluminescence ofneutrophils,,,https://www.semanticscholar.org/paper/67145bfac6d3a05bf6ac307dd53651b7ebeb59c6,
3074,Final Report: Migration Mechanisms for Large-scale Parallel Applications,"Process migration is the ability to transfer a process from one machine to another. It is a useful facility in distributed computing environments, especially as computing devices become more pervasive and Internet access becomes more ubiquitous. The potential benefits of process migration, among others, are fault resilience by migrating processes off of faulty hosts, data access locality by migrating processes closer to the data, better system response time by migrating processes closer to users, dynamic load balancing by migrating processes to less loaded hosts, and improved service availability and administration by migrating processes before host maintenance so that applications can continue to run with minimal downtime. Although process migration provides substantial potential benefits and many approaches have been considered, achieving transparent process migration functionality has been difficult in practice. To address this problem, our work has designed, implemented, and evaluated new and powerful transparent process checkpoint-restart and migration mechanisms for desktop, server, and parallel applications that operate across heterogeneous cluster and mobile computing environments. A key aspect of this work has been to introduce lightweight operating system virtualization to provide processes with private, virtual namespaces that decouple and isolate processes from dependencies on the host operating system instance. This decouplingmore » enables processes to be transparently checkpointed and migrated without modifying, recompiling, or relinking applications or the operating system. Building on this lightweight operating system virtualization approach, we have developed novel technologies that enable (1) coordinated, consistent checkpoint-restart and migration of multiple processes, (2) fast checkpointing of process and file system state to enable restart of multiple parallel execution environments and time travel, (3) process migration across heterogeneous software environments, (4) network checkpoint-restart and migration of distributed and parallel applications, (5) a utility computing infrastructure for mobile desktop cloud computing based on process checkpoint-restart and migration functionality, (6) a process migration security architecture for protecting applications and infrastructure from denial-of-service attacks, and (7) a checkpoint-restart mobile computing system using portable storage devices.« less",2009-10-30,https://www.semanticscholar.org/paper/8e65b20e39f645aae298680e107013329f2740c4,
3207,On assessing the importance of demographic change for social structure: A comment on Shizuka and Johnson,,2020-01-31,https://www.semanticscholar.org/paper/8d50f3d3df9aac61c8415cddb2d6a16675658e36,
1271,Search for production of single top quarks via tcg and tug flavor-changing-neutral-current couplings.,"We search for the production of single top quarks via flavor-changing-neutral-current couplings of a gluon to the top quark and a charm (c) or up (u) quark. We analyze 230 pb{-1} of lepton+jets data from pp[over] collisions at a center of mass energy of 1.96 TeV collected by the D0 detector at the Fermilab Tevatron Collider. We observe no significant deviation from standard model predictions, and hence set upper limits on the anomalous coupling parameters kappa{g}{c}/Lambda and kappa{g}{u}/Lambda, where kappa{g} define the strength of tcg and tug couplings, and Lambda defines the scale of new physics. The limits at 95% C.L. are kappa{g}{c}/Lambda<0.15 TeV-1 and kappa{g}{u}/Lambda<0.037 TeV-1.",2007-02-01,https://www.semanticscholar.org/paper/132fbf5732862878d37e61b258845f791b01aaed,Physical Review Letters
3522,An algorithm for minimum cuts,"A minimum cut is a set of edges of minimum weight whose removal disconnects a given graph. Minimum cut algorithms historically applied duality with maximum ows and thus had the same (mn) running time as maximum ow algorithms. More recent algorithms which are not based on maximum ows also require (mn) time. In this paper, we present the rst algorithm that breaks the (mn) \max-ow barrier"" for nding minimum cuts in weighted undirected graphs. We give a strongly polynomial randomized algorithm which nds a minimum cut with high probability in O(n 2 log 3 n) time. This suggests that the min-cut problem might be fundamentally easier to solve than the maximum ow problem. Our algorithm can be implemented in RNC using only n 2 processors|this is the rst eecient RNC algorithm for the min-cut problem. Our algorithm is simple and uses no complicated data structures.",,https://www.semanticscholar.org/paper/3271c7f71242e850f0b8bf9e3adfaa17d9dc34b8,Symposium on the Theory of Computing
999,Intraocular Pressure–lowering Efficacy of Dorzolamide/Timolol Fixed Combination in Normal-tension Glaucoma,"Purpose:To investigate the intraocular pressure (IOP)-lowering efficacy and safety of dorzolamide/timolol fixed combination (DTFC) in patients with normal-tension glaucoma (NTG). Methods:An open-label, 12-week, 2-center study was conducted. Thirty-seven patients with treatment-naïve NTG received DTFC for 12 weeks to reduce IOP. Primary outcome measures were changes in IOP from baseline to 12 weeks of treatment at a peak drug effect. Secondary outcome measures were changes in IOP from baseline to 12 weeks of treatment a trough drug effect and 8 hours after drug administration. At each visit, IOP was measured at 9 AM and then DTFC was administered by a hospital personnel. IOP was also measured at 11 AM and 5 PM At week 12, the IOP was measured at 1 and 3 PM as well. Results:The IOP at peak drug effect (11 AM) at 12 weeks was significantly reduced to 11.9±2.6 mm Hg from the baseline of 15.6±2.5 mm Hg (23.7%, P<0.0001). Significant reduction in the IOP was also achieved at trough drug effect (9 AM) and at 8 hours after drug administration (5 PM) at 12 weeks (20.5% and 24.4%, respectively, all P<0.0001). Eye irritation (59.5%) was the most frequently reported adverse event followed by ocular hyperemia (16.2%). The majority of eye irritations were mild in intensity. No patients discontinued the DTFC due to an adverse event and no systemic adverse event was considered related to study medication. Conclusions:DTFC is a safe and effective IOP-lowering agent in patients with NTG.",2014-06-01,https://www.semanticscholar.org/paper/8abfa2be7d692b2cfeaed755ca68488d73c1fb90,Journal of glaucoma
2546,Rubbing and tapping for precise and rapid selection on touch-screen displays,"We introduce two families of techniques, rubbing and tapping, that use zooming to make possible precise interaction on passive touch screens, and describe examples of each. Rub-Pointing uses a diagonal rubbing gesture to integrate pointing and zooming in a single-handed technique. In contrast, Zoom-Tapping is a two-handed technique in which the dominant hand points, while the non-dominant hand taps to zoom, simulating multi-touch functionality on a single-touch display. Rub-Tapping is a hybrid technique that integrates rubbing with the dominant hand to point and zoom, and tapping with the non-dominant hand to confirm selection. We describe the results of a formal user study comparing these techniques with each other and with the well-known Take-Off and Zoom-Pointing selection techniques. Rub-Pointing and Zoom-Tapping had significantly fewer errors than Take-Off for small targets, and were significantly faster than Take-Off and Zoom-Pointing. We show how the techniques can be used for fluid interaction in an image viewer and in Google Maps.",2008-04-06,https://www.semanticscholar.org/paper/94c0f6e243534886331b4c2f3cbeafa9cc224cc2,International Conference on Human Factors in Computing Systems
1242,Search for W' boson resonances decaying to a top quark and a bottom quark.,"We search for the production of a heavy W' gauge boson that decays to third generation quarks in 0.9 fb-1 of pp collisions at square root(s)=1.96 TeV, collected with the D0 detector at the Fermilab Tevatron collider. We find no significant excess in the final-state invariant mass distribution and set upper limits on the production cross section times branching fraction. For a left-handed W' boson with SM couplings, we set a lower mass limit of 731 GeV. For right-handed W' bosons, we set lower mass limits of 739 GeV if the W' boson decays to both leptons and quarks and 768 GeV if the W' boson decays only to quarks. We also set limits on the coupling of the W' boson to fermions as a function of its mass.",2008-03-01,https://www.semanticscholar.org/paper/9c2193299f46424b21113f68d2cbccb05ad90ff7,Physical Review Letters
2633,Augmented reality: a new way of seeing.,,2002-04-01,https://www.semanticscholar.org/paper/6fb18b3265a9697e8f88a80b8ab2890d5e253f56,Scientific American
1340,Search for neutral supersymmetric Higgs Bosons in multijet events at sqrt[s]=1.96 TeV.,"We have performed a search for neutral Higgs bosons produced in association with bottom quarks in pp collisions, using 260 pb-1 of data collected with the D0 detector in Run II of the Fermilab Tevatron Collider. The cross sections for these processes are enhanced in many extensions of the standard model (SM), such as in its minimal supersymmetric extension at large tanbeta. The results of our analysis agree with expectations from the SM, and we use our measurements to set upper limits on the production of neutral Higgs bosons in the mass range of 90 to 150 GeV.",2005-04-09,https://www.semanticscholar.org/paper/34eed6b775a121ae006f75c06bf4f04fc9f96cdf,Physical Review Letters
2439,Collaborative Virtual Reality for Low-Latency Interaction,"In collaborative virtual environments, users must often perform tasks requiring coordinated action between multiple parties. Some cases are symmetric, in which users work together on equal footing, while others are asymmetric, in which one user may have more experience or capabilities than another (e.g., one may guide another in completing a task). We present a multi-user virtual reality system that supports interactions of both these types. Two collaborating users, whether co-located or remote, simultaneously manipulate the same virtual objects in a physics simulation, in tasks that require low latency networking to perform successfully. We are currently applying this approach to motor rehabilitation, in which a therapist and patient work together.",2018-10-11,https://www.semanticscholar.org/paper/987cffb26eaf1941c142b3de9499c646a113b9cc,ACM Symposium on User Interface Software and Technology
2091,An AHP-based approach to ERP system selection,,2005-04-18,https://www.semanticscholar.org/paper/f633ae4f0b78c06a6faa44adf710004376eefa3d,
2984,Message Passing Algorithms for the Dirichlet Diffusion Tree,"We demonstrate efficient approximate inference for the Dirichlet Diffusion Tree (Neal, 2003), a Bayesian nonparametric prior over tree structures. Although DDTs provide a powerful and elegant approach for modeling hierarchies they haven’t seen much use to date. One problem is the computational cost of MCMC inference. We provide the first deterministic approximate inference methods for DDT models and show excellent performance compared to the MCMC alternative. We present message passing algorithms to approximate the Bayesian model evidence for a specific tree. This is used to drive sequential tree building and greedy search to find optimal tree structures, corresponding to hierarchical clusterings of the data. We demonstrate appropriate observation models for continuous and binary data. The empirical performance of our method is very close to the computationally expensive MCMC alternative on a density estimation problem, and significantly outperforms kernel density estimators.",,https://www.semanticscholar.org/paper/cf38d26d22c56ceda4779212ee11282716f4ef5f,International Conference on Machine Learning
2302,Expression of Fc gamma RIII in neutrophils in rheumatoid arthritis.,,1996-08-01,https://www.semanticscholar.org/paper/22521f6aea997d45b97e6240bddd570021479f24,Biochemical Society Transactions
546,On the Complexity of Circulations,,1986-03-01,https://www.semanticscholar.org/paper/1260f69b4f88e2229f5da07a21a7c48896ac7fef,J. Algorithms
79,Web Mining Meets Web Search,,,https://www.semanticscholar.org/paper/8f88b41d82d65165b3b98820358e86f0b0a505fc,Workshop on Research Issues on Data Mining and Knowledge Discovery
2166,An improved culture protocol for the differentiation and survival of human promyelocytic leukaemia PLB-985 cell-line into mature neutrophil-like granulocytes,"Circulating blood neutrophils are short-lived, lack proliferation capacity and cannot be transfected in vitro to express exogenous genes or proteins. These properties have made the ex vivo genetic manipulation of neutrophils challenging and hindered biochemical and molecular studies investigating the function of specific genes and proteins. Improved methodology for differentiating cell lines into mature neutrophil-like phenotypes, with similar morphological and functional properties to blood neutrophils would, therefore, be an important tool to probe the molecular properties of mature cells. The PLB-985 cell line was cultured in RPMI-1640 medium supplemented foetal calf serum (FCS) and penicillin/streptomycin. For induction of differentiation into neutrophil-like cells, the medium was supplemented with sodium pyruvate, N, N-dimethylformamide (DMF) and all-trans retinoic acid (ATRA), FCS and penicillin/streptomycin. The cytokines G-CSF and GM-CSF were used to enhance differentiation, prolong viability and delay the progression of the differentiated cells into apoptosis. The modified culture protocol and conditions induced PLB-985 cells to differentiate into mature, neutrophil-like granulocytes that resembled the morphology of mature blood neutrophils as evident by acquisition of a multi-lobed nucleus and granulated cytoplasm. These modified culture conditions resulted in enhanced differentiation into neutrophil-like cells and the apoptosis of these differentiated cells was delayed by supplementation with cytokines. This experimental system should be useful for studies probing the function of specific genes and proteins in human neutrophils.",2021-09-15,https://www.semanticscholar.org/paper/a2f93ffd8e961611d07328d25bc14dfc3cb66d65,bioRxiv
544,The theory of concurrency control,,,https://www.semanticscholar.org/paper/06bb0377de08908156fd02a11ae3325930e0bd2d,
2628,Session details: Session 2: environments,,2003-04-27,https://www.semanticscholar.org/paper/fb1973fc5e585a48bbf84804a206a68431198093,Proceedings of the 2003 symposium on Interactive 3D graphics
3749,Following Gaze in Video,"Following the gaze of people inside videos is an important signal for understanding people and their actions. In this paper, we present an approach for following gaze in video by predicting where a person (in the video) is looking even when the object is in a different frame. We collect VideoGaze, a new dataset which we use as a benchmark to both train and evaluate models. Given one frame with a person in it, our model estimates a density for gaze location in every frame and the probability that the person is looking in that particular frame. A key aspect of our approach is an end-to-end model that jointly estimates: saliency, gaze pose, and geometric relationships between views while only using gaze as supervision. Visualizations suggest that the model learns to internally solve these intermediate tasks automatically without additional supervision. Experiments show that our approach follows gaze in video better than existing approaches, enabling a richer understanding of human activities in video.",2017-10-01,https://www.semanticscholar.org/paper/241b86d3c71d14b8cc6044a425b047a0724cfdc9,IEEE International Conference on Computer Vision
2051,OR in the electronics industry,,2008-01-11,https://www.semanticscholar.org/paper/73877d51d9a8cdf0ae6eecdb4604368ed9353835,OR Spectr.
2481,The future is here: augmented and virtual reality (full text not available),,2014-07-27,https://www.semanticscholar.org/paper/aa182c7d95a877ca5ff9d3506f3b1283de718293,International Conference on Computer Graphics and Interactive Techniques
2897,Smoother: A Unified and Modular Framework for Incorporating Structural Dependency in Spatial Omics Data,"Spatial omics technologies can help identify spatially organized biological processes, but existing computational approaches often overlook structural dependencies in the data. Here, we introduce Smoother, a unified framework that integrates positional information into non-spatial models via modular priors and losses. In simulated and real datasets, Smoother enables accurate data imputation, cell-type deconvolution, and dimensionality reduction with remarkable efficiency. In colorectal cancer, Smoother-guided deconvolution revealed plasma cell and fibroblast subtype localizations linked to tumor microenvironment restructuring. Additionally, joint modeling of spatial and single-cell human prostate data with Smoother allowed for spatial mapping of reference populations with significantly reduced ambiguity.",2023-08-07,https://www.semanticscholar.org/paper/d9df5b93fc19eafb90a6809b6af4169676707b00,bioRxiv
2203,Human filarial Wolbachia lipopeptide directly activates human neutrophils in vitro,"The host inflammatory response to the Onchocerca volvulus endosymbiont, Wolbachia, is a major contributing factor in the development of chronic pathology in humans (onchocerciasis/river blindness). Recently, the toll‐like pattern recognition receptor motif of the major inflammatory ligands of filarial Wolbachia, membrane‐associated diacylated lipoproteins, was functionally defined in murine models of pathology, including mediation of neutrophil recruitment to the cornea. However, the extent to which human neutrophils can be activated in response to this Wolbachia pattern recognition motif is not known. Therefore, the responses of purified peripheral blood human neutrophils to a synthetic N‐terminal diacylated lipopeptide (WoLP) of filarial Wolbachia peptidoglycan‐associated lipoprotein (PAL) were characterized. WoLP exposure led to a dose‐dependent activation of healthy, human neutrophils that included gross morphological alterations and modulation of surface expressed integrins involved in tethering, rolling and extravasation. WoLP exposure induced chemotaxis but not chemokinesis of neutrophils, and secretion of the major neutrophil chemokine, interleukin 8. WoLP also induced and primed the respiratory burst, and enhanced neutrophil survival by delay of apoptosis. These results indicate that the major inflammatory motif of filarial Wolbachia lipoproteins directly activates human neutrophils in vitro and promotes a molecular pathway by which human neutrophils are recruited to sites of Onchocerca parasitism.",2014-09-17,https://www.semanticscholar.org/paper/116ba42b528ed8c60931bb022adc76a9bad77efc,Parasite immunology (Print)
1373,Installation and commissioning of the CDMSII experiment at Soudan,,2004-03-11,https://www.semanticscholar.org/paper/78b578479fe40b61e9d28620c9251971a561f604,
2231,Mcl‐1; the molecular regulation of protein function,,2010-07-16,https://www.semanticscholar.org/paper/8a94028104b1deb532ba9c56022072a0a672cfab,FEBS Letters
1587,The Blessings of Multiple Causes: Rejoinder,"We thank all the discussants for taking the time and energy to build on this work; and we thank the editors for putting together an engaging and thought-provoking collection of discussions. After reading these contributions, we were struck that these are not mere discussions—indeed, each is an article in itself. This collection pushes forward “The Blessings of Multiple Causes” in significant ways, offering new theory, new criticism, and new application. After highlighting some of the themes of these articles, we will turn to each individually. “The Blessings of Multiple Causes” provide assumptions, theory, and algorithms for multiple causal inference. The deconfounder algorithm involves modeling the causes, using the model to infer a substitute confounder, and then using the substitute confounder in a downstream causal inference. The deconfounder is not a black-box solution to causal inference. Rather, it is a way to use careful domain-specific modeling in the service of causal inference. Causal inference with the deconfounder involves a number of assumptions and trade-offs, and many of the discussants highlighted these. Among them are the following. (1) There can be no unobserved single-cause confounders. (2) When we apply the deconfounder, we trade an increase in estimation variance for a reduction in confounding bias; there is no free lunch. (3) We do not recommend using the deconfounder with causally dependent causes, such as a time series; finding a substitute confounder may be too difficult in these scenarios. There are many directions for further research, and the discussants have pointed out several of the most important ones. We need a more complete picture of identification; D’Amour (2019) and the discussions here make good progress (see Table1). We need to understand the finite-sample properties of the deconfounder, and how to estimate uncertainty about causal inferences when using a substitute multi-cause confounder. We need rigorous methods of model criticism for assessing the validity of the substitute confounder. Deconfounder-like methods have already been used for genome-wide association studies (e.g., Pritchard et al. 2000) and estimating peer effects in networks (Shalizi and McFowland III 2016). More broadly, the deconfounder strategy points to many applications, including in genetics, psychology, education, and marketing, where factor models are routinely fit to largescale data. We hope that statisticians and machine learners will",2019-10-02,https://www.semanticscholar.org/paper/faf9108b8698f34fe80abb5c996b4394611bbc53,Journal of the American Statistical Association
439,NP-Completeness: A Retrospective,,1997-07-07,https://www.semanticscholar.org/paper/ca6e78bc7b3e942750b2c52f00b13c1030d6e557,"International Colloquium on Automata, Languages and Programming"
631,The adjacency relation on the traveling salesman polytope is NP-Complete,,1978-12-01,https://www.semanticscholar.org/paper/2578271780622b98d9a9316e927781db3a1942ea,Mathematical programming
888,A Note on Succinct Representations of Graphs,,1986-12-01,https://www.semanticscholar.org/paper/087f7f09020cb5f65b990b9c7d6fca85b13f59c1,Information and Control
990,Changes of the Macular Ganglion Cell-Inner Plexiform Layer Thickness after Cataract Surgery in Glaucoma Patients,"Purpose. To investigate the effect of uneventful cataract surgery on macular ganglion cell-inner plexiform layer (mGC-IPL) thickness in glaucoma patients. Methods. This retrospective study included 65 eyes of 65 subjects who underwent uneventful cataract surgery, including 13 glaucoma eyes and 52 normal eyes. Using spectral domain optical coherence tomography, the mGC-IPL thickness was measured and compared between glaucoma and normal eyes preoperatively as well as 1 month and 3 months postoperatively. Linear regression analysis was used to determine the factors associated with postoperative change in mGC-IPL thickness. Results. The mean mGC-IPL significantly increased in both groups 1 month and 3 months after surgery (all P values equal to or less than 0.001). The postoperative changes between groups were not significantly different (P = 0.171). In the multivariate regression analysis, preoperative mGC-IPL thickness showed a significant association with the change of average mGC-IPL thickness 1 month and 3 months after surgery (all P values < 0.001). Conclusions. The mean mGC-IPL thickness was increased after cataract surgery, and the postoperative mGC-IPL thickness changes were associated with preoperative mGC-IPL thickness in both groups and axial length in normal eye. The effects of cataract surgery on mean mGC-IPL thickness were not different in glaucomatous and normal eyes.",2016-12-22,https://www.semanticscholar.org/paper/4d2ad8e492e956c192fa837d62faa11fc3de336d,Journal of Ophthalmology
2287,Apoptosis is rapidly triggered by antisense depletion of MCL-1 in differentiating U937 cells.,"Mcl-1 is a member of the Bcl-2 protein family, which has been shown to delay apoptosis in transfection and/or overexpression experiments. As yet no gene knockout mice have been engineered, and so there is little evidence to show that loss of Mcl-1 expression is sufficient to trigger apoptosis. U937 cells constitutively express the antiapoptotic protein Bcl-2; but during differentiation, in response to the phorbol ester PMA (phorbol 12 beta-myristate 13 alpha-acetate), Mcl-1 is transiently induced. The purpose of this investigation was to determine the functional role played by Mcl-1 in this differentiation program. Mcl-1 expression was specifically disrupted by chimeric methylphosphonate/phosphodiester antisense oligodeoxynucleotides to just 5% of control levels. The depletion of Mcl-1 messenger RNA (mRNA) and protein was both rapid and specific, as indicated by the use of control oligodeoxynucleotides and analysis of the expression of other BCL2 family members and PMA-induced tumor necrosis factor-alpha (TNF-alpha). Specific depletion of Mcl-1 mRNA and protein, in the absence of changes in cellular levels of Bcl-2, results in a rapid entry into apoptosis. Levels of the proapoptotic protein Bax remained unchanged during differentiation, while Bak expression doubled within 24 hours. Apoptosis was detected within 4 hours of Mcl-1 antisense treatment by a variety of parameters including a novel live cell imaging technique allowing correlation of antisense treatment and apoptosis in individual cells. The induction of Mcl-1 is required to prevent apoptosis during differentiation of U937 cells, and the constitutive expression of Bcl-2 is unable to compensate for the loss of Mcl-1. (Blood. 2000;96:1756-1763)",2000-09-01,https://www.semanticscholar.org/paper/7ec2e261e337b086d8089fb39d5712893294c9f0,Blood
3323,Is there always an influence of shoal size on predator hunting success,"Theoretical and empirical studies predict that there should be a decrease in hunting success of predators with increasing prey group size. Most of these studies investigated situations in which predator and prey were in full view of each other before, during and after an attack. In this study, single rock bass Ambloplites rupestris were given an opportunity to launch surprise attacks at shoals of creek chub Semotilus atromaculatus that ranged in size from two to 13 fish. There was no significant influence of either shoal size or attack distance on predator success rate and no significant relationship between attack distance and shoal size. Furthermore, it was found that the leading fish of a shoal was attacked significantly more often than fish in other shoal positions, indicating that predation risk was not shared equally among shoal members. Also, leading fish in larger shoals (eight to 13 fish) were not more likely to survive a predator attack than ones in small shoals (two to seven fish). The consequences of these results are discussed in the general context of antipredator benefits of grouping. ? 1998 The Fisheries Society of the British Isles",1998-03-01,https://www.semanticscholar.org/paper/c4e2534c8714e4d3d8d11e4a5d891112109657b1,
1050,"Constraints on low-mass, relic dark matter candidates from a surface-operated SuperCDMS single-charge sensitive detector","This article presents an analysis and the resulting limits on light dark matter inelastically scattering off of electrons, and on dark photon and axion-like particle absorption, using a second-generation SuperCDMS high-voltage eV-resolution detector. The 0.93 gram Si detector achieved a 3 eV phonon energy resolution; for a detector bias of 100 V, this corresponds to a charge resolution of 3% of a single electron-hole pair. The energy spectrum is reported from a blind analysis with 1.2 gram-days of exposure acquired in an above-ground laboratory. With charge carrier trapping and impact ionization effects incorporated into the dark matter signal models, the dark matter-electron cross section $\bar{\sigma}_{e}$ is constrained for dark matter masses from 0.5--$10^{4} $MeV$/c^{2}$; in the mass range from 1.2--50 eV$/c^{2}$ the dark photon kinetic mixing parameter $\varepsilon$ and the axioelectric coupling constant $g_{ae}$ are constrained. The minimum 90% confidence-level upper limits within the above mentioned mass ranges are $\bar{\sigma}_{e}\,=\,8.7\times10^{-34}$ cm$^{2}$, $\varepsilon\,=\,3.3\times10^{-14}$, and $g_{ae}\,=\,1.0\times10^{-9}$.",2020-05-28,https://www.semanticscholar.org/paper/43dfcef1f5c45674aeceab7f4300b05d3844e3ab,Physical Review D
3214,Reciprocity and rotating social advantage among females in egalitarian primate societies,,2019-11-01,https://www.semanticscholar.org/paper/0ff2cb4b1efb2e211a76952cedbe1b5d18ce8443,Animal Behaviour
1233,Measurement of the Polarization of the ð 1 S Þ and ð 2 S Þ States in p p Collisions at ffiffi s p 1⁄4 1 : 96 TeV,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, S. H. Ahn, M. Ahsan, G.D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G.A. Alves, M. Anastasoaie, L. S. Ancu, T. Andeen, S. Anderson, B. Andrieu, M. S. Anzelc, M. Aoki, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, A. C. S. Assis Jesus, O. Atramentov, C. Avila, F. Badaud, A. Baden, L. Bagby, B. Baldin, D. V. Bandurin, P. Banerjee, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V.A. Bezzubov, P. C. Bhat, V. Bhatnagar, C. Biscarat, G. Blazey, F. Blekman, S. Blessing, D. Bloch, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, E. E. Boos, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, S. Burke, T. H. Burnett, C. P. Buszello, J.M. Butler, P. Calfayan, S. Calvet, J. Cammin, W. Carvalho, B. C. K. Casey, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K. Chan, K.M. Chan, A. Chandra, F. Charles,** E. Cheu, F. Chevallier, D. K. Cho, S. Choi, B. Choudhary, L. Christofek, T. Christoudias, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, D. Cutts, M. Ćwiok, H. da Motta, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, J. D. Degenhardt, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, H. Dong, L. V. Dudko, L. Duflot, S. R. Dugad, D. Duggan, A. Duperrin, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V. D. Elvira, Y. Enari, S. Eno, P. Ermolov, H. Evans, A. Evdokimov, V.N. Evdokimov, A.V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, E. Gallas, C. Garcia, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, D. Gelé, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, N. Gollub, B. Gómez, A. Goussiou, P. D. Grannis, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Harder, A. Harel, J.M. Hauptman, R. Hauser, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, A. P. Heinson, U. Heintz, C. Hensel,22,x K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, J. D. Hobbs, B. Hoeneisen, H. Hoeth, M. Hohlfeld, S. J. Hong, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, C. Jarvis, R. Jesik, K. Johns, C. Johnson, M. Johnson, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, J.M. Kalk, D. Karmanov, P. A. Kasper, I. Katsanos, D. Kau, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y.M. Kharzheev, D. Khatidze, T. J. Kim, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, J.-P. Konrath, A. V. Kozelov, J. Kraus, D. Krop, T. Kuhl, A. Kumar, A. Kupco, T. Kurča, V. A. Kuzmin, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, W.M. Lee, A. Leflat, J. Lellouch, J. Leveque, J. Li, L. Li, Q. Z. Li, S.M. Lietti, J. G. R. Lima, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna, A. L. Lyon, A. K.A. Maciel, D. Mackin, R. J. Madaras, P. Mättig, C. Magass, A. Magerkurth, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, H. S. Mao, Y. Maravin, B. Martin, R. McCarthy, A. Melnitchouk, L. Mendoza, P. G. Mercadante, M. Merkin, K.W. Merritt, A. Meyer, J. Meyer,22,x T. Millet, J. Mitrevski, R. K. Mommsen, N.K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, N. A. Naumann, H.A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, V. O’Dell, D. C. O’Neil, G. Obrant, C. Ochando, D. Onoprienko, N. Oshima, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park,22,x S.K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, M. Petteni, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma, V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, B.G. Pope, A.V. Popov, C. Potter, W. L. Prado da Silva, H. B. Prosper, S. Protopopescu, J. Qian, A. Quadt,22,x B. Quinn, A. Rakitine, M. S. Rangel, K. Ranjan, P. N. Ratoff, P. Renkel, S. Reucroft, P. Rich, J. Rieger, M. Rijssenbeek, I. Ripp-Baudot, F. Rizatdinova, S. Robinson, R. F. Rodrigues, PRL 101, 182004 (2008) P HY S I CA L R EV I EW LE T T E R S week ending 31 OCTOBER 2008",,https://www.semanticscholar.org/paper/8232c2db1dfc85d6a85bc47bc6d50eb86ca838a2,
2659,Automated generation of visual discourse,"Visual presentations can help us understand information better. However, handcrafting customized, effective visual presentations requires much skill, time and effort. To present information in a timely, customized manner, we develop comprehensive and systematic methodologies to automate the visual design process. In particular, we focus on automatically creating coherent, versatile, and interactive visual discourse. We use the term visual discourse to refer to a series of connected visual displays, of which a single display or a series of static displays may be considered as special cases. A coherent visual discourse has smooth transitions between displays, consistent designs within and among displays, and effective visual unification among various components. A versatile visual discourse is capable of representing a wide range of information through different visual media and visual techniques. An interactive visual discourse encourages and supports user interactivity. 
This thesis addresses a set of research issues vital to the creation of coherent, versatile, and interactive visual discourse. We describe how to characterize presentation data, model presentation context, and classify presentation tasks. To equip presentation systems with visual design knowledge, we discuss the design and formal representation of a presentation design language, which covers a wide variety of visual patterns, visual techniques, and visual design principles at multiple levels of abstraction. We also present a powerful and efficient inferencing paradigm to reason about various conditions and infer a visual design. To demonstrate the coverage and utility of our research, we describe the design and implementation of a system called IMPROVISE (Illustrative Metaphor PROduction in VISual Environments). We have used IMPROVISE to automatically create coherent visual presentations in two different domains. In one domain, IMPROVISE is used as a stand-alone system for a computer network management application to provide users with cohesive visual explanations about network structures and behaviors. IMPROVISE is also employed as a graphics generation component in a collaborative effort with Columbia's Natural Language Processing group and Knowledge Representation group to produce multimedia summaries of patient medical records, containing coordinated text, speech, and graphics.",,https://www.semanticscholar.org/paper/1c4306a424647dc139f46827a9ff3a2978fe5b55,
2240,Neutrophil cytoskeletal abnormalities in systemic sclerosis.,,,https://www.semanticscholar.org/paper/3b91b881e956c534f9dbf161c903730780ab6088,
2823,The bone marrow compartment is modified in the absence of galectin-3,,2011-11-27,https://www.semanticscholar.org/paper/9f731e6e25016bd5fa095af39d612128337bfff6,Cell and Tissue Research
336,Turing's Test,"Our hero is Turing, an interactive tutoring program and namesake (or virtual emanation?) of Alan Turing, World War II code breaker and father of computer science. In this unusual novel, Turing's idiosyncratic version of intellectual history from a computational point of view unfolds in tandem with the story of a love affair involving Ethel, a successful computer executive, Alexandros, a melancholy archaeologist, and Ian, a charismatic hacker. After Ethel (who shares her first name with Alan Turing's mother) abandons Alexandros following a sundrenched idyll on Corfu, Turing appears on Alexandros's computer screen to unfurl a tutorial on the history of ideas. He begins with the philosopher-mathematicians of ancient Greece -- ""discourse, dialogue, argument, proof... can only thrive in an egalitarian society"" -- and the Arab scholar in ninth-century Baghdad who invented algorithms; he moves on to many other topics, including cryptography and artificial intelligence, even economics and developmental biology. (These lessons are later critiqued amusingly and developed further in postings by a fictional newsgroup in the book's afterword.) As Turing's lectures progress, the lives of Alexandros, Ethel, and Ian converge in dramatic fashion, and the story takes us from Corfu to Hong Kong, from Athens to San Francisco -- and of course to the Internet, the disruptive technological and social force that emerges as the main locale and protagonist of the novel.Alternately pedagogical and romantic, Turing (A Novel about Computation) should appeal both to students and professionals who want a clear and entertaining account of the development of computation and to the general reader who enjoys novels of ideas.",,https://www.semanticscholar.org/paper/a7dc1e6dc004062980ab1b74db1119637da03baa,
1293,Search for W' bosons decaying to an electron and a neutrino with the D0 detector.,"This Letter describes the search for a new heavy charged gauge boson W' decaying into an electron and a neutrino. The data were collected with the D0 detector at the Fermilab Tevatron pp[over] Collider at sqrt[s]=1.96 TeV, and correspond to an integrated luminosity of about 1 fb(-1). Lacking any significant excess in the data in comparison with known processes, an upper limit is set on sigma_(W') x B(W')-->e nu), and a W' boson with mass below 1.00 TeV can be excluded at the 95% C.L., assuming standard-model-like couplings to fermions. This result significantly improves upon previous limits and is the most stringent to date.",2007-10-16,https://www.semanticscholar.org/paper/d4101c2c9c065dadd401b7c76bfd3243036feefc,Physical Review Letters
3344,Social Evolution.Robert Trivers,,1986-03-01,https://www.semanticscholar.org/paper/9b6b1fa9aa298dc15eb8c66f78e0320c86e1aa90,
1447,BaBar technical design report,,,https://www.semanticscholar.org/paper/875340d3bc77a2f669c29108709d6e70b3782f39,
309,"Discrete Algorithms for Mobile and Wireless Networks Lecture 8 Part B : Thursday , 8 th February 2007 Instructor : Soma Chaudhuri Scribe : Puviyarasan Pandian 1 Lecture topic","In the last lecture, we discussed Reference Broadcast Synchronization, a mechanism which addresses the problem of energy-frugal μ-second precision time synchronization. The method involved synchronization between receivers based on the arrival time of a reference broadcast. The algorithm was extended to work on multiple domains as well, where nodes not in the same broadcast domain achieve this by performing a chain of pairwise synchronizations.",,https://www.semanticscholar.org/paper/97a2d632ac77386e07726b8e26aec5b2ff4fc77c,
3210,"Anthropogenic injuries disrupt social associations of common bottlenose dolphins (
 
 Tursiops truncatus
 )
 
 in Sarasota Bay, Florida",,2020-08-24,https://www.semanticscholar.org/paper/cfaf57a6351ca324151439809009c93d51f136d1,
3027,Hardware and Software Support for Virtualization,"This book focuses on the core question of the necessary architectural support provided by hardware to efficiently run virtual machines, and of the corresponding design of the hypervisors that run them. Virtualization is still possible when the instruction set architecture lacks such support, but the hypervisor remains more complex and must rely on additional techniques. Despite the focus on architectural support in current architectures, some historical perspective is necessary to appropriately frame the problem. The first half of the book provides the historical perspective of the theoretical framework developed four decades ago by Popek and Goldberg. It also describes earlier systems that enabled virtualization despite the lack of architectural support in hardware. As is often the case, theory defines a necessary-but not sufficient-set of features, and modern architectures are the result of the combination of the theoretical framework with insights derived from practical systems. The second half of the book describes state-of-the-art support for virtualization in both x86-64 and ARM processors. This book includes an in-depth description of the CPU, memory, and I/O virtualization of these two processor architectures, as well as case studies on the Linux/KVM, VMware, and Xen hypervisors. It concludes with a performance comparison of virtualization on current-generation x86- and ARM-based systems across multiple hypervisors.",2017-02-21,https://www.semanticscholar.org/paper/79d0d56f06beb438366a503078cf0aa4b8c94396,Synthesis Lectures on Computer Architecture
1743,Hierarchical bayesian modeling: efficient inference and applications,"Appropriate tools for managing large-scale data, like online texts, images and user profiles, are becoming increasingly important. Hierarchical Bayesian models provide a natural framework for building these tools due to their flexibility in modeling real-world data. In this thesis, we describe a suite of efficient inference algorithms and novel models under the hierarchical Bayesian modeling framework. 
We first present a novel online inference algorithm for the hierarchical Dirichlet process. The hierarchical Dirichlet process (HDP) is a Bayesian nonparametric model that can be used to model mixed-membership data with a potentially infinite number of components. Our online variational inference algorithm is easily applicable to massive and streaming data and significantly faster than traditional inference algorithms. 
Second, we present a generic approximation framework for variational inference in a large family of nonconjugate models. For example, this includes multi-level logistic regression/generalized linear models and correlated topic models. With this, developing variational inference algorithm for many nonconjugate models is much easier. 
Finally, we describe two novel models for real-world applications. This first application is about simultaneous image classification and annotation. We show that image classification and annotation can be integrated together using the same underlying probabilistic model. The second application is to better disseminate scientific information using recommendations. Compared with traditional recommendation algorithms, our algorithm not only improves the recommendation accuracy, but also provides interpretable structure of users and scientific articles. This interpretability provides lots of potential for designing better recommender systems.",,https://www.semanticscholar.org/paper/0a8f089741ef2785dd02e6d8ca48c023e322a025,
3266,The launch of Environmental Research Reviews,"In this issue we are excited to launch a new section entitled Environmental Research Reviews (ERR). These aremeant to be topical and evidence-based. The aim is to provide reviews of the environmental literature in key areas that are changing so quickly that it is hard for all but the specialists in these areas to keep up. Taken together, Environmental Research Letters (ERL) and ERR provide a unique set of venues to present both advances in our understanding of environmental issues, and to review, synthesize and disseminate our knowledge base about the changing natural world. ERR will appear initially as a section within ERL, but one with its own dedicated Editorial Board and Reviews Editor, utilising a format that provides depth and background into the topic under review, as well as a unique forum to synthesize and to draw evidencebased assessments and evaluations of keyfields. The first three such reviews appearing in this issue of ERL all focus on climate change through a variety of methodological approaches, and highlight the rich diversity of approaches possible to make sense of anthropogenic climate change as well as mitigation and adaptation strategies. Goetz and colleagues (1) use a traditional ‘expert knowledge’ based approach for collecting key articles on the new technologies that are being employed to measure and monitor reductions of greenhouse gas emissions from degraded and deforested lands under REDD+. As experts, the authors assembled a collection of key articles that they and their colleagues knew best and concurred were of exceptional quality. By using key words they expanded their collection of articles by searching the Google Scholar and Web of Science databases. By emphasizing synthetic papers and those that provide information on uncertainty and error, the authors’ comprehensive, systematic and step by step review concludes that current technologies are capable of providing measurable and verifiable levels of forest cover and biomass density in relation to baselines, but not yet with respect to biodiversity. Giupponi and Biscaro (2) take a different approach to reviewing how the concept of ‘vulnerability’ in the climate change literature has changed as the field has matured. They too used a variety of key words to search the Web of Science for articles on climate change adaptation and disaster risk, but their focus was more on the dynamics of the scientific enterprise then the science itself. In order to study the dynamics of vulnerability to climate change, they analyzed the literature in terms of its bibliographic history. In doing so they show that two communities developed at the outset with distinct research foci and agendas. By using social network analysis, however, they delved into the historical dynamics of these communities and uncovered the fact that authors in each area were connected to authors in the other areas. This awareness and the fact that United Nations documents, which initially helped define area-separating vocabularies, have recently begun reconciling differences in vocabulary. As Giupponi’s and Biscaro’s bibliographic analysis strikingly shows, this deliberate attempt at harmonizing language is having a dramatic impact on closing the knowledge gap between those communities. In the third review, Bunch and Ford (3) explore the extent to which issues of adaptation, resilience and vulnerability to climate change are connected to gender in non-tokenistic ways. As in the previous study, the search for gender-focused articles relied on searching digital databases, in this case the Web of Science and Scopus. Over 1000 articles were identified, but in the end only 123 met the criteria of having a ‘substantive’ focus on gender. Bunch and Ford developed a conceptual model that ranked the importance of climate change on different genders and the different gender impacts on adaptation and vulnerability. Their review highlights both the differential impacts of climate change on gender and also how much variation exists among geographic areas, with the highest levels being seen in research in Sub-Saharan Africa, and type of study. They also show that these increasing trends are stronger for adaptation as opposed to vulnerability research and that gendered studies tend to focus more onwomen thanmen. While each review focuses on a different aspect of the process and outcome of climate change OPEN ACCESS",2015-12-22,https://www.semanticscholar.org/paper/fe57dfab112f80e19890d19ff2e78f39c52cde43,
2754,Coordinating Text and Graphics in Explanation Generation,"To generate multimedia explanations, a system must be able to coordinate the use of different media in a single explanation. In this paper, we present the architecture that we have developed for COMET (COordinated Multimedia Explanation Testbed), a system that generates directions for equipment maintenance and repair, and we show how it addresses the coordination problem. COMET includes a single content planner that produces a common content description used by multiple media-specific generators, and a media coordinator that performs a fine-grained division of information among media. Bidirectional interaction between media-specific generators allows influence across media. We describe COMET's current capabilities and provide an overview of our plans for extending the system.",1989-10-15,https://www.semanticscholar.org/paper/6ec283b2928292ba8175346e489accded8e758ac,Human Language Technology - The Baltic Perspectiv
3470,Improved bicriteria existence theorems for scheduling,"Two common objectives for evaluating a schedule are the makespan, or schedule length, and the average completion time. In this note, we give improved bounds on the existence of schedules that simultaneously optimize both criteria. In a scheduling problem, we are given n jobs and m machines. With each job j we associate a nonnegative weight wj . A schedule is an assignment of jobs to machines over time, and yields a completion time Cj for each job j. We then define the average completion time as ∑n j=1 wjCj and the makespan as Cmax = maxj Cj . We use C opt max and ∑ wjC ∗ j to denote the optimal makespan and average completion time. We will give results which will hold for a wide variety of combinatorial scheduling problems. In particular, we require that valid schedules for the problem satisfy two very general conditions. First, if we take a valid schedule S and remove from it all jobs that complete after time t, the schedule remains a valid schedule for those jobs that remain. Second, given two valid schedules S1 and S2 for two sets J1 and J2 of jobs (where J1 ∩ J2 is potentially nonempty), the composition of S1 and S2, obtained by appending S2 to the end of S1, and removing from S2 all jobs that are in J1 ∩ J2, is a valid schedule for J1 ∪ J2. For the rest of this note we will make claims about “any” scheduling problem, and mean any problem that satisfies the two conditions above. In addition, if a schedule has Cmax ≤ αC opt max and ∑",2002-05-09,https://www.semanticscholar.org/paper/d33a63896f497e5f9d4bb23b59a22ec4f2a343f8,ACM-SIAM Symposium on Discrete Algorithms
1845,TagLDA: Bringing a document structure knowledge into topic models,"Latent Dirichlet Allocation models a document by a mixture of topics, where each topic itself is typically modeled by a unigram word distribution. Documents however often have known structures, and the same topic can exhibit dif ferent word distributions under different parts of the structure. We extend laten t Dirichlet allocation model by replacing the unigram word distributions with a factored r epresentation conditioned on both the topic and the structure. In the resultant m odel each topic is equivalent to a set of unigrams, reflecting the structure a wo rd is in. The proposed model is more flexible in modeling the corpus. The factore d representation prevents combinatorial explosion and leads to efficient parame terization. We derive the variational optimization algorithm for the new model. The mode l shows improved perplexity on text and image data, but not significant ac cur y improvement when used for classification.",,https://www.semanticscholar.org/paper/92da26eff6632a343ddd613a4c34ec96c5bc40ee,
1308,Model-independent measurement of the W-boson helicity in top-quark decays at D0.,"We present the first model-independent measurement of the helicity of W bosons produced in top quark decays, based on a 1 fb(-1) sample of candidate tt events in the dilepton and lepton plus jets channels collected by the D0 detector at the Fermilab Tevatron pp Collider. We reconstruct the angle theta(*) between the momenta of the down-type fermion and the top quark in the W boson rest frame for each top quark decay. A fit of the resulting costheta(*) distribution finds that the fraction of longitudinal W bosons f(0)=0.425+/-0.166(stat)+/-0.102(syst) and the fraction of right-handed W bosons f(+)=0.119+/-0.090(stat)+/-0.053(syst), which is consistent at the 30% C.L. with the standard model.",2006-09-25,https://www.semanticscholar.org/paper/37657f98230b68262164dee86e6d7c8fb01ae6e1,Physical Review Letters
505,On selecting a satisfying truth assignment,"The complexity of certain natural generalizations of satisfiability, in which one of the possibly exponentially many satisfying truth assignments must be selected, is studied. Two natural selection criteria, default preference and minimality (circumscription), are considered. The thrust of the complexity results seems to be that hard problems become harder, while easy problems remain easy. This consideration yields as a byproduct a new and very natural polynomial-time randomized algorithm for 2SAT.<<ETX>>",1991-09-01,https://www.semanticscholar.org/paper/d32b2afda59dba352be0811c5eaef03566408fc2,[1991] Proceedings 32nd Annual Symposium of Foundations of Computer Science
1522,Transport Score Climbing: Variational Inference Using Forward KL and Adaptive Neural Transport,"Variational inference often minimizes the""reverse""Kullbeck-Leibler (KL) KL(q||p) from the approximate distribution q to the posterior p. Recent work studies the""forward""KL KL(p||q), which unlike reverse KL does not lead to variational approximations that underestimate uncertainty. This paper introduces Transport Score Climbing (TSC), a method that optimizes KL(p||q) by using Hamiltonian Monte Carlo (HMC) and a novel adaptive transport map. The transport map improves the trajectory of HMC by acting as a change of variable between the latent variable space and a warped space. TSC uses HMC samples to dynamically train the transport map while optimizing KL(p||q). TSC leverages synergies, where better transport maps lead to better HMC sampling, which then leads to better transport maps. We demonstrate TSC on synthetic and real data. We find that TSC achieves competitive performance when training variational autoencoders on large-scale data.",2022-02-03,https://www.semanticscholar.org/paper/5de7813ce5bc9f361f2b6fd09f884b468dcb43bf,arXiv.org
3663,C++ Programming Language,"From the Publisher: 
Written by Bjarne Stroustrup, the creator of C, this is the world's most trusted and widely read book on C. 
 
For this special hardcover edition, two new appendixes on locales and standard library exception safety have been added. The result is complete, authoritative coverage of the C language, its standard library, and key design techniques. Based on the ANSI/ISO C standard, The C Programming Language provides current and comprehensive coverage of all C language features and standard library components. 
 
For example: 
abstract classes as interfaces class hierarchies for object-oriented programming templates as the basis for type-safe generic software exceptions for regular error handling namespaces for modularity in large-scale software run-time type identification for loosely coupled systems the C subset of C for C compatibility and system-level work standard containers and algorithms standard strings, I/O streams, and numerics C compatibility, internationalization, and exception safety 
Bjarne Stroustrup makes C even more accessible to those new to the language, while adding advanced information and techniques that even expert C programmers will find invaluable.",,https://www.semanticscholar.org/paper/c04e29b09f67158e7c4405ddad18108a1ddecbd4,IEEE Software
1108,Working Group Report: Dark Matter Complementarity,,2013-10-31,https://www.semanticscholar.org/paper/b9dfc10ddffeadaf13b58bb28eef92317cf4d8b6,
970,Primary Open-angle Glaucoma and Increased Risk of Chronic Kidney Disease,"Supplemental Digital Content is available in the text. Precis: The association between primary open-angle glaucoma (POAG) and subsequent development of chronic kidney disease (CKD) was investigated using a nationwide, population-based, retrospective cohort in South Korea. POAG increases the risk of subsequent CKD development. Purpose: The purpose of this study was to investigate the risk of subsequent CKD development in patients with POAG. Methods: In this nationwide, population-based longitudinal cohort, 1,025,340 beneficiaries in the 2002-2013 Korean National Health Insurance database were included. We identified patients with incident POAG and evaluated the risk of subsequent CKD development using diagnostic codes from the database after 2-year wash-out periods. We applied time-varying covariate Cox regression analyses to determine the effect of POAG on the development of CKD: Model 1 included only POAG as a time-varying covariate; Model 2 included Model 1 and demographic information; and Model 3 included Model 2, comorbidity, comedication, and the Charlson Comorbidity Index score. Results: The fixed cohort included 478,303 eligible subjects, and of these subjects, 1749 suffered incident POAG, and 3157 developed CKD. POAG was associated with an increased risk of CKD development [hazard ratio (HR)=7.63; 95% confidence interval (CI), 5.89-9.87] in Model 1; HR=3.54 (95% CI, 2.73-4.58) in Model 2; and HR=2.90 (95% CI, 2.24-3.76) in Model 3]. Conclusion: POAG increased the risk of subsequent CKD in the general population, suggesting that POAG and CKD might share a common pathogenic mechanism.",2019-10-17,https://www.semanticscholar.org/paper/0f498f31899832a3189f86380bbaf7e1cc11554e,Journal of glaucoma
248,Continuous local search,"We introduce CLS, for continuous local search, a class of polynomial-time checkable total functions that lies at the intersection of PPAD and PLS, and captures a particularly benign kind of local optimization in which the domain is continuous, as opposed to combinatorial, and the functions involved are continuous. We show that this class contains several well known intriguing problems which were heretofore known to lie in the intersection of PLS and PPAD but were otherwise unclassifiable: Finding fixpoints of contraction maps, the linear complementarity problem for P matrices, finding a stationary point of a low-degree polynomial objective, the simple stochastic games of Shapley and Condon, and finding a mixed Nash equilibrium in congestion, implicit congestion, and network coordination games. The last four problems belong to CCLS, for convex CLS, another subclass of PPAD ∩ PLS seeking the componentwise local minimum of a componentwise convex function. It is open whether any or all of these problems are complete for the corresponding classes.",2011-01-23,https://www.semanticscholar.org/paper/0422dfac6623506a8b6980e51224982a1c720b7e,ACM-SIAM Symposium on Discrete Algorithms
2690,UIST'007: Where Will We Be Ten Years from Now? (Panel).,,,https://www.semanticscholar.org/paper/f7cc8b8c723ac9c0e63d1f5a382ff5cfcf731204,
2667,Mixed reality: where real and virtual worlds meet,,1999-07-01,https://www.semanticscholar.org/paper/cce8aa4a8991fb249d2a2698ef7ae80a6f24437f,International Conference on Computer Graphics and Interactive Techniques
629,The serializability of concurrent database updates,"A sequence of interleaved user transactions in a database system may not be ser:ahzable, t e, equivalent to some sequential execution of the individual transactions Using a simple transaction model, it ~s shown that recognizing the transaction histories that are serlahzable is an NP-complete problem. Several efficiently recognizable subclasses of the class of senahzable histories are therefore introduced; most of these subclasses correspond to senahzabdity principles existing in the hterature and used in practice Two new principles that subsume all previously known ones are also proposed Necessary and sufficient conditions are given for a class of histories to be the output of an efficient history scheduler, these conditions imply that there can be no efficient scheduler that outputs all of senahzable histories, and also that all subclasses of senalizable histories studied above have an efficient scheduler Finally, it is shown how these results can be extended to far more general transaction models, to transactions with partly interpreted functions, and to distributed database systems",1979-10-01,https://www.semanticscholar.org/paper/e7ab23d011e5183db78cfea48e303210f6e57e2e,JACM
2232,SYSTEMIC SCLEROSIS SERUM INCREASES ENDOTHELIAL CELL APOPTOSIS AND ACTIVATION IN NEUTROPHIL-ENDOTHELIAL CELL CO-CULTURES: A ROLE FOR INTERLEUKIN 6,,,https://www.semanticscholar.org/paper/8f686580072fc0f68c0aa1a77adf28e1e95ddfe4,
2220,Oral abstracts 7: Molecular mechanisms of disease—osteoarthritisS1. Identification of novel osteoarthritis genes using zebrafish,,2012-05-01,https://www.semanticscholar.org/paper/18232a7dd9672caab2d86ec71627696f9177e59b,
3377,Learning-Augmented Online Packet Scheduling with Deadlines,"The modern network aims to prioritize critical traffic over non-critical traffic and effectively manage traffic flow. This necessitates proper buffer management to prevent the loss of crucial traffic while minimizing the impact on non-critical traffic. Therefore, the algorithm's objective is to control which packets to transmit and which to discard at each step. In this study, we initiate the learning-augmented online packet scheduling with deadlines and provide a novel algorithmic framework to cope with the prediction. We show that when the prediction error is small, our algorithm improves the competitive ratio while still maintaining a bounded competitive ratio, regardless of the prediction error.",2023-05-11,https://www.semanticscholar.org/paper/60ae6a3626b3150bb0a80ead1062c5b314585a5d,arXiv.org
249,5 Preliminary Simulation Results,"Sensor-based motion planning in three dimensions for a highly redundant snake robot. Advanced robotics, 9:255{280, 1995. 13] E. Rimon and J. F. Canny. Construction of c-space raodmaps from local sensory data. what should the sensors look for ? In IEEE Conference on Robotics and Automation, pages 117{123, 1994. 14] A. Sankaranarayanan and M. Vidyasagar. Path planning for moving a point object amidst unknown obstacles in a plane: the universal lower bound on worst case path lengths and a classiication of algorithms. Figure 10: In this example the locally optimal path from S diiers from the globally shortest one, because it is based only on the visible obstacles. degrees of freedom robots. For example, for planning the three-dimensional trajectory of an end-eeector or a sensing device mounted on a manipulator arm. References 1] J. F. Canny. The complexity of robot motion planning. A new range-sensor based globally convergent navigation algorithm for mobile robots. Vision guided exploration: a step toward general motion planning in three dimensions. In IEEE Conference on Robotics and Automation, pages 289{296, 1993. 7] V. J. Lumelsky. A comparative study on the path length performance of maze-searching and robot motion planning algorithms. Figure 9: A simple simulation example of local minima. In this environment, the algorithm usually uses only the motion towards the target behavior, and generates globally optimal paths. In the second environment the obstacles are larger (Figure 10). Therefore the robot has a larger probability to activate the boundary-following behavior. In this environment there are more cases where a large part of an obstacle is occluded. In these cases the locally shortest path may diier signiicantly from the globally shortest one (Figure 10). Thus the generated path depends more on the local arrangement of the obstacles. We consider these examples as preliminary results. A more complete implementation of the algorithm is under construction. 6 Concluding Discussion We presented 3DBug, a new range-sensor based globally convergent algorithm for navigating a point robot in an unknown three-dimensional polyhedral environment. 3DBug uses 3D range data in the most reactive fashion possible and plans 3D motion throughout the navigation process. Thus 3DBug provides a new and eeective Bug-type navigation algorithm for three-dimensions. During motion towards the target, the robot follows the locally shortest path, and we presented an eecient method for generating it. We also presented a novel method for estimating the locally shortest path, in time which is linear in …",,https://www.semanticscholar.org/paper/33d542140db7840b50ae72fe2cd82f80d5dae50c,
2074,A Case Study to Evaluate the Productivity Changes of the Thermal Power Plants of the Taiwan Power Company,"This paper developed an approach based on data envelopment analysis and Malmquist productivity index to investigate the performance of power plants and conducted an empirical study with eight thermal power plants in Taiwan. The analysis results show the productivity improvements, and thus, help Taiwan Power Company to monitor and diagnose changes in the productivity of its thermal power plants. Furthermore, this study also provides specific directions for improvements to increase competitiveness in the face of the continuing liberalization of the Taiwanese power generation market.",2007-08-20,https://www.semanticscholar.org/paper/e635f7f03dde899bdde25e91de178372d2edaa51,IEEE transactions on energy conversion
1497,A detailed study of 'extra muon' production in deep inelastic muon interactions,,,https://www.semanticscholar.org/paper/35683f840d70e3a29d57a06f9862bff189bb908d,
2441,Mercury: A Messaging Framework for Modular UI Components,"In recent years, the entity--component--system pattern has become a fundamental feature of the software architectures of game-development environments such as Unity and Unreal, which are used extensively in developing 3D user interfaces. In these systems, UI components typically respond to events, requiring programmers to write application-specific callback functions. In some cases, components are organized in a hierarchy that is used to propagate events among vertically connected components. When components need to communicate horizontally, programmers must connect those components manually and register/unregister events as needed. Moreover, events and callback signatures may be incompatible, making modular UIs cumbersome to build and share within or across applications. To address these problems, we introduce a messaging framework, Mercury, to facilitate communication among components. We provide an overview of Mercury, outline its underlying protocol and how it propagates messages to responders using relay nodes, describe a reference implementation in Unity, and present example systems built using Mercury to explain its advantages.",2018-04-21,https://www.semanticscholar.org/paper/cea0e4778f02d0663062b510868747108571c085,International Conference on Human Factors in Computing Systems
3697,Doubly Right Object Recognition: A Why Prompt for Visual Rationales,"Many visual recognition models are evaluated only on their classification accuracy, a metric for which they obtain strong performance. In this paper, we investigate whether computer vision models can also provide correct rationales for their predictions. We propose a “doubly right” object recognition benchmark, where the metric requires the model to simultaneously produce both the right labels as well as the right rationales. We find that state-of-the-art visual models, such as CLIP, often provide incorrect rationales for their categorical predictions. However, by transferring the rationales from language models into visual representations through a tailored dataset, we show that we can learn a “why prompt,” which adapts large visual representations to produce correct rationales. Visualizations and empirical experiments show that our prompts significantly improve performance on doubly right object recognition, in addition to zero-shot transfer to unseen tasks and datasets.",2022-12-12,https://www.semanticscholar.org/paper/4eb5198062f78ecf844ff48bcaefe4c1c0f395cc,Computer Vision and Pattern Recognition
1181,Measurement of the Zγ→νν‾γ production cross section and limits on anomalous ZZγ and Zγγ couplings in pp‾ collisions at √s=1.96 TeV,"We present the first observation of the Zγ→ννγ‾ process at the Fermilab Tevatron at 5.1 standard deviations significance, 
based on 3.6 fb -1 of integrated luminosity collected with the D0 detector at the Fermilab Tevatron pp‾ Collider at √s=1.96 TeV. The measured Z? 
production cross section multiplied by the branching fraction of Z→νν‾ is 32± 9(stat+syst)± 2(lumi) fb for the photon E T > 90 GeV. It is in agreement with the standard model prediction of 39± 4 fb. We set limits on anomalous trilinear Zγγ and ZZγ gauge boson couplings, most of which are the most restrictive to date.",,https://www.semanticscholar.org/paper/c68454c1e88976836bd56dfe0232daefb767b622,
1036,Motion Planning and Differential Flatness of Mechanical Systems on Principal Bundles,"Mechanical systems often exhibit physical symmetries in their configuration variables, allowing for significant reduction of their mathematical complexity arising from characteristics such as underactuation and nonlinearity. In this paper, we exploit the geometric structure of such systems to explore the following motion planning problem: given a desired trajectory in the workspace, can we explicitly solve for the appropriate inputs to follow it? We appeal to results on differential flatness from the nonlinear control literature to develop a general motion planning formulation for systems with symmetries and constraints, which also applies to both fully constrained and unconstrained kinematic systems. We conclude by demonstrating the utility of our results on several canonical mechanical systems found in the locomotion literature.Copyright © 2015 by ASME",2015-10-28,https://www.semanticscholar.org/paper/ed708f263f053fe68fb4e5250430eab56d0cc651,
983,Safety of Nonporous Silica Nanoparticles in Human Corneal Endothelial Cells,,2017-11-06,https://www.semanticscholar.org/paper/049ace421ade4c45c779e29c6923e33ef8de02da,Scientific Reports
940,The Complexity of Restricted Minimum Spanning Tree Problems (Extended Abstract),,1979-07-16,https://www.semanticscholar.org/paper/939910f3e1a823a8b3b88854f151cd8579a0913e,"International Colloquium on Automata, Languages and Programming"
2031,The TSMC Way: Meeting Customer Needs at Taiwan Semiconductor Manufacturing Co.,"When L.C. Tu receives an emergency order, he is confronted with a range of production scheduling choices, each of which has unique costs and trade-offs. The case was designed to help students understand job-shop style production and the impact of disruptions and reactive scheduling. Students use two of Taiwan Semiconductor Manufacturing Company's mainstream processes as a vehicle for analysis. The case describes a real situation in which upper management accepts an emergency order. By working through the impact on the production system, students should develop a feel for how shifting demand in a large factory that is structured as a job shop alters the demands on, and utilization rates of expensive capital equipment in a complex way. As bottlenecks shift, students can explore several alternatives, each with different costs and trade-offs. Students may also reflect on the true cost of providing the extraordinary service, and whether management properly takes the impact on operations into account when it makes customer commitments.Learning Objective:To understand the impact of disruptions on job shop production systems.",2009-08-13,https://www.semanticscholar.org/paper/0bb102c0c3051a4cc7885869906bacc8fb313394,
2266,Oscillations in NF-κB Signaling Control the Dynamics of Gene Expression,"Signaling by the transcription factor nuclear factor kappa B (NF-κB) involves its release from inhibitor kappa B (IκB) in the cytosol, followed by translocation into the nucleus. NF-κB regulation of IκBα transcription represents a delayed negative feedback loop that drives oscillations in NF-κB translocation. Single-cell time-lapse imaging and computational modeling of NF-κB (RelA) localization showed asynchronous oscillations following cell stimulation that decreased in frequency with increased IκBα transcription. Transcription of target genes depended on oscillation persistence, involving cycles of RelA phosphorylation and dephosphorylation. The functional consequences of NF-κB signaling may thus depend on number, period, and amplitude of oscillations.",2004-10-22,https://www.semanticscholar.org/paper/f524615f85ad6c945ddcf885ba3a05ad3048abc4,Science
3143,The design and implementation of Zap,"We have created Zap, a novel system for transparent migration of legacy and networked applications. Zap provides a thin virtualization layer on top of the operating system that introduces pods, which are groups of processes that are provided a consistent, virtualized view of the system. This decouples processes in pods from dependencies to the host operating system and other processes on the system. By integrating Zap virtualization with a checkpoint-restart mechanism, Zap can migrate a pod of processes as a unit among machines running independent operating systems without leaving behind any residual state after migration. We have implemented a Zap prototype in Linux that supports transparent migration of unmodified applications without any kernel modifications. We demonstrate that our Linux Zap prototype can provide general-purpose process migration functionality with low overhead. Our experimental results for migrating pods used for running a standard user's X windows desktop computing environment and for running an Apache web server show that these kinds of pods can be migrated with subsecond checkpoint and restart latencies.",2002-12-09,https://www.semanticscholar.org/paper/a6b100291fe50fd8a563e0ade459081827792ef6,USENIX Symposium on Operating Systems Design and Implementation
1482,Progress report on the SLD cerenkov ring imaging detector,"We describe test beam results from a prototype cerenkov Ring Imaging Detector (CRID) for the SLD experiment at the SLAC Linear Collider (SLC). The system includes both liquid and gas radiators, a long drift box containing gaseous TMAE and a proportional wire chamber with charge division readout. Measurements of the multiplicity and detection resolution of cerenkov photons, from both radiators are presented. Various design aspects of a new engineering prototype, currently under construction, are discussed and recent R&D results relevant to this effort are reported.",1987-02-01,https://www.semanticscholar.org/paper/a0b7120ba33a8d780a39ded7caee1176329a9702,IEEE Transactions on Nuclear Science
769,Testing hierarchical systems,"We investigate the testing of hierarchical (modular) systems, in which individual modules are modeled by finite state machines. Given a hierarchical system, we are interested in finding a small set of tests that exercises all the transitions of the system. We present tight approximation algorithms and hardness results for the problem. Our techniques extend to other criteria and metrics.",2005-01-23,https://www.semanticscholar.org/paper/7a0be5eddcd5d3e131fa9b02d90d07f30abe22ea,ACM-SIAM Symposium on Discrete Algorithms
2783,Intracranial alternating current stimulation facilitates neurogenesis in a mouse model of Alzheimer’s disease,,2020-07-23,https://www.semanticscholar.org/paper/0c57759037fae41ed0d09a57f95c1d503666c9bd,Alzheimer's Research & Therapy
1558,Double Empirical Bayes Testing,"Analysing data from large‐scale, multiexperiment studies requires scientists to both analyse each experiment and to assess the results as a whole. In this article, we develop double empirical Bayes testing (DEBT), an empirical Bayes method for analysing multiexperiment studies when many covariates are gathered per experiment. DEBT is a two‐stage method: in the first stage, it reports which experiments yielded significant outcomes and in the second stage, it hypothesises which covariates drive the experimental significance. In both of its stages, DEBT builds on the work of Efron, who laid out an elegant empirical Bayes approach to testing. DEBT enhances this framework by learning a series of black box predictive models to boost power and control the false discovery rate. In Stage 1, it uses a deep neural network prior to report which experiments yielded significant outcomes. In Stage 2, it uses an empirical Bayes version of the knockoff filter to select covariates that have significant predictive power of Stage 1 significance. In both simulated and real data, DEBT increases the proportion of discovered significant outcomes and selects more features when signals are weak. In a real study of cancer cell lines, DEBT selects a robust set of biologically plausible genomic drivers of drug sensitivity and resistance in cancer.",2020-11-25,https://www.semanticscholar.org/paper/552facf726bd0ee7c4a54632d2ce36c2cf67efe1,International statistical review = Revue internationale de statistique
2086,Downgrade decision for control/dummy wafers in a fab,,2005-09-01,https://www.semanticscholar.org/paper/30fb93cb647d580f5c728cfa1e4be9abf86214f0,
76,Distributed Search over the Hidden Web: Hierarchical Database Sampling and Selection,,2002-08-20,https://www.semanticscholar.org/paper/3240f47572a6efef76c6bb6656d4cc0bbb9eb03a,Very Large Data Bases Conference
2961,An Empirical Study of Stochastic Variational Inference Algorithms for the Beta Bernoulli Process,,2015-06-01,https://www.semanticscholar.org/paper/fa2883d2074b02151df459eddd10992e35ad8c98,International Conference on Machine Learning
2595,u BRIDGING THE GAPS : HYBRID TRACKING FOR ADAPTIVE MOBILE AUGMENTED REALITY,"Tracking accuracy in a location-aware mobile system can change dynamically as a function of the user’s location and other variables specific to the tracking technologies used. This is especially problematic for mobile augmented reality systems, which ideally require extremely precise position tracking for the user’s head, but which may not always be able to achieve that level of accuracy. While it is possible to ignore variable positional accuracy in an augmented reality user interface, this can make for a confusing system; for example, when accuracy is low, virtual objects that are nominally registered with real ones may be too far off to be of use. To address this problem, we describe an experimental mobile augmented reality system that: (1) employs multiple position-tracking technologies, including ones that apply heuristics based on environmental knowledge; (2) coordinates these concurrently monitored tracking systems; and (3) automatically adapts the user interface to varying degrees of confidence in tracking accuracy. We share our experiences with managing these multiple tracking technologies, employing various techniques to facilitate smooth and reasonable ‘‘hand-offs’’ between the cooperating systems. We present these results in the context of a intelligent navigational guidance system that helps users to orient themselves in an unfamiliar environment, using path planning to guide them toward destinations they choose, and sometimes towards ones the system infers as equally relevant.",,https://www.semanticscholar.org/paper/28edb42d90b3bf9a4bc053064ceb23210e3fac45,
2647,User interface management techniques for collaborative mobile augmented reality,,2001-10-01,https://www.semanticscholar.org/paper/c34b386d148b8bd270ef656a811ef85fcee87a3b,Computers & graphics
3360,The Impact of the Planned Environment on the Elderly,,,https://www.semanticscholar.org/paper/9af5cee7bf237e3153bdb6dea204fdbb174f3406,
831,Some Open Problems in Approximation,,1994-03-01,https://www.semanticscholar.org/paper/5776470d2096eae53e8abcffefcb84c9c04afa33,International/Italian Conference on Algorithms and Complexity
1171,Measurement of theZγ→νν¯γProduction Cross Section and Limits on AnomalousZZγandZγγCouplings inpp¯Collisions ats=1.96TeV,,2009-05-22,https://www.semanticscholar.org/paper/9ab976596b8a13ea3c1fa3dd434cf9cd44fa120d,
58,Optimizing top-k selection queries over multimedia repositories,"Repositories of multimedia objects having multiple types of attributes (e.g., image, text) are becoming increasingly common. A query on these attributes will typically, request not just a set of objects, as in the traditional relational query model (filtering), but also a grade of match associated with each object, which indicates how well the object matches the selection condition (ranking). Furthermore, unlike in the relational model, users may just want the k top-ranked objects for their selection queries for a relatively small k. In addition to the differences in the query model, another peculiarity of multimedia repositories is that they may allow access to the attributes of each object only through indexes. We investigate how to optimize the processing of top-k selection queries over multimedia repositories. The access characteristics of the repositories and the above query model lead to novel issues in query optimization. In particular, the choice of the indexes used to search the repository strongly influences the cost of processing the filtering condition. We define an execution space that is search-minimal, i.e., the set of indexes searched is minimal. Although the general problem of picking an optimal plan in the search-minimal execution space is NP-hard, we present an efficient algorithm that solves the problem optimally with respect to our cost model and execution space when the predicates in the query are independent. We also show that the problem of optimizing top-k selection queries can be viewed, in many cases, as that of evaluating more traditional selection conditions. Thus, both problems can be viewed together as an extended filtering problem to which techniques of query processing and optimization may be adapted.",2004-08-01,https://www.semanticscholar.org/paper/52667eff2fea8af809465233b8667277e1e47ecb,IEEE Transactions on Knowledge and Data Engineering
258,Kurt Gödel and the Foundations of Mathematics: Computation and Intractability: Echoes of Kurt Gödel,,,https://www.semanticscholar.org/paper/ca7a529d487a7f4e3a4621a08c05324a4337475f,
1922,User-experience-based design of experiments for new product development of consumer electronics and an empirical study,"Abstract User Experience (UX) has been employed for new product development, yet few systematic approaches have been developed. This study aims to propose a systematic approach, namely, User-experience-based design of experiments (UXDOE) to capture user response and filter design ideas to derive new product design directions. Two empirical studies were conducted with the collaboration of a world leading electronics manufacturing services (EMS) company. The derived results can support the confirmation of the target segments from the perspective of marketing and clarifying key factors. Based on UXDOE, this study investigated the influence of UX on 14 notebook prototypes and wearable product design practices. The results of empirical studies have shown practical viability of the proposed approach. This study filters design ideas of esthetics and indicate several key factors of the products that enables better understanding of UX and preferences across different segments and their evaluation toward various product concepts.",2017-09-06,https://www.semanticscholar.org/paper/b625d20d8fb73036bbf9a6a8012b093b15ff9460,
3428,Divide-and-Conquer Approximation Algorithm for Vertex Cover,"The vertex cover problem is a classical NP-complete problem for which the best worst-case approximation ratio is $2-o(1)$. In this paper, we use a collection of simple graph transformations, each of which guarantees an approximation ratio of $\frac{3}{2}$, to find approximate vertex covers for a large collection of randomly generated graphs and test graphs from various sources. The graph reductions are extremely fast, and even though they by themselves are not guaranteed to find a vertex cover, we manage to find a $\frac{3}{2}$-approximate vertex cover for almost every single graph in our collection. The few graphs that we cannot solve have specific structure: they are triangle-free, with a minimum degree of at least 3, a lower bound of $\frac{n}{2}$ on the optimal vertex cover, and are unlikely to have a large bipartite subgraph.",2009-07-01,https://www.semanticscholar.org/paper/451f6671853c02d40b78e839471a930930ea9c5a,SIAM Journal on Discrete Mathematics
2145,Delay with network coding and feedback,"We consider the problem of minimizing delay when broadcasting over erasure channels with feedback. A sender wishes to communicate the same set of µ messages to several receivers over separate erasure channels. The sender can broadcast a single message or a combination (encoding) of messages at each timestep. Receivers provide feedback as to whether the transmission was received. If at some time step a receiver cannot identify a new message, delay is incurred. Our notion of delay is motivated by real-time applications that request progressively refined input, such as the successive refinement of an image encoded using multiple description coding. Our setup is novel because it combines coding techniques with feedback information to the end of minimizing delay. It allows Θ(µ) benefits as compared to previous approaches for offline algorithms, while feedback allows online algorithms to achieve smaller delay than online algorithms without feedback. Our main complexity results are that the offline minimization problem is NP-hard when the sender only schedules single messages and that the general problem remains NP-hard even when coding is allowed. However we show that coding does offer delay and complexity gains over scheduling. We also discuss online heuristics and evaluate their performance through simulations.",2009-06-28,https://www.semanticscholar.org/paper/7150cbbbef826cc9c753a44c947a689c8237fe06,2009 IEEE International Symposium on Information Theory
2918,"The sensitivity ranking of ductile material mechanical properties, geometrical factors, friction coefficients and damage parameters for small punch test",,2021-10-01,https://www.semanticscholar.org/paper/83f86740fab217a63afa912d06fc1a5994024a4e,
489,On Finding Extensions of Default Theories,,1992-10-14,https://www.semanticscholar.org/paper/50edbb4e99d724ea1a2a57c61e8a759a94fa5c28,International Conference on Database Theory
1699,Introduction to Mixed Membership Models and Methods,1.1 Historical Developments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.2 A General Formulation for Mixed Membership Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.3 Advantages of Mixed Membership Models in Applied Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1.4 Theoretical Issues with Mixed Membership Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 1.4.1 General Issues Inherent to Mixtures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10,2014-11-06,https://www.semanticscholar.org/paper/6cec1861b1717d3ec1f558d48d40ae23e5d42b1e,Handbook of Mixed Membership Models and Their Applications
3603,A Formalism for C,"In this paper, we develop a general formalism for describing the C++ programming language, and regular enough to cope with proposed extensions (such as concepts) for C++0x that affect its type system. Concepts are a mechanism for checking template arguments currently being developed to help cope with the massive use of templates in modern C++. The main challenges in developing a formalism for C++ are scoping, overriding, overloading, templates, specialization, and the C heritage exposed in the built-in types. Here, we primarily focus on templates and overloading.",,https://www.semanticscholar.org/paper/59d379a4f80440b3f7b664941145be15e48f27ab,
2585,Exploring interaction with a simulated wrist-worn projection display,"One of the major limitations of portable computing devices is the small size of their built-in displays. Fortunately, extremely small projection systems are being developed that can be integrated into devices that are small enough to be body-worn, yet can project a large image onto surfaces in the environment. To explore how a user might interact with this near-horizon technology, we created a functional simulation of a wrist-worn projector. We then developed a set of interaction techniques that assume that the wrist-worn computer and projector are equipped with position and orientation sensors, in addition to a touch-sensitive built-in screen. To complement the techniques that rely on the spatial manipulation of the user's forearm and the device itself, we also describe the use of a cursor less watch user interface that minimizes the need for the user to look down at the device's built-in screen. Finally, we present a sample application that illustrates our interaction techniques.",2005-10-18,https://www.semanticscholar.org/paper/9e6ec12254969377c3133f7ab32beebdc826f8ca,International Semantic Web Conference
2653,Dynamic space management for user interfaces,"We present a general approach to the dynamic representation of 2D space that is well suited for user-interface layout. We partition space into two distinct categories: full and empty. The user can explicitly specify a set of possibly overlapping upright rectangles that represent the objects of interest. These full-space rectangles are processed by the system to create a representation of the remaining empty space. This representation makes it easy for users to develop customized spatial allocation strategies that avoid overlapping the full-space rectangles. We describe the representation; provide efficient incremental algorithms for adding and deleting full-space rectangles, and for querying the empty-space representation; and show several allocation strategies that the representation makes possible. We present two testbed applications that incorporate an implementation of the algorithm; one shows the utility of our representation for window management tasks; the other applies it to the layout of components in a 3D user interface, based on the upright 2D bounding boxes of their projections.",2000-11-01,https://www.semanticscholar.org/paper/92f4b67419139aeb6fdc6929a51348e9c58a8b2e,ACM Symposium on User Interface Software and Technology
1377,Search for doubly charged higgs boson pair production in the decay to mu(+)mu(+)mu(-)mu(-) in pp collisions at sqrt[s]=1.96 TeV.,"A search for pair production of doubly charged Higgs bosons in the process pp -->H(++)H(--) -->mu(+)mu(+)mu(-)mu(-) is performed with the D0 run II detector at the Fermilab Tevatron. The analysis is based on a sample of inclusive dimuon data collected at an energy of sqrt[s]=1.96 TeV, corresponding to an integrated luminosity of 113 pb(-1). In the absence of a signal, 95% confidence level mass limits of M(H(+/-+/-)(L))>118.4 GeV/c(2) and M(H(+/-+/-)(R))>98.2 GeV/c(2) are set for left-handed and right-handed doubly charged Higgs bosons, respectively, assuming 100% branching into muon pairs.",,https://www.semanticscholar.org/paper/c5a38c8ca241e3be8363d65309b712d9def4cc67,Physical Review Letters
2499,Designing inpatient technology to meet the medication information needs of cardiology patients,"As patients are encouraged to become active participants in their own care, recent research has begun to explore the direct sharing of electronic health information with patients during hospital visits. The design of patient-facing views of clinical information is, however, a relatively recent line of inquiry. Research is needed to further understand guidelines for communicating specific types of information to hospital patients. In this work, we focus on cardiology patients' information needs related to their hospital medications. We assessed these needs to inform the design of interactive, electronic views of medication information for cardiology inpatients. We present results of in-situ interviews with 11 inpatients and 6 nurses in a cardiology step-down unit. Our findings suggest that cohesive trends in medication information needs exist across cardiology inpatients. We discuss interview results and their implications for the design of inpatient-facing information technology. We also discuss key ways in which electronic medication information, formatted for inpatient use, differs from that formatted for outpatient or transitional medication-management use.",2012-01-28,https://www.semanticscholar.org/paper/8d774db92e5367a3d15e828fb724a0bc1cb83b90,International Health Informatics Symposium
1789,Linguistic extensions of topic models,"Topic models like latent Dirichlet allocation (LDA) provide a framework for analyzing large datasets where observations are collected into groups. Although topic modeling has been fruitfully applied to problems social science, biology, and computer vision, it has been most widely used to model datasets where documents are modeled as exchangeable groups of words. In this context, topic models discover topics, distributions over words that express a coherent theme like “business” or “politics.” While one of the strengths of topic models is that they make few assumptions about the underlying data, such a general approach sometimes limits the type of problems topic models can solve. 
When we restrict our focus to natural language datasets, we can use insights from linguistics to create models that understand and discover richer language patterns. In this thesis, we extend LDA in three different ways: adding knowledge of word meaning, modeling multiple languages, and incorporating local syntactic context. These extensions apply topic models to new problems, such as discovering the meaning of ambiguous words, extend topic models for new datasets, such as unaligned multilingual corpora, and combine topic models with other sources of information about documents' context. 
In Chapter 2, we present latent Dirichlet allocation with WordNet (LDAWN), an unsupervised probabilistic topic model that includes word sense as a hidden variable. LDAWN replaces the multinomial topics of LDA with Abney and Light's distribution over meanings. Thus, posterior inference in this model discovers not only the topical domains of each token, as in LDA, but also the meaning associated with each token. We show that considering more topics improves the problem of word sense disambiguation. 
LDAWN allows us to separate the representation of meaning from how that meaning is expressed as word forms. In Chapter 3, we extend LDAWN to allow meanings to be expressed using different word forms in different languages. In addition to the disambiguation provided by LDAWN, this offers a new method of using topic models on corpora with multiple languages. 
In Chapter 4, we relax the assumptions of multilingual LDAWN. We present the multilingual topic model for unaligned text (MuTo). Like multilingual LDAWN, it is a probabilistic model of text that is designed to analyze corpora composed of documents in multiple languages. Unlike multilingual LDAWN, which requires the correspondence between languages to be painstakingly annotated, MuTo also uses stochastic EM to simultaneously discover both a matching between the languages while it simultaneously learns multilingual topics. We demonstrate that MuTo allows the meaning of similar documents to be recovered across languages. 
In Chapter 5, we address a recurring problem that hindered the performance of the models presented in the previous chapters: the lack of a local context. We develop the syntactic topic model (STM), a non-parametric Bayesian model of parsed documents. The STM generates words that are both thematically and syntactically constrained, which combines the semantic insights of topic models with the syntactic information available from parse trees. Each word of a sentence is generated by a distribution that combines document-specific topic weights and parse-tree-specific syntactic transitions. Words are assumed to be generated in an order that respects the parse tree. We derive an approximate posterior inference method based on variational methods for hierarchical Dirichlet processes, and we report qualitative and quantitative results on both synthetic data and hand-parsed documents. 
In Chapter 6, we conclude with a discussion of how the models presented in this thesis can be applied in real world applications such as sentiment analysis and how the models can be extended to capture even richer linguistic information from text.",,https://www.semanticscholar.org/paper/d3e3affa94244fd3d6d0253a0cce0949a596b24a,
319,Recognizing Hole-Free 4-Map Graphs in Cubic Time,,2006-06-01,https://www.semanticscholar.org/paper/6a6d0c9e2bf9a1b894ee98b91accffc673b98802,Algorithmica
2112,Using Bayesian Network for Fault Location on Distribution Feeder,"The Bayesian network is a probabilistic graphical model in which a problem is structured as a set of variables (parameters) and probabilistic relationships among them. The Bayesian network has been effectively used to incorporate expert knowledge and historical data for revising the prior belief in the light of new evidence in many fields. However, little research has been done to apply the Bayesian network for fault location in power delivery systems. We construct a Bayesian network on the basis of expert knowledge and historical data for fault diagnosis on a distribution feeder in Taiwan. The experimental results validate the practical viability of the proposed approach.",2002-11-07,https://www.semanticscholar.org/paper/96f57edd19ad252639e4003cec6da87ce3b37e07,IEEE Power Engineering Review
279,VC v. VCG: Inapproximability of Combinatorial Auctions via Generalizations of the VC Dimension,"The existence of incentive-compatible computationally-efficient protocols for combinatorial auctions with decent approximation ratios is the paradigmatic problem in computational mechanism design. It is believed that in many cases good approximations for combinatorial auctions may be unattainable due to an inherent clash between truthfulness and computational efficiency. However, to date, researchers lack the machinery to prove such results. In this paper, we present a new approach that we believe holds great promise for making progress on this important problem. We take the first steps towards the development of new technologies for lower bounding the VC-dimension of k-tuples of disjoint sets. We apply this machinery to prove the first computational-complexity inapproximability results for incentive-compatible mechanisms for combinatorial auctions. These results hold for the important class of VCG-based mechanisms, and are based on the complexity assumption that NP has no polynomial-size circuits.",2009-05-12,https://www.semanticscholar.org/paper/acf1c480d31881cbc22b752673d3442813ce0886,arXiv.org
3203,Resolution of Respect Robert M. May (1936–2020),,2020-09-24,https://www.semanticscholar.org/paper/10b5b9a5c3a6e9057e7fc617f92d4fe6963b1479,
1820,The nested Chinese restaurant process and Bayesian inference of topic hierarchies,"We present the nested Chinese restaurant process (nCRP), a stochastic process which assigns probability distributions to infinitely-deep, infinitely-branching trees. We show how this stochastic process can be used as a prior distribution in a Bayesian nonparametric model of document collections. Specifically, we present an application to information retrieval in which documents are modeled as paths down a random tree, and the preferential attachment dynamics of the nCRP leads to clustering of documents according to sharing of topics at multiple levels of abstraction. Given a corpus of documents, a posterior inference algorithm finds an approximation to a posterior distribution over trees, topics and allocations of words to levels of the tree. We demonstrate this algorithm on collections of scientific abstracts from several journals. This model exemplifies a recent trend in statistical machine learning--the use of Bayesian nonparametric methods to infer distributions on flexible data structures.",2007-10-03,https://www.semanticscholar.org/paper/276579dd0d88a0046f58586db0047fe7e71c3571,
1554,Invariant Representation Learning for Treatment Effect Estimation,"The defining challenge for causal inference from observational data is the presence of `confounders', covariates that affect both treatment assignment and the outcome. To address this challenge, practitioners collect and adjust for the covariates, hoping that they adequately correct for confounding. However, including every observed covariate in the adjustment runs the risk of including `bad controls', variables that \emph{induce} bias when they are conditioned on. The problem is that we do not always know which variables in the covariate set are safe to adjust for and which are not. To address this problem, we develop Nearly Invariant Causal Estimation (NICE). NICE uses invariant risk minimization (IRM) [Arj19] to learn a representation of the covariates that, under some assumptions, strips out bad controls but preserves sufficient information to adjust for confounding. Adjusting for the learned representation, rather than the covariates themselves, avoids the induced bias and provides valid causal inferences. NICE is appropriate in the following setting. i) We observe data from multiple environments that share a common causal mechanism for the outcome, but that differ in other ways. ii) In each environment, the collected covariates are a superset of the causal parents of the outcome, and contain sufficient information for causal identification. iii) But the covariates also may contain bad controls, and it is unknown which covariates are safe to adjust for and which ones induce bias. We evaluate NICE on both synthetic and semi-synthetic data. When the covariates contain unknown collider variables and other bad controls, NICE performs better than existing methods that adjust for all the covariates.",2020-11-24,https://www.semanticscholar.org/paper/44071a76a00a37caea959068800f5be1b0192f1c,Conference on Uncertainty in Artificial Intelligence
461,Beyond competitive analysis [on-line algorithms],"The competitive analysis of on-line algorithms has been criticized as being too crude and unrealistic. We propose two refinements of competitive analysis an two directions: The first restricts the power of the adversary by allowing only certain input distributions, while the other allows for comparisons between information regimes for on-line decision-making. We illustrate the first with an application to the paging problem; as a by product we characterize completely the work functions of this important special case of the k-server problem. We use the second refinement to explore the power of lookahead in server systems, and the power of visual sensors in robot navigation.<<ETX>>",1994-11-20,https://www.semanticscholar.org/paper/0596142782494dd8b45f8c7069641a10d8bd5406,Proceedings 35th Annual Symposium on Foundations of Computer Science
1413,Multiple Jet Production at Low Transverse Energies in $p\overline{p}$ Collisions at $\sqrt{s}$ = 1.8 TeV,,,https://www.semanticscholar.org/paper/b73697f856b232c8103a30d8418ac56a8ab84c4a,
713,Power Grid State Estimation Following a Joint Cyber and Physical Attack,"This paper focuses on joint cyber and physical attacks on power grids and presents methods to retrieve the grid state information following such an attack. We consider a model where an adversary attacks a zone by physically disconnecting some of its power lines and blocking the information flow from the zone to the grid's control center. We use tools from linear algebra and graph theory and leverage the properties of the linearized power flow model to develop methods for information recovery. Using information observed outside the attacked zone, these methods recover information about the disconnected lines and the phase angles at the buses. We identify sufficient conditions on the zone structure and constraints on the attack characteristics  such that these methods can recover the information. We also show that it is NP-hard to find an approximate solution to the problem of partitioning the power grid into the minimum number of attack-resilient zones. However, since power grids can often be represented by planar graphs, we develop a constant approximation partitioning algorithm for these graphs and numerically demonstrate its performance on real power grids.",2018-03-01,https://www.semanticscholar.org/paper/f4d15393209d19b03e30c31f657a35482bc65653,IEEE Transactions on Control of Network Systems
1608,Learning with Reflective Likelihoods,,2018-09-27,https://www.semanticscholar.org/paper/ad81013e8afc5e2fd5d279468dd6c9bb504179e7,
1960,The cooperative estimation of distribution algorithm: a novel approach for semiconductor final test scheduling problems,,2014-10-01,https://www.semanticscholar.org/paper/7007373cdac029a224e4a69e6a4f75a0f6e489f2,Journal of Intelligent Manufacturing
2379,"Purification, morphometric analysis, and characterization of the glycosomes (microbodies) of the protozoan hemoflagellate Trypanosoma brucei","Trypanosoma brucei glycosomes (microbodies containing nine enzymes involved in glycolysis) have been purified to near homogeneity from bloodstream-form trypomastigotes for the purpose of morphologic and biochemical analysis. Differential centrifugation followed by two isopycnic centrifugations in an isotonic Percoll and in a sucrose gradient, respectively, resulted in 12- to 13-fold purified glycosomes with an overall yield of 31%. These glycosomes appeared to be highly pure and contained less than 1% mitochondrial contamination as judged by morphometric and biochemical analyses. In intact cells, glycosomes displayed a remarkably homogeneous size distribution centered on an average diameter of 0.27 micron with a standard deviation of 0.03 micron. The size distribution of isolated glycosomes differed only slightly from that measured in intact cells. One T. brucei cell contained on average 230 glycosomes, representing 4.3% of the total cell volume. The glycosomes were surrounded by a single membrane and contained as phospholipids only phosphatidyl choline and phosphatidyl ethanolamine in a ratio of 2:1. The purified glycosomal fraction had a very low DNA content of 0.18 microgram/mg protein. No DNA molecules were observed that could not have been derived from contaminating mitochondrial or nuclear debris.",1984-04-01,https://www.semanticscholar.org/paper/3f7b8754289b74492f92d7f025311b4f20382d3c,Journal of Cell Biology
3413,A 2-Competitive Algorithm For Online Convex Optimization With Switching Costs,"We consider a natural online optimization problem set on the real line. The state of the online algorithm at each integer time is a location on the real line. At each integer time, a convex function arrives online. In response, the online algorithm picks a new location. The cost paid by the online algorithm for this response is the distance moved plus the value of the function at the final destination. The objective is then to minimize the aggregate cost over all time. The motivating application is rightsizing power-proportional data centers. We give a 2-competitive algorithm for this problem. We also give a 3-competitive memoryless algorithm, and show that this is the best competitive ratio achievable by a deterministic memoryless algorithm. Finally we show that this online problem is strictly harder than the standard ski rental problem.",,https://www.semanticscholar.org/paper/aeba62d4a55bb17ddd1b52fd9801dd463b9e0b8d,"International Workshop and International Workshop on Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques"
1109,Silicon detector results from the first five-tower run of CDMS II,"We report results of a search for weakly interacting massive particles (WIMPs) with the Si detectors of the CDMS II experiment. This report describes a blind analysis of the first data taken with CDMS II’s full complement of detectors in 2006–2007; results from this exposure using the Ge detectors have already been presented. We observed no candidate WIMP-scattering events in an exposure of 55.9 kg-days before analysis cuts, with an expected background of ∼1.1 events. The exposure of this analysis is equivalent to 10.3 kg-days over a recoil energy range of 7–100 keV for an ideal Si detector and a WIMP mass of 10  GeV/c^2. These data set an upper limit of 1.7×10^(-41)  cm^2 on the WIMP-nucleon spin-independent cross section of a 10  GeV/c^2 WIMP. These data exclude parameter space for spin-independent WIMP-nucleon elastic scattering that is relevant to recent searches for low-mass WIMPs.",2013-04-12,https://www.semanticscholar.org/paper/dbebfbc14ddc523f404efa3f5f28d0afb839a9ba,
2569,Authoring and presenting situated media in augmented and virtual reality,"This dissertation investigates the research challenges in authoring and presenting situated media in augmented and virtual reality. We use the term situated media to refer to multimedia and hypermedia that are embedded in the surrounding spatial environment. Linking information to physical objects and locations provides the ability to access and interact with information in context, using head-worn and hand-held displays. It potentially eases interaction with the physical world, enhances perception, and helps with users' tasks. 
We have developed authoring techniques that enable non-programmer users to create a variety of augmented and virtual reality experiences, ranging from stand-alone multimedia to richly linked hypermedia narratives embedded in the users' surroundings, which we call situated hypermedia. Depending on the task at hand, and the level of precision required, users can use stationary desktop-based or mobile tablet-based tools for authoring, to take advantage of the different input devices and interaction techniques available on these platforms. We collaborated with content creators who used our desktop-based authoring system and related presentation tools at different stages of their development to author situated hypermedia for course projects, and present informal feedback from these experiences. 
An essential complement to authoring is the ability to present the created content in an interactive and intuitive way to the users. To accomplish this, we have developed presentation techniques that make it possible for users to interact with situated media and navigate in large situated media spaces. Our augmenting pictures technique and animated timelines register and superimpose historic images onto real or virtual objects and provide a means of interacting with them, to make it possible for users to gain a better understanding of historic events and places. Our lifting, tilting, shifting and scaling techniques enable users to navigate and visualize complex hypermedia structures distributed across large distances. Using our techniques, users can selectively ""pick up"" interesting parts of a complex situated hypermedia structure, lift or tilt them to view otherwise occluded nodes and links, as well as shift and scale the structure for closer examination. We also present the results of a formal user study that evaluates several of these techniques.",,https://www.semanticscholar.org/paper/3ecc6adae2ffb1dc97c85aff139cac443935781d,
874,On recognizing integer polyhedra,,1990-03-01,https://www.semanticscholar.org/paper/d90b135f5e58fb656b958c3732b318d559e97129,Comb.
488,The Complexity of the Lin-Kernighan Heuristic for the Traveling Salesman Problem,"It is shown that finding a local optimum solution with respect to the Lin–Kernighan heuristic for the traveling salesman problem is PLS-complete, and thus as hard as any local search problem.",1992-06-01,https://www.semanticscholar.org/paper/4a75769dd195e97de23ae05f6c60a5eb4c8a51a0,SIAM journal on computing (Print)
457,Vector Analysis of Threshold Functions,"13] M. Krause and S. Waack. Variation ranks of communication matrices and lower bounds for depth two circuits having symmetric gates with unbounded fan-in. 22 Acknowledgments The authors would like to thank the referees for their detailed comments, and for strengthening the result presented in Theorem 6. A plc of the rows of the array that does not contain any row from the bottom N=16 rows will always have at least one positive coordinate. This is because: (1) if the rows are chosen only from the top 3N=4 rows then it follows from the previous discussion that at least one coordinate in the rst four coordinates of the plc will have a positive coordinate, (2) if the plc has at least one row from among other rows (i.e., from row number 3N=4 + 1 to row number (N ?N=16)) then consider the last four coordinates: it is a plc of rows that contains at least one row from among r 1 ; r 2 , and r 3 and does not contain r 4 ; hence, by property P4, at least one coordinate will be positive. Continue the procedure by adding log 4 N (= n=2) layers, each of which is 4 columns wide; thus constructing 2n columns. By then, any subset S that does not contain the very bottom row has the following property: any plc of the rows has at least one positive coordinate. Now change the ?1 in the 4th coordinate of the last row to a +1; this completes the construction of A. It follows from property P3 that any plc that contains the last row of A must have at least one positive coordinate in the rst 4 columns. As for the column sums, properties P1 and P2 ensure that they are all 0, except for the 4th column that we modiied in the last row, which sums to 2. 1. The matrix A in the above construction has identical rows. If one wants to construct an A with distinct rows, then one can add n extra columns to obtain an 2 n 3n matrix as follows: add n extra columns, such that each row has a unique identiier in these columns. Since we use all 2 n identiiers, each of these n columns sums to 0. 2. Since any plc of the rows of A has at least one positive coordinate, it implies that …",,https://www.semanticscholar.org/paper/b39d6ebbbe64ed363544ec7cb3b8cd1aa7240562,
377,On the Eigenvalue Power Law,,2002-09-13,https://www.semanticscholar.org/paper/ca6432cc2b8a50c953f049d900cb219a84e53336,International Workshop Randomization and Approximation Techniques in Computer Science
699,Computational Hardness of the Hylland-Zeckhauser Scheme,"We study the complexity of the classic Hylland-Zeckhauser scheme [HZ'79] for one-sided matching markets. We show that the problem of finding an $\epsilon$-approximate equilibrium in the HZ scheme is PPAD-hard, and this holds even when $\epsilon$ is polynomially small and when each agent has no more than four distinct utility values. Our hardness result, when combined with the PPAD membership result of [VY'21], resolves the approximation complexity of the HZ scheme. We also show that the problem of approximating the optimal social welfare (the weight of the matching) achievable by HZ equilibria within a certain constant factor is NP-hard.",2021-07-12,https://www.semanticscholar.org/paper/a0e27f6e982852e853398a64d494ac4cad00670b,ACM-SIAM Symposium on Discrete Algorithms
1272,Measurement of the charge asymmetry in semileptonic Bs0 decays.,"We have performed the first direct measurement of the time-integrated flavor untagged charge asymmetry in semileptonic Bs0 decays ASLs,unt by comparing the decay rate of Bs0-->micro+Ds-nuX, where Ds- -->phipi- and phi-->K+K-, with the charge-conjugate Bs0 decay rate. This sample was selected from 1.3 fb-1 of data collected by the D0 experiment in run II of the Fermilab Tevatron collider. We obtain ASLs,unt=[1.23+/-0.97(stat)+/-0.17(syst)]x10(-2). Assuming that Deltam(s)/Gamma(s)>>1, this result can be translated into a measurement of the CP-violating phase in Bs0 mixing: DeltaGamma(s)/Deltam(s)tanphi(s)=[2.45+/-1.93(stat)+/-0.35(syst)]x10(-2).",2007-01-06,https://www.semanticscholar.org/paper/280217fc5db85b8c11456930032b55c98130e5dc,Physical Review Letters
1678,HVMs extend the applicability of normalizing flows to discrete variables. We can also place a distribution over transformations to build an HVM without Jacobians (2).,,,https://www.semanticscholar.org/paper/49885ebfd0135dd5399137b0216b629f0ee85ffe,
1683,Correlated Random Measures,"ABSTRACT We develop correlated random measures, random measures where the atom weights can exhibit a flexible pattern of dependence, and use them to develop powerful hierarchical Bayesian nonparametric models. Hierarchical Bayesian nonparametric models are usually built from completely random measures, a Poisson-process-based construction in which the atom weights are independent. Completely random measures imply strong independence assumptions in the corresponding hierarchical model, and these assumptions are often misplaced in real-world settings. Correlated random measures address this limitation. They model correlation within the measure by using a Gaussian process in concert with the Poisson process. With correlated random measures, for example, we can develop a latent feature model for which we can infer both the properties of the latent features and their dependency pattern. We develop several other examples as well. We study a correlated random measure model of pairwise count data. We derive an efficient variational inference algorithm and show improved predictive performance on large datasets of documents, web clicks, and electronic health records. Supplementary materials for this article are available online.",2015-07-02,https://www.semanticscholar.org/paper/889bc6066784fa1e2f05a1480f397a77c9c31468,
595,On Concurrency Control by Multiple Versions,We examine the problem of concurrency control when the database management system supports multiple versions of the data. We characterize the limit of the parallelism achievable by the multiversion approach and demonstrate the resulting space-parallelism trade-off.,1982-03-29,https://www.semanticscholar.org/paper/9166b33bb042c0623b037a74158be0f0e797d1be,TODS
3388,Number 18,"Different Search techniques were developed over the period, each of them having certain advantages and disadvantages. Improving the search techniques result in better performance thus better efficiency. Data Structures can be improved by some minor tweaks leading to improving the quality of data structure. In Linked List, searching is slow due to sequential search requirement, which can be improved by properly indexing the list thus improving speed. There are various indexing methods such as uniform indexing, Tree based indexing, dense indexing, clustered indexing, etc. This paper focuses on the indexed based searching using an additional lane linked list and equips a method to incorporate different series such as squared series and cubic series which further leads to speed enhancement as compared with traditional indexing counterparts due to their nature of increasing gaps between sequential indexes, which reduces the dependency on the main linked list and increasing the dependency on the lane linked list thus using the nature of series more efficiently as the list size increases.",,https://www.semanticscholar.org/paper/18e8443d72013c118ea5200881032632af09a8ad,
3165,SchedulerUnacceptablefor MultimediaApplications,"Applications that manipulate digital audio and video are rapidly being added to workstations. Such computations can often consume the resources of an entire machine. By incorporating a “realtime” process scheduler, UNIX System V Release 4 (SVR4), the most common basis of workstation operating systems, claims to provide system support for multimedia applications. Our quantitative measurements of real application performance demonstrate that this process scheduler is largely ineffective and can even produce system lockup. While SVR4 UNIX provides many controls for changing scheduler performance, they are virtually impossible to use successfully. Furthermore, the existence of a realtime static priority process scheduler in no way allows a user to deal with these problems. This paper provides a quantitative analysis of real system behavior, demonstrates why it is not possible to obtain the kind of behavior desired with the mechanisms currently provided by the system, and presents modifications to improve the situation.",,https://www.semanticscholar.org/paper/22a72172cbaad09910b23b932743d5153fb640a8,
2019,Optimizing information value for supporting production decisions for semiconductor manufacturing,"• Through the proposed method, the streamlined high-priority lots can be obtained with maximum information coverage and best KPI, and the model has good ability of abnormal discrimination. • Cost reduction by catching more abnormal events • Decreasing business impact to improve customer's satisfaction",2011-09-01,https://www.semanticscholar.org/paper/e2b478d803dc1ff49066a65afeec58a96cd9ba59,2011 e-Manufacturing & Design Collaboration Symposium & International Symposium on Semiconductor Manufacturing (eMDC & ISSM)
3652,Panel: Object-Oriented Languages: Premises and Promises,,,https://www.semanticscholar.org/paper/7a6b0bee8b14bb22464c5fd7098cf41c9fe4d778,"Conference on Object-Oriented Programming Systems, Languages, and Applications"
363,A simple algorithm for finding frequent elements in streams and bags,"We present a simple, exact algorithm for identifying in a multiset the items with frequency more than a threshold θ. The algorithm requires two passes, linear time, and space 1/θ. The first pass is an on-line algorithm, generalizing a well-known algorithm for finding a majority element, for identifying a set of at most 1/θ items that includes, possibly among others, all items with frequency greater than θ.",2003-03-01,https://www.semanticscholar.org/paper/e82c4930ec5f01508313d8ad9b41565d25ea96d5,TODS
1695,Real-time Topic Models for Crisis Counseling,"The proliferation of text-based crisis counseling platforms in recent months has opened an exciting opportunity for applied machine learning to (1) provide practical assistance for human counselors who provide emotional and practical support and (2) analyze counselor-caller interactions to build a landscape of the distribution of mental health issues experienced by callers on an unprecedented scale. We present Fathom, a natural language interface powered by topic models to help crisis counselors on Crisis Text Line, a new 911-like crisis hotline that takes calls via text messaging. We apply a mixed-initiative labeled LDA model to analyze counselor-caller conversations and use them to power real-time visualizations aimed at mitigating counselor cognitive load. We discuss three key aspects of crisis counseling and why topic models are suitable for mining this phenomenon. We propose new variants of topic models inspired by the practical constraints posed by their real-time deployment.",,https://www.semanticscholar.org/paper/2a1186207dd9e25b67c89067f0913bb0847d791f,
1314,Limits on spin-dependent WIMP-nucleon interactions from the cryogenic dark matter search,"The Cryogenic Dark Matter Search (CDMS) is an experiment to detect weakly interacting massive particles (WIMPs), which may constitute the universe’s dark matter, based on their interactions with Ge and Si nuclei. We report the results of an analysis of data from the first two runs of CDMS at the Soudan Underground Laboratory in terms of spin-dependent WIMP-nucleon interactions on 73 Ge and 29 Si. These data exclude new regions of WIMP parameter space, including regions relevant to spin-dependent interpretations of the annual modulation signal reported by the DAMA/NaI experiment.",,https://www.semanticscholar.org/paper/5d7ad273313447a404a43a742722d96863f69ae4,
293,"The complexity of game dynamics: BGP oscillations, sink equilibria, and beyond","We settle the complexity of a well-known problem in networking by establishing that it is PSPACE-complete to tell whether a system of path preferences in the BGP protocol [25] can lead to oscillatory behavior; one key insight is that the BGP oscillation question is in fact one about Nash dynamics. We also show that the concept of sink equilibria proposed recently in [11] is PSPACE-complete to analyze and approximate for graphical games. Finally, we propose a new equilibrium concept inspired by game dynamics, unit recall equilibria, which we show to be close to universal (exists with high probability in a random game) and algorithmically promising. We also give a relaxation thereof, called componentwise unit recall equilibria, which we show to be both tractable and universal (guaranteed to exist in every game).",2008-01-20,https://www.semanticscholar.org/paper/b284c43884f57935e61e189a18ffe432a2a1ef9e,ACM-SIAM Symposium on Discrete Algorithms
2526,Perceptual issues in augmented reality revisited,"This paper provides a classification of perceptual issues in augmented reality, created with a visual processing and interpretation pipeline in mind. We organize issues into ones related to the environment, capturing, augmentation, display, and individual user differences. We also illuminate issues associated with more recent platforms such as handhelds or projector-camera systems. Throughout, we describe current approaches to addressing these problems, and suggest directions for future research.",2010-11-22,https://www.semanticscholar.org/paper/db5b0202e1de96f151a3efb36f68aeb332cf2eea,2010 IEEE International Symposium on Mixed and Augmented Reality
294,Papers about papers.,,,https://www.semanticscholar.org/paper/b7e6d3f405a15084cf8dfe877378897df9ac927a,Nature Nanotechnology
3044,VMTorrent: scalable P2P virtual machine streaming,"Clouds commonly store Virtual Machine (VM) images on networked storage. This poses a serious potential scalability bottleneck as launching a single fresh VM instance requires, at minimum, several hundred MB of network reads. As this bottleneck occurs most severely during read-intensive launching of new VMs, we focus on scalably minimizing time to boot a VM and load its critical applications.
 While effective scalable P2P streaming techniques for Video on Demand (VOD) scenarios where blocks arrive in-order and at constant rate are available, no techniques address scalable large-executable streaming. VM execution is non-deterministic, divergent, variable rate, and cannot miss blocks. VMTORRENT introduces a novel combination of block prioritization, profile-based execution prefetch, on-demand fetch, and decoupling of VM image presentation from underlying data-stream. VMTORRENT provides the first complete and effective solution to this growing scalability problem that is based on making better use of existing capacity, instead of throwing more hardware at it.
 Supported by analytic modeling, we present comprehensive experimental evaluation of VMTORRENT on real systems at scale, demonstrating the effectiveness of VMTORRENT. We find that VMTORRENT supports comparable execution time to that achieved using local disk. VMTORRENT maintains this performance while scaling to 100 instances, providing up to 11x speedup over current state-of-the-art and 30x over traditional network storage.",2012-12-10,https://www.semanticscholar.org/paper/bf9c8100d311af457c347d0ec6fcdf507fb64f85,Conference on Emerging Network Experiment and Technology
817,Invaluable Feedback from a Superb Team of Requirements Engineers,"There are many obstacles to be overcome before formal methods are accepted as an integral part of the industrial design process. Many papers have been written about the nature of these obstacles. It can be argued convincingly that some of the objections that have been raised are based on misconceptions, or mere myths, about formal methods, e.g., 2]. But beyond these phases of \anger"" and \denial,"" we m a y h a ve reached a point i n t h e d e v elopment of formal methods where we \accept"" the blame and develop new methods that form a better match with existing practice. This paper reports on our attempts to do so. One of the objectives of the early fault detection tools described here and in 1, 4 ] is to ease the transition towards the adoption of more formal design techniques, by accepting that design choices that are made in the early phases of a design are tentative and deliberately incomplete. Demanding that they be rigorous and complete at that stage of the design would be counterproductive. We h a ve argued that this potential handicap can be turned into an advantage. Acknowledgements: The work on early fault detection tools started with MSC, w h i c h w as built in a collaborative eort with my colleagues Rajeev Alur,",,https://www.semanticscholar.org/paper/80f7af29be19cfb514427e1fc4fe7c8076e9cdd9,
161,A Biologically Plausible Parser,"Abstract We describe a parser of English effectuated by biologically plausible neurons and synapses, and implemented through the Assembly Calculus, a recently proposed computational framework for cognitive function. We demonstrate that this device is capable of correctly parsing reasonably nontrivial sentences.1 While our experiments entail rather simple sentences in English, our results suggest that the parser can be extended beyond what we have implemented, to several directions encompassing much of language. For example, we present a simple Russian version of the parser, and discuss how to handle recursion, embedding, and polysemy.",2021-08-04,https://www.semanticscholar.org/paper/e1a6360d8694f3b7e0fbc27b7e0464a91a97d644,Transactions of the Association for Computational Linguistics
1116,Combined limits on WIMPs from the CDMS and EDELWEISS experiments,"The CDMS and EDELWEISS collaborations have combined the results of their direct searches for dark matter using cryogenic germanium detectors. The total data set represents 614  kg·days equivalent exposure. A straightforward method of combination was chosen for its simplicity before data were exchanged between experiments. The results are interpreted in terms of limits on spin-independent weakly interacting, massive particle (WIMP)-nucleon cross section. For a WIMP mass of 90  GeV/c^2, where this analysis is most sensitive, a cross section of 3.3×10^(-44)  cm^2 is excluded at 90% C.L. At higher WIMP masses, the combination improves the individual limits, by a factor 1.6 above 700  GeV/c^2. Alternative methods of combining the data provide stronger constraints for some ranges of WIMP masses and weaker constraints for others.",2011-05-17,https://www.semanticscholar.org/paper/6c0b0205f355c473e75e3e741c749b44b1270164,
792,Analysis of recursive state machines,"Recursive state machines (RSMs) enhance the power of ordinary state machines by allowing vertices to correspond either to ordinary states or to potentially recursive invocations of other state machines. RSMs can model the control flow in sequential imperative programs containing recursive procedure calls. They can be viewed as a visual notation extending Statecharts-like hierarchical state machines, where concurrency is disallowed but recursion is allowed. They are also related to various models of pushdown systems studied in the verification and program analysis communities.After introducing RSMs and comparing their expressiveness with other models, we focus on whether verification can be efficiently performed for RSMs. Our first goal is to examine the verification of linear time properties of RSMs. We begin this study by dealing with two key components for algorithmic analysis and model checking, namely, reachability (Is a target state reachable from initial states?) and cycle detection (Is there a reachable cycle containing an accepting state?). We show that both these problems can be solved in time O(nθ2) and space O(nθ), where n is the size of the recursive machine and θ is the maximum, over all component state machines, of the minimum of the number of entries and the number of exits of each component. From this, we easily derive algorithms for linear time temporal logic model checking with the same complexity in the model. We then turn to properties in the branching time logic CTL*, and again demonstrate a bound linear in the size of the state machine, but only for the case of RSMs with a single exit node.",2001-07-18,https://www.semanticscholar.org/paper/c33a7f02d85e6e17c8509324f8e95483f9db62bb,TOPL
2747,Computer graphics: principles and practice (2nd ed.),,1990-07-01,https://www.semanticscholar.org/paper/49fe743e80c4919bc252b0c01299ffed57a0e5f1,
3398,Parallel Graph Connectivity in Log Diameter Rounds,"Many modern parallel systems, such as MapReduce, Hadoop and Spark, can be modeled well by the MPC model. The MPC model captures well coarse-grained computation on large data — data is distributed to processors, each of which has a sublinear (in the input data) amount of memory and we alternate between rounds of computation and rounds of communication, where each machine can communicate an amount of data as large as the size of its memory. This model is stronger than the classical PRAM model, and it is an intriguing question to design algorithms whose running time is smaller than in the PRAM model. One fundamental graph problem is connectivity. On an undirected graph with n nodes and m edges, O(log n) round connectivity algorithms have been known for over 35 years. However, no algorithms with better complexity bounds were known. In this work, we give fully scalable, faster algorithms for the connectivity problem, by parameterizing the time complexity as a function of the diameter of the graph. Our main result is a O(log D log log_m/n n) time connectivity algorithm for diameter-d graphs, using Θ(m) total memory. If our algorithm can use more memory, it can terminate in fewer rounds, and there is no lower bound on the memory per processor. We extend our results to related graph problems such as spanning forest, finding a DFS sequence, exact/approximate minimum spanning forest, and bottleneck spanning forest. We also show that achieving similar bounds for reachability in directed graphs would imply faster boolean matrix multiplication algorithms. We introduce several new algorithmic ideas. We describe a general technique called double exponential speed problem size reduction which roughly means that if we can use total memory n to reduce a problem from size n to n/k, for k=(N/n)^Θ(1) in one phase, then we can solve the problem in O(loglog_N/n n) phases. In order to achieve this fast reduction for graph connectivity, we use a multistep algorithm. One key step is a carefully constructed truncated broadcasting scheme where each node broadcasts neighbor sets to its neighbors in a way that limits the size of the resulting neighbor sets. Another key step is random leader contraction, where we choose a smaller set of leaders than many previous works do.",2018-05-08,https://www.semanticscholar.org/paper/8b7733d62a1ccde31a309349b1a868a7dd4e3a58,IEEE Annual Symposium on Foundations of Computer Science
3722,Generative Interventions for Causal Learning,"We introduce a framework for learning robust visual representations that generalize to new viewpoints, backgrounds, and scene contexts. Discriminative models often learn naturally occurring spurious correlations, which cause them to fail on images outside of the training distribution. In this paper, we show that we can steer generative models to manufacture interventions on features caused by confounding factors. Experiments, visualizations, and theoretical results show this method learns robust representations more consistent with the underlying causal relationships. Our approach improves performance on multiple datasets demanding out-of-distribution generalization, and we demonstrate state-of-the-art performance generalizing from ImageNet to ObjectNet dataset.",2020-12-22,https://www.semanticscholar.org/paper/945aa2eb4b7ceecebf0562dfc12fcadb8fd38970,Computer Vision and Pattern Recognition
2737,Generating customized text and graphics in the COMET explanation testbed,"It is shown how COMET, a system that uses natural language and graphics generation components to produce the text and pictures of its explanations dynamically, can create a variety of different explanations to explain the same concepts, and thus better meets the needs of different users. The authors focus on four ways in which COMET produces different explanations for the same concepts, describing how it is influenced by the plan containing the concept, by user background knowledge, by previous dialogue, and by interactive exploration of an explanation.<<ETX>>",1991-12-01,https://www.semanticscholar.org/paper/2d40e59c3c8bbc3194200d2a1d2c513cd4a0695e,Winter simulation conference : proceedings
2064,Economic analysis of 450mm wafer migration,"To achieve the required continuous cost reduction driven by Moore's Law, both miniaturization through technology advances and wafer size increase have been employed in order to maintain the growth and profitability of semiconductor industry. Although some technical analyses have been done for 450 mm migration, little research has been done on economic analysis to justify the decisions and thus suggest appropriate timing for 450 mm migration. This study aims to fill the gap by proposing a preliminary economic analysis to clarify some myths and facilitate further discussions concerning collaborations among the stakeholders including equipment vendors, customers, and chipmakers.",2007-10-01,https://www.semanticscholar.org/paper/68e6c40bd71c6615ce9045830562d376f00f9e5c,International Symposium on Semiconductor Manufacturing
2704,Virtual Reality Unbound,"Virtual reality involves a compelling vision: using computers to create three-dimensional environments that immerse the user in application-specific objects. These objects have a strong sense of spatial presence, and have programmed appearances and behaviors tailored to the virtual environment's task. What could be more compelling than an environment you ""step into,"" specially built for your 3D task?",1995-09-01,https://www.semanticscholar.org/paper/ccf9afcdba238d302d35ec90c25a30a998d2dc69,
456,Optimal Information Delivery,,1995-12-04,https://www.semanticscholar.org/paper/a1b40a67999e055bb2e625730e9d23d1235f8b1d,International Symposium on Algorithms and Computation
2211,Mucocutaneous manifestations in a UK national cohort of juvenile-onset systemic lupus erythematosus patients.,"OBJECTIVE
To determine whether mucocutaneous manifestations are associated with major organ involvement in a UK national cohort of juvenile-onset SLE (JSLE) patients.


METHODS
JSLE patients (n = 241) from 15 different centres whose diagnosis fulfilled four or more of the ACR criteria were divided into two groups: those with at least one ACR mucocutaneous criterion (ACR skin feature positive) and those without (ACR skin feature negative) at diagnosis. The relative frequency of skin involvement was described by the paediatric adaptation of the 2004 British Isles Lupus Assessment Group (pBILAG-2004) index.


RESULTS
One hundred and seventy-nine patients (74%) had ACR-defined skin involvement with no significant demographic differences compared with those without. ACR skin feature negative patients showed greater haematological (84% vs 67%), renal (43% vs 26%) (P < 0.05) and neurological (16% vs 4%) involvement (P = 0.001). Forty-two per cent of ACR skin feature negative patients had skin involvement using pBILAG-2004, which included maculopapular rash (17%), non-scaring alopecia (15%), cutaneous vasculitis (12%) and RP (12%). ACR skin feature negative patients with moderate to severe skin involvement by pBILAG-2004 showed greater renal and haematological involvement at diagnosis and over the follow-up period (P < 0.05). Higher immunosuppressive drug use in the skin feature negative group was demonstrated.


CONCLUSION
Patients who fulfil the ACR criteria but without any of the mucocutaneous criteria at diagnosis have an increased risk of major organ involvement. The pBILAG-2004 index has shown that other skin lesions may go undetected using the ACR criteria alone, and these lesions show a strong correlation with disease severity and major organ involvement.",2014-08-01,https://www.semanticscholar.org/paper/b5433cb8f1996b7666a4cfd9cec0aa54c6f64425,Rheumatology
892,On a Class of Totally Unimodular Matrices,"We examine the class of totally unimodular matrices-that contain no odd cycles, which we call restricted totally unimodular RTUM. We show that a matrix is RTUM if and only if it can be decomposed in a very simple way into the incidence matrices or their transposes of bipartite graphs or directed graphs, and give a linear time algorithm to perform this task. Based on this decomposition, we show that the 0,1 Integer Programming Problem with an RTUM matrix of constraints has the same time complexity as the b-matching and the max flow problems.",1985-05-01,https://www.semanticscholar.org/paper/22bf0037f688b2d68a3bed9be3f03e1b11b8a1b7,Mathematics of Operations Research
3339,13. Ecology and Sociality in Horses and Zebras,,1987-12-31,https://www.semanticscholar.org/paper/39cf1d953590b9b6f026d056906734a5aaf5a63b,
1988,Hybrid Genetic Algorithms for Solving Reentrant Flow-Shop Scheduling with Time Windows,"The semiconductor industry has grown rapidly, and subsequently production planning problems have raised many important research issues. The reentrant flow-shop (RFS) scheduling problem with time windows constraint for harddisk devices (HDD) manufacturing is one such problem of the expanded semiconductor industry. The RFS scheduling problem with the objective of minimizing the makespan of jobs is considered. Meeting this objective is directly related to maximizing the system throughput which is the most important of HDD industry requirements. Moreover, most manufacturing systems have to handle the quality of semiconductor material. The time windows constraint in the manufacturing system must then be considered. In this paper, we propose a hybrid genetic algorithm (HGA) for improving chromosomes/offspring by checking and repairing time window constraint and improving offspring by leftshift routines as a local search algorithm to solve effectively the RFS scheduling problem with time windows constraint. Numerical experiments on several problems show that the proposed HGA approach has higher search capability to improve quality of solutions.",2013-12-31,https://www.semanticscholar.org/paper/e40d0f1f81246af0990bce0b8e57cbe448ba5389,
2622,9 Chapter Nine Mobile Augmented Reality,"As computers increase in power and decrease in size, new mobile, wearable, and pervasive computing applications are rapidly becoming feasible, providing people access to online resources always and everywhere. This new flexibility makes possible new kind of applications that exploit the person's surrounding context. Augmented reality (AR) presents a particularly powerful user interface (UI) to context-aware computing environments. AR systems integrate virtual information into a person's physical environment so that he or she will perceive that information as existing in their surroundings. Mobile augmented reality systems (MARS) provide this service without constraining the individual’s whereabouts to a specially equipped area. Ideally, they work virtually anywhere, adding a palpable layer of information to any environment whenever desired. By doing so, they hold the potential to revolutionize the way in which information is presented to people. Computer-presented material is directly integrated with the real world surrounding the freely roaming person, who can interact with it to display related information, to pose and resolve queries, and to collaborate with other people. The world becomes the user interface. This chapter provides a detailed introduction to mobile AR technology with in-depth reviews of important topics, such as wearable display and computing hardware, tracking, registration, user interaction, heterogeneous UIs, collaboration, and UI management for situated computing. As part of this introduction, we define what we mean by augmented reality, give a brief overview of the history of the field in general, and review some important mobile AR system considerations. Section 9.2 discusses the potential and possibilities of MARS technology, with a detailed overview of prototype application areas, and reviews the challenges that impede immediate widespread commercial adoption. In Section 9.3 we take a closer look at the requirements and specific components of MARS, before examining UI concepts in Section 9.4. We conclude the chapter with an outlook on research directions.",,https://www.semanticscholar.org/paper/8dbdd436b2a6aa43dee83dbd21dcaf6970e98a0d,
398,Sharing the cost of muliticast transmissions (preliminary version),,,https://www.semanticscholar.org/paper/9f067319d7a709a6dbebbc9941c5cdc81e9c2417,Symposium on the Theory of Computing
2975,Gaussian Process Regression Networks Supplementary Material,"In this supplementary material, we discuss some further details of our ESS and VB inference (Sections 1 and 2), the computational complexity of our inference procedures (Section 3), and the correlation structure induced by the GPRN model (Section 4). We also discuss multimodality in the GPRN posterior (Section 5), SVLMC, and some background information and notation for Gaussian process regression (Section 7). Figure 1 shows the network structure of GPRN learned on the JURA dataset.",,https://www.semanticscholar.org/paper/51c515b78d9559a1e3d32558dab7327891996936,
1888,UNISON data-driven intermittent demand forecast framework to empower supply chain resilience and an empirical study in electronics distribution,,2019-09-01,https://www.semanticscholar.org/paper/0af15eaf9abb97e1e758a3a4d8a23fa138a11904,Computers & industrial engineering
2538,Prototyping an Outdoor Mobile Augmented Reality Street View Application,"We describe the early development of an experimental outdoor mobile augmented reality (AR) application, ―AR street view,‖ running on a Google Android Dev Phone 1. This project addresses the design of interaction and visualization techniques for AR user interfaces on mobile phones. Our experience suggests that usability is compromised by a variety of issues, including tracking and registration errors caused by the relatively inaccurate GPS and orientation sensor, the need to hold the phone away from the body in potentially awkward poses, and the relatively small field of view covered by the display and camera.",,https://www.semanticscholar.org/paper/ec2003ca12fdd33c0fe4fd45920305369a127bf2,
150,AVENUE: Automated site modeling in urban environments,This paper is an overview of the AVENUE project at Columbia University. AVENUE's main goal is to automate the site modeling process in urban environments. The first component of AVENUE is a 3-D modeling system which constructs complete 3-D geometric models with photometric texture mapping acquired from different viewpoints. The second component is a planning system that plans the Next-Best-View for acquiring a model of the site. The third component is a mobile robot we have built that contains an integrated sensor suite for automatically performing the site modeling task. We present results for modeling buildings in New York City.,2001-05-28,https://www.semanticscholar.org/paper/862967da1feb15fc9dcfd9a6a1e61f9821fa0ece,Proceedings Third International Conference on 3-D Digital Imaging and Modeling
2736,Authoring Large Hypermedia Documents with IGD,"SUMMARY The IGD (Interactive Graphical Documents) hypermedia system was designed to make possible interactive presentations that can be explored by and customized for individual users. We describe IGD’s authoring facilities through an annotated excerpt from an editing session, emphasizing how the system’s document model and user interface help support the creation of large documents. Although we feel that IGD successfully addressed some of the issues of scale, experience with the system has convinced us that it is wrong to cast many of the problems of authoring large hypertexts as ones that can be solved by implementing editors of sufficient scope and sophistication. We believe that hypertext design systems based on direct editing of documents inherit many of the bottlenecks associated with the conventional document authoring process. These problems are compounded by the added intellectual burden of designing a connective structure of keyworded links. We contrast the reality of the author-centered, editor-based approach to document design and layout, exemplified by IGD, with the promise of a knowledge-based, automated alternative, and discuss why we feel that many of the facilities provided by IGD will still be useful even if presentations can be created entirely automatically.",1991-01-02,https://www.semanticscholar.org/paper/27e2a38eceaa51cafa84baf6199fb96c8ea9ac44,Electronic publishing
2708,Research issues in perception and user interfaces,"Current visualization tools are capable but still require too much visualization knowledge on the user's part. This requirement restricts the user in what is possible. Nor do the tools take account of what is known regarding cognition and perception. The authors focus at on three things: presentation of information to best match human cognitive and perceptual capabilities, interactive tools and systems to facilitate creation and navigation of visualizations, and software system features to improve visualization tools.<<ETX>>",1994-03-01,https://www.semanticscholar.org/paper/bb12239125e436f3d4e4bd4864c4a653cae49c4e,IEEE Computer Graphics and Applications
2948,Batch effects and the effective design of single-cell gene expression studies,,2016-07-08,https://www.semanticscholar.org/paper/61bc0578a8d2e94f745aa9c26501872e3ab51281,Scientific Reports
3405,16. Greedy-Algorithmen,,2017-01-31,https://www.semanticscholar.org/paper/f6cb7b97527f97d93340ec20abc9bf59df2b877d,
341,Global Synchronization in Sensornets,,2004-04-05,https://www.semanticscholar.org/paper/0c334fd5dd371a36390117910372b189045fdc77,Latin American Symposium on Theoretical Informatics
2006,Decision support system for rehabilitation scheduling to enhance the service quality and the effectiveness of hospital resource management,"In hospitals, rehabilitation inpatients often complain about long waiting time between the therapeutic processes. Due to the partial precedence constraints of rehabilitation therapies, the rehabilitation scheduling problem is a hybrid shop scheduling problem. This article aims to construct a decision support system for rehabilitation scheduling. Equipped with the developed genetic algorithm, this system can generate the optimal schedules for rehabilitation patients to minimize waiting time and thus enhance service quality and overall resource effectiveness of rehabilitation facilities. The developed system is also equipped with GUI (graphical user interfaces) to provide scheduling information including Gantt charts and scheduling lists to support various users including therapists and inpatients. We conducted an empirical study in a general hospital for validation. The results showed that the waiting time of each inpatient is reduced significantly and thus demonstrated the practical viability of the proposed solution to enhance the effectiveness of hospital resource management. The developed system has been implemented online in the hospital.",2012-07-01,https://www.semanticscholar.org/paper/fe7ae54de30cf1a570dcc95c61054f0596f0ab08,
286,The Search for Equilibrium Concepts,,2008-04-30,https://www.semanticscholar.org/paper/4cfee2549f408f62e675a29e514a4650bfdc3fe3,Algorithmic Game Theory
260,Complexity of Efficiency-Revenue Trade-offs in Bayesian Auctions,"When agents with independent priors bid for a single item, Myerson’s optimal auction maximizes expected revenue, whereas Vickrey’s second-price auction optimizes social welfare. We address the natural question of trade-offs, auctions that optimize revenue without losing too much welfare, say. If one allows for randomized mechanisms, it is easy to see that there are polynomial-time mechanisms that achieve any point in the trade-off (the Pareto curve) between revenue and welfare. We ask the question of whether one can achieve the same guarantees using deterministic mechanisms. We provide a negative answer to this question by showing that this is a weakly NP-hard problem. On the positive side, we provide polynomial-time deterministic mechanisms that approximate with arbitrary precision any point of the trade-off between these two fundamental objectives for the case of two bidders, even when the valuations are correlated arbitrarily. The major problem left open by our work is whether there is such an algorithm for independent valuation distributions and three or more bidders.",,https://www.semanticscholar.org/paper/ea985f90e7626b46809aff77b8c1a00092556cff,
962,Case report: what gives the myopic tilted disc an oval appearance?,,2020-01-09,https://www.semanticscholar.org/paper/0e4cdddec3cba9176f6719b2560b5d09cc05b1ef,BMC Ophthalmology
502,Optimal coteries,"In a network processors may faiL It is desirable that the surviving nodes continue to operate, but no two disjoint partitions operate independently. One SOIUtion for this problem is based on the notion of coteries. A coterie is a family of sets of nodes such that any two sets in the family intersect. in the protocol implied by a coterie, a connected subgraph of the network functions if its set of nodes contains one of the sets in the family. One simple way to implement coteries is by voting. We study the following problem: Given a network with weigh ts, find the coterie that maximizes the expected number of operating nodes. We show that this problem, although hopelessly intractable in general, can be solved when the network is a cactus (all biconnected components are either edges or cycles). Even the case of a cycle with equal probabilities and weights is quite nontrivial and interesting.",1991-07-01,https://www.semanticscholar.org/paper/a52ee366a2ffd7d26af1d8ad9b438d3512917934,ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing
3372,Examination of the Agonistic Behaviour of the Crayfish Orconectes Virilis By Character Analysis,"The agonistic behavior of the crayfish Orconectes virilis was observed in the laboratory, with attention to the effects of size, past experience, and displays. Character analysis was utilized to quantify the relative importance of these three factors. I) In short fights, larger animals and animals which had won previous fights had a decided advantage. 2) In long fights, size and past experience seemed to have little influence on who would win. 3) Initiating an interaction gave an animal and advantage in short fights or when both were the same size. 4) Model presentations indicated that postures assumed during fights were effective visual stimuli and that the white areas on appendages are important components of displays. 5) The greatest reduction in uncertainty concerning which behavior pattern would occur at any time in a fight came from knowing the just previous act of the other crayfish. 6) The amount of information transmitted from one crayfish to another by displays increased during fights to a peak of 160 bits (53% uncertainty reduction) in the middle of fights. 7) Partitioning the data into long or short fights and into initiator-won or defender-won fights increased the apparent importance of inter-animal communication.",,https://www.semanticscholar.org/paper/2d2aac0d441833578c8999ed370b7e24caf4ceea,
2012,A two-stage stochastic programming approach for new tape-out allocation decisions for demand fulfillment planning in semiconductor manufacturing,,2011-07-26,https://www.semanticscholar.org/paper/3c93ca2e846a676f2de656ac98ba5f977bfb7820,Flexible Services and Manufacturing Journal
1730,Mixed Membership Models,,,https://www.semanticscholar.org/paper/235721e4e986d5dc5e00a2e0431ffeabd8d3ea0f,
3241,"Wildbook: Crowdsourcing, computer vision, and data science for conservation","Photographs, taken by field scientists, tourists, automated cameras, and incidental photographers, are the most abundant source of data on wildlife today. Wildbook is an autonomous computational system that starts from massive collections of images and, by detecting various species of animals and identifying individuals, combined with sophisticated data management, turns them into high resolution information database, enabling scientific inquiry, conservation, and citizen science. 
We have built Wildbooks for whales (flukebook.org), sharks (whaleshark.org), two species of zebras (Grevy's and plains), and several others. In January 2016, Wildbook enabled the first ever full species (the endangered Grevy's zebra) census using photographs taken by ordinary citizens in Kenya. The resulting numbers are now the official species census used by IUCN Red List: this http URL In 2016, Wildbook partnered up with WWF to build Wildbook for Sea Turtles, Internet of Turtles (IoT), as well as systems for seals and lynx. Most recently, we have demonstrated that we can now use publicly available social media images to count and track wild animals. 
In this paper we present and discuss both the impact and challenges that the use of crowdsourced images can have on wildlife conservation.",2017-10-24,https://www.semanticscholar.org/paper/8e0ca63bfb804a2f865caf4c0cfdb2ec6fc73216,arXiv.org
1313,Search for neutral Higgs bosons decaying to tau pairs in p anti-p collisions at s**(1/2) = 1.96-TeV,"A search for the production of neutral Higgs bosons {Phi} decaying into {tau}{sup +}{tau}{sup -} final states in p{bar p} collisions at a center-of-mass energy of 1.96 TeV is presented. The data, corresponding to an integrated luminosity of approximately 325 pb{sup -1}, were collected by the D0 experiment at the Fermilab Tevatron Collider. Since no excess compared to the expectation from standard model processes is found, limits on the production cross section times branching ratio are set. The results are combined with those obtained from the D0 search for {Phi}b({bar b}) {yields} b{bar b}b({bar b}) and are interpreted in the minimal supersymmetric standard model.",2006-05-01,https://www.semanticscholar.org/paper/5624c861808e86f51c0cb51c44c00fe8f23e26a4,
1831,Statistical discovery of signaling pathways from an ensemble of weakly informative data sources,"Brief introduction. Signaling pathways are complex biological mechanisms. For instance, consider the Mitogen-activated protein (MAP) kinase pathway, available on Kyoto Encyclopedia of Genes and Genomes (KEGG) (Kanehisa et al., 2006). It involves 55 genes/proteins, it sub-divides into four interconnected modules (pheromone response, high osmolarity glycerol response, hypotonic shock response, and starvation response), and their circuitry is currently instantiated by 104 directed interactions with various meanings (e.g. activation, phosphorylation, binding, and inhibition)",,https://www.semanticscholar.org/paper/cf69a1ef575077115e3542bebf975666f7884845,
1582,Model-based Classification,"• A probability model is a joint distribution of a set of observations. • Often, a model is indexed by a parameter. Each value of the parameter gives a different distribution of the data. – The parameter of a Bernoulli is the probability of heads. – The parameters of a Gaussian are its mean and variance. • Many models (but not all) assume the data are independent and identically distributed. N n=1 p (x i | π). (1) Each term is a Bernoulli, p (x n | π) = π 1(x n =h) (1 − π) 1(x n =t) (2) • Suppose we flip a coin N times and record the outcomes. • Further suppose that we think that the probability of heads is π. (This is distinct from whatever the probability of heads "" really "" is.)",2019-07-31,https://www.semanticscholar.org/paper/e1a868d2782fa8756433661e21771517f7960e5c,Model-Based Clustering and Classification for Data Science
3767,Goals Inferring the Why in Images,"Humans have the remarkable capability to infer the motivations of other people’s actions, likely due to cognitive skills known in psychophysics as the theory of mind. In this paper, we strive to build a computational model that predicts the motivation behind the actions of people from images. To our knowledge, this challenging problem has not yet been extensively explored in computer vision. We present a novel learning based framework that uses high-level visual recognition to infer why people are performing an actions in images. However, the information in an image alone may not be sufficient to automatically solve this task. Since humans can rely on their own experiences to infer motivation, we propose to give computer vision systems access to some of these experiences by using recently developed natural language models to mine knowledge stored in massive amounts of text. While we are still far away from automatically inferring motivation, our results suggest that transferring knowledge from language into vision can help machines understand why a person might be performing an action in an image.",,https://www.semanticscholar.org/paper/8073bb5b5d26430c3d6ca55504c7c224a69736f0,
3375,"Insecticide Residues, Residue Analysis of a Chlorinated Insecticide (Thiodan) by Combination of Gas Chromatography and infrared Spectrophotometry",,1960-05-01,https://www.semanticscholar.org/paper/87cd79ffbca00388e0e05691a45cf9cff3ede43d,
1024,Extensions of the Principal Fiber Bundle Model for Locomoting Robots,"Our goal is to establish a rigorous formulation for modeling the locomotion of a broad class of robotic systems. Recent research has identifi?ed a number of systems with the structure of a principal ?fiber bundle. This framework has led to a number of tools for analysis and motion planning applicable to various robotic confi?gurations in diff?erent environments, but it also requires a number of assumptions that limit its usefulness to certain \idealized"" systems. Systems that cannot be fully described with a principal fi?ber bundle or cannot make full use of the subsequent tools include those whose joints are not fully controllable, those with control inputs or dynamics external to their mechanism, and those whose external con?figurations do not forma symmetry group. In addition, the motion planning techniques derived from this structure have traditionally assumed a mapping from internal joint confi?gurations toexternal position con?figurations. The reverse of this mapping will be discussed in this thesis, as well as the analysis and solutions for problems violating each of the aboveassumptions in turn. For each case, we introduce one or two motivating examples of robotic systems and discuss novel locomotive characteristics that do not previouslyappear under the standard assumptions. This thesis expands the applicability of the principal ?fiber bundle model, as well as derivative tools for analysis and motionplanning, to a larger variety of locomoting systems.",2018-08-01,https://www.semanticscholar.org/paper/a38988f7e11dfa96169d03242b2e1ca8a213da67,
1310,"Characterization, performance, and future advanced analysis of detectors in the cryogenic dark matter search (CDMS-II)",,2006-04-15,https://www.semanticscholar.org/paper/3c353827dca88793a33ef3117d8c029049c1f156,
3156,SMART UNIX SVR4 support for multimedia applications,"Multimedia applications have dynamic and adaptive real-time requirements. Current scheduling practice, as typified by UNIX System V Release 4, lacks the necessary information and interfaces to meet these requirements. To address this problem, we have created the SMART (Scheduler for Multimedia And Real-Time) interface. It explicitly accounts for application-specific time constraints and provides dynamic feedback from the scheduler to applications to allow them to adapt to the system loading condition. This paper describes the design of the interface and its implementation in the Solaris UNIX operating system to provide an effective SVR4-conformant full featured environment for supporting multimedia applications.",1997-06-03,https://www.semanticscholar.org/paper/d7693012c522efbdc59f784214b711836048f58e,Proceedings of IEEE International Conference on Multimedia Computing and Systems
2821,Galectin-3 preserves renal tubules and modulates extracellular matrix remodeling in progressive fibrosis.,"Renal tubular cell apoptosis is a critical detrimental event that leads to chronic kidney injury in association with renal fibrosis. The present study was designed to investigate the role of galectin-3 (Gal-3), an important regulator of multiple apoptotic pathways, in chronic kidney disease induced by unilateral ureteral obstruction (UUO). After UUO, Gal-3 expression significantly increased compared with basal levels reaching a peak increase of 95-fold by day 7. Upregulated Gal-3 is predominantly tubular at early time points after UUO but shifts to interstitial cells as the injury progresses. On day 14, there was a significant increase in TdT-mediated dUTP nick end labeling-positive cells (129%) and cytochrome c release (29%), and a decrease in BrdU-positive cells (62%) in Gal-3-deficient compared with wild-type mice. The degree of renal damage was more extensive in Gal-3-deficient mice at days 14 and 21, 35 and 21% increase in total collagen, respectively. Despite more severe fibrosis, myofibroblasts were significantly decreased by 58% on day 14 in the Gal-3-deficient compared with wild-type mice. There was also a corresponding 80% decrease in extracellular matrix synthesis in Gal-3-deficient compared with wild-type mice. Endo180 is a recently recognized receptor for intracellular collagen degradation that is expressed by interstitial cells during renal fibrogenesis. Endo180 expression was significantly decreased by greater than 50% in Gal-3-deficient compared with wild-type mice. Taken together, these results suggested that Gal-3 not only protects renal tubules from chronic injury by limiting apoptosis but that it may lead to enhanced matrix remodeling and fibrosis attenuation.",,https://www.semanticscholar.org/paper/756bfc6688fc0663efbffb152bda0c586886638e,AJP - Renal Physiology
108,Database research at Columbia University,"Columbia University has a number of projects that touch on database systems issues. In this report, we describe the Columbia Fast Query Project (Section 2), the JAM project (Section 3), the CARDGIS project (Section 4), the Columbia Internet Information Searching Project (Section 5), the Columbia Content-Based Visual Query project (Section 6), and projects associated with Columbia's Programming Systems Laboratory (Section 7).",1998-09-01,https://www.semanticscholar.org/paper/0d862a75271c152537ec41e24cbf5b0cd645a41e,SGMD
1150,Search for weakly interacting massive particles with the first five-tower data from the cryogenic dark matter search at the soudan underground laboratory.,"We report results from the Cryogenic Dark Matter Search at the Soudan Underground Laboratory (CDMS II) featuring the full complement of 30 detectors. A blind analysis of data taken between October 2006 and July 2007 sets an upper limit on the weakly interacting massive particle (WIMP) nucleon spin-independent cross section of 6.6x10;{-44} cm;{2} (4.6x10;{-44} cm;{2} when combined with previous CDMS II data) at the 90% confidence level for a WIMP mass of 60 GeV/c;{2}. This achieves the best sensitivity for dark matter WIMPs with masses above 44 GeV/c;{2}, and significantly restricts the parameter space for some favored supersymmetric models.",2009-01-05,https://www.semanticscholar.org/paper/3a62e29c0d7f3489a89a8fa181427ef05476f5f7,Physical Review Letters
3234,An Assessment of Tree Availability as a Possible Cause of Population Declines in Scavenging Raptors,"Lack of suitable nesting trees is an increasingly common issue for avian conservation given rampant habitat and tree destruction around the world. In the African savannah, habitat loss and particularly tree damage caused by elephants have been suggested as possible factors in the decline of large bird species. Given the recent declines of vultures and other scavenging raptors, it is critical to understand if nest availability is a limiting factor for these threatened populations. Loss of woodland, partially due to elephant populations, has been reported for the Mara-Serengeti ecosystem. Data on characteristics of trees used for nesting were collected for White-backed, Lappet-faced, White-headed vulture, and Tawny eagle nests in Masai Mara National Reserve, Kenya. Nest tree characteristics were compared with the distribution of a random subsample of trees to assess nest preferences and determine suitability of available trees. Nearest neighbor distances were estimated as well as availability of preferred nesting trees to determine if tree availability is a limiting factor for tree-nesting vultures. Tree availability was found to greatly exceed nesting needs for African vultures and Tawny eagles. We thus conclude that on a landscape scale, tree availability is not a limiting factor for any of the species considered here (White-backed, Lappet-faced, White-headed vultures, and Tawny eagles).

This article is protected by copyright. All rights reserved.",,https://www.semanticscholar.org/paper/ec7d1cd1e1305ac200dedea4feae82e46a0105d7,
1716,Content-based recommendations with Poisson factorization,"We develop collaborative topic Poisson factorization (CTPF), a generative model of articles and reader preferences. CTPF can be used to build recommender systems by learning from reader histories and content to recommend personalized articles of interest. In detail, CTPF models both reader behavior and article texts with Poisson distributions, connecting the latent topics that represent the texts with the latent preferences that represent the readers. This provides better recommendations than competing methods and gives an interpretable latent space for understanding patterns of readership. Further, we exploit stochastic variational inference to model massive real-world datasets. For example, we can fit CPTF to the full arXiv usage dataset, which contains over 43 million ratings and 42 million word counts, within a day. We demonstrate empirically that our model outperforms several baselines, including the previous state-of-the art approach.",2014-12-08,https://www.semanticscholar.org/paper/d01508b7f10468b47712cfdc19c028997b541dd1,Neural Information Processing Systems
1503,Search for Third Generation Scalar Leptoquarks Decaying into B,,,https://www.semanticscholar.org/paper/690e824f26723d4aaab50e22d985b511442aaf21,
219,Strategic Classification,"Machine learning relies on the assumption that unseen test instances of a classification problem follow the same distribution as observed training data. However, this principle can break down when machine learning is used to make important decisions about the welfare (employment, education, health) of strategic individuals. Knowing information about the classifier, such individuals may manipulate their attributes in order to obtain a better classification outcome. As a result of this behavior -- often referred to as gaming -- the performance of the classifier may deteriorate sharply. Indeed, gaming is a well-known obstacle for using machine learning methods in practice; in financial policy-making, the problem is widely known as Goodhart's law. In this paper, we formalize the problem, and pursue algorithms for learning classifiers that are robust to gaming. We model classification as a sequential game between a player named ""Jury"" and a player named ""Contestant."" Jury designs a classifier, and Contestant receives an input to the classifier drawn from a distribution. Before being classified, Contestant may change his input based on Jury's classifier. However, Contestant incurs a cost for these changes according to a cost function. Jury's goal is to achieve high classification accuracy with respect to Contestant's original input and some underlying target classification function, assuming Contestant plays best response. Contestant's goal is to achieve a favorable classification outcome while taking into account the cost of achieving it. For a natural class of ""separable"" cost functions, and certain generalizations, we obtain computationally efficient learning algorithms which are near optimal, achieving a classification error that is arbitrarily close to the theoretical minimum. Surprisingly, our algorithms are efficient even on concept classes that are computationally hard to learn. For general cost functions, designing an approximately optimal strategy-proof classifier, for inverse-polynomial approximation, is NP-hard.",2015-06-23,https://www.semanticscholar.org/paper/81fd20c2b903d979075e0c6a59258b0a84213095,Information Technology Convergence and Services
2275,Synovial fluid neutrophils transcribe and express class II major histocompatibility complex molecules in rheumatoid arthritis.,"OBJECTIVE
To investigate a potential interaction between neutrophils and T cells in rheumatoid arthritis (RA), by defining the optimal conditions for induction of class II major histocompatibility complex (MHC) expression on peripheral blood neutrophils in vitro and investigating the capacity for neutrophils to express class II MHC molecules in RA.


METHODS
Surface expression of class II MHC and costimulatory molecules by peripheral blood and synovial fluid (SF) neutrophils obtained from healthy controls and patients with RA was measured by flow cytometry and fluorescence microscopy. Intracellular class II MHC protein and messenger RNA (mRNA) were detected by Western blotting and Northern blotting, respectively.


RESULTS
Freshly isolated peripheral blood neutrophils from controls did not express surface class II MHC; expression was induced by culture with appropriate cytokines. Freshly isolated peripheral blood neutrophils from patients with RA expressed mRNA, but there was no surface expression of class II MHC. Freshly isolated SF neutrophils from patients with RA contained high levels of class II MHC mRNA, did not express surface class II MHC, but did have large intracellular amounts of this protein as detected by Western blotting. After culture for 20 hours in vitro, SF neutrophils from RA patients expressed large amounts of surface class II MHC but very low levels of costimulatory molecules CD80 and CD86. Fluorescence microscopy localized surface class II MHC to discrete areas on the neutrophil. Class II MHC-expressing neutrophils stimulated T cell proliferation.


CONCLUSION
Peripheral blood neutrophils from patients with RA but not healthy controls express class II MHC mRNA. SF neutrophils in RA synthesize and express large amounts of class II MHC but not costimulatory molecules. This might underlie a novel interaction with T cells that is important in terms of disease pathology.",2003-10-01,https://www.semanticscholar.org/paper/dd8c82f8f0dba5dda5a1b98b97a8450387d07bfd,Arthritis & Rheumatism
3294,A Social Networks Approach to Sheep Movement and Leadership,"Networks of interactions based on social associations and movement offer insights into group organization and dynamics, and provide unique tools for biologists. An important topic in animal social behavior is how individual differences drive group behaviors and shape collective decisions. The identity of influential individuals may vary by behavioral context – one individual may lead group movements, while another influences group consolidation when subgroups disperse. Therefore, identifying influential individuals and determining how they exert influence is not a trivial task. Social network analysis helps biologists understand group structure, movement, and the spread of information.",,https://www.semanticscholar.org/paper/9d448ef5078a989005bbc36b488bdc0a29f0f64a,
1543,Posterior Predictive Null Checks,"Bayesian model criticism is an important part of the practice of Bayesian statistics. Traditionally, model criticism methods have been based on the predictive check, an adaptation of goodness-of-fit testing to Bayesian modeling and an effective method to understand how well a model captures the distribution of the data. In modern practice, however, researchers iteratively build and develop many models, exploring a space of models to help solve the problem at hand. While classical predictive checks can help assess each one, they cannot help the researcher understand how the models relate to each other. This paper introduces the posterior predictive null check (PPN), a method for Bayesian model criticism that helps characterize the relationships between models. The idea behind the PPN is to check whether data from one model’s predictive distribution can pass a predictive check designed for another model. This form of criticism complements the classical predictive check by providing a comparative tool. A collection of PPNs, which we call a PPN study, can help us understand which models are equivalent and which models provide different perspectives on the data. With mixture models, we demonstrate how a PPN study, along with traditional predictive checks, can help select the number of components by the principle of parsimony. With probabilistic factor models, we demonstrate how a PPN study can help understand relationships between different classes of models, such as linear models and models based on neural networks. Finally, we analyze data from the literature on predictive checks to show how a PPN study can improve the practice of Bayesian model criticism. Code to replicate the results in this paper is available at https://github.com/gemoran/ppn-code.",,https://www.semanticscholar.org/paper/6fb0a646bc4d62fb103a2702e4e5ca3c484e3c3f,
1510,A Measurement of the Total Hadronic Cross Section in Tagged 77 Reactions *,"We present a measurement of the total cross section for yy + hadrons, with one photon quasi-real and the other a spacelike photon of mass-squared-Q2. Results are presented as a function of Q2 and the yy center-of-mass energy W, with the Q2 range extending from 0.2 GeV2 to 60 GeV2, and W in the range from 2 to 10 GeV. The data were taken with the TPC/T wo-Gamma facility at the SLAC eSe-storage ring PEP, which was operated at a beam energy of 14.5 GeV. The cross section exhibits a gentle fall-off with increasing W. Its Q2-dependence is shown to be well-described by an incoherent sum of vector-meson and point-like scattering over most of the observed W range. Agreement at high Q2 is improved if a minimum pT cutoff (motivated by &CD) is imposed on the point-like contribution.",,https://www.semanticscholar.org/paper/f09f4a8348ca93b75e86fd2be7a7d23c8febca66,
3584,Programming: Principles and Practice Using C++,"An Introduction to Programming by the Inventor of C++ Preparation for Programming in the Real World The book assumes that you aim eventually to write non-trivial programs, whether for work in software development or in some other technical field. Focus on Fundamental Concepts and Techniques The book explains fundamental concepts and techniques in greater depth than traditional introductions. This approach will give you a solid foundation for writing useful, correct, maintainable, and efficient code. Programming with Todays C++ The book is an introduction to programming in general, including object-oriented programming and generic programming. It is also a solid introduction to the C++ programming language, one of the most widely used languages for real-world software. The book presents modern C++ programming techniques from the start, introducing the C++ standard library to simplify programming tasks. For BeginnersAnd Anyone Who Wants to Learn Something New The book is primarily designed for people who have never programmed before, and it has been tested with more than 1,000 first-year university students. However, practitioners and advanced students will gain new insight and guidance by seeing how a recognized master approaches the elements of his art. Provides a Broad View The first half of the book covers a wide range of essential concepts, design and programming techniques, language features, and libraries. Those will enable you to write programs involving input, output, computation, and simple graphics. The second half explores more specialized topics, such as text processing and testing, and provides abundant reference material. Source code and support supplements are available from the authors website.",2008-12-25,https://www.semanticscholar.org/paper/d1f73d7c073c8c5547082001cf5c6db156ac479c,
1260,Study of DirectViolation inDecays,,2008-05-30,https://www.semanticscholar.org/paper/dc821a75e1e7eccc9390d1095f5df318da5fd5ce,
714,The Complexity of Non-Monotone Markets,"We introduce the notion of non-monotone utilities, which covers a wide variety of utility functions in economic theory. We then prove that it is PPAD-hard to compute an approximate Arrow-Debreu market equilibrium in markets with linear and non-monotone utilities. Building on this result, we settle the long-standing open problem regarding the computation of an approximate Arrow-Debreu market equilibrium in markets with CES utility functions, by proving that it is PPAD-complete when the Constant Elasticity of Substitution parameter ρ is any constant less than − 1.",2017-06-16,https://www.semanticscholar.org/paper/2146eccff3191925e04d883a705a15ec0ff0aa8c,
1372,Measurement of the Lambda0b lifetime in the decay lambda0b--> J/psiLambda0 with the D0 detector.,"We present measurements of the Lambda(0)(b) lifetime in the exclusive decay channel Lambda(0)(b)--> J/psiLambda(0), with J/psi--> mu(+)mu(-) and Lambda(0)--> ppi(-), the B0 lifetime in the decay B0-->J/psiK(0)(S) with J/psi--> mu(+)mu(-) and K(0)(S)-->pi(+)pi(-), and the ratio of these lifetimes. The analysis is based on approximately 250 pb(-1) of data recorded with the D0 detector in pp collisions at sqrt[s] = 1.96 TeV. The Lambda(0)(b) lifetime is determined to be tau(Lambda(0)(b)) = 1.22(+0.22)(-0.18)(stat) +/- 0.04(syst) ps, the B0 lifetime tau(B0) = 1.40(+0.11)(-0.10)(stat) +/- 0.03(syst) ps, and the ratio tau(Lambda(0)(b))/tau(B0) = 0.87(+0.17)(-0.14)(stat) +/- 0.03(syst). In contrast with previous measurements using semileptonic decays, this is the first determination of the Lambda(0)(b) lifetime based on a fully reconstructed decay channel.",2004-10-19,https://www.semanticscholar.org/paper/736be2a3eec762cbccf2d9dbf70f4275a8567087,Physical Review Letters
2030,Data mining for yield enhancement in TFT-LCD manufacturing: an empirical study,"The lengthy manufacturing processes of thin film transistor-liquid crystal displays (TFT-LCDs) are complex, in which many factors can cause different types of defects on the panel and result in low yield. Examples are line defects, point defects, and Mura defects. Engineers rely on personal experience for trouble shooting during TFT-LCD manufacture, which does not quickly locate possible fault root causes using their own domain knowledge or rules of thumb. In a fully automated manufacturing environment in TFT-LCD factories, large amounts of raw data are increasingly accumulated from various sources, automatically or semi-automatically, for fault diagnosis and process monitoring. This study aims to propose a data mining framework for diagnosing the root causes of defects in factories. The extracted information and knowledge is helpful to engineers as a basis for trouble shooting and defect diagnosis. To examine the validity of this approach, an empirical study was conducted in a TFT-LCD company in Taiwan, and the results demonstrated the practical viability of this approach.",2010-02-09,https://www.semanticscholar.org/paper/f8abcb590bab3b87d08844e11936fa54e83e6eb0,
2834,Galectin-3 is critical for the development of the allergic inflammatory response in a mouse model of atopic dermatitis.,"Galectin-3 belongs to a family of beta-galactoside-binding animal lectins expressed in several cell types, including epithelial and immune cells. To establish the role of galectin-3 in the development of allergic skin inflammation, we compared inflammatory skin responses of galectin-3-deficient (gal3(-/-)) and wild-type (gal3(+/+)) mice to epicutaneous sensitization with ovalbumin (OVA). OVA-treated gal3(-/-) mice exhibited markedly reduced epidermal thickening, lower eosinophil infiltration, and lower serum IgE levels compared with gal3(+/+) mice. The former evoked lower interleukin-4, but higher interferon-gamma, mRNA expression at OVA-treated skin sites. Moreover, gal3(-/-) splenocytes from OVA-sensitized mice secreted more interleukin-12 compared with gal3(+/+) splenocytes. In addition, antigen presentation by gal3(-/-) dendritic cells to T cells in vitro were T helper cell (Th1)-polarized relative to presentation by gal3(+/+) dendritic cells. When exposed to OVA, recipients engrafted with T cells from gal3(-/-) OVA-specific T cell receptor transgenic mice developed significantly reduced dermatitis and a markedly lower Th2 response compared with recipients of comparable gal3(+/+) T cells. We conclude that galectin-3 is critical for the development of inflammatory Th2 responses to epicutaneously administered antigens; in its absence, mice develop a Th1-polarized response. This regulatory effect of galectin-3 on Th development is exerted at both the dendritic cell and T cell levels. Our studies suggest that galectin-3 may play an important role in the acute phase of human atopic dermatitis.",2009-03-01,https://www.semanticscholar.org/paper/aae0cd8b144dff9e0192a3a405f644c32b3da7c0,American Journal of Pathology
3280,"Initiators, Leaders, and Recruitment Mechanisms in the Collective Movements of Damselfish","Explaining how individual behavior and social interactions give rise to group-level outcomes and affect issues such as leadership is fundamental to the understanding of collective behavior. Here we examined individual and collective behavioral dynamics in groups of humbug damselfish both before and during a collective movement. During the predeparture phase, group activity increased until the collective movement occurred. Although such movements were precipitated by one individual, the success or failure of any attempt to instigate a collective movement was not solely dependent on this initiator’s behavior but on the behavior of the group as a whole. Specifically, groups were more active and less cohesive before a successful initiation attempt than before a failed attempt. Individuals who made the most attempts to initiate a collective movement during each trial were ultimately most likely to lead the collective movement. Leadership was not related to dominance but was consistent between trials. The probability of fish recruiting to a group movement initiative was an approximately linear function of the number of fish already recruited. Overall, these results are consistent with nonselective local mimetism, with the decision to leave based on a group’s, rather than any particular individual’s, readiness to leave.",2013-04-12,https://www.semanticscholar.org/paper/7527d195acceb3b56fccedecae491dc290416ea9,American Naturalist
2788,857 An in vitro assay of inflammatory monocyte-keratinocyte activation predicts in vivo activity of BET inhibitors in a preclinical model of psoriasis,,2020-07-01,https://www.semanticscholar.org/paper/a2eb97b5a95d4656b28a89e20b5f8d22e5289dd1,
559,Algorithmic aspects of multiversion concurrency control,"Multiversion schedulers are now a widely accepted method for enhancing the performance of the concurrency control component of a database. In this paper we introduce a new notion of multiversion serializability (MVSR) based on conflicts (MVCSR), and discuss its relation with the well known single version conflict serializability (CSR). On-line schedulable (OLS) subsets of (MVSR) were defined in Papadimitriou and Kanellakis, ACM Trans. Database Systems 9, No. 1 (1984). We prove there that it is NP-complete to decide whether a set of schedules is OLS. We next introduce the concept of maximal OLS sets, and show that no efficient scheduler can be designed that recognizes maximal subsets of the MVSR or MVCSR schedules.",1985-03-25,https://www.semanticscholar.org/paper/7bcb7dbd2ac8e5ea52d37f909e189116b6d2e5a1,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
2644,Research Paper: Generation and Evaluation of Intraoperative Inferences for Automated Health Care Briefings on Patient Status After Bypass Surgery,"OBJECTIVE
The authors present a system that scans electronic records from cardiac surgery and uses inference rules to identify and classify abnormal events (e.g., hypertension) that may occur during critical surgical points (e.g., start of bypass). This vital information is used as the content of automatically generated briefings designed by MAGIC, a multimedia system that they are developing to brief intensive care unit clinicians on patient status after cardiac surgery. By recognizing patterns in the patient record, inferences concisely summarize detailed patient data.


DESIGN
The authors present the development of inference rules that identify important information about patient status and describe their implementation and an experiment they carried out to validate their correctness. The data for a set of 24 patients were analyzed independently by the system and by 46 physicians.


MEASUREMENTS
The authors measured accuracy, specificity, and sensitivity by comparing system inferences against physician judgments, in cases where all three physicians agreed and against the majority opinion in all cases.


RESULTS
For laboratory inferences, evaluation shows that the system has an average accuracy of 98 percent (full agreement) and 96 percent (majority model). An analysis of interrater agreement, however, showed that physicians do not agree on abnormal hemodynamic events and could not serve as a gold standard for evaluating hemodynamic events. Analysis of discrepancies reveals possibilities for system improvement and causes of physician disagreement.


CONCLUSIONS
This evaluation shows that the laboratory inferences of the system have high accuracy. The lack of agreement among physicians highlights the need for an objective quality-assurance tool for hemodynamic inferences. The system provides such a tool by implementing inferencing procedures established in the literature.",2001-05-01,https://www.semanticscholar.org/paper/6370d5d5f16310a46285977e6a95e9a153393184,J. Am. Medical Informatics Assoc.
2979,Dichotomous cellular properties of mouse orexin/hypocretin neurons,"Non‐technical summary  Orexin/hypocretin neurons are widely projecting, ‘multi‐tasking’ brain cells that promote alertness, reward seeking and feeding. They are vital for stable consciousness in higher mammals. Loss of orexin/hypocretin cells produces narcolepsy. It was originally assumed that orexin/hypocretin neurons are one uniform population of cells, but recent studies hinted that they may be split into subsystems. To explore this, we performed unbiased statistical analysis of electrical properties of orexin/hypocretin cells in combination with 3‐D analysis of their shape. Our results pointed to an existence of two subgroups of orexin/hypocretin neurons, that have unique ‘electrical fingerprints’ and distinct ways of receiving information from other neurons.",2011-06-01,https://www.semanticscholar.org/paper/3298bf1af03f90ab95266e6f516c43e9cb2ccbc8,Journal of Physiology
3755,"Shared ' Cross + Modal ' Representation religious , * church , * plants",,,https://www.semanticscholar.org/paper/48b5289aa08beb10fca58c6a542a597afc359e5d,
119,STARTS: Stanford Protocol Proposal for Internet Retrieval and Search,"Document databases are available everywhere, both within the internal networks of the organizations and on the Internet. The database contents are often ""hidden"" behind search interfaces. These interfaces vary from database to database. Also, the algorithms with which the associated search engines rank the documents in the query results are usually incompatible across databases. Even individual organizations use search engines from different vendors to index their internal document collections. These organizations could benefit from unified query interfaces to multiple search engines, for example, that would give users the illusion of a single big document database. Building such ""metasearchers"" is nowadays a hard task because different search engines are largely incompatible and do not allow for interoperability. To improve this situation, the Digital Library project at Stanford has coordinated among search-engine vendors and other key players to reach informal agreements for unifying basic interactions in these three areas. This is the final writeup of our informal ""standards"" effort. This draft is based on feedback from people from Excite, Fulcrum, GILS, Harvest, Hewlett-Packard Laboratories, Infoseek, Microsoft Network, Netscape, PLS, Verity, and WAIS, among others.",,https://www.semanticscholar.org/paper/f0c02277e26255b418d5f76d514c5eec0a4b47f8,
1328,The upgraded DØ detector,,2006-09-15,https://www.semanticscholar.org/paper/ca11f6374696a0c0439cb38efc768e4ffeddfdbe,
3084,Deux: Autonomic Testing System for Operating System Upgrades,"Operating system upgrades and patches sometimes break applications that worked fine on the older version. We present an autonomic approach to testing of OS updates while minimizing downtime, usable without local regression suites or IT expertise. Deux utilizes a dual-layer virtual machine architecture, with lightweight application process checkpoint and resume across OS versions, enabling simultaneous execution of the same applications on both OS versions in different VMs. Inputs provided by ordinary users to the production old version are also fed to the new version. The old OS acts as a pseudo-oracle for the update, and application state is automatically re-cloned to continue testing after any output discrepancies (intercepted at system call level) all transparently to users. If all differences are deemed inconsequential, then the VM roles are switched with the application state already in place. Our empirical evaluation with both LAMP and standalone applications demonstrates Deux’s efficiency and effectiveness.",,https://www.semanticscholar.org/paper/e59a3f312a3f3381cc489146221e79a44ac53324,
835,Multiway Cuts in Directed and Node Weighted Graphs,,1994-07-11,https://www.semanticscholar.org/paper/ce18a622d6cfc38ff739f850f01a750d33587fd4,"International Colloquium on Automata, Languages and Programming"
3615,C++ Programming Styles and Libraries,"One of the main aims of C++ has been to make it an excellent tool for writing libraries. Here, I present some points about the role of libraries and of the programming styles that they support and rely on. For lack of space for a thorough treatment of these themes, I refer to books.",,https://www.semanticscholar.org/paper/fa0e922f7aff9a5d14bc1a6005092f6224fbbb4e,
1652,Correlated Random Measures: Appendix,,,https://www.semanticscholar.org/paper/6476e3738935f89c0e5d7b300ea77b6cd203966c,
880,Shortest Paths Without a Map,,1989-07-11,https://www.semanticscholar.org/paper/ff187225ff569e01e751ebf004076350d4456a51,Theoretical Computer Science
2084,"Vice President, Finance Activities",,,https://www.semanticscholar.org/paper/22f6a91bee4cc4f966b4a85435f9db056ef63aa3,
799,Inference of message sequence charts,"Software designers draw Message Sequence Charts for early modeling of the individual behaviors they expect from the concurrent system under design. Can they be sure that precisely the behaviors they have described are realizable by some implementation of the components of the concurrent system? If so, can one automatically synthesize concurrent state machines realizing the given MSCs? If, on the other hand, other unspecified and possibly unwanted scenarios are ""implied"" by their MSCs, can the software designer be automatically warned and provided the implied MSCs? In this paper we provide a framework in which all these questions are answered positively. We first describe the formal framework within which one can derive implied MSCs, and we then provide polynomial-time algorithms for implication, realizability, and synthesis. In particular, we describe a novel algorithm for checking deadlock-free (safe) realizability.",2000-06-01,https://www.semanticscholar.org/paper/b7797eaedd724c8f4ad5e26f1ab01c391785759c,Proceedings of the 2000 International Conference on Software Engineering. ICSE 2000 the New Millennium
1191,Search for Associated W and Higgs Boson Production in pp Collisions at â‹ıs = 1.96 TeV,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, M. Ahsan, G. D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G.A. Alves, M. Anastasoaie, L. S. Ancu, T. Andeen, B. Andrieu, M. S. Anzelc, M. Aoki, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, A. C. S. Assis Jesus, O. Atramentov, C. Avila, F. Badaud, L. Bagby, B. Baldin, D. V. Bandurin, P. Banerjee, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, C. Biscarat, G. Blazey, F. Blekman, S. Blessing, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, E. E. Boos, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, X. B. Bu, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, T. H. Burnett, C. P. Buszello, J.M. Butler, P. Calfayan, S. Calvet, J. Cammin, E. Carrera, W. Carvalho, B. C. K. Casey, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K.M. Chan, A. Chandra, E. Cheu, F. Chevallier, D. K. Cho, S. Choi, B. Choudhary, L. Christofek, T. Christoudias, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, V. Cuplov, D. Cutts, M. Ćwiok, H. da Motta, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, K. DeVaughan, J. D. Degenhardt, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, H. Dong, T. Dorland, A. Dubey, L. V. Dudko, L. Duflot, S. R. Dugad, D. Duggan, A. Duperrin, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V.D. Elvira, Y. Enari, S. Eno, P. Ermolov, H. Evans, A. Evdokimov, V.N. Evdokimov, A.V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, C. Garcia, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, W. Geng, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, N. Gollub, B. Gómez, A. Goussiou, P. D. Grannis, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Harder, A. Harel, J.M. Hauptman, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, A. P. Heinson, U. Heintz, C. Hensel,22,x K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, J. D. Hobbs, B. Hoeneisen, H. Hoeth, M. Hohlfeld, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, C. Jarvis, R. Jesik, K. Johns, C. Johnson, M. Johnson, D. Johnston, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, J.M. Kalk, D. Karmanov, P. A. Kasper, I. Katsanos, D. Kau, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y.M. Kharzheev, D. Khatidze, T. J. Kim, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, J.-P. Konrath, A. V. Kozelov, J. Kraus, T. Kuhl, A. Kumar, A. Kupco, T. Kurča, V. A. Kuzmin, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, W.M. Lee, A. Leflat, J. Lellouch, J. Li, L. Li, Q. Z. Li, S.M. Lietti, J. K. Lim, J. G. R. Lima, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna, A. L. Lyon, A. K.A. Maciel, D. Mackin, R. J. Madaras, P. Mättig, C. Magass, A. Magerkurth, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, Y. Maravin, B. Martin, R. McCarthy, A. Melnitchouk, L. Mendoza, P. G. Mercadante, M. Merkin, K.W. Merritt, A. Meyer, J. Meyer,22,x J. Mitrevski, R.K. Mommsen, N.K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, N.A. Naumann, H.A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, V. O’Dell, D. C. O’Neil, G. Obrant, C. Ochando, D. Onoprienko, N. Oshima, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park,22,x S.K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, M. Petteni, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma, V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, B.G. Pope, A.V. Popov, C. Potter, W. L. Prado da Silva, H. B. Prosper, S. Protopopescu, J. Qian, A. Quadt,22,x B. Quinn, A. Rakitine, M. S. Rangel, K. Ranjan, P. N. Ratoff, P. Renkel, P. Rich, J. Rieger, M. Rijssenbeek, I. Ripp-Baudot, F. Rizatdinova, S. Robinson, R. F. Rodrigues, M. Rominsky, PRL 102, 051803 (2009) P HY S I CA L R EV I EW LE T T E R S week ending 6 FEBRUARY 2009",,https://www.semanticscholar.org/paper/ebf050b2532d8235b456d865361e0676f4058ed4,
2445,Session details: VR/AR,,2017-10-20,https://www.semanticscholar.org/paper/56ae50e3d9a86ead8317e8a3c1cebff8a1775fee,ACM Symposium on User Interface Software and Technology
1295,Zγ production and limits on anomalous ZZγ and Zγγ couplings in collisions at,,2007-09-27,https://www.semanticscholar.org/paper/da735ecb6115eb9ae0836df590e0fd805435d373,
2650,Environment management for hybrid user interfaces,"As computers proliferate, becoming smaller, more mobile, more powerful and more diverse, how will the ways in which we interact with them change? In this article, we describe research in developing ""hybrid user interfaces"" that tie together the diverse displays and interaction devices that a user may encounter in a mobile, shared environment. Controlling such a dynamically changing, heterogeneous mix of computers is a problem that we refer to as ""environment management"". We sketch some ways in which publicizing semantic information about computational objects and tasks can make it possible to automate environment management operations, and we describe research testbeds we are developing within which to explore these ideas.",2000-10-01,https://www.semanticscholar.org/paper/4341c9491c9832331ba388d89a7e4f6a9f898e13,IEEE wireless communications
3494,An Implementation of a Combinatorial Approximation Algorithm for Minimum-Cost Multicommodity Flow,,1997-12-01,https://www.semanticscholar.org/paper/1bc0da2739f47c77abbe0770daa31b925d75f2a3,Conference on Integer Programming and Combinatorial Optimization
1976,An intelligent system for wafer bin map defect diagnosis: An empirical study for semiconductor manufacturing,,2013-05-01,https://www.semanticscholar.org/paper/26368ed17e6ecd502ef8a8df065771cf2b728d61,Engineering applications of artificial intelligence
28,Learning similarity metrics for event identification in social media,"Social media sites (e.g., Flickr, YouTube, and Facebook) are a popular distribution outlet for users looking to share their experiences and interests on the Web. These sites host substantial amounts of user-contributed materials (e.g., photographs, videos, and textual content) for a wide variety of real-world events of different type and scale. By automatically identifying these events and their associated user-contributed social media documents, which is the focus of this paper, we can enable event browsing and search in state-of-the-art search engines. To address this problem, we exploit the rich ""context"" associated with social media content, including user-provided annotations (e.g., title, tags) and automatically generated information (e.g., content creation time). Using this rich context, which includes both textual and non-textual features, we can define appropriate document similarity metrics to enable online clustering of media to events. As a key contribution of this paper, we explore a variety of techniques for learning multi-feature similarity metrics for social media documents in a principled manner. We evaluate our techniques on large-scale, real-world datasets of event images from Flickr. Our evaluation results suggest that our approach identifies events, and their associated social media documents, more effectively than the state-of-the-art strategies on which we build.",2010-02-04,https://www.semanticscholar.org/paper/d7f72ac79527b9e3fd612fc5202b5c83721d9d52,Web Search and Data Mining
1076,Search for Long-Lived Particles Decaying into Electron or Photon Pairs with the D 0 Detector,,,https://www.semanticscholar.org/paper/f63b4ad3462c7ca4ab6ba7a4a91be58c5bbda09f,
2338,Activation of neutrophils by soluble and insoluble immunoglobulin aggregates from synovial fluid of patients with rheumatoid arthritis.,"OBJECTIVES--Previous work has shown that synovial fluid isolated from patients with active rheumatoid arthritis contains soluble (not sedimented by centrifugation at 11,600 g for two minutes) and insoluble (sedimented by centrifugation at 11,600 g for two minutes) immunoglobulin aggregates that are capable of activating reactive oxidant production by bloodstream neutrophils. The purpose of this study was to determine which of these types of immunoglobulin aggregates activated the secretion of reactive oxygen metabolites and granule enzymes from neutrophils. METHODS--Cell free synovial fluid (from patients with rheumatoid arthritis) was added to neutrophils isolated from blood of healthy controls that had been incubated in the presence and absence of granulocyte-macrophage colony stimulating factor (GM-CSF). Reactive oxidant production was measured by luminol chemiluminescence (which detects both intracellular and extracellular oxidant production) and by cytochrome c reduction (which measures superoxide secretion). RESULTS--The soluble aggregates only activated neutrophils that were previously primed, and activated a rapid and transient burst of reactive oxidant secretion. On the other hand, the insoluble aggregates activated primed and unprimed neutrophils with similar efficacy and most of the oxidants generated (especially in unprimed cells) were intracellular. The soluble aggregates, but not the insoluble aggregates, also activated the secretion of myeloperoxidase from neutrophils that had either been pretreated with cytochalasin B or primed with GM-CSF. CONCLUSION--It is thus proposed that these soluble immunoglobulin aggregates are responsible for activation of the release of tissue damaging granule enzymes and reactive oxidants from primed neutrophils within the rheumatoid joint.",1993-05-01,https://www.semanticscholar.org/paper/c2f927bc9b6699b6e51e7827ac55216d6f34459d,Annals of the Rheumatic Diseases
2411,Mitigation of VR Sickness During Locomotion With a Motion-Based Dynamic Vision Modulator,"In virtual reality, VR sickness resulting from continuous locomotion via controllers or joysticks is still a significant problem. In this article, we present a set of algorithms to mitigate VR sickness that dynamically modulate the user's field of view by modifying the contrast of the periphery based on movement, color, and depth. In contrast with previous work, this vision modulator is a shader that is triggered by specific motions known to cause VR sickness, such as acceleration, strafing, and linear velocity. Moreover, the algorithm is governed by delta velocity, delta angle, and average color of the view. We ran two experiments with different washout periods to investigate the effectiveness of dynamic modulation on the symptoms of VR sickness, in which we compared this approach against a baseline and pitch-black field-of-view restrictors. Our first experiment made use of a just-noticeable-sickness design, which can be useful for building experiments with a short washout period.",2022-06-10,https://www.semanticscholar.org/paper/1cc6aee12e6fdd1cc30b9684212d5cc7b71e3563,IEEE Transactions on Visualization and Computer Graphics
2525,Session details: Graphs,,2010-04-10,https://www.semanticscholar.org/paper/bdcd648da25f4758b72c14f0e0bffbdc1ff9a742,Proceedings of the SIGCHI Conference on Human Factors in Computing Systems
2482,Gaze locking: passive eye contact detection for human-object interaction,"Eye contact plays a crucial role in our everyday social interactions. The ability of a device to reliably detect when a person is looking at it can lead to powerful human-object interfaces. Today, most gaze-based interactive systems rely on gaze tracking technology. Unfortunately, current gaze tracking techniques require active infrared illumination, calibration, or are sensitive to distance and pose. In this work, we propose a different solution-a passive, appearance-based approach for sensing eye contact in an image. By focusing on gaze *locking* rather than gaze tracking, we exploit the special appearance of direct eye gaze, achieving a Matthews correlation coefficient (MCC) of over 0.83 at long distances (up to 18 m) and large pose variations (up to ±30° of head yaw rotation) using a very basic classifier and without calibration. To train our detector, we also created a large publicly available gaze data set: 5,880 images of 56 people over varying gaze directions and head poses. We demonstrate how our method facilitates human-object interaction, user analytics, image filtering, and gaze-triggered photography.",2013-10-08,https://www.semanticscholar.org/paper/06f02199690961ba52997cde1527e714d2b3bf8f,ACM Symposium on User Interface Software and Technology
252,An analytical contrast between fitness maximization and selection for mixability.,,2011-03-21,https://www.semanticscholar.org/paper/615815563886fd7152c59483230c7c6ebf5fcc27,Journal of Theoretical Biology
3125,Improving Web Browsing on Wireless PDAs Using Thin-Client Computing,"Web applications are becoming increasingly popular for mobile wireless PDAs. However, web browsing on these systems can be quite slow. An alternative approach is handheld thin-client computing, in which the web browser and associated application logic run on a server, which then sends simple screen updates to the PDA for display. To assess the viability of this thin-client approach, we compare the web browsing performance of thin clients against fat clients that run the web browser locally on a PDA. Our results show that thin clients can provide better web browsing performance compared to fat clients, both in terms of speed and ability to correctly display web content. Surprisingly, thin clients are faster even when having to send more data over the network. We characterize and analyze different design choices in various thin-client systems and explain why these approaches can yield superior web browsing performance on mobile wireless PDAs.",,https://www.semanticscholar.org/paper/b69ebc745a52b19db476a823b0625234d59f7b24,
3270,Genetic Polymorphism of Beta-lactoglobulin in Kenyan Small East African Goat Breed Using PCR-RFLP and Sequencing,"Refinement of coherence and economic gains is an essential target in Dairy industry. This can be achieved by increasing economic returns without increasing the size of the herd. Animal selection is the main method for improvement of livestock production around the world. The determination of candidate genes for economic traits holds a promising future as molecular markers for improving productivity in farm animals. Polymorphism in the beta-lactoglobulin gene has been successfully studied in many goat populations of the world. However, this has not been clarified yet in the local Kenyan goat breeds.  The objectives of this study were to screen beta-lactoglobulin gene variants and to identify its polymorphism in Small east African goat breed using Polymorphic Chain Reaction and Restriction Fragment Length Polymorphism and sequencing techniques. A total of 60 goats were genotyped, 30 from each region (Samburu and Narok Counties). Genomic DNA was then isolated using Qiagen QiAmp blood mini kit. The amplified product was observed as 426 bp of exon 7 and the restriction digestion with SacII revealed two alleles, namely A and B and three genotypes, (AA, AB and BB) at the β-lactoglobulin gene locus. Allelic frequencies for goats found in Samburu and Narok were 0.233 and 0.133 respectively for A allele; 0.767 and 0.867 for B allele respectively , while genotypic frequencies were 0.1 and 0.0 for AA, 0.267 and 0.267 for AB, and 0.633 and 0.733 for BB respectively. In the pooled data for the small east African goat breed, the allelic frequencies were 0.183 and 0.817 for the A and B allele respectively, while genotypic frequencies were 0.05, 0.267 and 0.683 for the AA, AB and BB respectively. No deviations from the Hardy Weinberg equilibrium were observed.  After PCR, a 426 base pairs sequence in exon 7 of 60 goat samples were sequenced and variation analyzed. Two point mutations corresponding to base substitutions were identified. The substitutions of G to A were found at both positions 6705 and 6751 as compared to the Capra hircus sequence (Accession number Z33881.1). Further studies on other beta-lactoglobulin gene regions as well as other milk protein genes are necessary to establish associations of all its variations and the effects of the variants in the indigenous goat breeds.",2014-09-26,https://www.semanticscholar.org/paper/2aedad06c095318a7dfa52cc22590a63700239b2,
2225,Basic science232. Certolizumab pegol prevents pro-inflammatory alterations in endothelial cell function,"Background: Cardiovascular disease is a major comorbidity of rheumatoid arthritis (RA) and a leading cause of death. Chronic systemic inflammation involving tumour necrosis factor alpha (TNF) could contribute to endothelial activation and atherogenesis. A number of anti-TNF therapies are in current use for the treatment of RA, including certolizumab pegol (CZP), (Cimzia ®; UCB, Belgium). Anti-TNF therapy has been associated with reduced clinical cardiovascular disease risk and ameliorated vascular function in RA patients. However, the specific effects of TNF inhibitors on endothelial cell function are largely unknown. Our aim was to investigate the mechanisms underpinning CZP effects on TNF-activated human endothelial cells. Methods: Human aortic endothelial cells (HAoECs) were cultured in vitro and exposed to a) TNF alone, b) TNF plus CZP, or c) neither agent. Microarray analysis was used to examine the transcriptional profile of cells treated for 6 hrs and quantitative polymerase chain reaction (qPCR) analysed gene expression at 1, 3, 6 and 24 hrs. NF-κB localization and IκB degradation were investigated using immunocytochemistry, high content analysis and western blotting. Flow cytometry was conducted to detect microparticle release from HAoECs. Results: Transcriptional profiling revealed that while TNF alone had strong effects on endothelial gene expression, TNF and CZP in combination produced a global gene expression pattern similar to untreated control. The two most highly up-regulated genes in response to TNF treatment were adhesion molecules E-selectin and VCAM-1 (q 0.2 compared to control; p > 0.05 compared to TNF alone). The NF-κB pathway was confirmed as a downstream target of TNF-induced HAoEC activation, via nuclear translocation of NF-κB and degradation of IκB, effects which were abolished by treatment with CZP. In addition, flow cytometry detected an increased production of endothelial microparticles in TNF-activated HAoECs, which was prevented by treatment with CZP. Conclusions: We have found at a cellular level that a clinically available TNF inhibitor, CZP reduces the expression of adhesion molecule expression, and prevents TNF-induced activation of the NF-κB pathway. Furthermore, CZP prevents the production of microparticles by activated endothelial cells. This could be central to the prevention of inflammatory environments underlying these conditions and measurement of microparticles has potential as a novel prognostic marker for future cardiovascular events in this patient group. Disclosure statement: Y.A. received a research grant from UCB. I.B. received a research grant from UCB. S.H. received a research grant from UCB. All other authors have declared no conflicts of interest",2012-05-01,https://www.semanticscholar.org/paper/7da3a277789429d394490bc9a4184eb5587bff39,
2571,Vertical Vergence Calibration for Augmented Reality Displays,"Stereo and bi-ocular head-mounted displays (HMDs) require the user to fuse two images into a coherent picture of the threedimensional world. The human visual system performs this task constantly, but when the input images contain both real and graphical depictions, the problem becomes more difficult. A vertical disparity in the graphics causes diplopia for users trying to fuse the real and virtual objects simultaneously. We implement three methods to measure and correct this disparity and assess them with a collection of a single model of optical see-through HMD.",2006-03-25,https://www.semanticscholar.org/paper/5be7e31f4acbb26e1fb77fcc816c05cb94845d9b,IEEE Conference on Virtual Reality and 3D User Interfaces
1985,Powerchip Semiconductor Corporation,,2013-07-08,https://www.semanticscholar.org/paper/de76635f4abdefe0bfd3199f1e0de736735f636d,
1746,Nested Hierarchical Dirichlet Processes,"We develop a nested hierarchical Dirichlet process (nHDP) for hierarchical topic modeling. The nHDP generalizes the nested Chinese restaurant process (nCRP) to allow each word to follow its own path to a topic node according to a per-document distribution over the paths on a shared tree. This alleviates the rigid, single-path formulation assumed by the nCRP, allowing documents to easily express complex thematic borrowings. We derive a stochastic variational inference algorithm for the model, which enables efficient inference for massive collections of text documents. We demonstrate our algorithm on 1.8 million documents from The New York Times and 2.7 million documents from Wikipedia.",2012-10-25,https://www.semanticscholar.org/paper/2ecf9a574ef868a48fadd94bd5ca45f6a051b49a,IEEE Transactions on Pattern Analysis and Machine Intelligence
212,On the optimality of grid cells,"Grid cells, discovered more than a decade ago [5], are neurons in the brain of mammals that fire when the animal is located near certain specific points in its familiar terrain. Intriguingly, these points form, for a single cell, a two-dimensional triangular grid, not unlike our Figure 3. Grid cells are widely believed to be involved in path integration, that is, the maintenance of a location state through the summation of small displacements. We provide theoretical evidence for this assertion by showing that cells with grid-like tuning curves are indeed well adapted for the path integration task. In particular we prove that, in one dimension under Gaussian noise, the sensitivity of measuring small displacements is maximized by a population of neurons whose tuning curves are near-sinusoids -- that is to say, with peaks forming a one-dimensional grid. We also show that effective computation of the displacement is possible through a second population of cells whose sinusoid tuning curves are in phase difference from the first. In two dimensions, under additional assumptions it can be shown that measurement sensitivity is optimized by the product of two sinusoids, again yielding a grid-like pattern. We discuss the connection of our results to the triangular grid pattern observed in animals.",2016-06-15,https://www.semanticscholar.org/paper/e3df557d0e40e2464773960a81bc12ec914b6b8f,arXiv.org
2945,Inferring relevant cell types for complex traits using single-cell gene expression,"Previous studies have prioritized trait-relevant cell types by looking for an enrichment of GWAS signal within functional regions. However, these studies are limited in cell resolution by the lack of functional annotations from difficult-to-characterize or rare cell populations. Measurement of single-cell gene expression has become a popular method for characterizing novel cell types, and yet, hardly any work exists linking single-cell RNA-seq to phenotypes of interest. To address this deficiency, we present RolyPoly, a regression-based polygenic model that can prioritize trait-relevant cell types and genes from GWAS summary statistics and single-cell RNA-seq. We demonstrate RolyPoly’s accuracy through simulation and validate previously known tissue-trait associations. We discover a significant association between microglia and late-onset Alzheimer’s disease, and an association between oligodendrocytes and replicating fetal cortical cells with schizophrenia. Additionally, RolyPoly computes a trait-relevance score for each gene which reflects the importance of expression specific to a cell type. We found that differentially expressed genes in the prefrontal cortex of Alzheimer’s patients were significantly enriched for highly ranked genes by RolyPoly gene scores. Overall, our method represents a powerful framework for understanding the effect of common variants on cell types contributing to complex traits.",2017-05-10,https://www.semanticscholar.org/paper/a7e975383c3a3e996e46b8fa8479016b08c1951e,bioRxiv
487,Optimal Coteries on a Network,,,https://www.semanticscholar.org/paper/12fcfd8c992b2894b8ea36ad5708b64e643b80f2,
3295,Reproductive Skew in Vertebrates: Sociality and reproductive skew in horses and zebras,,,https://www.semanticscholar.org/paper/054290d86fd24f37c8d94f0af6be867862c7e1af,
1710,Scaling probabilistic models of genetic variation to millions of humans,"A major goal of population genetics is to quantitatively understand variation of genetic polymorphisms among individuals. The aggregated number of genotyped humans is currently on the order of millions of individuals, and existing methods do not scale to data of this size. To solve this problem, we developed TeraStructure, an algorithm to fit Bayesian models of genetic variation in structured human populations on tera-sample-sized data sets (1012 observed genotypes; for example, 1 million individuals at 1 million SNPs). TeraStructure is a scalable approach to Bayesian inference in which subsamples of markers are used to update an estimate of the latent population structure among individuals. We demonstrate that TeraStructure performs as well as existing methods on current globally sampled data, and we show using simulations that TeraStructure continues to be accurate and is the only method that can scale to tera-sample sizes.",2014-12-24,https://www.semanticscholar.org/paper/a46b787c5a9cc883006fd81718d15eaad2fd4197,Nature Genetics
1057,Ju l 2 00 8 FERMILAB-PUB-08 / 056-E Evidence for production of single top quarks,,,https://www.semanticscholar.org/paper/335882615c60c680589357c6beed6e7ec9df6756,
3131,Web browsing performance of wireless thin-client computing,"Web applications are becoming increasingly popular for mobile wireless systems. However, wireless networks can have high packet loss rates, which can degrade web browsing performance on wireless systems. An alternative approach is wireless thin-client computing, in which the web browser runs on a remote thin server with a more reliable wired connection to the Internet. A mobile client then maintains a connection to the thin server to receive display updates over the lossy wireless network. To assess the viability of this thin-client approach, we compare the web browsing performance of thin clients against fat clients that run the web browser locally in lossy wireless networks. Our results show that thin clients can operate quite effectively over lossy networks. Compared to fat clients running web browsers locally, our results show surprisingly that thin clients can be faster and more resilient on web applications over lossy wireless LANs despite having to send more data over the network. We characterize and analyze different design choices in various thin-client systems and explain why these approaches can yield superior web browsing performance in lossy wireless networks.",2003-05-20,https://www.semanticscholar.org/paper/5bdbd4c2457d0610ead68d064bc26e60654903d6,The Web Conference
1932,Data-driven innovation to capture user-experience product design: An empirical study for notebook visual aesthetics design,,2016-09-01,https://www.semanticscholar.org/paper/37ddc78cc849fcefb0d6151bbe8a47d002e2851c,Computers & industrial engineering
3056,Lisa '09: 23rd Large Installation System Administration Conference,"First, Werner introduced an exemplary customer of Amazon’s services—“animoto” (http://animoto.com/), a company that developed an engine that automatically combines images, music, and video clips that you fashion into a polished production, something like a movie trailer. He said they are a New York-based enterprise that owns no servers. Instead, their product uses a four-step process (upload, analysis, rendering, and distribution) that employs Amazon cloud services: Amazon SQS to manage a queue of jobs, and Amazon EC2 to create and S3 to store content. When animoto launched a Facebook application for the service, they were able to immediately employ thousands of servers via Amazon EC2 servers to handle the influx of new users. He made the point that such a venture is revolutionary: you couldn’t secure startup funding for 5000 or more servers simply to launch a free Facebook application. Thus, Werner describes this as a “democratization of business”: essentially, that the little guy can get the resources to launch something great.",,https://www.semanticscholar.org/paper/2bfe186ebeb03e4e12bde228f03739f8b650563a,
1654,Multilingual Topic Models for Unaligned Text,"We develop the multilingual topic model for unaligned text (MuTo), a probabilistic model of text that is designed to analyze corpora composed of documents in two languages. From these documents, MuTo uses stochastic EM to simultaneously discover both a matching between the languages and multilingual latent topics. We demonstrate that MuTo is able to find shared topics on real-world multilingual corpora, successfully pairing related documents across languages. MuTo provides a new framework for creating multilingual topic models without needing carefully curated parallel corpora and allows applications built using the topic model formalism to be applied to a much wider class of corpora. Topic models are a powerful formalism for unsupervised analysis of corpora [1, 8]. They are an important tool in information retrieval [27], sentiment analysis [25], and collaborative filtering [18]. When interpreted as a mixed membership model, similar assumptions have been successfully applied to vision [6], population survey analysis [4], and genetics [5]. In this work, we build on latent Dirichlet allocation (LDA) [2], a generative, probabilistic topic model of text. LDA assumes that documents have a distribution over topics and that these topics are distributions over the vocabulary. Posterior inference discovers the topics that best explain a corpus; the uncovered topics tend to reflect thematically consistent patterns of words [8]. The goal of this paper is to find topics that express thematic coherence across multiple languages. LDA can capture coherence in a single language because semantically similar words tend to be used in similar contexts. This is not the case in multilingual corpora. For example, even though “Hund” and “hound” are orthographically similar and have nearly identical meanings in German and English (i.e., “dog”), they will likely not appear in similar contexts because almost all documents are written in a single language. Consequently, a topic model fit on a bilingual corpus reveals coherent topics but bifurcates the topic space between the two languages (Table 1). In order to build coherent topics across languages, there must be some connection to tie the languages together. Previous multilingual topic models connect the languages by assuming parallelism at either the sentence level [28] or document level [13, 23, 19]. Many parallel corpora are available, but they represent a small fraction of corpora. They also tend to be relatively well annotated and understood, making them less suited for unsupervised methods like LDA. A topic model on unaligned text in multiple languages would allow the exciting applications developed for monolingual topics models to be applied to a broader class of corpora and would help monolingual users to explore and understand multilingual corpora. We propose the MUltilingual TOpic model for unaligned text (MUTO). MUTO does not assume that it is given any explicit parallelism but instead discovers a parallelism at the vocabulary level. To find this parallelism, the model assumes that similar themes and ideas appear in both languages. For example, if the word “Hund” appears in the German side of the corpus, “hound” or “dog” should appear somewhere on the English side. The assumption that similar terms will appear in similar contexts has also been used to build lexicons from nonparallel but comparable corpora. What makes contexts similar can be evaluated through such measures as cooccurrence [20, 24] or tf-idf [7]. Although the emphasis of our work is on building consistent topic spaces and not the task of building dictionaries per se, good translations are required to find consistent topics. However, we can build on successful techniques at building lexicons across languages. This paper is organized as follows. We detail the model and its assumptions in Section 1, develop a stochastic expectation maximization (EM) inference procedure in Section 2, discuss the corpora and other linguistic resources necessary to evaluate the model in Section 3, and evaluate the performance of the model in Section 4.",,https://www.semanticscholar.org/paper/70454f5b45f77cd8ad34cd88b300f8ae92c8e978,
1017,The Relationships of Receptors for Phencyclidine and Sigma Opiates in Rat Cerebellum: An Electrophysiological Analysis,,,https://www.semanticscholar.org/paper/c24a0f97cfce99b970665bb5dbb00cdd83ac8b60,
968,Hemisphere opposite to vascular trunk deviation is earlier affected by glaucomatous damage in myopic high-tension glaucoma,"Purpose To investigate whether the position of the central vascular trunk, as a surrogate of lamina cribrosa (LC) shift, is associated with the initial hemisphere of visual field defect in myopic high-tension glaucoma (HTG) eyes. Methods The deviation of the central vascular trunk was measured from the center of the Bruch’s membrane opening (BMO), which was delineated by OCT imaging. The angular deviation was measured with the horizontal nasal midline as 0° and the superior location as a positive value. The initial hemisphere developing visual field defect was defined as three connected abnormal points (having a P value with less than 0.5% probability of being normal) appearing in only one hemisphere in pattern deviation plots. If those points were observed in both hemispheres initially, the eye was classified as bi-hemispheric visual field defect. Results Initially, 36 eyes (44%) had superior visual field defects, 27 (33%) inferior visual field defects, and 18 (22%) bi-hemispheric visual field defects. After a mean follow-up of 5 years, the number of bi-hemispheric visual field defects had increased to 34 (42%). A logistic regression analysis revealed that inferior deviation of vascular trunk was the only factor associated with initial inferior visual field defect (P = 0.001), while initial bi-hemispheric visual field defects were associated with worse mean deviation at initial visits (P<0.001). A conditional inference tree analysis showed that both the angular deviation (P<0.001) and initial mean deviation (P = 0.025) determined the initial hemispheres developing visual field defect. Conclusions Although both hemispheres were involved as glaucoma progression, the axons on the side counter to the vascular trunk deviation were damaged earlier in HTG. This finding implies the LC shift could add additional stress to axons exposed to high intraocular pressure.",2020-05-18,https://www.semanticscholar.org/paper/e7f71b62661f1fb128cecba7a03faa0ee60925f3,PLoS ONE
1402,Present results and future goals of the Cryogenic Dark Matter Search,"The Cryogenic Dark Matter Search (CDMS) uses Ge and Si detectors to search for Weakly Interacting Massive Particles (WIMPs) via their elastic-scattering interaction with atomic nuclei. The present results from CDMS give limits on the spin-independent WIMP-nucleon elastic-scattering cross section that exclude previously unexplored parameter space above 10 GeV/c2. The second phase of the CDMS experiment, scheduled to start in January 2002, is expected to improve on the present sensitivity by more than two orders of magnitude.",2002-03-08,https://www.semanticscholar.org/paper/f583f917cebd48663c96b8a3e5647812d853e4ef,
838,Computing the Throughput of a Network with Dedicated Lines,,1993-04-27,https://www.semanticscholar.org/paper/4f79b70053c844b2db434a17dacb81001fb7728c,Discrete Applied Mathematics
848,Timing Verification by Successive Approximation,"We present an algorithm for verifying that a model M with timing constraints satisfies a given temporal property T. The model M is given as a parallel composition of ?-automata Pi, where each automaton Pi is constrained by bounds on delays. The property T is given as an ?-automaton as well, and the verification problem is posed as a language inclusion question L(M) ? L(T). In constructing the composition M of the constrained automata Pi, one needs to rule out the behaviors that are inconsistent with the delay bounds, and this step is (provably) computationally expensive. We propose an iterative solution which involves generating successive approximations Mj to M, with containment L(M) ? L(Mj) and monotone convergence L(Mj) ? L(M) within a bounded number of steps. As the succession progresses, the approximations Mj become more complex. At any step of the iteration one may get a proof or a counter-example to the original language inclusion question. The described algorithm is implemented into the verifier Cospan. We illustrate the benefits of our strategy through some examples.",1992-06-29,https://www.semanticscholar.org/paper/3a799b970714d67225955861d690a24dd6e0c3b6,Information and Computation
1938,An Overview of the Development of a GPU with Integrated HBM on Silicon Interposer,"In recent years, the 2.5D IC (Integrated Circuit) package with TSV (Through Silicon Vias) has become important for high-bandwidth and high-performance applications. It is well known that 2.5D technology requires significant innovation in the areas of process technology, packaging, design, thermals, and test solutions leading to several hundred new technologies in a single product. With these complex material sets and process steps combined with new design requirements, methods, and components, a significant amount of research and engineering development is required to bring a successful product to market. After an 8 year development, in July of 2015 AMD reported it began shipment of a new generation of AMD Radeon Fury graphics cards, based on the development of the ""Fiji"" GPU and the first generation of High Bandwidth Memory (HBM1). This announcement is the next major step in an era for 2.5D IC package technology which will be used in a wide variety of applications. Given the scope of this undertaking many collaborations were required. This paper provides an overview of the collaboration between AMD and ASE. It chronicles the work from initial proof of concept to technology feasibility to product development to production ramp and ultimately high volume production. Details of several functional prototypes are outlined including warpage characterization, stress reduction, materials selection methodologies, and the use of finite element analysis (FEA) and advanced Warpage Metrology Analyzer (WMA) for optimization. The result is a reliable 2.5D process flow with >99% assembly yield for a 1011mm2 interposer with 5 dies attached in a 300+W 55x55mm2 package.",2016-05-01,https://www.semanticscholar.org/paper/aa96944f002e97690a05006490b25c5887cfcb56,Electronic Components and Technology Conference
132,Adaptive deadlock-free worm-hole routing in hypercubes,"Two new algorithms for worm-hole routing in the hypercube are presented. The first hypercube algorithm is adaptive, but non-minimal in the sense that some derouting is permitted. Then another deadlock-free adaptive worm-hole based routing algorithm for the hypercube interconnection is presented which is minimal. Finally some well-known worm-hole algorithms for the hypercube were evaluated together with the new ones on a hypercube of 2/sup 10/ nodes. One oblivious algorithm, the Dimension-Order, or E-Cube routing algorithm (W. Dally, C. Seitz, 1987) was tried. In addition, three partially adaptive algorithms were considered: the Hanging algorithm (Y. Birk, P. Gibbons, D. Soroker, J. Sanz, 1989 and S. Konstantinidou, 1990), the Zenith algorithm (S. Konstantinidou, 1990), and the Hanging-Order algorithm (G.-M. Chia, S. Chalasani, C.S. Raghavendra, 1991). Finally, a fully adaptive minimal algorithm presented independently by L. Gravano, G. Pifarre, S.A. Felperin and J. Sanz (1991) and J. Duato was tried. This algorithm allows each message to choose adaptively among all the shortest paths from its source to its destination. Only four virtual channels per physical link are needed to achieve this. This technique is referred to as Fully. The results obtained show that the two new algorithms are good candidates as a choice for worm-hole routing in the hypercube network.<<ETX>>",1992-03-01,https://www.semanticscholar.org/paper/cfb408cca6810a0509922ed963b14e6f35dbee05,Proceedings Sixth International Parallel Processing Symposium
2594,VITA: visual interaction tool for archaeology (demo),"VITA (Visual Interaction Tool for Archaeology) is an experimental collaborative mixed reality system for offsite visualization of an archaeological dig. Our demonstration of VITA allows multiple users to visualize the dig site in a mixed reality environment in which tracked, see-through, head-worn displays are combined with a multi-user, multi-touch, projected table surface, a large screen display, and tracked hand-held displays. VITA augments existing archaeological analysis methods with new ways to organize, visualize, and combine the standard 2D information available from an excavation (drawings, pictures, and notes) with textured, laser range-scanned 3D models of objects and the site itself. Users can combine speech, touch, and 3D hand gestures to interact multimodally with the environment.",2004-10-15,https://www.semanticscholar.org/paper/261c983b2d9f625b1bc582458a468605a1432684,ACM SIGMM workshop on Experiential Telepresence
3695,RESIN-11: Schema-guided Event Prediction for 11 Newsworthy Scenarios,"We introduce RESIN-11, a new schema-guided event extraction&prediction framework that can be applied to a large variety of newsworthy scenarios. The framework consists of two parts: (1) an open-domain end-to-end multimedia multilingual information extraction system with weak-supervision and zero-shot learningbased techniques. (2) schema matching and schema-guided event prediction based on our curated schema library. We build a demo website based on our dockerized system and schema library publicly available for installation (https://github.com/RESIN-KAIROS/RESIN-11). We also include a video demonstrating the system.",,https://www.semanticscholar.org/paper/396833983f6d7d77957e12c3839e5da05feb053a,North American Chapter of the Association for Computational Linguistics
310,Progress in approximate nash equilibria,"It is known [5] that an additively ε-approximate Nash equilibrium (with supports of size at most two) can be computed in polynomial time in any 2-player game with ε=.5. It is also known that no approximation better than .5 is possible unless equilibria with support larger than logn are considered, where n is the number of strategies per player. We give a polynomial algorithm for computing an ε-approximate Nash equilibrium in 2-player games with ε ≈ .38; our algorithm computes equilibria with arbitrarily large supports.",2007-06-11,https://www.semanticscholar.org/paper/a7699857f899a3d4e1c1df679a8ec669cbe63618,ACM Conference on Economics and Computation
635,On the Complexity of Local Search for the Traveling Salesman Problem,"It is shown that, unless $P = NP$, local search algorithms for the traveling salesman problem having polynomial time complexity per iteration will generate solutions arbitrarily far from the optimal.",1977-03-01,https://www.semanticscholar.org/paper/051d2d7cea8d57eca321d6536ece2b69700a49c3,SIAM journal on computing (Print)
935,Edge Dominating Sets in Graphs,"We prove that the edge dominating set problem for graphs is $NP$-complete even when restricted to planar or bipartite graphs of maximum degree 3. We show as a corollary that the minimum maximal matching and the achromatic number problems are $NP$-complete. A new linear time algorithm for finding minimum independent edge dominating sets in trees is described, based on an observed relationship between edge dominating sets and independent sets in total graphs.",1980-06-01,https://www.semanticscholar.org/paper/ab9d650ea2e999306b207ddbb990f5346376555c,
2450,Engaging hospitalized patients in clinical care: Study protocol for a pragmatic randomized controlled trial.,,2016-03-01,https://www.semanticscholar.org/paper/1bc99006152c2ea96b98de23a6926cf96e5bf3e5,Contemporary Clinical Trials
77,Query- vs. Crawling-based Classification of Searchable Web Databases.,"The World-Wide Web is one of the main channels through which people currently exchange information. Unfortunately, this information is not characterized in a way that would make its semantics readily understandable by computers, which complicates building value-added services on top of the existing information. An ambitious effort that aims to facilitate the development of such services is the so-called “Semantic Web.” According to Berners-Lee et al. [1]:",,https://www.semanticscholar.org/paper/3d15b09f8c1117157a7263830210c36ae2281124,
2534,Interference avoidance in multi-user hand-held augmented reality,"In a multi-user augmented reality application for a shared physical environment, it is possible for users to interfere with each other. For example, in a multi-player game in which each player holds a display whose tracked position and orientation affect the outcome, one player may physically block another player's view or physically contact another player. We explore software techniques intended to avoid such interference. These techniques modify what a user sees or hears, and what interaction capabilities they have, when their display gets too close to another user's display. We present Redirected Motion, an effective, yet nondistracting, interference avoidance technique for hand-held AR, which transforms the 3D space in which the user moves their display, to direct the display away from other displays. We conducted a within-subject, formal user study to evaluate the effectiveness and distraction level of Redirected Motion compared to other interference avoidance techniques. The study is based on an instrumented, two-player, first-person-shooter, augmented reality game, in which each player holds a 6DOF-tracked ultra-mobile computer. Comparison conditions include an unmanipulated control condition and three other software techniques for avoiding interference: dimming the display, playing disturbing sounds, and disabling interaction capabilities. Subjective evaluation indicates that Redirected Motion was unnoticeable, and quantitative analysis shows that the mean distance between users during Redirected Motion was significantly larger than for the comparison conditions.",2009-10-19,https://www.semanticscholar.org/paper/628c1ade689ced145d22e262cf832d1882dce392,2009 8th IEEE International Symposium on Mixed and Augmented Reality
1158,Measurement of the WW Production Cross Section with Dilepton Final States in p p Collisions at ffiffi s p 1⁄4 1 : 96 TeV and Limits on Anomalous Trilinear Gauge Couplings,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, M. Ahsan, G.D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G. A. Alves, L. S. Ancu, T. Andeen, M. S. Anzelc, M. Aoki, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, O. Atramentov, C. Avila, J. BackusMayes, F. Badaud, L. Bagby, B. Baldin, D.V. Bandurin, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V.A. Bezzubov, P. C. Bhat, V. Bhatnagar, G. Blazey, S. Blessing, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, E. E. Boos, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, X. B. Bu, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, T. H. Burnett, C. P. Buszello, P. Calfayan, B. Calpas, S. Calvet, J. Cammin, M.A. Carrasco-Lizarraga, E. Carrera, W. Carvalho, B. C. K. Casey, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K.M. Chan, A. Chandra, E. Cheu, D. K. Cho, S. Choi, B. Choudhary, T. Christoudias, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, V. Cuplov, D. Cutts, M. Ćwiok, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, K. DeVaughan, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, T. Dorland, A. Dubey, L. V. Dudko, L. Duflot, D. Duggan, A. Duperrin, S. Dutt, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V. D. Elvira, Y. Enari, S. Eno, P. Ermolov, M. Escalier, H. Evans, A. Evdokimov, V.N. Evdokimov, G. Facini, A. V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, W. Geng, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, B. Gómez, A. Goussiou, P. D. Grannis, S. Greder, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Harder, A. Harel, J.M. Hauptman, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, A. P. Heinson, U. Heintz, C. Hensel, I. Heredia-De La Cruz, K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, T. Hoang, J. D. Hobbs, B. Hoeneisen, M. Hohlfeld, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, N. Huske, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, D. Jamin, C. Jarvis, R. Jesik, K. Johns, C. Johnson, M. Johnson, D. Johnston, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, D. Karmanov, P. A. Kasper, I. Katsanos, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y. N. Kharzheev, D. Khatidze, T. J. Kim, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, J.-P. Konrath, A.V. Kozelov, J. Kraus, T. Kuhl, A. Kumar, A. Kupco, T. Kurča, V. A. Kuzmin, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, W.M. Lee, A. Leflat, J. Lellouch, J. Li, L. Li, Q. Z. Li, S.M. Lietti, J. K. Lim, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna-Garcia,34,xA.L. Lyon, A.K.A. Maciel, D. Mackin, P. Mättig, A. Magerkurth, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, Y. Maravin, B. Martin, R. McCarthy, C. L. McGivern, M.M. Meijer, A. Melnitchouk, L. Mendoza, D. Menezes, P. G. Mercadante, M. Merkin, K.W. Merritt, A. Meyer, J. Meyer, J. Mitrevski, R.K. Mommsen, N.K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, H. A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, G. Obrant, C. Ochando, D. Onoprienko, J. Orduna, N. Oshima, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, M. Padilla, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park, S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma,34,k V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, A.V. Popov, C. Potter, W. L. Prado da Silva, S. Protopopescu, J. Qian, A. Quadt, B. Quinn, A. Rakitine, M. S. Rangel, K. Ranjan, P. N. Ratoff, P. Renkel, P. Rich, M. Rijssenbeek, I. Ripp-Baudot, F. Rizatdinova, S. Robinson, R. F. Rodrigues, M. Rominsky, C. Royon, P. Rubinov, R. Ruchti, G. Safronov, G. Sajot, A. Sánchez-Hernández, PRL 103, 191801 (2009) P HY S I CA L R EV I EW LE T T E R S week ending 6 NOVEMBER 2009",,https://www.semanticscholar.org/paper/7575247c49d470823d2e802973f73a513c83fdd1,
622,Bounds for sorting by prefix reversal,,,https://www.semanticscholar.org/paper/2bfc23fef4a712b943098f15c0505041af996d87,Discrete Mathematics
3357,Behavioural ecology of island feral horses,"Resume 
Dans la population equine de l‘ile de Shacklesford Banks au large de la cote est est USA, des changements majeurs de l'organisation sociale sont apparus. Au lieu de vivre classiquement en harems occupant des territoires se “chevauchant”, on s'est rendu compte que certains harems defendaient leur territoire et meme que certains chevaux n'appartenaient meme pas a des groupes fixes. L'existence de ces variations sociales semble etre due a l'habitat et aux caracteristiques geographiques uniques de l’ile. Les territoires, dont les limites couraient le long de l‘ile, n'existaient que la ou celle-ci est etroite, la visibilite non obstruee et ou les principales zones de vegetation courent le long de l'axe principal de l’ile. Ce n'est qu‘a ces endroits que les difficultes de defense etaient reduites et les posibilites de se nourrir et d'assurer la garde pour les mâles etaient superieures. Dans les zones de hautes dunes de sable et de foret epaisse, des assemblages provisoires ont ete observes et des harems sans territoire fixe occupaient les zones semi-ouvertes accidentees avec des mâles celibataires. 
 
Une fois les territoires defendus, de nombreux aspects des relations sociales individuelles changent. Les etalons a territoire ont moins tendance a influencer les activites quotidiennes de leurs groupes et plus a s'occuper de leurs femelles dominantes et a regrouper leurs femelles subordonnees que les etalons sans territoire. De plus, les distances individuelles sont generalement plus grandes entre animaux vivant dans des harems territoriaux par opposition a des harems non territoriaux. 
 
Zusammenfassung 
Bei einer Pferdepopulation auf Shacklesford Banks, einer Insel vor der amerikanischen Ostkuste, haben sich grosere soziale Organisationsveranderungen ereignet. Anstatt in den typischen Harems in sich uberschneidenden Heimatgebieten zu leben, wurde festgestellt, das einige Harems ihre Territorien verteidigten und einige Pferde noch nicht einmal in festen Gruppen lebten. Das Bestehen dieser sozialen Variationen schien mit dem einzigartigen Lebensraum und den geographischen Besonderheiten der Insel in Zusammenhang zu stehen. Territorien, deren Grenzen uber die ganze Breite der Insel verliefen, gab es nur an den Stellen, wo die Insel schmal und die Sicht unbegrenzt war und wo die Vegetationszonen entlang der Langsachse der Insel verliefen. Nur hier waren die Schwierigkeiten der Verteidigung reduziert und die Ernahrung sowie die Moglichkeit der mannlichen Partnerbewachung besser. Wo die Sanddunen hoch und die Walder dicht waren, fanden zeitweise Zusammenschlusse statt, und nichtterritoriale Harems bewohnten zusammen mit den weibchenlosen Mannchen die uneinheitliche, halboffene Landschaft. Mit dem Beginn der Territoriumsverteidigung veranderten sich auch zahlreiche Aspekte der individuellen sozialen Verhaltnisse. Territoriale Hengste neigten weniger dazu, das tagliche Aktivitatsmuster ihrer Gruppe zu beeinflussen, und tendierten eher dazu, ihre dominanten Weibchen zu versorgen und zu pflegen und ihre untergeordneten Weibchen zusammenzutreiben als ihre nicht-territorialen Gegenstucke. Bei territorialen Harems wurden auch grosere Abstande zwischen den einzelnen Tieren beobachtet als bei nichtterritorialen. 
 
Summary 
In a horse population on Shackleford Banks, an island off the American east coast, major changes in social organisation have occurred. Instead of typically living in harems occupying overlapping home ranges, it was found that some harems defended territories and some horses did not even live in fixed membership groups. The existence of these social variations appeared to be correlated with the unique habitat and geographical features of the island. Territories, whose boundaries ran the width of the island, only occurred where the island was narrow, the visibility unrestricted and the essential vegetation zones ran along the island's long axis. Only here were the difficulties in defending reduced and feeding and male mate-guarding opportunities increased. Where the sand dunes were high and forest dense temporary assemblages occurred and non-territorial harems occupied the patchy semi-open area with the batchelor males. 
 
Once territories were defended many aspects of individual social relationships became altered. Territorial stallions were less likely to influence the daily activity patterns of their groups and more likely to groom their dominant females and round-up their subordinate females than were their non-territorial counterparts. In addition, interpersonal distances were likely to be greater among horses living in territorial, as opposed to nonterritorial, harems.",,https://www.semanticscholar.org/paper/bc9ed4dee967daba78301a63d349306748538ccb,
2434,Hatching for 3D prints: line-based halftoning for dual extrusion fused deposition modeling,,2018-05-03,https://www.semanticscholar.org/paper/5c5bc850bb55d80e3748126cf6bc88fb3fb75cfb,Computers & graphics
1068,Study of the Decay Bs0 âƒTM Ds(*)Ds(*),,,https://www.semanticscholar.org/paper/1d0f16b74312c025af62510d319c43bab6fafdbb,
1383,WIMP exclusion results from the CDMS experiment,In early 2000 CDMS set the most competitive exclusion limit for scalar-interaction WIMPs at the Stanford Underground Facility (SUF). A new search (CDMS II) is now commencing at the Deep-site Soudan Facility.,2003-05-01,https://www.semanticscholar.org/paper/0d2089d2d0a3b78635139ecd87be4539f75b82c0,
1033,The three-link nonholonomic snake as a hybrid kinodynamic system,"Motion planners often avoid the so-called singular configurations of a locomoting system because they can change a system's dynamics and cause it to incur unbounded input controller costs. However, such configurations can also allow a system to exhibit new modes of locomotion, which can be incorporated into previously established planning techniques. Here we take a nonholonomic kinematic system and present the formalism for representing it as a hybrid system taking advantage of the singular configuration and the associated dynamics. We show how to achieve the transition maps between the modes of operation by allowing actuated joints to become passive or locked, circumventing problems with unbounded constraint forces. This new model offers a new capability to take advantage of drift dynamics and rolling motions, which we demonstrate using a switching controller involving established kinematic techniques and preliminary dynamic maneuvers.",2016-07-06,https://www.semanticscholar.org/paper/d89d57cf06364b4740574c7d8b47493efffff13d,American Control Conference
1956,Inventory survival analysis for semiconductor memory manufacturing,"The high variety of and intermittent demand for semiconductor memory products frequently limits the use of forecast error normalization in estimating inventory. Inventory turnover is a practical performance indicator that is used to calculate the number of days for which a company retains inventory before selling a product. Although previous studies on inventory level settings have primarily applied information regarding demand variability and forecast error, few studies have investigated the inventory turnover for inventory decisions. Inventory turnover data are time scaled, suited for a small sample, and right censored to fit the input of survival analysis. In this study, a model in which inventory turnover and survival analysis were integrated was developed to estimate the production inventory survival function used to determine inventory level. Data analysis results based on real settings indicated the viability of using inventory survival analysis to determine semiconductor memory inventory level settings.",2014-12-07,https://www.semanticscholar.org/paper/441fa7fb9ed08e278268761d0e6aec4adff23714,Proceedings of the Winter Simulation Conference 2014
2108,A retrospective study of the development of theories of industrial engineering and its application in Taiwan,,,https://www.semanticscholar.org/paper/ad38744839fdfcc3c48038b07ab2e7c1ed59d413,
3433,An O(n5/2logn) algorithm for the Rectilinear Minimum Link-Distance Problem in three dimensions,,2009-07-01,https://www.semanticscholar.org/paper/c20973a4a4703b5cfbd9c92eca82228981bcd68e,Computational geometry
909,On notions of information transfer in VLSI circuits,"Several papers have recently dealt with techniques for proving area-time lower bounds for VLSI computation by “crossing sequence” methods. A number of natural questions are raised by these definitions. 1.Is the fooling set approach the most powerful way to get information-transfer-based lower bounds? We shall show it is not, and offer a candidate for the title “most powerful.” Of course, without a precise definition of “information transfer argument,” there could be other contenders. 2.Are the notions of the three papers cited equivalent? We shall exhibit certain inequivalences among the three notions, although open questions remain. However, we can resolve an open question of Papadimitriou and Sipser [PS] concerning the relationship between nondeterministic and deterministic communication complexity.",1983-12-01,https://www.semanticscholar.org/paper/b2027f32f45b30c810acf95bf2748eb064c3bb90,Symposium on the Theory of Computing
2624,Taking it to the streets: how virtual reality can change mobile computing,"Virtual reality has long been an indoor affair. Whether constrained by stationary computers ordisplays, or by the limitations of our tracking technologies, researchers typically build virtualenvironments that work within a single physical room or a portion of a room. Even distributedvirtual reality systems usually interconnect two or more such indoor spaces. Meanwhile, ascomputers grow ever smaller and faster, mobile computing is becoming an increasingly importantpart of our daily lives, accompanying us wherever we go, outdoors, as well as indoors.What will it take for virtual reality to move outdoors and finally see the light of day? And, whyshould we care? Within the virtual reality research community, work on augmented reality hasalready begun to explore outdoor environments-tracking using computer vision, gyroscopes,accelerometers, compasses, and GPS; and experimenting with (barely) wearable testbeds. I willdiscuss why virtual reality (especially in the form of augmented reality) and mobile computing are asynergistic combination, and will provide an overview of the research problems that must beaddressed for mobile augmented reality systems to play a major role in our future.Among the issues that I will review are overcoming physical and aesthetic barriers to mobilityand wearability; tracking and registration of heads, hands, bodies, and other objects; renderingvirtual objects in the real world; and developing sufficiently high quality displays. Equallyimportant is the design of head-tracked user interfaces that are well suited to mobility. Wearablesystems will need to support collaboration among mobile users, facile interaction with real andvirtual objects, and coordination across a wide range of heterogeneous displays and devices. Keyhere is the volatile nature of mobile interactions-users continually move into and out of thepresence of other users, devices, and objects, and rapidly change tasks. Furthermore, augmentedreality makes it possible for real and virtual objects to share the same display space, creating thepotential for a variety of visually confusing relationships as objects overlap and occlude each other.Avoiding these problems will require that the virtual world be redesigned and laid out on the fly, tomaintain desired visual relationships between virtual objects and other real and virtual objects.",2003-03-22,https://www.semanticscholar.org/paper/ad0dd2bff4744a367996843689710ba0bcae5da3,"IEEE Virtual Reality, 2003. Proceedings."
3505,Finding Real-Valued Single-Source Shortest Paths,,1996-06-03,https://www.semanticscholar.org/paper/2c7317e7bce5fd473b5eea232d1ffdd27429b0a5,Conference on Integer Programming and Combinatorial Optimization
3130,Thin Client Performance for Remote 3-D Image Display,"Several trends in biomedical computing are converging in a way that will require new approaches to telehealth image display. Image viewing is becoming an ""anytime, anywhere"" activity. In addition, organizations are beginning to recognize that healthcare providers are highly mobile and optimal care requires providing information wherever the provider and patient are. Thin-client computing is one way to support image viewing this complex environment. However little is known about the behavior of thin client systems in supporting image transfer in modern heterogeneous networks. Our results show that using thin-clients can deliver acceptable performance over conditions commonly seen in wireless networks if newer protocols optimized for these conditions are used.",,https://www.semanticscholar.org/paper/55bd56ec8241880b92972cbb2b59e2136a4cc745,American Medical Informatics Association Annual Symposium
3730,Learning to Learn Words from Visual Scenes,,2019-11-25,https://www.semanticscholar.org/paper/007ca8ca7a68451c32da034c72a06238434843c1,European Conference on Computer Vision
2346,Neutrophils isolated fromthesynovial fluid of patients withrheumatoid arthritis: priming and activationin vivo,,,https://www.semanticscholar.org/paper/a6dcabb73abcfe6a7111c970216059c0ced8da1e,
2147,Online Broadcasting with Network Coding,"Consider a source broadcasting M packets to N receivers over independent erasure channels, where perfect feedback is available from the receivers to the source, and the source is allowed to use coding. We investigate offline and online algorithms that optimize delay, both through theoretical analysis as well as simulation results.",2008-03-31,https://www.semanticscholar.org/paper/b8c9dd37746f10f466f0cf59afd29a7b7e09decd,"2008 Fourth Workshop on Network Coding, Theory and Applications"
2118,Sampling strategy and model to measure and compensate overlay errors,"Overlay is one of the key designed rules for producing VLSI devices. In order to have a better resolution and alignment accuracy in lithography process, it is important to model the overlay errors and then to compensate them into tolerances. This study aimed to develop a new model that bridges the gap between the existing theoretical models and the data obtained in real settings and to discuss the overlay sampling strategies with empirical data in a wafer fab. In addition, we used simulation to examine the relations between the various factors and the caused overlay errors. This paper concluded with discussions on further research.",2001-08-22,https://www.semanticscholar.org/paper/c0202599d024955251d1ce5c83f1082a6732d422,SPIE Advanced Lithography
1535,Adjusting for indirectly measured confounding using large-scale propensity score,,2021-10-23,https://www.semanticscholar.org/paper/06546042da3547154d7446832dd5943c0b92bcbe,Journal of Biomedical Informatics
3181,Social dilemmas of sociality due to beneficial and costly contagion,"Levels of sociality in nature vary widely. Some species are solitary; others live in family groups; some form complex multi-family societies. Increased levels of social interaction can allow for the spread of useful innovations and beneficial information, but can also facilitate the spread of harmful contagions, such as infectious diseases. It is natural to assume that these contagion processes shape the evolution of complex social systems, but an explicit account of the dynamics of sociality under selection pressure imposed by contagion remains elusive. We consider a model for the evolution of sociality strategies in the presence of both a beneficial and costly contagion. We study the dynamics of this model at three timescales: using a susceptible-infectious-susceptible (SIS) model to describe contagion spread for given sociality strategies, a replicator equation to study the changing fractions of two different levels of sociality, and an adaptive dynamics approach to study the long-time evolution of the population level of sociality. For a wide range of assumptions about the benefits and costs of infection, we identify a social dilemma: the evolutionarily-stable sociality strategy (ESS) is distinct from the collective optimum—the level of sociality that would be best for all individuals. In particular, the ESS level of social interaction is greater (respectively less) than the social optimum when the good contagion spreads more (respectively less) readily than the bad contagion. Our results shed light on how contagion shapes the evolution of social interaction, but reveals that evolution may not necessarily lead populations to social structures that are good for any or all.",2022-02-20,https://www.semanticscholar.org/paper/9a8161c23ea8cd73c3c4cb1b25b5595ed8230e77,PLoS Comput. Biol.
987,An Evaluation of the in vivo Safety of Nonporous Silica Nanoparticles: Ocular Topical Administration versus Oral Administration,,2017-08-15,https://www.semanticscholar.org/paper/b8b76a3e45aa224944b8010a3054ebb0c1ec4297,Scientific Reports
1411,Search for heavy particles decaying into electron-positron pairs in p-pbar collisions,"We present results of searches for technirho, techniomega, and Z' particles, using the decay channels technirho, techniomega, Z' ->e+e-. The search is based on 124.8 pb-1 of data collected by the D0 detector at the Fermilab Tevatron during 1992-1996. In the absence of a signal, we set 95% C.L. upper limits on the cross sections for the processes p pbar ->technirho, techniomega, Z' ->e+e- as a function of the mass of the decaying particle. For certain model parameters, we exclude the existence of degenerate technirho and techniomega states with masses below about 200 GeV. We exclude a Z' with mass below 670 GeV, assuming that it has the same couplings to fermions as the Z boson.",2001-02-24,https://www.semanticscholar.org/paper/65f01ed7058cf979a245f14dc1352cb9fe02f138,
1496,Multimuon final states in muon-nucleon scattering at 270 GeV,"Data from a new muon-nucleon scattering experiment includes 513 events, of which 449 are dimuons and 64 are trimuons. Conventional hadronic and electromagnetic processes account for less than 15% of these events. Model calculations suggest that the majority of the dimuons result from associated charm production with a total cross section of about 3 nb.",1979-11-19,https://www.semanticscholar.org/paper/ca103c20e1252009ccda916f761471bedc93f929,
2810,The involvement of the spleen during chronic phase of Schistosoma mansoni infection in galectin-3-/- mice.,"Schistosoma mansoni synthesizes glycoconjugates which interact with galectin-3, eliciting an intense humoral immune response. Moreover, it was demonstrated that galectin-3 regulates B cell differentiation into plasma cells. Splenomegaly is a hallmark event characterized by polyclonal B cell activation and enhancement of antibody production. Here, we investigated whether galectin-3 interferes with spleen organization and B cell compartment during chronic schistosomiasis, using wild type (WT) and galectin-3-/- mice. In chronically-infected galectin-3-/- mice the histological architecture of the spleen, including white and red pulps, was disturbed with heterogeneous lymphoid follicles, an increased number of plasma cells (CD19-B220-/lowCD138+) and a reduced number of macrophages (CD19-B220-Mac-1+CD138-) and B lymphocytes (CD19+B220+/highCD138-), compared with the WT infected mice. In the absence of galectin-3 there was an increase of annexin-V+PI- cells and a major presence of apoptotic cells in spleen compared with WT infected mice. In spleen of WT infected mice galectin-3 was largely expressed in lymphoid follicles and extrafollicular sites. Thus, we propose that galectin-3 plays a role in splenic architecture, controlling distinct events such as apoptosis, macrophage activity, B cell differentiation and plasmacytogenesis in the course of S. mansoni infection.",2012-08-01,https://www.semanticscholar.org/paper/c0eae18e21823bc305c980dc4a86f0a8f47876a1,Histology and Histopathology
498,On Selecting a Satisfying Truth Assignment (Extended Abstract),,,https://www.semanticscholar.org/paper/4c89a88a678ce4a2c9b2ea66739da41c8c9a09c8,IEEE Annual Symposium on Foundations of Computer Science
2533,ActiveNotes: computer-assisted creation of patient progress notes,"We present activeNotes, a prototype application that supports the creation of Critical Care Notes by physicians in a hospital intensive care unit. activeNotes integrates automated, context-sensitive patient data retrieval and user control of automated data updates and alerts into the note-creation process. In a user study at New York Presbyterian Hospital, we gathered qualitative feedback on the prototype from 15 physicians. The physicians found activeNotes to be valuable and said they would use it to create both formal notes for medical records and informal notes. One surprising finding is that while physicians have rejected template-based clinical documentation systems in the past, they expressed a desire to use activeNotes to create personalized, physician-specific note templates to be reused with a given patient, or for a given condition.",2009-04-04,https://www.semanticscholar.org/paper/567334b48820323b2472bc1584f2ceb909bc27e7,CHI Extended Abstracts
528,Computational complexity of generalized graph coloring problems,"In this work we study a wide class of problems in graph theory, called generalized node-coloring problems, defined as follows: given graphs $G$ and $H$, can the nodes of $H$ be colored with $k$ colors to avoid containing $G$ as a subgraph in each color component? 
For each fixed choice of $G$ and $k$, we denote such problem as the generalized coloring problem with respect to $G$ and $k$, or GCP$\sb{G,k}$. When $G$ is $K\sb2$ (i.e., a single edge), then GCP$\sb{K\sb2,k}$ becomes the ordinary node-coloring problem (OCP$\sb{k}$). Therefore, the class of problems we consider is a natural generalization of the OCP, generalizing the forbidden subgraph from $K\sb2$ to an arbitrary one. The generalized coloring problems are abstractions of graph partitioning problems that are of interest in distributed operating systems, constraint satisfaction in artificial intelligence, VLSI design, and resource allocation. 
We completely characterize the complexity of the class of generalized coloring problems GCP$\sb{G,k}$. In fact, this characterization is a special case of our complete characterization of the class of all the problems of avoiding any nontrivial finite family of graphs $F$ (denoted GCP$\sb{F,k}$), rather than a single graph. We prove that all such problems are NP-complete for three or more colors. For two colors, they are NP-complete when $F$ does not contain a graph of maximum degree one. Otherwise, it is in ${\cal P}$, and we exhibit a polynomial-time (in fact, ${\cal NC}$) algorithm for the solution of such problems. 
We also consider what happens when $G$ is part of the input. This problem, denoted $GCP\sb{k}$, can be viewed as the composition of an NP-complete problem with a co-NP-complete problem. We show that, in this case, deciding whether $H$ can be colored (even with two colors) to avoid $G$ is $\Sigma\sbsp{2}{p}$-complete. This result involves an interesting extension of our reduction techniques, and appears to be the first natural graph problem known to be complete for an intermediate level of the polynomial hierarchy. 
The same techniques can be generalized to prove the $\Sigma\sbsp{2}{p}$-completeness of other related problems, including that of the Generalized Node Deletion Problem with forbidden subgraphs being part of the input. This theorem is an extension of the results of Yannakakis, who proved NP-hardness of Node Deletion Problems with fixed forbidden graphs. This result is in turn used in establishing the $\Sigma\sbsp{2}{p}$-completeness of the Clause Maintenance System, an important paradigm in artificial intelligence.",,https://www.semanticscholar.org/paper/445544b4ead154da47bda8660629095752dd979d,
3202,Global Marine Fishing across Space and Time,"Human health and livelihoods are threatened by declining marine fisheries catches, causing substantial interest in the sources and dynamics of fishing. Catch analyses in individual exclusive economic zones (EEZs) and the high seas are abundant, and research across multiple EEZs is growing. However, no previous studies have systematically compared catches, intranational versus international fish flows, and fishing nations within all of the world’s EEZs and across adjacent and distant EEZs and the high seas to inform “metacoupled” fisheries management. We use the metacoupling framework—a new approach for evaluating human–nature interactions within and across adjacent and distant systems (metacouplings)—to illustrate how fisheries catches were locally, regionally, and globally interconnected in 1950–2014, totaling 5.8 billion metric tons and increasing by 298% (tonnage) and 431% (monetary value) over this time period. Catches by nations in their own EEZs (largest in Peru) and adjacent EEZs (largest in Indonesia) constituted 86% of worldwide catches, growing in 1950–1996 but declining in 1997–2014. In contrast, catches in distant EEZs and the high seas—largest in Morocco, Mauritania, and Canada—peaked in 1973 and have since represented 9–21% of annual catches. Our 65-year, local–regional–global analysis illustrates how metacoupled fisheries governance—holistic management of multiscalar catches, flows, and tradeoffs within and among fisheries—can improve food and nutrition security, livelihood resilience, and biodiversity conservation across the world.",2020-06-01,https://www.semanticscholar.org/paper/07c4bf054e249e7f4a7d4caca62db7d82f7d0423,Sustainability
343,Networks and Games,,2004-12-19,https://www.semanticscholar.org/paper/3aa9447d39762e7cd2d298f8c99c3e7ad77c810d,International Conference on High Performance Computing
3306,"Social relationships and reproductive state influence leadership roles in movements of plains zebra, Equus burchellii
",,2007-05-01,https://www.semanticscholar.org/paper/02f6d0ca8b1d8bc6bf480312658bced412abf759,Animal Behaviour
113,Merging Ranks from Heterogeneous Internet Sources,"Many sources on the Internet and elsewhere rank the objects in query results according to how well these objects match the original query. For example, a real-estate agent might rank the available houses according to how well they match the user's preferred location and price. In this environment, ``meta-brokers'' usually query multiple autonomous, heterogeneous sources that might use varying result-ranking strategies. A crucial problem that a meta-broker then faces is extracting from the underlying sources the top objects for a user query according to the meta-broker's ranking function. This problem is challenging because these top objects might not be ranked high by the sources where they appear. In this paper we discuss strategies for solving this ``meta-ranking'' problem. In particular, we present a condition that a source must satisfy so that a meta-broker can extract the top objects for a query from the source without examining its entire contents. Not only is this condition necessary but it is also sufficient, and we show an efficient algorithm to extract the top objects from sources that satisfy the given condition.",1997-08-25,https://www.semanticscholar.org/paper/15c5cd0f4bc3fa966924a8a76118f6011dffba41,Very Large Data Bases Conference
916,Freedom from Deadlock of Safe Locking Policies,"The usual method for preserving the consistency of a database when accessed (read and updated) concurrently by several transactions, is by locking the transactions according to some locking policy; a locking policy that guarantees the preservation of consistency of the database is called safe. Furthermore, if no deadlocks can arise the policy is called deadlock-free. In this paper we are concerned with the freedom from deadlock of safe locking policies. We show that a simple extension of the DAG policy of [Y] is the most general safe and deadlock-free policy for a pair of transactions. We prove however, that it is NP-complete to test whether a set of transactions is not deadlock-free even for the simplest kind of transactions, those that are two-phase locked [E]. We show that for the natural class of safe locking policies, the L-policies, studied in [Y], freedom from deadlock is determined only by the order in which entities are accessed by the transactions and not by the way in which safety is ensured. A...",1982-05-01,https://www.semanticscholar.org/paper/a55c37c432b6550867bbbcf96e0360ba9a9fcd86,SIAM journal on computing (Print)
1285,LIMITS ON THE WIMP-NUCLEON CROSS-SECTION FROMTHE CRYOGENIC DARK MATTER,,,https://www.semanticscholar.org/paper/9886b4dcc6793e8ef2d9e7ad312469b56c00a472,
1819,PU-BCD: Exponential Family Models for the Coarse- and Fine-Grained All-Words Tasks,This paper describes an exponential family model of word sense which captures both occurrences and co-occurrences of words and senses in a joint probability distribution. This statistical framework lends itself to the task of word sense disambiguation. We evaluate the performance of the model in its participation on the SemEval-2007 coarse- and fine-grained all-words tasks under a variety of parameters.,2007-06-23,https://www.semanticscholar.org/paper/1df5e35f08cfb8105d34bd97848b877ebfa6ccf6,International Workshop on Semantic Evaluation
1320,Search for particles decaying into a Z boson and a photon in p(p)over-bar collisions at root s=1.96 TeV,,2006-10-01,https://www.semanticscholar.org/paper/7178217ea8c5a1b026a4ba7b393de26591eb924c,
3374,An Examination of Social Participation Found among a National Sample of Black and White Elderly,"Family and kin often are the primary source for emotional support in the later years. Older people are expected to attach a relatively higher value to the emotional aspects of life as other social functions diminish. They are expected to develop a greater orientation to affective, expressive, and affectional goals (Rosow, 1967). Consequently, the family and kinship system becomes the major social institution for the social participation of elderly people. At a time of life when emotional security is so greatly challenged (Simpson and McKinney, 1969), one’s family and kin are expected to provide the necessary support for one’s morale or well-being. In this article I will identify and describe the Black older person, and examine his social participation (in comparison with White aged) with family and kin. Social participation is here defined as the activity with other people that contributes to one’s social relationships which he comes to depend on for emotional support and responsiveness and which maintain him in many subtle ways (Lehr and Rudinger, 1969). To provide a framework for this examination, one assumption is made and one hypothesis is posed. It is assumed that: There are demographic differences between Black and White elderly; that is, when income, marital status, education, occupation, and religion are examined by sex, residential location and race are expected to differ significantly. It is hypothesized that: Household situations are different for Black and White elderly. It is proposed that these differences show that the elderly Black are more likely to live alone or in household situations without spouse and that White elderly are more likely to live with a spouse as a couple, or in household situations with a spouse. It is further hypothesized that Black elderly persons living alone or without a spouse have a low state of morale or well-being in old age.",1971-04-15,https://www.semanticscholar.org/paper/79d77a7660fe638a34b1f45e8269908abf64675b,
2672,Visual task characterization for automated visual discourse synthesis,"To develop a comprehensive and systematic approach to the automated design of visual discourse, we introduce a visual task taxonomy that interfaces high-level presentation intents with low-level visual techniques. In our approach, visual tasks describe presentation intents through their visual accomplishments, and suggest desired visual techniques through their visual implications. Therefore, we can characterize visual tasks by their visual accomplishments and implications. Through this characterization, visual tasks can guide the visual discourse synthesis process by specifying what presentation intents can be achieved and how to achieve them.",1998-01-01,https://www.semanticscholar.org/paper/4eafbddeabb3c1f4143b8ee190680d0bdcd398f3,International Conference on Human Factors in Computing Systems
2726,Generating Cross-References for Multimedia Explanation,"When explanations include multiple media, such as text and illustrations, a reference to an object can be made through a combination of media. We call part of a presentation that references material elsewhere a cross-reference. We are concerned here with how textual expressions can refer to parts of accompanying illustrations. The illustration to which a cross-reference refers should also satisfy the specific goal of identifying an object for the user. Thus, producing an effective cross-reference not only involves text generation, but may also entail modifying or replacing an existing illustration and in some cases, generating an illustration where previously none was needed. In this paper, we describe the different types of cross-references that COMET (COordinated Multimedia Explanation Testbed) generates and show the roles that both its text and graphics generators play in this process.",1992-07-12,https://www.semanticscholar.org/paper/2cac67b2b327512ce2c44df4f97632db5b434715,AAAI Conference on Artificial Intelligence
1406,Search for Heavy Particles Decaying into Electron-positron Pairs in Pp Collisions,,,https://www.semanticscholar.org/paper/0ce642461e46eef38a2186b6cd032acb90715304,
3551,Foundations of C++,,2012-03-24,https://www.semanticscholar.org/paper/c53e9984c66db460c2005256a1028117ca00faef,European Symposium on Programming
2725,Cutaways and ghosting: satisfying visibility constraints in dynamic 3D illustrations,,1992-09-01,https://www.semanticscholar.org/paper/21d3e6dcfb3ac93c1124f09118bb636e959728af,The Visual Computer
574,A simple criterion for structurally fixed modes,,1984-09-01,https://www.semanticscholar.org/paper/4d23c0cb5122abf68b1a1654301c391cb0154ff7,
62,Proceedings of the 7th International Workshop on the Web and Databases: colocated with ACM SIGMOD/PODS 2004,,2004-06-17,https://www.semanticscholar.org/paper/df601aeb0734178e660944b5381c328063f2e62c,
1240,Evidence for the decay Bs0-->Ds(*)Ds(*) and a measurement of DeltaGammasCP/Gammas.,"We search for the semi-inclusive process Bs0-->Ds(*)Ds(*) using 2.8 fb(-1) of pp collisions at sqrt[s]=1.96 TeV recorded by the D0 detector operating at the Fermilab Tevatron Collider. We observe 26.6+/-8.4 signal events with a significance above background of 3.2 standard deviations yielding a branching ratio of B(Bs0-->Ds(*)Ds(*))=0.035+/-0.010(stat.)+/-0.011(syst.). Under certain theoretical assumptions, these double-charm final states saturate CP-even eigenstates in the Bs0 decays resulting in a width difference of DeltaGammasCP/Gammas=0.072+/-0.021(stat.)+/-0.022(syst.).",2008-11-13,https://www.semanticscholar.org/paper/968a8a289dfa1e1c1033140ba281fdb3d0464b56,Physical Review Letters
1573,Counterfactual inference for consumer choice across many product categories,,2019-06-06,https://www.semanticscholar.org/paper/818d138bb6614f226a6cf73f69404ca917aebfdf,Quantitative Marketing and Economics
1795,Connections between the lines: augmenting social networks with text,"Network data is ubiquitous, encoding collections of relationships between entities such as people, places, genes, or corporations. While many resources for networks of interesting entities are emerging, most of these can only annotate connections in a limited fashion. Although relationships between entities are rich, it is impractical to manually devise complete characterizations of these relationships for every pair of entities on large, real-world corpora.
 In this paper we present a novel probabilistic topic model to analyze text corpora and infer descriptions of its entities and of relationships between those entities. We develop variational methods for performing approximate inference on our model and demonstrate that our model can be practically deployed on large corpora such as Wikipedia. We show qualitatively and quantitatively that our model can construct and annotate graphs of relationships and make useful predictions.",2009-06-28,https://www.semanticscholar.org/paper/161cc1dc14a4c30f16b35fac1868f4b9b9ad7f1d,Knowledge Discovery and Data Mining
3173,More than ponds amid skyscrapers: Urban fisheries as multiscalar human–natural systems,"Although social-ecological fisheries research is growing, comparatively little attention is paid to fisheries in urban environments. We aim to address this imbalance, because as cities expand worldwide, we expect urban fisheries to become more widespread and important in providing food/nutrition security, recreation, community well-being, and other benefits to fisheries stakeholders and urban dwellers across spatiotemporal scales. This paper contains a first analysis of the economic and sociocultural provisions, trade-offs, and dilemmas associated with urban fisheries to yield insights for sustainable management and planning of urban blue space. To address these objectives, we use the metacoupling framework, a method for assessing human–nature interactions within and across adjacent and distant fisheries systems. We use examples from multiple countries and data from the United States to illustrate how urban fisheries encompass flows of people, money, and information across multiple spatiotemporal scales and provide nutritional, recreational, social, and cultural benefits to fisheries stakeholders. Throughout the world, urban fisheries are influenced by wide-ranging human needs (e.g. food provisioning, recreation, aquatic resource education) that generate social-ecological effects within and beyond cities. Our analysis yields insights for developing holistic, metacoupling-informed management approaches that address the diverse social-ecological objectives and trade-offs involved in sustainable development of urban fisheries.",2022-01-01,https://www.semanticscholar.org/paper/2d5494e7702209a3a79cc2f8157f2e17bf405753,Aquatic Ecosystem Health & Management
3623,The Real Stroustrup Interview,"argued that "" a programming language is really a very tiny part of the world, and as such, it ought not be taken too seriously. Keep a sense of proportion and most importantly keep a sense of humor. Among major programming languages, C++ is the richest source of puns and jokes. That is no accident. "" For the past few months, a hoax interview between Stroustrup and Computer has been making the rounds in cyberspace. While we regret the incident , it offers us a welcome opportunity to have the father of C++ share his insights on Standard C++ and software development in general. We can also attest to his continued sense of proportion and humor—he suggests that the fictitious interview would have been a much funnier parody had he written it himself. STANDARD C++ Computer: ISO approved the Standard C++ in November 1997, and you published a third edition of your The C++ Programming Language (Addison Wes-ley, 1997). How has C++ evolved over the past few years and what does the ISO standard mean for the C++ community? Stroustrup: It is great to finally have a complete, detailed, and stable definition of C++. This will be a great help to the C++ community in myriad direct and not-so-direct ways. Obviously, we will get better implementations as compiler providers start shifting attention from catching up with the standards committee to quality-of-implementation issues. This is already happening. Standards-conforming implementations will prove a boon to tools and library suppliers by providing a larger common platform to build for. The standard gives the programmer an opportunity to be more adventurous with new techniques. Programming styles that used to be unrealistic in production code are becoming realistic propositions. Thus, more flexible, general , faster, and more maintainable code can be written. Naturally, we should keep cool and not indulge in orgies of "" advanced "" techniques. There are still no miracles, and the best code is still the code that most directly matches a sound design. However , now is the time to experiment and see which techniques will suit particular people, organizations, and projects. Much of The C++ Programming Language is devoted to these techniques and the trade-offs they represent. The most visible aspects of what makes this progress feasible are the "" new "" major language facilities—tem-plates, exceptions, runtime type information , and namespaces—and the new standard library. The minor improvements to …",1998-06-01,https://www.semanticscholar.org/paper/9717316c4089f6220cb28ee9f2b7d46961bc6e6f,Computer
3514,Improved Algorithms for Bipartite Network Flow,"In this paper, network flow algorithms for bipartite networks are studied. A network $G=(V,E)$ is called bipartite if its vertex set $V$ can be partitioned into two subsets $V_1$ and $V_2$ such that all edges have one endpoint in $V_1$ and the other in $V_2$. Let $n=|V|$, $n_1 = |V_1|$, $n_2 = |V_2|$, $m=|E|$ and assume without loss of generality that $n_1 \leq n_2$. A bipartite network is called unbalanced if $n_1 \ll n_2$ and balanced otherwise. (This notion is necessarily imprecise.) It is shown that several maximum flow algorithms can be substantially sped up when applied to unbalanced networks. The basic idea in these improvements is a two-edge push rule that allows one to ""charge"" most computation to vertices in $V_1$, and hence develop algorithms whose running times depend on $n_1$ rather than $n$. For example, it is shown that the two-edge push version of Goldberg and Tarjan's FIFO preflow-push algorithm runs in $O(n_1 m + n_1^3)$ time and that the analogous version of Ahuja and Orlin's excess scaling algorithm runs in $O(n_1 m + n_1^2 log U)$ time, where $U$ is the largest edge capacity. These ideas are also extended to dynamic tree implementations, parametric maximum flows, and minimum-cost flows.",1994-10-01,https://www.semanticscholar.org/paper/8e3bf550416964efd451b33f06d30a6f4c763074,SIAM journal on computing (Print)
288,On the complexity of reconfiguration problems,,2008-10-03,https://www.semanticscholar.org/paper/53d06855ade3e9de5efa0c7fb47fd424981c6225,Theoretical Computer Science
2483,Webizing mobile AR contents,"This paper presents a content structure to build mobile AR applications in HTML5 to achieve a clean separation of mobile AR contents from their application logic to scale like the web. By extending POIs (Point of Interest) to objects and places with Uniform Resource Identifier (URI), we could build objects of interest for mobile AR application as DOM (Document Object Model) elements and control their behavior and user interactions through DOM events. Using our content structure, a mobile AR applications can be developed as normal HTML documents seamlessly under current web eco-system.",2013-03-18,https://www.semanticscholar.org/paper/2957395fc48b1c2338ae3dbf696b940379d1eb89,IEEE Conference on Virtual Reality and 3D User Interfaces
2850,Role of galectin-3 in prion infections of the CNS.,,2007-08-03,https://www.semanticscholar.org/paper/57d41d27a733abba2ebfb616d2c33d03b5133551,Biochemical and Biophysical Research Communications - BBRC
1494,Further Measurement of Nucleon Structure Function in High-energy Muon - Iron Interactions,,,https://www.semanticscholar.org/paper/2d95366a4cd3d6af446a1b0941736a791f7af77a,
1599,Avoiding Latent Variable Collapse With Generative Skip Models,"Variational autoencoders learn distributions of high-dimensional data. They model data with a deep latent-variable model and then fit the model by maximizing a lower bound of the log marginal likelihood. VAEs can capture complex distributions, but they can also suffer from an issue known as ""latent variable collapse,"" especially if the likelihood model is powerful. Specifically, the lower bound involves an approximate posterior of the latent variables; this posterior ""collapses"" when it is set equal to the prior, i.e., when the approximate posterior is independent of the data. While VAEs learn good generative models, latent variable collapse prevents them from learning useful representations. In this paper, we propose a simple new way to avoid latent variable collapse by including skip connections in our generative model; these connections enforce strong links between the latent variables and the likelihood function. We study generative skip models both theoretically and empirically. Theoretically, we prove that skip models increase the mutual information between the observations and the inferred latent variables. Empirically, we study images (MNIST and Omniglot) and text (Yahoo). Compared to existing VAE architectures, we show that generative skip models maintain similar predictive performance but lead to less collapse and provide more meaningful representations of the data.",2018-07-12,https://www.semanticscholar.org/paper/5f4bee489f595bd3d3dda7fd88de8d79b006aa52,International Conference on Artificial Intelligence and Statistics
2193,Neutrophil biomarkers predict response to therapy with tumor necrosis factor inhibitors in rheumatoid arthritis,"Neutrophils are implicated in the pathology of rheumatoid arthritis (RA), but the mechanisms regulating their activation are largely unknown. RA is a heterogeneous disease, and whereas many patients show clinical improvement during TNF inhibitor (TNFi) therapy, a significant proportion fails to respond. In vitro activation of neutrophils with agents, including TNF, results in rapid and selective changes in gene expression, but how neutrophils contribute to TNF signaling in RA and whether TNFi sensitivity involves differential neutrophil responses are unknown. With the use of RNA sequencing (RNA‐Seq), we analyzed blood neutrophils from 20 RA patients, pre‐TNFi therapy, to identify biomarkers of response, measured by a decrease in disease activity score based on 28 joint count (DAS28), 12 wk post‐therapy. Biomarkers were validated by quantitative PCR (qPCR) of blood neutrophils from 2 further independent cohorts of RA patients: 16 pre‐TNFi and 16 predisease‐modifying anti‐rheumatic drugs (DMARDs). Twenty‐three neutrophil transcripts predicted a 12‐wk response to TNFi: 10 (IFN‐regulated) genes predicting a European League against Rheumatism (EULAR) good response and 13 different genes [neutrophil granule protein (NGP) genes] predicting a nonresponse. Statistical analysis indicated a predictive sensitivity and specificity of each gene in the panel of >80%, with some 100% specific. A combination of 3 genes [cytidine monophosphate kinase 2 (CMPK2), IFN‐induced protein with tetratricopeptide repeats 1B (IFIT1B), and RNASE3] had the greatest predictive power [area under the curve (AUC) 0.94]. No correlation was found for a response to DMARDs. We conclude that this panel of genes is selective for predicting a response to TNFi and is not a surrogate marker for disease improvement. We also show that in RA, there is great plasticity in neutrophil phenotype, with circulating cells expressing genes normally only expressed in more immature cells.",2017-03-01,https://www.semanticscholar.org/paper/d8cf40856abe734ac803bb3b0020619a7a13ad17,Journal of Leukocyte Biology
335,Computing correlated equilibria in multi-player games,"We develop a polynomial-time algorithm for finding correlated equilibria (a well-studied notion of rationality due to Aumann that generalizes the Nash equilibrium) in a broad class of succinctly representable multiplayer games, encompassing essentially all known kinds, including all graphical games, polymatrix games, congestion games, scheduling games, local effect games, as well as several generalizations. Our algorithm is based on a variant of the existence proof due to Hart and Schmeidler [11], and employs linear programming duality, the ellipsoid algorithm, Markov chain steady state computations, as well as application-specific methods for computing multivariate expectations.",2005-05-22,https://www.semanticscholar.org/paper/a1143ee30e652360234a1bb37c5d48ab46d34a05,Symposium on the Theory of Computing
1217,Evidence of WW and WZ production with lepton + jets final states in pp collisions at square root s=1.96 TeV.,"We present first evidence for WW+WZ production in lepton + jets final states at a hadron collider. The data correspond to 1.07 fb-1 of integrated luminosity collected with the D0 detector at the Fermilab Tevatron in pp collisions at square root s=1.96 TeV. The observed cross section for WW+WZ production is 20.2+/-4.5 pb, consistent with the standard model and more precise than previous measurements in fully leptonic final states. The probability that background fluctuations alone produce this excess is <5.4 x 10-6, which corresponds to a significance of 4.4 standard deviations.",2008-10-21,https://www.semanticscholar.org/paper/4cd7be7bc84861e359c1a7a1651e1eae4dcf58d1,Physical Review Letters
3161,SVR4UNIX Scheduler Unacceptable for Multimedia Applications,,1993-11-03,https://www.semanticscholar.org/paper/c3f01f7e2704192afe78a7e8ae54f431e6c09722,International Workshop on Network and Operating System Support for Digital Audio and Video
3014,Heterogeneous Multi-Mobile Computing (video),"As smartphones and tablets proliferate, there is a growing demand for multi-mobile computing [1, 2], the ability to combine multiple commodity mobile systems into more capable ones, including using multiple hardware devices such as cameras, displays, speakers, microphones, sensors, GPS, and input. However, the tremendous device, hardware, and software heterogeneity of mobile systems makes this difficult. In this demo, we present M2, a system for multi-mobile computing that enables existing unmodified mobile apps to make use of new ways of sharing and combining multiple devices. M2 introduces a new data-centric approach that leverages higher-level device abstractions and encoding/decoding hardware to efficiently share device data as opposed to low-level device-specific APIs.",2019-06-12,https://www.semanticscholar.org/paper/38cf86b4377c6367545ac0e11113bb19d704c3f8,"ACM SIGMOBILE International Conference on Mobile Systems, Applications, and Services"
48,Modeling and managing changes in text databases,"Large amounts of (often valuable) information are stored in web-accessible text databases. “Metasearchers” provide unified interfaces to query multiple such databases at once. For efficiency, metasearchers rely on succinct statistical summaries of the database contents to select the best databases for each query. So far, database selection research has largely assumed that databases are static, so the associated statistical summaries do not evolve over time. However, databases are rarely static and the statistical summaries that describe their contents need to be updated periodically to reflect content changes. In this article, we first report the results of a study showing how the content summaries of 152 real web databases evolved over a period of 52 weeks. Then, we show how to use “survival analysis” techniques in general, and Cox's proportional hazards regression in particular, to model database changes over time and predict when we should update each content summary. Finally, we exploit our change model to devise update schedules that keep the summaries up to date by contacting databases only when needed, and then we evaluate the quality of our schedules experimentally over real web databases.",2007-08-01,https://www.semanticscholar.org/paper/cf3f1cb8fb7fbf9d8393c24eb20d11a585a46b65,TODS
3694,Adversarially Robust Video Perception by Seeing Motion,"Despite their excellent performance, state-of-the-art computer vision models often fail when they encounter adversarial examples. Video perception models tend to be more fragile under attacks, because the adversary has more places to manipulate in high-dimensional data. In this paper, we find one reason for video models' vulnerability is that they fail to perceive the correct motion under adversarial perturbations. Inspired by the extensive evidence that motion is a key factor for the human visual system, we propose to correct what the model sees by restoring the perceived motion information. Since motion information is an intrinsic structure of the video data, recovering motion signals can be done at inference time without any human annotation, which allows the model to adapt to unforeseen, worst-case inputs. Visualizations and empirical experiments on UCF-101 and HMDB-51 datasets show that restoring motion information in deep vision models improves adversarial robustness. Even under adaptive attacks where the adversary knows our defense, our algorithm is still effective. Our work provides new insight into robust video perception algorithms by using intrinsic structures from the data. Our webpage is available at https://motion4robust.cs.columbia.edu.",2022-12-13,https://www.semanticscholar.org/paper/384d527447f96c7efec56a9bd0a352f9a764ed63,arXiv.org
3167,New estimates indicate that males are not larger than females in most mammals,"Sexual size dimorphism (SSD) has motivated a large body of research on mammalian mating strategies and sexual selection. Despite some contrary evidence, the narrative that larger males are the norm in mammals – upheld since Darwin’s Descent of Man – still dominates today, supported by meta-analyses that use crude measures of dimorphism and taxonomically-biased data. With newly-available datasets and primary sources reporting sex-segregated means and variances in adult body mass, we estimated statistically-determined rates of SSD in mammals, sampling taxa by their species richness at the family level. Our analyses of >400 species indicate that although males tend to be larger than females when dimorphism occurs, males are not larger in most mammals, and suggest a need to revisit other assumptions in sexual selection research. One-Sentence Summary Taxonomically-balanced estimates of rates of sexual size dimorphism in mammals refute the ‘larger males’ narrative.",2023-02-23,https://www.semanticscholar.org/paper/4c41e5c180212eb295e2335ba64725701fc459fb,bioRxiv
788,AMC: An Adaptive Model Checker,,2002-07-27,https://www.semanticscholar.org/paper/e4d5c4ce1760cf2f0746178e7b18feb5ab240b11,International Conference on Computer Aided Verification
452,Multimedia Information Caching for Personalized Video-on-Demand,,1995-03-01,https://www.semanticscholar.org/paper/2d7165b2b27f4d58b6a892f5eeccdf252af104b0,Computer Communications
1449,Measurement of {alpha}{sub s} in e{sup +}e{sup {minus}} annihilation at E{sub cm} = 29 GeV,"A measurement of the strong coupling constant {alpha}{sub s} using the event-shape variable y{sub 3} (the differential two-jet rate) in the reaction e{sup +}e{sup {minus}} {yields} hadrons is presented. The analysis is based on data from the TPC/Two-Gamma detector at the PEP e{sup +}e{sup {minus}} storage ring taken between 1984 and 1986 at a center-of-mass energy of E{sub cm} = 29 GeV. A value of {alpha}{sub s}(29 GeV) = 0.160 {+-} 0.012 is obtained, where the error is the quadratic sum of experimental and theoretical uncertainties. The procedure for determining {alpha}{sub s} is the same as that used by the ALEPH and TOPAZ experiments, which allows for a consistent comparison of the {alpha}{sub s} values obtained at different center-of-mass energies. The observed energy dependence {open_quotes}running{close_quotes} of {alpha}{sub s} is found to be in good agreement with the QCD prediction, and is clearly incompatible with a constant value.",1994-07-01,https://www.semanticscholar.org/paper/4b5c33ba7731291ae1e329eb742a8da7eefdf35b,
1721,Stochastic Structured Variational Inference,,2014-04-16,https://www.semanticscholar.org/paper/e97be50cc895bc1b819fac457a6203bb066a5ae4,International Conference on Artificial Intelligence and Statistics
2715,Knowledge-based augmented reality,,1993-07-01,https://www.semanticscholar.org/paper/4580129bc3105521dc1e2ffd3a3cfc151728b158,CACM
3313,The Impact of Increased Environmental Stochasticity Due to Climate Change on the Dynamics of Asiatic Wild Ass,"Abstract:  Theory proposes that increased environmental stochasticity negatively impacts population viability. Thus, in addition to the directional changes predicted for weather parameters under global climate change (GCC), the increase in variance of these parameters may also have a negative effect on biodiversity. As a case study, we assessed the impact of interannual variance in precipitation on the viability of an Asiatic wild ass (Equus hemionus) population reintroduced in Makhtesh Ramon Nature Reserve, Israel. We monitored the population from 1985 to 1999 to determine what environmental factors affect reproductive success. Annual precipitation during the year before conception, drought conditions during gestation, and population size determined reproductive success. We used the parameters derived from this model to assess population performance under various scenarios in a Leslie matrix type model with demographic and environmental stochasticity. Specifically, we used a change in the precipitation regime in our study area to formulate a GCC scenario and compared the simulated dynamics of the population with a no‐change scenario. The coefficient of variation in population size under the global change scenario was 30% higher than under the no‐change scenario. Minor die‐offs (≥15%) following droughts increased extinction probability nearly 10‐fold. Our results support the idea that an increase in environmental stochasticity due to GCC may, in itself, pose a significant threat to biodiversity.",2006-10-01,https://www.semanticscholar.org/paper/e2f19cc8a134a717e16af97a458b988650b8b2cd,Conservation Biology
3567,Reliable and Efficient Concurrent Synchronization for Embedded Real-Time Software,"The high degree of autonomy and increased complexity of future robotic spacecraft pose significant challenges in assuring their reliability and efficiency. To achieve fast and safe concurrent interactions in mission critical code, we survey the practical state-of-the-art nonblocking programming techniques. We study in detail two nonblocking approaches: (1) CAS-based algorithms and (2) Software Transactional Memory. We evaluate the strengths and weaknesses of each approach by applying each methodology for engineering the design and implementation of a nonblocking shared vector. Our study investigates how the application of nonblocking synchronization can help eliminate the problems of deadlock, livelock, and priority inversion and at the same time deliver a performance improvement in embedded real-time software.",2009-07-19,https://www.semanticscholar.org/paper/0b553242f822c4a7443bc3fd0d6b378276465f7c,2009 Third IEEE International Conference on Space Mission Challenges for Information Technology
2252,Neutrophil apoptosis in rheumatoid arthritis is regulated by local oxygen tensions within joints,"Neutrophils are normally short‐lived cells and die by apoptosis, but when recruited into tissues, their apoptosis is delayed, and they survive for much longer time periods. In inflammatory diseases, such as rheumatoid arthritis (RA), this delayed apoptosis may lead to increased tissue damage and a failure of the inflammation to resolve. However, there are conflicting reports in the literature as to whether neutrophil apoptosis is delayed or accelerated in rheumatoid joints. In this report, we show that neutrophils isolated from the ynovial fluid (SF) of patients with RA show accelerated rates of apoptosis when incubated ex vivo and that SF, despite containing a variety of antiapoptotic cytokines, is proapoptotic. Paradoxically, levels of the key neutrophil survival protein Mcl‐1 are elevated in freshly isolated SF neutrophils compared with matched peripheral blood samples from the same patients, indicating that delayed neutrophil apoptosis has been signaled in vivo as the cells enter the joints. However, when SF was added to neutrophils and incubated under hypoxia (1% O2), conditions known to exist in vivo within joints, the SF was antiapoptotic. These data reveal that the rheumatoid synovial joint contains a complex mixture of pro‐ and antiapoptotic factors and that the low, local oxygen tensions that exist within these joints can exert profound effects on neutrophil survival. These experiments also highlight the importance of performing in vitro experiments under laboratory conditions that closely mimic those that occur in vivo; otherwise, misleading conclusions may be drawn.",2006-09-01,https://www.semanticscholar.org/paper/280b7723e1dbb36943ad3d1da3105306e6748c9e,Journal of Leukocyte Biology
609,The complexity of searching a graph,"T. Parsons proposed and partially analyzed the following pursuit-evasion problem on graphs: A team of searchers traverse the edges of a graph G in pursuit of a fugitive, who moves along the edges of the graph with complete knowledge of the locations of the pursuers. What is the smallest number s(G) of searchers that will suffice for guaranteeing capture of the fugitive? We show that determining whether s(G) ≤ K, for a given integer K, is NP-hard for general graphs but can be solved in linear time for trees. We also provide a structural characterization of those graphs with s(G) ≤ K for K = 1,2,3.",,https://www.semanticscholar.org/paper/bc5cc32ae4e10e2aca8e40170f2ec5a33c84bf7a,22nd Annual Symposium on Foundations of Computer Science (sfcs 1981)
1761,"Extracting information from high-dimensional data: probabilistic modeling, inference and evaluation","In this thesis, we shall derive, in a variety of settings, and for different applications, efficient posterior inference algorithms handling large data sets, and use side information to derive superior inference techniques. We demonstrate the efficiency and accuracy of those models and algorithms in the different applications, on both real and synthetic data sets. We evaluate the quality of the results, with both quantitative and human evaluation experiments. 
In the first part of the thesis the general framework is that of sparsity: we assume the data have a sparse representation; the application on which we focus is image super-resolution, in which one seeks to ""up-scale images"", i.e. ""reconstruct"" finer detail in an image than given in the data. Image super-resolution has been tackled successfully via sparse coding but not, so far, by Bayesian nonparametric methods (BNM). In other contexts, BNMs were shown to be powerful because they infer parameters that otherwise have to be assigned a priori. We build here the tools enabling such a BNM for the super-resolution of images. We start with building a sparse nonparametric factor analysis model for image super-resolution, more precisely, a model with a beta-Bernoulli process to learn the number of dictionary elements from the data. We test the results on both benchmark and natural images, comparing with the models in the literature. Then, we perform large-scale human evaluation experiments to explicitly assess the visual quality of the results. In a first implementation, we use Gibbs sampling, operating on the data in batch mode, and assess its performance. However, for large-scale data, such a Gibbs sampling approach is typically not feasible. To circumvent this, we develop an online variational Bayes (VB) algorithm that can deal with larger-scale data in a fraction of the time needed by traditional inference. 
In the second part of the thesis we consider data sets with rich side information. We study 2 different frameworks that have such side information: relational information and group information. To handle relational information, we build a relational factor analysis (rFA) model which incorporates this into the dictionary learning. We show that the use of relational information (e.g. spatial location), helps learning higher quality dictionaries and improves the recommendation systems in a social network and the image analysis algorithms (e.g. image inpainting). To handle group information, we propose a multi-task learning framework for image super-resolution problem using a hierarchical beta-process as a prior to dictionary assignments. In this model, we study grouped data and we build a model incorporating the group information. We show that by incorporating group information in this way the algorithm avoids erroneous selection of dictionary elements. 
Finally, in the third part of the thesis, we study latent sequential information between observations. We use this information to build a novel dynamic programming algorithm for sequential models. Hidden Markov models (HMMs) and conditional random fields (CRFs) are two popular techniques for modeling sequential data. Inference algorithms designed over CRFs and HMMs allow estimation of the state sequence, given the observations. In several applications, the end goal is not the estimation of the state sequence, but rather the estimation of the value of some function of the state sequence. In such scenarios, estimating the state sequence by conventional inference techniques, followed by computing the functional mapping from this estimate, is not necessarily optimal; it may be more efficient to directly infer the final outcome from the observations. In particular, we consider the specific instantiation of the problem where the goal is to find the state trajectories without exact transition points; we derive a novel polynomial time inference algorithm that outperforms vanilla inference techniques. We show that this particular problem arises commonly in many disparate applications and present the results for experiments on three different applications: (1) Toy robot tracking; (2) Single stroke character recognition; (3) Handwritten word recognition. (Abstract shortened by UMI.)",,https://www.semanticscholar.org/paper/dd6def73c4dfeb8c314f77b2fe9119c52f36871b,
3013,Optimizing Nested Virtualization Performance Using Direct Virtual Hardware,"Nested virtualization, running virtual machines and hypervisors on top of other virtual machines and hypervisors, is increasingly important because of the need to deploy virtual machines running software stacks on top of virtualized cloud infrastructure. However, performance remains a key impediment to further adoption as application workloads can perform many times worse than native execution. To address this problem, we introduce DVH (Direct Virtual Hardware), a new approach that enables a host hypervisor, the hypervisor that runs directly on the hardware, to directly provide virtual hardware to nested virtual machines without the intervention of multiple levels of hypervisors. We introduce four DVH mechanisms, virtual-passthrough, virtual timers, virtual inter-processor interrupts, and virtual idle. DVH provides virtual hardware for these mechanisms that mimics the underlying hardware and in some cases adds new enhancements that leverage the flexibility of software without the need for matching physical hardware support. We have implemented DVH in the Linux KVM hypervisor. Our experimental results show that DVH can provide near native execution speeds and improve KVM performance by more than an order of magnitude on real application workloads.",2020-03-09,https://www.semanticscholar.org/paper/af687ee53dbbfc35eeec2e6e66f37587cad9ed7d,International Conference on Architectural Support for Programming Languages and Operating Systems
762,A note on broadcast encryption key management with applications to large scale emergency alert systems,"Emergency alerting capability is crucial for the prompt response to natural disasters and terrorist attacks. The emerging network infrastructure and secure broadcast techniques enable prompt and secure delivery of emergency notification messages. With the ubiquitous deployment of alert systems, scalability and heterogeneity pose new challenges for the design of secure broadcast schemes. In this paper, we discuss the key generation problem with the goal of minimizing the total number of keys which need to be generated by the alert center and distributed to the users. Two encryption schemes, zero message scheme and extended header scheme, are modeled formally. For both schemes we show the equivalence of the general optimal key generation (OKG) problem and the bipartite clique cover (BCC) problem, and show that OKG problem is NP-hard. The result is then generalized to the case with resource constraints, and we provide a heuristic algorithm for solving the restricted BCC (and OKG) problem.",2006-04-25,https://www.semanticscholar.org/paper/6d87b107c6290487c32d49574f5563f388cc72e7,Proceedings 20th IEEE International Parallel & Distributed Processing Symposium
2208,232. Interferons Alter the Response of Neutrophils to Inflammatory Cytokines in vitro,"Background: Neutrophils are central to the initiation, progression and resolution of inflammatory diseases such as RA. We have previously shown that neutrophils from RA patients have a gene expression signature indicating activation in vivo by interferons (IFNs), and higher expression of IFN-response genes is associated with a good response to TNFi therapy. The aim of this work was to investigate the functional effects of IFNs on neutrophils in vitro both (i) alone, and (ii) in combination with inflammatory cytokines. Methods: Neutrophils were isolated from peripheral blood of healthy controls and incubated with Type-I IFN (IFNa) or Type-II IFN (IFNg) at a range of concentrations in the absence or presence of GM-CSF and TNFa. Apoptosis was measured at 18h by flow cytometry using annexin V/PI; respiratory burst was measured at hourly intervals up to 5h using luminol-enhanced chemiluminescence after stimulation with fMLP or PMA; changes in protein expression and phosphorylation were measured by Western blotting; changes in gene expression were measured by RNA-Seq (Illumina). Results: Neutrophils stimulated with IFNs in vitro underwent rapid phosphorylation of STAT proteins (5–30 min), activation of IFNresponse genes (1h), and priming of the respiratory burst (3h), but only Type-II IFN delayed apoptosis, measured at 18h (unstimulated 58.6% 0.6, IFNg 41.4% 4.1, P<0.05). Addition of IFNs to neutrophil suspensions containing GM-CSF or TNFa had a profound dose-dependent effect on the function of the inflammatory cytokines. Type-I IFNs abrogated the protective effect of GM-CSF on neutrophil apoptosis at 18h (GM-CSF 25.6% 2.7, GM-CSFþ IFNa 49.5% 1.2, P<0.01), whereas Type-II IFNs enhanced the anti-apoptotic effect of TNFa (TNFa 42.3% 3.3, TNFaþ IFNg 27.4% 1.2, P< 0.05) and sustained the TNFa priming effect on the respiratory burst for up to 4h (P<0.01). Type-I and Type-II IFNs enhanced STAT3 phosphorylation by GM-CSF, and altered the activation kinetics of ERK and AKT by GM-CSF. Type-I IFN enhanced AKT phosphorylation in TNFa stimulated neutrophils. Conclusion: IFNs profoundly alter the functional effects of inflammatory cytokines on neutrophils in vitro. This may have important consequences in vivo during therapy with biologic drugs such as TNFi. The complexity and heterogeneity of inflammatory diseases such as RA, where different cytokines dominate or act synergistically to perpetuate systemic inflammation, may explain why some patients respond better to certain biologic therapies than others. We are currently investigating the consequences of TNFi (Infliximab) and JAKi (Tofacitinib) on neutrophils stimulated in vitro with IFNs, GM-CSF and TNFa. Disclosure statement: The authors have declared no conflicts of interest.",2014-04-01,https://www.semanticscholar.org/paper/6fa8c90f4159a1d08b8f68ae3e21d1ebe544a580,
2427,Manipulating 3D Anatomic Models in Augmented Reality: Comparing a Hands-Free Approach and a Manual Approach,"Many AR and VR task domains involve manipulating virtual objects; for example, to perform 3D geometric transformations. These operations are typically accomplished with tracked hands or hand-held controllers. However, there are some activities in which the user's hands are already busy with another task, requiring the user to temporarily stop what they are doing to perform the second task, while also taking time to disengage and reengage with the original task (e.g., putting down and picking up tools). To avoid the need to overload the user's hands this way in an AR system for guiding a physician performing a surgical procedure, we developed a hands-free approach to performing 3D transformations on patient-specific virtual organ models. Our approach uses small head motions to accomplish first-order and zero-order control, in conjunction with voice commands to establish the type of transformation. To show the effectiveness of this approach for translating, scaling, and rotating 3D virtual models, we conducted a within-subject study comparing the hands-free approach with one based on conventional manual techniques, both running on a Microsoft HoloLens and using the same voice commands to specify transformation type. Independent of any additional time to transition between tasks, users were significantly faster overall using the hands-free approach, significantly faster for hands-free translation and scaling, and faster (although not significantly) for hands-free rotation.",2019-10-01,https://www.semanticscholar.org/paper/434d802aeaf56dc659f5c153b2ebc49f3e4e020a,International Symposium on Mixed and Augmented Reality
2930,Phenome-scale causal network discovery with bidirectional mediated Mendelian randomization,"Inference of directed biological networks from observational genomics datasets is a crucial but notoriously difficult challenge. Modern population-scale biobanks, containing simultaneous measurements of traits, biomarkers, and genetic variation, offer an unprecedented opportunity to study biological networks. Mendelian randomization (MR) has received attention as a class of methods for inferring causal effects in observational data that uses genetic variants as instrumental variables, but MR methods rely on assumptions that limit their application to complex traits at the biobank-scale. Moreover, MR estimates the total effect of one trait on another, which may be mediated by other factors. Biobanks include measurements of many potential mediators, in principle enabling the conversion of MR estimates into direct effects representing a causal network. Here, we show that this can be accomplished by a flexible two stage procedure we call bidirectional mediated Mendelian randomization (bimmer). First, bimmer estimates the effect of every trait on every other. Next, bimmer finds a parsimonious network that explains these effects using direct and mediated causal paths. We introduce novel methods for both steps and show via extensive simulations that bimmer is able to learn causal network structures even in the presence of non-causal genetic correlation. We apply bimmer to 405 phenotypes from the UK biobank and demonstrate that learning the network structure is invaluable for interpreting the results of phenome-wide MR, while lending causal support to several recent observational studies.",2020-06-20,https://www.semanticscholar.org/paper/a323e4a821b8704240bd077bf690c9bff5b4a098,bioRxiv
2174,The Inhibitory Effect of Validamycin A on Aspergillus flavus,"Aspergillus flavus is one of the most common isolates from patients with fungal infections. Aspergillus infection is usually treated with antifungal agents, but side effects of these agents are common. Trehalase is an essential enzyme involved in fungal metabolism, and the trehalase inhibitor, validamycin A, has been used to prevent fungal infections in agricultural products. In this study, we observed that validamycin A significantly increased trehalose levels in A. flavus conidia and delayed germination, including decreased fungal adherence. In addition, validamycin A and amphotericin B showed a combinatorial effect on A. flavus ATCC204304 and clinical isolates with high minimum inhibitory concentrations (MICs) of amphotericin B using checkerboard assays. We observed that validamycin A and amphotericin B had a synergistic effect on A. flavus strains resistant to amphotericin B. The MICs in the combination of validamycin A and amphotericin B were at 0.125 μg/mL and 2 μg/mL, respectively. The FICI of validamycin A and amphotericin B of these clinical isolates was about 0.25–0.28 with synergistic effects. No drug cytotoxicity was observed in human bronchial epithelial cells treated with validamycin A using LDH-cytotoxicity assays. In conclusion, this study demonstrated that validamycin A inhibited the growth of A. flavus and delayed conidial germination. Furthermore, the combined effect of validamycin A with amphotericin B increased A. flavus killing, without significant cytotoxicity to human bronchial epithelial cells. We propose that validamycin A could potentially be used in vivo as an alternative treatment for A. flavus infections.",2020-06-27,https://www.semanticscholar.org/paper/97f8e1a67f475b5ce4f41eb0a0674c8e0230f8a8,International Journal of Microbiology
1934,Modeling and Analysis of Semiconductor Supply Chains (Dagstuhl Seminar 16062),In February 2016 the Dagstuhl Seminar 16062 explored the needs of the semiconductor industry for better planning and scheduling approaches at the supply chain level and the requirements for information systems to support the approaches. The seminar participants also spent time identifying the core elements of a conceptual reference model for planning and control of semiconductor manufacturing supply chains. This Executive Summary describes the process of the seminar and discusses key findings and areas for future research regarding these topics. Abstracts of presentations given during the seminar and the output of breakout sessions are collected in appendices.,,https://www.semanticscholar.org/paper/67ac6e4c0f8ffe05ed027aaa350d0864a0ae3bd7,Dagstuhl Reports
1698,Deterministic Annealing for Stochastic Variational Inference,"Stochastic variational inference (SVI) maps posterior inference in latent variable models to nonconvex stochastic optimization. While they enable approximate posterior inference for many otherwise intractable models, variational inference methods suffer from local optima. We introduce deterministic annealing for SVI to overcome this issue. We introduce a temperature parameter that deterministically deforms the objective, and then reduce this parameter over the course of the optimization. Initially it encourages high entropy variational distributions, which we find eases convergence to better optima. We test our method with Latent Dirichlet Allocation on three large corpora. Compared to SVI, we show improved predictive likelihoods on held-out data.",2014-11-07,https://www.semanticscholar.org/paper/5cee21ae4605a330d9977164523be4b865df6ebd,arXiv.org
1869,Ieee Transaction on Pattern Analysis and Machine Intelligence 1 a Bayesian Nonparametric Approach to Image Super-resolution,"—Super-resolution methods form high-resolution images from low-resolution images. In this paper, we develop a new Bayesian nonparametric model for super-resolution. Our method uses a beta-Bernoulli process to learn a set of recurring visual patterns, called dictionary elements, from the data. Because it is nonparametric, the number of elements found is also determined from the data. We test the results on both benchmark and natural images, comparing with several other models from the research literature. We perform large-scale human evaluation experiments to assess the visual quality of the results. In a first implementation, we use Gibbs sampling to approximate the posterior. However, this algorithm is not feasible for large-scale data. To circumvent this, we then develop an online variational Bayes (VB) algorithm. This algorithm finds high quality dictionaries in a fraction of the time needed by the Gibbs sampler.",,https://www.semanticscholar.org/paper/77081383a7ef9fa3ebe47f7b13230476e9232395,
412,Map graphs,"We consider a modified notion of planarity, in which two nations of a map are considered adjacent when they share any point of their boundaries (not necessarily an edge, as planarity requires). Such adjacencies define a map graph. We give an NP characterization for such graphs, derive some consequences regarding sparsity and coloring, and survey some algorithmic results.",1999-10-13,https://www.semanticscholar.org/paper/c9d2e979c18ffda37215607e915bdd0d5f523e47,JACM
2228,Respiratory Syncytial Virus Binds and Undergoes Transcription in Neutrophils From the Blood and Airways of Infants With Severe Bronchiolitis,"Background. Neutrophils are the predominant cell in the lung inflammatory infiltrate of infants with respiratory syncytial virus (RSV) bronchiolitis. Although it has previously been shown that neutrophils from both blood and bronchoalveolar lavage (BAL) are activated, little is understood about their role in response to RSV infection. This study investigated whether RSV proteins and mRNA are present in neutrophils from blood and BAL of infected infants. Methods. We obtained blood and BAL samples from 20 infants with severe RSV bronchiolitis and 8 healthy control infants. Neutrophil RSV F, G, and N proteins, RSV N genomic RNA, and messenger RNA (mRNA) were quantified. Results. RSV proteins were found in BAL and blood neutrophils in infants with RSV disease but not in neutrophils from healthy infants. BAL and blood neutrophils from infants with RSV disease, but not those from healthy infants, expressed RSV N genomic RNA, indicating uptake of whole virus; 17 of 20 BAL and 8 of 9 blood neutrophils from patients expressed RSV N mRNA. Conclusions. This work shows, for the first time, the presence of RSV proteins and mRNA transcripts within BAL and blood neutrophils from infants with severe RSV bronchiolitis.",2011-08-01,https://www.semanticscholar.org/paper/46af2674c6b5f4e0a9c7d4374e544085f31a16ff,Journal of Infectious Diseases
654,Acute angiographic and clinical results of long balloon percutaneous transluminal coronary angioplasty and adjuvant stenting for long narrowings.,,1994-04-01,https://www.semanticscholar.org/paper/e9cd4fc91b9d1285744574d07167b3af0581c601,American Journal of Cardiology
1307,Detector commissioning for the CDMS-II final run at the Soudan Underground Laboratory,,2006-04-15,https://www.semanticscholar.org/paper/3513c2bf0dfce7700e9cc8aa66a1dcd3987c5a30,
657,Intracoronary Stenting for Acute and Threatened Closure Complicating Percutaneous Transluminal Coronary Angioplasty,"BackgroundAcute closure remains a significant limitation of percutaneous transluminal coronary angioplasty (PTCA) and underlies the majority of ischemic complications. This study details the clinical and angiographic characteristics of a series of patients receiving an intracoronary stent device to manage acute and threatened closure and presents the early clinical results. Methods and ResultsFrom October 1989 through June 1991, 115 patients undergoing PTCA received intracoronary stents to treat acute or threatened closure in 119 vessels. Sixty-three percent had multivessel coronary disease, 33 (29%) had undergone prior coronary artery bypass grafting (CABG), and 52 (45%) had had previous PTCA. Using the American College of Cardiology/American Heart Association (ACC/AHA) classification, 15% of lesions were class A, 55% were class B, and 30% were class C. Eight patients were referred with severe coronary dissection and unstable angina after PTCA at other institutions. Acute closure was defined as occlusion of the vessel with TIMI (Thrombolysis in Myocardial Infarction) 0 or 1 flow immediately before stent placement. Threatened closure required two or more of the following criteria: 1) a residual stenosis greater than 50%, 2) TIMI grade 2 flow, 3) angiographic dissection comprising extraluminal dye extravasation and/or a length of greater than 15 mm, 4) evidence of clinical ischemia (either typical angina or ECG changes). Twelve vessels (10%) met the criteria for acute closure, and 87 vessels (73%) satisfied the criteria for threatened closure. Twenty vessels (17%) failed to meet two criteria. Stenting produced optimal angiographic results in 111 vessels (93%), with mean diameter stenosis (±1 SD) reduced from 83±12% before to 18±29% after stenting. Overall, in-hospital mortality was 1.7% and CABG was required in 4.2%; Q wave myocardial infarction (MI) occurred in 7% and non-Q wave MI in 91%. Stent thrombosis occurred in nine patients (7.6%). For the 108 patients who presented to the catheterization laboratory without evolving MI, Q wave MI occurred in 4% and non-Q wave MI occurred in 7%. Angiographic follow-up has been performed in 81 eligible patients (76%), and 34 patients (41%) had a lesion of .50%. ConclusionsThis stent may be a useful adjunct to balloon dilatation in acute or threatened closure. Randomized studies comparing this stent with alternative technologies are required.",1992-03-01,https://www.semanticscholar.org/paper/159f520e94781eb63dd1d15eb52b3b6a55dd0ec7,Circulation
3580,Runtime Concepts for the C++ STL,,,https://www.semanticscholar.org/paper/430f866f9b12d53ef2d46dd7f52b828c91b2f6f0,
2666,Virtual Reality Software and Technology,"Virtual Reality (VR) refers to a technology which is capable of shifting a subject into a different environment without physically moving him/her. To this end the inputs into the subject's sensory organs are manipulated in such a way, that the perceived environment is associated with the desired Virtual Environment (VE) and not with the physical one. The manipulation process is controlled by a computer model that is based on the physical description of the VE. Consequently, the technology is able to create almost arbitrarily perceived environments. Immersion is a key issue in VR systems as it is central to the paradigm where the user becomes part of the simulated world, rather than the simulated world being a feature of the user's own world. The first "" immersive VR systems "" have been the flight simulators where the immersion is achieved by a subtle mixture of real hardware and virtual imagery. The term ""immersion"" is a description of a technology, which can be achieved to varying degrees. A necessary condition is Ellis' notion [1] of a VE, maintained in at least one sensory modality (typically the visual). For example, a head-mounted display with wide field of view, and at least head tracking would be essential. The degree of immersion is increased by adding additional, and consistent modalities, greater",,https://www.semanticscholar.org/paper/bef856707c28f52486b9a7eb5a9b9e29b4d2cd81,
1071,ZZ → l + lv + v-production in pp collisions at √ s = 1 . 96 TeV,,,https://www.semanticscholar.org/paper/6b49bd750613d8860ee1a3e57eb13a7697442fd3,
883,Verifying temporal properties of finite-state probabilistic programs,"The complexity of testing whether a finite-state (sequential or concurrent) probabilistic program satisfies its specification expressed in linear temporal logic. For sequential programs an exponential-time algorithm is given and it is shown that the problem is in PSPACE; this improves the previous upper bound by two exponentials and matches the known lower bound. For concurrent programs is is shown that the problem is complete in double exponential time, improving the previous upper and lower bounds by one exponential each. These questions are also addressed for specifications described by omega -automata or formulas in extended temporal logic.<<ETX>>",1988-10-24,https://www.semanticscholar.org/paper/5d6b5905c006dd527af13a93fc9ba3704663cb64,[Proceedings 1988] 29th Annual Symposium on Foundations of Computer Science
3604,Supporting SELL for High-Performance Computing,,2005-10-20,https://www.semanticscholar.org/paper/76669a17732fbc84e4f7f94ceb30ef34fa73c0cf,International Workshop on Languages and Compilers for Parallel Computing
1136,Search for CP violation in Bs0→μ+Ds-X decays in pp̅ collisions at √s=1.96 TeV,"We have performed a search for CP violation in a sample of B 0 s ! (cid:1) þ D (cid:1) s X decays corresponding to 5 fb (cid:1) 1 of proton-antiproton collisions collected by the D0 detector in Run II at the Fermilab Tevatron Collider. New physics in B 0 s mixing could contribute a signiﬁcant CP violating weak phase, which would be observed as a difference in the decay-time distribution for B 0 s ! (cid:1) B 0 s oscillated states versus that for (cid:1) B 0 s ! B 0 s . A ﬁt to the decay-time distributions of the B 0 s = (cid:1) B 0 s candidates yields the ﬂavor-speciﬁc asymmetry a s fs ¼ ½(cid:1) 1 : 7 (cid:2) 9 : 1 ð stat Þ þ 1 : 4 (cid:1) 1 : 5 ð syst Þ(cid:3) (cid:4) 10 (cid:1) 3 , which excludes CP violation due to new physics within the experimental sensitivity.",,https://www.semanticscholar.org/paper/f0fe908337f363725981f9b4d0e068b8b0979d86,
82,Simplifying Data Access: The Energy Data Collection Project,"Using technology developed at the Digital Government Research Center, a team of researchers is seeking to make government statistical data more accessible through the Internet. In collaboration with government experts, they are conducting research into advanced information systems, developing standards, interfaces and a shared infrastructure, and building and managing pilot systems.",2001-02-01,https://www.semanticscholar.org/paper/19e71f233fa1f862623d841743f02fd26ad0a07f,Computer
2739,A Nose Gesture Interface Device: Extending Virtual Realities,"This paper reports on the1 development of a nose-machine interface device that provides real-time gesture, position, smell and facial expression information. The DATANOSE™2—Data AtomaTa CORNUCOPIA pNeumatic Olfactory 1/O-deviSE Tactile Manipulation (Olsen, 1986; Myers, 1991)—allows novice users without any formal nose training to perform complex interactive tasks.",1991-11-11,https://www.semanticscholar.org/paper/5a397cf9ca943a529a0c75fc0ce020265ec41478,Presence: Teleoperators & Virtual Environments
2144,Directly lower bounding the information capacity for channels with I.I.D.deletions and duplications,"In this paper, we directly lower bound the information capacity for channels with independent identically distributed (i.i.d.) deletions and duplications. Our approach differs from previous work in that we focus on the information capacity using ideas from renewal theory, rather than focusing on the transmission capacity by analyzing the error probability of some randomly generated code using a combinatorial argument. Of course, the transmission and information capacities are equal, but our change of perspective allows for a much simpler analysis that gives more general theoretical results. We then apply these results to the binary deletion channel to improve existing lower bounds on its capacity.",,https://www.semanticscholar.org/paper/98b83fad457ed9d4b0227948c78d1dcf3b84dfde,IEEE Transactions on Information Theory
114,The Stanford Digital Library metadata architecture,,1997-04-15,https://www.semanticscholar.org/paper/182357ed2ad1bfe8806ccc0a63c366e55819a70d,International Journal on Digital Libraries
2079,建構cDNA生物晶片之二元資料挖礦模式及其實證研究; A Data Mining Framework for Binary cDNA bio-chip Data Analysis and Its Validation,,,https://www.semanticscholar.org/paper/8f37a635da730e103bb33cca0fd3af2adc5be917,
2412,Precueing Sequential Rotation Tasks in Augmented Reality,"Augmented reality has been used to improve sequential-task performance by cueing information about a current task step and precueing information about future steps. Existing work has shown the benefits of precueing movement (translation) information. However, rotation is also a major component in many real-life tasks, such as turning knobs to adjust parameters on a console. We developed an AR testbed to investigate whether and how much precued rotation information can improve user performance. We consider two unimanual tasks: one requires a user to make sequential rotations of a single object, and the other requires the user to move their hand between multiple objects to rotate them in sequence. We conducted a user study to explore these two tasks using circular arrows to communicate rotation. In the single-object task, we examined the impact of number of precues and visualization style on user performance. Results show that precues improved performance and that arrows with highlighted heads and tails, with each destination aligned with the next origin, yielded the shortest completion time on average. In the multiple-object task, we explored whether rotation precues can be helpful in conjunction with movement precues. Here, using a rotation cue without rotation precues in conjunction with a movement cue and movement precues performed the best, implying that rotation precues were not helpful when movement was also required.",2022-11-29,https://www.semanticscholar.org/paper/2b28e82d29a3f825a25c4a92349a56aa813e1b60,Virtual Reality Software and Technology
134,Routing techniques for massively parallel communication,"A survey of some packet-switched routing methods for massively parallel computers is presented. Some of the techniques are applicable to both shared-memory and message-passing architectures. These routing methods are compared in terms of their efficiency in supporting programming models, efficiency in mapping to parallel machines, and practicality. Among the outlined methods, three nonadaptive techniques and some adaptive routing algorithms are discussed. >",1991-04-01,https://www.semanticscholar.org/paper/286c8b5d5b12e043954eb145eef8330f3276cc5f,Proceedings of the IEEE
576,The Complexity of Cubical Graphs (Extended Abstract),,1984-07-16,https://www.semanticscholar.org/paper/a63cf60c2d0a7e157afe6f70bc31a845d8fda89c,"International Colloquium on Automata, Languages and Programming"
428,A Microeconomic View of Data Mining,,1998-12-01,https://www.semanticscholar.org/paper/e0c4fac2c53c3ef840cf6ba278eaebad61a1e47d,Data mining and knowledge discovery
1492,Hadronic production of charmonium in 225-GeV/c. pi. /sup -/ Be interactions,Events in which the charmonium states J/psi and psi' are produced in 225-GeV/c ..pi../sup -/Be collisions have been selected with a dimuon trigger. Coincidences with detected photons have identified radiative decays from the charmonium P states (chi) to the J/psi. The fraction of J/psi's resulting from such decays is determined to be 0.37 +- 0.09. .AE,1984-08-01,https://www.semanticscholar.org/paper/0220bb1162d9d3ebeb9dd4b28ac66130c6cf7913,
1644,Causal Inference for Recommendation,"We develop a causal inference approach to recommender systems. Observational recommendation data contains two sources of information: which items each user decided to look at and which of those items each user liked. We assume these two types of information come from differentmodels—the exposure data comes from a model by which users discover items to consider; the click data comes from a model by which users decide which items they like. Traditionally, recommender systems use the click data alone (or ratings data) to infer the user preferences. But this inference is biased by the exposure data, i.e., that users do not consider each item independently at random. We use causal inference to correct for this bias. On real-world data, we demonstrate that causal inference for recommender systems leads to improved generalization to new data.",,https://www.semanticscholar.org/paper/0f95aa631f88512667da9b06e95deedfe410a8b8,
554,On negative cycles in mixed graphs,,1985-10-01,https://www.semanticscholar.org/paper/145944520d6121fec086b841d343aa9135573072,
1422,"Data Acquisition, Reduction, and Calibration 6.1 Introduction 6.2 Trigger and Data Acquitision the Trigger and Daq System Were Developed 6.2.1 Overview","In this chapter, I describe the triggering and data-acquisition system, fitting of pulses to determine energies, and calibration of the energy over extended periods. Andrew Sonnenschein, and myself. The Receiver/Trigger/Filter 9U-format boards were produced at Fermilab under the direction of Mike Crisler and Steve Eichblatt. A diagram of the data-acquisition system is shown in Figure 6.1. The data-acquisition system • configures the detectors and their front-end boards by setting assorted bias values, polarities, gains, etc.; • receives and digitizes the analog detector pulses output by the front-end electronics; • receives, amplifies, and digitizes the integral of the pulses from the veto-counter phototubes; • discriminates each analog detector pulse to form detector-trigger signals; • forms a global trigger based on the detector-trigger signals; • digitizes a time history of detector and veto-counter triggers; • and ships the digitized information to the analysis computers.",,https://www.semanticscholar.org/paper/63f0986cec38cea305e634af878d90d8e8f3e4bf,
905,Scheduling Opposing Forests,"A basic problem of deterministic scheduling theory is that of scheduling n unit-length tasks on m identical processors subject to precedence constraints so as to meet a given overall deadline. T. C. Hu’s classic “level algorithm” can be used to solve this problem in linear time if the precedence constraints have the form of an in-forest or an out-forest. We show that a polynomial time algorithm for a wider class of precedence constraints is unlikely, by proving the problem to be NP-complete for precedence constraints that are the disjoint union of an in-forest and an out-forest (the “opposing forests” of our title). However, for any fixed value of m we show that this problem can be solved in polynomial time for such precedence constraints. For the special case of $m = 3$ we provide a linear time algorithm.",1983-03-01,https://www.semanticscholar.org/paper/0a9d225f3ff41076b686c81d9743d4d2e67462eb,
1557,Text-Based Ideal Points,"Ideal point models analyze lawmakers’ votes to quantify their political positions, or ideal points. But votes are not the only way to express a political position. Lawmakers also give speeches, release press statements, and post tweets. In this paper, we introduce the text-based ideal point model (TBIP), an unsupervised probabilistic topic model that analyzes texts to quantify the political positions of its authors. We demonstrate the TBIP with two types of politicized text data: U.S. Senate speeches and senator tweets. Though the model does not analyze their votes or political affiliations, the TBIP separates lawmakers by party, learns interpretable politicized topics, and infers ideal points close to the classical vote-based ideal points. One benefit of analyzing texts, as opposed to votes, is that the TBIP can estimate ideal points of anyone who authors political texts, including non-voting actors. To this end, we use it to study tweets from the 2020 Democratic presidential candidates. Using only the texts of their tweets, it identifies them along an interpretable progressive-to-moderate spectrum.",2020-05-08,https://www.semanticscholar.org/paper/49f9d8505e8d27041cc57cd3d06c2741f21120c1,Annual Meeting of the Association for Computational Linguistics
2841,Galectin‐3 regulates cytokine production and bacteria burden in macrophages during Listeria infection,"Galectin‐3 is a β‐galactoside‐binding animal lectin expressed in various immune cell types and has been implicated in immune and inflammatory responses during infectious disease processes. However, the mechanism of how galectin‐3 regulates macrophage's antibacterial function remains unclear. We proposed to elucidate the role of galectin‐3 in macrophage‐mediated inflammatory and innate immune responses by using bone marrow‐derived macrophages (BMM) from wild‐type (WT) and galectin‐3‐deficient (gal3−/−) mice for in vitro experiments, and a Listeria monocytogenes (LM)‐infected mouse model for in vivo experiments. The production of reactive oxygen species (ROS), nitric oxide (NO), and inflammatory cytokines as well as phagocytosis ability and intracellular bacteria number in LM‐infected WT and gal3−/− BMM were compared. Significantly lower amounts of IL‐12, IL‐1β, and IL‐6 were produced by LM‐infected gal3−/− BMM compared to WT BMM. No significant differences in ROS and NO production or phagocytosis of LM were observed. However, at 24 hr post‐infection, gal3−/− BMM contained dramatically lower number of intracellular bacteria than WT. These results suggest that galectin‐3 plays an important role in regulating cytokine production and intracellular bacteria load in macrophages during LM infection process.",2008-03-01,https://www.semanticscholar.org/paper/68df6d5bdce3d72ac7f9b2065e9a744ea0d4cead,
129,The Efficacy of GlOSS for the Text Database Discovery Problem,"The popularity of information retrieval has led users to a new problem: finding which text databases (out of thousands of candidate choices) are the most relevant to a user. Answering a given query with a list of relevant databases is the text database discovery problem. The first part of this paper presents a practical method for attacking this problem based on estimating the result size of a query and a database. The method is termed GlOSS--Glossary of Servers Server. The second part of this paper evaluates GlOSS using four different semantics to answer a user''s queries. Real users'' queries were used in the experiments. We also describe several variations of GlOSS and compare their efficacy. In addition, we analyze the storage cost of our approach to the problem.",1993-12-01,https://www.semanticscholar.org/paper/8fc1b50c90069f2d1720aecf76ed03f0d402b36b,ACM SIGMOD Conference
3097,pTHINC: a thin-client architecture for mobile wireless web,"Although web applications are gaining popularity on mobile wireless PDAs, web browsers on these systems can be quite slow and often lack adequate functionality to access many web sites. We have developed pTHINC, a PDA thin-client solution that leverages more powerful servers to run full-function web browsers and other application logic, then sends simple screen updates to the PDA for display. pTHINC uses server-side screen scaling to provide high-fidelity display and seamless mobility across a broad range of different clients and screen sizes, including both portrait and landscape viewing modes. pTHINC also leverages existing PDA control buttons to improve system usability and maximize available screen resolution for application display. We have implemented pTHINC on Windows Mobile and evaluated its performance on mobile wireless devices. Our results compared to local PDA web browsers and other thin-client approaches demonstrate that pTHINC provides superior web browsing performance and is the only PDA thin client that effectively supports crucial browser helper applications such as video playback.",2006-05-23,https://www.semanticscholar.org/paper/69a3aa909aec09f6a33631a266ac4b696c4664b5,The Web Conference
1707,"Jordan Boyd-Graber, David Mimno, and David Newman. Care and Feeding of Topic Models: Problems, Diagnostics, and Improvements. Handbook of Mixed Membership Models and Their Applications, 2014.",,,https://www.semanticscholar.org/paper/8db0184f4388f71a2a764b8d5a6f51488f691665,
1140,Measurement of the Zγ → vvγ Production Cross Section and Limits on Anomalous ZZγ and Zγγ Couplings in p Collisions at √s = 1.96 TeV,"We present the first observation of the Zγ → vvγ process at the Fermilab Tevatron at 5.1 standard deviations significance, based on 3.6 fb ―1 of integrated luminosity collected with the D0 detector at the Fermilab Tevatron pp Collider at √s = 1.96 TeV. The measured Zγ production cross section multiplied by the branching fraction of Z → vv is 32 ± 9(stat + syst) ± 2(lumi) fb for the photon E T > 90 GeV. It is in agreement with the standard model prediction of 39 ± 4 fb. We set limits on anomalous trilinear Zγγ and ZZγ gauge boson couplings, most of which are the most restrictive to date.",,https://www.semanticscholar.org/paper/05719dfb2dc29248122ec4ab78365bee1eb5c3de,
618,On the performance of balanced hashing functions when the keys are not equiprobable,"The cost (expected number of accesses per retrieval) of hashing functions is examined without the assumption that it is equally probable for all keys to be present in the table. It is shown that the obvious strategy—trying to balance the sums of probabilities of the keys mapped to any given address—may be suboptimal; however, the difference from the exactly optimal distribution cannot be large.",,https://www.semanticscholar.org/paper/c90ba73e111af466c4e408826cb29474672927ca,TOPL
24,Automatic Identification and Presentation of Twitter Content for Planned Events,"
 
 We demonstrate a system for augmenting information about planned events with Twitter messages, using a set of automatic query building strategies. We present two alternative interfaces to our system, namely, a browser plug-in and a customizable Web interface.
 
",2011-07-05,https://www.semanticscholar.org/paper/b16f594e3ed94e864cf4aa1ff183532107bffed0,International Conference on Web and Social Media
2293,Mcl-1 expression in human neutrophils: regulation by cytokines and correlation with cell survival.,"Human neutrophils possess a very short half-life because they constitutively undergo apoptosis. Cytokines, such as granulocyte-macrophage colony-stimulating factor (GM-CSF), and other agents can rescue neutrophils from apoptosis but the molecular mechanisms involved in this rescue are undefined. Here, we show by Western blotting that human neutrophils do not express Bcl-2 or Bcl-X but constitutively express Bax. However, cellular levels of these proteins are unaffected by agents which either accelerate or delay neutrophil apoptosis. In contrast, neutrophils express the antiapoptotic protein Mcl-1 and levels of this protein correlate with neutrophil survival. Thus, cellular levels of Mcl-1 decline as neutrophils undergo apoptosis and are enhanced by agents (eg, GM-CSF, interleukin-1beta, sodium butyrate, and lipopolysaccharide) that promote neutrophil survival. Neutrophils only possess few, small mitochondria, and much of the Mcl-1 protein seems to be located in nuclear fractions. These observations provide the first evidence implicating a Bcl-2 family member in the regulation of neutrophil survival. Moreover, this work also provides a potential mechanism whereby cytokine-regulated gene expression regulates the functional lifespan of neutrophils and hence their ability to function for extended time periods during acute inflammation.",,https://www.semanticscholar.org/paper/6a622a3b1d46985f8ad7880f1c35361bf3707086,Blood
1268,Erratum: Measurement of inclusive differential cross sections for Υ(1S) production in pp̄ collisions at s=1.96TeV (Physical Review Letters (2005) 94 (232001)),"V. M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, M. Agelou, J.-L. Agram, S. H. Ahn, M. Ahsan, G. D. Alexeev, G. Alkhazov, A. Alton, G. Alverson, G. A. Alves, M. Anastasoaie, T. Andeen, S. Anderson, B. Andrieu, Y. Arnoud, A. Askew, B. Åsman, A. C. S. Assis Jesus, O. Atramentov, C. Autermann, C. Avila, F. Badaud, A. Baden, B. Baldin, P. W. Balm, S. Banerjee, E. Barberis, P. Bargassa, P. Baringer, C. Barnes, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, A. Bean, S. Beauceron, M. Begel, A. Bellavance, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, M. Binder, C. Biscarat, K. M. Black, I. Blackler, G. Blazey, F. Blekman, S. Blessing, D. Bloch, U. Blumenschein, A. Boehnlein, O. Boeriu, T. A. Bolton, F. Borcherding, G. Borissov, K. Bos, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, S. Burdin, T. H. Burnett, E. Busato, J. M. Butler, J. Bystricky, S. Caron, W. Carvalho, B. C. K. Casey, N. M. Cason, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K. M. Chan, A. Chandra, D. Chapin, F. Charles, E. Cheu, D. K. Cho, S. Choi, B. Choudhary, T. Christiansen, L. Christofek, D. Claes, B. Clément, C. Clément, Y. Coadou, M. Cooke, W. E. Cooper, D. Coppage, M. Corcoran, A. Cothenet, M.-C. Cousinou, B. Cox, S. Crépé-Renaudin, M. Cristetiu, D. Cutts, H. da Motta, B. Davies, G. Davies, G. A. Davis, K. De, P. de Jong, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, S. Dean, J. D. Degenhardt, F. Déliot, M. Demarteau, R. Demina, P. Demine, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, M. Doidge, H. Dong, S. Doulas, L. V. Dudko, L. Duflot, S. R. Dugad, A. Duperrin, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, T. Edwards, J. Ellison, J. Elmsheuser, V. D. Elvira, S. Eno, P. Ermolov, O. V. Eroshin, J. Estrada, D. Evans, H. Evans, A. Evdokimov, V. N. Evdokimov, J. Fast, S. N. Fatakia, L. Feligioni, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, I. Fleck, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, E. Gallas, E. Galyaev, C. Garcia, A. Garcia-Bellido, J. Gardner, V. Gavrilov, P. Gay, D. Gelé, R. Gelhaus, K. Genser, C. E. Gerber, Y. Gershtein, G. Ginther, T. Golling, B. Gómez, K. Gounder, A. Goussiou, P. D. Grannis, S. Greder, H. Greenlee, Z. D. Greenwood, E. M. Gregores, Ph. Gris, J.-F. Grivaz, L. Groer, S. Grünendahl, M. W. Grünewald, S. N. Gurzhiev, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, S. Hagopian, I. Hall, R. E. Hall, C. Han, L. Han, K. Hanagaki, K. Harder, R. Harrington, J. M. Hauptman, R. Hauser, J. Hays, T. Hebbeker, D. Hedin, J. M. Heinmiller, A. P. Heinson, U. Heintz, C. Hensel, G. Hesketh, M. D. Hildreth, R. Hirosky, J. D. Hobbs, B. Hoeneisen, M. Hohlfeld, S. J. Hong, R. Hooper, P. Houben, Y. Hu, J. Huang, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, V. Jain, K. Jakobs, A. Jenkins, R. Jesik, K. Johns, M. Johnson, A. Jonckheere, P. Jonsson, A. Juste, D. Käfer, W. Kahl, S. Kahn, E. Kajfasz, A. M. Kalinin, J. Kalk, D. Karmanov, J. Kasper, D. Kau, R. Kaur, R. Kehoe, S. Kermiche, S. Kesisoglou, A. Khanov, A. Kharchilava, Y. M. Kharzheev, H. Kim, B. Klima, M. Klute, J. M. Kohli, M. Kopal, V. M. Korablev, J. Kotcher, B. Kothari, A. Koubarovsky, A. V. Kozelov, J. Kozminski, A. Kryemadhi, S. Krzywdzinski, S. Kuleshov, Y. Kulik, A. Kumar, S. Kunori, A. Kupco, T. Kurča, J. Kvita, S. Lager, N. Lahrichi, G. Landsberg, J. Lazoflores, A.-C. Le Bihan, P. Lebrun, W. M. Lee, A. Leflat, F. Lehner, C. Leonidopoulos, J. Leveque, P. Lewis, J. Li, Q. Z. Li, J. G. R. Lima, D. Lincoln, S. L. Linn, J. Linnemann, V. V. Lipaev, R. Lipton, L. Lobo, A. Lobodenko, M. Lokajicek, A. Lounis, P. Love, H. J. Lubatti, L. Lueking, M. Lynker, A. L. Lyon, A. K. A. Maciel, R. J. Madaras, P. Mättig, C. Magass, A. Magerkurth, A.-M. Magnan, N. Makovec, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, H. S. Mao, Y. Maravin, M. Martens, S. E. K. Mattingly, A. A. Mayorov, R. McCarthy, R. McCroskey, D. Meder, H. L. Melanson, A. Melnitchouk, A. Mendes, M. Merkin, K. W. Merritt, A. Meyer, M. Michaut, H. Miettinen, J. Mitrevski, N. Mokhov, J. Molina, N. K. Mondal, R. W. Moore, G. S. Muanza, M. Mulders, Y. D. Mutaf, E. Nagy, M. Narain, N. A. Naumann, H. A. Neal, J. P. Negret, S. Nelson, P. Neustroev, C. Noeding, A. Nomerotski, S. F. Novaes, T. Nunnemann, E. Nurse, V. O’Dell, D. C. O’Neil, V. Oguri, N. Oliveira, N. Oshima, G. J. Otero y Garzón, P. Padley, N. Parashar, S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, P. M. Perea, E. Perez, P. Pétroff, M. Petteni, L. Phaf, R. Piegaia, M.-A. Pleier, P. L. M. Podesta-Lerma, V. M. Podstavkov, Y. Pogorelov, B. G. Pope, W. L. Prado da Silva, H. B. Prosper, S. Protopopescu, J. Qian, A. Quadt, B. Quinn, K. J. Rani, K. Ranjan, P. A. Rapidis, P. N. Ratoff, N. W. Reay, S. Reucroft, M. Rijssenbeek, I. Ripp-Baudot, F. Rizatdinova, R. F. Rodrigues, C. Royon, P. Rubinov, R. Ruchti, V. I. Rud, G. Sajot, A. Sánchez-Hernández, M. P. Sanders, A. Santoro, G. Savage, L. Sawyer, T. Scanlon, D. Schaile, R. D. Schamberger, H. Schellman, P. Schieferdecker, C. Schmitt, A. Schwartzman, R. Schwienhorst, S. Sengupta, H. Severini, E. Shabalina, M. Shamim, V. Shary, A. A. Shchukin, W. D. Shephard, R. K. Shivpuri, D. Shpakov, R. A. Sidwell, V. Simak, V. Sirotenko, PRL 100, 049902 (2008) P H Y S I C A L R E V I E W L E T T E R S week ending 1 FEBRUARY 2008",2008-02-01,https://www.semanticscholar.org/paper/f250ff697245d8dc7bba2e81363d6d0d6145f008,
1221,Search for Neutral Higgs Bosons in Multi-b-Jet Events in p p Collisions at ffiffi s p 1⁄4 1 : 96 TeV,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, S. H. Ahn, M. Ahsan, G.D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G.A. Alves, M. Anastasoaie, L. S. Ancu, T. Andeen, S. Anderson, B. Andrieu, M. S. Anzelc, M. Aoki, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, A. C. S. Assis Jesus, O. Atramentov, C. Avila, F. Badaud, A. Baden, L. Bagby, B. Baldin, D. V. Bandurin, P. Banerjee, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V.A. Bezzubov, P. C. Bhat, V. Bhatnagar, C. Biscarat, G. Blazey, F. Blekman, S. Blessing, D. Bloch, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, E. E. Boos, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, S. Burke, T. H. Burnett, C. P. Buszello, J.M. Butler, P. Calfayan, S. Calvet, J. Cammin, W. Carvalho, B. C. K. Casey, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K. Chan, K.M. Chan, A. Chandra, F. Charles,** E. Cheu, F. Chevallier, D. K. Cho, S. Choi, B. Choudhary, L. Christofek, T. Christoudias, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, D. Cutts, M. Ćwiok, H. da Motta, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, J. D. Degenhardt, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, H. Dong, L. V. Dudko, L. Duflot, S. R. Dugad, D. Duggan, A. Duperrin, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V. D. Elvira, Y. Enari, S. Eno, P. Ermolov, H. Evans, A. Evdokimov, V.N. Evdokimov, A.V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, E. Gallas, C. Garcia, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, D. Gelé, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, N. Gollub, B. Gómez, A. Goussiou, P. D. Grannis, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Harder, A. Harel, J.M. Hauptman, R. Hauser, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, A. P. Heinson, U. Heintz, C. Hensel,22,x K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, J. D. Hobbs, B. Hoeneisen, H. Hoeth, M. Hohlfeld, S. J. Hong, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, C. Jarvis, R. Jesik, K. Johns, C. Johnson, M. Johnson, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, J.M. Kalk, D. Karmanov, P. A. Kasper, I. Katsanos, D. Kau, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y.M. Kharzheev, D. Khatidze, T. J. Kim, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, J.-P. Konrath, A. V. Kozelov, J. Kraus, D. Krop, T. Kuhl, A. Kumar, A. Kupco, T. Kurča, V. A. Kuzmin, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, W.M. Lee, A. Leflat, J. Lellouch, J. Leveque, J. Li, L. Li, Q. Z. Li, S.M. Lietti, J. G. R. Lima, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna, A. L. Lyon, A. K.A. Maciel, D. Mackin, R. J. Madaras, P. Mättig, C. Magass, A. Magerkurth, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, H. S. Mao, Y. Maravin, B. Martin, R. McCarthy, A. Melnitchouk, L. Mendoza, P. G. Mercadante, M. Merkin, K.W. Merritt, A. Meyer, J. Meyer,22,x T. Millet, J. Mitrevski, R. K. Mommsen, N.K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, N. A. Naumann, H.A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, V. O’Dell, D. C. O’Neil, G. Obrant, C. Ochando, D. Onoprienko, N. Oshima, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park,22,x S.K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, M. Petteni, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma, V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, B.G. Pope, A.V. Popov, C. Potter, W. L. Prado da Silva, H. B. Prosper, S. Protopopescu, J. Qian, A. Quadt,22,x B. Quinn, A. Rakitine, M. S. Rangel, K. Ranjan, P. N. Ratoff, P. Renkel, S. Reucroft, P. Rich, J. Rieger, M. Rijssenbeek, I. Ripp-Baudot, F. Rizatdinova, S. Robinson, R. F. Rodrigues, PRL 101, 221802 (2008) P HY S I CA L R EV I EW LE T T E R S week ending 28 NOVEMBER 2008",,https://www.semanticscholar.org/paper/573a375dadb592283b97ff558127471d41b32146,
2688,Generating efficient virtual worlds for visualization using partial evaluation and dynamic compilation,"We argue that runtime program transformation, partial evaluation, and dynamic compilation are essential tools for automated generation of flexible, highly interactive graphical interfaces. In particular, these techniques help bridge the gap between a high-level, functional description and an efficient implementation. To support our claim, we describe our application of these techniques to a functional implementation of n-Vision, a real-time visualization system that represents multivariate relations as nested 3D interactors, and to Auto Visual, a rule-based system that designs n-Vision visualizations from high-level task specifications. n-Vision visualizations are specified using a simple functional language. These programs are transformed into a cached dataflow graph. A partial evaluator is used on particular computation-intensive function applications, and the results are compiled to native code. The functional representation simplifies generation of correct code, and the program transformations ensure good performance. We demonstrate why these transformations improve performance and why they cannot be done at compile time.",1997-12-01,https://www.semanticscholar.org/paper/6cc84504b696fae7bc2a285490bd88002d1c1ead,ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation
1577,Adapting Neural Networks for the Estimation of Treatment Effects,"This paper addresses the use of neural networks for the estimation of treatment effects from observational data. Generally, estimation proceeds in two stages. First, we fit models for the expected outcome and the probability of treatment (propensity score) for each unit. Second, we plug these fitted models into a downstream estimator of the effect. Neural networks are a natural choice for the models in the first step. The question we address is: how can we adapt the design and training of the neural networks used in the first step in order to improve the quality of the final estimate of the treatment effect? We propose two adaptations based on insights from the statistical literature on the estimation of treatment effects. The first is a new architecture, the Dragonnet, that exploits the sufficiency of the propensity score for estimation adjustment. The second is a regularization procedure, targeted regularization, that induces a bias towards models that have non-parametrically optimal asymptotic properties `out-of-the-box`. Studies on benchmark datasets for causal inference show these adaptations outperform existing methods. Code is available at this http URL.",2019-06-05,https://www.semanticscholar.org/paper/a278c07c8bd2921e59dd862cd91a0540dd340030,Neural Information Processing Systems
3667,Data abstraction in c,,,https://www.semanticscholar.org/paper/2a81b35c3bc29d644a2e4ecb615f509a4a8cdb03,
215,Can Almost Everybody be Almost Happy?,"We conjecture that PPAD has a PCP-like complete problem, seeking a near equilibrium in which all but very few players have very little incentive to deviate. We show that, if one assumes that this problem requires exponential time, several open problems in this area are settled. The most important implication, proved via a ""birthday repetition"" reduction, is that the nO(log n) approximation scheme of Lipton et al. [23] for the Nash equilibrium of two-player games is essentially optimum. Two other open problems in the area are resolved once one assumes this conjecture, establishing that certain approximate equilibria are PPAD-complete: Finding a relative approximation of two-player Nash equilibria (without the well-supported restriction of [14]), and an approximate competitive equilibrium with equal incomes [10] with small clearing error and near-optimal Gini coefficient.",2015-04-09,https://www.semanticscholar.org/paper/13440bd165cdd629fe77032b517641243bcc9687,Information Technology Convergence and Services
43,DeSIGN: an intelligent tutor to teach american sign language,"This paper presents the development of DeSIGN, an educational software application for those deaf students who are taught to communicate using American Sign Language (ASL). The software reinforces English vocabulary and ASL signs by providing two essential components of a tutor, lessons and tests. The current version was designed for 5 th and 6 th graders, whose literacy skills lag by a grade or more on average. In addition, a game that allows the students to be creative has been integrated into the tests. Another feature of DeSIGN is its ability to intelligently adapt its tests to the changing knowledge of the student as determined by a knowledge tracing algorithm. A separate interface for the teacher enables additions and modifications to the content of the tutor and provides progress monitoring. These dynamic aspects help motivate the students to use the software repeatedly. This software prototype aims at a feasible and sustainable approach to increase the participation of deaf people in society. DeSIGN has undergone an iteration of testing and is currently in use at a school for the deaf in Pittsburgh.",,https://www.semanticscholar.org/paper/16d388dc0275c888776859884a309168cd5aac0e,Slate
3089,Using Rescue Points to Navigate Software Recovery,"We present a new technique that enables software recovery in legacy applications by retrofitting exception-handling capabilities, error virtualization using rescue points. We introduce the idea of ""rescue points"" as program locations to which an application can recover its execution in the presence of failures. The use of rescue points reduces the chance of unanticipated execution paths thereby making recovery more robust by mimicking system behavior under controlled error conditions. These controlled error conditions can be thought of as a set erroneous inputs, like the ones used by most quality-assurance teams during software development, designed to stress-test an application. To discover rescue points applications are profiled and monitored during tests that bombard the program with bad/random inputs. The intuition is that by monitoring application behavior during these runs, we gain insight into how programmer-tested program points are used to propagate faults gracefully.",2007-05-20,https://www.semanticscholar.org/paper/8ca3c3eecfd92d3b5cf5a77f6a5051404d12ef9e,IEEE Symposium on Security and Privacy
578,Polytopes and Complexity,,,https://www.semanticscholar.org/paper/fe45b29590efb87949f191230944b5999fb5c48d,
2962,Transcriptome Sequencing of a Large Human Family Identifies the Impact of Rare Noncoding Variants,,2014-09-01,https://www.semanticscholar.org/paper/22477e3148a4d3959ee681f19f74b85be5fe15c1,American Journal of Human Genetics
1989,Semiconductor manufacturing,,2012-10-18,https://www.semanticscholar.org/paper/03c5a168e77720077204b78b6dd63ff76a2fbdb7,Flexible Services and Manufacturing Journal
2586,Multi-Language Edit-and-Continue for the Masses,"We present an Edit-and-Continue implementation that allows regular source files to be treated like interactively updatable, compiled scripts, coupling the speed of compiled native machine code, with the ability to make changes without restarting. Our implementation is based on the Microsoft .NET Framework and allows applications written in any .NET language to be dynamically updatable. Our solution works with the standard version of the Microsoft Common Language Runtime, and does not require a custom compiler or runtime. Because no application changes are needed, it is transparent to the application developer. The runtime overhead of our implementation is low enough to support updating real-time applications (e.g., interactive 3D graphics applications).",,https://www.semanticscholar.org/paper/a8f95f772e84f195344dabf4b1ca602ec065de3d,
2738,Software technology for wireless mobile computing,"Some of the possibilities and requirements for mobile computing on wireless local area networks (LANs) are discussed from the systems software viewpoint. The design of the Student Electronic Notebook (SEN) is sketched to provide a partial catalog of problems in building a real system for wireless mobile computing. This project was initiated to investigate the potential of wireless mobile computing to reshape education. Some of the key directions for research in software technology for wireless, mobile computing are examined. Some of the authors' experience with wireless LANs is related.<<ETX>>",1991-11-01,https://www.semanticscholar.org/paper/452335899f0bf0164add7de30f112047ee80d526,IEEE Network
117,STARTS: Stanford proposal for Internet meta-searching,"Document sources are available everywhere, both within the internal networks of organizations and on the Internet. Even individual organizations use search engines from different vendors to index their internal document collections. These search engines are typically incompatible in that they support different query models and interfaces, they do not return enough information with the query results for adequate merging of the results, and finally, in that they do not export metadata about the collections that they index (e.g., to assist in resource discovery). This paper describes STARTS, an emerging protocol for Internet retrieval and search that facilitates the task of querying multiple document sources. STARTS has been developed in a unique way. It is not a standard, but a group effort coordinated by Stanford's Digital Library project, and involving over 11 companies and organizations. The objective of this paper is not only to give an overview of the STARTS protocol proposal, but also to discuss the process that led to its definition.",1997-06-01,https://www.semanticscholar.org/paper/5296edc2dae04f759bc06f959ba83989920f6182,ACM SIGMOD Conference
3292,Group Choice as a Function of Group Size Differences and Assessment Time in Fish: The Influence of Species Vulnerability to Predation,"The shoal-choice behaviour of two species of fish that differ in their vulnerability to predation was compared. Individuals of threespine stickleback, Gasterosteus aculatus, and creek chub, Semotilus astromaculatus, were presented with a simultaneous choice of two equidistant stimulus shoals of conspecifics that differed in membership size (5 vs. 6 fish, 5 vs. 7, 5 vs. 8, 5 vs. 9 and 5 vs. 10). Test fish were allowed to view the stimulus shoals from a standard distance for either 10-20 or 120-150 s before being frightened with a stimulus from an overhead light and released to join either shoal. We observed which shoal (the smaller or the larger one) the test fish approached. Preference for the larger stimulus shoal generally increased with increasing shoal size difference and with the duration of the assessment period, and was more pronounced in chub (the more vulnerable of the two species). For the short assessment period, chub showed a significantly stronger preference for the larger stimulus shoal than sticklebacks, whereas there was no significant difference between species for the long assessment period. Furthermore, chub responded more readily to small differences in shoal size (of 1-3 fish) than sticklebacks, for both short and long assessment periods. The above results are consistent with the hypothesis that chub, as the more vulnerable of the two species (in terms of predation), should be able to identify the larger of two shoals more quickly and should be more sensitive to small differences in shoal size than sticklebacks.",2010-04-26,https://www.semanticscholar.org/paper/685ef1f5d8473cbc282ec697852f578314011bc6,
641,Grigni: [7] Topological Inference,"Geographical database systems deal with certain basic topological relations such as \A overlaps B"" and \B contains C"" between simply connected regions in the plane. It is of great interest to make sound inferences from elementary statements of this form. This problem has been identi ed extensively in the recent literature, but very limited progress has been made towards addressing the considerable technical di culties involved. In this paper we study the computational problems involved in developing such an inference system. We point out that the problem has two distinct components that interact in rather complex ways: relational consistency, and planarity. We develop polynomial-time algorithms for several important special cases, and prove almost all the others to be NP-hard.",,https://www.semanticscholar.org/paper/079ab20c10fa1ec1be8a8e6ea66901dc74ea7bca,
40,"Understanding, Estimating, and Incorporating Output Quality Into Join Algorithms For Information Extraction","Information extraction (IE) systems are trained to extract specific relations from text databases. Real-world applications often require that the output of multiple IE systems be joined to produce the data of interest. To optimize the execution of a join of multiple extracted relations, it is not sufficient to consider only execution time. In fact, the quality of the join output is of critical importance: unlike in the relational world, different join execution plans can produce join results of widely different quality whenever IE systems are involved. In this paper, we develop a principled approach to understand, estimate, and incorporate output quality into the join optimization process over extracted relations. We argue that the output quality is affected by (a) the configuration of the IE systems used to process the documents, (b) the document retrieval strategies used to retrieve documents, and (c) the actual join algorithm used. Our analysis considers a variety of join algorithms from relational query optimization, and predicts the output quality –and, of course, the execution time– of the alternate execution plans. We establish the accuracy of our analytical models, as well as study the effectiveness of a quality-aware join optimizer, with a large-scale experimental evaluation over real-world text collections and state-of-the-art IE systems.",2008-06-27,https://www.semanticscholar.org/paper/abe9e21b18ae3934dcaa4d449c25ceced0a4866b,
1534,Causal inference from text: A commentary,Statistical and machine learning methods help social scientists and other researchers make causal inferences from texts.,2022-10-01,https://www.semanticscholar.org/paper/f924b383cc7e83e454f8a43e7ff60355539e2110,Science Advances
1410,Results of the Cryogenic Dark Matter Search,,,https://www.semanticscholar.org/paper/5addaf9a421384fbd7047132fb092a63c6e425a3,
2872,Galectin-7 (PIG1) Exhibits Pro-apoptotic Function through JNK Activation and Mitochondrial Cytochrome cRelease* 210,"Galectin-7 is normally expressed in all types of stratified epithelia, but is significantly down-regulated in squamous cell carcinomas. This protein was recently found to be highly inducible by p53 in a colon carcinoma cell line, DLD-1, and designated as PIG1 (for p53-inducedgene 1). We studied transfectants of HeLa and DLD-1 cells ectopically expressing this protein and found that they were more susceptible to apoptosis than control transfectants. This was observed in apoptosis induced by mechanistically distinct stimuli, suggesting that galectin-7 acts on a common point in the apoptosis signaling pathways. Further analyses of actinomycin D-induced apoptosis demonstrated that galectin-7 expression causes enhanced caspase-3 activity and poly(ADP-ribose) polymerase cleavage, and the potentiation of apoptosis by galectin-7 was completely abrogated by a caspase inhibitor, benzyloxycarbonyl-Val-Ala-Asp-fluoromethyl ketone. In addition, galectin-7 transfectants displayed accelerated mitochondrial cytochrome c release and up-regulated JNK activity upon apoptosis induction. Several lines of evidence indicate that the effect on apoptosis is not due to the lectin functioning extracellularly through interactions with cell surface glycoconjugates. In fact, this lectin is found to localize in nuclei and cytoplasm of the transfectants and the transformed keratinocyte line HaCaT. Therefore, galectin-7 is a pro-apoptotic protein that functions intracellularly upstream of JNK activation and cytochrome c release. DNA microarray analysis revealed genes that are differentially expressed between galectin-7 and control transfectants. Some of them are potentially contributory to this lectin's proapoptotic function and these include redox-related genes monoamine oxidase B, ryanodine receptor 2, and glutathione S-transferase Mu 3.",2002-02-01,https://www.semanticscholar.org/paper/e3b64f35624eb03594cbf277125ca50e430643dc,Journal of Biological Chemistry
3148,Measuring thin-client performance using slow-motion benchmarking,"Modern thin-client systems are designed to provide the same graphical interfaces and applications available on traditional desktop computers while centralizing administration and allowing more efficient use of computing resources. Despite the rapidly increasing popularity of these client-server systems, there are few reliable analyses of their performance. Industry standard benchmark techniques commonly used for measuring desktop system performance are ill-suited for measuring the performance of thin-client systems because these benchmarks only measure application performance on the server, not the actual user-perceived performance on the client. To address this problem, we have developed slow-motion benchmarking, a new measurement technique for evaluating thin-client systems. In slow-motion benchmarking, performance is measured by capturing network packet traces between a thin client and its respective server during the execution of a slow-motion version of a conventional benchmark application. These results can then be used either independently or in conjunction with conventional benchmark results to yield an accurate and objective measure of the performance of thin-client systems. We have demonstrated the effectiveness of slow-motion benchmarking by using this technique to measure the performance of several popular thin-client systems in various network environments on Web and multimedia workloads. Our results show that slow-motion benchmarking solves the problems with using conventional benchmarks on thin-client systems and is an accurate tool for analyzing the performance of these systems.",2001-06-25,https://www.semanticscholar.org/paper/eb867b23e31dce148902b7ef879b63247d83f9c2,TOCS
1780,Bayesian Nonparametric Matrix Factorization for Recorded Music,"Recent research in machine learning has focused on breaking audio spectrograms into separate sources of sound using latent variable decompositions. These methods require that the number of sources be specified in advance, which is not always possible. To address this problem, we develop Gamma Process Nonnegative Matrix Factorization (GaP-NMF), a Bayesian nonparametric approach to decomposing spectrograms. The assumptions behind GaP-NMF are based on research in signal processing regarding the expected distributions of spectrogram data, and GaP-NMF automatically discovers the number of latent sources. We derive a mean-field variational inference algorithm and evaluate GaP-NMF on both synthetic data and recorded music.",2010-06-21,https://www.semanticscholar.org/paper/1dda1a4414675729f46594a5e609938ef3a48382,International Conference on Machine Learning
1661,"32nd International Conference on Machine Learning : (ICML 2015) : Lile, France, 6-11 July 2015",,,https://www.semanticscholar.org/paper/ad4ddc21a0cf5cc2a124a289d0cbb821f5aaeaab,
1092,Maximum Likelihood Analysis of Low Energy CDMS II Germanium Data,"We report on the results of a search for a Weakly Interacting Massive Particle (WIMP) signal in low-energy data of the Cryogenic Dark Matter Search experiment using a maximum likelihood analysis. A background model is constructed using GEANT4 to simulate the surface-event background from ^(210)Pb decay-chain events, while using independent calibration data to model the gamma background. Fitting this background model to the data results in no statistically significant WIMP component. In addition, we perform fits using an analytic ad hoc background model proposed by Collar and Fields, who claimed to find a large excess of signal-like events in our data. We confirm the strong preference for a signal hypothesis in their analysis under these assumptions, but excesses are observed in both single- and multiple-scatter events, which implies the signal is not caused by WIMPs, but rather reflects the inadequacy of their background model.",2014-10-04,https://www.semanticscholar.org/paper/4f5bcaca53c4fa3497bd57a1a42da4a1a4796c27,
1257,J an 2 00 8 Fermilab-Pub-08-007-E Search for excited electrons in pp̄ collisions at √ s = 1 . 96 TeV,"V.M. Abazov, B. Abbott, M. Abolins, B.S. Acharya, M. Adams, T. Adams, E. Aguilo, S.H. Ahn, M. Ahsan, G.D. Alexeev, G. Alkhazov, A. Alton, G. Alverson, G.A. Alves, M. Anastasoaie, L.S. Ancu, T. Andeen, S. Anderson, B. Andrieu, M.S. Anzelc, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, A.C.S. Assis Jesus, O. Atramentov, C. Autermann, C. Avila, C. Ay, F. Badaud, A. Baden, L. Bagby, B. Baldin, D.V. Bandurin, S. Banerjee, P. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J.F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J.A. Benitez, S.B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V.A. Bezzubov, P.C. Bhat, V. Bhatnagar, C. Biscarat, G. Blazey, F. Blekman, S. Blessing, D. Bloch, K. Bloom, A. Boehnlein, D. Boline, T.A. Bolton, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, N.J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, S. Burke, T.H. Burnett, C.P. Buszello, J.M. Butler, P. Calfayan, S. Calvet, J. Cammin, W. Carvalho, B.C.K. Casey, N.M. Cason, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K.M. Chan, K. Chan, A. Chandra, F. Charles, E. Cheu, F. Chevallier, D.K. Cho, S. Choi, B. Choudhary, L. Christofek,",,https://www.semanticscholar.org/paper/d7b1c7f0e6cf71d2096520ddea177d75bdc49533,
2713,Windows on the world: 2D windows for 3D augmented reality,"INTRODUCTION We describe the design and implementation of a prototype When we think of the use of head-mounted displays and 3D heads-up window system intended for use in a 3D environinteraction devices to present virtual worlds, it is often in ment. Our system includes a see-through head-mounted terms of environments populated solely by 3D objects. display that runs a full X server whose image is overlaid on There are many situations, however, in which 2D text and the user’s view of the physical world. The user’s head is graphics of the sort supported by current window systems tracked so that the display indexes into a large X bitmap, can be useful components of these environments. This is effectively placing the user inside a display space that is especially true in the case of the many applications that run mapped onto part of a surrounding virtual sphere. By under an industry standard window system such as X [13]. tracking the user’s body, and interpreting head motion relaWhile we might imagine porting or enhancing a significant tive to it, we create a portable information surround that X application to take advantage of the 3D capabilities of a envelopes the user as they move about. virtual world, the effort and cost may not be worth the return, especially if the application is inherently 2D. We support three kinds of windows implemented on top of Therefore, we have been exploring how we can incorporate the X server: windows fixed to the head-mounted display, an existing 2D window system within a 3D virtual world. windows fixed to the information surround, and windows fixed to locations and objects in the 3D world. Objects can We are building an experimental system that supports a full also be tracked, allowing windows to move with them. To X11 server on a see-through head-mounted display. Our demonstrate the utility of this model, we describe a small display overlays a selected portion of the X bitmap on the hypermedia system that allows links to be made between user’s view of the world, creating an X-based augmented windows and windows to be attached to objects. Thus, our reality. Depending on the situation and application, the hypermedia system can forge links between any combinauser may wish to treat a window as a stand-alone entity or tion of physical objects and virtual windows. to take advantage of the potential relationships that can be made between it and the visible physical world. To make this possible, we have developed facilities that allow X",1993-12-01,https://www.semanticscholar.org/paper/3a6ca1738e7affb77d001c6bc5128c85608cc912,ACM Symposium on User Interface Software and Technology
330,Experiments with an Economic Model of the Worldwide Web,,2005-12-15,https://www.semanticscholar.org/paper/4443b04a11215ff5867596ceb9b5a25dc239f1ad,Workshop on Internet and Network Economics
1712,Smoothed Gradients for Stochastic Variational Inference,"Stochastic variational inference (SVI) lets us scale up Bayesian computation to massive data. It uses stochastic optimization to fit a variational distribution, following easy-to-compute noisy natural gradients. As with most traditional stochastic optimization methods, SVI takes precautions to use unbiased stochastic gradients whose expectations are equal to the true gradients. In this paper, we explore the idea of following biased stochastic gradients in SVI. Our method replaces the natural gradient with a similarly constructed vector that uses a fixed-window moving average of some of its previous terms. We will demonstrate the many advantages of this technique. First, its computational cost is the same as for SVI and storage requirements only multiply by a constant factor. Second, it enjoys significant variance reduction over the unbiased estimates, smaller bias than averaged gradients, and leads to smaller mean-squared error against the full gradient. We test our method on latent Dirichlet allocation with three large corpora.",2014-06-13,https://www.semanticscholar.org/paper/b21fd95f438792add77d1d35132a01b895648c17,Neural Information Processing Systems
1955,A Frequency-Modulated Continuous Wave Phased Array Marine Radar System Based on Smart Antenna Technology,"We describe an X-band marine phased-array frequency-modulated continuous-wave (FMCW) radar system based on the smart antenna technology. Two main features, including the beam-forming and angles-of-arrival (AOA) estimation, are presented in this paper. Such a system is composed of eight subarray antennas arranged linearly, each of which consists of ten 1-D patch array antennas generating a directional pattern along the vertical plane. The hybrid analog-digital beam-forming scheme was implemented; specifically, the phased local oscillator was developed for manipulating the phase angle over the local oscillator rather than over the output X-band signal for transmission. Alternatively, by dynamically adjusting the amplitude and phase of the FMCW signals generated by direct digital synthesis (DDS) device, we can also achieve the function of beamforming. Additionally, the angles-of-arrival of the correlated echo signal scattering by targets are estimated by using the subspace method – space smooth multiple signal classification (MUSIC) algorithm. The AOA estimator, which includes the hardware for down-converting the X-band signals to I/Q baseband and the software for algorithm implementation, has been deployed. The measurements for range detection, angles of arrival estimation, and beam-forming has been carried out in this research work. Keywords—FMCW, smart antenna system, phased-array system, angle-of-arrival estimation, beam-forming technique.",,https://www.semanticscholar.org/paper/361226fe5cdc0e2248638a4954995dd6f6002b50,
3773,Acquiring Visual Classifiers from Human Imagination,"Abstract : The human mind can remarkably imagine objects that it has never seen, touched, or heard, all in vivid detail. Motivated by the desire to harness this rich source of information from the human mind, this paper investigates how to extract classifiers from the human visual system and leverage them in a machine. We introduce a method that, inspired by wellknown tools in human psychophysics, estimates the classifier that the human visual system might use for recognition but in computer vision feature spaces. Our experiments are surprising, and suggest that classifiers from the human visual system can be transferred into a machine with some success. Since these classifiers seem to capture favorable biases in the human visual system, we present a novel SVM formulation that constrains the orientation of the SVM hyperplane to agree with the human visual system. Our results suggest that transferring this human bias into machines can help object recognition systems generalize across datasets. Moreover, we found that people's culture may subtly vary the objects that people imagine, which influences this bias. Overall, human imagination can be an interesting resource for future visual recognition systems.",2014-10-16,https://www.semanticscholar.org/paper/e30a0e7a798831f8ab8b82ea3c51ba68201b27d1,arXiv.org
2767,DIAL: DIagrammatic Animation Language Tutorial and Reference Manual,,,https://www.semanticscholar.org/paper/7f5a31826758a38329e78a6998e5d8d2b315afe9,
1786,A focus on graphical model design and applications to document and image analysis ),"In this article, we review probabilistic topic models: graphical models that can be used to summarize a large collection of documents with a smaller number of distributions over words. Those distributions are called “topics” because, when fit to data, they capture the salient themes that run through the collection. We describe both finite-dimensional parametric topic models and their Bayesian nonparametric counterparts, which are based on the hierarchical Dirichlet process (HDP). We discuss two extensions of topic models to time-series data—one that lets the topics slowly change over time and one that lets the assumed prevalence of the topics change. Finally, we illustrate the application of topic models to nontext data, summarizing some recent research results in image analysis.",,https://www.semanticscholar.org/paper/a96e3a4a3af1de3c16a0914c5304db186fde6af0,
1933,UNISON framework of data-driven innovation for extracting user experience of product design of wearable devices,,2016-09-01,https://www.semanticscholar.org/paper/3ea3672aac2ad95b0ae7c804aefff6881c5457ec,Computers & industrial engineering
1676,The Population Posterior and Bayesian Modeling on Streams,"Many modern data analysis problems involve inferences from streaming data. However, streaming data is not easily amenable to the standard probabilistic modeling approaches, which require conditioning on finite data. We develop population variational Bayes, a new approach for using Bayesian modeling to analyze streams of data. It approximates a new type of distribution, the population posterior, which combines the notion of a population distribution of the data with Bayesian inference in a probabilistic model. We develop the population posterior for latent Dirichlet allocation and Dirichlet process mixtures. We study our method with several large-scale data sets.",2015-12-07,https://www.semanticscholar.org/paper/4718f38e709c8203201cf4e226519f985b3d0183,Neural Information Processing Systems
2198,Synovial fluid IL-6 concentrations associated with positive response to tocilizumab in an RA patient with failed response to anti-TNF and rituximab.,,2015-04-01,https://www.semanticscholar.org/paper/8f5b8138ff55fc48a0780c74274cc9fd85df5b1e,Rheumatology
3401,Submodular Secretary Problem with Shortlists,"In submodular $k$-secretary problem, the goal is to select $k$ items in a randomly ordered input so as to maximize the expected value of a given monotone submodular function on the set of selected items. In this paper, we introduce a relaxation of this problem, which we refer to as submodular $k$-secretary problem with shortlists. In the proposed problem setting, the algorithm is allowed to choose more than $k$ items as part of a shortlist. Then, after seeing the entire input, the algorithm can choose a subset of size $k$ from the bigger set of items in the shortlist. We are interested in understanding to what extent this relaxation can improve the achievable competitive ratio for the submodular $k$-secretary problem. In particular, using an $O(k)$ shortlist, can an online algorithm achieve a competitive ratio close to the best achievable online approximation factor for this problem? We answer this question affirmatively by giving a polynomial time algorithm that achieves a $1-1/e-\epsilon -O(k^{-1})$ competitive ratio for any constant $\epsilon > 0$, using a shortlist of size $\eta_\epsilon(k) = O(k)$. Also, for the special case of m-submodular functions, we demonstrate an algorithm that achieves a $1-\epsilon$ competitive ratio for any constant $\epsilon > 0$, using an $O(1)$ shortlist. Finally, we show that our algorithm can be implemented in the streaming setting using a memory buffer of size $\eta_\epsilon(k) = O(k)$ to achieve a $1 - 1/e - \epsilon-O(k^{-1})$ approximation for submodular function maximization in the random order streaming model. This substantially improves upon the previously best known approximation factor of $1/2 + 8 \times 10^{-14}$ [Norouzi-Fard et al. 2018] that used a memory buffer of size $O(k \log k)$.",2018-09-13,https://www.semanticscholar.org/paper/e795fbb0b7d89eca94d6710c77da10417ca62f6a,Information Technology Convergence and Services
1330,Measurement of theproduction cross section incollisions atusing secondary vertextagging,,2006-12-26,https://www.semanticscholar.org/paper/e70da24486cee1b09df5bf466f10266b9f679b8b,
1641,A probabilistic approach to discovering dynamic full-brain functional connectivity patterns,,2017-02-07,https://www.semanticscholar.org/paper/ff543c45096d817b748e29874317b31ec766dd33,NeuroImage
2928,Active Learning in CNNs via Expected Improvement Maximization,"Deep learning models such as Convolutional Neural Networks (CNNs) have demonstrated high levels of effectiveness in a variety of domains, including computer vision and more recently, computational biology. However, training effective models often requires assembling and/or labeling large datasets, which may be prohibitively time-consuming or costly. Pool-based active learning techniques have the potential to mitigate these issues, leveraging models trained on limited data to selectively query unlabeled data points from a pool in an attempt to expedite the learning process. Here we present ""Dropout-based Expected IMprOvementS"" (DEIMOS), a flexible and computationally-efficient approach to active learning that queries points that are expected to maximize the model's improvement across a representative sample of points. The proposed framework enables us to maintain a prediction covariance matrix capturing model uncertainty, and to dynamically update this matrix in order to generate diverse batches of points in the batch-mode setting. Our active learning results demonstrate that DEIMOS outperforms several existing baselines across multiple regression and classification tasks taken from computer vision and genomics.",2020-11-27,https://www.semanticscholar.org/paper/5af1dab052d40a938c8a8112844783264f1c2af5,arXiv.org
2296,Seeing the wood for the trees: the forgotten role of neutrophils in rheumatoid arthritis.,,1997-07-01,https://www.semanticscholar.org/paper/31cc5d012e7b67761fa01fcc86c51975029f9d45,Immunology today (Amsterdam. Regular ed.)
136,Fully-adaptive routing: packet switching performance and wormhole algorithms,No abstract available,1991-08-01,https://www.semanticscholar.org/paper/c60b14354b0ac82c2f883f739e16c6720ebe870a,Proceedings of the 1991 ACM/IEEE Conference on Supercomputing (Supercomputing '91)
2405,"Changes in Oxygen Uptake Rates, Enzyme Activities, Cytochrome Amounts and Adenine Nucleotide Pool Levels during Growth of Acanthamoeba castellanii in Batch Culture","Summary: Complex changes in the activities of cytochrome c oxidase, succinate dehydrogenase, catalase, alkaline phosphatase and acid hydrolases, and in the levels of cytochromes were observed during the growth cycle of Acanthamoeba castellanii in a proteose peptone/glucose/yeast extract medium. A transition occurred at the mid-exponential phase of growth without any change in the growth rate. A second transition corresponded with the cessation of growth; the specific activities of cytochrome c oxidase, succinate dehydrogenase and alkaline phosphatase declined during the stationary phase of growth whereas the specific activities of catalase and the acid hydrolases increased. Glucose was not utilized during the first 30 h of growth and the respiration rate was low, AMP levels were high and some AMP appeared extracellularly. After 30 h, values for the adenylate charge rose from less than 0.1 to more than 0.7, although ATP levels per cell did not vary. When cells were grown in conditioned medium (obtained by removing cells from a 48 h culture) the characteristics of a normal culture observed before 30 h were lost.",1977-09-01,https://www.semanticscholar.org/paper/2848a1691f20bfdba30b8ddc9cc48b157efb47be,
474,The Power of Re ective Relational MachinesS,"A model of database programming with reeection, called reeective relational machine, is introduced and studied. The reeection consists here of dynamic generation of queries in a host programming language. The main results characterize the power of the machine in terms of known complexity classes. In particular , the polynomial-time restriction of the machine is shown to express PSPACE, and to correspond precisely to uniform circuits of polynomial depth and exponential size. This provides an alternative, logic-based formulation of the uniform circuit model, more convenient for problems naturally formulated in logic terms. Since time in the polynomially-bounded machine coincides with time in the uniform circuit model, this also shows that reeection allows for more \intense"" par-allelism, which is not attainable otherwise (unless P = PSPACE). Other results concern the power of the reeective relational machine subject to restrictions on the number of variables used.",,https://www.semanticscholar.org/paper/c5f7bc1d5f9072bc3ff4b931756f992207b7877e,
56,"CIKM 2004 : proceedings of the Thirteenth ACM Conference on Information and Knowledge Management, November 8-13, 2004, Washington, DC, USA",,,https://www.semanticscholar.org/paper/31ccc944afda623530f81e980a864d62e82a446e,
2877,451 Galectin-3 induces monocyte migration by a chemokine receptor-independent pathway,,,https://www.semanticscholar.org/paper/7b4d89ef23f553414dcf34de79a54816089c225c,
710,Passive Static Equilibrium with Frictional Contacts and Application to Grasp Stability Analysis,"This paper studies the problem of passive grasp stability under an external disturbance, that is, the ability of a grasp to resist a disturbance through passive responses at the contacts. To obtain physically consistent results, such a model must account for friction phenomena at each contact; the difficulty is that friction forces depend in non-linear fashion on contact behavior (stick or slip). We develop the first polynomial-time algorithm which either solves such complex equilibrium constraints for two-dimensional grasps, or otherwise concludes that no solution exists. To achieve this, we show that the number of possible `slip states' (where each contact is labeled as either sticking or slipping) that must be considered is polynomial (in fact quadratic) in the number of contacts, and not exponential as previously thought. Our algorithm captures passive response behaviors at each contact, while accounting for constraints on friction forces such as the maximum dissipation principle.",2018-06-04,https://www.semanticscholar.org/paper/6594b81a9d2f9cfb94abe816ca5489c18d657926,Robotics: Science and Systems
1861,Matching Words and Pictures,"We present a new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text. Learning the joint distribution of image regions and words has many applications. We consider in detail predicting words associated with whole images (auto-annotation) and corresponding to particular image regions (region naming). Auto-annotation might help organize and access large collections of images. Region naming is a model of object recognition as a process of translating image regions to words, much as one might translate from one language to another. Learning the relationships between image regions and semantic correlates (words) is an interesting example of multi-modal data mining, particularly because it is typically hard to apply data mining techniques to collections of images. We develop a number of models for the joint distribution of image regions and words, including several which explicitly learn the correspondence between regions and words. We study multi-modal and correspondence extensions to Hofmann's hierarchical clustering/aspect model, a translation model adapted from statistical machine translation (Brown et al.), and a multi-modal extension to mixture of latent Dirichlet allocation (MoM-LDA). All models are assessed using a large collection of annotated images of real scenes. We study in depth the difficult problem of measuring performance. For the annotation task, we look at prediction performance on held out data. We present three alternative measures, oriented toward different types of task. Measuring the performance of correspondence methods is harder, because one must determine whether a word has been placed on the right region of an image. We can use annotation performance as a proxy measure, but accurate measurement requires hand labeled data, and thus must occur on a smaller scale. We show results using both an annotation proxy, and manually labeled data.",2003-03-01,https://www.semanticscholar.org/paper/6a26268d2ba9d34e5b59ae6e5c11a83cdca1a85e,Journal of machine learning research
2110,Using DEA to Measure the Relative Efficiency of the Service Center and Improve Operation Efficiency through Reorganization,"Data envelopment analysis (DEA) has become a practicable approach to evaluate the relative efficiencies of decision-making units in various contexts. A DEA study was conducted to measure the relative efficiencies of 17 service centers of the NAN-TOU electricity distribution district of Taiwan Power Company (TPC). Altematives for reorganizing the service centers via efficiency measurement were investigated. The results showed that the proposed reorganization alternatives have better efficiency scores. Based on DEA evaluations, we provide specific directions for the inefficient service centers to improve their operation efficiencies and thus maintain the competitive advantage of TPC in facing power market liberalization.",2002-11-01,https://www.semanticscholar.org/paper/04186f47f51401b1203f10f91c6ebc8cedb0139a,IEEE Power Engineering Review
2895,Computational models of dopamine release measured by fast scan cyclic voltammetry in vivo,"Abstract Dopamine neurotransmission in the striatum is central to many normal and disease functions. Ventral midbrain dopamine neurons exhibit ongoing tonic firing that produces low extrasynaptic levels of dopamine below the detection of conventional extrasynaptic cyclic voltammetry (∼10–20 nanomolar), with superimposed bursts that can saturate the dopamine uptake transporter and produce transient micromolar concentrations. The bursts are known to lead to marked presynaptic plasticity via multiple mechanisms, but analysis methods for these kinetic parameters are limited. To provide a deeper understanding of the mechanics of the modulation of dopamine neurotransmission by physiological, genetic, and pharmacological means, we present three computational models of dopamine release with different levels of spatiotemporal complexity to analyze in vivo fast-scan cyclic voltammetry recordings from the dorsal striatum of mice. The models accurately fit to cyclic voltammetry data and provide estimates of presynaptic dopamine facilitation/depression kinetics and dopamine transporter reuptake kinetics, and we used the models to analyze the role of synuclein proteins in neurotransmission. The models’ results support recent findings linking the presynaptic protein α-synuclein to the short-term facilitation and long-term depression of dopamine release, as well as reveal a new role for β-synuclein and/or γ-synuclein in the long-term regulation of dopamine reuptake.",2023-02-10,https://www.semanticscholar.org/paper/cc344a3a08a028a8ca9b77a39af138c7922f5617,PNAS Nexus
1657,Recurrent switching linear dynamical systems,"Many natural systems, such as neurons firing in the brain or basketball teams traversing a court, give rise to time series data with complex, nonlinear dynamics. We can gain insight into these systems by decomposing the data into segments that are each explained by simpler dynamic units. Building on switching linear dynamical systems (SLDS), we present a new model class that not only discovers these dynamical units, but also explains how their switching behavior depends on observations or continuous latent states. These ""recurrent"" switching linear dynamical systems provide further insight by discovering the conditions under which each unit is deployed, something that traditional SLDS models fail to do. We leverage recent algorithmic advances in approximate inference to make Bayesian inference in these models easy, fast, and scalable.",2016-10-26,https://www.semanticscholar.org/paper/79a970ad49d35173f3b789995de8237775b675ff,
1479,"MEASUREMENT OF THE PHOTON STRUCTURE-FUNCTION F2-GAMMA-(X,Q2) IN THE REGION 0.2 LESS-THAN Q2 LESS-THAN 7 GEV2",,,https://www.semanticscholar.org/paper/5c7464000660f78573407a47e4c641af313fc72b,
2627,Mutual disambiguation of 3D multimodal interaction in augmented and virtual reality,"We describe an approach to 3D multimodal interaction in immersive augmented and virtual reality environments that accounts for the uncertain nature of the information sources. The resulting multimodal system fuses symbolic and statistical information from a set of 3D gesture, spoken language, and referential agents. The referential agents employ visible or invisible volumes that can be attached to 3D trackers in the environment, and which use a time-stamped history of the objects that intersect them to derive statistics for ranking potential referents. We discuss the means by which the system supports mutual disambiguation of these modalities and information sources, and show through a user study how mutual disambiguation accounts for over 45% of the successful 3D multimodal interpretations. An accompanying video demonstrates the system in action.",2003-11-05,https://www.semanticscholar.org/paper/ed54d91b97f134437f18706462d957bde46ad0c3,International Conference on Multimodal Interaction
3298,Partnering with local communities to identify conservation priorities for endangered Grevy's zebra,,2009-07-01,https://www.semanticscholar.org/paper/75fed980475d4310f68bd66162f714c9fe3fd008,
1491,Performance of a lead glass spectrometer at high energies,,1985-05-15,https://www.semanticscholar.org/paper/93e9c78fe6f12a72580db698ecc91a0ed8f8c9e5,
754,Proceedings of the nineteenth annual ACM-SIAM Symposium on Discrete Algorithms (SODA '08),,,https://www.semanticscholar.org/paper/f6896a9cef2eecf6a34bf7ace8c86b5c6aac5e96,
3539,C programming language third edition,"provides an Introduction to the C Programming Language. en.wikipedia.org /wiki/ Assembly Language Step-by-Step Programming with Linux, 3rd Edition H. Python programming for the absolute beginner, 3rd edition C programming for the and easy c programming guide (c programming, c programming language. Robert Seacord introduces the second edition of The CERT C Coding Standard: 98 Rules for Developing Safe, Programming LanguagesC, Third Edition.",,https://www.semanticscholar.org/paper/b002528c1c9c74e428f7b50f854e21293176d372,
2185,High macrophage activities are associated with advanced periductal fibrosis in chronic Opisthorchis viverrini infection,"Liver fluke infection caused by Opisthorchis viverrini induces several hepatobiliary conditions including advanced periductal fibrosis (APF) and cholangiocarcinoma (CCA), but >25% of the infected population develops APF and 1% develop CCA. The innate immune response is the first line of defence, and macrophages are critical regulators of fibrosis. We hypothesized that macrophages from infected individuals have different capacities to either promote or suppress periductal fibrosis. We compared phagocytic activities of macrophages of healthy individuals and O viverrini‐infected individuals ± APF, and found that macrophages from infected individuals with APF ingested significantly higher numbers of beads compared with healthy controls and O viverrini‐infected individuals without APF. To further investigate proteolytic activity, we monitored real‐time phagosomal proteolysis of beads conjugated to DQ‐BODIPY‐BSA using live cell imaging. We show that macrophages from O viverrini‐infected individuals with APF also have elevated phagosomal proteolysis activity, which is consistent with their increased phagocytic activity. Additionally, stimulated ROS production by blood monocytes was higher in individuals with APF compared with healthy controls and infected individuals without APF. These results suggest that during O viverrini infection, macrophages with high phagocytic and proteolytic activities together with elevated ROS production are the phenotypes that can promote tissue damage, which results in periductal fibrosis.",2018-12-03,https://www.semanticscholar.org/paper/51f7427f9015e08e2b2766c3830457d1f46bae47,Parasite immunology (Print)
112,Mediating and Metasearching on the Internet,"The Internet emerges as the largest database. Increasingly, users want to issue complex queries across Internet sources to obtain the data they require. However, finding relevant information sources and querying them manually is problematic: there are numerous sources, and they vary in the type of information objects they contain and in the interface they present to their users. Some sources contain text documents and support simple query models where a query is just a list of keywords. Other sources contain more structured data and provide query interfaces in the style of relational query languages. Furthermore, users have to manually fuse the query results by merging information, removing redundancies, ranking the answer objects in the appropriate order, and so on. Since it is tedious to contact several heterogeneous sources, users can benefit from metasearchers and mediators, which are services that provide users with a virtual integrated view of the heterogeneous sources. Users access the view using a unified query interface that offers location, model, and interface transparency, i.e., users have the illusion of a single database and do not have to be aware of the location and interface of the sources. Although users and applications might access data directly through wrappers, mediators and metasearchers offer an integrated view of the world, where information related to the same entity has been fused together, redundancies have been eliminated, and inconsistencies have been removed. The architecture of metasearchers and mediators are virtually identical (Figure 1). Wrappers export a common data model view of each source’s data. Wrappers also provide a common query interface. After receiving a query, a wrapper translates it into a source-specific query or command, hence giving interface transparency to the user. Then, the wrapper translates the query results from the underlying source into the common data model or format. To evaluate a user query over multiple heterogeneous databases, both metasearchers and mediators will typically perform three main tasks:",,https://www.semanticscholar.org/paper/89e4353bf86caa32b2a7deb1b2b3d75fc3d34ab9,IEEE Data Engineering Bulletin
314,On Extroverted Complexity Theory,"Complexity theory has come a long way in the thirty years since its inception. It has identiied some of the most fundamental and deep problems related to computation, it has developed a powerful methodology for attacking them, and it is broadly considered as one of the most challenging mathematical frontiers. Considered as a pure mathematical discipline in the pursuit of mathematical insight and depth, complexity is successful and well-established. In this note, however, I would like to concentrate on complexity as an applied mathematical discipline whose function is to gain insights into the problems of the natural, social, and applied and engineering sciences. This aspect has been somewhat peripheral to what we usually mean by \complexity theory,"" but I believe it is important for its future. Understanding the position of complexity theory within the realm of scien-tiic inquiry is an important project which is, of course, well beyond the scope of this note; here I shall only refer anecdotally to six distinct ways in which complexity theory has reached out and touch other elds: Complexity as NP-completeness. One of the major achievements of complexity theory is the living connection it has forged between application problems and modes of resource-bounded computation. This is typically done through the key notion of completeness, of which NP-completeness is of course the most popular kind. Completeness comes so natural to a complexity theorist, that it is easy to forget what an important and innuential concept it has been. In fact, outside theoretical computer science, \complexity theory"" is often understood |unjustly, to be sure| as synonymous to \NP-completeness."" 2 Complexity as mathematical poverty. One of the fundamental theses that seems to be almost universally accepted and practiced in computer science is that algorithms |and eecient algorithms in particular| are the natural outtow of mathematical structure discovered in applications. 3 If we accept this implication , then we must also espouse the contrapositive one, namely, that complexity is the manifestation of mathematical nastiness. Complexity has been often and brilliantly used within computer science and mathematics in this allegorical way; a computational problem is formulated and proved hard for the sole purpose of pointing out the mathematical diiculties involved in an area or approach (see 6] for an early example from database theory). Adapted from the introduction of 8] 2 Among treatments of complexity theory by scientists outside our eld this is one is not the most ignorantly …",,https://www.semanticscholar.org/paper/df75ddcf3504be84f4805b06b9d9542904cf2e76,
2463,Breaking the Barriers to True Augmented Reality,"In recent years, Augmented Reality (AR) and Virtual Reality (VR) have gained considerable commercial traction, with Facebook acquiring Oculus VR for \$2 billion, Magic Leap attracting more than \$500 million of funding, and Microsoft announcing their HoloLens head-worn computer. Where is humanity headed: a brave new dystopia-or a paradise come true? 
In this article, we present discussions, which started at the symposium ""Making Augmented Reality Real"", held at Nara Institute of Science and Technology in August 2014. Ten scientists were invited to this three-day event, which started with a full day of public presentations and panel discussions (video recordings are available at the event web page), followed by two days of roundtable discussions addressing the future of AR and VR.",2015-12-17,https://www.semanticscholar.org/paper/27871230af68b3567193f2417877e0a9bc9f98c6,arXiv.org
2752,Worlds within worlds: metaphors for exploring n-dimensional virtual worlds,"n-Vision is a testbed for exploring n-dimensional worlds containing functions of an arbitrary number of variables. Although our interaction devices and display hardware are inherently 3D, we demonstrate how they can be used to support interaction with these higher-dimensional objects. We introduce a new interaction metaphor developed for the system, which we call “worlds within worlds”: nested heterogeneous coordinate systems that allow the user to view and manipulate functions. Objects in our world may be explored with a set of tools. We describe an example n-Vision application in “financial visualization,” where the functions are models of financial instruments. n-Vision’s software architecture supports a hierarchy of arbitrarily transformed, nested boxes that defines an interactive space within which information is displayed and input obtained. Our design, modeled in part after the hierarchical 2D windows of the X Window System, is intended to provide an environment that is well suited to the use of true 3D input and stereo display devices. Boxes are associated with event handlers that support 3D motion, enter, and leave events, and provide recognition of finger gestures. CR",1990-08-01,https://www.semanticscholar.org/paper/e08c8b4e2d3d2f11ff2302cd4ca9f6fed71e228f,ACM Symposium on User Interface Software and Technology
1895,Management Suggestions for Process Control of Semiconductor Manufacturing: An Operations Research and Data Science Perspective,,2019-09-21,https://www.semanticscholar.org/paper/6bc75b9064dd7f7094d63a3c4f78ee01c90933ac,Computational Intelligence and Optimization Methods for Control Engineering
203,Computation as a Scientific Weltanschauung (Invited Talk),"Computation as a mechanical reality is young - almost exactly seventy years of age - and yet the spirit of computation can be traced several millennia back. Any moderately advanced civilization depends on calculation (for inventory, taxation, navigation, land partition, among many others) - our civilization is the first one that is conscious of this reliance. 
 
Computation has also been central to science for centuries. This is most immediately apparent in the case of mathematics: the idea of the algorithm as a mathematical object of some significance was pioneered by Euclid in the 4th century BC, and advanced by Archimedes a century later. But computation plays an important role in virtually all sciences: natural, life, or social. Implicit algorithmic processes are present in the great objects of scientific inquiry - the cell, the universe, the market, the brain - as well as in the models developed by scientists over the centuries for studying them. This brings about a very recent - merely a few decades old - mode of scientific inquiry, which is sometime referred to as the lens of computation: When students of computation revisit central problems in science from the computational viewpoint, often unexpected progress results. This has happened in statistical physics through the study of phase transitions in terms of the convergence of Markov chain-Monte Carlo algorithms, and in quantum mechanics through quantum computing. 
 
This talk will focus on three other manifestations of this phenomenon. Almost a decade ago, ideas and methodologies from computational complexity revealed a subtle conceptual flaw in the solution concept of Nash equilibrium, which lies at the foundations of modern economic thought. In the study of evolution, a new understanding of century-old questions has been achieved through surprisingly algorithmic ideas. Finally, current work in theoretical neuroscience suggests that the algorithmic point of view may be invaluable in the central scientific question of our era, namely understanding how behavior and cognition emerge from the structure and activity of neurons and synapses.",,https://www.semanticscholar.org/paper/86a4401869d9f929fb59ed4ef51d04a89ef53d4b,Scandinavian Workshop on Algorithm Theory
2802,Galectin-3 binds to CD45 on diffuse large B-cell lymphoma cells to regulate susceptibility to cell death.,"Diffuse large B-cell lymphoma (DLBCL) is the most common non-Hodgkin lymphoma and an aggressive malignancy. Galectin-3 (gal-3), the only antiapoptotic member of the galectin family, is overexpressed in DLBCL. While gal-3 can localize to intracellular sites, gal-3 is secreted by DLBCL cells and binds back to the cell surface in a carbohydrate-dependent manner. The major counterreceptor for gal-3 on DLBCL cells was identified as the transmembrane tyrosine phosphatase CD45. Removal of cell-surface gal-3 from CD45 with the polyvalent glycan inhibitor GCS-100 rendered DLBCL cells susceptible to chemotherapeutic agents. Binding of gal-3 to CD45 modulated tyrosine phosphatase activity; removal of endogenous cell-surface gal-3 from CD45 with GCS-100 increased phosphatase activity, while addition of exogenous gal-3 reduced phosphatase activity. Moreover, the increased susceptibility of DLBCL cells to chemotherapeutic agents after removal of gal-3 by GCS-100 required CD45 phosphatase activity. Gal-3 binding to a subset of highly glycosylated CD45 glycoforms was regulated by the C2GnT-1 glycosyltransferase, indicating that specific glycosylation of CD45 is important for regulation of gal-3-mediated signaling. These data identify a novel role for cell-surface gal-3 and CD45 in DLBCL survival and suggest novel therapeutic targets to sensitize DLBCL cells to death.",2012-11-29,https://www.semanticscholar.org/paper/0399898ac1781ca236655c82513aad81c4356013,Blood
2759,Specifying composite illustrations with communicative goals,"IBIS (Intent-Based Illustration System) generates illustrations automatically, guided by communicative goals. Communicative goals specify that particular properties of objects, such as their color, size, or location are to be conveyed in the illustration. IBIS is intended to be part of an interactive multimedia explanation generation system. It has access to a knowledge base that contains a collection of objects, including information about their geometric properties, material, and location. As the goals are interpreted by a rule-based control component, the system generates a precise definition of the final illustration. If IBIS determines that a set of goals cannot be satisfied in a single picture, then it attempts to create a composite illustration that has multiple viewports. For example, a composite illustration may contain a nested inset illustration showing an object in greater detail than is possible in the parent picture. Each component illustration is defined by its placement, size, viewing specification, lighting specification, and list of objects to be displayed and their graphical style.",1989-11-13,https://www.semanticscholar.org/paper/d972ba590cd8ed600860c7cac308f065701fdcdb,ACM Symposium on User Interface Software and Technology
918,Bounds on the size and transmission rate of communications protocols,,,https://www.semanticscholar.org/paper/f37823b272bbdc55ba2e55b7deb513dbe1f4c2f1,
1174,Measurement of trilinear gauge boson couplings fromevents incollisions at,,2009-09-23,https://www.semanticscholar.org/paper/a82fe56bd7984e999dc944085173102fb769ec13,
1851,Hierarchical Dirichlet Processes,"We consider problems involving groups of data where each observation within a group is a draw from a mixture model and where it is desirable to share mixture components between groups. We assume that the number of mixture components is unknown a priori and is to be inferred from the data. In this setting it is natural to consider sets of Dirichlet processes, one for each group, where the well-known clustering property of the Dirichlet process provides a nonparametric prior for the number of mixture components within each group. Given our desire to tie the mixture models in the various groups, we consider a hierarchical model, specifically one in which the base measure for the child Dirichlet processes is itself distributed according to a Dirichlet process. Such a base measure being discrete, the child Dirichlet processes necessarily share atoms. Thus, as desired, the mixture models in the different groups necessarily share mixture components. We discuss representations of hierarchical Dirichlet processes in terms of a stick-breaking process, and a generalization of the Chinese restaurant process that we refer to as the “Chinese restaurant franchise.” We present Markov chain Monte Carlo algorithms for posterior inference in hierarchical Dirichlet process mixtures and describe applications to problems in information retrieval and text modeling.",2006-12-01,https://www.semanticscholar.org/paper/b90d922ff07d0eb8d77b8687aba7f55bd3926436,
915,The complexity of restricted spanning tree problems,"The complexity of the foUowmg class of problems Is investigated: Given a distance matrix, fred the shortest spanning tree that is isomorphic to a given prototype. Several classical combinatorial problems, both easy and hard, fall into this category for an appropriate choice of the family of prototypes, for example, taking the family to be the set of all paths gives the traveling salesman problem or taking the family to be the set of all 2-stars gives the weighted matching problem It is shown that the complexity of these problems depends explicitly on the rate of growth of a sLmple parameter of the family of prototypes.",1982-04-01,https://www.semanticscholar.org/paper/877e282d16d2f1aa657c8840514df781ee46abc2,JACM
2694,MAGIC: an experimental system for generating multimedia briefings about post-bypass patient status.,"We describe MAGIC, an experimental system for generating multimedia briefings about the clinical status of post-bypass patients entering a cardiac ICU. MAGIC is a distributed system whose components use knowledge-based techniques for planning and generating briefings in text, speech, and graphics. These briefings are coordinated together by reasoning with dynamically generated temporal and spatial constraints. Formative evaluation using system mock-ups with ICU nurses and residents have been used to determine the general format and content of these briefings. We present an overview of MAGIC's architecture and show what it can currently generate.",,https://www.semanticscholar.org/paper/74a43408011fbf9144ebf7dfc68a4b1a1c6024fd,Proceedings : a conference of the American Medical Informatics Association. AMIA Fall Symposium
2972,The Supervised IBP: Neighbourhood Preserving Infinite Latent Feature Models,"We propose a probabilistic model to infer supervised latent variables in the Hamming space from observed data. Our model allows simultaneous inference of the number of binary latent variables, and their values. The latent variables preserve neighbourhood structure of the data in a sense that objects in the same semantic concept have similar latent values, and objects in different concepts have dissimilar latent values. We formulate the supervised infinite latent variable problem based on an intuitive principle of pulling objects together if they are of the same type, and pushing them apart if they are not. We then combine this principle with a flexible Indian Buffet Process prior on the latent variables. We show that the inferred supervised latent variables can be directly used to perform a nearest neighbour search for the purpose of retrieval. We introduce a new application of dynamically extending hash codes, and show how to effectively couple the structure of the hash codes with continuously growing structure of the neighbourhood preserving infinite latent feature space.",2013-08-11,https://www.semanticscholar.org/paper/e4a1b4d5211f05bd1dd0d9fc51cd3f9e639855ab,Conference on Uncertainty in Artificial Intelligence
3408,Max-min Fair Rate Allocation and Routing in Energy Harvesting Networks: Algorithmic Analysis,,2016-06-08,https://www.semanticscholar.org/paper/7035e705130ba4fab8e93941add4d9555415b26d,Algorithmica
1590,Interpreting Mixed Membership Models : Implications of Erosheva ’ s Representation Theorem,,,https://www.semanticscholar.org/paper/15397bbfbf84385a55d7f116cb9fbb68472cd66c,
75,Top-k selection queries over relational databases: Mapping strategies and performance evaluation,"In many applications, users specify target values for certain attributes, without requiring exact matches to these values in return. Instead, the result to such queries is typically a rank of the ""top k"" tuples that best match the given attribute values. In this paper, we study the advantages and limitations of processing a top-k query by translating it into a single range query that a traditional relational database management system (RDBMS) can process efficiently. In particular, we study how to determine a range query to evaluate a top-k query by exploiting the statistics available to an RDBMS, and the impact of the quality of these statistics on the retrieval efficiency of the resulting scheme. We also report the first experimental evaluation of the mapping strategies over a real RDBMS, namely over Microsoft's SQL Server 7.0. The experiments show that our new techniques are robust and significantly more efficient than previously known strategies requiring at least one sequential scan of the data sets.",2002-06-01,https://www.semanticscholar.org/paper/10927ae8a906b482330a95b411285e2e4e407ca6,TODS
1549,Adjusting for Unobserved Confounding Using Large-Scale Propensity Scores,"Even though observational data contain an enormous number of covariates, the existence of unobserved confounders still cannot be excluded and remains a major barrier to drawing causal inference from observational data. A large-scale propensity score (LSPS) approach may adjust for unobserved confounders by including tens of thousands of available covariates that may be correlated with them. In this paper, we present conditions under which LSPS can remove bias due to unobserved confounders. In addition, we show that LSPS may avoid bias that can be induced when adjusting for various unwanted variables (e.g., M-structure colliders). We demonstrate the performance of LSPS on bias reduction using both simulations and real medical data.",,https://www.semanticscholar.org/paper/ba4ea42d99b6ac8d2f76ce62dc9fa5b28795ac1e,
385,Game theory and mathematical economics: a theoretical computer scientist's introduction,"There has been recently increasing interaction between game theory and, more generally, economic theory, with theoretical computer science, mainly in the context of the Internet. The paper is an invitation to this important frontier.",2001-10-14,https://www.semanticscholar.org/paper/6016924e8dfff12fec172480a629e893f3091026,Proceedings IEEE International Conference on Cluster Computing
1003,Glaucoma Severity Correlates with Lamina Cribrosa Depth and Thickness,,2013-06-16,https://www.semanticscholar.org/paper/f0607599e84849a20be228bab35e5d4412bac807,
2390,The cell division cycle : temporal organization and control of cellular growth and reproduction,,,https://www.semanticscholar.org/paper/7c2dbd04e50e483f167e38851a8c55b3de63dc3c,
2308,Preservation of the activity of NADPH oxidase in human monocyte/macrophages.,,1996-08-01,https://www.semanticscholar.org/paper/b91598bca25df98e9131d50c373321ac6f5fa1b2,Biochemical Society Transactions
2027,Implementation of the University-Industry Collaboration at National Tsing Hua University in Taiwan,,,https://www.semanticscholar.org/paper/c13782c8880ebbfdae8f66947e37cf05d8fab1ca,
1345,Measurement of semileptonic branching fractions of B mesons to narrow D** states.,"Using the data accumulated in 2002-2004 with the D0 detector in proton-antiproton collisions at the Fermilab Tevatron collider with a center-of-mass energy of 1.96 TeV, the branching fractions of the decays B --> D0(1)(2420)mu+ vmuX and B --> D2(*0)(2460)mu+ vmuX and their ratio have been measured: B(b --> B) x B(B --> D0(1)mu+ vmuX) x B(D0(*0) --> D*- pi+) = [0.087 +/- 0.007(stat) +/- 0.014(syst)]%; B(b --> B) x B(B --> D2(*0) mu+ vmuX) x B(D2(*0) --> D*- pi+) = [0.035 +/- 0.007(stat) +/- 0.008(syst)]% and [B(B --> D2(*0)mu+ vmuX) x B(D2(*0) --> D*- pi+)]/[B(B --> D0(1)mu+ vmuX) x B(D0(1) --> D*- pi+)] = 0.39 +/- 0.09(stat) +/- 0.12 (syst), where the charge conjugated states are always implied.",2005-07-10,https://www.semanticscholar.org/paper/7954a4e30eda0139630cecf7da2aff734e821197,Physical Review Letters
726,Analysis of Boolean Programs,,2013-03-16,https://www.semanticscholar.org/paper/122a1d55daa1d0f721cd04ab371193b9d596b6ab,International Conference on Tools and Algorithms for Construction and Analysis of Systems
2825,The Promigratory Activity of the Matricellular Protein Galectin-3 Depends on the Activation of PI-3 Kinase,"Expression of galectin-3 is associated with sarcoma progression, invasion and metastasis. Here we determined the role of extracellular galectin-3 on migration of sarcoma cells on laminin-111. Cell lines from methylcholanthrene-induced sarcomas from both wild type and galectin-3−/− mice were established. Despite the presence of similar levels of laminin-binding integrins on the cell surface, galectin-3−/− sarcoma cells were more adherent and less migratory than galectin-3+/+ sarcoma cells on laminin-111. When galectin-3 was transiently expressed in galectin-3−/− sarcoma cells, it inhibited cell adhesion and stimulated the migratory response to laminin in a carbohydrate-dependent manner. Extracellular galectin-3 led to the recruitment of SHP-2 phosphatase to focal adhesion plaques, followed by a decrease in the amount of phosphorylated FAK and phospho-paxillin in the lamellipodia of migrating cells. The promigratory activity of extracellular galectin-3 was inhibitable by wortmannin, implicating the activation of a PI-3 kinase dependent pathway in the galectin-3 triggered disruption of adhesion plaques, leading to sarcoma cell migration on laminin-111.",2011-12-28,https://www.semanticscholar.org/paper/f05410d0e61fa74d7aa5f588c9429098cec9ce74,PLoS ONE
256,Kurt Gödel and the Foundations of Mathematics: Short Biography of Kurt Gödel,,,https://www.semanticscholar.org/paper/aa72aaca98849181ff82328e0791c4be54665518,
2127,An object-oriented analysis and design method for shop floor control systems,"An object-oriented analysis and design method is proposed here for the modelling of shop floor control systems. The major idea is to convert the static structure and the dynamic behaviour of a controlled system into the functional specification of a controlling system by using some modelling techniques. Then the shop floor control logic is translated into the language of the G2 expert system. In this way, it is easier to achieve the computer-integrated manufacturing (CIM) at the shop floor level. The proposed method is different from the procedure-oriented method, which is based on the functional decomposition of a system, and has the potential to be applied to more complex systems. During the modelling process, its modularity and reusability can dramatically reduce the complexity in system analysis and provides more flexibility for system development. The design of the shop floor control system of a mould-filling shop is used to illustrate the proposed method.",1998-01-01,https://www.semanticscholar.org/paper/0e44471231885dbc9df0c806b692bfbc038f8c2f,International journal of computer integrated manufacturing (Print)
3444,"Proceedings of the eighteenth annual ACM-SIAM Symposium on discrete algorithms, SODA'07, New Orleans LA, USA, January 7-9, 2007",,,https://www.semanticscholar.org/paper/cfcbb7d2ff478289f7515e262d39c309e76cfe23,
3415,A Fast Distributed Algorithm for α-Fair Packing Problems,"Over the past two decades, fair resource allocation problems received considerable attention in a variety of application areas. While polynomial time distributed algorithms have been designed for max-min fair resource allocation, the design of distributed algorithms with convergence guarantees for the more general �−fair allocations received little attention. In this paper, we study weighted �-fair packing problems, that is, the problems of maximizing the objective functions P j wjx 1 � j /(1 − �) when � 6 1 and P j wj lnxj when � = 1 over linear constraints Ax ≤ b, x ≥ 0, where wj are positive weights and A and b are non-negative. We consider the distributed computation model that was used for packing linear programs and network utility maximization problems. Under this model, we provide a distributed algorithm for general �. The algorithm uses simple local update rules and is stateless (namely, it allows asynchronous updates, is self-stabilizing, and allows incremental and local adjustments). It converges to approximate solutions in running times that have an inverse polynomial dependence on the approximation parameter "". The convergence time has polylogarithmic dependence on the problem size for � 6 1, and a nearly-linear dependence on the number of variables for � = 1. These are the best convergence times known for these problems.",2015-02-11,https://www.semanticscholar.org/paper/f3efee70865ee39fe2becd82c76eecf1881cbcc7,arXiv.org
1091,Dark matter effective field theory scattering in direct detection experiments,"We examine the consequences of the effective field theory (EFT) of dark matter–nucleon scattering for current and proposed direct detection experiments. Exclusion limits on EFT coupling constants computed using the optimum interval method are presented for SuperCDMS Soudan, CDMS II, and LUX, and the necessity of combining results from multiple experiments in order to determine dark matter parameters is discussed. We demonstrate that spectral differences between the standard dark matter model and a general EFT interaction can produce a bias when calculating exclusion limits and when developing signal models for likelihood and machine learning techniques. We also discuss the implications of the EFT for the next-generation (G2) direct detection experiments and point out regions of complementarity in the EFT parameter space.",2015-03-11,https://www.semanticscholar.org/paper/844c80ff0e502bf86568294418c014c107c6d31f,
1992,Main Branch Decision Tree Algorithm for Yield Enhancement with Class Imbalance,,2012-05-01,https://www.semanticscholar.org/paper/140abecce801310096d2b65afc0c78f554215de1,
3599,Specifying C++ concepts,"C++ templates are key to the design of current successful mainstream libraries and systems. They are the basis of programming techniques in diverse areas ranging from conventional general-purpose programming to software for safety-critical embedded systems. Current work on improving templates focuses on the notion of concepts (a type system for templates), which promises significantly improved error diagnostics and increased expressive power such as concept-based overloading and function template partial specialization. This paper presents C++ templates with an emphasis on problems related to separate compilation. We consider the problem of how to express concepts in a precise way that is simple enough to be usable by ordinary programmers. In doing so, we expose a few weakness of the current specification of the C++ standard library and suggest a far more precise and complete specification. We also present a systematic way of translating our proposed concept definitions, based on use-patterns rather than function signatures, into constraint sets that can serve as convenient basis for concept checking in a compiler.",2006-01-11,https://www.semanticscholar.org/paper/fbf25ee400933d680d9ff3fb7823fd10d2d135f0,ACM-SIGACT Symposium on Principles of Programming Languages
908,Tools for Template Dependencies,"Template dependencies (TD’s) are a class of data dependencies that include multivalued and join dependencies and embedded versions of these. A collection of techniques, examples and results about TD’s are presented. The principal results are: 1) Finite implication (implication over relations with a finite number of tuples) is distinct from unrestricted implication for TD’s. 2) There are, for TD’s over three or more attributes, infinite chains of increasingly weaker and increasingly stronger full TD’s. 3) However, there are weakest (nontrivial) and strongest full TD’s over any given set of attributes. 4) Over two attributes, there are only three distinct TD’s. 5) There is no weakest (not necessarily full) TD over any set of three or more attributes. 6) There is a finite relation that obeys every strictly partial TD but no full TD. 7) The conjunction of each finite set of full TD’s is equivalent to a single full TD. However, the conjunction of a finite set of (not necessarily full) TD’s is not necessarily e...",1983-02-01,https://www.semanticscholar.org/paper/a8610247fe0d4b549394986f2e7f10c2636ebb30,SIAM journal on computing (Print)
3195,Bothersome Flies: How Free-Ranging Horses Reduce Harm While Maintaining Nutrition,"The horses of Shackleford Banks, NC, United States are harassed by many species of biting flies. Apart from being a nuisance, their bites can lead to blood loss and transmit disease. As a result, these horses tend to avoid areas where fly abundances are high. Like other free-ranging horse populations, environmental factors such as low wind speeds and high temperatures increase fly loads per horse. Similarly, coat color matters since darker horses attract more flies than lighter ones, especially on hot sunny days. Many horse populations reduce per capita fly loads by living in large groups or by bunching tightly together. Shackleford horses do so, too, but also use wind speed differences among habitats to modulate fly numbers. By adopting a systematic pattern of moving between habitats such that they only visit a habitat when wind speed is high enough to keep fly harassment to a tolerable level, they can avoid being bitten while continuing to forage. Typically, they begin the day foraging on the salt marshes where fly abundance is inherently low and are lowered further by faint early morning breezes. Later in the morning, horses move to grassy patches (swales) when increasing wind speed reduces fly landings there to levels found on the marshes. Later still, when wind speeds peak, horses begin foraging among the sand dunes. At this point wind speeds are high enough so that horses using any habitat will be minimally harassed by flies, thus enabling them to freely choose where to feed based on which habitat meets particular dietary needs for protein, energy and nutrients on any particular day. Hence, Shackleford horses follow the breeze to solve a challenging dilemma of maintaining a high nutritional plane without succumbing to fly harassment. Other free-ranging horses populations appear to have a more limited “either-or” choice of “bite or be bitten,” thus limiting their decision-making options.",2021-09-24,https://www.semanticscholar.org/paper/968085f2b47ccd8a065a5d6f8e0f211792489863,Frontiers in Ecology and Evolution
3204,"Landscape sustainability science in the drylands: mobility, rangelands and livelihoods",,2020-07-17,https://www.semanticscholar.org/paper/27573bf322281e181cd19f8acfd4602f55f90d83,Landscape Ecology
656,Coronary Gianturco-Roubin stents,,,https://www.semanticscholar.org/paper/5796b024819c1681566f44aebb450e032545c051,
1945,Multistage production distribution under uncertain demands with integrated discrete particle swarm optimization and extended priority-based hybrid genetic algorithm,,2015-01-08,https://www.semanticscholar.org/paper/8128eee3739e1f7abf163c1d5487325892dcd099,Fuzzy Optimization and Decision Making
1794,FINDING LATENT SOURCES IN RECORDED MUSIC WITH A SHIFT-INVARIANT HDP,"We present the Shift-Invariant Hierarchical Dirichlet Process (SIHDP), a nonparametric Bayesian model for modeling multiple songs in terms of a shared vocabulary of latent sound sources. The SIHDP is an extension of the Hierarchical Dirichlet Process (HDP) that explicitly models the times at which each latent component appears in each song. This extension allows us to model how sound sources evolve over time, which is critical to the human ability to recognize and interpret sounds. To make inference on large datasets possible, we develop an exact distributed Gibbs sampling algorithm to do posterior inference. We evaluate the SIHDP’s ability to model audio using a dataset of real popular music, and measure its ability to accurately find patterns in music using a set of synthesized drum loops. Ultimately, our model produces a rich representation of a set of songs consisting of a set of short sound sources and when they appear in each song.",,https://www.semanticscholar.org/paper/0229a79f9d19a99510813ea61351a12efd037744,
1184,Measurement of the Semileptonic Branching Ratio ofto an Orbitally ExcitedState,,2009-02-03,https://www.semanticscholar.org/paper/ca0f10696be4062a9eae60af6abf0dd2ae4b3c2f,
903,On monotone formulae with restricted depth,"We prove a hierarchy theorem for the representation of monotone Boolean functions by monotone formulae with restricted depth. Specifically, we show that there are functions with π<subscrpt>k</subscrpt>-formula of size n for which every &sgr;<subscrpt>k</subscrpt>-formula has size exp ω(n<supscrpt>1/(k−1)</supscrpt>). A similar lower bound applies to concrete functions such as transitive closure and clique. We also show that any function with a formula of size n (and any depth) has a &sgr;<subscrpt>k</subscrpt>-formula of size exp o(n<supscrpt>1/(k−1)</supscrpt>). Thus our hierarchy theorem is the best possible.",1984-12-01,https://www.semanticscholar.org/paper/cbb6dd042a1eee8fcc608354fa5e86a1384b4af2,Symposium on the Theory of Computing
1879,Adaptive parametric yield enhancement via collinear multivariate analytics for semiconductor intelligent manufacturing,,2021-04-01,https://www.semanticscholar.org/paper/66245084511f29e39aba1c7e5533e80108016b11,Applied Soft Computing
1929,Semiconductor manufacturing intelligence and automation,,2016-09-01,https://www.semanticscholar.org/paper/04712c50c37817fa2f3443365d564c768d306693,Computers & industrial engineering
1796,Markov Topic Models,"We develop Markov topic models (MTMs), a novel family of generative probabilistic models that can learn topics simultaneously from multiple corpora, such as papers from different conferences. We apply Gaussian (Markov) random fields to model the correlations of different corpora. MTMs capture both the internal topic structure within each corpus and the relationships between topics across the corpora. We derive an efficient estimation procedure with variational expectation-maximization. We study the performance of our models on a corpus of abstracts from six different computer science conferences. Our analysis reveals qualitative discoveries that are not possible with traditional topic models, and improved quantitative performance over the state of the art.",2009-04-15,https://www.semanticscholar.org/paper/1e7d12d0782b700af534ad56f888903d6d80431b,International Conference on Artificial Intelligence and Statistics
2986,Modelling skin/ageing phenotypes with latent variable models in Infer.NET,"We demonstrate and compare three unsupervised Bayesian latent variable models implemented in Infer.NET [1] for biomedical data modeling of 42 skin and ageing phenotypes measured on the 12,000 female twins in the Twins UK study [2].",,https://www.semanticscholar.org/paper/2c67026fab87c7e9ee8b3cd3ec1ebd484d0c968c,
2408,The cytochromes of Acanthamoeba castellanii.,"1. Low-temperature difference spectra of gradient-purified mitochondria of Acanthamoeba castellanii reveal the presence of cytochromes b-555, b-562 and c-549, with a-type cytochromes having a broad asymmetrical maximum at 602 nm; these components were also observed in specta of whole cells. 2. The a-type cytochromes are unusual in that they have split Soret absorption maxima (at 442 and 449 nm) and an uncharacteristic CO difference spectrum. 3. CO difference spectra of whole cells and 'microsomal' membranes show large amounts of cytochrome P-420 compared with cytochrome P-450. 4. Difference spectra in the presence of cyanide indicate the presence of an a-type cytochrome and two cyanide-reacting components, one of which may be cytochrome a3. 5. Whole-cell respiration in a N2/O2 (19:1) atmosphere was decreased by 50%, suggesting the presence of a low-affinity oxidase. This lowered respiration is inhibited by 50% by CO, and the inhibition is partially light-reversible; photochemical action spectra suggest that cytochrome a3 contributes to this release of inhibition. Other CO-reacting oxidases are also present. 6. The results are discussed with the view that cytochrome a3 is present in A. castellanii, but its identification in CO difference spectra is obscured by other component(s).",1977-10-15,https://www.semanticscholar.org/paper/6bd6c4026b438168bce807fb8f74e8f348f5be17,Biochemical Journal
1995,A cut-to-order strategy for one-dimensional cable cutting and a case study,"Low-entry barrier for accessing the cable market leads to the intensive competition among hundreds of homogeneous cable manufacturers in China. Mass customization is an effective way to differentiate companies in a highly competitive market. Focused on the real needs of a leading cable manufacturer in China for operating a new e-business to sell customized cables, this study aims to propose a cut-to-order strategy that enables customized cables by utilizing risk pooling effects for customer satisfaction and green manufacturing. A two-stage approach was developed to implement the cut-to-order strategy, in which the inventory replenishment decision and cutting operations are determined, respectively. A case study was conducted to estimate the validity of the proposed approach and the results have shown its practical viability.",2012-11-23,https://www.semanticscholar.org/paper/1c241857c07c25d2c45e2af6aa8e5af5e45c4e40,
862,Testing Finite State Machines (Extended Abstract),,,https://www.semanticscholar.org/paper/6f964cb3a1e03ebcd79b9805a11ba542f8f8f2cb,Symposium on the Theory of Computing
3224,Mutualistic acacia ants exhibit reduced aggression and more frequent off‐tree movements near termite mounds,"In many ant–plant mutualisms, ants establish colonies in hollow thorns, leaf pouches, or other specialized structures on their host plants, which they then defend from herbivores. Resource heterogeneity could affect the maintenance of these mutualisms if it leads to one or both partners altering their investment in the interaction. Such a phenomenon may be especially pertinent to the Acacia–ant mutualism found in East African savannas, where termite mounds have a profound effect on the spatial structuring of resources used by both plants and ants. Here, we examined whether the proximity to termite mounds of Acacia drepanolobium trees is associated with variation in the behavior of one of their ant associates, Crematogaster nigriceps. We found that ant colonies near termite mounds had decreased aggressive responses to simulated herbivory as well as increased off‐tree movement. We hypothesize that these changes are the result of resident ant colonies near termite mounds shifting investment from defense of their host plant to foraging for nearby resources.",2018-06-13,https://www.semanticscholar.org/paper/43ace10ea9281ee469e62aa0ddc37fa28187ee6c,Biotropica
1591,Matrix Factorization,,,https://www.semanticscholar.org/paper/188933428ec7e2776c6e83407a5a4768c4a0ef62,Encyclopedia of Social Network Analysis and Mining. 2nd Ed.
241,Learning and verifying quantified boolean queries by example,"To help a user specify and verify quantified queries --- a class of database queries known to be very challenging for all but the most expert users --- one can question the user on whether certain data objects are answers or non-answers to her intended query. In this paper, we analyze the number of questions needed to learn or verify qhorn queries, a special class of Boolean quantified queries whose underlying form is conjunctions of quantified Horn expressions. We provide optimal polynomial-question and polynomial-time learning and verification algorithms for two subclasses of the class qhorn with upper constant limits on a query's causal density.",2013-04-15,https://www.semanticscholar.org/paper/fc0f0316cedd8a456a11e2537455b401afa1824f,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
2279,Bile acids inhibit Mcl-1 protein turnover via an epidermal growth factor receptor/Raf-1-dependent mechanism.,"Bile acids have been implicated in biliary tract carcinogenesis, in part, by activating the epidermal growth factor receptor (EGFR). Overexpression of Mcl-1, a potent antiapoptotic protein of the Bcl-2 family, has also been reported in cholangiocarcinomas. Because receptor tyrosine kinases like EGFR may modulate antiapoptotic protein expression, we examined the hypothesis that bile acids modulate Mcl-1 expression levels via EGFR. Deoxycholate increased cellular Mcl-1 protein in a concentration-dependent manner. The deoxycholate-mediated increase of cellular Mcl-1 protein was blocked equally by EGFR tyrosine kinase inhibitors or an EGFR-neutralizing antibody. Although inhibition of mitogen-activated protein kinases did not attenuate the deoxycholate-associated increase in Mcl-1 protein, the Raf-1 inhibitor, BAY 37-9751, effectively blocked the cellular increase of this protein. Neither Mcl-1 transcriptional activity nor its mRNA stability was altered by deoxycholate treatment. However, Mcl-1 protein stability was increased by bile acid treatment, an effect duplicated by proteasome inhibition. Deoxycholate prolongation of Mcl-1 turnover was blocked by either EGFR inhibitors or the Raf-1 inhibitor. Whereas the deoxycholate-induced increase in Mcl-1 reduced Fas-mediated apoptosis, the Raf-1 inhibitor potentiated Fas apoptosis. Our results demonstrate that bile acids block Mcl-1 protein degradation via activation of an EGFR/Raf-1 cascade resulting in its cellular accumulation. Raf-1 inhibitors block this increase of Mcl-1 and render the cells more susceptible to apoptosis, a potential therapeutic strategy for cholangiocarcinomas.",2002-11-15,https://www.semanticscholar.org/paper/6f4fcaed2a15555d952a43ee20586be2f095f7d7,Cancer Research
3492,Approximating Disjoint-Path Problems Using Greedy Algorithms and Packing Integer Programs ( Extended Abstract ),"The edge and vertex-disjoint path problems together with their unsplittable flow generalization are NP-hard problems with a multitude of applications in areas such as routing, scheduling and bin packing. Given the hardness of the problems, we study polynomial-time approximation algorithms with bounded performance guarantees. We introduce techniques which yield new algorithms for a wide range of disjoint-path problems. We use two basic techniques. First, we propose simple greedy algorithms for edgeand vertex-disjoint paths and second, we propose the use of a framework based on packing integer programs for more general problems such as unsplittable flow. As part of our tools we develop improved approximation algorithms for a class of packing integer programs, a result that we believe is of independent interest.",,https://www.semanticscholar.org/paper/eaa052f74fdf4da85d8459ee263fc5c1dd23bcbf,
2039,紫式決策分析以建構液晶原料廠製程確效評估模式; UNISON Decision Analysis Framework for Constructing the Process Validation Model for Liquid Crystal Manufacturing Plant,,,https://www.semanticscholar.org/paper/2676c0269ea6f2a2cd63af351c11e64592fd9700,
2426,A Hybrid RTK GNSS and SLAM Outdoor Augmented Reality System,"In the real world, we are surrounded by potentially important data. For example, military personnel and first responders may need to understand the layout of an environment, including the locations of designated assets, specified in latitude and longitude. However, many augmented reality (AR) systems cannot associate absolute geographic coordinates with the coordinate system in which they track. We describe a simple approach for developing a wide-area outdoor wearable AR system that uses RTK GNSS position tracking to align together and georegister multiple smaller maps from an existing SLAM tracking system.",2019-03-23,https://www.semanticscholar.org/paper/220ecaea8bf2d6102530cb4acc4cfc0fb79b75b3,IEEE Conference on Virtual Reality and 3D User Interfaces
979,Change of β-Zone Parapapillary Atrophy During Axial Elongation: Boramae Myopia Cohort Study Report 3.,"Purpose
To investigate changes of β-zone parapapillary atrophy (PPA) during axial elongation.


Methods
Change of β-zone PPA was evaluated by spectral-domain optical coherence tomography (SD-OCT) in myopic children for 2 years, prospectively. Using the infrared images acquired by a fixed scan circle in the glaucoma progression analysis (GPA) mode, the retinal pigment epithelial opening (RPEO) and the clinical disc margin (CDM) were manually delineated. The area and position of β-zone PPA was calculated as the differences from those of the RPEO and CDM, respectively. The β-zone PPA was further differentiated into βBM PPA (β-zone PPA with Bruch's membrane [BM]) and γ-zone PPA (β-zone PPA without BM). The change of β-zone PPA was compared between the first and final visits.


Results
The area of β-zone PPA increased in 35 eyes (76%). This increase was associated with RPEO area increase and CDM area decrease. The center of β-zone PPA moved along the direction of vascular trunk dragging, but to a lesser extent. The β-zone PPA enlargement was correlated with the extent of vascular trunk dragging (P = 0.014). In all eyes with β-zone PPA increase, the γ-zone portion had increased. Even in childhood, βBM PPA existed next to their γ-zone PPA in 11 eyes (24%), including 4 eyes that showed increase of both γ-zone and βBM portion during axial elongation.


Conclusions
Enlargement of β-zone PPA during axial elongation was affected by the extent and direction of vascular trunk dragging, thus implicating disproportionate growth between the retina and sclera.",2018-08-01,https://www.semanticscholar.org/paper/56a294c9c98c559eec46ced7460dc4ee0b998487,Investigative Ophthalmology and Visual Science
1177,Determination of the strong coupling constant from the inclusive jet cross section in pp collisions at Vs = 1.96 TeV,"We determine the strong coupling constant α s and its energy dependence from the p T dependence of the inclusive jet cross section in pp collisions at Vs = 1.96 TeV. The strong coupling constant is determined over the transverse momentum range 50 < p T < 145 GeV. Using perturbative QCD calculations to order O(α 3 s ) combined with O(α 4 s ) contributions from threshold corrections, we obtain α s (M Z ) = 0,1161 +0.0041 ―0.0048 . This is the most precise result obtained at a hadron-hadron collider.",,https://www.semanticscholar.org/paper/b6df53a752f4b5ecee8e21079348a5eb195688d1,
444,The complexity of knowledge representation,Representing knowledge in forms appropriate for rapid common-sense reasoning is a challenging current problem in artificial intelligence. We review certain recent results which suggest that complexity theory has an important role to play in this field.,1996-05-24,https://www.semanticscholar.org/paper/0bbbed32a18458ad9a973ca18447f194ad618d0e,Proceedings of Computational Complexity (Formerly Structure in Complexity Theory)
1637,Stochastic Gradient Descent as Approximate Bayesian Inference,"Stochastic Gradient Descent with a constant learning rate (constant SGD) simulates a Markov chain with a stationary distribution. With this perspective, we derive several new results. (1) We show that constant SGD can be used as an approximate Bayesian posterior inference algorithm. Specifically, we show how to adjust the tuning parameters of constant SGD to best match the stationary distribution to a posterior, minimizing the Kullback-Leibler divergence between these two distributions. (2) We demonstrate that constant SGD gives rise to a new variational EM algorithm that optimizes hyperparameters in complex probabilistic models. (3) We also propose SGD with momentum for sampling and show how to adjust the damping coefficient accordingly. (4) We analyze MCMC algorithms. For Langevin Dynamics and Stochastic Gradient Fisher Scoring, we quantify the approximation errors due to finite learning rates. Finally (5), we use the stochastic process perspective to give a short proof of why Polyak averaging is optimal. Based on this idea, we propose a scalable approximate MCMC algorithm, the Averaged Stochastic Gradient Sampler.",2017-04-13,https://www.semanticscholar.org/paper/ea68a5c75e0e228e54efd91db972f71c1a917e51,Journal of machine learning research
2550,Developing an augmented reality racing game,"Augmented reality (AR) makes it possible to create games in which virtual objects are overlaid on the real world, and real objects are tracked and used to control virtual ones. We describe the development of an AR racing game created by modifying an existing racing game, using an AR infrastructure that we developed for use with the XNA game development platform. In our game, the driver wears a tracked video see-through head-worn display, and controls the car with a passive tangible controller. Other players can participate by manipulating waypoints that the car must pass and obstacles with which the car can collide. We discuss our AR infrastructure, which supports the creation of AR applications and games in a managed code environment, the user interface we developed for the AR racing game, the game's software and hardware architecture, and feedback and observations from early demonstrations.",2008-01-08,https://www.semanticscholar.org/paper/ee27785c0e7f1ddacee7edd8bd47abbda0347403,Intelligent Technologies for Interactive Entertainment
2924,A human lung tumor microenvironment interactome identifies clinically relevant cell-type cross-talk,,2020-05-07,https://www.semanticscholar.org/paper/08f398d38914d7a261f764db287957f3923380c7,Genome Biology
3701,Visual Classification via Description from Large Language Models,"Vision-language models (VLMs) such as CLIP have shown promising performance on a variety of recognition tasks using the standard zero-shot classification procedure -- computing similarity between the query image and the embedded words for each category. By only using the category name, they neglect to make use of the rich context of additional information that language affords. The procedure gives no intermediate understanding of why a category is chosen, and furthermore provides no mechanism for adjusting the criteria used towards this decision. We present an alternative framework for classification with VLMs, which we call classification by description. We ask VLMs to check for descriptive features rather than broad categories: to find a tiger, look for its stripes; its claws; and more. By basing decisions on these descriptors, we can provide additional cues that encourage using the features we want to be used. In the process, we can get a clear idea of what features the model uses to construct its decision; it gains some level of inherent explainability. We query large language models (e.g., GPT-3) for these descriptors to obtain them in a scalable way. Extensive experiments show our framework has numerous advantages past interpretability. We show improvements in accuracy on ImageNet across distribution shifts; demonstrate the ability to adapt VLMs to recognize concepts unseen during training; and illustrate how descriptors can be edited to effectively mitigate bias compared to the baseline.",2022-10-13,https://www.semanticscholar.org/paper/a42b091adaf29b06a092b67192ac07cb93312f2a,International Conference on Learning Representations
2856,JNK Expression Impaired Mediator Release and Defective Galectin-3-Deficient Mast Cells Exhibit Role of Galectin-3 in Mast Cell Functions :,,,https://www.semanticscholar.org/paper/392b1e4a9ba27a51eb43ed7f1e12f54037e136c7,
166,31 : 2 Wealth Inequality and the Price of Anarchy,"The price of anarchy quantifies the degradation of social welfare in games due to the lack of a centralized authority that can enforce the optimal outcome. It is known that, in certain games, such effects can be ameliorated via tolls or taxes. This leads to a natural, but largely unexplored, question: what is the effect of such transfers on social inequality? We study this question in nonatomic congestion games, arguably one of the most thoroughly studied settings from the perspective of the price of anarchy. We introduce a new model that incorporates the income distribution of the population and captures the income elasticity of travel time (i.e., how does loss of time translate to lost income). This allows us to argue about the equality of wealth distribution both before and after employing a mechanism. We establish that, under reasonable assumptions, tolls always increase inequality in symmetric congestion games under any reasonable metric of inequality such as the Gini index. We introduce the inequity index, a novel measure for quantifying the magnitude of these forces towards a more unbalanced wealth distribution and show it has good normative properties (robustness to scaling of income, no-regret learning). We analyze inequity both in theoretical settings (Pigou’s network under various wealth distributions) as well as experimental ones (based on a large scale field experiment in Singapore). Finally, we provide an algorithm for computing optimal tolls for any point of the trade-off of relative importance of efficiency and equality. We conclude with a discussion of our findings in the context of theories of justice as developed in contemporary social sciences and present several directions for future research. 2012 ACM Subject Classification Theory of computation → Algorithmic game theory",,https://www.semanticscholar.org/paper/05ab6e27ebde49f4c932de6c0a9b4ff6737b8710,
2853,Galectin 3 is required for MLD-STZ induced diabetes in mice (130.38),"
 Galectin-3, member of ancient lectin family characterized by specific binding of β galactosides, has an antiapoptotic function in T cells, macrophages and islet cells. It was therefore of interest to evaluate the susceptibility to multiple low dose induced diabetes (MLD-STZ) in galectin (gal-3) deficient C57BL/6 mice. Gal-3 −/− and gal-3+/+ mice were treated with 5 daily injections of 40 mg/kg STZ and diabetes development evaluated by glycemia and immunohistochemistry of the pancreas. Gal-3+/+ mice developed delayed sustained and progressive hyperglucemia and mononuclear cell infiltrates in the islets. Gal-3 −/− demonstrated only mild glycemia with minimal islet pathology as evaluated by the number of infiltrating cells and insulin content. There was higher number of apoptotic cells in the islets of galectin-3 knock out than in the control gal-3+/+ mice. RT PCR analysis of pancreatic lymph node cells 17 days after diabetes induction revealed the presence of IL-23 and IL-17 in gal-3+/+ but not in Gal-3 −/− mice. TNF-α and INF-γ INOS expression was also attenuated in Gal-3 −/− mice. We concluded that antiapoptotic effect of gal-3 in diabetogenic cells favors the induction of disease. The data are also compatible with our previous finding that IL-23-Th17 axis plays a role in diabetogenesis (Eur J Immunol, 36: 216–23, 2006).
 (Supported by Sheikh Hamdan Awards for Medical Research).",2007-04-01,https://www.semanticscholar.org/paper/bc92a3b420613ddb24681755e36bf754eb9b3318,Journal of Immunology
1389,$t \bar{t}$ production cross-section in $p \bar{p}$ collisions at $\sqrt{s}$ = 1.8-TeV,"Results are presented on a measurement of the t (t) over bar pair production cross section in p (p) over bar collisions at roots=1.8 TeV from nine independent decay channels. The data were collected by the D empty set experiment during the 1992-1996 run of the Fermilab Tevatron Collider. A total of 80 candidate events is observed with an expected background of 38.8+/-3.3 events. For a top quark mass of 172.1 GeV/c(2), the measured cross section is 5.69+/-1.21(stat)+/-1.04(syst) pb.",2003-01-15,https://www.semanticscholar.org/paper/b24835ecead66979c69ba2721a0756e9324f7f7b,
3673,Communication and control in distributed computer systems,,,https://www.semanticscholar.org/paper/b2627a73887234f93c687775cf70c995cb70c1ae,
1797,Variational Inference for the Nested Chinese Restaurant Process,"The nested Chinese restaurant process (nCRP) is a powerful nonparametric Bayesian model for learning tree-based hierarchies from data. Since its posterior distribution is intractable, current inference methods have all relied on MCMC sampling. In this paper, we develop an alternative inference technique based on variational methods. To employ variational methods, we derive a tree-based stick-breaking construction of the nCRP mixture model, and a novel variational algorithm that efficiently explores a posterior over a large set of combinatorial structures. We demonstrate the use of this approach for text and hand written digits modeling, where we show we can adapt the nCRP to continuous data as well.",2009-12-07,https://www.semanticscholar.org/paper/2f14e3b459dc78868851c372ae00a74519c3e1f4,Neural Information Processing Systems
2921,An integrated approach to identify environmental modulators of genetic risk factors for complex traits,"Complex traits and diseases can be influenced by both genetics and environment. However, given the large number of environmental stimuli and power challenges for gene-by-environment testing, it remains a critical challenge to identify and prioritize specific disease-relevant environmental exposures. We propose a novel framework for leveraging signals from transcriptional responses to environmental perturbations to identify disease-relevant perturbations that can modulate genetic risk for complex traits and inform the functions of genetic variants associated with complex traits. We perturbed human skeletal muscle, fat, and liver relevant cell lines with 21 perturbations affecting insulin resistance, glucose homeostasis, and metabolic regulation in humans and identified thousands of environmentally responsive genes. By combining these data with GWAS from 31 distinct polygenic traits, we show that heritability of multiple traits is enriched in regions surrounding genes responsive to specific perturbations and, further, that environmentally responsive genes are enriched for associations with specific diseases and phenotypes from the GWAS catalogue. Overall, we demonstrate the advantages of large-scale characterization of transcriptional changes in diversely stimulated and pathologically relevant cells to identify disease-relevant perturbations.",2021-02-25,https://www.semanticscholar.org/paper/f1152db12ffdfc80d33070e8fa86dce089a0f864,bioRxiv
2355,Stimulation of protein synthesis in human neutrophils by γ-interferon,,1989-04-15,https://www.semanticscholar.org/paper/5698324dd3c5c793e3bbb38e90c519616a8da935,
1809,Hierarchical relational models for document networks,"We develop the relational topic model (RTM), a hierarchical model of both network structure and node attributes. We focus on document networks, where the attributes of each document are its words, that is, discrete observations taken from a fixed vocabulary. For each pair of documents, the RTM models their link as a binary random variable that is conditioned on their contents. The model can be used to summarize a network of documents, predict links between them, and predict words within them. We derive efficient inference and estimation algorithms based on variational methods that take advantage of sparsity and scale with the number of links. We evaluate the predictive performance of the RTM for large networks of scientific abstracts, web documents, and geographically tagged news.",2009-09-23,https://www.semanticscholar.org/paper/a23f77cb550362995409646d3ff65d769009ef3a,
565,A note the expressive power of Prolog,,,https://www.semanticscholar.org/paper/e4faadf6a6b0523482c1bfff53c4c5cfd1f8225f,Bull. EATCS
59,Selectivity estimation for string predicates: overcoming the underestimation problem,"Queries with (equality or LIKE) selection predicates over string attributes are widely used in relational databases. However, state-of-the-art techniques for estimating selectivities of string predicates are often biased towards severely underestimating selectivities. We develop accurate selectivity estimators for string predicates that adapt to data and query characteristics, and which can exploit and build on a variety of existing estimators. A thorough experimental evaluation over real data sets demonstrates the resilience of our estimators to variations in both data and query characteristics.",2004-03-30,https://www.semanticscholar.org/paper/5b777468a9e4dceef957872dfc033e790e352dab,Proceedings / International Conference on Data Engineering
2100,Machine grouping algorithm for stepper back-up and an empirical study,"Considering the limitations of the operation cost and the flexibility need of the manufacturing, the wafer was unable to expose in the same stepper from layer to layer in the real setting. In addition, the lithographic systems also require appreciate back-ups to avoid the yield loss as the equipment fault or shut-down for maintenance. This study aims to develop a machine group algorithm for the stepper and thus propose appropriate back-up based on the similarity of systematic overlay errors and residuals. The results are confirmed with judgments of domain experts and thus validated this approach",2004-09-09,https://www.semanticscholar.org/paper/f3152d7920f1fe938648f5fd1961c5467dedcfc8,2004 Semiconductor Manufacturing Technology Workshop Proceedings (IEEE Cat. No.04EX846)
3766,Where are they looking?,"Humans have the remarkable ability to follow the gaze of other people to identify what they are looking at. Following eye gaze, or gaze-following, is an important ability that allows us to understand what other people are thinking, the actions they are performing, and even predict what they might do next. Despite the importance of this topic, this problem has only been studied in limited scenarios within the computer vision community. In this paper, we propose a deep neural network-based approach for gaze-following and a new benchmark dataset, GazeFollow, for thorough evaluation. Given an image and the location of a head, our approach follows the gaze of the person and identifies the object being looked at. Our deep network is able to discover how to extract head pose and gaze orientation, and to select objects in the scene that are in the predicted line of sight and likely to be looked at (such as televisions, balls and food). The quantitative evaluation shows that our approach produces reliable results, even when viewing only the back of the head. While our method outperforms several baseline approaches, we are still far from reaching human performance on this task. Overall, we believe that gaze-following is a challenging and important problem that deserves more attention from the community.",2015-12-07,https://www.semanticscholar.org/paper/7294d3ac0001e4b36c67aeb5c31d1db8ba1da23a,Neural Information Processing Systems
2032,Designing Performance Indices and a Novel Mechanism for Evaluating Government R&D Projects,"Due to increasingly strained governmental resources, effective management and efficient utilization of government funds for R&D projects has become a critical issue. This study aimed to design performance indices and the associated mechanism to assist the National Science Council (NSC) of Taiwan in evaluating the performance of government funded R&D projects to enhance the decision quality for government R&D funding. In particular, a hierarchy of performance indices was developed that can be employed for different types of R&D projects with the corresponding weighting. Then, a novel mechanism with systematic procedures was designed to undertake the evaluation before, during, and after the project execution for feed forward and feedback control of government funded R&D projects. Therefore, the collected performance data can be analyzed for effective project management and rational resource allocation decisions. This study concludes with discussions of future studies.",2009-04-01,https://www.semanticscholar.org/paper/55cb5dc6a19ed10dddc5ea216fa65aa57805ef82,
1752,Surveying a suite of algorithms that offer a solution to managing large document archives.,,,https://www.semanticscholar.org/paper/8b9b56af372e4fa50ee616ddf200254ddd315cb7,
989,Assessment of glaucoma progression by Cirrus optical coherence tomography-guided progression analysis,,2016-09-26,https://www.semanticscholar.org/paper/4277f6e0c8e59b34391f89e68e60c828f39b57b9,
3686,What You Can Reconstruct from a Shadow,"3D reconstruction is a fundamental problem in computer vision, and the task is especially challenging when the object to reconstruct is partially or fully occluded. We introduce a method that uses the shadows cast by an unobserved object in order to infer the possible 3D volumes under occlusion. We create a differentiable image formation model that allows us to jointly infer the 3D shape of an object, its pose, and the position of a light source. Since the approach is end-to-end differentiable, we are able to integrate learned priors of object geometry in order to generate realistic 3D shapes of different object categories. Experiments and visualizations show that the method is able to generate multiple possible solutions that are consistent with the observation of the shadow. Our approach works even when the position of the light source and object pose are both unknown. Our approach is also robust to real-world images where ground-truth shadow mask is unknown.",2023-06-01,https://www.semanticscholar.org/paper/7f368c2255a3dbd1356c21af574f493b8e90174a,Computer Vision and Pattern Recognition
2387,The mitochondrial adenosine triphosphatase of Acanthamoeba castellanii. Partial characterization and changes in activity during exponential growth.,,,https://www.semanticscholar.org/paper/66d03c3b665332a0befc03bd3d8b4ed7e9254bf0,"Comparative biochemistry and physiology. B, Comparative biochemistry"
547,The Complexity of the Travelling Repairman Problem,"Le probleme du reparateur itinerant consiste en la donnee d'un ensemble fini de points, et des temps de parcours entre ces points. Le but est de trouver une trajectoire qui passe par tous ces points et qui minimise la duree totale du trajet. On etudie ce probleme dans le cas ou tous les points sont alignes, et on presente une solution polynomiale. Si le retard maximum pour chaque point est borne, le probleme devient NP-complet, mais il peut etre resolu avec un algorithme pseudo-polynome",,https://www.semanticscholar.org/paper/373db0e4aef0c59c634be8ec835262d0a449b607,RAIRO - Theoretical Informatics and Applications
152,On the complexity of dynamic mechanism design,,2022-03-01,https://www.semanticscholar.org/paper/93022f2ecb0c64dd2b27a095d1d10c5a1f0ff143,Games Econ. Behav.
199,Variable Binding through Assemblies in Spiking Neural Networks,"We propose a model for the binding of variables to concrete fillers in the human brain. The model is based on recent experimental data about corresponding neural processes in humans. First, electrode recordings from the human brain suggest that concepts are represented in the medial temporal lobe (MTL) through sparse sets of neurons (assemblies). Second, fMRI recordings from the human brain suggest that specific subregions of the temporal cortex are dedicated to the representation of specific roles (e.g., subject or object) of concepts in a sentence or visually presented episode. We propose that quickly recruited assemblies of neurons in these subregions act as pointers to previously created assemblies that represent concepts. As a proof of principle, we performed computer simulations of a spiking neural network model that implemented the proposed paradigm for binding through assembly pointers. We show that the model supports basic operations of brain computations, such as structured recall and copying of information.",,https://www.semanticscholar.org/paper/64455bc7b86c1f4dff304f61c6aff3133a9c84ad,CoCo@NIPS
1106,Search for low-mass weakly interacting massive particles using voltage-assisted calorimetric ionization detection in the SuperCDMS experiment.,"SuperCDMS is an experiment designed to directly detect weakly interacting massive particles (WIMPs), a favored candidate for dark matter ubiquitous in the Universe. In this Letter, we present WIMP-search results using a calorimetric technique we call CDMSlite, which relies on voltage-assisted Luke-Neganov amplification of the ionization energy deposited by particle interactions. The data were collected with a single 0.6 kg germanium detector running for ten live days at the Soudan Underground Laboratory. A low energy threshold of 170  eVee (electron equivalent) was obtained, which allows us to constrain new WIMP-nucleon spin-independent parameter space for WIMP masses below 6  GeV/c2.",2013-09-12,https://www.semanticscholar.org/paper/86852325718f22c201b0f867a86f5da8572eb8d6,Physical Review Letters
757,On the Complexity of Nash Equilibria and Other Fixed Points (Extended Abstract),"We reexamine, what it means to compute Nash equilibria and, more, generally, what it means to compute a fixed point of a given Brouwer function, and we investigate the complexity of the associated problems. Specifically, we study the complexity of the following problem: given a finite game, Gamma, with 3 or more players, and given epsiv > 0, compute a vector x' (a mixed strategy profile) that is within distance e (say in t^) of some (exact) Nash equilibrium. We show that approximation of an (actual) Nash equilibrium for games with 3 players, even to within any non-trivial constant additive factor epsiv < 1/2 in just one desired coordinate, is at least as hard as the long standing square-root sum problem, as well as more general arithmetic circuit decision problems, and thus that even placing the approximation problem in NP would-resolve a major open problem in the complexity of numerical computation. Furthermore, we show that the (exact or approximate) computation of Nash equilibria for 3 or more players is complete for the class of search problems, which we call FIXP, that can be cast as fixed point computation problems for functions represented by algebraic circuits (straight line programs) over basis {+, *, -, /, max, min}, with rational constants. We show that the linear fragment of FIXP equals PPAD. Many problems in game theory, economics, and probability theory, can be cast as fixed point problems for such algebraic functions. We discuss several important such problems: computing the value of Shapley's stochastic games, and the simpler games of Condon, extinction probabilities of branching processes, termination probabilities of stochastic context-free grammars, and of Recursive Markov Chains. We show that for some of them, the approximation, or even exact computation, problem can be placed-in PPAD, while for others, they are at least as hard as the square-root sum and arithmetic circuit decision problems.",2007-10-21,https://www.semanticscholar.org/paper/38e35793b0a3de5bb8e72489c66375557e3325d4,IEEE Annual Symposium on Foundations of Computer Science
1972,"User-experience of tablet operating system: An experimental investigation of Windows 8, iOS 6, and Android 4.2",,2014-07-01,https://www.semanticscholar.org/paper/f8451d64eeb352e099a60fae126e84e7fbe813d6,Computers & industrial engineering
1696,Statistical Models,,,https://www.semanticscholar.org/paper/33ad5a55670f346716e974221f03330dac6f6c9f,Encyclopedia of Social Network Analysis and Mining
2087,Factor Analysis in Data Mining,"The rapid growth and advances of information technology enable data to be accumulated faster and in much larger quantities (i.e., data warehousing). Faced with vast new information resources, scientists, engineers, and business people need efficient analytical techniques to extract useful information and effectively uncover new, valuable knowledge patterns. Data preparation is the beginning activity of exploring for potentially useful information. However, there may be redundant dimensions (i.e., variables) in the data, even after the data are well prepared. In this case, the performance of data-mining methods will be affected negatively by this redundancy. Factor Analysis (FA) is known to be a commonly used method, among others, to reduce data dimensions to a small number of substantial characteristics. FA is a statistical technique used to find an underlying structure in a set of measured variables. FA proceeds with finding new independent variables (factors) that describe the patterns of relationships among original dependent variables. With FA, a data miner can determine whether or not some variables should be grouped as a distinguishing factor, based on how these variables are related. Thus, the number of factors will be smaller than the number of original variables in the data, enhancing the performance of the data-mining task. In addition, the factors may be able to reveal underlying attributes that cannot be observed or interpreted explicitly so that, in effect, a reconstructed version of the data is created and used to make hypothesized conclusions. In general, FA is used with many data-mining methods (e.g., neural network, clustering). BACKGROUND",,https://www.semanticscholar.org/paper/6c652d02afcafa45d3818f32231f79c2dd764e6f,
60,When one sample is not enough: improving text database selection using shrinkage,"Database selection is an important step when searching over large numbers of distributed text databases. The database selection task relies on statistical summaries of the database contents, which are not typically exported by databases. Previous research has developed algorithms for constructing an approximate content summary of a text database from a small document sample extracted via querying. Unfortunately, Zipf's law practically guarantees that content summaries built this way for any relatively large database will fail to cover many low-frequency words. Incomplete content summaries might negatively affect the database selection process, especially for short queries with infrequent words. To improve the coverage of approximate content summaries, we build on the observation that topically similar databases tend to have related vocabularies. Therefore, the approximate content summaries of topically related databases can complement each other and increase their coverage. Specifically, we exploit a (given or derived) hierarchical categorization of the databases and adapt the notion of ""shrinkage"" -a form of smoothing that has been used successfully for document classification-to the content summary construction task. A thorough evaluation over 315 real web databases as well as over TREC data suggests that the shrinkage-based content summaries are substantially more complete than their ""unshrunk"" counterparts. We also describe how to modify existing database selection algorithms to adaptively decide -at run-time-whether to apply shrinkage for a query. Our experiments, which rely on TREC data sets, queries, and the associated ""relevance judgments,"" show that our shrinkage-based approach significantly improves state-of-the-art database selection algorithms, and also outperforms a recently proposed hierarchical strategy that exploits database classification as well.",2004-06-13,https://www.semanticscholar.org/paper/71de6625e881220fad562972f0af288cb5649e85,ACM SIGMOD Conference
3242,Lingering effects of contraception management on feral mare (Equus caballus) fertility and social behavior,Extended subfertility can cause changes in feral horse reproductive physiology and behavior. Here we examine long-term effects of contraception treatment on females even after cessation of treatment. We identify treatment schedules that have more/less pronounced effects and suggest management recommendations for future populations.,2017-03-18,https://www.semanticscholar.org/paper/915df9310a7b78d660daae2c81ab9ac79b0c471d,Conservation Physiology
13,Learning to Rank Adaptively for Scalable Information Extraction,"Information extraction systems extract structured data from natural language text, to support richer querying and analysis of the data than would be possible over the unstructured text. Unfortunately, information extraction is a computationally expensive task, so exhaustively processing all documents of a large collection might be prohibitive. Such exhaustive processing is generally unnecessary, though, because many times only a small set of documents in a collection is useful for a given information extraction task. Therefore, by identifying these useful documents, and not processing the rest, we could substantially improve the efficiency and scalability of an extraction task. Existing approaches for identifying such documents often miss useful documents and also lead to the processing of useless documents unnecessarily, which in turn negatively impacts the quality and efficiency of the extraction process. To address these limitations of the state-of-the-art techniques, we propose a principled, learning-based approach for ranking documents according to their potential usefulness for an extraction task. Our low-overhead, online learning-to-rank methods exploit the information collected during extraction, as we process new documents and the fine-grained characteristics of the useful documents are revealed. Then, these methods decide when the ranking model should be updated, hence significantly improving the document ranking quality over time. Our experiments show that our approach achieves higher accuracy than the state-of-the-art alternatives. Importantly, our approach is lightweight and efficient, and hence is a substantial step towards scalable information extraction.",,https://www.semanticscholar.org/paper/0316c64a5eb9152c18433fa4b92e023881e87287,International Conference on Extending Database Technology
973,Angular location of retinal nerve fiber layer defect in myopic open-angle glaucoma: a comparison between the Bruch’s membrane opening and the disc as a reference point,,2019-07-22,https://www.semanticscholar.org/paper/f2092b7ce7f4bdb396ce69bc118b0d11fc3ea08f,
1126,Search forviolation indecays incollisions at,,2010-07-26,https://www.semanticscholar.org/paper/37003535a80fbfcb159dc74e3b9175016d724e21,
2824,Galectin-3 modulates T helper responses by regulating dendritic cell cytokine expression (103.11),"
 Dendritic cells play a critical role in the initiation and maintenance of inflammatory responses. Galectin-3, a protein found in DCs, is a carbohydrate-binding protein implicated in several cellular processes. In mouse models of asthma and atopic dermatitis, galectin-3-deficient (gal3-/-) mice had significantly fewer infiltrating eosinophils and displayed lower Th2 but higher Th1 responses compared to wild-type mice, suggesting that galectin-3 plays a key role in allergic inflammation. Given the ability of DCs to direct the T lymphocyte response, we hypothesized that galectin-3 may affect immune responses by altering DC functions and tested the hypothesis by comparing wild-type and gal3-/- DCs. OT-II CD4+ cells cultured with OVA-pulsed gal3-/- DCs generated higher Th1 responses relative to gal3+/+ DCs, and the differences were diminished following IL-12 neutralization. Moreover, gal3-/- DCs expressed more IL-12p35 mRNA than gal3+/+ DCs, indicating that gal3 may modulate IL-12 at the transcriptional level or through upstream signaling pathways. T cells co-cultured with gal3-/- DCs also secreted more IL-17 than cells cultured with gal3+/+ DCs, suggesting that gal3 may also negatively regulate Th17 responses. Furthermore, we observed higher IL-6 secretion and IL-23p19 expression in gal3-/- DCs, which may contribute to the enhanced Th17 polarization induced by these cells. We conclude that gal3 may regulate DC cytokine expression, thereby modulating T helper responses.",2011-04-01,https://www.semanticscholar.org/paper/c7439e84e1508a25fd07036a915a3bbf910e699e,Journal of Immunology
1736,Poisson Trust Factorization for Incorporating Social Networks into Personalized Item Recommendation,"Many web users are faced with the problem of selecting which books to read and movies to watch. Traditionally, we ask our trusted friends for recommendations, but algorithmic recommendation models make those choices even easier, saving us time and effort by steering us towards media we are more likely to enjoy. The downside to most algorithmic recommendations is that, for some people, part of the appeal of reading or consuming other media is in creating shared experiences with friends. In this work, we aim to bridge this gap. We present a model that incorporates social network information into recommendation models, reintroducing the social aspect to recommendation and having the potential to improve overall recommendations. Further, our model discovers the latent trust that exists between users in a network and allows us to consider which users are more trustworthy than others, providing us insight into the social network’s dynamics.",,https://www.semanticscholar.org/paper/8d67f3d8924316dc999360dcc0e0a17047be3e46,
3776,Efficiently Scaling up Crowdsourced Video Annotation,,2012-09-05,https://www.semanticscholar.org/paper/981e7c22aaeb7756e2f7bb33186d44b4929bd76e,International Journal of Computer Vision
99,Computing Geographical Scopes of Web Resources,"Many information resources on the web are relevant primarily to limited geographical communities. For instance, web sites containing information on restaurants, theaters, and apartment rentals are relevant primarily to web users in geographical proximity to these locations. In contrast, other information resources are relevant to a broader geographical community. For instance, an on-line newspaper may be relevant to users across the United States. Unfortunately, current web search engines largely ignore the geographical scope of web resources. In this paper, we introduce techniques for automatically computing the geographical scope of web resources, based on the textual content of the resources, as well as on the geographical distribution of hyperlinks to them. We report an extensive experimental evaluation of our strategies using real web data. Finally, we describe a geographicallyaware search engine that we have built to showcase our techniques.",2000-09-10,https://www.semanticscholar.org/paper/4abe2165b0f43588134dc06ea4b4e917ba74924e,Very Large Data Bases Conference
1647,Automatic Differentiation Variational Inference,"Probabilistic modeling is iterative. A scientist posits a simple model, fits it to her data, refines it according to her analysis, and repeats. However, fitting complex models to large data is a bottleneck in this process. Deriving algorithms for new models can be both mathematically and computationally challenging, which makes it difficult to efficiently cycle through the steps. To this end, we develop automatic differentiation variational inference (ADVI). Using our method, the scientist only provides a probabilistic model and a dataset, nothing else. ADVI automatically derives an efficient variational inference algorithm, freeing the scientist to refine and explore many models. ADVI supports a broad class of models-no conjugacy assumptions are required. We study ADVI across ten different models and apply it to a dataset with millions of observations. ADVI is integrated into Stan, a probabilistic programming system; it is available for immediate use.",2016-03-02,https://www.semanticscholar.org/paper/30691d2a4eb1a6e88116c357e95b49f9573bcdae,Journal of machine learning research
2090,建構關聯規則資料挖礦架構及其在台電配電事故定位之研究; Constructing a Data Mining Framework of Association Rule and an Empirical Study for Fault Location,,,https://www.semanticscholar.org/paper/e9c7f820c8879012c4dc389ea0548d7ebcb697c8,
273,Comparing Trade-off Based Models of the Internet,"We introduce and evaluate several new models of network growth. Our models are extensions of the FKP model, modifying and improving it in various dimensions. In all these models nodes arrive one by one, and each node is connected to previous nodes by optimizing a trade-off between a geometric objective (""last mile cost"") and a topological objective (""position in the network""). Our new models differ from the original FKP model in directions inspired by the real Internet: two or more edges are attached to each arriving node (while the FKP model produces a tree); these edges are chosen according to various criteria such as robustness; edges may be added to the network between old nodes; or only certain ""fertile"" nodes (an attribute that changes dynamically) are capable of attracting new edges. We evaluate these models, and compare them with the graph of the Internet's autonomous systems, with respect to a suite of many test parameters (such as average degree, power law exponent, and local clustering rank) proposed in the literature; to this end we have developed the network generation and measurement system Pandora.",2009-06-30,https://www.semanticscholar.org/paper/274a29fbc41855812cfa5493fabcabc65d52550f,Fundamenta Informaticae
101,Combining Strategies for Extracting Relations from Text Collections,"Text documents often contain valuable structured data that is hidden in regular English sentences. This data is best exploited if available as a relational table that we could use for answering precise queries or for running data mining tasks. Our Snowball system extracts these relations from document collections starting with only a handful of user-provided example tuples. Based on these tuples, Snowball generates patterns that are used, in turn, to find more tuples. In this paper we introduce a new pattern and tuple generation scheme for Snowball, with different strengths and weaknesses than those of our original system. We also show preliminary results on how we can combine the two versions of Snowball to extract tuples more accurately.",,https://www.semanticscholar.org/paper/98a39e8a2d31d0a6adeccb86effb990067d6ab85,ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery
139,Stable Flight and Object Tracking with a Quadricopter Using an Android Device,"We discuss a novel system architecture for quadricopter control, the Robocopter platform, in which the quadricopter can behave near-autonomously and processing is handled by an Android device on the quadricopter. The Android device communicates with a laptop, receiving commands from the host and sending imagery and sensor data back. We also discuss the results of a series of tests of our platform on our first hardware iteration, named Jabberwock.",,https://www.semanticscholar.org/paper/b1d0f72f48b4573d132fcc555894024a934de0ff,
1658,Factorization Meets the Item Embedding: Regularizing Matrix Factorization with Item Co-occurrence,"Matrix factorization (MF) models and their extensions are standard in modern recommender systems. MF models decompose the observed user-item interaction matrix into user and item latent factors. In this paper, we propose a co-factorization model, CoFactor, which jointly decomposes the user-item interaction matrix and the item-item co-occurrence matrix with shared item latent factors. For each pair of items, the co-occurrence matrix encodes the number of users that have consumed both items. CoFactor is inspired by the recent success of word embedding models (e.g., word2vec) which can be interpreted as factorizing the word co-occurrence matrix. We show that this model significantly improves the performance over MF models on several datasets with little additional computational overhead. We provide qualitative results that explain how CoFactor improves the quality of the inferred factors and characterize the circumstances where it provides the most significant improvements.",2016-09-07,https://www.semanticscholar.org/paper/89a16eb847e5039fe5d9c6372ab45145400c9aa1,ACM Conference on Recommender Systems
1517,Practical and Asymptotically Exact Conditional Sampling in Diffusion Models,"Diffusion models have been successful on a range of conditional generation tasks including molecular design and text-to-image generation. However, these achievements have primarily depended on task-specific conditional training or error-prone heuristic approximations. Ideally, a conditional generation method should provide exact samples for a broad range of conditional distributions without requiring task-specific training. To this end, we introduce the Twisted Diffusion Sampler, or TDS. TDS is a sequential Monte Carlo (SMC) algorithm that targets the conditional distributions of diffusion models. The main idea is to use twisting, an SMC technique that enjoys good computational efficiency, to incorporate heuristic approximations without compromising asymptotic exactness. We first find in simulation and on MNIST image inpainting and class-conditional generation tasks that TDS provides a computational statistical trade-off, yielding more accurate approximations with many particles but with empirical improvements over heuristics with as few as two particles. We then turn to motif-scaffolding, a core task in protein design, using a TDS extension to Riemannian diffusion models. On benchmark test cases, TDS allows flexible conditioning criteria and often outperforms the state of the art.",2023-06-30,https://www.semanticscholar.org/paper/79531b47bb27cb18022891eb2ab1fcb41745fca6,arXiv.org
1830,A dynamic theory of social failure in isolated communities,"We introduce a statistical model for dynamic network analysis and we apply it to Sampson’s longitudinal collection of the sociometric relation trust, among 18 novices in a monastery (Sampson, 1968). A preliminary analysis offers a suggestive characterization of the social dynamics that led to the collapse of the congregation—purportedly over religious differences. Such a characterization provides the elements for a theory of failure in isolated communities that is rooted in latent aspects of the dynamics of social interaction. Namely, the existence of tight informal groups as a precondition, the progressive polarization of such groups as a signal of increasing differences, and the emergence of an interstitial group of individuals over time as a signal of imminent conflict.",,https://www.semanticscholar.org/paper/c5bd589b5ab7287151c21e482597a19a58ffb35b,
643,Computability and Complexity Jon Kleinberg,"One of the great obsessions of Renaissance sages was the solution of polynomial equations: find an x that causes a certain polynomial to evaluate to 0. Today we all learn in school how to solve quadratic equations (polynomial equations of degree two, such as ax + bx + c = 0), even though many of us have to look up the formula every time (it’s x = 1 2a (−b± √ b − 4ac)). Versions of this formula were known to the Babylonians as early as 2000 BC, and were rediscovered in many ancient cultures. The discovery of similar but much more complicated formulas for solving equations of degree three and four — the cubic and quartic formulae — had to wait until the 16th century AD. During the next three centuries, the greatest minds in Europe strove unsuccessfully to discover the quintic formula, cracking equations of degree five, until the flowering of modern algebra brought the quest to a sudden, surprising resolution: A proof that there is no quintic formula. This story, on first hearing, can engender a few natural reactions. Among them, surprise — what’s the obstacle to a quintic formula? Why was it so hard to prove it didn’t exist? And, more subtly, a mild sense of perplexity — what do we mean by a quintic formula anyway? Why can’t we write “the largest x such that ax + bx + cx + dx + ex + f = 0” and declare this to be a formula? So we back up. By a “formula” in this story, we meant a particular thing: a finite sequence of steps that begins with the given values of the coefficients and ends with a root x; each step consists of one of the basic arithmetic operations applied to certain of the quantities already computed, or else it consists of the extraction of a root of one of the quantities already computed. Now we can assert more precisely, thanks to the work of the nineteenth-century mathematicians Abel and Galois: there is no quintic formula. Viewed from the safe distance of a few centuries, the story is clearly one about computation, and it contains many of the key ingredients that arise in later efforts to model computation: We take a computational process that we understand intuitively (solving an equation, in this case), formulate a precise model, and from the model derive some highly unexpected consequences about the computational power of the process. It is precisely this approach that we wish to apply to computation in general. But moving from this example",,https://www.semanticscholar.org/paper/38ed9a68e8758a60c1d36b5e5bf03e6d70b7409d,
3291,"Ecology, social behavior, and conservation in zebras",,,https://www.semanticscholar.org/paper/5b420ef27ba23673c9ddf5db9b318b9b2e0681da,
2038,What constitutes 'A quality decision'?,,,https://www.semanticscholar.org/paper/ee9fc6ce7c3e60925491fdee1670e1dcba37f3b2,
2782,Social media (SoMe) enhances exposure of dermatology articles.,"Social media (SoMe) refers to a variety of virtual platforms used to enhance sharing of information. To evaluate the influence of SoMe with regards to views and downloads of published dermatology articles, we conducted a retrospective study from July 2020-March 2021 examining articles published on Instagram and Twitter under Dermatology Online Journal (DOJ) accounts and compared these with type-matched and issue-matched articles that were not posted on social media. During this time period, 163 total articles of the three types used for social media (Case Report, Case Presentation, and Photo Vignette) were published in DOJ and 15 were promoted via SoMe. Utilization of SoMe demonstrated a significant (P<0.0001) positive effect with regards to both views (175.5±16.4) and downloads (31.5±4.0) over matched articles not published on SoMe. Similar trends illustrating the positive effect of SoMe on readership have been previously observed in the field of dermatology as well as other medical specialties. Most direct accessions to articles arrived via Instagram rather than Twitter, diverging from previous studies on SoMe use in medical journals. Social media, in particular Instagram, can be a successful platform to enhance the exposure of peer-reviewed medical information.",2021-07-15,https://www.semanticscholar.org/paper/84778857e14b024639869887d201a97d80b71bb6,Dermatology Online Journal
417,Planar Topological Inference (Algorithms and Theory of Computing),,1998-04-01,https://www.semanticscholar.org/paper/0c36cc23253fdcd7b83a54f299520c306bb0df72,
2867,Regulation of cellular homeostasis by galectins,,,https://www.semanticscholar.org/paper/e9c4946435ddfd6d18f8a7394e3b2661abb8a5f8,Glycoconjugate Journal
2114,DEVELOPING DATA MINING FRAMEWORK AND METHODS FOR DIAGNOSING SEMICONDUCTOR MANUFACTURING DEFECTS AND AN EMPIRICAL STUDY OF WAFER ACCEPTANCE TEST DATA IN A WAFER FAB,"ABSTRACT As global competition continues to strengthen in the semiconductor industry, wafer fabs have been placing increasing importance on increasing die yield and reducing operation costs. Because of automatic manufacturing and information integration technologies, an increasingly large amount of raw data has been accumulated from various sources automatically or semi-automatically from day to day. Mining potentially useful information from large such database becomes very important in both research and application. However, little research has been done on manufacturing data of high-tech industry. In particular, due to the complex fabrication processes and the high cost of defects, using data mining approach to diagnosing defects in semiconductor manufacturing is a critical issue. We constructed a conceptual framework for data mining, proposed two methods for mining WAT data, and then applied them empirically in a fab. The results show the practical viability to assist the domain engineer in narrowing possible causes of manufacturing defects. This study concludes with discussions and remarks on future research directions.",2001-01-01,https://www.semanticscholar.org/paper/01ab51d50f24f4a3017192a70aec0aff870c4fb1,
27,Popularity-guided top-k extraction of entity attributes,"Recent progress in information extraction technology has enabled a vast array of applications that rely on structured data that is embedded in natural-language text. In particular, the extraction of concepts from the Web---with their desired attributes---is important to provide applications with rich, structured access to information. In this paper, we focus on an important family of concepts, namely, entities (e.g., people or organizations) and their attributes, and study how to efficiently and effectively extract them from Web-accessible text documents. Unfortunately, information extraction over the Web is challenging for both quality and efficiency reasons. Regarding quality, many sources on the Web contain misleading or invalid information; furthermore, extraction systems often return incorrect data. Regarding efficiency, information extraction is a time-consuming process, often involving expensive text-processing steps. We present a top-k extraction processing approach that addresses both the quality and efficiency challenges: for each entity and attribute of interest, we return the top-k values of the attribute for the entity according to a scoring function for extracted attribute values. This scoring function weighs the extraction confidence from individual documents, as well as the ""importance"" of the documents where the information originates. We define the document importance in terms of entity-specific document ""popularity"" statistics from a major search engine. Overall, our top-k extraction processing approach manages to identify the top attribute values for the entities of interest efficiently, as we demonstrate with a large-scale experimental evaluation over real-life data.",2010-06-06,https://www.semanticscholar.org/paper/d55e2998548a8fc202413ebe473f5e74ad69e800,International Workshop on the Web and Databases
3146,Fast Indexing: Support for Size-Changing Algorithms in Stackable File Systems,"Stackable file systems can provide extensible file system functionality with minimal performance overhead and development cost. However, previous approaches provide only limited functionality. In particular, they do not support size-changing algorithms (SCAs), which are important and useful for many applications such as compression and encryption. We propose fast indexing, a technique for efficient support of SCAs in stackable file systems. Fast indexing provides a page mapping between file system layers in a way that can be used with any SCA. We use index files to store this mapping. Index files are designed to be recoverable if lost and add less than 0.1% disk space overhead. We have implemented fast indexing using portable stackable templates, and we have used this system to build several example file systems with SCAs. We demonstrate that fast index files have low overhead for typical user workloads such as large compilations, only 2.3% over other stacked file systems and 4.7%over non-stackable file systems. Our system can deliver better performance with SCAs than userlevel applications, as much as five times faster.",2001-06-25,https://www.semanticscholar.org/paper/535ffd4979373706dc7d4cc6ca670f518fce3f2d,"USENIX Annual Technical Conference, General Track"
1734,An Adaptive Learning Rate for Stochastic Variational Inference,"Stochastic variational inference finds good posterior approximations of probabilistic models with very large data sets. It optimizes the variational objective with stochastic optimization, following noisy estimates of the natural gradient. Operationally, stochastic inference iteratively subsamples from the data, analyzes the subsample, and updates parameters with a decreasing learning rate. However, the algorithm is sensitive to that rate, which usually requires hand-tuning to each application. We solve this problem by developing an adaptive learning rate for stochastic variational inference. Our method requires no tuning and is easily implemented with computations already made in the algorithm. We demonstrate our approach with latent Dirichlet allocation applied to three large text corpora. Inference with the adaptive learning rate converges faster and to a better approximation than the best settings of hand-tuned rates.",2013-06-16,https://www.semanticscholar.org/paper/7ce557aa5ee42846061a7ee5344ee56b43775ee0,International Conference on Machine Learning
240,Satisfiability and Evolution,"We show that, if truth assignments on n variables reproduce through recombination so that satisfaction of a particular Boolean function confers a small evolutionary advantage, then a polynomially large population over polynomially many generations (polynomial in n and the inverse of the initial satisfaction probability) will end up almost certainly consisting exclusively of satisfying truth assignments. We argue that this theorem sheds light on the problem of the evolution of complex adaptations.",2013-12-06,https://www.semanticscholar.org/paper/f1f66ec5dfc47bdd96fe6771b049304f235f7152,IEEE Annual Symposium on Foundations of Computer Science
434,On the analysis of indexing schemes,"We consider the problem of indexing general database workloads (combinations of data sets and sets of potential queries). We define a framework for measuring the efficiency of an indexing scheme for a workload based on two characterizations: storage redundancy (how many times each item in the data set is stored), and access overhead (how many times more blocks than necessary does a query retrieve). Using this framework we present some initial results, showing upper and lower bounds and trade-offs between them in the case of multi-dimensional range queries and set queries.",1997-05-01,https://www.semanticscholar.org/paper/5291d116e72d0ca96f654bd8893c01564fa1603a,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
3282,HotSpotter — Patterned species instance recognition,"We present HotSpotter, a fast, accurate algorithm for identifying individual animals against a labeled database. It is not species specific and has been applied to Grevy's and plains zebras, giraffes, leopards, and lionfish. We describe two approaches, both based on extracting and matching keypoints or “hotspots”. The first tests each new query image sequentially against each database image, generating a score for each database image in isolation, and ranking the results. The second, building on recent techniques for instance recognition, matches the query image against the database using a fast nearest neighbor search. It uses a competitive scoring mechanism derived from the Local Naive Bayes Nearest Neighbor algorithm recently proposed for category recognition. We demonstrate results on databases of more than 1000 images, producing more accurate matches than published methods and matching each query image in just a few seconds.",2013-01-15,https://www.semanticscholar.org/paper/cf0a5d6667d43f31215a8c92c236e0ddb3ddb8dd,2013 IEEE Workshop on Applications of Computer Vision (WACV)
811,Testing for Finite State Systems,,1998-08-24,https://www.semanticscholar.org/paper/ec82e1676b6516e7a84eac905afbb08a302875b6,Annual Conference for Computer Science Logic
2391,"The mitochondrial adenosine triphosphatase of Acanthamoeba castellanii. Oscillatory accumulation of enzyme activity, enzyme protein and F1-inhibitor during the cell cycle.","1. The mitochondrial ATPase of Acanthamoeba castellanii accumulated discontinuously in synchronous cultures prepared by a minimally perturbing size-selection technique. 2. Enzyme activity per ml of culture doubled overall during one cell cycle time of 8 h, but oscillated to give seven maxima during this period. Similar oscillations were observed in the specific activities of ATPase and of the naturally occurring inhibitor protein. 3. These variations in enzyme activity reflected changes in amount of enzyme protein as assayed by an immunological technique. 4. Large variations in I50 values (micrograms of inhibitor/mg of protein necessary for 50% inhibition of inhibitor-sensitive activity) for inhibition of ATPase activity by seven different inhibitors of energy conservation were observed. Activity was more sensitive to inhibition by oligomycin, efrapeptin, citreoviridin and quercetin when values were highest. 5. The results are discussed in relation to the phased organization of biosynthesis and degradation of cellular components known to occur during the cell cycle of this organization.",1982-02-15,https://www.semanticscholar.org/paper/e9d25e518d55e3f2ebb03ec658935561b2a1b167,Biochemical Journal
1984,A system for online detection and classification of wafer bin map defect patterns for manufacturing intelligence,"Wafer bin maps (WBM) in circuit probe (CP) tests that present specific defect patterns provide crucial information to identifying assignable causes in the semiconductor manufacturing process. However, most semiconductor companies rely on engineers using eyeball analysis to judge defect patterns, which is time-consuming and not reliable. Furthermore, the conventional statistical process control used in CP tests only monitors the mean or standard deviation of yield rates and failure percentages without detecting defect patterns. To fill the gap, this study aims to develop a manufacturing intelligence solution that integrates spatial statistics and neural networks for the detection and classification of WBM patterns to construct a system for online monitoring and visualisation of WBM failure percentages and corresponding spatial patterns with an extended statistical process control chart. An empirical study was conducted in a leading semiconductor company in Taiwan to validate the effectiveness of the proposed system. The results show its practical viability and thus the proposed solution has been implemented in this company.",2013-02-28,https://www.semanticscholar.org/paper/d04f0eedd31bf016a6d9111a2aae775f87b101ad,
2795,Chlamydophila psittaci-negative ocular adnexal marginal zone lymphomas express self polyreactive B-cell receptors,,2015-02-13,https://www.semanticscholar.org/paper/67ab55b75ab2b9473d89a6bbe739af90455972f9,Leukemia
2288,"Functional analysis of the human MCL-1 gene
",,2000-04-01,https://www.semanticscholar.org/paper/a57cebce14108badaa01a2c598d3539ee7981ee7,Cellular and Molecular Life Sciences (CMLS)
2164,Upregulation of p16INK4A in Peripheral White Blood Cells as a Novel Screening Marker for Colorectal Carcinoma,"Objective: Screening of colorectal cancer (CRC) is important for the early detection. CRC is relating to aging and immuno-senescence. One such senescent marker is p16INK4A expression in immune cells. The objective of the study is to investigate the protein expression of p16INK4A in peripheral white blood cells as a screening marker for colorectal cancer. Methods: A case-control studies were conducted. Cases were patients with colorectal cancer and controls were matched with cases based on age and sex. Peripheral blood was collected from patients and controls and the protein p16INK4A was measured with immunofluorescent techniques. The p16INK4A levels from cases and controls were evaluated using ROC analysis to be used as a screening marker in CRC patients. Mean fluorescent intensity of p16INK4A of cases and controls were analyzed in CD45+, CD3+ or CD14+ cells. The p16INK4A levels of cases were also correlated with clinical data. Result: Statistically significant increased expression of p16INK4A levels were found in cases compared to controls. p16INK4A in peripheral immune cells had 78% sensitivity and 71% specificity which can possibly be used as a diagnosis tool for colorectal cancer. P16INK4A-positive cell percentage and mean florescent intensity were significantly higher in CD45+ cells, CD3 positive cells and CD14 positive cells. No significant correlation was observed with the clinical data and p16INK4A level of CRC patients. Conclusion: The significant increase of p16 INK4A expression level in peripheral immune cells represents potential for use as a CRC screening marker.",2022-11-01,https://www.semanticscholar.org/paper/a010912da96094fc1182703dd5b7315df99a145c,Asian Pacific Journal of Cancer Prevention
2803,The Role of Galectin-3 in Malignant Melanoma,,,https://www.semanticscholar.org/paper/06d705df7a30000cc1933a0c98d24ba44f7f3de8,
735,The complexity of non-monotone markets,"We introduce the notion of non-monotone utilities, which covers a wide variety of utility functions in economic theory. We show that it is PPAD-hard to compute an approximate Arrow-Debreu market equilibrium in markets with linear and non-monotone utilities. Building on this result, we settle the long-standing open problem regarding the computation of an approximate Arrow-Debreu market equilibrium in markets with CES utilities, by proving that it is PPAD-complete when the Constant Elasticity of Substitution parameter, ρ, is any constant less than -1.",2012-11-20,https://www.semanticscholar.org/paper/7a1ec5c9cbff3b233f276e358c1f371011a66ca0,Symposium on the Theory of Computing
1248,Search for large extra spatial dimensions in the dielectron and diphoton channels in pp[over ] collisions at sqrt[s]=1.96 TeV.,We report on a search for large extra spatial dimensions in the dielectron and diphoton channels using a data sample of 1.05 fb;{-1} of pp[over ] collisions at a center-of-mass energy of 1.96 TeV collected by the D0 detector at the Fermilab Tevatron Collider. The invariant mass spectrum of the data agrees well with the prediction of the standard model. We find the most restrictive 95% C.L. lower limits on the effective Planck scale between 2.1 and 1.3 TeV for 2 to 7 extra dimensions.,2008-09-16,https://www.semanticscholar.org/paper/b18bea4b54a690146748833fb25aed470d24eacf,Physical Review Letters
1287,Search for B 0 s → μ + μ - decays at DO,"We report results from a search for the decay B 0 s → μ + μ - using 1.3 fb -1 of pp collisions at √ s = 1.96 TeV collected by the DO experiment at the Fermilab Tevatron Collider. We find two candidate events, consistent with the expected background of 1.24 ± 0.99, and set an upper limit on the branching fraction of B(B 0 s → μ + μ - ) -7 at the 95% C.L.",2007-11-05,https://www.semanticscholar.org/paper/aaca7fc921a8c362bc48a1b9a828c0119c4d26fa,
265,Continuous local search Citation,"We introduce CLS, for continuous local search, a class of polynomial-time checkable total functions that lies at the intersection of PPAD and PLS, and captures a particularly benign kind of local optimization in which the domain is continuous, as opposed to combinatorial, and the functions involved are continuous. We show that this class contains several well known intriguing problems which were heretofore known to lie in the intersection of PLS and PPAD but were otherwise unclassifiable: Finding fixpoints of contraction maps, the linear complementarity problem for P matrices, finding a stationary point of a low-degree polynomial objective, the simple stochastic games of Shapley and Condon, and finding a mixed Nash equilibrium in congestion, implicit congestion, and network coordination games. The last four problems belong to CCLS, for convex CLS, another subclass of PPAD ∩ PLS seeking the componentwise local minimum of a componentwise convex function. It is open whether any or all of these problems are complete for the corresponding classes.",,https://www.semanticscholar.org/paper/146368ca45b8030d210e588907abe14e8d1905a6,
1265,Search for long-lived particles decaying into electron or photon pairs with the D0 detector,"In this Letter we report on a search for long-lived particles that decay into final states with two electrons or photons. Such long-lived particles arise in a variety of theoretical models, like hidden valleys and supersymmetry with gauge-mediated breaking. By precisely reconstructing the direction of the electromagnetic shower we are able to probe much longer lifetimes than previously explored. We see no evidence of the existence of such long-lived particles and interpret this search as a quasi model-independent limit on their production cross section, as well as a limit on a long-lived fourth generation quark.",2008-06-13,https://www.semanticscholar.org/paper/e9a7feba70284a224d2a9627a3972ed68832bb77,
445,Topological queries in spatial databases,"Handling spatial information is required by many database applications, and each poses different requirements on query languages. In many cases the precise size of the regions is important, while in other applications we may only be interested in the TOPOLOGICAL relations- hips between regions — intuitively, those that pertain to adjacency and connectivity properties of the regions, and are therefore invariant under homeomorphisms. Such differences in scope and emphasis are crucial, as they affect the data model, the query language, and performance. This talk focuses on queries targeted towards topological information for two- dimensional spatial databases, where regions are specified by polynomial inequalities with integer coeficients. We focus on two main aspects: (i) languages for expressing topological queries, and (ii) the representation of topological information. In regard to (i), we study several languages geared towards topological queries, building upon well-known topologi- cal relationships between pairs of planar regions proposed by Egenhofer. In regard to (ii), we show that the topological information in a spatial database can be precisely summarized by a finite relational database which can be viewed as a topological annotation to the raw spatial data. All topological queries can be answered using this annotation, called to- pological invariant. This yields a potentially more economical evaluation strategy for such queries, since the topological invariant is generally much smaller than the raw data. We examine in detail the problem of transla- ting topological queries against the spatial database into queries against the topological invariant. The languages considered are first-order on the spatial database side, and fixpoint and first-order on the topological in- variant side. In particular, it is shown that fixpoint expresses precisely the PTIME queries on topological invariants. This suggests that topolo- gical invariants are particularly well-behaved with respect to descriptive complexity. (Based on joint work with C.H.Papadimitriou, D. Suciu and L. Segoufin.)",1996-06-03,https://www.semanticscholar.org/paper/1de9a034e0511eb2800c5947309f32106ab73da5,Journal of computer and system sciences (Print)
1199,First Study of the Radiation-Amplitude Zero in WProduction and Limits,,,https://www.semanticscholar.org/paper/0c1f377f3160a07cdf1eec5d3d9b52f664624076,
2297,Activation of human neutrophils by soluble immune complexes: role of Fc gamma RII and Fc gamma RIIIb in stimulation of the respiratory burst and elevation of intracellular Ca2+.,"Activation of control, unprimed neutrophils with soluble immune complexes fails to generate a respiratory burst. However, if the cells are primed with either tumor necrosis factor-alpha or granulocyte-macrophage colony-stimulating factor prior to addition of soluble immune complexes, then a rapid and transient burst of reactive oxidant secretion is observed. In unprimed neutrophils the soluble immune complexes stimulate an intracellular Ca2+ transient that arises from the mobilization of intracellular Ca2+. However, in primed cells, an ""extra"" intracellular Ca2+ signal is observed that arises from Ca2+ influx. After removal of Fc gamma RIIIb by treatment with pronase or PI-PLC, the soluble immune complexes fail to activate a respiratory burst in unprimed neutrophils and the ""extra"" Ca2+ signal is not observed. These results indicate that during priming Fc gamma RIIIb becomes functionally activated and thence its ligation leads to stimulated Ca2+ influx and the generation of intracellular signals that lead to NADPH oxidase activation. Experiments using Fab/F(ab')2 fragments to specifically crosslink either Fc gamma RII or Fc gamma RIIIb and experiments with neutrophils from an individual with Fc gamma RIIIb gene deficiency confirm this important function for Fc gamma RIIIb in neutrophil activation.",,https://www.semanticscholar.org/paper/6433344edd6fb7854933cc5270722945e1762394,Annals of the New York Academy of Sciences
1213,Precise measurement of the top-quark mass from lepton + jets events.,We measure the mass of the top quark using top-quark pair candidate events in the lepton+jets channel from data corresponding to 1 fb;{-1} of integrated luminosity collected by the D0 experiment at the Fermilab Tevatron collider. We use a likelihood technique that reduces the jet energy scale uncertainty by combining an in situ jet energy calibration with the independent constraint on the jet energy scale (JES) from the calibration derived using photon+jets and dijet samples. We find the mass of the top quark to be 171.5+/-1.8(stat.+JES)+/-1.1(syst.) GeV.,2008-07-14,https://www.semanticscholar.org/paper/4a55811ac821b9bbc90b535f284457fd8745ca04,Physical Review Letters
834,Linear approximation of shortest superstrings,"We consider the following problem: given a collection of strings <italic>s<subscrpt>1</subscrpt></italic>,…, <italic>s<subscrpt>m</subscrpt></italic>, find the shortest string <italic>s</italic> such that each <italic>s<subscrpt>i</subscrpt></italic> appears as a substring (a consecutive block) of <italic>s</italic>. Although this problem is known to be NP-hard, a simple greedy procedure appears to do quite well and is routinely used in DNA sequencing and data compression practice, namely: repeatedly merge the pair of (distinct) strings with maximum overlap until only one string remains. Let <italic>n</italic> denote the length of the optimal superstring. A common conjecture states that the above greedy procedure produces a superstring of length <italic>O(n)</italic> (in fact, 2<italic>n</italic>), yet the only previous nontrivial bound known for any polynomial-time algorithm is a recent <italic>O(n</italic> log <italic>n</italic>) result.
We show that the greedy algorithm does in fact achieve a constant factor approximation, proving an upper bound of 4<italic>n</italic>. Furthermore, we present a simple modified version of the greedy algorithm that we show produces a superstring of length at most 3<italic>n</italic>. We also show the superstring problem to be MAXSNP-hard, which implies that a polynomial-time approximation scheme for this problem is unlikely.",1994-07-01,https://www.semanticscholar.org/paper/b9bd744a4337f4469afaa246cd34990908a2561d,JACM
1127,Combination of Tevatron searches for the standard model Higgs boson in the W+W- decay mode.,"We combine searches by the CDF and D0 Collaborations for a Higgs boson decaying to W+W-. The data correspond to an integrated total luminosity of 4.8 (CDF) and 5.4 (D0) fb(-1) of pp collisions at square root(s) = 1.96 TeV at the Fermilab Tevatron collider. No excess is observed above background expectation, and resulting limits on Higgs boson production exclude a standard model Higgs boson in the mass range 162-166 GeV at the 95% C.L.",2010-01-25,https://www.semanticscholar.org/paper/4a07d407cba3352bf12ebf95dc17345e6ba7cca1,Physical Review Letters
1254,Measurement of the Inclusive Jet Cross Section inCollisions at,,2008-08-06,https://www.semanticscholar.org/paper/cc8f93dae21899ad9000fee971923e0c373150b0,
381,"Algorithms, games, and the internet","If the Internet is the next great subject for Theoretical Computer Science to model and illuminate mathematically, then Game Theory, and Mathematical Economics more generally, are likely to prove useful tools. In this talk I survey some opportunities and challenges in this important frontier.",2001-07-06,https://www.semanticscholar.org/paper/2434a75d334b10f2eadddb80bb6cbe7af9f19bae,Symposium on the Theory of Computing
6,Training Neural Networks for Aspect Extraction Using Descriptive Keywords Only,,2019-03-14,https://www.semanticscholar.org/paper/d76a010abcf1db4b687809393b0e6c2338249d1d,
3732,Bringing Engineering Rigor to Deep Learning,"Deep learning (DL) systems are increasingly deployed in safety- and security-critical domains including autonomous driving, robotics, and malware detection, where the correctness and predictability of a system on corner-case inputs are of great importance. Unfortunately, the common practice to validating a deep neural network (DNN) - measuring overall accuracy on a randomly selected test set - is not designed to surface corner-case errors. As recent work shows, even DNNs with state-of-the-art accuracy are easily fooled by human-imperceptible, adversarial perturbations to the inputs. Questions such as how to test corner-case behaviors more thoroughly and whether all adversarial samples have been found remain unanswered. In the last few years, we have been working on bringing more engineering rigor into deep learning. Towards this goal, we have built five systems to test DNNs more thoroughly and verify the absence of adversarial samples for given datasets. These systems check a broad spectrum of properties (e.g., rotating an image should never change its classification) and find thousands of error-inducing samples for popular DNNs in critical domains (e.g., ImageNet, autonomous driving, and malware detection). Our DNN verifiers are also orders of magnitude (e.g., 5,000×) faster than similar tools. This article overviews our systems and discusses three open research challenges to hopefully inspire more future research towards testing and verifying DNNs.",2019-07-25,https://www.semanticscholar.org/paper/1657065a6f3933a8fcfa7ab99b8bcafb0e610e2d,ACM SIGOPS Operating Systems Review
3496,"Optimal Time-Critical Scheduling via Resource Augmentation
",,1997-04-01,https://www.semanticscholar.org/paper/6778008e23e05b69e0e243b1f0b63db7056336d8,Symposium on the Theory of Computing
1256,Study of direct CP violation in B-+/--> J/psi K-+/-(pi(+/-)) decays,We present a search for direct CP violation in B-+/- -> J/psi K-+/- (pi(+/-)) decays. The event sample is selected from 2: 8 fb(-1) of p (p) over bar collisions recorded by D0 experiment in run II of the Fermilab Tevatron Collider. The charge asymmetry A(CP)(B+ -> J/psi K+) = +0: 0075 +/- 0: 0061(stat) +/- 0: 0030 (syst) is obtained using a sample of approximately 40 000 B-+/- -> J/psi K-+/- decays. The achieved precision is of the same level as the expected deviation predicted by some extensions of the standard model. We also measured the charge asymmetry A(CP) (B+ -> J/psi pi(+)) = - 0: 09 +/- 0: 08(stat) +/- 0: 03(syst).,2008-02-22,https://www.semanticscholar.org/paper/d780902e86d5bb3498f551d57e074296498db424,
2471,ISSUES IN GENERATING GRAPHICAL EXPLANATIONSt,"Advances In computer graphics have led to the ever-Increasing ability to depict objects realistically, while work In expert systems has resulted In the capacity to model objects and their Interactions well enough to solve some dlmcult problems. One application In which the power of both disciplines can be coupled Is the generation of graphical explanations that depict the performance of actions on objects. This paper Introduces a high-level conceptual architecture for automatically generating presentations. It serves as an organizing framework In which to examine some of the problems that we have encountered In Implementing APEX, a test-bed system for creating and laying out pictures that depict actions performed by a problem solver.",,https://www.semanticscholar.org/paper/b40db4b72fa3b6761767c5df439e4db68dbce540,
1829,Supervised Topic Models,"We introduce supervised latent Dirichlet allocation (sLDA), a statistical model of labelled documents. The model accommodates a variety of response types. We derive a maximum-likelihood procedure for parameter estimation, which relies on variational approximations to handle intractable posterior expectations. Prediction problems motivate this research: we use the fitted model to predict response values for new documents. We test sLDA on two real-world problems: movie ratings predicted from reviews, and web page popularity predicted from text descriptions. We illustrate the benefits of sLDA versus modern regularized regression, as well as versus an unsupervised LDA analysis followed by a separate regression.",2007-12-03,https://www.semanticscholar.org/paper/c13aa63ccd5cf972a0a8c6b236c1dfad95b19b4e,Neural Information Processing Systems
121,dSCAM: finding document copies across multiple databases,"The advent of the Internet has made the illegal dissemination of copyrighted material easy. An important problem is how to automatically detect when a ""new"" digital document is ""suspiciously close"" to existing ones. The SCAM project at Stanford University has addressed this problem when there is a single registered-document database. However, in practice, test documents may appear in many autonomous databases, and one would like to discover copies without having to exhaustively search in all databases. The authors' approach, dSCAM, is a distributed version of SCAM that keeps succinct metainformation about the contents of the available document databases. Given a suspicious document S, dSCAM uses its information to prune all databases that cannot contain any document that is close enough to S, and hence the search can focus on the remaining sites. They also study how to query the remaining databases so as to minimize different querying costs. They empirically study the pruning and searching schemes, using a collection of 50 databases and two sets of test documents.",1996-12-01,https://www.semanticscholar.org/paper/44e832f182dd508587d6abed2e61cad8061c68c0,Fourth International Conference on Parallel and Distributed Information Systems
678,Sample Complexity of Learning Mahalanobis Distance Metrics,"Metric learning seeks a transformation of the feature space that enhances prediction quality for the given task at hand. In this work we provide PAC-style sample complexity rates for supervised metric learning. We give matching lower- and upper-bounds showing that the sample complexity scales with the representation dimension when no assumptions are made about the underlying data distribution. However, by leveraging the structure of the data distribution, we show that one can achieve rates that are fine-tuned to a specific notion of intrinsic complexity for a given dataset. Our analysis reveals that augmenting the metric learning optimization criterion with a simple norm-based regularization can help adapt to a dataset's intrinsic complexity, yielding better generalization. Experiments on benchmark datasets validate our analysis and show that regularizing the metric can help discern the signal even when the data contains high amounts of noise.",2015-05-11,https://www.semanticscholar.org/paper/5872d29e682b5ffa9b09de44b4fa3d19279f15f1,Neural Information Processing Systems
1782,Probabilistic Topic Models,"In this article, we review probabilistic topic models: graphical models that can be used to summarize a large collection of documents with a smaller number of distributions over words. Those distributions are called ""topics"" because, when fit to data, they capture the salient themes that run through the collection. We describe both finite-dimensional parametric topic models and their Bayesian nonparametric counterparts, which are based on the hierarchical Dirichlet process (HDP). We discuss two extensions of topic models to time-series data-one that lets the topics slowly change over time and one that lets the assumed prevalence of the topics change. Finally, we illustrate the application of topic models to nontext data, summarizing some recent research results in image analysis.",2010-10-18,https://www.semanticscholar.org/paper/44ab78d0605f2b4905e19ba56d6e51529da4bed9,IEEE Signal Processing Magazine
1788,A Language-based Approach to Measuring Scholarly Impact,"Identifying the most influential documents in a corpus is an important problem in many fields, from information science and historiography to text summarization and news aggregation. Unfortunately, traditional bibliometrics such as citations are often not available. We propose using changes in the thematic content of documents over time to measure the importance of individual documents within the collection. We describe a dynamic topic model for both quantifying and qualifying the impact of these documents. We validate the model by analyzing three large corpora of scientific articles. Our measurement of a document's impact correlates significantly with its number of citations.",2010-06-21,https://www.semanticscholar.org/paper/c645d99bf9b3f496a561818b37350d7a1834b92b,International Conference on Machine Learning
2424,XREye: Simulating Visual Impairments in Eye-Tracked XR,"Many people suffer from visual impairments, which can be difficult for patients to describe and others to visualize. To aid in understanding what people with visual impairments experience, we demonstrate a set of medically informed simulations in eye-tracked XR of several common conditions that affect visual perception: refractive errors (myopia, hyperopia, and presbyopia), cornea disease, and age-related macular degeneration (wet and dry).",2020-03-01,https://www.semanticscholar.org/paper/494357c63cd2a38d503ef6ea2e53216b0ce9ae19,2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)
138,Querying Large Text Databases for Efficient Information Extraction,"A wealth of data is hidden within unstructured text. This data is often best exploited in structured or relational form, which is suited for sophisticated query processing, for integration with relational databases, and for data mining. Current information extraction techniques extract relations from a text database by examining every document in the database. This exhaustive approach is not practical, or sometimes even feasible, for large databases. In this paper, we develop an efficient query-based technique to identify documents that are potentially useful for the extraction of a target relation. We start by sampling the database to characterize the documents from which an information extraction system manages to extract relevant tuples. Then, we apply machine learning and information retrieval techniques to derive queries likely to match additional useful documents in the database. Finally, we issue these queries to the database to retrieve documents from which the information extraction system can extract the final relation. Our technique requires that databases support only a minimal boolean query interface, and is independent of the choice of the underlying information extraction system. We report a thorough experimental evaluation over more than one million documents that shows that we significantly improve the efficiency of the extraction process by focusing only on promising documents. Our proposed technique could be used to query a standard web search engine, hence providing a building block for efficient information extraction over the web at large.",,https://www.semanticscholar.org/paper/d34a065a8324975ba9b14fec3e5cf4a8df1dfd46,
1284,A study of the decay Λ b,"COLLABORATION — Using ∼ 360 pb − 1 of Run II data collected by the CDF detector, we search for the decay Λ 0 b → Λ + c π − π + π − , in p ¯ p collisions at √ s = 1 . 96 TeV, where Λ c baryon is reconstructed as Λ + c → p + K − π + . This decay mode is plagued by a substantial combinatorial background arising from a large track multiplicity characteristic of hadronic envi-ronment. We investigate ways of suppressing the combinatorial background in order to extract the Λ b signal.",,https://www.semanticscholar.org/paper/933071aa9b327d595c446d0c4130403626e28d33,
2311,Cell sigualliug by iutegfius immnoglobu in reeept primed neutropNJs,"TOBS 20 - SEPTEMBER 1995 THE MAIN FUNCTION of neutrophils is to seek out and destroy invading mb crobial pathogens in order to protect the host from infections. During phagocy- tosis, many antimicrobial enzyme sys- tems are activated and delivered at high concentrations into phagocytic yes- ides, where they first kill, then digest, the pathogens (Fig. la). These antimi- crobial systems include an 02-/H~O~- generating NADPH oxidase, myelo- peroxidase, a ~-ariety of proteases, hydrolases and proteins that affect the permeability of the microbial plasma membraneL The components of the NADPH oxidase 2, as well as many of the other ant[microbial proteins, have now been identified and characterized at the molecular level, but the mechanisms by which they become activated have not been fully defined. Indeed, the signal transduction systems that regulate ac- tivation of the NADPH oxidase and phagocytosis are extraordinarily com- plex, which probably reflects the need for tight control of neutrophil function, since if the products of the NADPH oxi- dase or the degradative enzymes were released from neutrophils in high concentrations (Fig. lb) they could inflict considerable damage to the host tissues. Activation and priming In order to mount an effective anti- microbial challenge, circulating neutro- phUs must respond appropriately to a range of pro-inflammatory signals. After leaving the circulation and migrating by chemotaxis to the site of infection, they must recognize, bind and engulf the pathogens into phagocytic vesicles. The NADPH oxidase is then activated (the respiratory burst) and the anti- microbial enzymes (normally located within subcellular granules) are dis- charged into the pathogen-containing vesicles. The major neutrophil chemoattractants [formyl-Met.Leu.Phe ([bliP), complement component C5a, platelet-activating [actor, Leukotrie~le B 4 (LTB4) and interleukin-8] are recognized by receptors that possess a common structure with seven transmembrane helices, originally identified in the rhodopsin-llke, G-protein-coupled recep- tors. Much is known of the mechanisms by which these chemoattractants activate neutrophlls, and many of the signalling systems that are involved $. W, F.ch~NIs is at the Department of Biochemistry, University of Liverpool, PO Box 147, Liverpool, UK L69 3BX.",,https://www.semanticscholar.org/paper/3ff8b323ec5c3b80dc602da700a1ba0a212912b4,
1684,Automatic Differentiation Variational Inference,"Modern data analysis requires an iterative cycle: in the probabilistic modeling framework, a sim1 ple model is fit to the data, and it is refined as we gather more knowledge about the data’s hidden 2 structure. However, fitting complex models to large datasets is mathematically and computationally 3 challenging. We develop an automated tool called automatic differentiation variational inference 4 (advi). The scientist only provides a probabilistic model and a dataset; nothing else. advi auto5 matically derives an efficient algorithm that handles both complex models and large datasets. No 6 conjugacy assumptions are required, and a broad class ofmodels is supported. We studyadvi across 7 ten different models and apply it to a dataset with millions of observations. advi is integrated into 8 Stan, a probabilistic programming system; this makes advi available for immediate use. 9",,https://www.semanticscholar.org/paper/9028e2b0d3ce51d310458c922f747b76f6c46590,
3216,"Behavioral and Ecological Implications of Bunched, Rotational Cattle Grazing in East African Savanna Ecosystem",,2019-01-01,https://www.semanticscholar.org/paper/bd79d787459160239a954332450aaa95edbefeb4,Rangeland Ecology & Management
3717,The Boombox: Visual Reconstruction from Acoustic Vibrations,"Interacting with bins and containers is a fundamental task in robotics, making state estimation of the objects inside the bin critical. While robots often use cameras for state estimation, the visual modality is not always ideal due to occlusions and poor illumination. We introduce The Boombox, a container that uses sound to estimate the state of the contents inside a box. Based on the observation that the collision between objects and its containers will cause an acoustic vibration, we present a convolutional network for learning to reconstruct visual scenes. Although we use low-cost and low-power contact microphones to detect the vibrations, our results show that learning from multimodal data enables state estimation from affordable audio sensors. Due to the many ways that robots use containers, we believe the box will have a number of applications in robotics. Our project website is at: boombox.cs.columbia.edu",2021-05-17,https://www.semanticscholar.org/paper/d666e22aa939a262bcf2a7985bcc3eb16dcb85e4,Conference on Robot Learning
1445,Neutron background for a dark matter experiment at a shallow depth site,,1995-01-30,https://www.semanticscholar.org/paper/31abcdaed3bdfc4d499f9b6e368c1b33d5af8468,
914,Independent database schemas,"Abstract A database schema is independent with respect to a given set of constraints if the constraints can be enforced separately in the relations. A polynomial time algorithm is presented that recognizes independent schemas, when the given constraints consist of functional dependencies and the join dependency of the database schema.",1982-03-29,https://www.semanticscholar.org/paper/79452415c4785939e214ea25e4a4eab1c6bc4704,Journal of computer and system sciences (Print)
3572,Programming in an undergraduate CS curriculum,"This note argues for a fairly classical undergraduate computer science (CS) curriculum where ""software"" (programming and related topics) takes a bigger role than is often the case. The discussion is based partly on experience with an undergraduate curriculum change at Texas A&M University and with developing a new freshman programming course. That freshman course is the central topic of this note. Based on industrial experience, it is argued that the primary aim of a university education in the area of ""software"" is to be a foundation for professional work. The primary design criterion for the freshman (first year) programming course is to make it a good start at that. Caveat: the opinions expressed about the needed improvements of and directions for software education is based on personal experience rather than hard data.",2009-05-01,https://www.semanticscholar.org/paper/672ff6a0fb966c477cab7125f313471e17d5cda0,
2248,Replication of Colonic Crohn's Disease Mucosal Escherichia coli Isolates within Macrophages and Their Susceptibility to Antibiotics,"ABSTRACT There is increasing evidence that Escherichia coli organisms are important in Crohn's disease (CD) pathogenesis. In CD tissue they are found within macrophages, and the adherent-invasive CD ileal E. coli isolate LF82 can replicate inside macrophage phagolysosomes. This study investigates replication and antibiotic susceptibility of CD colonic E. coli isolates inside macrophages. Replication of CD colonic E. coli within J774-A1 murine macrophages and human monocyte-derived macrophages (HMDM) was assessed by culture and lysis after gentamicin killing of noninternalized bacteria and verified by electron microscopy (EM). All seven CD colonic isolates tested replicated within J774-A1 macrophages by 3 h (6.36-fold ± 0.7-fold increase; n = 7 isolates) to a similar extent to CD ileal E. coli LF82 (6.8-fold ± 0.8-fold) but significantly more than control patient isolates (5.2-fold ± 0.25-fold; n = 6; P = 0.006) and E. coli K-12 (1.0-fold ± 0.1-fold; P < 0.0001). Replication of CD E. coli HM605 within HMDM (3.9-fold ± 0.7-fold) exceeded that for K-12 (1.4-fold ± 0.2-fold; P = 0.03). EM showed replicating E. coli within macrophage vacuoles. Killing of HM605 within J774-A1 macrophages following a 3-h incubation with antibiotics at published peak serum concentrations (Cmax) was as follows: for ciprofloxacin, 99.5% ± 0.2%; rifampin, 85.1% ± 6.6%; tetracycline, 62.8% ± 6.1%; clarithromycin, 62.1% ± 5.6% (all P < 0.0001); sulfamethoxazole, 61.3% ± 7.0% (P = 0.0007); trimethoprim, 56.3% ± 3.4% (P < 0.0001); and azithromycin, 41.0% ± 10.5% (P = 0.03). Ampicillin was not effective against intracellular E. coli. Triple antibiotic combinations were assessed at 10% Cmax, with ciprofloxacin, tetracycline, and trimethoprim causing 97% ± 0.0% killing versus 86% ± 2.0% for ciprofloxacin alone. Colonic mucosa-associated E. coli, particularly CD isolates, replicate within macrophages. Clinical trials are indicated to assess the efficacy of a combination antibiotic therapy targeting intramacrophage E. coli.",2007-12-10,https://www.semanticscholar.org/paper/b054ce15e0ddbf2485ddf65d8dd5598b617237e0,Antimicrobial Agents and Chemotherapy
375,A deterministic (2-2/(k+1))n algorithm for k-SAT based on local search,,2002-10-23,https://www.semanticscholar.org/paper/a9359f5d9ef7b3484c24ba65467dcb337d341e40,Theoretical Computer Science
2669,Wearing It Out : First Steps Toward Mobile Augmented Reality Systems,,,https://www.semanticscholar.org/paper/f75ffadab01f3a6b8472c1bc3ee8574eb54b5d65,
1105,Erratum: Silicon detector results from the first five-tower run of CDMS II (Physical Review D (2013) 88 (031104) DOI:10.1103/PhysRevD.88.031104),,2013-09-09,https://www.semanticscholar.org/paper/7bc162a9bda2728b19ddbd6fd5f4e7fb7a61f65f,
2376,Regulation of superoxide generation by myeloperoxidase during the respiratory burst of human neutrophils.,"The role of myeloperoxidase in the regulation of the respiratory burst of human neutrophils activated by the chemotactic peptide (N-formyl-L-methionyl-L-leucyl-L-phenylalanine) plus cytochalasin B was determined by using anti-(human myeloperoxidase) antibody. The respiratory burst activated under these conditions consisted of an initial (1-2 min) phase with high rates of O2 uptake, luminol-dependent chemiluminescence and superoxide radical (O2-.) generation and a second, more sustained, phase of lower magnitude of chemiluminescence and O2 uptake: O2-. generation did not occur during this second phase. In cell suspensions stimulated in the presence of anti-(human myeloperoxidase) antibody, the magnitude of the initial phase of both O2 uptake and O2-. generation was unaffected, but these high rates were maintained over much longer periods than in control suspensions. It is therefore proposed that a product of myeloperoxidase normally regulates the duration of O2-. generation during the respiratory burst, possibly by inhibition of NADPH oxidase.",1986-07-15,https://www.semanticscholar.org/paper/e0b40946ed93a765c96c233206711ad32d5e573c,Biochemical Journal
422,Latent semantic indexing: a probabilistic analysis,"Latent semantic indexing (LX) is an information retrieval technique based on the spectral analysis of the term-document matrix, whose empirical success had heretofort been without rigorous prediction and explanation. We prove that, under certain conditions, LSI does succeed in capturing the underlying semantics of the corpus and achieves improved retrieval performance. We also propose the technique of random projection as a way of speeding up LSI. We complement our theorems with encouraging experimental results. We also argue that our results may be viewed in a more general framework, as a theoretical basis for the use of spectral methods in a wider class of applications such as collaborative filtering.",1998-05-01,https://www.semanticscholar.org/paper/5cfac7b32b7f2e279a63c90c8f0798f4d9f24c12,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
2859,Galectin-3 and Galectin-1 Bind Distinct Cell Surface Glycoprotein Receptors to Induce T Cell Death1,"Galectins are a family of mammalian β-galactoside-binding proteins that positively and negatively regulate T cell death. Extracellular galectin-1 directly induces death of T cells and thymocytes, while intracellular galectin-3 blocks T cell death. In contrast to the antiapoptotic function of intracellular galectin-3, we demonstrate that extracellular galectin-3 directly induces death of human thymocytes and T cells. However, events in galectin-3- and galectin-1-induced cell death differ in a number of ways. Thymocyte subsets demonstrate different susceptibility to the two galectins: whereas galectin-1 kills double-negative and double-positive human thymocytes with equal efficiency, galectin-3 preferentially kills double-negative thymocytes. Galectin-3 binds to a complement of T cell surface glycoprotein receptors distinct from that recognized by galectin-1. Of these glycoprotein receptors, CD45 and CD71, but not CD29 and CD43, appear to be involved in galectin-3-induced T cell death. In addition, CD7 that is required for galectin-1-induced death is not required for death triggered by galectin-3. Following galectin-3 binding, CD45 remains uniformly distributed on the cell surface, in contrast to the CD45 clustering induced by galectin-1. Thus, extracellular galectin-3 and galectin-1 induce death of T cells through distinct cell surface events. However, as galectin-3 and galectin-1 cell death are neither additive nor synergistic, the two death pathways may converge inside the cell.",2006-01-15,https://www.semanticscholar.org/paper/e9783386ba96aadfb2b43bda8d6bd70c6714815a,Journal of Immunology
705,Smoothed complexity of local max-cut and binary max-CSP,"We show that the smoothed complexity of the FLIP algorithm for local Max-Cut is at most φ n O(√logn), where n is the number of nodes in the graph and φ is a parameter that measures the magnitude of perturbations applied on its edge weights. This improves the previously best upper bound of φ n O(logn) by Etscheid and Roglin. Our result is based on an analysis of long sequences of flips, which shows that it is very unlikely for every flip in a long sequence to incur a positive but small improvement in the cut weight. We also extend the same upper bound on the smoothed complexity of FLIP to all binary Maximum Constraint Satisfaction Problems.",2019-11-23,https://www.semanticscholar.org/paper/83228979c513f79efea340bb7ae4820faa730276,Symposium on the Theory of Computing
1948,UNISON DECISION ANALYSIS FRAMEWORK FOR WORKFORCE PLANNING FOR SEMICONDUCTOR FABS AND AN EMPIRICAL STUDY,"With the increase in the scale of semiconductor manufacturing, the number of knowledge-workers has also increased tremendously. The cost of automation and manpower is increasing annually, and engineers and technical operators are playing an increasingly crucial role in factories. The optimal workforce plan for manufacturing and the improvement of productivity have become key topics. In semiconductor manufacturing, numerous factors affect the workforce plan for manufacturing. The problem of determining the actual manpower demand, given the different preference structures of various decision makers, is difficult to solve. This study employed a UNISON decision analysis framework for constructing an workforce planning decision model for semiconductor manufacturing. We also held discussions with domain experts to identify key performance indices for human capital management. An empirical study was conducted in a semiconductor company, and the results showed that the proposed framework could assist the company in developing an operation workforce planning model and an associated management mechanism for improving the decision quality and decision rationality. Thus, the company could enhance human capital and productivity to maintain corporate competitiveness.",2015-10-26,https://www.semanticscholar.org/paper/db6c81a0696f57cf6df53667ee2c4f49b91bfd08,
606,Covering Graphs by Simple Circuits,"We show that any biconnected graph with n nodes and m edges can be covered by simple circuits whose total length is at most $\min (3m,m + 6n)$. Our proof suggests an efficient algorithm for finding such a cover.",1981-11-01,https://www.semanticscholar.org/paper/8c79014f35a8f9d9ca14b8a65aab846902a6a0e4,SIAM journal on computing (Print)
636,The Euclidean Traveling Salesman Problem is NP-Complete,,,https://www.semanticscholar.org/paper/b151ce5e30980fdeda2fc2413250d6502cdddcc5,Theoretical Computer Science
934,On a class of totally unimodular matrices,"We examine the class of matrices that satisfy Commoner's sufficient condition for total unimodularity [C], which we call restricted totally unimodular (RTUM). We show that a matrix is RTUM if and only if it can be decomposed in a very simple way into the incidence matrices (or their transposes) of bipartite graphs or directed graphs, and give a linear time algorithm to perform this task. Based on this decomposition, we show that the 0,1 Integer Programming Problem with an RTUM matrix of constraints has the same time complexity as the b-matching and the max flow problems.",1980-10-13,https://www.semanticscholar.org/paper/a5c4cf30dcbbc130f693dd1b75e0032f42b741bd,21st Annual Symposium on Foundations of Computer Science (sfcs 1980)
3500,On the existence of schedules that are near-optimal for both makespan and total weighted completion time,,1997-10-01,https://www.semanticscholar.org/paper/c21b96e3cafc1ab2817a4b40c55a00d3523f319f,Operations Research Letters
683,Learning hierarchical similarity metrics,"Categories in multi-class data are often part of an underlying semantic taxonomy. Recent work in object classification has found interesting ways to use this taxonomy structure to develop better recognition algorithms. Here we propose a novel framework to learn similarity metrics using the class taxonomy. We show that a nearest neighbor classifier using the learned metrics gets improved performance over the best discriminative methods. Moreover, by incorporating the taxonomy, our learned metrics can also help in some taxonomy specific applications. We show that the metrics can help determine the correct placement of a new category that was not part of the original taxonomy, and can provide effective classification amongst categories local to specific subtrees of the taxonomy.",2012-06-16,https://www.semanticscholar.org/paper/ed3d28a6015937a282e4f9c273307fb4a732f8ff,2012 IEEE Conference on Computer Vision and Pattern Recognition
2251,Arthritis Stimulated Monocytes in Rheumatoid Production by Immune Complexes Soluble TNF-Like Cytokine ( TL 1 A ) Bambara,,,https://www.semanticscholar.org/paper/fdd4bae529947010d1230046f43e7dddfe51b88c,
1778,Spatial distance dependent Chinese restaurant processes for image segmentation,"The distance dependent Chinese restaurant process (ddCRP) was recently introduced to accommodate random partitions of non-exchangeable data [1]. The dd-CRP clusters data in a biased way: each data point is more likely to be clustered with other data that are near it in an external sense. This paper examines the dd-CRP in a spatial setting with the goal of natural image segmentation. We explore the biases of the spatial ddCRP model and propose a novel hierarchical extension better suited for producing ""human-like"" segmentations. We then study the sensitivity of the models to various distance and appearance hyperparameters, and provide the first rigorous comparison of nonparametric Bayesian models in the image segmentation domain. On unsupervised image segmentation, we demonstrate that similar performance to existing nonparametric Bayesian models is possible with substantially simpler models and algorithms.",2011-12-12,https://www.semanticscholar.org/paper/ecfbd1a30a243f15610fa6b76907f8455560da3a,Neural Information Processing Systems
437,Emerging opportunities for theoretical computer science,"The principles underlying this report can be summarized as follows:1. A strong theoretical foundation is vital to computer science.2. Theory can be enriched by practice.3. Practice can be enriched by theory.4. If we are guided by (2) and (3), the value, impact, and funding of theory will be enhanced.In order to achieve a greater synergy between theory and application, and to sustain and expand on the remarkable successes of Theory of Computing (TOC), we consider it essential to increase the impact of theory on key application areas. This requires additional financial resources in support of theory, and closer interaction between theoreticians and researchers in other areas of computer science and in other disciplines.The report does not make a detailed assessment of the overall state of theoretical computer science or fully chronicle the achievements of this field. Instead, it has the specific objective of recommending ways to harness these remarkable achievements for the solution of challenging problems emerging from new developments such as the information superhighway.Section 1 describes the events leading up to this report and delineates the report's objectives. Section 2 establishes the context for the report. It traces the history of TOC, describes the impact that TOC has achieved in the areas of core theory and fundamental algorithms, points out the differences between these areas and application-oriented theory, and calls for an intensified effort to bring the methods of TOC to bear on applications. It then goes on to define the four main categories into which our recommen- dations fall: building bridges between theory and applications, algorithm engineering, communication, and education. Section 3 discusses some specific opportunities for stimulating interactions between TOC and applied areas. Section 4 proposes an applied research initiative, Information Access in a Globally Distributed Environment, which identifies an exciting current technological area that we believe presents challenging opportunities for excellent theoretical work. Section 5 proposes a second applied research initiative, The Algorithmic Stockroom, that would exploit and extend the body of theoretical knowledge in the field of algorithms. Section 6 proposes a broadening in graduate education with two purposes in mind: to better prepare theoreticians to interact creatively with practitioners, and to provide future practitioners with the background they will need to benefit from this exchange.",1997-09-01,https://www.semanticscholar.org/paper/893b6f77e6243c7c85df3c6dc6f595228cf958d0,Sigact News
2230,"Changes in expression of membrane TNF, NF-κB activation and neutrophil apoptosis during active and resolved inflammation","Background Tumour necrosis factor (TNF) is central to the pathophysiological process of rheumatoid arthritis (RA), whether as soluble cytokine or membrane-expressed pro-TNF (mTNF). Objectives To determine whether neutrophils, which can express TNF, are activated in the blood of patients with RA compared with healthy controls. To investigate, by focusing on mTNF expression, if the functions of RA neutrophils change in response to therapeutic TNF inhibition. Methods TNF was measured by flow cytometry and qPCR in neutrophils from 20 patients with RA before and after the start of TNF inhibitor therapy. Apoptosis was measured by morphology, and western blotting of pro- and antiapoptotic proteins in cell lysates. Nuclear factor κB (NF-κB) activation was determined by western blotting of phosphorylated NF-κB (p65). Results Before treatment RA neutrophils exhibited increased TNF mRNA expression, elevated mTNF levels and NF-κB activity compared with controls. They also underwent delayed apoptosis as shown by altered expression of anti- and proapoptotic proteins, such as Mcl-1 and caspases. Neutrophil TNF expression returned to baseline levels during successful treatment with anti-TNF biological agents, and there was a close correlation between clinical disease improvement and changes in neutrophil function. Conclusions Neutrophils express elevated levels of TNF in RA and the transcription factor, NF-κB, a target of TNF, is activated. This mechanism could lead to a self-sustained inflammatory process. These data point to an important role of neutrophils in the abnormal TNF signalling pathways activated in RA and provide new evidence that neutrophils actively contribute to altered cytokine signalling in inflammatory diseases.",2010-11-24,https://www.semanticscholar.org/paper/2d7f6bec8bc34bd53c554821060916e5a0a7dcba,Annals of the Rheumatic Diseases
1605,Measuring discursive inﬂuence across scholarship,"Assessing scholarly inﬂuence is critical for understanding the col- lective system of scholarship and the history of academic inquiry. Inﬂuence is multifaceted, and citations reveal only part of it. Cita- tion counts exhibit preferential attachment and follow a rigid “news cycle” that can miss sustained and indirect forms of inﬂu- ence. Building on dynamic topic models that track distributional shifts in discourse over time, we introduce a variant that incor- porates features, such as authorship, afﬁliation, and publication venue,toassesshowthesecontextsinteractwithcontenttoshapefuturescholarship.Weperformin-depthanalysesoncollectionsof",,https://www.semanticscholar.org/paper/8fb7a8657e801396fd61ea2a8af21b86eeed8705,
2395,Oscillatory Accumulation of Catalase during the Cell Cycle of Acanthamoeba castellanii,"The accumulation of catalase in synchronously dividing cultures of Acanthamoeba castellanii, prepared by size selection techniques involving minimal perturbation, was discontinuous. During the cell cycle of 8 h both catalase activity and immunologically determined catalase protein oscillated with a periodicity of about 1 h and a mean trough-to-peak amplitude of 21% of the minimal values. These patterns of enzyme accumulation were not observed in control asynchronous cultures after exposure to identical experimental conditions. The results are discussed suggesting that periodic biosynthesis and degradation occurs during growth and division of this organism.",1981-08-01,https://www.semanticscholar.org/paper/a6384f25fadc1b6ed266939066513c206f10b83f,
3330,Science and the Pursuit of a Sustainable World.,,1993-11-01,https://www.semanticscholar.org/paper/eab3e6f6c0be505da229bcd878234b5062aa519a,Ecological Applications
2748,Visualizing n-dimensional virtual worlds with n-vision,"There are many applications in science, mathematics , statistics, and business, in which it is important to explore an d manipulate clam in more than three dimensions . In thes e applications, data can be defined by points in Euclidean n-space . A point's position is then specified with it coordinates . each o f which determines its position relative to one of It mutuall y perpendicular axes . We describe here research that has as its goa l the development of interaction techniques and metaphors for th e 4D and higher-dimensional worlds that this data represents .",1990-02-01,https://www.semanticscholar.org/paper/8f09a0a105a36997179c9f4a36b3acab522e46e6,ACM Symposium on Interactive 3D Graphics and Games
3739,DeepBase: Deep Inspection of Neural Networks,"Although deep learning models perform remarkably well across a range of tasks such as language translation and object recognition, it remains unclear what high-level logic, if any, they follow. Understanding this logic may lead to more transparency, better model design, and faster experimentation. Recent machine learning research has leveraged statistical methods to identify hidden units that behave (e.g., activate) similarly to human understandable logic, but those analyses require considerable manual effort. Our insight is that many of those studies follow a common analysis pattern, and therefore there is opportunity to provide a declarative abstraction to easily express, execute and optimize them. This paper describes DeepBase, a system to inspect neural network behaviors through a unified interface. We model logic with user-provided hypothesis functions that annotate the data with high-level labels (e.g., part-of-speech tags, image captions). DeepBase lets users quickly identify individual or groups of units that have strong statistical dependencies with desired hypotheses. We discuss how DeepBase can express existing analyses, propose a set of simple and effective optimizations to speed up a standard Python implementation by up to 72x, and reproduce recent studies from the NLP literature.",2018-08-13,https://www.semanticscholar.org/paper/1d913f05044382ddc1fea170a739fffa189c9c88,SIGMOD Conference
460,On the k-server conjecture,"We prove that the <italic>work function algorithm</italic> for the <italic>k</italic>-server problem has a competitive ratio at most 2<italic>k</italic>−1. Manasse et al. [1988] conjectured that the competitive ratio for the <italic>k</italic>-server problem is exactly <italic>k</italic> (it is trivially at least <italic>k</italic>); previously the best-known upper bound was exponential in <italic>k</italic>. Our proof involves three crucial ingredients: A <italic>quasiconvexity property</italic> of work functions, a <italic>duality lemma</italic> that uses quasiconvexity to characterize the configuration that achieve maximum increase of the work function, and a <italic>potential function</italic> that exploits the duality lemma.",1995-09-01,https://www.semanticscholar.org/paper/fff192ac4261f92383529b6405213430492758af,JACM
1031,Locomotive analysis of a single-input three-link snake robot,"When commanding gaits for snake robots and other articulated systems, direct control of all possible joint inputs may not always be necessary or optimal to achieve a locomotive goal. Here we consider a three-link nonholonomic snake robot-an already underactuated system with locomotive capabilities in SE(2)-and reduce its input space to a single actuated joint, replacing the other joint's motor with a passive mass-spring-damper system. We show that the modified system can operate dynamically in addition to kinematically, and that it is possible to find gaits that produces locomotion similar to a fully actuated system. In particular, we describe the emergence of a new type of gait that incorporates the system's singular configurations to produce high locomotive efficiency without incurring unbounded constraint forces.",2016-12-01,https://www.semanticscholar.org/paper/68d0fc8c081630b4473d1b7a12d890ff64761dee,IEEE Conference on Decision and Control
2551,Pointer warping in heterogeneous multi-monitor environments,"Warping the pointer across monitor bezels has previously been demonstrated to be both significantly faster and preferred to the standard mouse behavior when interacting across displays in homogeneous multi-monitor configurations. Complementing this work, we present a user study that compares the performance of four pointer-warping strategies, including a previously untested frame-memory placement strategy, in heterogeneous multi-monitor environments, where displays vary in size, resolution, and orientation. Our results show that a new frame-memory pointer warping strategy significantly improved targeting performance (up to 30% in some cases). In addition, our study showed that, when transitioning across screens, the mismatch between the visual and the device space has a significantly bigger impact on performance than the mismatch in orientation and visual size alone. For mouse operation in a highly heterogeneous multi-monitor environment, all our participants strongly preferred using pointer warping over the regular mouse behavior.",2007-05-28,https://www.semanticscholar.org/paper/07c34b4df41357ef44058a09127ff372aaad634a,International Genetic Improvement Workshop
679,Efficient energy management and data recovery in sensor networks using latent variables based tensor factorization,"A key factor in a successful sensor network deployment is finding a good balance between maximizing the number of measurements taken (to maintain a good sampling rate) and minimizing the overall energy consumption (to extend the network lifetime). In this work, we present a data-driven statistical model to optimize this tradeoff. Our approach takes advantage of the multivariate nature of the data collected by a heterogeneous sensor network to learn spatio-temporal patterns. These patterns enable us to employ an aggressive duty cycling policy on the individual sensor nodes, thereby reducing the overall energy consumption. Our experiments with the OMNeT++ network simulator using realistic wireless channel conditions, on data collected from two real-world sensor networks, show that we can sample just 20% of the data and can reconstruct the remaining 80% of the data with less than 9% mean error, outperforming similar techniques such is distributed compressive sampling. In addition, energy savings ranging up to 76%, depending on the sampling rate and the hardware configuration of the node.",2013-11-03,https://www.semanticscholar.org/paper/118d0304b459b4c338f5c7368187f0d7c8638a62,"International Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems"
1974,Hybrid Particle Swarm Optimization with Genetic Operators and Cauchy Distribution for Flexible Job-shop Scheduling Problem,"Flexible job-shop scheduling problem (FJSP) has been well known as one of the most difficult NP-hard combinatorial optimization problems. This problem FJSP is an extension of job-shop scheduling problem (JSP) which is to create a sequence of operations satisfying the precedence relationship together with assignment of time and resources for each operation. Thus, the FJSP model is closer to the real factory situation and greater complexity than JSP model due to the need to determine the assignment of operations to machines. This paper proposes a hybrid particle swarm optimization (PSO) algorithm combined with genetic algorithm (GA) and Cauchy distribution to solve the flexible job shop scheduling problem. The objective is to find a job sequence that minimizes the makespan. The hybrid PSO combined with GA is based on the particle swarm optimization for creating operation sequences and assign operations on machines, and for improving by the genetic operators such as crossover and mutation to update particles. Finally, the proposed method is illustrated with a numerical example and numerical experiment results show that the effectiveness of the approach by the hybrid PSO combined with GA and Cauchy distribution (PSO + GA with CD).",,https://www.semanticscholar.org/paper/10411851655b6fd220c3ac383d8fcf8b85239130,
1453,Measurement of αs in e + e − Annihilation at Ecm = 29 GeV 1 TPC / Two-Gamma Collaboration,"A measurement of the strong coupling constant αs using the event-shape variable y3 (the differential two-jet rate) in the reaction e+e− → hadrons is presented. The analysis is based on data from the TPC/Two-Gamma detector at the PEP e+e− storage ring taken between 1984 and 1986 at a center-of-mass energy of Ecm = 29 GeV. A value of αs(29 GeV) = 0.160 ± 0.012 is obtained, where the error is the quadratic sum of experimental and theoretical uncertainties. The procedure for determining αs is the same as that used by the ALEPH and TOPAZ experiments, which allows for a consistent comparison of the αs values obtained at different center-of-mass energies. The observed energy dependence “running” of αs is found to be in good agreement with the QCD prediction, and is clearly incompatible with a constant value.",,https://www.semanticscholar.org/paper/e9b172939c63b2cc6af20a0e9c8e3e95491cce97,
860,Minimum and maximum delay problems in real-time systems,,1991-07-01,https://www.semanticscholar.org/paper/5e3fdbe80861e7bbb2bd8c6c3a3c348075f6276c,Formal Methods Syst. Des.
1711,Decomposing spatiotemporal brain patterns into topographic latent sources,,2014-09-01,https://www.semanticscholar.org/paper/a5b50170e7270d20c03fed29602f1fccf4552965,NeuroImage
2680,Efficiently planning coherent visual discourse,,1998-03-01,https://www.semanticscholar.org/paper/ec8ef0ac755725140abef7d2feece61fd4e00afa,Knowledge-Based Systems
3524,Parallel algorithms for the assignment and minimum-cost flow problems,,1993-11-01,https://www.semanticscholar.org/paper/f6e94da6740eee7e2de64b69ff53a32f3f444cc3,Operations Research Letters
246,An Algorithmic View of the Universe,"In the years since Alan Turing, and following his lead, computer scientists advanced their understanding of computational phenomena by developing a very specialized, original and penetrating way of rigorous thinking. Now it turns out that this ""algorithmic"" way of thinking can be applied productively to the study of important phenomena outside computation proper (examples: the cell, the brain, the market, the universe, indeed mathematical truth itself). This development is an exquisite unintended consequence of the fact that there is latent computation underlying each of these phenomena, or the ways in which science studies them.",2012-06-15,https://www.semanticscholar.org/paper/99c913f58fb3aaf365fc67a7627ce6fafe7942c6,ACM-TURING '12
234,A Multiplayer Generalization of the MinMax Theorem,"We show that in zero-sum polymatrix games, a multiplayer generalization of two-person zerosum games, Nash equilibria can be found efficiently with linear programming. We also show that the set of coarse correlated equilibria collapses to the set of Nash equilibria. In contrast, other positive properties of two-person zero-sum games are not preserved: Nash equilibrium payoffs need not be unique, and Nash equilibrium strategies need not be exchangeable or max-min.",,https://www.semanticscholar.org/paper/c0404caefdfafe8415a84c9583924881d563a54c,
1022,Locomotion of a multi-link non-holonomic snake robot with passive joints,"Conventional approaches in prescribing controls for locomoting robots assume control over all input degrees of freedom (DOFs). Many robots, such as those with non-holonomic constraints, may not require or even allow for direct command over all DOFs. In particular, a snake robot with more than three links with non-holonomic constraints cannot achieve arbitrary configurations in all of its joints while simultaneously locomoting. For such a system, we assume partial command over a subset of the joints, and allow the rest to evolve according to kinematic chained and dynamic models. Different combinations of actuated and passive joints, as well as joints with dynamic elements such as torsional springs, can drastically change the coupling interactions and stable oscillations of joints. We use tools from nonlinear analysis to understand emergent oscillation modes of various robot configurations and connect them to overall locomotion using geometric mechanics and feedback control for robots that may not fully utilize all available inputs. We also experimentally verify observations and motion planning results on a physical non-holonomic snake robot.",2020-01-27,https://www.semanticscholar.org/paper/e641fa9ee43b4f2f83e76293772cc6eefa2eab38,Int. J. Robotics Res.
2406,Cyanide-insensitive Respiration in Acanthamoeba castellanii. Changes in Sensitivity of Whole Cell Respiration during Exponential Growth,"Respiration of Acanthamoeba castellanii shows varying sensitivity to cyanide during exponential growth in a medium containing proteose peptone, glucose and yeast extract. After 20 h growth, respiration was stimulated up to 40% by 1 mM-cyanide; sensitivity to cyanide then gradually increased until 90% inhibition of respiration was attained in late-exponential phase cultures. Salicyl hydroxamic acid alone never stimulated or inhibited respiration by more than 20% but, when added together with cyanide, inhibition was always 70 to 100% from 3h onward. Sensitivity to antimycin A was similar, but not identical to that shown to cyanide; when antimycin A was added together with salicyl hydroxamic acid, the inhibition was greater. Increased sensitivities to arsenite and malonate were also observed in late-exponential phase cultures. These changes in sensitivities were not associated with alterations in the growth medium since similar changes in sensitivity to inhibitors were observed during growth in conditioned medium. A rotenone-sensitive site is associated with cyanide-stimulated respiration and the results suggest that A. castellanii possesses a branched electron transport system.",1977-12-01,https://www.semanticscholar.org/paper/5c308bfa8f8e8a01473cedb7bdfb29f95df36acc,
959,Visual fatigue induced by watching virtual reality device and the effect of anisometropia,"Abstract The effect of small anisometropia on visual fatigue when using virtual reality (VR) devices was investigated. Participants (n = 34) visited three times. In the first visit, VR exposure (10 min) was conducted with the full correction of the refractive error of both eyes. Experimental anisometropia was induced by adding a + 1.0 dioptre spherical lens either on the dominant eyes in the second visit or on the non-dominant eyes in the third visit. At each visit, the participants played a predetermined video game using a head-mounted display VR for 10 min. Visual fatigue was assessed before and after playing VR game using the Virtual Reality Symptom Questionnaire (VRSQ) and high-frequency component of accommodative microfluctuation. Results showed that watching VR induced significant increase of VRSQ score, significant decrease in the maximum accommodation power and objective increase in visual fatigue. Experimental anisometropia induction either on the dominant or non-dominant eyes did not aggravate visual fatigue. Practitioner summary: Mild differences in refractive error (up to 1.0 dioptre) between both eyes do not significantly increase ocular fatigue by viewing virtual reality device (10 min). The impact of small anisometropia may be limited in developing a virtual reality device. Abbreviations: VR: virtual reality; VRSQ: virtual reality symptom questionnaire; HMD: head-mounted display; HFC: high-frequency component",2021-07-16,https://www.semanticscholar.org/paper/fbafc578bb16a55bb14a20a764eef99506209019,Ergonomics
816,On the complexity of database queries (extended abstract),"We revisit the issue of the complexity of database queries, in the light of the recent parametric refinement of complexity theory. We show that, if the query size (or the number of variables in the query) is considered as a parameter, then the relational calculus and its fragments (conjunctive queries, positive queries) are classified at appropriate levels of the so-called W hierarchy of Downey and Fellows. These results strongly suggest that the query size is inherently in the exponent of the data complexity of any query evaluation algorithm, with the implication becoming stronger as the expressibility of the query language increases. For recursive languages (fixpoint logic, Datalog) this is provably the case [14]. On the positive side, we show that this exponential dependence can be avoided for the extension of acyclic queries with # (but not <) inequalities.",1997-05-01,https://www.semanticscholar.org/paper/f6d76c42bc47979485b525fb331afae68eced1eb,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
2777,[38] O. Sudarsky and C. Gotsman. Output-sensitive Rendering and Communication in Dynamic A. Funkhouser. Ring: a Client-server System for Multi-user Virtual Environments. in Summary and Conclusions,"[30] B. F. Naylor. Partitioning tree image representation and generation from 3D geometric models. [37] O. Sudarsky and C. Gotsman. Output-sensitive visibility algorithms for dynamic scenes with applications to virtual reality. [18] T. A. Funkhouser. Database management for interactive display of large architectural models. Kinetic binary space partitions for intersecting segments and disjoint triangles. BSP tree projection. Different culling algorithms can be used in a similar way. Minor adjustments may be required for some algorithms. For example, if Teller and Funkhouser's cell intervisibility precalculation is used [19, 41], then occlusions of dynamic objects by static scenery can easily be utilized, but occlusions by dynamic objects are harder to detect. Other occlusion culling techniques may be even harder to adapt to dynamic scenes. For example, in a static scene, the set of objects seen from each region of viewpoints in space can simply be found by brute force at preprocessing, and stored for use at runtime; however, the generalization of this method to dynamic scenes is not simple, and might even be less efficient than rendering the whole model without any occlusion culling. The TBVs used in this research are "" flat, "" in the sense that each is related to a single object (usually composed of numerous primitives). An alternative that can be explored is to employ hierarchical TBVs, i.e. temporal bounding volumes that contain, in turn, other volumes, thus relating to more than one object. This may have some advantages in certain cases, e.g. when the dynamic objects tend to stay in clusters rather than being evenly spread through space. As mentioned above, one of the main advantages of dynamic scene occlusion culling is that it saves unneeded updates of unseen dynamic objects. It thus harnesses the power of occlusion culling to reduce the number of object update messages, which can potetially be very time-consuming in distributed environments. Another possible direction of future research is the combination this message reduction method with other techniques, such as dead reckoning. The same general idea may also be applied to level-of-detail control: update messages for distant objects with small screen projections can be sent less frequently than for apparently large objects. In conclusion, the rich body of work on 3D graphics optimization includes a lot of techniques that were originally developed with static scenes in mind. The generalization of these techniques to dynamic scenes is not always simple, but it is definitely …",,https://www.semanticscholar.org/paper/c9f5682d15b84d548a613006cf467000bbc2a113,
1586,Prescribed Generative Adversarial Networks,"Generative adversarial networks (GANs) are a powerful approach to unsupervised learning. They have achieved state-of-the-art performance in the image domain. However, GANs are limited in two ways. They often learn distributions with low support---a phenomenon known as mode collapse---and they do not guarantee the existence of a probability density, which makes evaluating generalization using predictive log-likelihood impossible. In this paper, we develop the prescribed GAN (PresGAN) to address these shortcomings. PresGANs add noise to the output of a density network and optimize an entropy-regularized adversarial loss. The added noise renders tractable approximations of the predictive log-likelihood and stabilizes the training procedure. The entropy regularizer encourages PresGANs to capture all the modes of the data distribution. Fitting PresGANs involves computing the intractable gradients of the entropy regularization term; PresGANs sidestep this intractability using unbiased stochastic estimates. We evaluate PresGANs on several datasets and found they mitigate mode collapse and generate samples with high perceptual quality. We further found that PresGANs reduce the gap in performance in terms of predictive log-likelihood between traditional GANs and variational autoencoders (VAEs).",2019-10-09,https://www.semanticscholar.org/paper/fae3d474c4d7745be06458df0c20bf837a6055ef,arXiv.org
66,QProber: A system for automatic classification of hidden-Web databases,"The contents of many valuable Web-accessible databases are only available through search interfaces and are hence invisible to traditional Web ""crawlers."" Recently, commercial Web sites have started to manually organize Web-accessible databases into Yahoo!-like hierarchical classification schemes. Here we introduce QProber, a modular system that automates this classification process by using a small number of query probes, generated by document classifiers. QProber can use a variety of types of classifiers to generate the probes. To classify a database, QProber does not retrieve or inspect any documents or pages from the database, but rather just exploits the number of matches that each query probe generates at the database in question. We have conducted an extensive experimental evaluation of QProber over collections of real documents, experimenting with different types of document classifiers and retrieval models. We have also tested our system with over one hundred Web-accessible databases. Our experiments show that our system has low overhead and achieves high classification accuracy across a variety of databases.",,https://www.semanticscholar.org/paper/5e13887f269b61c14142b6286665579abe5a9f45,TOIS
1808,Relational Topic Models for Document Networks,"We develop the relational topic model (RTM), a model of documents and the links between them. For each pair of documents, the RTM models their link as a binary random variable that is conditioned on their contents. The model can be used to summarize a network of documents, predict links between them, and predict words within them. We derive efficient inference and learning algorithms based on variational methods and evaluate the predictive performance of the RTM for large networks of scientific abstracts and web documents.",2009-04-15,https://www.semanticscholar.org/paper/9f68d27df3a4c4be8636f376cb15f77e55a2f496,International Conference on Artificial Intelligence and Statistics
3661,What is object-oriented programming?,"The meaning of the term 'object oriented' is examined in the context of the general-purpose programming language C++. This choice is made partly to introduce C++ and partly because C++ is one of the few languages that supports data abstraction, object-oriented programming, and traditional programming techniques. The support of programming paradigms by languages is discussed and four paradigms are examined: procedural, data hiding, data abstraction, and object-oriented programming. The support of the latter two by C++ is discussed in some detail.<<ETX>>",1987-06-15,https://www.semanticscholar.org/paper/c5a38f242075a938dc760b2ef59e8f59f2a60fe0,IEEE Software
3740,Multi-Level Multimodal Common Semantic Space for Image-Phrase Grounding,"We address the problem of phrase grounding by learning a multi-level common semantic space shared by the textual and visual modalities. We exploit multiple levels of feature maps of a Deep Convolutional Neural Network, as well as contextualized word and sentence embeddings extracted from a character-based language model. Following dedicated non-linear mappings for visual features at each level, word, and sentence embeddings, we obtain multiple instantiations of our common semantic space in which comparisons between any target text and the visual content is performed with cosine similarity. We guide the model by a multi-level multimodal attention mechanism which outputs attended visual features at each level. The best level is chosen to be compared with text content for maximizing the pertinence scores of image-sentence pairs of the ground truth. Experiments conducted on three publicly available datasets show significant performance gains (20%-60% relative) over the state-of-the-art in phrase localization and set a new performance record on those datasets. We provide a detailed ablation study to show the contribution of each element of our approach and release our code on GitHub.",2018-11-28,https://www.semanticscholar.org/paper/2718cd594d2aa09315da52594877cd71d377dfcf,Computer Vision and Pattern Recognition
1427,And a Measurement of ∆γ,,,https://www.semanticscholar.org/paper/d4c0c3eb7da9b8313d9c6b24a2b4aefc5f71a3f5,
1777,Bayesian Checking for Topic Models,"Real document collections do not fit the independence assumptions asserted by most statistical topic models, but how badly do they violate them? We present a Bayesian method for measuring how well a topic model fits a corpus. Our approach is based on posterior predictive checking, a method for diagnosing Bayesian models in user-defined ways. Our method can identify where a topic model fits the data, where it falls short, and in which directions it might be improved.",2011-07-27,https://www.semanticscholar.org/paper/d9e650bebc559b34a4b5ae379d20933a8d0c9335,Conference on Empirical Methods in Natural Language Processing
2763,Editable graphical histories,"The authors have designed a testbed system that creates a series of automatically generated panels that depict in chronological order the important events in the history of a users session with Chimera, a graphical editor. The authors' system heuristically determines the contents of each panel and the actions that it illustrates. The user can scroll through the sequence of panels, reviewing actions at different levels of detail, and selectively undoing, modifying, and redoing previous actions.<<ETX>>",1988-10-10,https://www.semanticscholar.org/paper/4551f016f4dad887465c7b83839ed41ade8f49ca,[Proceedings] 1988 IEEE Workshop on Visual Languages
3238,Animal Population Censusing at Scale with Citizen Science and Photographic Identification,"Population censusing is critical to monitoring the health of an animal population. A census results in a population size estimate, which is a fundamental metric for deciding the demographic and conservation status of a species. Current methods for producing a population census are expensive, demanding, and may be invasive, leading to the use of overly-small sample sizes. In response, we propose to use volunteer citizen scientists to collect large numbers of photographs taken over large geographic areas, and to use computer vision algorithms to semi-automatically identify and count individual animals. Our data collection and processing are distributed, non-invasive, and require no specialized hardware and no scientific training. Our method also engages the community directly in conservation. We analyze the results of two population censusing events, the Great Zebra and Giraffe Count (2015) and the Great Grevy’s Rally (2016), where combined we processed over 50,000 photographs taken with more than 200 different cameras and over 300 on-the-ground volunteers.",,https://www.semanticscholar.org/paper/46a934b8c1b2ee73d4f855e9b16a646779157ba8,AAAI Spring Symposia
1803,Bayesian Spectral Matching: Turning Young MC into MC Hammer via MCMC Sampling,"In this paper, we introduce an audio mosaicing technique based on performing posterior inference on a probabilistic generative model. Whereas previous approaches to concatenative synthesis and audio mosaicing have mostly tried to match higher-level descriptors of audio or individual STFT frames, we try to directly match the magnitude spectrogram of a target sound by combining and overlapping a set of short samples at different times and amplitudes. Our use of the graphical modeling formalism allows us to use a standard Markov Chain Monte Carlo (MCMC) posterior inference algorithm to find a set of time shifts and amplitudes for each sample that results in a layered composite sound whose spectrogram approximately matches the target spectrogram.",,https://www.semanticscholar.org/paper/7b1d9dd5be58acb2d25d27a0dfa40c0088f3df77,International Conference on Mathematics and Computing
3772,Inferring the Why in Images,"Abstract : Humans have the remarkable capability to infer the motivations of other people's actions, likely due to cognitive skills known in psychophysics as the theory of mind. In this paper, we strive to build a computational model that predicts the motivation behind the actions of people from images. To our knowledge, this challenging problem has not yet been extensively explored in computer vision. We present a novel learning based framework that uses high-level visual recognition to infer why people are performing an actions in images. However, the information in an image alone may not be sufficient to automatically solve this task. Since humans can rely on their own experiences to infer motivation, we propose to give computer vision systems access to some of these experiences by using recently developed natural language models to mine knowledge stored in massive amounts of text. While we are still far away from automatically inferring motivation, our results suggest that transferring knowledge from language into vision can help machines understand why a person might be performing an action in an image.",2014-06-20,https://www.semanticscholar.org/paper/dfe448d6297ea0a3d4deba21fbf1006bc35877d7,arXiv.org
2160,Platelet TLR7 is essential for the formation of platelet-neutrophil complexes and low-density neutrophils in lupus nephritis.,"OBJECTIVES
Platelets and low-density neutrophils (LDNs) are major players in the immunopathogenesis of systemic lupus erythematosus (SLE). Despite evidence showing the importance of platelet neutrophil complexes (PNCs) in inflammation, little is known about the relationship between LDNs and platelets in SLE. We sought to characterize the role of LDNs and TLR7 in clinical disease.


METHODS
Flow cytometry was used to immunophenotype LDNs from SLE patients and controls. The association of LDNs with organ damage was investigated in a cohort of 290 SLE patients. TLR7mRNA expression was assessed in LDNs and high-density neutrophils (HDNs) using publicly available mRNA sequencing datasets, and our own cohort using RT-PCR. The role of TLR7 in platelet binding was evaluated in platelet: HDN mixing studies using TLR7 deficient mice and Klinefelter syndrome patients.


RESULTS
SLE patients with active disease have more LDNs, which are heterogeneous and more immature in patients with evidence of kidney dysfunction. LDNs are platelet bound, in contrast to HDNs. LDNs settle in the PBMC layer due to the increased buoyancy and neutrophil degranulation from platelet binding. Mixing studies demonstrated that this PNC formation was dependent on platelet-TLR7, and that the association results in increased NETosis. The neutrophil-to-platelet ratio (NPR), is a useful clinical correlate for LDNs, and a higher NPR is associated with past and current flares of lupus nephritis.


CONCLUSIONS
LDNs sediment in the upper PBMC fraction due to PNC formation, which is dependent on the expression of TLR7 in platelets. Collectively, our results reveal a novel TLR7-dependent crosstalk between platelets and neutrophils, which may be an important therapeutic opportunity for lupus nephritis.",2023-06-21,https://www.semanticscholar.org/paper/fe8bcb06e0cd3686854c95a5134cab25647f61f8,Rheumatology
3648,The Annotated C++ Reference Manual,"Preface. 1. Introduction. Overview. Syntax Notation. Evolution of C++. Acknowledgements. 2. Lexical Conventions. Tokens. Comments. Identifiers. Keywords. Literals. Implementation Dependencies. 3. Basic Concepts. Declarations and Definitions. Scopes. Program and Linkage. Start and Termination. Storage Classes. Types. Lvalues. Name Spaces. Numerical Limits. 4. Standard Conversions. Integral Promotions. Integral Conversions. Float and Double. Floating and Integral. Arithmetic Conversions. Pointer Conversions. Reference Conversions. Pointers to Members. Arithmetic Conversions. 5. Expressions. Primary Expressions. Postfix Expressions. Unary Operators. Explicit Type Conversion. Pointer-to-Member Operators. Multiplicative Operators. Additive Operators. Shift Operators. Relational Operators. Equality Operators. Bitwise AND Operator. Bitwise Exclusive OR Operator. Bitwise Inclusive OR Operator. Logical AND Operator. Logical OR Operator. Conditional Operator. Assignment Operators. Comma Operator. Constant Expressions. 6. Statements. Labeled Statement. Expression Statement. Compound Statement, or Block. Selection Statements. Iteration Statements. Jump Statements. Declaration Statement. Ambiguity Resolution. 7. Declarations. Specifiers. Enumeration Declarations. Asm Declarations. Linkage Specifications. Linkage Specifications. Type-safe Linkage. Limitations. 8. Declarators. Type Names Meaning of Declarators. Function Definitions. Initializers. Pointers to Members. 9. Classes. Class Names. Class Members. Member Functions. Static Members. Unions. Bit-Fields. Nested Class Declarations. Local Class Declarations. Local Type Names. Interfaces. 10. Derived Classes. Multiple Base Classes. Virtual Functions. Abstract Classes. Summary of Scope Rules. Single Inheritance. Multiple Inheritance. Multiple Inheritance and Casting. Multiple Inheritance and Implicit Conversion. Virtual Base Classes. Virtual Base Classes and Casting. Single Inheritance and Virtual Functions. Multiple Inheritance and Virtual Functions. Instantiation of Virtual Functions. Virtual Base Classes with Virtual Functions. Renaming. 11. Member Access Control. Access Specifiers. Access Specifiers for Base Classes. Access Declarations. Friends. Protected Member Access. Access to Virtual Functions. Multiple Access. General Ideas. Per Class Protection. Access Control. 12. Special Member Functions. Constructors. Temporary Objects. Conversions. Destructors. Free Store. Initialization. Constructors and Destructors. Copying Class Objects. Temporary Elimination. Access Control and Special Functions. Summary of Member, Friend, and Special Functions. 13. Overloading. Declaration Matching. Argument Matching. Address of Overload Function. Overloaded Operators. 14. Templates. Templates. Class Templates. Type Equivalence. Function Templates. Declarations and Definitions. Member Function Templates. Friends. Static Members and Variables. 15. Exception Handling. Exception Handling. Throwing an Exception. Constructors and Destructors. Handling and Exception. Exception Specifications. Special Functions. Exceptions and Access. 16. Preprocessing. Phases of Preprocessing. Trigraph Sequences. Macro Definition and Expansion. File Inclusion. Conditional Compilation. Line Control. Error Directive. Pragmas. Null Directive. Predefined Names. C++ Constructs versus #define. Compatibility. Classic C Preprocessing. 17. Grammar Summary. Keywords. Expressions. Declarations. Declarators. Class. Statements. Preprocessor. Templates. Exception. 18. Compatibility. Extensions. C++ and ANSI C. Anachronisms. ANSI/ISO Resolutions. Index. 0201514591T04062001",,https://www.semanticscholar.org/paper/6cbe7cd81bd799e04692acbd467c175b5ec00b01,
3244,Seasonal influences on gelada social networks,,,https://www.semanticscholar.org/paper/13019ef061579c38f47eb8d76bc4ce803de5c750,
376,Market equilibrium via a primal-dual-type algorithm,"Although the study of market equilibria has occupied center stage within mathematical economics for over a century, polynomial time algorithms for such questions have so far evaded researchers. We provide the first such algorithm for the linear version of a problem defined by Irving Fisher in 1891. Our algorithm is modeled after Kuhn's (1995) primal-dual algorithm for bipartite matching.",2002-11-16,https://www.semanticscholar.org/paper/b31c29a4353fdd958ecdb96bdb677c4ba4e8ab69,"The 43rd Annual IEEE Symposium on Foundations of Computer Science, 2002. Proceedings."
1662,The $\chi$-Divergence for Approximate Inference,"Variational inference enables Bayesian analysis for complex probabilistic models with massive data sets. It posits a family of approximating distributions and finds the member closest to the posterior. While successful, variational inference methods can run into pathologies; for example, they typically underestimate posterior uncertainty. In this paper we propose CHIVI, a complementary algorithm to traditional variational inference. CHIVI is a black box algorithm that minimizes the χ-divergence from the posterior to the family of approximating distributions and provides an upper bound of the model evidence. We studied CHIVI in several scenarios. On Bayesian probit regression and Gaussian process classification it yielded better classification error rates than expectation propagation (EP) and classical variational inference (VI). When modeling basketball data with a Cox process, it gave better estimates of posterior uncertainty. Finally, we show how to use the CHIVI upper bound and classical VI lower bound to sandwich estimate the model evidence.",2016-11-01,https://www.semanticscholar.org/paper/b4c8cc15005058146d0b66a8f4490a323d5bbe7f,
1759,Variational inference in nonconjugate models,"Mean-field variational methods are widely used for approximate posterior inference in many probabilistic models. In a typical application, mean-field methods approximately compute the posterior with a coordinate-ascent optimization algorithm. When the model is conditionally conjugate, the coordinate updates are easily derived and in closed form. However, many models of interest--like the correlated topic model and Bayesian logistic regression--are nonconjugate. In these models, mean-field methods cannot be directly applied and practitioners have had to develop variational algorithms on a case-by-case basis. In this paper, we develop two generic methods for nonconjugate models, Laplace variational inference and delta method variational inference. Our methods have several advantages: they allow for easily derived variational algorithms with a wide class of nonconjugate models; they extend and unify some of the existing algorithms that have been derived for specific models; and they work well on real-world data sets. We studied our methods on the correlated topic model, Bayesian logistic regression, and hierarchical Bayesian logistic regression.",2012-09-19,https://www.semanticscholar.org/paper/c9db97118af813a87eb355c5a80671364c9ebbe1,Journal of machine learning research
3140,The design and implementation of Zap: a system for migrating computing environments,"We have created Zap, a novel system for transparent migration of legacy and networked applications. Zap provides a thin virtualization layer on top of the operating system that introduces pods, which are groups of processes that are provided a consistent, virtualized view of the system. This decouples processes in pods from dependencies to the host operating system and other processes on the system. By integrating Zap virtualization with a checkpoint-restart mechanism, Zap can migrate a pod of processes as a unit among machines running independent operating systems without leaving behind any residual state after migration. We have implemented a Zap prototype in Linux that supports transparent migration of unmodified applications without any kernel modifications. We demonstrate that our Linux Zap prototype can provide general-purpose process migration functionality with low overhead. Our experimental results for migrating pods used for running a standard user's X windows desktop computing environment and for running an Apache web server show that these kinds of pods can be migrated with subsecond checkpoint and restart latencies.",,https://www.semanticscholar.org/paper/4bed5060dcf909d851a8ba1876b8aba4c9d8819b,USENIX Symposium on Operating Systems Design and Implementation
3462,Scheduling an Industrial Production Facility,,2004-06-07,https://www.semanticscholar.org/paper/1af12f53bb43e8f8c357249e6d4b586c88b79b95,Conference on Integer Programming and Combinatorial Optimization
32,Join Optimization of Information Extraction Output: Quality Matters!,"Information extraction (IE) systems are trained to extract specific relations from text databases. Real-world applications often require that the output of multiple IE systems be joined to produce the data of interest. To optimize the execution of a join of multiple extracted relations, it is not sufficient to consider only execution time. In fact, the quality of the join output is of critical importance: unlike in the relational world, different join execution plans can produce join results of widely different quality whenever IE systems are involved. In this paper, we develop a principled approach to understand, estimate, and incorporate output quality into the join optimization process over extracted relations. We argue that the output quality is affected by (a) the configuration of the IE systems used to process documents, (b) the document retrieval strategies used to retrieve documents, and (c) the actual join algorithm used. Our analysis considers several alternatives for these factors, and predicts the output quality---and, of course, the execution time---of the alternate execution plans. We establish the accuracy of our analytical models, as well as study the effectiveness of a quality-aware join optimizer, with a large-scale experimental evaluation over real-world text collections and state-of-the-art IE systems.",2009-03-29,https://www.semanticscholar.org/paper/ba44bd05bff54484803abd54f20625b0e8c07847,IEEE International Conference on Data Engineering
2946,Annotation-free quantification of RNA splicing using LeafCutter,,2017-12-11,https://www.semanticscholar.org/paper/d1c2faa14fb8b8091ad9cf3393711c44353aac7e,Nature Genetics
3245,Evidence based review: positive versus negative effects of livestock grazing on wildlife. What do we really know?,"More than a quarter of earth’s land surface is used for grazing domestic livestock. Livestock grazing is generally assumed to negatively affect wildlife, however, a number of studies have found positive impacts as well. We conducted an evidence-based review of the existing literature using a series of livestock- and wildlife-related search words to systematically query Google Scholar and Web of Science. A total of 807 sources were included in the final list, including 646 primary sources which reported original data. The majority of studies were conducted in North America (338) or Europe (123), with many fewer from Africa (57), Australia (54), Central/South America (43), or Asia (31). Most studies examined birds (330) and mammals (262), with fewer including reptiles (91) or amphibians (58). We extracted further information from studies that included mammals on positive, negative, and neutral effects of livestock grazing on mammals. We found that livestock change vegetation structure and cover in ways important to small mammals, while ungulates may be affected more by interference competition and changes in forage quantity and quality. Community-level total abundance of small mammals typically declines with grazing. Species richness of small mammals either declines or stays the same, as many studies found a change in species composition from ungrazed to grazed sites while the number of species remained similar. Individual species responses of small mammals vary. Voles, harvest mice, cotton rats, and shrews show consistently negative responses to grazing while deer mice, kangaroo rats, ground squirrels, and lagomorphs show positive or variable responses. In general, species adapted to open habitats are often positively affected by grazing, while species needing denser cover are negatively affected. Studies of wild ungulates are more variable in methodology and quality than those for small mammals. We found more negative (n = 86) than positive (n = 34) ungulate responses overall, however, most studies have been on browsers and mixed feeders, namely deer and elk, and there is little available data for other groups. Although data is limited, several of the grazing species in Africa may show a trend toward positive responses, suggesting possible facilitation. For a number of species, responses varied by season. We find a strong need for additional research on ungulates of varying diets and body sizes, especially in the developing world, and across longer time scales to examine possible tradeoffs between competition and facilitation from livestock.",2016-11-11,https://www.semanticscholar.org/paper/2962e564ec1aeb2622f3dcf2f77069f3854e4c02,
3326,The Dynamics of Herds: From Individuals to Aggregations,"Abstract The dynamic behavior of small herds is investigated by means of simulations of two-dimensional discrete-stochastic models. An individual-based approach is used to relate collective behavior to individual decisions. In our model, the motion of an individual in a herd is assumed to be the combined result of both density-independent and density-dependent decisions, in the latter case based on the influence of surrounding neighbors; assumed decision rules are hierarchical, balancing short range repulsion against long-range attraction. The probability of fragmentation of the model herd depends on parameter values. We explore the variety and characteristics of spatial patterns that develop during migration, for herds that are homogeneous and heterogeneous regarding intrinsic walking speeds. Group integrity can be maintained even in mixed populations, but fragmentation results for these more easily than for a homogeneous herd. Observations of natural populations suggest that animals move away from individuals that intrude too closely into their environment, but are attracted to individuals at a distance. Between these extremes, there appears to be a neutral zone, within which other individuals engender no response. We explore the importance of this neutral zone, and offer evolutionary interpretations. In particular, the neutral zone, if not too large, permits the individual to remain in contact with the herd, while reducing the frequency with which acceleration or deceleration must be undertaken. This offers obvious energetic benefits.",1996-09-07,https://www.semanticscholar.org/paper/4321cc4c4d1306cc7f9d183cc41f577ace63578c,
508,On the optimal bisection of a polygon (extended abstract),We give a polynomial approximation sceme for subdividing a simple polygon into approximately equal parts by curves of the smallest possible total length. For convex polygons we show that an exact fast algorithm is possible. Several generalizations are shown NP-complete.,1990-05-01,https://www.semanticscholar.org/paper/0589ffacc424e9b8d63bcdd21d1ebf1d34f8961c,SCG '90
1049,The LUX-ZEPLIN (LZ) radioactivity and cleanliness control programs,,2020-06-03,https://www.semanticscholar.org/paper/3e9e175902eab398b8a574a23d4311bc66318b74,The European Physical Journal C
1505,1 7 Ju n 20 01 Search for New Physics Using quaero : A General Interface to DØ Event Data,"We describe quaero, a method that i) enables the automatic optimization of searches for physics beyond the standard model, and ii) provides a mechanism for making high energy collider data generally available. We apply quaero to searches for standard model WW , ZZ, and tt̄ production, and to searches for these objects produced through a new heavy resonance. Through this interface, we make three data sets collected by the DØ experiment at √ s = 1.8 TeV publicly available.",,https://www.semanticscholar.org/paper/a0b7b4baa6def9303938424e1c7f93dfae7916c8,
3532,Thriving in a crowded and changing world: C++ 2006–2020,"By 2006, C++ had been in widespread industrial use for 20 years. It contained parts that had survived unchanged since introduced into C in the early 1970s as well as features that were novel in the early 2000s. From 2006 to 2020, the C++ developer community grew from about 3 million to about 4.5 million. It was a period where new programming models emerged, hardware architectures evolved, new application domains gained massive importance, and quite a few well-financed and professionally marketed languages fought for dominance. How did C++ -- an older language without serious commercial backing -- manage to thrive in the face of all that? This paper focuses on the major changes to the ISO C++ standard for the 2011, 2014, 2017, and 2020 revisions. The standard library is about 3/4 of the C++20 standard, but this paper's primary focus is on language features and the programming techniques they support. The paper contains long lists of features documenting the growth of C++. Significant technical points are discussed and illustrated with short code fragments. In addition, it presents some failed proposals and the discussions that led to their failure. It offers a perspective on the bewildering flow of facts and features across the years. The emphasis is on the ideas, people, and processes that shaped the language. Themes include efforts to preserve the essence of C++ through evolutionary changes, to simplify its use, to improve support for generic programming, to better support compile-time programming, to extend support for concurrency and parallel programming, and to maintain stable support for decades' old code. The ISO C++ standard evolves through a consensus process. Inevitably, there is competition among proposals and clashes (usually polite ones) over direction, design philosophies, and principles. The committee is now larger and more active than ever, with as many as 250 people turning up to week-long meetings three times a year and many more taking part electronically. We try (not always successfully) to mitigate the effects of design by committee, bureaucratic paralysis, and excessive enthusiasm for a variety of language fashions. Specific language-technical topics include the memory model, concurrency and parallelism, compile-time computation, move-semantics, exceptions, lambda expressions, and modules. Designing a mechanism for specifying a template's requirements on its arguments that is sufficiently flexible and precise yet doesn't impose run-time costs turned out to be hard. The repeated attempts to design ``concepts'' to do that have their roots back in the 1980s and touch upon many key design issues for C++ and for generic programming. The description is based on personal participation in the key events and design decisions, backed by the thousands of papers and hundreds of meeting minutes in the ISO C++ standards committee's archives.",2020-06-12,https://www.semanticscholar.org/paper/1c2688189548fecf0a030cad80b4cd3dbf98e0bc,Proc. ACM Program. Lang.
689,Learning the structure of manifolds using random projections,We present a simple variant of the k-d tree which automatically adapts to intrinsic low dimensional structure in data.,2007-12-03,https://www.semanticscholar.org/paper/ba0ef595dd32c6d770bc7bc1c155061512f9389b,Neural Information Processing Systems
810,Model checking of hierarchical state machines,"Model checking is emerging as a practical tool for detecting logical errors in early stages of system design. We investigate the model checking of sequential hierarchical (nested) systems, i.e., finite-state machines whose states themselves can be other machines. This nesting ability is common in various software design methodologies, and is available in several commercial modeling tools. The straightforward way to analyze a hierarchical machine is to flatten it (thus incurring an exponential blow up) and apply a model-checking tool on the resulting ordinary FSM. We show that this flattening can be avoided. We develop algorithms for verifying linear-time requirements whose complexity is polynomial in the size of the hierarchical machine. We also address the verification of branching time requirements and provide efficient algorithms and matching lower bounds.",1998-11-01,https://www.semanticscholar.org/paper/d1278ca288db67c98e0d1f4ab42bb3c384bf3b14,TOPL
1361,Search for the Higgs boson in H --> WW(*) decays in pp collisions at square root of 1.96 TeV.,"We present a search for the standard model Higgs boson in H --> WW(*) decays with e+e-, e+/-mu-/+, and mu+mu- final states in pp collisions at a center-of-mass energy of square root of s = 1.96 TeV. The data, collected from April 2002 to June 2004 with the D0 detector, correspond to an integrated luminosity of 300-325 pb(-1), depending on the final state. The number of events observed is consistent with the expectation from backgrounds. Limits from the combination of all three channels on the Higgs boson production cross section times branching ratio sigma x BR(H --> WW(*) are presented.",2005-08-01,https://www.semanticscholar.org/paper/e0ad856dcd7e9e464cc577f88b0bb37671cbb690,Physical Review Letters
571,Updates of Relational Views,"The problem of translating updates of database views is studied. View updates are disambi- guated by requiring that a specified view complement (i.e., a second view that contains all the information omitted from the given view) remain constant during the translation. Some of the computational problems related to the apphcafion of this general methodology in the context of relational databases are studied. Projective views of databases that consist of a single relation and satisfy funcuonal dependencies are emphasized. After characterizing complementary views, the authors show that finding a minimum complement of a given view is NP-complete. The problem of translating the insertion of a tuple into a view is then studied in detail, and the results are extended to the cases of deletion and replacement of a tuple. Finally, the explicit functional dependencies, a new kind of dependency that intuitively states that some part of the database information can be computed from the rest, are defined and studied.",1984-09-20,https://www.semanticscholar.org/paper/2aef3318842c74fa1a9b78f4a0ebcd13a9c2849f,JACM
2977,Non-conjugate Variational Message Passing for Multinomial and Binary Regression,"Variational Message Passing (VMP) is an algorithmic implementation of the Variational Bayes (VB) method which applies only in the special case of conjugate exponential family models. We propose an extension to VMP, which we refer to as Non-conjugate Variational Message Passing (NCVMP) which aims to alleviate this restriction while maintaining modularity, allowing choice in how expectations are calculated, and integrating into an existing message-passing framework: Infer.NET. We demonstrate NCVMP on logistic binary and multinomial regression. In the multinomial case we introduce a novel variational bound for the soft-max factor which is tighter than other commonly used bounds whilst maintaining computational tractability.",2011-12-12,https://www.semanticscholar.org/paper/15bbea3d58ac3f7c21392eaba72b8b166888f81f,Neural Information Processing Systems
15,k-Shape: Efficient and Accurate Clustering of Time Series,"The proliferation and ubiquity of temporal data across many disciplines has generated substantial interest in the analysis and mining of time series. Clustering is one of the most popular data mining methods, not only due to its exploratory power, but also as a preprocessing step or subroutine for other techniques. In this paper, we present k-Shape, a novel algorithm for time-series clustering. k-Shape relies on a scalable iterative refinement procedure, which creates homogeneous and well-separated clusters. As its distance measure, k-Shape uses a normalized version of the cross-correlation measure in order to consider the shapes of time series while comparing them. Based on the properties of that distance measure, we develop a method to compute cluster centroids, which are used in every iteration to update the assignment of time series to clusters. To demonstrate the robustness of k-Shape, we perform an extensive experimental evaluation of our approach against partitional, hierarchical, and spectral clustering methods, with combinations of the most competitive distance measures. k-Shape outperforms all scalable approaches in terms of accuracy. Furthermore, k-Shape also outperforms all non-scalable (and hence impractical) combinations, with one exception that achieves similar accuracy results. However, unlike k-Shape, this combination requires tuning of its distance measure and is two orders of magnitude slower than k-Shape. Overall, k-Shape emerges as a domain-independent, highly accurate, and highly efficient clustering approach for time series with broad applications.",2015-05-27,https://www.semanticscholar.org/paper/8278ca04c4ffafef80abfbe0ce3c6cfc07b2792d,SIGMOD Conference
1893,Real Time Electronic Design Automation (EDA) Scheduling System in IC Design Industry,"Because of the global competition and short life cycle in semiconductor industry, the IC design companies try to keep their competitiveness. Besides the human resources and advanced technology, enhancing the speed of the development is important for market share and time to market. IC designers usually use electronic design automation tool to shorten and verify the development. However, the EDA tools and servers are expensive and limited. Hence, it becomes a critical problem to allocate the resources and schedule the jobs. This study aims to develop the decision support system framework for IC design job scheduling. The framework enhances the throughput and reduces waiting time. In practice, this study implements the proposed framework in an IC design service company in Taiwan as the empirical study. The empirical study reduced 77.4% of waiting time and 60% of makespan.",2019-05-24,https://www.semanticscholar.org/paper/54d3abf600bc226e8743b202150d678b59fa2d60,MSIE 2019
55,Session details: Search engineering 1,,2004-05-17,https://www.semanticscholar.org/paper/2889d7f93a9cdb0f2cc00464b0da6c2708523913,Proceedings of the 13th international conference on World Wide Web
1442,Progress of the Cryogenic Dark Matter Search (CDMS) experiment,,1996-11-01,https://www.semanticscholar.org/paper/bcee7ad54d6d011d5be45c0aafa9d0eae1a99203,
3499,Improved approximation algorithms for unsplittable flow problems,"In the single-source unsplittable flow problem we are given a graph G, a source vertex s and a set of sinks t/sub 1/, ..., t/sub k/ with associated demands. We seek a single s-t/sub i/ flow path for each commodity i so that the demands are satisfied and the total flow routed across any edge e is bounded by its capacity c/sub e/. The problem is an NP-hard variant of max flow and a generalization of single-source edge-disjoint paths with applications to scheduling, load balancing and virtual-circuit routing problems. In a significant development, Kleinberg gave recently constant-factor approximation algorithms for several natural optimization versions of the problem. In this paper we give a generic framework, that yields simpler algorithms and significant improvements upon the constant factors. Our framework, with appropriate subroutines applies to all optimization versions previously considered and treats in a unified manner directed and undirected graphs.",1997-10-19,https://www.semanticscholar.org/paper/bbe009658953de1079b3f4767653b8619047908c,Proceedings 38th Annual Symposium on Foundations of Computer Science
2243,The dual effects of TNFalpha on neutrophil apoptosis are mediated via differential effects on expression of Mcl-1 and Bfl-1.,"Neutrophils have a very short half-life in the circulation, undergoing rapid death by apoptosis, but a number of agents can either delay or accelerate the rate at which these cells undergo death. TNFalpha can exert opposing, concentration-dependent effects on neutrophils to either accelerate their apoptosis or enhance their survival. We show that TNFalpha greatly increases the rate of turnover of Mcl-1, an antiapoptotic protein that plays a key role in neutrophil survival. In contrast to Mcl-1 turnover in control- or granulocyte-macrophage colony-stimulating factor (GM-CSF)-treated neutrophils that occurs via the proteasome, TNFalpha-accelerated Mcl-1 turnover occurs via activation of caspases. Mcl-1-depleted cells thus have accelerated rates of apoptosis. While TNFalpha had no effect on MCL-1 transcription, it induced expression of another antiapoptotic molecule, BFL-1. Low concentrations of TNFalpha (<or=1 ng/mL) stimulated BFL-1 expression, whereas higher concentrations (>or=10 ng/mL) triggered caspase-dependent acceleration of Mcl-1 turnover. These opposing effects on 2 separate antiapoptotic systems of neutrophils explain the divergent effects of TNFalpha on neutrophil apoptosis and have important implications for understanding how TNFalpha may affect immune function in inflammatory diseases.",2008-01-15,https://www.semanticscholar.org/paper/bde83e31c323c2206ab39a28d8c60c8fa2b910fc,Blood
2305,Stimulation of primed neutrophils by soluble immune complexes.,"Soluble IgG-containing immune complexes are unable to initiate oxidant production in unprimed neutrophils. However, priming of the neutrophils with either granulocyte-macrophage colony-stimulating factor (GM-CSF) or cytochalasin B prior to exposure to these complexes results in activation of a rapid and extensive secretion of reactive oxidants. In this study, we have investigated the ability of soluble immune complexes to: (1) induce oxidant generation; (2) bind to the cell surface; and (3) induce Ca2+ transients in neutrophils primed by incubation with GM-CSF or cytochalasin B. Our findings give new insight into the molecular processes involved in the ""priming"" phenomenon.",1996-12-01,https://www.semanticscholar.org/paper/9b21b5fdc7209a894e86c5452c213875fde2758f,Biologicals (Print)
1703,Population Empirical Bayes,"Bayesian predictive inference analyzes a dataset to make predictions about new observations. When a model does not match the data, predictive accuracy suffers. We develop population empirical Bayes (POP-EB), a hierarchical framework that explicitly models the empirical population distribution as part of Bayesian analysis. We introduce a new concept, the latent dataset, as a hierarchical variable and set the empirical population as its prior. This leads to a new predictive density that mitigates model mismatch. We efficiently apply this method to complex models by proposing a stochastic variational inference algorithm, called bumping variational inference (BUMP-VI). We demonstrate improved predictive accuracy over classical Bayesian inference in three models: a linear regression model of health data, a Bayesian mixture model of natural images, and a latent Dirichlet allocation topic model of scientific documents.",2014-11-02,https://www.semanticscholar.org/paper/7b22ad7650211047208dfa2cd1cc69cea71851f8,Conference on Uncertainty in Artificial Intelligence
841,Approximate max-flow min-(multi)cut theorems and their applications,"Consider the multicommodity flow problem in which the object is to maximize the sum of commodities routed. We prove the following approximate max-flow min-multicut theorem: $$ \dst \frac{\mbox{\rm min multicut}}{O(\log k)} \leq \mbox{ \rm max flow } \leq \mbox{ \rm min multicut}, $$ \noindent where $k$ is the number of commodities. Our proof is constructive; it enables us to find a multicut within $O(\log k)$ of the max flow (and hence also the optimal multicut). In addition, the proof technique provides a unified framework in which one can also analyse the case of flows with specified demands of Leighton and Rao and Klein et al. and thereby obtain an improved bound for the latter problem.",1993-06-01,https://www.semanticscholar.org/paper/a2ad294dced8fe080cf9eb9a2aabd7cb4a5eb74a,SIAM journal on computing (Print)
2591,Introduction to computer graphics,"Computer graphics is an exciting field of endeavor, but it is often difficult for a newcomer to get started. This course is that opportunity! The topics being presented will address many areas within computer graphics and treat each from the point of view of ""why-do-I-care"" and ""how-to."" Those who take this course will emerge well-prepared to take on further study, including the taking of other SIGGRAPH courses. Attendees will also be ready to take on the vendor show and better appreciate the Electronic Theatre. We hope you enjoy reading and using these notes as much as we enjoyed preparing them.",2004-08-08,https://www.semanticscholar.org/paper/07de518de3b47427a38f5be2f15f538a0a22686f,International Conference on Computer Graphics and Interactive Techniques
2677,Computer vision in 3D interactivity (panel),"With microprocessor clock rates in excess of 350MHz, SIMD integer instructions commonplace, and shared memory multiprocessing available for under $3,000.00, integration of computer vision with 3D graphics is now more practical than ever. Tracking the user’s head, hands, and body, and detecting gestures, is one obvious direction to explore to eliminate encumbering sensors and enable new modes of interaction. Another direction is using computer vision techniques to understand 3D structure and camera parameters in multi-view imagebased scenes for the purpose of re-rendering the scenes as a user directs. Yet another is giving animated characters visual awareness of users and other characters to enable richer interactions. What will be the most compelling integration of computer vision with 3D graphics?",1998-07-21,https://www.semanticscholar.org/paper/9d5253924091fb0509a019a243f91897ba2db2eb,International Conference on Computer Graphics and Interactive Techniques
374,A BGP-based mechanism for lowest-cost routing,,2002-07-21,https://www.semanticscholar.org/paper/9697f782ee1fb60ec9c5030422eea7f7b5f8f628,ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing
2516,Comparing steering-based travel techniques for search tasks in a CAVE,"We present a novel bimanual body-directed travel technique, PenguFly (PF), and compare it with two standard travel-by-pointing techniques by conducting a between-subject experiment in a CAVE. In PF, the positions of the user's head and hands are projected onto the ground, and travel direction and speed are computed based on direction and magnitude of the vector from the midpoint of the projected hand positions to the projected head position. The two baseline conditions both use a single hand to control the direction, with speed controlled discretely by button pushes with the same hand in one case, and continuously by the distance between the hands in the other case. Users were asked to travel through a simple virtual world and collect virtual coins within a set time. We found no significant differences between travel conditions for reported presence or usability, but a significant increase in nausea with PF. Total travel distance was significantly higher for the baseline condition with discrete speed selection, whereas travel accuracy in terms of coin-to-distance ratio was higher with PF.",2011-03-19,https://www.semanticscholar.org/paper/f805897ba10f8fdb69a9f8d57a305b189e3be02c,IEEE Conference on Virtual Reality and 3D User Interfaces
2636,A graphical user interface toolkit approach to thin-client computing,"Network and server-centric computing paradigms are quickly returning to being the dominant methods by which we use computers. Web applications are so prevalent that the role of a PC today has been largely reduced to a terminal for running a client or viewer such as a Web browser. Implementers of network-centric applications typically rely on the limited capabilities of HTML, employing proprietary ""plug ins"" or transmitting the binary image of an entire application that will be executed on the client. Alternatively, implementers can develop without regard for remote use, requiring users who wish to run such applications on a remote server to rely on a system that creates a virtual frame buffer on the server, and transmits a copy of its raster image to the local client.We review some of the problems that these current approaches pose, and show how they can be solved by developing a distributed user interface toolkit. A distributed user interface toolkit applies techniques to the high level components of a toolkit that are similar to those used at a low level in the X Window System. As an example of this approach, we present RemoteJFC, a working distributed user interface toolkit that makes it possible to develop thin-client applications using a distributed version of the Java Foundation Classes.",2002-05-07,https://www.semanticscholar.org/paper/ac923ea792134f229a4b6519ce0447fb14ca5287,The Web Conference
2029,Requirement estimation for indirect workforce allocation in semiconductor manufacturing,"This work, based on a real case, presents a model to estimate indirect workforce requirements of semiconductor fabrication facilities (fabs) so that the workforce can be fairly allocated. There is a concern in a real setting to fairly allocate the overall corporate workforce among the fabs, particularly when they compete in performance, and properly determining the actual requirement is the most critical in the decision process. The actual requirements of the workforce, especially the indirect workforce, for fabs may be indeterminate due to the lack of a well-defined workforce-output relationship. This paper presents a non-parametric frontier approach for estimating the indirect workforce, and the estimate is based on the best past performance adjusted to reflect the expected productivity growth. An empirical study was conducted in a leading foundry in Taiwan that has a number of 8-inch fabs. The proposed (re)allocation approach can provide an explicit decision support mechanism to balance the workloads in light of various production environments to enable an equitable basis for performance evaluation to foster constructive competition among the fabs.",2010-01-15,https://www.semanticscholar.org/paper/ebff970af58ae3b550d1cb20c4239e84b6f3bc6e,
3765,Visualizing Object Detection Features,,2015-02-18,https://www.semanticscholar.org/paper/54bf134b47bdadbf2dd04956cf51076d4f26ce01,International Journal of Computer Vision
2855,Toxoplasma gondii infection reveals a novel regulatory role for galectin-3 in the interface of innate and adaptive immunity.,"In attempts to investigate the role of galectin-3 in innate immunity, we studied galectin-3-deficient (gal3-/-) mice with regard to their response to Toxoplasma gondii infection, which is characterized by inflammation in affected organs, Th-1-polarized immune response, and accumulation of cysts in the central nervous system. In wild-type (gal3+/+) mice, infected orally, galectin-3 was highly expressed in the leukocytes infiltrating the intestines, liver, lungs, and brain. Compared with gal3+/+, infected gal3-/- mice developed reduced inflammatory response in all of these organs but the lungs. Brain of gal3-/- mice displayed a significantly reduced number of infiltrating monocytes/macrophages and CD8+ cells and a higher parasite burden. Furthermore, gal3-/- mice mounted a higher Th1-polarized response and had comparable survival rates on peroral T. gondii infection, even though they were more susceptible to intraperitoneal infection. Interestingly, splenic cells and purified CD11c+ dendritic cells from gal3-/- mice produced higher amounts of interleukin-12 than cells from gal3+/+ mice, possibly explaining the higher Th1 response verified in the gal3-/- mice. We conclude that galectin-3 exerts an important role in innate immunity, including not only a pro-inflammatory effect but also a regulatory role on dendritic cells, capable of interfering in the adaptive immune response.",2006-06-01,https://www.semanticscholar.org/paper/2a9e45578b4fa9651f0ed44e4dd08120ea7cacb4,American Journal of Pathology
869,Graph-theoretic methods in database theory,"As in many areas of computer science and other disciplines, graph theoretic tools play an important role also in databases. Many concepts are best captured in terms of graphs or hypergraphs, and problems can then be formulated and solved using graph theoretic algorithms. There is a great number of such examples from schema design, dependency theory, transaction processing, query optimization, data distribution, and a host of other areas. We will not attempt to touch on the wide range of all these applications. Rather, we will concentrate on a particular, basic type of problems that has attracted a great deal of attention in the database literature over the last few years and has come to play a central role: techniques for searching graphs and computing transitive closure, and some of the applications and related problems in query processing. There is an extensive literature on these types of problems, which we cannot reasonably hope to cover in this space, but we shall give a flavour of the issues that arise in solving these problems in various frameworks.",1990-04-02,https://www.semanticscholar.org/paper/62fa835ba18dfac1e5ee801da1e27634cc5370e7,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
349,Turing ’ s Imitation Game : a discussion with the benefit of hindsight,"Alan Turing proposed the imitation game in his 1950 paper titled “Computing Machinery and Intelligence” [1]. This paper discussed the arguments for and against artificial intelligence that existed then. Since this time, science has advanced in areas of neuroscience, machine learning, and computer theory granting us a different perspective on the argument. This paper discusses the history of Artificial Intelligence (AI), progress made in the field, and the arguments against AI. It also summarizes the discussion from the 19 October meeting of “Reading the Classics.""",,https://www.semanticscholar.org/paper/ef00277a66f4ea885cdf44ca16fca0dd740fa830,
826,Testing Finite State Machines: Fault Detection,"Abstract We present simple randomized algorithms for the fault detection problem: Given a specification in the form of a deterministic finite state machine A and an implementation machine B, determine whether B is equal to A. If A has n states and p inputs, then in randomized polynomial time we can construct with high probability a checking sequence of length O(pn4 log n), i.e., a sequence that detects all faulty machines with at most n states. Better bounds can be obtained in certain cases. The techniques generalize to partially specified finite state machines.",1995-04-01,https://www.semanticscholar.org/paper/af20258b9728c146715ecf5515d58c88f61b42eb,Journal of computer and system sciences (Print)
1484,Study of two photon production of rho0 omega in e+ e- interactions,,,https://www.semanticscholar.org/paper/b7f1df642f57220aa1317bb6c31360d99d8a162a,
1040,MECHANICS AND CONTROL OF A TERRESTRIAL VEHICLE EXPLOITING A NONHOLONOMIC CONSTRAINT FOR FISHLIKE LOCOMOTION,"We present a novel mechanical system, the “landfish,” which takes advantage of a combination of articulation and a nonholonomic constraint to exhibit fishlike locomotion. We apply geometric mechanics techniques to establish the equations of motion in terms of the system’s nonholonomic momentum and analyze the system’s equilibrium properties. Finally, we demonstrate its locomotion capabilities under several controllers, including heading and joint velocity control.",2013-10-21,https://www.semanticscholar.org/paper/aeb6e83ecdfcf44c5cb286f3a8f7d1f8c9cf7f6c,
2201,Interferon gene expression signature in rheumatoid arthritis neutrophils correlates with a good response to TNFi therapy.,"OBJECTIVE
The aim of this study was to use whole transcriptome sequencing (RNA-Seq) of RA neutrophils to identify pre-therapy gene expression signatures that correlate with disease activity or response to TNF inhibitor (TNFi) therapy.


METHODS
Neutrophils were isolated from the venous blood of RA patients (n = 20) pre-TNFi therapy and from healthy controls (n = 6). RNA was poly(A) selected and sequenced on the Illumina HiSeq 2000 platform. Reads were mapped to the human genome (hg19) using TopHat and differential expression analysis was carried out using edgeR (5% false discovery rate). Signalling pathway analysis was carried out using Ingenuity Pathway Analysis (IPA) software. IFN signalling was confirmed by western blotting for phosphorylated signal transducer and activator of transcription (STAT) proteins. Response to TNFi was measured at 12 weeks using change in the 28-item DAS (DAS28).


RESULTS
Pathway analysis with IPA predicted activation of IFN signalling in RA neutrophils, identifying 178 IFN-response genes regulated by IFN-α, IFN-β or IFN-γ (P < 0.01). IPA also predicted activation of STAT1, STAT2 and STAT3 transcription factors in RA neutrophils (P < 0.01), which was confirmed by western blotting. Expression of IFN-response genes was heterogeneous and patients could be categorized as IFN-high or IFN-low. Patients in the IFN-high group achieved a better response to TNFi therapy [ΔDAS28, P = 0.05, odds ratio (OR) 1.4 (95% CI 1.005, 1.950)] than patients in the IFN-low group. The level of expression of IFN-response genes (IFN score) predicted a good response [European League Against Rheumatism (EULAR) criteria] to TNFi using receiver operating characteristic curve analysis (area under the curve 0.76).


CONCLUSION
IFN-response genes are significantly up-regulated in RA neutrophils compared with healthy controls. Higher IFN-response gene expression in RA neutrophils correlates with a good response to TNFi therapy.",,https://www.semanticscholar.org/paper/e315426625933e9b8a140832936abcd8dd79b8c3,Rheumatology
3186,Vaccination-hesitancy and global warming: distinct social challenges with similar behavioural solutions,"Although the COVID-19 vaccine has dramatically changed the fight against the pandemic, many exhibit vaccination-hesitancy. At the same time, continued human-induced emissions of greenhouse gases pose an alarming threat to humanity. Based on the theory of Subjective Expected Relative Similarity (SERS) and a recent international study that drastically modified COVID-19 health-related attitudes, we explain why a similar approach and a corresponding public policy are expected to help resolve both behavioural issues: reduce vaccination hesitancy and motivate climate actions.",2022-06-01,https://www.semanticscholar.org/paper/fdd9672af55d0d9e161f4c0cf97dd51138211e29,Royal Society Open Science
351,Turing - a novel about computation,"Our hero is Turing, an interactive tutoring program and namesake (or virtual emanation?) of Alan Turing, World War II code breaker and father of computer science. In this unusual novel, Turing's idiosyncratic version of intellectual history from a computational point of view unfolds in tandem with the story of a love affair involving Ethel, a successful computer executive, Alexandros, a melancholy archaeologist, and Ian, a charismatic hacker. After Ethel (who shares her first name with Alan Turing's mother) abandons Alexandros following a sundrenched idyll on Corfu, Turing appears on Alexandros's computer screen to unfurl a tutorial on the history of ideas. He begins with the philosopher-mathematicians of ancient Greece--""discourse, dialogue, argument, proof...can only thrive in an egalitarian society""--and the Arab scholar in ninth-century Baghdad who invented algorithms; he moves on to many other topics, including cryptography and artificial intelligence, even economics and developmental biology. (These lessons are later critiqued amusingly and developed further in postings by a fictional newsgroup in the book's afterword.) As Turing's lectures progress, the lives of Alexandros, Ethel, and Ian converge in dramatic fashion, and the story takes us from Corfu to Hong Kong, from Athens to San Francisco--and of course to the Internet, the disruptive technological and social force that emerges as the main locale and protagonist of the novel. Alternately pedagogical and romantic, Turing (A Novel about Computation) should appeal both to students and professionals who want a clear and entertaining account of the development of computation and to the general reader who enjoys novels of ideas.",2003-10-10,https://www.semanticscholar.org/paper/16bc3079002a1b81da1c25dd9adb4a32ab28e34b,
3589,Proposed Wording for Concepts (Revision 3),Introduction This document provides proposed wording for concepts. Readers unfamiliar with concepts are encouraged to read the complete proposal [1]. This document provides wording for changes to the core language. Changes to the standard library are discussed in separate documents: — Concepts for the C++0x Standard Library: Approach [N2036=06-0106] — Concepts for the C++0x Standard Library: Introduction [N2037=06-0107] — Concepts for the C++0x Standard Library: Utilities (Revision 2) [N2322=07-0182] — Concepts for the C++0x Standard Library: Containers [N2085=06-0155] — Concepts for the C++0x Standard Library: Iterators (Revision 2) [N2323=07-0183] — Concepts for the C++0x Standard Library: Algorithms (Revision 1) [N2084=06-0154] — Concepts for the C++0x Standard Library: Numerics [N2041=06-0111],,https://www.semanticscholar.org/paper/682f7ea24c6e3d0c43f00fd900704d6f53696480,
1156,Ju n 20 09 Fermilab-Pub-09 / 006-E Search for resonant diphoton production with the D 0 detector,,,https://www.semanticscholar.org/paper/6cd1f1e18abb814ea8b235200f8810d41b000dde,
2861,Impaired retinal angiogenesis in diabetes: role of advanced glycation end products and galectin-3.,"Suppression of angiogenesis during diabetes is a recognized phenomenon but is less appreciated within the context of diabetic retinopathy. The current study has investigated regulation of retinal angiogenesis by diabetic serum and determined if advanced glycation end products (AGEs) could modulate this response, possibly via AGE-receptor interactions. A novel in vitro model of retinal angiogenesis was developed and the ability of diabetic sera to regulate this process was quantified. AGE-modified serum albumin was prepared according to a range of protocols, and these were also analyzed along with neutralization of the AGE receptors galectin-3 and RAGE. Retinal ischemia and neovascularization were also studied in a murine model of oxygen-induced proliferative retinopathy (OIR) in wild-type and galectin-3 knockout mice (gal3(-/-)) after perfusion of preformed AGEs. Serum from nondiabetic patients showed significantly more angiogenic potential than diabetic serum (P < 0.0001) and within the diabetic group, poor glycemic control resulted in more AGEs but less angiogenic potential than tight control (P < 0.01). AGE-modified albumin caused a dose-dependent inhibition of angiogenesis (P < 0.001), and AGE receptor neutralization significantly reversed the AGE-mediated suppression of angiogenesis (P < 0.01). AGE-treated wild-type mice showed a significant increase in inner retinal ischemia and a reduction in neovascularization compared with non-AGE controls (P < 0.001). However, ablation of galectin-3 abolished the AGE-mediated increase in retinal ischemia and restored the neovascular response to that seen in controls. The data suggest a significant suppression of angiogenesis by the retinal microvasculature during diabetes and implicate AGEs and AGE-receptor interactions in its causation.",2005-03-01,https://www.semanticscholar.org/paper/10a39a1c3c2236902bf5a3f0674474fee5143f2f,Diabetes
779,2. Computational complexity,,2003-12-31,https://www.semanticscholar.org/paper/6819884a3b52437880c5863e6ef46d2d9ec807b7,
1225,Observation ofProduction inCollisions at,,2008-10-23,https://www.semanticscholar.org/paper/6ede44ad902332acd1de536622f8bf5da5b32c9d,
430,"On kernels, defaults and even graphs",,1997-01-09,https://www.semanticscholar.org/paper/1bdacb0d3267afb98a6dce652ee81dee58e56756,Annals of Mathematics and Artificial Intelligence
3547,A Tour of C,,2013-09-16,https://www.semanticscholar.org/paper/de53a09e00d2d3b325a9d0483e39b240ea42e86d,
2093,Developing statistical models in an early warning system and its empirical study,"When a new equipment or process is released, it is critical to ensure it behave as expected and stay in normal condition. The study proposes a research framework in which a statistical model is constructed for newly released equipment and process monitoring. An empirical study is conducted in a DRAM fabrication facility for validation. Based on the model, a best set of sample test items which discriminates the newly released equipment is selected and a group of normal equipments is obtained. Thus, the alarm signals can be triggered in an early warning system.",2004-09-09,https://www.semanticscholar.org/paper/0afbdfbb2b8668a6c832ecad0226fd2768813b28,2004 Semiconductor Manufacturing Technology Workshop Proceedings (IEEE Cat. No.04EX846)
2105,Analyzing Alternative Strategies of Semiconductor Final Testing,,,https://www.semanticscholar.org/paper/3432c04c2b31330dd598af54a743763e66b2daa6,
2722,Automated presentation planning of animation using task decomposition with heuristic reasoning,"We describe ESPLANADE (Expert System for PLANning Animation, Design, and Editing), a knowledge-based animation presentation planner. ESPLANADE receives as input a script generated by a separate action planner and a set of communicative goals that specify what the animation is to communicate to the viewer. The presentation plan that ESPLANADE creates is a complete description of every frame of an animation and includes viewing specifications, viewport dimensions, and object properties. Instead of treating animation as a flat sequence of frames, our approach is to use a top-down task decomposition strategy with heuristic reasoning to build a frame-based semantic representation of an animation. The structure built by ESPLANADE is a hierarchy of sequences, scenes, and shots, based on a representation used by filmmakers . This approach allows the planning to be performed with contextual information that is inferred while building the semantic representation and results in a better animation . . We demonstrate our system with a detailed example of a generated animation.",,https://www.semanticscholar.org/paper/cc18c1a3b3e8973e329620f3ab82392612223ca9,
2364,Impaired neutrophil killing in a patient with defective degranulation of myeloperoxidase.,"A case of recurrent, superficial abscesses in an 18 year old girl, is described. Staphylococcus aureus was the pathogen most often implicated and on several occasions the abscesses required surgical drainage. Defects in humoral immunity, neutrophil chemotaxis or opsonophagocytosis were not observed. However, her neutrophil's ability to kill ingested S. aureus in vitro was impaired. This was associated with impaired luminol-dependent chemiluminescence in response to stimulation by either latex beads, or the chemotactic peptide FMLP plus cytochalasin B. Oxygen uptake and superoxide anion production were normal but release of myeloperoxidase by this patient's neutrophils occurred more slowly and to a lower extent than in control cells. These data suggest that the recurrent infections and diminished in vitro neutrophil bactericidal activity observed in this patient are associated with impaired degranulation of myeloperoxidase.",1988-04-01,https://www.semanticscholar.org/paper/8fa6bd51379d11d50f5317c728a67e6b5c0fbeae,Journal of clinical & laboratory immunology
3702,Causal Transportability for Visual Recognition,"Visual representations underlie object recognition tasks, but they often contain both robust and non-robust features. Our main observation is that image classifiers may perform poorly on out-of-distribution samples because spurious correlations between non-robust features and labels can be changed in a new environment. By analyzing procedures for out-of-distribution generalization with a causal graph, we show that standard classifiers fail because the association between images and labels is not transportable across settings. However, we then show that the causal effect, which severs all sources of confounding, remains invariant across domains. This motivates us to develop an algorithm to estimate the causal effect for image classification, which is transportable (i.e., invariant) across source and target environments. Without observing additional variables, we show that we can derive an estimand for the causal effect under empirical assumptions using representations in deep models as proxies. Theoretical analysis, empirical results, and visualizations show that our approach captures causal invariances and improves overall generalization.",2022-04-26,https://www.semanticscholar.org/paper/b400b066929e8070842b33b450fe69698c5ed826,Computer Vision and Pattern Recognition
2119,MODELING OVERLAY ERRORS AND SAMPLING STRATEGIES TO IMPROVE YIELD,"ABSTRACT Overlay is one of the key designed rules for producing VLSI devices. In order to have a better resolution and alignment accuracy in lithography process, it is important to model the overlay errors and then to compensate them into tolerances. This study aimed to develop a new model that bridges the gap between the existing theoretical models and the data obtained in real settings and to discuss the overlay sampling strategies with empirical data in a wafer fab. In addition, we used simulation to examine the relations between the various factors and the caused overlay errors. This paper concluded with discussions on further research.",2001-01-01,https://www.semanticscholar.org/paper/f7d8b0b88a72cc97476d0c055915e9d7d797bd6c,
2929,Distinct Classes of Complex Structural Variation Uncovered across Thousands of Cancer Genome Graphs,,2020-10-01,https://www.semanticscholar.org/paper/69c0c194ac64239a6149fbe07e45671c35ea61ba,Cell
852,Tie-breaking semantics and structural totality,"We address the question of when the structure of a Datalog program with negation guarantees the existence of a fixpoint. We propose a semantics of Datalog programs with negation, which we call the tie–breaking semantics. The tie–breaking semantics can be computed in polynomial time, and results in a fix-point whenever the rule–goal graph of the program has no cycle with an odd number of negative edges. We show that, in some well-defined sense, this is the most general fixpoint semantics of negation possible; in particular we show that if a cycle with an odd number of negative edges is present, then the logic program is not structurally total, that is, it has an alphabetic variant which has no fixpoint semantics whatsoever. Determining whether a program is (nonstructurally) total is undecidable.",1992-07-01,https://www.semanticscholar.org/paper/c5fe320a1643d77975ccfa05394d31dfa5b0a4d9,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
1236,Search for large extra dimensions via single photon plus missing energy final states at sqrt s = 1.96 TeV.,We report on a search for large extra dimensions in a data sample of approximately 1 fb(-1) of pp[over] collisions at sqrt s=1.96 TeV. We investigate Kaluza-Klein graviton production with a photon and missing transverse energy in the final state. At the 95% C.L. we set limits on the fundamental mass scale M(D) from 884 to 778 GeV for two to eight extra dimensions.,,https://www.semanticscholar.org/paper/8947c5688408cc22299b6fab270544839b781cab,Physical Review Letters
1454,The first cryogenic dark matter experiment,,1993-11-01,https://www.semanticscholar.org/paper/541494242fa4f1628a8690d0619275a148d6c12f,
708,Alembic: Automated Model Inference for Stateful Network Functions,"Network operators today deploy a wide range of complex, stateful network functions (NFs). Typically, they only have access to the NFs’ binary executables, configuration interfaces, and manuals from vendors. To ensure correct behavior of NFs, operators use network testing and verification tools, which often rely on models of the deployed NFs. The effectiveness of these tools depends on the fidelity of such models. Today, models are handwritten, which can be error prone, tedious, and does not account for implementation-specific artifacts. To address this gap, our goal is to automatically infer behavioral models of stateful NFs for a given configuration. The problem is challenging because NF configurations can contain diverse rule types and the space of dynamic and stateful NF behaviors is large. In this work, we present Alembic, which synthesizes NF models viewed as an ensemble of finite-state machines (FSMs). Alembic consists of an offline stage that learns symbolic FSM representations for each NF rule type and an online stage that generates a concrete behavioral model for a given configuration using these symbolic FSMs. We demonstrate that Alembic is accurate, scalable, and sheds light on subtle differences across NF implementations.",,https://www.semanticscholar.org/paper/b4295b05ed4efd680880230883fecf71c1d60059,Symposium on Networked Systems Design and Implementation
2494,Subtle cueing for visual search in augmented reality,"Visual search in augmented reality environments is an important task that can be facilitated through different cueing methods. Current cueing methods rely on explicit cueing, which can potentially reduce visual search performance. In comparison, this paper proposes a subtle cueing method that improves visual search performance while being clutter-neutral. Two empirical user studies were conducted to evaluate our subtle cueing method in outdoor scenes. The results show that subtle cueing functions well within a narrow Feature Congestion range, and could be a feasible alternative to explicit cueing.",2012-11-05,https://www.semanticscholar.org/paper/4c2b484e5723b015ec7c20c9b7b3d16bb5c7cc67,International Symposium on Mixed and Augmented Reality
500,How to learn an unknown environment,"The authors consider the problem faced by a newborn that must explore and learn an unknown room with obstacles in it. They seek algorithms that achieve a bounded ratio of the worst-case distance traversed in order to see all visible points of the environment (thus creating a map), divided by the optimum distance needed to verify the map. The situation is complicated by the fact that the latter offline problem (optimally verifying a map) is NP-hard and thus must be solved approximately. Although the authors show that there is no such competitive algorithm for general obstacle courses, they give a competitive algorithm for the case of a polygonal room with a bounded number of obstacles in it.<<ETX>>",1991-09-01,https://www.semanticscholar.org/paper/76796667145fda08526b455d23e66952ba17eaca,[1991] Proceedings 32nd Annual Symposium of Foundations of Computer Science
3318,Combining Strategies to Select Reserves in Fragmented Landscapes,"Abstract:  In the identification of reserve networks in fragmented landscapes with limited species‐specific data at hand, one approach is to use selection criteria, such as patch size, to rank the habitat patches' conservation value and evaluate reserve‐network alternatives. These criteria are assumed to be reasonable surrogates for the true network objectives. Caution is warranted, however, because the relationships between the selection criteria and the reserve‐network objectives may be inconsistent. Conflicts are also likely to arise because no single reserve network will be optimal with respect to multiple objectives (or selection criteria) simultaneously. Instead, reserve planners must compromise between conflicting demands. We field tested the relationships between a variety of selection criteria and the objectives of a reserve network for the sandplain natural communities on Martha's Vineyard Island, Massachusetts (U.S.A.). Selection criteria that correlated with the reserve‐network objectives were used in a multi‐objective integer program to identify the 10‐patch reserve networks that were optimal with each objective independently and those that offered optimal tradeoffs between the reserve‐network objectives. From these 10‐patch networks, one can select a final reserve network that provides the preferred compromise between the objectives.",2004-08-01,https://www.semanticscholar.org/paper/ecd3ab87007b5657ccffbff9eac303f28c248f14,
94,Performance of Multiattribute Top-K Queries on Relational Systems,"In many applications, users specify target values for the attributes of a relation, and expect in return the k tuples that best match these values. Traditional RDBMSs do not process these “top-k queries” efficiently. In our previous work, we outlined a family of strategies to map a top-k query into a traditional selection query that a RDBMS can process efficiently. The goal of such mapping strategies is to get all needed tuples (but minimize the number of retrieved tuples) and thus avoid “restarts” to get additional tuples. Unfortunately, no single mapping strategy performed consistently the best under all data distributions. In this paper, we develop a novel mapping technique that leverages information about the data distribution and adapts itself to the local characteristics of the data and the histograms available to do the mapping. We also report the first experimental evaluation of the new and old mapping strategies over a real RDBMS, namely over Microsoft’s SQL Server 7.0. The experiments show that our new techniques are robust and significantly more efficient than previously known strategies requiring at least one sequential scan of the data sets.",,https://www.semanticscholar.org/paper/175a7e3e4674b31ca622c49d0307a1e9e3f93ab5,
328,Algorithmic Problems in Ad Hoc Networks,,2005-06-30,https://www.semanticscholar.org/paper/27862eab7e0a36d732e788b2080a25b7a9636f30,International Conference on Distributed Computing in Sensor Systems
1655,Comment,"Blei, D. M., Griffiths, T. L., and Jordan, M. I. (2010), “The Nested Chinese Restaurant Process and Bayesian Nonparametric Inference of Topic Hierarchies,” Journal of the ACM (JACM), 57, 7. [1407] Pauca, V. P., Piper, J., and Plemmons, R. J. (2006), “NonnegativeMatrix Factorization for Spectral Data Analysis,” Linear Algebra and Its Applications, 416, 29–47. [1407] Pauca, V. P., Shahnaz, F., Berry, M. W., and Plemmons, R. J. (2004), “Text Mining Using Non-Negative Matrix Factorizations,” in SDM (Vol. 4), SIAM, pp. 452–456. [1407] Price, B. S., Geyer, C. J., and Rothman, A. J. (2015), “Ridge Fusion in Statistical Learning,” Journal of Computational and Graphical Statistics, 24, 439–454. [1407]",2016-10-01,https://www.semanticscholar.org/paper/7346ef92076885eb6b59e55027c32cb1fa142a06,
3392,Scheduling When You Do Not Know the Number of Machines,"Often in a scheduling problem, there is uncertainty about the jobs to be processed. The issue of uncertainty regarding the machines has been much less studied. In this article, we study a scheduling environment in which jobs first need to be grouped into some sets before the number of machines is known, and then the sets need to be scheduled on machines without being separated. To evaluate algorithms in such an environment, we introduce the idea of an α-robust algorithm, one that is guaranteed to return a schedule on any number m of machines that is within an α factor of the optimal schedule on m machine, where the optimum is not subject to the restriction that the sets cannot be separated. Under such environment, we give a (5\3+ε)-robust algorithm for scheduling on parallel machines to minimize makespan and show a lower bound 4\3. For the special case when the jobs are infinitesimal, we give a 1.233-robust algorithm with an asymptotic lower bound of 1.207. We also study a case of fair allocation, where the objective is to minimize the difference between the maximum and minimum machine load.",2019-11-15,https://www.semanticscholar.org/paper/dba7ac9f2c38409f746e80c791a192911b60d737,ACM Trans. Algorithms
2469,Spatial computing,"Knowing where you are in space and time promises a deeper understanding of neighbors, ecosystems, and the environment.",2015-12-21,https://www.semanticscholar.org/paper/8f2a05700ec83896bd0efd4755a26e24e3e57d3b,Communications of the ACM
2345,Protein kinase C-dependent and -independent activation of the NADPH oxidase of human neutrophils.,"The protein kinase C inhibitor, staurosporine, inhibited NADPH oxidase activity of human neutrophils activated by phorbol myristate acetate. However, this inhibitor had no effect on either the initiation or the maximal rate of O2- secretion activated by the chemotactic peptide, fMet-Leu-Phe, but resulted in a more rapid termination of oxidant production. Similarly, staurosporine had no effect on the rapid (1 min) increase in luminol-dependent chemiluminescence activated by fMet-Leu-Phe, but the second (intracellular) phase of oxidant production was inhibited. The initial burst of oxidant production during phagocytosis was similarly protein kinase C-independent, but again the later phases of oxidase activity were staurosporine-sensitive. Neutrophils loaded with Quin-2 at concentrations sufficient to act as a Ca2+ buffer could not secrete O2- in response to fMet-Leu-Phe; although the initial (protein kinase C-independent) burst of luminol chemiluminescence was not observed in fMet-Leu-Phe-stimulated Ca2(+)-buffered cells, the second phase of (protein kinase C-dependent) oxidant production was largely unaffected. Hence, the initial burst of oxidant production activated by fMet-Leu-Phe, opsonized zymosan, and latex beads is independent of the activity of protein kinase C-dependent intracellular activation processes, but the activity of this kinase is required to extend or sustain the duration of oxidant production.",1991-04-25,https://www.semanticscholar.org/paper/8ded598e0b3951647253fd6e183c7c4a28f5fb1a,Journal of Biological Chemistry
2675,A Distributed 3 D Graphics Library,"We present Repo-3D, a general-purpose, object-oriented library developing distributed, interactive 3D graphics applications acr a range of heterogeneous workstations. Repo-3D is designe make it easy for programmers to rapidly build prototypes usin familiar multi-threaded, object-oriented programming paradig All data sharing of both graphical and non-graphical data is do via general-purpose remote and replicated objects, presenting illusion of a single distributed shared memory. Graphical obje are directly distributed, circumventing the “duplicate databas problem and allowing programmers to focus on the applicat details. Repo-3D is embedded in Repo, an interpreted, lexically-scop distributed programming language, allowing entire applications be rapidly prototyped. We discuss Repo-3D’s design, and introd the notion of local variations to the graphical objects, which allow local changes to be applied to shared graphical structures. L variations are needed to support transient local changes, suc highlighting, and responsive local editing operations. Finally, w discuss how our approach could be applied using other progr ming languages, such as Java.",,https://www.semanticscholar.org/paper/7704c099a3abb3a8cc04ede915ad29cefbc404f8,
2295,Stimulation of Intracellular Ca2+ Levels in Human Neutrophils by Soluble Immune Complexes,"Soluble immune complexes bind to unprimed neutrophils and generate intracellular Ca2+transients but fail to activate the NADPH oxidase. Following priming of the neutrophils with either tumor necrosis factor α or granulocyte-macrophage colony-stimulating factor, stimulation of the cells with the soluble immune complexes leads to an enhanced Ca2+ signal and significant secretion of reactive oxidants. The enhanced Ca2+ signal observed in primed neutrophils results from the influx of Ca2+ from the external environment and is partly sensitive to tyrosine kinase inhibitors. This is in contrast to the Ca2+ signal observed in unprimed neutrophils, which arises from the mobilization of intracellular stores. When the surface expression of FcγRIIIb on primed neutrophils was decreased either through incubation with Pronase or phosphoinositide-specific phospholipase C, the extra enhanced Ca2+ mobilization seen in primed cells was significantly lowered, while the initial rise in intracellular Ca2+ was unaffected. Depletion of FcγRIIIb had no significant effect on the Ca2+ transients in unprimed neutrophils. Cross-linking FcγRII, but not FcγRIIIb, induced increases in intracellular Ca2+ in unprimed neutrophils, while cross-linking either of these receptors increased Ca2+ levels in primed neutrophils. The FcγRII-dependent intracellular Ca2+ rise in primed cells was unaffected by incubation in Ca2+-free medium, whereas the FcγRIIIb-dependent transient was significantly decreased when Ca2+ influx was prevented in Ca2+-free medium supplemented with EGTA. Cross-linking either FcγRII or FcγRIIIb in primed or unprimed cells failed to stimulate substantial levels of inositol 1,4,5-trisphosphate production. These results indicate that following stimulation of primed neutrophils with soluble immune complexes the enhanced Ca2+ mobilization observed is the result of a functional activation of the glycosylphosphatidylinositol-linked FcγRIIIb.",1997-07-18,https://www.semanticscholar.org/paper/2b09547913a5f27e2c24b8888db636fad775c082,Journal of Biological Chemistry
33,Querying text databases and the web: beyond traditional keyword search,"Traditional keyword search---where a query is a list of keywords and query results are a relevance-ordered list of documents---is, of course, a powerful query paradigm for text databases and the Web. However, more expressive query paradigms, where both queries and their results can exhibit a richer structure than in traditional keyword search, are often desirable. Information extraction systems identify and extract intrinsically structured data that is embedded in natural-language text documents, hence enabling these alternative query paradigms. Unfortunately, information extraction is a time-consuming process, often involving complex text analysis, so exhaustively processing all documents in a large text database --or on the Web-- could be prohibitively expensive. Beyond efficiency, query result quality is also important: information extraction is error-prone and not all extracted data is equally likely to be correct, so result quality is an important consideration during query processing. In this talk, I will discuss recent work on cost-based optimization of structured queries in this information extraction scenario, where modeling query result quality--in addition to execution efficiency-- is a distinctive and important challenge.",2009-06-28,https://www.semanticscholar.org/paper/e4521648675cc58d2c2bbe3b479e2085ebdf1a25,KEYS '09
397,SOME CONPLEXiT¥ ~ES~ILTS FOR THE TNAVELING SALESMAN PROBLEMS,"It is shown that, unless P=NP, local search algorithms for the Traveling Salesman Problem having polynomial time complexity per iteration will generate solutions arbitrarily far from the optimal. The [raveling Salesman Problem is also shown to be NP-Complete even if its instances are restricted to be realizable by a set of points on the Euclidean plane.",,https://www.semanticscholar.org/paper/991ddb090e3002575bb9fbb9a0f384cb42732af5,
3036,Cider: native execution of iOS apps on android,"We present Cider, an operating system compatibility architecture that can run applications built for different mobile ecosystems, iOS or Android, together on the same smartphone or tablet. Cider enhances the domestic operating system, Android, of a device with kernel-managed, per-thread personas to mimic the application binary interface of a foreign operating system, iOS, enabling it to run unmodified foreign binaries. This is accomplished using a novel combination of binary compatibility techniques including two new mechanisms: compile-time code adaptation, and diplomatic functions. Compile-time code adaptation enables existing unmodified foreign source code to be reused in the domestic kernel, reducing implementation effort required to support multiple binary interfaces for executing domestic and foreign applications. Diplomatic functions leverage per-thread personas, and allow foreign applications to use domestic libraries to access proprietary software and hardware interfaces. We have built a Cider prototype, and demonstrate that it imposes modest performance overhead and runs unmodified iOS and Android applications together on a Google Nexus tablet running the latest version of Android.",2014-02-24,https://www.semanticscholar.org/paper/24b59c9addd0262228259b1b30e5448632756caa,International Conference on Architectural Support for Programming Languages and Operating Systems
2291,Effects of Staphylococcal Enterotoxins on Human Neutrophil Functions and Apoptosis,"ABSTRACT Staphylococcal enterotoxins have marked effects on the properties of T cells and monocytes and have recently been reported to affect neutrophil function. In this study, we investigated the abilities of staphylococcal enterotoxins A and B and toxic shock syndrome toxin 1 to affect respiratory burst activity and to delay apoptosis in human neutrophils. When cultures containing approximately 97% neutrophils were tested, the toxins all delayed neutrophil apoptosis in a dose-dependent manner and induced the expression of FcγRI on the neutrophil cell surface. These effects on apoptosis and expression of FcγRI were largely abrogated by the addition of a neutralizing anti-gamma interferon antibody. Similarly, the effects of these toxins on phorbol ester-induced chemiluminescence were decreased after neutralization of gamma interferon. These effects on neutrophil function were mimicked by the addition of conditioned medium from peripheral blood mononuclear cells incubated with the toxins, and again, neutralizing anti-gamma interferon antibodies largely negated the effects. However, when highly purified neutrophils prepared by immunodepletion of T cells and major histocompatibility complex class II-expressing cells were analyzed, the toxins were without effect on apoptosis and FcγRI expression, but granulocyte-macrophage colony-stimulating factor and gamma interferon could still delay apoptosis. These data indicate that these toxins have no direct effect on neutrophil apoptosis but can act indirectly via the production of T-cell-derived and monocyte-derived cytokines. It is noteworthy that such effects are detected in neutrophil suspensions containing only 3% contamination with T cells and other mononuclear cells.",1999-05-01,https://www.semanticscholar.org/paper/564c2ff9dc62f708fdc158a2427915ba834ed307,Infection and Immunity
2588,Session details: Smart interaction techniques 1,,2005-04-02,https://www.semanticscholar.org/paper/b77a4ce3cbe3dcd9c73596729259e32a036ca98c,International Conference on Human Factors in Computing Systems
3251,"Correction for Giuggioli et al., Stigmergy, collective actions, and animal social spacing","ECOLOGY, APPLIED MATHEMATICS Correction for “Stigmergy, collective actions, and animal social spacing,” by Luca Giuggioli, Jonathan R. Potts, Daniel I. Rubenstein, and Simon A. Levin, which appeared in issue 42, October 15, 2013, of Proc Natl Acad Sci USA (110:16904–16909; first published September 30, 2013; 10.1073/pnas.1307071110). The authors note that Fig. 3 appeared incorrectly. The corrected figure and its legend appear below. The authors thank Dr. Jannis Uhlendorf for calling their attention to this error.",2016-02-01,https://www.semanticscholar.org/paper/e6c4e9cf919627b282589f08f1041ee975c554af,Proceedings of the National Academy of Sciences of the United States of America
1907,Semiconductor manufacturing,,2018-10-03,https://www.semanticscholar.org/paper/6c27ce9a5aaae8954ed3bf404f2ca90dd08441ed,Electrical Engineering Handbook
650,Early experience with the Bard XT stent.,"The Bard XT stent is a new generation balloon expandable intracoronary stent. It has several unique design advantages. Between October 1996 and November 1997, 127 Bard XT stents of various length were deployed in 93 patients with 109 lesions. According to the American College of Cardiology (ACC) and American Heart Association (AHA) classifications 7 lesions were type A, 38 were type B1, 43 were type B2 and 21 were type C [Ellis et al.: Circulation 82:1193-1202, 1990]. Stent delivery was successful in 98% of attempts. Angiographic success was achieved in 98% of 109 lesions. Procedural success was achieved in 94% of 93 patients. Minimal luminal diameter (MLD) increased from 0.91+/-0.34 mm to 3.03+/-0.44 mm and percentage diameter stenosis reduced from 69.1+/-11.07 to 9.96+/-6.81. Complications occurred in four patients. One patient had intracranial hemorrhage, one patient had subacute thrombosis and two patients died postprocedure. Patients were followed for a period of 1 to 14 months (average 7+/-4 months) for major cardiac events and clinical restenosis. The Bard XT stent is a user-friendly device which provided excellent angiographic results and short-term clinical outcome in selected cases. Further study is required to evaluate effects on restenosis.",1998-12-01,https://www.semanticscholar.org/paper/7eed1cd3d49226261286d326c5df14b25e4bc1ab,Catheterization and Cardiovascular Diagnosis
443,Computational aspects of organization theory,,1996-09-25,https://www.semanticscholar.org/paper/0b92a880c7980923e0ea6586564b585ff74c5c5c,
587,On the complexity of unique solutions,We show that the problem of deciding whether an instance of the traveling salesman problem has a uniquely optimal solution is complete for Δ2P.,1982-11-03,https://www.semanticscholar.org/paper/1e86b27cc53db003e8aa43eff89407f9cc5b9e9c,23rd Annual Symposium on Foundations of Computer Science (sfcs 1982)
1864,Topic segmentation with an aspect hidden Markov model,"We present a novel probabilistic method for topic segmentation on unstructured text. One previous approach to this problem utilizes the hidden Markov model (HMM) method for probabilistically modeling sequence data [7]. The HMM treats a document as mutually independent sets of words generated by a latent topic variable in a time series. We extend this idea by embedding Hofmann's aspect model for text [5] into the segmenting HMM to form an aspect HMM (AHMM). In doing so, we provide an intuitive topical dependency between words and a cohesive segmentation model. We apply this method to segment unbroken streams of New York Times articles as well as noisy transcripts of radio programs on SpeechBot, an online audio archive indexed by an automatic speech recognition engine. We provide experimental comparisons which show that the AHMM outperforms the HMM for this task.",2001-09-01,https://www.semanticscholar.org/paper/845c20b482765922c67d3ee0ae650c069d7013b0,Annual International ACM SIGIR Conference on Research and Development in Information Retrieval
2133,Response of prestressed concrete continuous beams to static loads,The inelastic response of statically indeterminate reinforced concrete frames can be predicted by the trilinear theory reported recently. In this Paper the trilinear theory is further developed to include prestressed concrete continuous beams. This generalized theory predicts the inelastic response of 15·24 m long continuous prestressed concrete test beams with acceptable accuracy.,1993-06-01,https://www.semanticscholar.org/paper/43372c43a7e74c620d80a432936266949a54e226,
1464,The CDF central electromagnetic calorimeter,,1988-05-01,https://www.semanticscholar.org/paper/10b8e154c2b1458c33ddd99104f19b1c39780a22,
1617,Bayesian Inference for Latent Hawkes Processes,"Hawkes processes are multivariate point processes that model excitatory interactions among vertices in a network. Each vertex emits a sequence of discrete events: points in time with associated content, or marks. Unlike Poisson processes, Hawkes processes allow events on one vertex to influence the subsequent rate of events on downstream vertices. With this property, they are ideally suited to model a variety of phenomena, like social network interactions, the spread of earthquake aftershocks, and spiking activity in neural circuits. This paper addresses a natural question: what if some vertices, marks, or time intervals are hidden from view? Such scenarios often arise in practice, as when neuroscientists work with recordings of subsets of neurons, or when social exchanges are not fully observed. These latent Hawkes processes pose a serious inferential challenge: we must perform inference in a model whose latent variables are marked point processes. We derive Bayesian inference and learning algorithms for latent Hawkes processes and demonstrate their efficacy on a variety of synthetic data and neural data.",,https://www.semanticscholar.org/paper/07e16f31d9b4c1fd4dd5f2d65d9c31a04654292f,
897,The complexity of reliable concurrency control,"We define what it means for a schedule to be reliable, that is, correct in the face of possible transaction failures (assuming that aborting a transaction to restore correctness is not allowed). It turns out that the right definition is recursive, and surprisingly involved. We show that, in fact, testing a schedule for reliability is PSPACE-complete, and thus in some sense even harder than the ordinary NP-complete notions of correctness examined in the past. However, we also prove that all conflict serializable schedules are always reliable, and thus reliability should not be an extra complication for practical concurrency control systems. Finally, we examine two other notions of reliability, related to multiple versions and aborts.",1985-03-25,https://www.semanticscholar.org/paper/a9133f4f0fa0663d33d819fd0f031bf42248924c,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
1645,Rejection Sampling Variational Inference,"Variational inference using the reparameterization trick has enabled large-scale approximate Bayesian inference in complex probabilistic models, leveraging stochastic optimization to sidestep intractable expectations. The reparameterization trick is applicable when we can simulate a random variable by applying a (differentiable) deterministic function on an auxiliary random variable whose distribution is fixed. For many distributions of interest (such as the gamma or Dirichlet), simulation of random variables relies on rejection sampling. The discontinuity introduced by the accept–reject step means that standard reparameterization tricks are not applicable. We propose a new method that lets us leverage reparameterization gradients even when variables are outputs of a rejection sampling algorithm. Our approach enables reparameterization on a larger class of variational distributions. In several studies of real and synthetic data, we show that the variance of the estimator of the gradient is significantly lower than other state-of-the-art methods. This leads to faster convergence of stochastic optimization variational inference. Let p(x, z) be a probabilistic model, i.e., a joint probability distribution of data x and latent (unobserved) variables z. In Bayesian inference, we are interested in the posterior distribution p(z|x) = p(x,z) p(x) . For most models, the posterior distribution is analytically intractable and we have to use an approximation, such as Monte Carlo methods or variational inference. In this paper, we focus on variational inference. In variational inference, we approximate the posterior with a variational family of distributions q(z ; θ), parameterized by θ. Typically, we choose the variational parameters θ that minimize the Kullback-Leibler (KL) divergence between q(z ; θ) and p(z|x). This minimization is equivalent to maximizing the evidence lower bound (ELBO) [Jordan et al., 1999], L(θ) = Eq(z ;θ) [f(z)] +H[q(z ; θ)], f(z) := log p(x, z), H[q(z ; θ)] := Eq(z ;θ)[− log q(z ; θ)]. (1) When the model and variational family satisfy conjugacy requirements, we can use coordinate ascent to find a local optimum of the ELBO [Ghahramani and Beal, 2001, Blei et al., 2016]. If the conjugacy requirements are not satisfied, a common approach is to build a Monte Carlo estimator of the gradient of the ELBO [Paisley et al., 2012, Ranganath et al., 2014, Salimans and Knowles, 2013]. Empirically, the reparameterization trick has been shown to be beneficial over direct Monte Carlo estimation of the gradient using the score fuction estimator [Rezende et al., 2014, Kingma and Welling, 2014, Titsias and Lázaro-Gredilla, 2014, Fan et al., 2015]. However, it is not generally applicable, it requires that: (i) the latent variables z are continuous; and (ii) we can simulate from q(z ; θ) as follows, z = h(ε, θ), with ε ∼ s(ε). (2) Here, s(ε) is a distribution that does not depend on the variational parameters; it is typically a standard normal or a standard uniform. Further, h(ε, θ) is differentiable with respect to θ. Using (2), we can move the derivative inside the expectation and rewrite the gradient of the ELBO as ∇θL(θ) = Es(ε) [∇zf(h(ε, θ))∇θh(ε, θ)] +∇θH[q(z ; θ)]. ∗Corresponding author: christian.a.naesseth@liu.se Advances in Approximate Bayesian Inference (NIPS 2016 Workshop), Barcelona, Spain. Algorithm 1 Reparameterized Rejection Sampling Input: target q(z ; θ), proposal r(z ; θ), and constant Mθ, with q(z ; θ) ≤Mθr(z ; θ) Output: ε such that h(ε, θ) ∼ q(z ; θ) 1: i← 0 2: repeat 3: i← i+ 1 4: Propose εi ∼ s(ε) 5: Simulate ui ∼ U [0, 1] 6: until ui < q(h(εi,θ) ;θ) Mθr(h(εi,θ) ;θ) 7: return εi 6 4 2 0 2 4 6 ε 10 10 10 10 10 10 10 10 10",2016-10-18,https://www.semanticscholar.org/paper/26a125c7453d56d8ff52ee3f0902631174b99fd1,
722,"Greatest Fixed Points of Probabilistic Min/Max Polynomial Equations, and Reachability for Branching Markov Decision Processes",,2015-02-19,https://www.semanticscholar.org/paper/00de2315d1880833ec33435f3fd919d6b13e44ff,"International Colloquium on Automata, Languages and Programming"
2718,Inferring constraints from multiple snapshots,"Many graphic tasks, such as the manipulation of graphical objects and the construction of user-interface widgets, can be facilitated by geometric constraints. However, the difficulty of specifying constraints by traditional methods forms a barrier to their widespread use. In order to make constraints easier to declare, we have developed a method of specifying constraints implicitly, through multiple examples. Snapshots are taken of an initial scene configuration, and one or more additional snapshots are taken after the scene has been edited into other valid configurations. The constraints that are satisfied in all of the snapshots are then applied to the scene objects. We discuss an efficient algorithm for inferring constraints from multiple snapshots. The algorithm has been incorporated into the Chimera editor, and several examples of its use are discussed.",1993-10-01,https://www.semanticscholar.org/paper/89f81d0e3ea7cd192cf94615169d21738bb47a6e,TOGS
2784,A small molecule CCR2 antagonist depletes tumor macrophages and synergizes with anti-PD1 in a murine model of cutaneous T cell lymphoma (CTCL).,,2020-01-13,https://www.semanticscholar.org/paper/3054c107cbf9d2803463b040e766e341e71817d6,Journal of Investigative Dermatology
2857,Functional Capacity of Macrophages Determines the Induction of Type 1 Diabetes,"Abstract:  Macrophages are potent immune regulators and are critical in the development and pathogenesis of autoimmune diabetes. They are said to be the first cell type to infiltrate the pancreatic islet, serve as antigen‐presenting cells, and are important as effector cells during diabetogenesis. The article examines the role of macrophages in autoimmune diabetes with particular emphasis on the role of galectin‐3, a β‐galactoside‐binding lectin, and T1/ST2, an IL‐1 receptor‐like protein, both of which play significant roles in the immunomodulatory functions of macrophages. Multiple low‐dose streptozotocin (MLD‐STZ) induces infiltration of mononuclear cells in the islets of susceptible strains leading to insulitis. Deletion of the galectin‐3 gene from C57BL/6 mice significantly attenuates this effect as evaluated by quantitative histology of mononuclear cells and loss of insulin‐producing β cells. In contrast, deletion of the ST2 gene enhanced insulitis after MLD‐STZ treatment when compared with relatively resistant wild‐type BALB/c mice. Thus, it appears that functional capacity of macrophages influences their participation in T helper (Th) 1‐mediated autoimmunity and the development of autoimmune diabetogenesis.",2006-11-01,https://www.semanticscholar.org/paper/8ab494ff928151b629377413534eb3cf8973553c,Annals of the New York Academy of Sciences
3762,Kitchen Units for Food Units for Table . . . Past Future Predictor,"In many computer vision applications, machines will need to reason beyond the present, and predict the future. This task is challenging because it requires leveraging extensive commonsense knowledge of the world that is difficult to write down. We believe that a promising resource for efficiently obtaining this knowledge is through the massive amounts of readily available unlabeled video. In this paper, we present a large scale framework that capitalizes on temporal structure in unlabeled video to learn to anticipate both actions and objects in the future. The key idea behind our approach is that we can train deep networks to predict the visual representation of images in the future. We experimentally validate this idea on two challenging “in the wild” video datasets, and our results suggest that learning with unlabeled videos significantly helps forecast actions and anticipate objects.",,https://www.semanticscholar.org/paper/0b07f20c2037a6ca5fcc1dd022092fd5c57dd647,
525,Finding Feasible Paths for a Two-Point Body,,1989-03-01,https://www.semanticscholar.org/paper/8de116327b63349c4519fb0ce9afa463b9b5e4c3,J. Algorithms
151,"Design, architecture and control of a mobile site-modeling robot","A distributed, modular, heterogeneous architecture is presented that illustrates an approach to solving and integrating common tasks in mobile robotics, such as path planning, localization, sensor fusion, environmental modeling, and motion control. Experimental results are shown for an autonomous navigation task to confirm the applicability of our approach.",2000-04-24,https://www.semanticscholar.org/paper/9bd959bac105c8a25cb50776cc25e6090754f035,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065)
1175,Bulk and surface charge collection: CDMS detector performance and design implications,"The Cryogenic Dark Matter Search (CDMS) searches for Weakly Interacting Massive Particles (WIMPs) with cryogenic germanium particle detectors. These detectors discriminate between nuclear‐recoil candidate and electron‐recoil background events by collecting both phonon and ionization energy from interactions in the crystal. Incomplete ionization collection results in the largest background in the CDMS detectors as this causes electron‐recoil background interactions to appear as false candidate events. Two primary causes of incomplete ionization collection are suface and bulk charge trapping. Recent work has been focused on reducing surface trapping through the modification of fabrication methods for future detectors. Analyzing data taken with test devices shows that hydrogen passivation of the amorphous silicon blocking layer does not reduce the effects of surface trapping. Other data shows that the iron‐ion implantation used to lower the critical temperature of the tungsten transition‐edge sensors increases surface trapping, causing a degradation of the ionization collection. Using selective implantation on future detectors may improve ionization collection for events near the phonon side detector surface. Bulk trapping is minimized by neutralizing ionized lattice impurities. Detector investigations at testing facilities and at the experimental site in Soudan, MN have provided methods to optimize the neutralization process and monitor running conditions to maintain maximal ionization collection.",2009-12-16,https://www.semanticscholar.org/paper/b394e5bcebee1a696550b9c049071b08d4595db8,
1566,Variational Bayes under Model Misspecification,"Variational Bayes (VB) is a scalable alternative to Markov chain Monte Carlo (MCMC) for Bayesian posterior inference. Though popular, VB comes with few theoretical guarantees, most of which focus on well-specified models. However, models are rarely well-specified in practice. In this work, we study VB under model misspecification. We prove the VB posterior is asymptotically normal and centers at the value that minimizes the Kullback-Leibler (KL) divergence to the true data-generating distribution. Moreover, the VB posterior mean centers at the same value and is also asymptotically normal. These results generalize the variational Bernstein--von Mises theorem [29] to misspecified models. As a consequence of these results, we find that the model misspecification error dominates the variational approximation error in VB posterior predictive distributions. It explains the widely observed phenomenon that VB achieves comparable predictive accuracy with MCMC even though VB uses an approximating family. As illustrations, we study VB under three forms of model misspecification, ranging from model over-/under-dispersion to latent dimensionality misspecification. We conduct two simulation studies that demonstrate the theoretical results.",2019-05-26,https://www.semanticscholar.org/paper/0a538c7e1f943a30f048eec0a3b0dfff25062b1a,Neural Information Processing Systems
1569,Using Text Embeddings for Causal Inference,"We address causal inference with text documents. For example, does adding a theorem to a paper affect its chance of acceptance? Does reporting the gender of a forum post author affect the popularity of the post? We estimate these effects from observational data, where they may be confounded by features of the text such as the subject or writing quality. Although the text suffices for causal adjustment, it is prohibitively high-dimensional. The challenge is to find a low-dimensional text representation that can be used in causal inference. A key insight is that causal adjustment requires only the aspects of text that are predictive of both the treatment and outcome. Our proposed method adapts deep language models to learn low-dimensional embeddings from text that predict these values well; these embeddings suffice for causal adjustment. We establish theoretical properties of this method. We study it empirically on semi-simulated and real data on paper acceptance and forum post popularity. Code is available at this https URL.",2019-05-29,https://www.semanticscholar.org/paper/298b72096b8a770b0cdb263dd53cf2463b8a1a1d,arXiv.org
3034,A Measurement Study of ARM Virtualization Performance,"ARM servers are becoming increasingly common, making server technologies such as virtualization for ARM of growing importance. We present the first in-depth study of ARM virtualization performance on ARM server hardware, including measurements of two popular ARM and x86 hypervisors, KVM and Xen. We show how the ARM hardware support for virtualization can support much faster transitions between VMs and the hypervisor, a key hypervisor operation. However, current hypervisor designs, including both Type 1 hypervisors such as Xen and Type 2 hypervisors such as KVM, are not able to leverage this performance benefit in practice for real application workloads. We discuss the reasons why and show that other factors related to hypervisor software design and implementation have a larger role in overall performance. Based on our measurements, we discuss changes to ARM’s hardware virtualization support that can potentially bridge the gap to bring its faster VM-tohypervisor transition mechanism to modern Type 2 hypervisors running real applications. These changes have been incorporated into the latest ARM architecture.",,https://www.semanticscholar.org/paper/a9fa98baed4be38aa216722cc0f4872a4b10a99d,
2153,On lower bounds for the capacity of deletion channels,"We consider binary deletion channels, where bits are deleted independently with probability d. We extend the framework used to analyze the capacity of binary deletion channels established by Diggavi and Grossglauser [2001], improving on their lower bounds. In Diggavi and Grossglauser, the codewords are generated by a first order Markov chain. Our improvements arise from two considerations. First, Diggavi and Grossglauser consider typical outputs, where an output is typical if an N bit input produces an output of at least N(1-d)(1-/spl epsi/) bits. We provide a stronger notion of a typical output that yields better bounds even for the cases studied in Diggavi and Grossglauser. Second, we consider codewords generated by more general processes than first order Markov chains.",2004-06-27,https://www.semanticscholar.org/paper/9f540c371bfd92c622a6321a15001b941b0b7e63,"International Symposium onInformation Theory, 2004. ISIT 2004. Proceedings."
3677,ClimSim: An open large-scale dataset for training high-resolution physics emulators in hybrid multi-scale climate simulators,"Modern climate projections lack adequate spatial and temporal resolution due to computational constraints. A consequence is inaccurate and imprecise predictions of critical processes such as storms. Hybrid methods that combine physics with machine learning (ML) have introduced a new generation of higher fidelity climate simulators that can sidestep Moore's Law by outsourcing compute-hungry, short, high-resolution simulations to ML emulators. However, this hybrid ML-physics simulation approach requires domain-specific treatment and has been inaccessible to ML experts because of lack of training data and relevant, easy-to-use workflows. We present ClimSim, the largest-ever dataset designed for hybrid ML-physics research. It comprises multi-scale climate simulations, developed by a consortium of climate scientists and ML researchers. It consists of 5.7 billion pairs of multivariate input and output vectors that isolate the influence of locally-nested, high-resolution, high-fidelity physics on a host climate simulator's macro-scale physical state. The dataset is global in coverage, spans multiple years at high sampling frequency, and is designed such that resulting emulators are compatible with downstream coupling into operational climate simulators. We implement a range of deterministic and stochastic regression baselines to highlight the ML challenges and their scoring. The data (https://huggingface.co/datasets/LEAP/ClimSim_high-res, https://huggingface.co/datasets/LEAP/ClimSim_low-res, and https://huggingface.co/datasets/LEAP/ClimSim_low-res_aqua-planet) and code (https://leap-stc.github.io/ClimSim) are released openly to support the development of hybrid ML-physics and high-fidelity climate simulations for the benefit of science and society.",2023-06-14,https://www.semanticscholar.org/paper/111ef44f5c3cf2f8a93a124ef152ebc116135def,arXiv.org
2579,Interaction techniques using prosodic features of speech and audio localization,"We describe several approaches for using prosodic features of speech and audio localization to control interactive applications. This information can be applied to parameter control, as well as to speech disambiguation. We discuss how characteristics of spoken sentences can be exploited in the user interface; for example, by considering the speed with which a sentence is spoken and the presence of extraneous utterances. We also show how coarse audio localization can be used for low-fidelity gesture tracking, by inferring the speaker's head position.",2005-01-10,https://www.semanticscholar.org/paper/23062112a90cf95c4743d9db7a9dbe073aa123b4,International Conference on Intelligent User Interfaces
1521,Learning Transferrable Representations of Career Trajectories for Economic Prediction,"Understanding career trajectories—the sequences of jobs that individuals hold over their working lives—is important to economists for studying labor markets. In the past, economists have estimated relevant quantities by ﬁtting predictive models to small surveys, but in recent years large datasets of online resumes have also become available. These new datasets provide job sequences of many more individuals, but they are too large and complex for standard econometric modeling. To this end, we adapt ideas from modern language modeling to the analysis of large-scale job sequence data. We develop CAREER, a transformer-based model that learns a low-dimensional representation of an individual’s job history. This representation can be used to predict jobs directly on a large dataset, or can be “transferred” to represent jobs in smaller and better-curated datasets. We ﬁt the model to a large dataset of resumes, 24 million people who are involved in more than a thousand unique occupations. It forms accurate predictions on held-out data, and it learns useful career representations that can be ﬁne-tuned to make accurate predictions on common economics datasets. for predicting and forecasting career",,https://www.semanticscholar.org/paper/57ceadbb37da24ce24b3ab8ff826ddcae717c0e2,arXiv.org
3281,Field-Based Teacher Research: How Teachers and Scientists Working Together Answers Questions about Turtle Nesting Ecology while Enhancing Teachers' Inquiry Skills,,2013-12-01,https://www.semanticscholar.org/paper/a4e6c3fcca8a308f427f72693bcff18eca208ff9,
3624,The C++ programming language (3. ed.),,,https://www.semanticscholar.org/paper/29f92dbc9e1ade36c921b88a492554acdd6751b0,
290,Computing correlated equilibria in multi-player games,"We develop polynomial-time algorithms for finding correlated equilibria—a well-studied notion of rationality that generalizes the Nash equilibrium—in a broad class of succinctly representable multiplayer games, encompassing graphical games, anonymous games, polymatrix games, congestion games, scheduling games, local effect games, as well as several generalizations. Our algorithm is based on a variant of the existence proof due to Hart and Schmeidler, and employs linear programming duality, the ellipsoid algorithm, Markov chain steady state computations, as well as application-specific methods for computing multivariate expectations over product distributions.
 For anonymous games and graphical games of bounded tree-width, we provide a different polynomial-time algorithm for optimizing an arbitrary linear function over the set of correlated equilibria of the game. In contrast to our sweeping positive results for computing an arbitrary correlated equilibrium, we prove that optimizing over correlated equilibria is NP-hard in all of the other classes of games that we consider.",2008-07-01,https://www.semanticscholar.org/paper/6ae3ddfb3e59019d6b01d1670bb0133141ce373a,JACM
231,"Algorithms, Games, and Evolution (Invited Talk)","Even the most seasoned students of evolution, starting with Darwin himself, have occasionally expressed amazement at the fact that the mechanism of natural selection has produced the whole of Life as we see it around us. From a computational perspective, it is natural to marvel at evolution's solution to the problems of robotics, vision and theorem proving! What, then, is the complexity of evolution, viewed as an algorithm? One answer to this question is 10^{12}, roughly the number of sequential steps or generations from the earliest single celled creatures to today's Homo Sapiens. To put this into perspective, the processor of a modern cell phone can perform 10^{12} steps in less than an hour. Another answer is 10^30, the degree of parallelism, roughly the maximum number of organisms living on the Earth at any time. Perhaps the answer should be the product of the two numbers, roughly 10^42, to reflect the total work done by evolution, viewed as a parallel algorithm. 
 
Here we argue, interpreting our recently published paper, that none of the above answers is really correct. Viewing evolution as an algorithm poses an additional challenge: recombination. Even if evolution succeeds in producing a particularly good solution (a highly fit individual), its offspring would only inherit half its genes, and therefore appear unlikely to be a good solution. This is the core of the problem of explaining the role of sex in evolution, known as the ""queen of problems in evolutionary biology"". 
 
The starting point is the diffusion-equation-based approach of theoretical population geneticists, who analyze the changing allele frequencies (over the generations) in the gene pool, consisting of the aggregate of the genetic variants (or ""alleles"") over all genes (or ""loci"") and over all individuals in a species. Taking this viewpoint to its logical conclusion, rather than acting on individuals or species or genes, evolution acts on this gene pool, or genetic soup, by making it more ""potent"", in the sense that it increases the expected fitness of genotype drawn randomly from this soup. Moreover, for much genetic variation, this soup may be assumed to be in the regime of weak selection, a regime where the probability of occurrence of a certain genotype involving various alleles at different loci is simply the product of the probabilities of each of its alleles. In this regime, we show that evolution in the regime of weak selection can be formulated as a game, where the recombining loci are the players, the alleles in those loci are possible moves or actions of each player, and the expected payoff of each player-locus is precisely the organism's expected fitness across the genotypes that are present in the population. Moreover, the dynamics specified by the diffusion equations of theoretical population geneticists is closely approximated by the dynamics of multiplicative weight updates (MWUA). 
 
The algorithmic connection to MWUA brings with it new insights for evolutionary biology, specifically, into the question of how genetic diversity is maintained in the presence of natural selection. For this it is useful to consider a dual view of MWUA, which expresses ""what each gene is optimizing"" as it plays the game. Remarkably this turns out to be a particular convex combination of the entropy of its distribution over alleles and cumulative expected fitness. This sheds new light on the maintenance of diversity in evolution. 
 
All of this suggests that the complexity of evolution should indeed be viewed as 10^12, but for a subtle reason. It is the number of steps of multiplicative weight updates carried out on allele frequencies in the genetic soup. A closer examination of this reveals further that the accurate tracking of allele frequencies over the generations requires the simulation of a quadratic dynamical system (two parents for each offspring). Moreover the simulation of even simple quadratic dynamical systems is known to be PSPACE-hard. This suggests that the tracking of allele frequencies might require large population sizes for each species, putting into perspective the number 10^30. Finally, it is worth noting that in this view there is a primacy to recombination or sex, which serve to provide robustness to the mechanism of evolution, as well as the framework within which MWUA operates.",,https://www.semanticscholar.org/paper/9918cbee1ee84ed2129a8a0091f48207ad41ce7d,Foundations of Software Technology and Theoretical Computer Science
820,On nested depth first search,We show in this paper that the algorithm for solving the model checking problem with a nested depth-first search can interfere with algorithms that support partial order reduction. We introduce a revised version of the algorithm that guarantees compatibility. The change also improves the performance of the nested depth-first search algorithm when partial order reduction is not used.,,https://www.semanticscholar.org/paper/c35f37a7980d4523d6de2f7ffbb4797405d1bc93,The Spin Verification System
1324,Measurement of the Bs(0) lifetime using semileptonic decays.,"We report a measurement of the Bs(0) lifetime in the semileptonic decay channel Bs(0) --> Ds- mu+ nuX (and its charge conjugate), using approximately 0.4 fb(-1) of data collected with the D0 detector during 2002-2004. Using 5176 reconstructed Ds- mu+ signal events, we have measured the Bs(0) lifetime to be tau(Bs(0))=1.398+/-0.044(stat)(-0.025)(+0.028)(syst) ps. This is the most precise measurement of the Bs(0) lifetime to date.",2006-04-24,https://www.semanticscholar.org/paper/aa9b1fdfce9f08aa56263c9f0736d7fe7043d70b,Physical Review Letters
1612,Augment and Reduce: Stochastic Inference for Large Categorical Distributions,"Categorical distributions are ubiquitous in machine learning, e.g., in classification, language models, and recommendation systems. They are also at the core of discrete choice models. However, when the number of possible outcomes is very large, using categorical distributions becomes computationally expensive, as the complexity scales linearly with the number of outcomes. To address this problem, we propose augment and reduce (A&R), a method to alleviate the computational complexity. A&R uses two ideas: latent variable augmentation and stochastic variational inference. It maximizes a lower bound on the marginal likelihood of the data. Unlike existing methods which are specific to softmax, A&R is more general and is amenable to other categorical models, such as multinomial probit. On several large-scale classification problems, we show that A&R provides a tighter bound on the marginal likelihood and has better predictive performance than existing approaches.",2018-02-12,https://www.semanticscholar.org/paper/d640dffe89d91367577e4e017d69a9c2bb3c8339,International Conference on Machine Learning
2909,A method to extract slip system dependent information for crystal plasticity models,,2022-06-01,https://www.semanticscholar.org/paper/92b4341ff6c92728f13278f3fb7f4643733ece2c,MethodsX
538,Exponential lower bounds for finding Brouwer fixed points,,1987-10-12,https://www.semanticscholar.org/paper/a25e30be4d0aa5f11d284acbc3fd3374e0e3ce1a,28th Annual Symposium on Foundations of Computer Science (sfcs 1987)
225,A New Age of Computing and the Brain,"Throughout its history, humankind has been fascinated by a question that is simple to pose, yet remarkably resistant to resolution: ""How does the brain work?"" Philosophers have debated the workings of the mind for centuries. Da Vinci made detailed sketches of the brain. By the turn of the century, scientists began to understand some of the brain's basic structure and function. Today, we can image and record brain activity from the neural to whole-brain level. Yet, divining how the structure and function of the several billion neurons and their trillions of interconnections leads to the complexity, diversity, and adaptability of human behavior continues to elude us. It is indeed ironic that almost every advance in brain science has given us a deeper appreciation of the challenges of understanding the brain.",2014-12-03,https://www.semanticscholar.org/paper/1fbea1d40348f8e767d4d1feb6dfa45f1a55cbeb,arXiv.org
378,Communities and reputation on the web,"Search engines play a valuable social role by increasing the visibility of information on the world wide web. While their retrieval performance is impressive, little work has been done to support other social needs, such as evaluating the reputation of information. The goal of this work is to enable search systems to use the social context, of a particular community, to assess the reputation of web pages. 
We shall start by assuming that we can do textual retrieval well: in particular, that we can perform broad-topic queries which return large sets of pages. A community is defined by the pages in such a set. We argue, based on considerations of the nature of human activity, that it is reasonable for algorithms to focus on the hyperlinks between pages in the community, in order to assess reputation. 
We demonstrate that a good candidate for doing such link analysis is the HITS algorithm. However, this has problems of slow execution, instability of results, and an issue known as topic drift: when analysing link structures, pages in “nearby” communities sometimes garner overly high scores. 
To improve execution speed, we show that we can define a measure of centrality in a vector space, which generalises the HITS model and makes it analogous to Latent Semantic Analysis, a powerful text analysis technique. The Generalised HITS algorithm precomputes global summary vectors and uses them to perform local reputation calculations quickly. 
To tackle both instability and topic drift, we introduce a tunable parameter which reduces the influence of nearby communities, without losing the benefits of the HITS algorithm. The calculation is efficient enough to allow us to control this effect interactively. 
Using controlled experiments, we verify that our techniques succeed on realistic simulations of the web, which match observed properties such as the “power-law” linkage structure. We also consider the real linkage structures created by webloggers, and show that we have the same ability to judge reputation. 
These techniques enable us to integrate the presentation of reputation judgements into web-scale search systems, in a way which is justifiably meaningful, accommodating of realistic web phenomena, and community specific.",,https://www.semanticscholar.org/paper/ef17c5e69e2a516062d59372f7ce066e08947e7d,
1764,Dynamic and Supervised Topic Models for Literature-Based Discovery,"Abstract : Under the support of the ONR my research focused on extending the state ot the an or probabilistic topic modeling, algorithms for making discoveries from and predictions about large collections of texts. For the past three years, my group has published many papers in the service of this goal. In this report, I will highlight some of the themes and publications that represent this work. Thanks to the support of the ONR, we have made excellent progress in our stated goals.",2011-12-21,https://www.semanticscholar.org/paper/4ad4fa27aa1cd113b1e50e1e542cad845e34dcae,
2886,"Evidence for IgG autoantibodies to galectin-3, a beta-galactoside-binding lectin (Mac-2, epsilon binding protein, or carbohydrate binding protein 35) in human serum.","Galectin-3 is a beta-galactoside-binding animal lectin formerly called epsilon protein, Mac-2, carbohydrate binding protein 35, CBH 30, L-29, or L34. The possible occurrence of autoantibodies to galectin-3 was investigated because crosslinking of galectins bound to IgE or Fc epsilon RI might produce mediator release from mast cells or basophils. Unexpectedly, a control serum from an individual free of current allergic symptoms was found to have a significantly elevated level of IgG anti-galectin-3 by ELISA employing galectin-3-coated wells incubated with test serum followed by HRPO-conjugated goat anti-human IgG. The reaction was not inhibitable by lactose, suggesting that it is not a result of binding of IgG by galectin-3 through lectin-carbohydrate interactions. The antibody activity was specifically adsorbed by galectin-3 and protein A-conjugated Sepharose and was associated primarily with subclass IgG1. The presence of the antibodies was confirmed by immunoblotting showing binding of IgG to the 30-kD galectin-3 band. The relevant epitopes were in the galectin-3 N-terminal domain. The propositus was subsequently found to have adenocarcinoma of the colon, and titers of IgG anti-galectin-3 were found to be sharply elevated after hemicolectomy. Similar antibody titers have not been found in family members, but small numbers of normal persons and patients with malignant neoplasms have been found to have evidence of IgG anti-galectin-3 antibodies at lower titers than the propositus. The pathogenesis of this autoimmune reaction is unclear, though there is a trend for it to occur in older persons.",,https://www.semanticscholar.org/paper/f978c88e82407e29f98f40659a07f3adaf43c1a3,Journal of Clinical Immunology
3015,Microservices and Containers,"The articles in this special section focus on microservices and containers. These services allow an application to be comprised of many independently operating and scalable components, have become a common service paradigm. The ability to construct an application by provisioning these interoperating components has various advantages, including the isolation and independent development of tools such as key-value stores, authentication, logging, and many others. Containers are one type of system infrastructure that is commonly used to support microservices. With container management systems like Docker and orchestration systems like Kubernetes to control applications and dynamically provision their resources, cloud services can be extremely scalable, reliable, and reactive. However, other systems beyond containers can be used to support microservices, and many applications other than microservices benefit from containerization.",2019-11-01,https://www.semanticscholar.org/paper/480846bb2752dbdbaa3382c33c82b8affb1e5437,IEEE Internet Computing
739,"Market equilibrium under separable, piecewise-linear, concave utilities","We consider Fisher and Arrow--Debreu markets under additively separable, piecewise-linear, concave utility functions and obtain the following results. For both market models, if an equilibrium exists, there is one that is rational and can be written using polynomially many bits. There is no simple necessary and sufficient condition for the existence of an equilibrium: The problem of checking for existence of an equilibrium is NP-complete for both market models; the same holds for existence of an ε-approximate equilibrium, for ε = O(n−5). Under standard (mild) sufficient conditions, the problem of finding an exact equilibrium is in PPAD for both market models. Finally, building on the techniques of Chen et al. [2009a] we prove that under these sufficient conditions, finding an equilibrium for Fisher markets is PPAD-hard.",2011-05-01,https://www.semanticscholar.org/paper/8b1f7c0426499591885930fea1b6ec519a0761d8,JACM
2626,User Interfaces for Mobile Augmented Reality Systems,"In this dissertation, we present typical components of, useful services associated with, and user interactions possible with mobile augmented reality systems, based on a comprehensive series of hardware and software infrastructures and application prototypes we developed. We define a practical taxonomy of user interface components for such systems and establish methodology for adaptive mobile augmented reality interfaces that dynamically rearrange themselves in response to changes in user context. 
The research contributions to the state-of-the-art in augmented reality begin with the author's participation in the design of the “Columbia Touring Machine” in 1997, the first example of an outdoor mobile augmented reality system, and his lead in developing later prototypes. We develop a series of hardware and software infrastructures for prototyping mobile augmented reality applications that allow multiple users to participate in collaborative tasks taking place indoors and outdoors. 
We present exploratory user interfaces for many different applications and user scenarios, including the Situated Documentaries application framework for experiencing spatially distributed hypermedia presentations. Based on these explorations, we develop a taxonomic categorization of mobile augmented reality interface components and their properties. Virtual and real world objects alike are considered part of the interface. We tag each component with information about its purpose, its intrinsic properties, its relationship to other objects, and its capabilities and flexibility with regard to various manipulations. 
Mobile augmented reality has until now faced a significant challenge: the complexity of the augmented views rapidly increases when many virtual objects fight for screen space to annotate physical entities in the dynamic views of multiple fast-paced roaming users. Responding to this, we develop user interface management techniques for mobile augmented reality. A rule-based reasoning architecture uses the taxonomic data classification mentioned above to automatically rearrange augmented reality views in dynamic situations; for example to remove clutter in the augmented view of the world or to react to infrastructural context changes, such as variations in tracking accuracy.",,https://www.semanticscholar.org/paper/e801b5711f4727ddf42176820cc2e3e31243a20c,"International Conference on Vision, Video and Graphics"
603,On the power of locking,"We study the expressive power of locking primitives, as measured by ther ability to implement different concurrency control principles. We give a necessary and sufficient condition for a concurrency control principle (abstractly, a set of histories) to be implementable by binary semaphores. Also, we characterize exactly those sets of locking primitives that are no more powerful than binary semaphores.",1981-04-29,https://www.semanticscholar.org/paper/6d57730605f25a80e0c1dd3f9b6263d4eb393b47,ACM SIGMOD Conference
951,Central retinal vascular trunk deviation in unilateral normal-tension glaucoma,"Purpose To investigate whether the position of the central retinal vascular trunk (CRVT), as a surrogate of lamina cribrosa (LC) offset, was associated with the presence of glaucoma in normal-tension glaucoma (NTG) patients. Methods The position of the CRVT was measured as the deviation from the center of the Bruch’s membrane opening (BMO), as delineated by spectral-domain optical coherence tomography imaging. The offset index was calculated as the distance of the CRVT from the BMO center relative to that of the BMO margin. The angular deviation of CRVT was measured with the horizontal nasal midline as 0° and the superior location as a positive value. The offset index and angular deviation were compared between glaucoma and fellow control eyes within individuals. Results NTG eyes had higher baseline intraocular pressure (P = 0.001), a larger β-zone parapapillary atrophy area (P = 0.013), and a larger offset index (P<0.001). In a generalized linear mixed-effects model, larger offset index was the only risk factor of NTG diagnosis (OR = 31.625, P<0.001). A generalized estimating equation regression model revealed that the offset index was larger in the NTG eyes than in the control eyes for all ranges of axial length, while it was the smallest for the axial length of 23.4 mm (all P<0.001). Conclusions The offset index was larger in the unilateral NTG eyes, which fact is suggestive of the potential role of LC/BMO offset as a loco-regional susceptibility factor.",2021-07-20,https://www.semanticscholar.org/paper/2623e58e75be11428f65ceb460d95fc5582609b1,PLoS ONE
3177,Both prey and predator features predict the individual predation risk and survival of schooling prey,"Predation is one of the main evolutionary drivers of social grouping. While it is well appreciated that predation risk is likely not shared equally among individuals within groups, its detailed quantification has remained difficult due to the speed of attacks and the highly dynamic nature of collective prey response. Here, using high-resolution tracking of solitary predators (Northern pike) hunting schooling fish (golden shiners), we not only provide insights into predator decision-making, but show which key spatial and kinematic features of predator and prey predict the risk of individuals to be targeted and to survive attacks. We found that pike tended to stealthily approach the largest groups, and were often already inside the school when launching their attack, making prey in this frontal ‘strike zone’ the most vulnerable to be targeted. From the prey’s perspective, those fish in central locations, but relatively far from, and less aligned with, neighbours, were most likely to be targeted. While the majority of attacks were successful (70%), targeted individuals that did manage to avoid being captured exhibited a higher maximum acceleration response just before the attack and were further away from the pike‘s head. Our results highlight the crucial interplay between predators’ attack strategy and response of prey underlying the predation risk within mobile animal groups.",2022-07-19,https://www.semanticscholar.org/paper/62e0f7a5c2f48d394471fa1dc81e59a724c96107,eLife
2987,Nonparametric Bayesian Sparse Factor Models with application to Gene Expression modelling,"A nonparametric Bayesian extension of Factor Analysis (FA) is proposed where observed data $\mathbf{Y}$ is modeled as a linear superposition, $\mathbf{G}$, of a potentially infinite number of hidden factors, $\mathbf{X}$. The Indian Buffet Process (IBP) is used as a prior on $\mathbf{G}$ to incorporate sparsity and to allow the number of latent features to be inferred. The model's utility for modeling gene expression data is investigated using randomly generated data sets based on a known sparse connectivity matrix for E. Coli, and on three biological data sets of increasing complexity.",2010-11-29,https://www.semanticscholar.org/paper/effe59b2ac139fcef5cc5f7470f323a09fb1cd6f,Annals of Applied Statistics
3696,It's Time for Artistic Correspondence in Music and Video,"We present an approach for recommending a music track for a given video, and vice versa, based on both their temporal alignment and their correspondence at an artistic level. We propose a self-supervised approach that learns this correspondence directly from data, without any need of human annotations. In order to capture the high-level concepts that are required to solve the task, we propose modeling the long-term temporal context of both the video and the music signals, using Transformer networks for each modality. Experiments show that this approach strongly outperforms alternatives that do not exploit the temporal context. The combination of our contributions improve retrieval accuracy up to 10× over prior state of the art. This strong improvement allows us to introduce a wide range of analyses and applications. For instance, we can condition music retrieval based on visually defined attributes.",2022-06-01,https://www.semanticscholar.org/paper/4b57f6eb0c1a69349dd3f446d114f2e8301bfcbe,Computer Vision and Pattern Recognition
1816,Relative Performance Guarantees for Approximate Inference in Latent Dirichlet Allocation,"Hierarchical probabilistic modeling of discrete data has emerged as a powerful tool for text analysis. Posterior inference in such models is intractable, and practitioners rely on approximate posterior inference methods such as variational inference or Gibbs sampling. There has been much research in designing better approximations, but there is yet little theoretical understanding of which of the available techniques are appropriate, and in which data analysis settings. In this paper we provide the beginnings of such understanding. We analyze the improvement that the recently proposed collapsed variational inference (CVB) provides over mean field variational inference (VB) in latent Dirichlet allocation. We prove that the difference in the tightness of the bound on the likelihood of a document decreases as O(k - 1) + √log m/m, where k is the number of topics in the model and m is the number of words in a document. As a consequence, the advantage of CVB over VB is lost for long documents but increases with the number of topics. We demonstrate empirically that the theory holds, using simulated text data and two text corpora. We provide practical guidelines for choosing an approximation.",2008-12-08,https://www.semanticscholar.org/paper/497e22323137e909f64dccd8695dcfb72e82e032,Neural Information Processing Systems
1002,Comparison of Optic Nerve Head Parameters in Myopic and Nonmyopic Glaucoma Eyes,,2013-06-16,https://www.semanticscholar.org/paper/c401e8b0cc165ae7487c89e16a6bf45b040d6cd4,
808,Markov decision processes and regular events,,,https://www.semanticscholar.org/paper/8097db0f844d9663ab5e90ae9a8b1db7192d4a03,IEEE Transactions on Automatic Control
2188,Oral Ulcers in Juvenile-Onset Systemic Lupus Erythematosus: A Review of the Literature,,2017-05-05,https://www.semanticscholar.org/paper/13e5479f7bb9736698f02c869ffcda9c136e8f37,American Journal of Clinical Dermatology
3071,Session details: SIGMETRICS/Performance 2009 posters,,2009-10-16,https://www.semanticscholar.org/paper/47ce1b01dd8eb15a9fadf5004ba8c0a80ca6e36d,
1863,"Learning with Scope, with Application to Information Extraction and Classification","In probabilistic approaches to classification and information extraction, one typically builds a statistical model of words under the assumption that future data will exhibit the same regularities as the training data. In many data sets, however, there are scope-limited features whose predictive power is only applicable to a certain subset of the data. For example, in information extraction from web pages, word formatting may be indicative of extraction category in different ways on different web pages. The difficulty with using such features is capturing and exploiting the new regularities encountered in previously unseen data. In this paper, we propose a hierarchical probabilistic model that uses both local/scope-limited features, such as word formatting, and global features, such as word content. The local regularities are modeled as an unobserved random parameter which is drawn once for each local data set. This random parameter is estimated during the inference process and then used to perform classification with both the local and global features--- a procedure which is akin to automatically retuning the classifier to the local regularities on each newly encountered web page. Exact inference is intractable and we present approximations via point estimates and variational methods. Empirical results on large collections of web data demonstrate that this method significantly improves performance from traditional models of global features alone.",2002-08-01,https://www.semanticscholar.org/paper/41eba1efcd55beb1b70db260dc6f070f7317b71b,Conference on Uncertainty in Artificial Intelligence
245,Algorithmic Aspects of Game Theory Spring 2001 Lecture 2 : January 23,"We begin by looking at a set of theorems from various disciplines and how they relate to one another. From combinatorics, we take Sperner’s Lemma which we can use to prove Brouwer’s Fixed Point Theorem from topology. Brouwer’s Fixed Point Theorem can be used to prove the Arrow-Debreu Theorem from economics which states that general equilibria exist, and can also be used to prove Kakutani’s Fixed Point Theorem. Kakutani’s Fixed Point Theorem can be used to prove that Nash Equilibria exist for all games. A graph illustrating how these theorems can be used to prove each other is given in Figure 2.1.",,https://www.semanticscholar.org/paper/5839cdb24d93c1bfe577752c1d01044a19e0ff29,
2013,A novel bi-vector encoding genetic algorithm for the simultaneous multiple resources scheduling problem,,2011-07-27,https://www.semanticscholar.org/paper/7869da224d87a65f8649ffbf1f698b138038df00,Journal of Intelligent Manufacturing
1713,The Inverse Regression Topic Model,"Taddy (2013) proposed multinomial inverse regression (MNIR) as a new model of annotated text based on the influence of metadata and response variables on the distribution of words in a document. While effective, MNIR has no way to exploit structure in the corpus to improve its predictions or facilitate exploratory data analysis. On the other hand, traditional probabilistic topic models (like latent Dirichlet allocation) capture natural heterogeneity in a collection but do not account for external variables. In this paper, we introduce the inverse regression topic model (IRTM), a mixed-membership extension of MNIR that combines the strengths of both methodologies. We present two inference algorithms for the IRTM: an efficient batch estimation algorithm and an online variant, which is suitable for large corpora. We apply these methods to a corpus of 73K Congressional press releases and another of 150K Yelp reviews, demonstrating that the IRTM outperforms both MNIR and supervised topic models on the prediction task. Further, we give examples showing that the IRTM enables systematic discovery of in-topic lexical variation, which is not possible with previous supervised topic models.",2014-06-21,https://www.semanticscholar.org/paper/bc0d7df38dd99d19ea586ecea1e478c4305993fc,International Conference on Machine Learning
3196,Predator Attack Strategy and Prey Behaviour Drive Individual Predation Risk in Schooling Prey,"Predation is one of the main drivers of animal grouping. However, predation risk is not shared equally within groups. Despite long-standing theoretical work and strong empirical insights, very little work has examined the real-time dynamics of predators attacking groups of prey nor quantified the features that predict prey predation risk and survival. Here we used high resolution tracking of Northern pike (Esox lucius) attacking large schools of prey (golden shiner fish, Notemigonus crysoleucas) to get a mechanistic quantification of predation at every stage of the attack. We found that pike tended to attack the groups head-on, but did so stealthily, often striking only when partly within the school. From the predator’s perspective, relative position to the prey was the most important feature, with shiners very close and directly in front of the pike being most at risk. From the prey’s perspective, we found that central individuals, with relatively low local neighbour density and alignment, face increased risk. While the majority of attacks were successful, escape was associated with individuals achieving high maximum movement speeds, relative to others. Our study highlights both predator attack strategy and prey behaviour are key factors underlying the predation risk of grouping prey, and our results contradict the long-held assertion arising from Hamilton’s “selfish herd” concept that central positions are safer. To ultimately understand the cost-benefits that underly the evolution of animal grouping it is thus key to consider the multifaceted, and dynamical, nature of predator-prey relationships.",2021-01-26,https://www.semanticscholar.org/paper/a6178db6a7f22500fefd28b03497a5971dcf3bc1,
2101,CONSTRUCTING SEMICONDUCTOR MANUFACTURING PERFORMANCE INDEXES AND APPLYING DATA MINING FOR MANUFACTURING DATA ANALYSIS,"ABSTRACT The indexes for semiconductor manufacturing management are complicated and interrelated. Therefore, it is hard to clarify the relationships among the indexes and to derive useful rules for production management. Existing approaches rely on following individual indexes without considering the production system as a whole. This study aims to fill the gap by reviewing the related studies on semiconductor manufacturing management and developing a complete set of performance indexes in hierarchy. In addition, we apply data mining techniques for analyzing production data collected in a semiconductor fab in Taiwan to validate this approach. The empirically derived patterns among the critical indexes were useful for supporting production management decisions. The results demonstrate the practical viability of this approach. This study concludes with results and discussion on future research.",2004-01-01,https://www.semanticscholar.org/paper/f7041e71a0820cf45e7f4221fd9c768bacb58a56,
2023,Manufacturing intelligence for semiconductor demand forecast based on technology diffusion and product life cycle,,2010-12-01,https://www.semanticscholar.org/paper/334995c539cb65876d68e10b68b2fa3d7fdc9708,
2339,Effect of cytotoxic drugs on mature neutrophil function in the presence and absence of granulocyte‐macrophage colony‐stimulating factor,"Summary. The effects of the cytotoxic drugs, adriamycin, cyclophosphamide, daunomycin (daunorubicin), prednisolone, actinomycin D. azacytidine and vincristine at concentrations of 1 μM on mature neutrophil function were examined. Up to 5 h incubation with adriamycin, azacytidine, cyclophosphamide, daunomycin and prednisolone had no effect on either luminol chemiluminescence or superoxide secretion. However, after 15 min or 1 h (but not 5 h) incubation vincristine enhanced fMet‐Leu‐Phe stimulated chemiluminescence, whilst after 5 h incubation with actinomycin D the ability of neutrophils to generate reactive oxidants in response to all stimuli tested was impaired: after 5 h incubation with adriamycin reactive oxidant production was also impaired, but only when fMet‐Leu‐Phe was used as stimulant. All of the drugs tested except azacytidine inhibited neutrophil oxidant production after 5 h incubation in the presence of granulocyte‐macrophage colony‐stimulating factor (GM‐CSF). Actinomycin D and cyclophosphamide also inhibited GM‐CSF stimulated protein biosynthesis. These data indicate that cytotoxic drugs may compromise the potentially beneficial effects of CSFs on mature neutrophil function during therapy.",1993-06-01,https://www.semanticscholar.org/paper/fdc39f9e3b8197890d905e1f38b86b76800167d9,British Journal of Haematology
1008,Changes in Anterior Chamber Configuration after Cataract Surgery as Measured by Anterior Segment Optical Coherence Tomography,"Purpose To evaluate the changes in anterior chamber depth (ACD) and angle width induced by phacoemulsification and intraocular lens (IOL) implantation in normal eyes using anterior segment optical coherence tomography (AS-OCT). Methods Forty-five eyes (45 patients) underwent AS-OCT imaging to evaluate anterior chamber configuration before and 2 days after phacoemulsification and IOL implantation. We analyzed the central ACD and angle width using different methods: anterior chamber angle (ACA), trabecular-iris angle (TIA), angle opening distance (AOD), and trabecular iris surface area (TISA) in the nasal and temporal quadrants. Comparison between preoperative and postoperative measurement was done using paired t-tests and each of the angle parameters was analyzed with Pearson correlation testing. Subgroup analyses according to the IOL and axial length were performed with a general multivariate linear model adjusted for age. Results Before surgery, the mean anterior chamber angle widths were 23.21 ± 6.70° in the nasal quadrant and 24.89 ± 7.66° in the temporal quadrant. The mean central ACD was 2.75 ± 0.43 mm. After phacoemulsification and IOL implantation, the anterior chamber angle width increased significantly to 35.16 ± 4.65° in the nasal quadrant (p = 0.001) and 36.03 ± 4.86° in the temporal quadrant (p = 0.001). Also, central ACD increased to 4.14 ± 0.31 mm (p = 0.001). AOD, TISA, and TIA increased significantly after cataract surgery and showed positive correlation with ACA. Conclusions After cataract surgery, the ACD and angle width significantly increased in eyes with cataract. AS-OCT is a good method for obtaining quantitative data regarding anterior chamber configuration.",2011-03-11,https://www.semanticscholar.org/paper/18caeebafd600bf7330315d8bd4dcf1a37f6be62,Korean Journal of Ophthalmology
3168,Author Correction: Zebras of all stripes repel biting flies at close range,,2023-01-31,https://www.semanticscholar.org/paper/94ca125734bced5cfbad55715748b622fd0ffd8b,Scientific Reports
3213,Multilevel Organisation of Animal Sociality.,,2020-05-27,https://www.semanticscholar.org/paper/ff3ee824863692861609ae51976fd550e45829a2,Trends in Ecology & Evolution
2652,"Proceedings : IEEE Virtual Reality 2000 : 18-22 March 2000, New Brunswick, New Jersey",Workbenches Haptics Feeling Good! Applications Perception Projection-Based Displays Distributed Virtual Environments Animation and Navigation Haptics - Movers and Shakers Mixed Reality and Tracking.,,https://www.semanticscholar.org/paper/823f56a0441c592656b8e7565487a183bff29c26,
253,Kurt Gödel and the Foundations of Mathematics: Acknowledgments,,,https://www.semanticscholar.org/paper/6af2d97c14d0633e538bc3ca20da7362e1bc174e,
3178,Individual identification and photographic techniques in mammalian ecological and behavioural research—Part 1: Methods and concepts,,2022-06-01,https://www.semanticscholar.org/paper/68ddca179b35d3107fc1ec113ad1eaae876a1b8c,Mammalian Biology
3439,Models of malicious behavior in sponsored search,"Search engines such as Google, Yahoo, and MSN now auction off search terms to potential advertisers. The potential advertisers place their bids on each search term of interest, as well as specifying a daily budget. Each search on this term displays an advertisement that is linked to the advertiser's website, and the advertiser pays the search engine every time the link is activated. When an advertiser's budget is reached, the search engine stops displaying their ad. This kind of advertising is extremely popular -- the combined revenue of Yahoo and Google in 2005 was estimated at over 4.5 billion dollars. We develop small models which still have the property that malicious behavior such as bid-jamming still occurs as a rational best-response strategy. Such malicious behavior occurs frequently in practice. We are able to derive bidding strategies which are the best-responses when the budget of the bidder is low relative to her competitors, as well as strategies which protect against bid-jamming.",2007-03-25,https://www.semanticscholar.org/paper/05507d3c0b78768b0936674565a155c0668b4c96,Spring Simulation Multiconference
827,Perspectives on database theory,"Database management systems address the need to store, retrieve, and manipulate large amounts of data in an organized fashion. The database held has grown tremendously in the last 25 years. It is reported that the database industry generated $7 billion in revenue in 1994 and is growing at a rate of 35% per year. Industrial and academic research have been instrumental to this growth. Theory has played an important role in defining the right abstractions and concepts, and providing a firm foundation for the field. In order to access effectively a large volume of data, one needs an abstract logical view of the data, which must be separate from the physical storage of data. The important first component of a database is therefore an abstract view of data (called the data model) and the accompanying specialized high-level language that is used to access the data. The second important component is the data structures that are used to store the data along with the algorithms to support the efficient translation from the logical to the physical world. The third important component is the mechanisms that allow the database to be accessed concurrently by many users, without violating its integrity. Theory has contributed to all three fronts, starting with what is undoubtedly the cornerstone of the area, the introduction and formal definition of the relational model by F.P. Codd (1970). It is a highly unusual compliment for theory when the major commercial products in the field have at their core a mathematically rigorous, formal model. Our primary aims in this paper will be to give a flavor of the types of problems that database theory addresses, and to review how research in the area has evolved over the years. At the end we will try to point to some topics that may be of interest to people in the FOCS community tempted to work in database theory.",1995-10-23,https://www.semanticscholar.org/paper/b956b1e2eb41936462933913ebd7cf104b52d6d0,Proceedings of IEEE 36th Annual Foundations of Computer Science
1757,Stochastic variational inference,"We develop stochastic variational inference, a scalable algorithm for approximating posterior distributions. We develop this technique for a large class of probabilistic models and we demonstrate it with two probabilistic topic models, latent Dirichlet allocation and the hierarchical Dirichlet process topic model. Using stochastic variational inference, we analyze several large collections of documents: 300K articles from Nature, 1.8M articles from The New York Times, and 3.8M articles from Wikipedia. Stochastic inference can easily handle data sets of this size and outperforms traditional variational inference, which can only handle a smaller subset. (We also show that the Bayesian nonparametric topic model outperforms its parametric counterpart.) Stochastic variational inference lets us apply complex Bayesian models to massive data sets.",2012-06-29,https://www.semanticscholar.org/paper/bccb2f99a9d1c105699f5d88c479569085e2c7ba,Journal of machine learning research
1332,Study ofZγEvents and Limits on AnomalousZZγandZγγCouplings inpp¯Collisions ats=1.96TeV,,2005-07-27,https://www.semanticscholar.org/paper/03373ef58bccdbda29ca251f605f25a9f28a080f,
2050,Enhancing Competitive Advantages and Operational Excellence for High-Tech Industry through Data Mining and Digital Management,"As global competition continues to intensity in high-tech industry such as the semiconductor industry, wafer fabs have been placing more importance on the increase of die yield and the reduction of costs. Because of automatic manufacturing and information integration technologies, a large amount of raw data has been increasingly accumulated from various sources. Mining potentially useful information from such large databases becomes very important for high-tech industry to enhance operational excellence and thus maintain competitive advantages. However, little research has been done on manufacturing data of high-tech industry. Due to the complex fabrication processes, the data integration, system design, and requirement for cooperation among domain experts, IT specialists, and statisticians, the development and deployment of data mining applications is difficult. This chapter aims to describe characteristics of various data mining empirical studies in semiconductor manufacturing, particularly defect diagnosis and yield enhancement. We analyze engineering data and manufacturing data in different cases and discuss specific needs for data preparation in light of different characteristics of these data. This study concludes with several critical success factors for the development of data mining applications in high-tech industry.",,https://www.semanticscholar.org/paper/6b39cbc186769d9a8b0096aed76ce7a7a590df4b,
549,Shortest-Path Motion,,1986-12-18,https://www.semanticscholar.org/paper/4ebe2a7b86327b5ccf85ba7d9f093ba8a9bb83aa,Foundations of Software Technology and Theoretical Computer Science
2197,Whose Gene Is It Anyway? The Effect of Preparation Purity on Neutrophil Transcriptome Studies,"Protocols for the isolation of neutrophils from whole blood often result in neutrophil preparations containing low numbers (~5%) of contaminating leukocytes, and it is possible that these contaminating cells contribute to highly sensitive assays that measure neutrophil gene expression (e.g. qPCR). We investigated the contribution of contaminating leukocytes on the transcriptome profile of human neutrophils following stimulation with inflammatory cytokines (GM-CSF, TNFα), using RNA-Seq. Neutrophils were isolated using Polymorphprep or the StemCell untouched neutrophil isolation kit (negative selection of “highly pure” neutrophils). The level of contamination was assessed by morphology and flow cytometry. The major source of contamination in Polymorphprep neutrophil preparations was from eosinophils and was highly donor dependent. Contaminating cells were largely, but not completely, absent in neutrophil suspensions prepared using negative selection, but the overall yield of neutrophils was decreased by around 50%. RNA-seq analysis identified only 25 genes that were significantly differentially-expressed between Polymorphprep and negatively-selected neutrophils across all three treatment groups (untreated, GM-CSF, TNFα). The expression levels of 34 cytokines/chemokines both before and after GM-CSF or TNFα treatment were not significantly different between neutrophil isolation methods and therefore not affected by contributions from non-neutrophil cell types. This work demonstrates that low numbers (<5%) of contaminating leukocytes in neutrophil preparations contribute very little to the overall gene expression profile of cytokine-stimulated neutrophils, and that protocols for the isolation of highly pure neutrophils result in significantly lower yields of cells which may hinder investigations where large numbers of cells are required or where volumes of blood are limited.",2015-09-24,https://www.semanticscholar.org/paper/8e0a74cd5105e724df473d62cdbc807e96f233c8,PLoS ONE
171,An Axiomatic Approach to Block Rewards,"Proof-of-work blockchains reward each miner for one completed block by an amount that is, in expectation, proportional to the number of hashes the miner contributed to the mining of the block. Is this proportional allocation rule optimal? And in what sense? And what other rules are possible? In particular, what are the desirable properties that any ""good"" allocation rule should satisfy? To answer these questions, we embark on an axiomatic theory of incentives in proof-of-work blockchains at the time scale of a single block. We consider desirable properties of allocation rules including: symmetry; budget balance (weak or strong); sybil-proofness; and various grades of collusion-proofness. We show that Bitcoin's proportional allocation rule is the unique allocation rule satisfying a certain system of properties, but this does not hold for slightly weaker sets of properties, or when the miners are not risk-neutral. We also point out that a rich class of allocation rules can be approximately implemented in a proof-of-work blockchain.",2019-09-23,https://www.semanticscholar.org/paper/55e75c05da175841cdf096d0584a6202ccf619ee,Conference on Advances in Financial Technologies
1619,Comment: A Discussion of “Nonparametric Bayes Modeling of Populations of Networks”,"Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A., and Blei, D.M. (2017), “Automatic Differentiation Variational Inference,” Journal of Machine Learning Research, 18, 430–474. [1542] Ma, Y., Chen, T., and Fox, E. B. (2016), “A Complete Recipe for Stochastic Gradient MCMC,” in Advances in Neural Information Processing Systems (Vol. 28), pp. 2899–2907, Cambridge, MA: MIT Press. [1542] Ma, Y., Foti, N. J., and Fox, E. B. (2017), “Stochastic Gradient MCMC Methods for Hidden Markov Models,” in International Conference on Machine Learning, Proceedings of Machine Learning Research (Vol. 70), pp. 2265–2274. [1542] Neal, R. M. (2010), “MCMC Using Hamiltonian Dynamics,” Handbook of Markov Chain Monte Carlo, 54, 113–162. [1542] Rezende, D. J., Mohamed, S., and Wierstra, D. (2014), “Stochastic Backpropagation and Approximate Inference in Deep Generative Models,” in International Conference on Machine Learning. [1540] Tran, D., Kucukelbir, A., Dieng, A. B., Rudolph, M., Liang, D., and Blei, D. M. (2016), “Edward: A Library for Probabilistic Modeling, Inference, and Criticism,” arXiv preprint arXiv:1610.09787. [1540]",2017-10-02,https://www.semanticscholar.org/paper/163c48055cc2d26a1a1251c257ab55070794c07b,
2749,Interactive Multimedia Explanation for Equipment Maintenance and Repair,"We are developing COMET, an interactive system that generates multimedia explanations of how to operate, maintain, and repair equipment. Our research stresses the dynamic generation of the content and form of all material presented, addressing issues in the generation of text and graphics, and in coordinating text and graphics in an integrated presentation.",1990-06-24,https://www.semanticscholar.org/paper/9a1a9428af70ff258ca2ca42548d9c51f9a30a99,Human Language Technology - The Baltic Perspectiv
980,The Effects of Nonporous Silica Nanoparticles on Human Trabecular Meshwork Cells,,2018-07-13,https://www.semanticscholar.org/paper/a480b852aafaa574c287788e0e7f8afcaed2f291,
3560,Dynamic algorithm selection for runtime concepts,,2010-09-01,https://www.semanticscholar.org/paper/3fba9cbfd08e6cdeb0882be29a77bfc806aaaad1,Science of Computer Programming
1392,Status of CDMS search for dark matter WIMPs,"We report on the latest results from the CDMS (cryogenic dark matter search) experiment. The experiment uses superconducting particle detectors, operated below 100 mK, to search for dark matter in the form of weakly interacting massive elementary particles or WIMPs. These detectors are either Si or Ge crystals, where the electron-hole production and the phonon production are measured for each event, allowing the discrimination of electron recoils (most backgrounds due to gammas and betas) from nuclear recoils (due to WIMPs and neutrons). We have recently reported new limits from the Stanford shallow site experiment (CDMS-I) which explore supersymmetric models where the lightest supersymmetric particle is often an excellent WIMP candidate. We will also report on the Soudan deep site facility for the CDMS-II experiment which is under construction, and on the status of the CDMS-II detector fabrication.",2002-02-20,https://www.semanticscholar.org/paper/1a8000173e8f3d8efe4c293459dc3f4a5888082f,
3412,A Fast Distributed Stateless Algorithm for alpha-Fair Packing Problems,"Over the past two decades, fair resource allocation problems have received considerable attention in a variety of application areas. However, little progress has been made in the design of distributed algorithms with convergence guarantees for general and commonly used $\alpha$-fair allocations. In this paper, we study weighted $\alpha$-fair packing problems, that is, the problems of maximizing the objective functions (i) $\sum_j w_j x_j^{1-\alpha}/(1-\alpha)$ when $\alpha > 0$, $\alpha \neq 1$ and (ii) $\sum_j w_j \ln x_j$ when $\alpha = 1$, over linear constraints $Ax \leq b$, $x\geq 0$, where $w_j$ are positive weights and $A$ and $b$ are non-negative. We consider the distributed computation model that was used for packing linear programs and network utility maximization problems. Under this model, we provide a distributed algorithm for general $\alpha$ that converges to an $\varepsilon-$approximate solution in time (number of distributed iterations) that has an inverse polynomial dependence on the approximation parameter $\varepsilon$ and poly-logarithmic dependence on the problem size. This is the first distributed algorithm for weighted $\alpha-$fair packing with poly-logarithmic convergence in the input size. The algorithm uses simple local update rules and is stateless (namely, it allows asynchronous updates, is self-stabilizing, and allows incremental and local adjustments). We also obtain a number of structural results that characterize $\alpha-$fair allocations as the value of $\alpha$ is varied. These results deepen our understanding of fairness guarantees in $\alpha-$fair packing allocations, and also provide insight into the behavior of $\alpha-$fair allocations in the asymptotic cases $\alpha\rightarrow 0$, $\alpha \rightarrow 1$, and $\alpha \rightarrow \infty$.",2015-02-11,https://www.semanticscholar.org/paper/8d507b7f9bd9880134cdad1809cca22ada7a3faa,"International Colloquium on Automata, Languages and Programming"
2001,Manufacturing Intelligence to Forecast the Customer Order Behavior for Vendor Managed Inventory,,2012-05-01,https://www.semanticscholar.org/paper/85fce5c28a2e0770fd703ce95146fecf156b23ff,
2631,A menu interface for wearable computing,"We present a menu interface designed primarily for head-worn displays that have a small field-of-view. To support interaction with a hierarchical menu, we logically divide an absolute positioning device into finger-operated strip segments, which we use as one-dimensional scrolling devices. Our menu system is intended to make user interaction faster by not requiring constant visual feedback. This is preferable for interaction in which the visual user interface elements occupy only a small portion of the eye's entire field-of-view and in which navigating in menus with a pointer would be awkward and time-consuming. With our approach, it is even possible for the user to use peripheral vision for interaction, since there is no need to precisely position a small pointer on the screen. Thus, the user can maintain eye contact with others or keep his or her focus of attention on the environment while using a wearable device.",2002-10-07,https://www.semanticscholar.org/paper/5454925c64247189aae73eb94333ea19e15b12b8,"Proceedings. Sixth International Symposium on Wearable Computers,"
1379,A precision measurement of the mass of the top quark.,"The standard model of particle physics contains parameters--such as particle masses--whose origins are still unknown and which cannot be predicted, but whose values are constrained through their interactions. In particular, the masses of the top quark (M(t)) and W boson (M(W)) constrain the mass of the long-hypothesized, but thus far not observed, Higgs boson. A precise measurement of M(t) can therefore indicate where to look for the Higgs, and indeed whether the hypothesis of a standard model Higgs is consistent with experimental data. As top quarks are produced in pairs and decay in only about 10(-24) s into various final states, reconstructing their masses from their decay products is very challenging. Here we report a technique that extracts more information from each top-quark event and yields a greatly improved precision (of +/- 5.3 GeV/c2) when compared to previous measurements. When our new result is combined with our published measurement in a complementary decay mode and with the only other measurements available, the new world average for M(t) becomes 178.0 +/- 4.3 GeV/c2. As a result, the most likely Higgs mass increases from the experimentally excluded value of 96 to 117 GeV/c2, which is beyond current experimental sensitivity. The upper limit on the Higgs mass at the 95% confidence level is raised from 219 to 251 GeV/c2.",,https://www.semanticscholar.org/paper/e3ba7046752113f610952b9bc36f3b54b627bd56,Nature
1415,High-p(T) jets in p(p)over-bar collisions at root s=630 and 1800 GeV,,2001-08-01,https://www.semanticscholar.org/paper/d45207ce8fbc8b893375e772092d60ffaf321244,
3340,"An introduction to behavioural ecology (2nd edn): by J.R. Krebs and N.B. Davies, Blackwell Scientific Publications, 1987. £26.25 hbk, £12.80 pbk (ix + 389 pages) ISBN 0 632 01498 9",,1987-11-01,https://www.semanticscholar.org/paper/45f2947b4d8c87747ada083966b17e38c815a057,
878,"Pfaffian orientations, 0-1 permanents, and even cycles in directed graphs",,1989-09-01,https://www.semanticscholar.org/paper/4efb49c67ced92e20385af11db5cfd71bf3fe256,Discrete Applied Mathematics
1600,Noisin: Unbiased Regularization for Recurrent Neural Networks,"Recurrent neural networks (RNNs) are powerful models of sequential data. They have been successfully used in domains such as text and speech. However, RNNs are susceptible to overfitting; regularization is important. In this paper we develop Noisin, a new method for regularizing RNNs. Noisin injects random noise into the hidden states of the RNN and then maximizes the corresponding marginal likelihood of the data. We show how Noisin applies to any RNN and we study many different types of noise. Noisin is unbiased--it preserves the underlying RNN on average. We characterize how Noisin regularizes its RNN both theoretically and empirically. On language modeling benchmarks, Noisin improves over dropout by as much as 12.2% on the Penn Treebank and 9.4% on the Wikitext-2 dataset. We also compared the state-of-the-art language model of Yang et al. 2017, both with and without Noisin. On the Penn Treebank, the method with Noisin more quickly reaches state-of-the-art performance.",2018-05-03,https://www.semanticscholar.org/paper/672f28e2772b7d7895c5ce08ccd07eac3e60219e,International Conference on Machine Learning
160,Self-Attention Networks Can Process Bounded Hierarchical Languages,"Despite their impressive performance in NLP, self-attention networks were recently proved to be limited for processing formal languages with hierarchical structure, such as Dyck-k, the language consisting of well-nested parentheses of k types. This suggested that natural language can be approximated well with models that are too weak for formal languages, or that the role of hierarchy and recursion in natural language might be limited. We qualify this implication by proving that self-attention networks can process Dyck-(k, D), the subset of Dyck-k with depth bounded by D, which arguably better captures the bounded hierarchical structure of natural language. Specifically, we construct a hard-attention network with D+1 layers and O(log k) memory size (per token per layer) that recognizes Dyck-(k, D), and a soft-attention network with two layers and O(log k) memory size that generates Dyck-(k, D). Experiments show that self-attention networks trained on Dyck-(k, D) generalize to longer inputs with near-perfect accuracy, and also verify the theoretical memory advantage of self-attention networks over recurrent networks.",2021-05-24,https://www.semanticscholar.org/paper/b2186dd1ccc4b7adcf70c0cf7649c2c118e4ceea,Annual Meeting of the Association for Computational Linguistics
1918,Strategic capacity planning for smart production: Decision modeling under demand uncertainty,,2017-06-06,https://www.semanticscholar.org/paper/2626f5e6f8592c4baee9a17edc74105ba85bb654,Applied Soft Computing
1970,Hierarchical indices to detect equipment condition changes with high dimensional data for semiconductor manufacturing,,2014-10-01,https://www.semanticscholar.org/paper/debebc5cfdfeb3232bbf633eb352432c7478b53a,Journal of Intelligent Manufacturing
140,View planning and automated data acquisition for three‐dimensional modeling of complex sites,"Constructing highly detailed three‐dimensional (3‐D) models of large complex sites using range scanners can be a time‐consuming manual process. One of the main drawbacks is determining where to place the scanner to obtain complete coverage of a site. We have developed a system for automatic view planning called VuePlan. When combined with our mobile robot, AVENUE, we have a system that is capable of modeling large‐scale environments with minimal human intervention throughout both the planning and acquisition phases. The system proceeds in two distinct stages. In the initial phase, the system is given a two‐dimensional site footprint with which it plans a minimal set of sufficient and properly constrained covering views. We then use a 3‐D laser scanner to take scans at each of these views. When this planning system is combined with our mobile robot it automatically computes and executes a tour of these viewing locations and acquires them with the robot's onboard laser scanner. These initial scans serve as an approximate 3‐D model of the site. The planning software then enters a second phase in which it updates this model by using a voxel‐based occupancy procedure to plan the next best view (NBV). This NBV is acquired, and further NBVs are sequentially computed and acquired until an accurate and complete 3‐D model is obtained. A simulator tool that we developed has allowed us to test our entire view planning algorithm on simulated sites. We have also successfully used our two‐phase system to construct precise 3‐D models of real‐world sites located in New York City: Uris Hall on the campus of Columbia University and Fort Jay on Governors Island. © 2009 Wiley Periodicals, Inc.",,https://www.semanticscholar.org/paper/983d19a3b6559e487b6ed831a4631ca1a1bc1a37,J. Field Robotics
2565,LeafView: A User Interface for Automated Botanical Species Identification and Data Collection,"LeafView is a Tablet-PC–based user interface for automated identification of botanical species in the field, developed for the Columbia, University of Maryland and Smithsonian Electronic Field Guide Project. Leaf images are captured with a digital camera and wirelessly transferred to the tablet. A computer vision component developed by our colleagues finds the best set of matching species, and we present the results in a zoomable user interface. Samples are matched with existing species or marked unknown for further study. A history of collected samples along with collection context can be browsed for further study and comparison. The system has been field tested by Smithsonian botanists on Plummers Island, Maryland.",,https://www.semanticscholar.org/paper/03aaf836d2e83377535745ab9cf139e362ed1ed4,
3763,Anticipating the future by watching unlabeled video,"In many computer vision applications, machines will need to reason beyond the present, and predict the future. This task is challenging because it requires leveraging extensive commonsense knowledge of the world that is difficult to write down. We believe that a promising resource for efficiently obtaining this knowledge is through the massive amounts of readily available unlabeled video. In this paper, we present a large scale framework that capitalizes on temporal structure in unlabeled video to learn to anticipate both actions and objects in the future. The key idea behind our approach is that we can train deep networks to predict the visual representation of images in the future. We experimentally validate this idea on two challenging ""in the wild"" video datasets, and our results suggest that learning with unlabeled videos significantly helps forecast actions and anticipate objects.",2015-04-29,https://www.semanticscholar.org/paper/0fb3b63090f95af97723efe565893eb25ea9188c,arXiv.org
3008,A Secure and Formally Verified Linux KVM Hypervisor,"Commodity hypervisors are widely deployed to support virtual machines (VMs) on multiprocessor hardware. Their growing complexity poses a security risk. To enable formal verification over such a large codebase, we introduce microverification, a new approach that decomposes a commodity hypervisor into a small core and a set of untrusted services so that we can prove security properties of the entire hypervisor by verifying the core alone. To verify the multiprocessor hypervisor core, we introduce security-preserving layers to modularize the proof without hiding information leakage so we can prove each layer of the implementation refines its specification, and the top layer specification is refined by all layers of the core implementation. To verify commodity hypervisor features that require dynamically changing information flow, we introduce data oracles to mask intentional information flow. We can then prove noninterference at the top layer specification and guarantee the resulting security properties hold for the entire hypervisor implementation. Using microverification, we retrofitted the Linux KVM hypervisor with only modest modifications to its codebase. Using Coq, we proved that the hypervisor protects the confidentiality and integrity of VM data, while retaining KVM’s functionality and performance. Our work is the first machine-checked security proof for a commodity multiprocessor hypervisor.",2021-05-01,https://www.semanticscholar.org/paper/66537bf2100089307bb0baa0dc6df11a04c62531,IEEE Symposium on Security and Privacy
10,Sampling strategies for information extraction over the deep web,,2017-03-01,https://www.semanticscholar.org/paper/b358851d198a0fe1797bdcae52cf625c10b68986,Information Processing & Management
3180,Effects of a grazing permit market on pastoralist behavior and overgrazing in Kenya,"The success of market-based mechanisms in reducing conflicts and internalizing externalities depends on their ability to clarify property rights amongst heterogenous resource users. We investigate the effectiveness of novel markets in achieving their goals using the case study of grazing markets in Laikipia County, Kenya. In this system, sheep- and goat (shoat)- and cattle-rearing pastoralists negotiate land access for cattle with neighboring cattle ranchers. Using data on pastoralists’ livestock and contracting preferences and a model of pastoral herd management, we show that contracting for cattle grazing access on private property alters relative input shadow prices for grazing resources in communal pastoral lands, ultimately resulting in relieved cattle grazing pressure. However, the permitting process is less attractive to pastoralists who prefer rearing shoats instead of cattle. These shoat-rearing pastoralists instead fill some of the vacated space with shoats instead of purchasing permits themselves. This leakage offsets some of the conservation benefits arising from the contracting program and results in a greater share of shoats in the communal herd mix. Approximately 0.59 cows’ worth of free space persists on the commons per permit sold, indicating reduced grazing pressure, but this represents a small proportion (3.8%) of the total livestock in the system. The narrow introduction of the cattle-focused permit market and lack of strong management institutions on the commons dampen the permitting program’s conservation benefits, necessitating further interventions. Alleviating these factors and dramatically scaling up the program has the potential to turn the permitting system into a successful conservation tool.",2022-02-14,https://www.semanticscholar.org/paper/9757b6e25950c970ab1bbe8098901ff228dc24c7,Environmental Research Letters
3477,Introduction to algorithms. Chapter 16. 2nd Edition,,,https://www.semanticscholar.org/paper/88dc520fef31b16d8a4d491d85dfdb7d31c1deee,
3436,On distributing symmetric streaming computations,"A common approach for dealing with large data sets is to stream over the input in one pass, and perform computations using sublinear resources. For truly massive data sets, however, even making a single pass over the data is prohibitive. Therefore, streaming computations must be distribued over many machines. In practice, obtaining significant speedups using distributed computations has numerous challenges including synchronization, load balancing, overcoming processor failures, and data distribution. Successful Systems in practice such as Google's MapReduce and Apache's Hadoop address these problems by only allowing a certain class of highly distributable tasks defined by local computations that can be applied in any order to the input.
 The fundamental question that arises is: How does the class of computational tasks supported by these systems differ from the class for which streaming solutions exist?
 We introduce a simple algorithmic model for massive, unordered, distributed (mud) computation, as implemented by these systems. We show that in principle, mud algorithms are equivalent in power to symmetric streaming algorithms. More precisely, we show that any symmetric (order-invariant) function that can be computed by a steraming algorithm can also be computed by a mud algorithym, with comparable space and communication complexity. Our simulation uses Savitch's theorem and therefore has superpolynomial time complexity. We extend our simulation result to some natural classes of approximate and randomized steraming algorithms. We also give negative results, using communication complexity arguments to prove that extensions to private randomness, promise problems and indeterminate functions are impossible. We also introduce an extension of the mud model to multiple keys and multiple rounds.",2008-01-20,https://www.semanticscholar.org/paper/09d2f2521cff8614f5508f95db94356fe453cc5d,ACM-SIAM Symposium on Discrete Algorithms
2933,A New Distribution on the Simplex with Auto-Encoding Applications,"We construct a new distribution for the simplex using the Kumaraswamy distribution and an ordered stick-breaking process. We explore and develop the theoretical properties of this new distribution and prove that it exhibits symmetry under the same conditions as the well-known Dirichlet. Like the Dirichlet, the new distribution is adept at capturing sparsity but, unlike the Dirichlet, has an exact and closed form reparameterization--making it well suited for deep variational Bayesian modeling. We demonstrate the distribution's utility in a variety of semi-supervised auto-encoding tasks. In all cases, the resulting models achieve competitive performance commensurate with their simplicity, use of explicit probability models, and abstinence from adversarial training.",2019-05-28,https://www.semanticscholar.org/paper/5b79f76f26cc5bdfed0c5ac5ac3f34c6426ac8d3,Neural Information Processing Systems
2601,An evaluation of automatically generated briefings of patient status.,"We report on an evaluation of MAGIC, a system that automatically generates briefings of patient status after coronary bypass surgery, completed in the Cardio Thoracic Intensive Care Unit at New York Presbyterian Hospital. Through enhancements in system design, robustness and speed, we compared information obtained by nurses against two briefings, one automatically generated by MAGIC and one provided by physicians upon the patient's arrival to the ICU. Our results show that MAGIC and the physician briefing provide a substantial increase in the amount of information than is available prior to the patient's arrival and that the information MAGIC provides is accurate. In many aspects, MAGIC out-performs the physician briefing; information is reported earlier and is always available. We conclude that MAGIC provides the CT ICU staff early on with a better assessment of the patient's status than in current practice and allows them to better prepare for the patient's arrival.",,https://www.semanticscholar.org/paper/846dc901a3d0fdf79d604b1f48f93f18d1b974c7,
2830,Lack of Galectin-3 Drives Response to Paracoccidioides brasiliensis toward a Th2-Biased Immunity,"There is recent evidence that galectin-3 participates in immunity to infections, mostly by tuning cytokine production. We studied the balance of Th1/Th2 responses to P. brasiliensis experimental infection in the absence of galectin-3. The intermediate resistance to the fungal infection presented by C57BL/6 mice, associated with the development of a mixed type of immunity, was replaced with susceptibility to infection and a Th2-polarized immune response, in galectin-3-deficient (gal3−/−) mice. Such a response was associated with defective inflammatory and delayed type hypersensitivity (DTH) reactions, high IL-4 and GATA-3 expression and low nitric oxide production in the organs of infected animals. Gal3−/− macrophages exhibited higher TLR2 transcript levels and IL-10 production compared to wild-type macrophages after stimulation with P. brasiliensis antigens. We hypothesize that, during an in vivo P. brasiliensis infection, galectin-3 exerts its tuning role on immunity by interfering with the generation of regulatory macrophages, thus hindering the consequent Th2-polarized type of response.",2009-02-20,https://www.semanticscholar.org/paper/34c11fdb303daf9abe3228921665b3429b11a90f,PLoS ONE
2634,The AIL automated interface layout system,"We describe an automated layout system called AIL that generates the user interface for the PERSIVAL digital library project. AIL creates a layout based on a variety of content components and associated meta-data information provided by the PERSIVAL generation and retrieval modules. By leveraging semantic links between the content components, the layout that AIL provides is both context and user-model aware. In addition, AIL is capable of interacting intelligently with the natural language generation components of PERSIVAL to tailor the length of the text content for a given layout.",2002-01-13,https://www.semanticscholar.org/paper/94f39d5e80bbef400ba2acb339afe04a797d4e5f,International Conference on Intelligent User Interfaces
3017,Heterogeneous Multi-Mobile Computing,"As smartphones and tablets proliferate, there is a growing demand for multi-mobile computing, the ability to combine multiple mobile systems into more capable ones. We present M2, a system for multi-mobile computing that enables existing unmodified mobile apps to share and combine multiple devices, including cameras, displays, speakers, microphones, sensors, GPS, and input. M2 introduces a new data-centric approach that leverages higher-level device abstractions and hardware acceleration to efficiently share device data, not API calls. To support heterogeneous devices, M2 introduces device transformation, a new technique to mix and match different types of devices. Example transformations include combining multiple displays into a single larger display for better viewing, or substituting accelerometer for touchscreen input to provide a Nintendo Wii-like experience with existing mobile gaming apps. We have implemented M2 and show that it (1) operates across heterogeneous systems, including multiple versions of Android and iOS, (2) can enable unmodified Android apps to use multiple mobile devices in new and powerful ways, including supporting users with disabilities and better audio conferencing, and (3) can run apps across mobile systems with modest overhead and qualitative performance indistinguishable from using local device hardware.",2019-06-12,https://www.semanticscholar.org/paper/5beb9ed1dd02bcc0baa26d21a2b7568aec47901b,"ACM SIGMOBILE International Conference on Mobile Systems, Applications, and Services"
1211,Simultaneous measurement of the ratio R=B(t --> Wb)/B(t --> Wq) and the top-quark pair production cross section with the D0 detector at sqrt(s) = 1.96 TeV.,"We present the first simultaneous measurement of the ratio of branching fractions, R=B(t --> Wb)/B(t --> Wq), with q being a d, s, or b quark, and the top-quark pair production cross section sigma(tt[over]) in the lepton plus jets channel using 0.9 fb(-1) of pp[over] collision data at sqrt(s)=1.96 TeV collected with the D0 detector. We extract R and sigma(tt[over]) by analyzing samples of events with 0, 1, and > or =2 identified b jets. We measure R=0.97(+0.09)/(-0.08)(stat+syst) and sigma(tt[over])=8.18(+0.09)(-0.84)(stat+syst) +/- 0.50(lumi) pb, in agreement with the standard model prediction.",2008-01-08,https://www.semanticscholar.org/paper/46b09acf2ebed02ef3261ee33491138c83dbcd87,Physical Review Letters
2970,"Gene expression changes with age in skin, adipose tissue, blood and brain",,2013-07-01,https://www.semanticscholar.org/paper/083a1627e327721de3dc8b5818a351fd6b7939a4,Genome Biology
3243,"Vegetation, Wildlife, and Livestock Responses to Planned Grazing Management in an African Pastoral Landscape","Rangelands are vital for wildlife conservation and socio‐economic well‐being, but many face widespread degradation because in part of poor grazing management practices. Planned grazing management, typically involving time‐controlled rotational livestock grazing, is widely touted as a tool for promoting sustainable rangelands. However, real‐world assessments of its efficacy have been lacking in communal pastoral landscapes globally, and especially in Africa. We performed landscape‐scale assessment of the effects of planned grazing on selected vegetation, wildlife, and cattle attributes across wide‐ranging communally managed pastoral rangelands in northern Kenya. We found that planned grazing enhanced vegetation condition through a 17% increase in normalized difference vegetation index, 45–234% increases in herbaceous vegetation foliar cover, species richness and diversity, and a 70% reduction in plant basal gap. In addition, planned grazing increased the presence (44%) and species richness (53%) of wild ungulates and improved cattle weight gain (>71%) during dry periods when cattle were in relatively poor condition. These changes occurred relatively rapidly (within 5 years) and despite grazing incursion incidents and higher livestock stocking rates in planned grazing areas. These results demonstrate, for the first time in Africa, the positive effects of planned grazing implementation in communal pastoral rangelands. These improvements can have broad implications for biodiversity conservation and pastoral livelihoods. Copyright © 2017 John Wiley & Sons, Ltd.",2017-10-01,https://www.semanticscholar.org/paper/ed5e7c94119f34a41d41a58756fe7fa9289fe1ab,
1172,Measurement of dijet angular distributions at square root(s) = 1.96 TeV and searches for quark compositeness and extra spatial dimensions.,"We present the first measurement of dijet angular distributions in pp collisions at square root(s) = 1.96 TeV at the Fermilab Tevatron Collider. The measurement is based on a dataset corresponding to an integrated luminosity of 0.7 fb(-1) collected with the D0 detector. Dijet angular distributions have been measured over a range of dijet masses, from 0.25 TeV to above 1.1 TeV. The data are in good agreement with the predictions of perturbative QCD and are used to constrain new physics models including quark compositeness, large extra dimensions, and TeV(-1) scale extra dimensions. For all models considered, we set the most stringent direct limits to date.",,https://www.semanticscholar.org/paper/9ea51e0457f41ec5d1f0e8abc75fac913207e213,Physical Review Letters
863,Linear approximation of shortest superstrings,"We consider the following problem: given a collection of strings s1,…, sm, find the shortest string s such that each si appears as a substring (a consecutive block) of s. Although this problem is known to be NP-hard, a simple greedy procedure appears to do quite well and is routinely used in DNA sequencing and data compression practice, namely: repeatedly merge the pair of (distinct) strings with maximum overlap until only one string remains. Let n denote the length of the optimal superstring. A common conjecture states that the above greedy procedure produces a superstring of length O(n) (in fact, 2n), yet the only previous nontrivial bound known for any polynomial-time algorithm is a recent O(n log n) result.We show that the greedy algorithm does in fact achieve a constant factor approximation, proving an upper bound of 4n. Furthermore, we present a simple modified version of the greedy algorithm that we show produces a superstring of length at most 3n. We also show the superstring problem to be MAXSNP-hard, which implies that a polynomial-time approximation scheme for this problem is unlikely.",1991-01-03,https://www.semanticscholar.org/paper/94dc290720959e2f8f4314e1c119db19775038e5,Symposium on the Theory of Computing
1623,Hierarchical Implicit Models and Likelihood-Free Variational Inference,"Implicit probabilistic models are a flexible class of models defined by a simulation process for data. They form the basis for theories which encompass our understanding of the physical world. Despite this fundamental nature, the use of implicit models remains limited due to challenges in specifying complex latent structure in them, and in performing inferences in such models with large data sets. In this paper, we first introduce hierarchical implicit models (HIMs). HIMs combine the idea of implicit densities with hierarchical Bayesian modeling, thereby defining models via simulators of data with rich hidden structure. Next, we develop likelihood-free variational inference (LFVI), a scalable variational inference algorithm for HIMs. Key to LFVI is specifying a variational family that is also implicit. This matches the model's flexibility and allows for accurate approximation of the posterior. We demonstrate diverse applications: a large-scale physical simulator for predator-prey populations in ecology; a Bayesian generative adversarial network for discrete data; and a deep implicit model for text generation.",2017-02-28,https://www.semanticscholar.org/paper/375aa8e5ed444c6f83e2abeff8475f76833a0a2e,Neural Information Processing Systems
1182,Search for the associated production of a b quark and a neutral supersymmetric Higgs boson which decays to tau pairs,We report results from a search for production of a neutral Higgs boson in association with a $b$ quark. We search for Higgs decays to $\tau$ pairs with one $\tau$ subsequently decaying to a muon and the other to hadrons. The data correspond to 2.7fb$^{-1}$ of $\ppbar$ collisions recorded by the D0 detector at $\sqrt{s} = 1.96$TeV. The data are found to be consistent with background predictions. The result allows us to exclude a significant region of parameter space of the minimal supersymmetric model.,2009-12-05,https://www.semanticscholar.org/paper/c75fdbeba0d9bd82748ccbc7660aaa97bf56b5c1,
202,From Nash Equilibria to Chain Recurrent Sets: Solution Concepts and Topology,"Nash's universal existence theorem for his notion of equilibria was essentially an ingenious application of fixed point theorems, the most sophisticated result in his era's topology --- in fact, recent algorithmic work has established that Nash equilibria are in fact computationally equivalent to fixed points. Here, we shift focus to universal non-equilibrium solution concepts that arise from an important theorem in the topology of dynamical systems that was unavailable to Nash. This approach takes as input both a game and a learning dynamic, defined over mixed strategies. Nash equilibria are guaranteed to be fixed points of such dynamics; however, the system behavior is captured by a more general object that is known in dynamical systems theory as chain recurrent set. Informally, once we focus on this solution concept, every game behaves like a potential game with the dynamic converging to these states. We characterize this solution for simple benchmark games under replicator dynamics, arguably the best known evolutionary dynamic in game theory. For potential games it coincides with the notion of equilibrium; however, in simple zero sum games, it can cover the whole state space. We discuss numerous novel computational as well as structural, combinatorial questions that chain recurrence raises.",2016-01-14,https://www.semanticscholar.org/paper/77512cd92ad8a22e756835c74c51c7853ab2cd0e,Information Technology Convergence and Services
332,Recent Developments in Equilibria Algorithms,,2005-12-15,https://www.semanticscholar.org/paper/64cf156a8b357aa592fc19f613470a46bb31debd,Workshop on Internet and Network Economics
3142,THE COLUMBIA HOTSPOT RESCUE SERVICE: A RESEARCH PLAN,"The technical reports in this series are considered to be semi-formal. The ideas expressed are solely those of the authors, and questions about the content should be directed to them. 1 Introduction Internet performance is unpredictable, and users often find the level of service inadequate. We expect this problem to worsen as the Internet continues to grow, both in the number of users and in the stringency of the requirements of new applications. Intolerable levels of service stem from a lack of sufficient resources being targeted to locations where service quality is lacking. In a system as complex as the Internet, the insufficient resource can be of many types. It may be a server with insufficient processing power to handle a large load of requests. It may be a router at the edge of the network that is forced to carry a heavy load to or from its local area network. It may be a router in the middle of the network that must carry a large load, perhaps connecting a set of ISPs, such that upgrading its performance does not directly increase any company's profits. Lastly, it may be an attacker intentionally trying to bring down a portion of the network. Commonly, the periods of insufficiency are short-lived. In other words, the resources allocated within a network to support a service are sufficient most of the time, but every so often and quite suddenly, there may be a sharp increase in demand, and the resource quickly becomes overwhelmed. Such an event is called a network hotspot [1, 2]. There are several remedies currently available to deal with network hotspots. The easiest, most common solution is to make do with the network as is and deal ad hoc with the unpredictable level of service. A second remedy that works in theory is to "" build a better network "" in which hot spots do not occur. Here, each network and server component must be provisioned with enough resources to handle the maximum possible short-term overload. However, such overprovisioning is extremely costly, making it an infeasible solution for the majority of network servers and users. Another remedy is for companies to offer content delivery services, such as caching or access to additional network bandwidth [3]. The content delivery company deploys servers throughout the network, and then profits when those wishing to provide information efficiently are forced to pay for access to …",,https://www.semanticscholar.org/paper/97fde10b5cd0e68f7257009caa2829f6c2f8109b,
1438,Physics at γγ and eγ Colliders,"New developments in linear collider and laser technology should soon make it possible to construct a Photon Linear Collider, where high energy photon beams, produced by Compton backscattering laser photons off linac electrons, are brought into collision with electron beams or with other photon beams. High luminosities, along with control over both the energy distribution and polarization of the photon beams, will give such a facility the potential for a very interesting physics program. In particular, a Photon Linear Collider offers a unique environment for the study of Higgs bosons and discovery of new particles such as excited electron states, supersymmetric particles, heavy charged particle pairs, or any particles with appreciable two-photon couplings. Precision electroweak tests also benefit from such a machine, allowing a test of the three-gauge-boson WWγ vertex. The Photon Linear Collider would serve as an excellent laboratory for Quantum Chromodynamics studies involving photon structure functions, jet and hadron production, and resonance production.",1996-04-10,https://www.semanticscholar.org/paper/2a927e1d3cf2900a1f738fa250e8721aeacc6b55,
768,"Recursive Markov chains, stochastic grammars, and monotone systems of nonlinear equations","We define Recursive Markov Chains (RMCs), a class of finitely presented denumerable Markov chains, and we study algorithms for their analysis. Informally, an RMC consists of a collection of finite-state Markov chains with the ability to invoke each other in a potentially recursive manner. RMCs offer a natural abstract model for probabilistic programs with procedures. They generalize, in a precise sense, a number of well-studied stochastic models, including Stochastic Context-Free Grammars (SCFG) and Multi-Type Branching Processes (MT-BP).
 We focus on algorithms for reachability and termination analysis for RMCs: what is the probability that an RMC started from a given state reaches another target state, or that it terminates? These probabilities are in general irrational, and they arise as (least) fixed point solutions to certain (monotone) systems of nonlinear equations associated with RMCs. We address both the qualitative problem of determining whether the probabilities are 0, 1 or in-between, and the quantitative problems of comparing the probabilities with a given bound, or approximating them to desired precision.
 We show that all these problems can be solved in PSPACE using a decision procedure for the Existential Theory of Reals. We provide a more practical algorithm, based on a decomposed version of multi-variate Newton's method, and prove that it always converges monotonically to the desired probabilities. We show this method applies more generally to any monotone polynomial system. We obtain polynomial-time algorithms for various special subclasses of RMCs. Among these: for SCFGs and MT-BPs (equivalently, for 1-exit RMCs) the qualitative problem can be solved in P-time; for linearly recursive RMCs the probabilities are rational and can be computed exactly in P-time.
 We show that our PSPACE upper bounds cannot be substantially improved without a breakthrough on long standing open problems: the square-root sum problem and an arithmetic circuit decision problem that captures P-time on the unit-cost rational arithmetic RAM model. We show that these problems reduce to the qualitative problem and to the approximation problem (to within any nontrivial error) for termination probabilities of general RMCs, and to the quantitative decision problem for termination (extinction) of SCFGs (MT-BPs).",2005-02-24,https://www.semanticscholar.org/paper/3939ab4498e35f8404fddbe42ae5bb1d4e62258f,JACM
1147,Observation of Single Top-Quark Production,"We report observation of the electroweak production of single top quarks in ppbar collisions at sqrt(s) = 1.96 TeV based on 2.3 fb^-1 of data collected by the D0 detector at the Fermilab Tevatron Collider. Using events containing an isolated electron or muon and missing transverse energy, together with jets originating from the fragmentation of b quarks, we measure a cross section of sigma(ppbar ->tb + X, tqb + X) = 3.94 +- 0.88 pb. The probability to measure a cross section at this value or higher in the absence of signal is 2.5 x 10^-7, corresponding to a 5.0 standard deviation significance for the observation.",2009-03-04,https://www.semanticscholar.org/paper/286e2c01cf6cc7bce6899064074569e6f888aaad,
2347,Chemiluminescence and superoxide production in Acanthamoeba castellanii: free radicals generated during oxidative stress,"The amoeba Acanthamoeba castellanii generated both luminol- and lucigenin-enhanced chemiluminescence upon addition of the respiratory inhibitor sodium cyanide, but not upon the addition of sodium azide. Photon emission in the presence of lucigenin was three- to fourfold greater than that measured in the presence of luminol, but both forms of chemiluminescence were strictly dependent upon the presence of O2, indicating the requirement for oxidative reactions in these processes. Lucigenin-chemilununescence measured during the phagocytosis of latex beads under identical conditions was, however, barely detectable above background levels. Cyanide similarly induced the formation of O-2, as indicated by the stimulation of superoxide-dismutase-inhibitable cytochrome c reduction, and the rate of production was similar to that previously observed during phagocytosis of latex particles or yeasts by these cells. Thus, in view of the similar rates of O-2 production during cyanide exposure or phagocytosis, but disparate rates of lucigenin-chemiluminescence, these two treatments must activate different molecular processes leading to reactive oxidant production. The rates of cyanide-stimulated lucigenin-chemiluminescence were directly proportional to the O2 tensions in the medium from 0 to 300 μM, indicating that the rates of free-radical-generating reactions were directly related to the oxygen tensions in the environment. The superoxide dismutase inhibitor diethyldithiocarbamate similarly stimulated lucigenin-chemiluminescence, with photon emission again being dependent upon O2 tensions in the range 0-320 μM. A mechanism by which cells may limit O-2 generating reactions, and so reduce damaging free radical reactions, was observed when anaerobic suspensions were re-aerated. These data indicate that oxidative stress and phagocytosis provide two intracellular sources of free-radical generating reactions in these cells.",1991-05-01,https://www.semanticscholar.org/paper/f400b84c85a6ab9354b908c6f7e2c3e57dcf21f5,
2558,Urban Computing and Mobile Devices,"In this issue's Works in Progress department, we have 12 urban computing and mobile device entries that span a wide range of computing and social areas. The first entry examines how an urban environment could operate as a large-scale, real-time control system. One project focuses on annotating public spaces and sharing the tags with others. Two projects tie together social networking in cyberspace with local urban communities. Two projects examine computing and social interactions in physical spaces. Two entries explore how to combine synthetic and physical views of urban environments. Four entries investigate how we explore urban spaces, interact with technology in those spaces, and create shared community histories.",2007-07-01,https://www.semanticscholar.org/paper/9216aa5bc9e3f20d190e7c7c9fc9e6c3b591b39a,IEEE pervasive computing
3649,Exception handling for c++ (revised),,,https://www.semanticscholar.org/paper/6fa900a129754d636424c6ac7bad6d9e84978f36,
922,Node-Deletion Problems on Bipartite Graphs,"A set of problems which has attracted considerable interest recently is the set of node-deletion problems. The general node-deletion problem can be stated as follows: Given a graph, find the minimum number of nodes whose deletion results in a subgraph satisfying property $\pi $. In [LY] this problem was shown to be NP-complete for a large class of properties (the class of properties that are hereditary on induced subgraphs) using a small number of reduction schemes from the node cover problem. Since the node cover problem becomes polynomial on bipartite graphs, it might be hoped that this is the case with other node-deletion problems too.In this paper we characterize those properties for which the bipartite restriction of the node-deletion problem is polynomial and those for which it remains NP-complete. Similar results follow for analogous problems on other structures such as families of sets, hypergraphs and 0,1 matrices. For example, in the case of matrices, our result states that if M is a class of 0,...",1981-05-01,https://www.semanticscholar.org/paper/72ce49a2fb801d583ed1074625ce826c17609664,SIAM journal on computing (Print)
2123,貝氏推論架構與概似函數特性之研究; A Proposed Bayesian Inference Framework and the Property of the Likelihood Function,,,https://www.semanticscholar.org/paper/6ad566173ee2502689761253b848e73a57164d80,
2770,An integrated system for creating and presenting complex computer-based documents,"An experimental system is described for the design, development, and presentation of computer-based documents that combine pictures and text on a high-resolution raster color display. Such documents can be used, for example, for maintenance and repair tasks or computer-aided instruction.
 Documents are directed graphs whose nodes we refer to as pages, in analogy to the pages of a paper book. A page includes a set of simultaneously displayed pictures, actions (procedures and processes) triggered when the page is accessed or when pickable picture elements on it are selected, and indexing information. Pages may be nested arbitrarily deeply in chapters that serve much the same organizing function as those of conventional books.
 The system is comprised of separate programs for laying out and drawing pictures, for graphically specifying the contents of pages, chapters, and their interconnections, and for displaying the document for user interaction.
 Examples are given from a prototype document for the maintenance and repair of computerized numerical control equipment. Emphasis was placed on designing actions for simple realtime animation (both by color table techniques and by transforming named primitives and manipulating their attributes), and for finding one's way around the document (displays include: a “timeline” of recently visited pages, immediate predecessor and successor pages, sibling pages and their interconnections, and those pages satisfying key-word retrieval requests).",1981-08-03,https://www.semanticscholar.org/paper/763fef1efe5bba96020e784657423a0a0a198875,International Conference on Computer Graphics and Interactive Techniques
1306,Search for pair production of scalar bottom quarks in $p \bar p $ collisions at $\sqrt s $ 1.96-TeV,"A search for direct production of scalar bottom quarks (sb) is performed with 310 pb-1 of data collected by the DO experiment in ppbar collisions at sqrt(s)=1.96 TeV at the Fermilab Tevatron Collider. The topology analyzed consists of two b jets and an imbalance in transverse momentum due to undetected neutralinos chi0_1, with chi0_1 assumed to be the lightest supersymmetric particle. We find the data consistent with standard model expectations, and set a 95% C.L. exclusion domain in the (m_sb,m_chi0_1) mass plane, improving significantly upon the results from Run I of the Tevatron.",2006-08-01,https://www.semanticscholar.org/paper/2e4f64f8a3ee5415da0617466dee0c8ab5d6f2be,
2178,"Type I interferon regulates cytokine‐delayed neutrophil apoptosis, reactive oxygen species production and chemokine expression","Interferons (IFNs) are key regulators of a number of inflammatory conditions in which neutrophils play an important role in pathology, such as rheumatoid arthritis (RA) and systemic lupus erythematosus (SLE), where type I IFNs are implicated in disease pathology. However, IFNs are usually generated in vivo together with other cytokines that also have immunoregulatory functions, but such interactions are poorly defined experimentally. We measured the effects of type I (IFN‐α) IFN, elevated in both RA and SLE, on the functions of healthy neutrophils incubated in vitro in the absence and presence of proinflammatory cytokines typically elevated in inflammatory diseases [tumour necrosis factor (TNF‐α), granulocyte–macrophage colony‐stimulating factor (GM‐CSF)]. IFN‐α alone had no effect on neutrophil apoptosis; however, it abrogated the anti‐apoptotic effect of GM‐CSF (18 h, P < 0·01). The enhanced stability of the anti‐apoptotic protein myeloid cell leukaemia 1 (Mcl‐1) and delayed activation of caspase activation normally regulated by GM‐CSF were blocked by IFN‐α: this effect was mediated, in part, by activation of p38 mitogen‐activated protein kinase (MAPK). IFN‐α alone also primed reactive oxygen species (ROS) production and maintained the transient priming effect of TNF‐α for up to 4 h: it also down‐regulated GM‐CSF‐ and TNF‐α‐activated expression of chemokine (C‐X‐C motif) ligand (CXCL)1, CXCL2, CXCL3, CXCL8, CCL3 and CCL4 but, in contrast, increased the expression of CXCL10. These novel data identify complex regulatory signalling networks in which type I IFNs profoundly alter the response of neutrophils to inflammatory cytokines. This is likely to have important consequences in vivo and may explain the complexity and heterogeneity of inflammatory diseases such as RA, in which multiple cytokine cascades have been activated.",2020-09-29,https://www.semanticscholar.org/paper/e4023a06fbb929f6eebe9719d3822ff5451d0b29,Clinical and Experimental Immunology
2629,An annotated situation-awareness aid for augmented reality,"We present a situation-awareness aid for augmented reality systems based on an annotated ""world in miniature."" Our aid is designed to provide users with an overview of their environment that allows them to select and inquire about the objects that it contains. Two key capabilities are discussed that are intended to address the needs of mobile users. The aid's position, scale, and orientation are controlled by a novel approach that allows the user to inspect the aid without the need for manual interaction. As the user alternates their attention between the physical world and virtual aid, popup annotations associated with selected objects can move freely between the objects' representations in the two models.",2002-10-27,https://www.semanticscholar.org/paper/2e4eb85e1173798f96ebc6ddce4b3e500ba9829e,ACM Symposium on User Interface Software and Technology
3187,Stepping Up: A U.S. Perspective on the Ten Steps to Responsible Inland Fisheries,,2021-12-22,https://www.semanticscholar.org/paper/0386c5c438f41ed726c6160df759a532d5f55832,Fisheries
1374,Further results from the CDMS experiment,,2004-03-11,https://www.semanticscholar.org/paper/8258f9be51479e22ac62f69d62a326498995bcbc,
2657,Exploring MARS: developing indoor and outdoor user interfaces to a mobile augmented reality system,,1999-12-01,https://www.semanticscholar.org/paper/0da46b2f0c58f993af35a976033ff056c56cdf86,Computers & graphics
3418,Fast First-Order Algorithms for Packing–Covering Semidefinite Programs,,,https://www.semanticscholar.org/paper/1728962b46fa79efb1ffe2b99b66651b09e412f6,
781,Inference of Message Sequence Charts *,"Software designers draw Message Sequence Charts for early modeling of the individual behaviors they expect from the concurrent system under design. Can they be sure that precisely the behaviors they have described are realizable by some implementation of the components of the concurrent system? If so, can we automatically synthesize concurrent state machines realizing the given MSCs? If, on the other hand, other unspecified and possibly unwanted scenarios are 100 "" implied "" by their MSCs, can the software designer be automatically warned and provided the implied MSCs? In this paper we provide a framework in which all these questions are answered positively. We first describe the formal framework within which one can derive implied MSCs, and then provide polynomial-time algorithms for implication, realizability, and synthesis.",,https://www.semanticscholar.org/paper/e9a68500d31794d8dbe57614087e248669bf56dc,
692,Smoothed Complexity of SWAP in Local Graph Partitioning,"We give the first quasipolynomial upper bound $\phi n^{\text{polylog}(n)}$ for the smoothed complexity of the SWAP algorithm for local Graph Partitioning (also known as Bisection Width), where $n$ is the number of nodes in the graph and $\phi$ is a parameter that measures the magnitude of perturbations applied on its edge weights. More generally, we show that the same quasipolynomial upper bound holds for the smoothed complexity of the 2-FLIP algorithm for any binary Maximum Constraint Satisfaction Problem, including local Max-Cut, for which similar bounds were only known for $1$-FLIP. Our results are based on an analysis of cycles formed in long sequences of double flips, showing that it is unlikely for every move in a long sequence to incur a positive but small improvement in the cut weight.",2023-05-25,https://www.semanticscholar.org/paper/b1b60d6f6a6679e616c7efeaaeb2e0229cda3e8a,arXiv.org
1360,Study of Z Events and Limits on Anomalous ZZ and Z Couplings in p p Collisions at s p 1 : 96 TeV,"V. M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, M. Agelou, J.-L. Agram, S. H. Ahn, M. Ahsan, G. D. Alexeev, G. Alkhazov, A. Alton, G. Alverson, G. A. Alves, M. Anastasoaie, T. Andeen, S. Anderson, B. Andrieu, Y. Arnoud, A. Askew, B. Åsman, A. C. S. Assis Jesus, O. Atramentov, C. Autermann, C. Avila, F. Badaud, A. Baden, B. Baldin, P. W. Balm, S. Banerjee, E. Barberis, P. Bargassa, P. Baringer, C. Barnes, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, A. Bean, S. Beauceron, M. Begel, A. Bellavance, S. B. Beri, G. Bernardi, R. Bernhard,* I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, M. Binder, C. Biscarat, K. M. Black, I. Blackler, G. Blazey, F. Blekman, S. Blessing, D. Bloch, U. Blumenschein, A. Boehnlein, O. Boeriu, T. A. Bolton, F. Borcherding, G. Borissov, K. Bos, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, S. Burdin, T. H. Burnett, E. Busato, J. M. Butler, J. Bystricky, S. Caron, W. Carvalho, B. C. K. Casey, N. M. Cason, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K. M. Chan, A. Chandra, D. Chapin, F. Charles, E. Cheu, D. K. Cho, S. Choi, B. Choudhary, T. Christiansen, L. Christofek, D. Claes, B. Clément, C. Clément, Y. Coadou, M. Cooke, W. E. Cooper, D. Coppage, M. Corcoran, A. Cothenet, M.-C. Cousinou, B. Cox, S. Crépé-Renaudin, M. Cristetiu, D. Cutts, H. da Motta, B. Davies, G. Davies, G. A. Davis, K. De, P. de Jong, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, S. Dean, J. D. Degenhardt, F. Déliot, M. Demarteau, R. Demina, P. Demine, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, M. Doidge, H. Dong, S. Doulas, L. V. Dudko, L. Duflot, S. R. Dugad, A. Duperrin, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, T. Edwards, J. Ellison, J. Elmsheuser, V. D. Elvira, S. Eno, P. Ermolov, O. V. Eroshin, J. Estrada, D. Evans, H. Evans, A. Evdokimov, V. N. Evdokimov, J. Fast, S. N. Fatakia, L. Feligioni, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, I. Fleck, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, E. Gallas, E. Galyaev, C. Garcia, A. Garcia-Bellido, J. Gardner, V. Gavrilov, P. Gay, D. Gelé, R. Gelhaus, K. Genser, C. E. Gerber, Y. Gershtein, G. Ginther, T. Golling, B. Gómez, K. Gounder, A. Goussiou, P. D. Grannis, S. Greder, H. Greenlee, Z. D. Greenwood, E. M. Gregores, Ph. Gris, J.-F. Grivaz, L. Groer, S. Grünendahl, M. W. Grünewald, S. N. Gurzhiev, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, S. Hagopian, I. Hall, R. E. Hall, C. Han, L. Han, K. Hanagaki, K. Harder, R. Harrington, J. M. Hauptman, R. Hauser, J. Hays, T. Hebbeker, D. Hedin, J. M. Heinmiller, A. P. Heinson, U. Heintz, C. Hensel, G. Hesketh, M. D. Hildreth, R. Hirosky, J. D. Hobbs, B. Hoeneisen, M. Hohlfeld, S. J. Hong, R. Hooper, P. Houben, Y. Hu, J. Huang, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, V. Jain, K. Jakobs, A. Jenkins, R. Jesik, K. Johns, M. Johnson, A. Jonckheere, P. Jonsson, A. Juste, D. Käfer, W. Kahl, S. Kahn, E. Kajfasz, A. M. Kalinin, J. Kalk, D. Karmanov, J. Kasper, D. Kau, R. Kaur, R. Kehoe, S. Kermiche, S. Kesisoglou, A. Khanov, A. Kharchilava, Y. M. Kharzheev, H. Kim, B. Klima, M. Klute, J. M. Kohli, M. Kopal, V. M. Korablev, J. Kotcher, B. Kothari, A. Koubarovsky, A. V. Kozelov, J. Kozminski, A. Kryemadhi, S. Krzywdzinski, S. Kuleshov, Y. Kulik, A. Kumar, S. Kunori, A. Kupco, T. Kurča, J. Kvita, S. Lager, N. Lahrichi, G. Landsberg, J. Lazoflores, A.-C. Le Bihan, P. Lebrun, W. M. Lee, A. Leflat, F. Lehner,* C. Leonidopoulos, J. Leveque, P. Lewis, J. Li, Q. Z. Li, J. G. R. Lima, D. Lincoln, S. L. Linn, J. Linnemann, V. V. Lipaev, R. Lipton, L. Lobo, A. Lobodenko, M. Lokajicek, A. Lounis, P. Love, H. J. Lubatti, L. Lueking, M. Lynker, A. L. Lyon, A. K. A. Maciel, R. J. Madaras, P. Mättig, C. Magass, A. Magerkurth, A.-M. Magnan, N. Makovec, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, H. S. Mao, Y. Maravin, M. Martens, S. E. K. Mattingly, A. A. Mayorov, R. McCarthy, R. McCroskey, D. Meder, H. L. Melanson, A. Melnitchouk, A. Mendes, M. Merkin, K. W. Merritt, A. Meyer, M. Michaut, H. Miettinen, J. Mitrevski, N. Mokhov, J. Molina, N. K. Mondal, R. W. Moore, G. S. Muanza, M. Mulders, Y. D. Mutaf, E. Nagy, M. Narain, N. A. Naumann, H. A. Neal, J. P. Negret, S. Nelson, P. Neustroev, C. Noeding, A. Nomerotski, S. F. Novaes, T. Nunnemann, E. Nurse, V. O’Dell, D. C. O’Neil, V. Oguri, N. Oliveira, N. Oshima, G. J. Otero y Garzón, P. Padley, N. Parashar, S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, P. M. Perea, E. Perez, P. Pétroff, M. Petteni, L. Phaf, R. Piegaia, M.-A. Pleier, P. L. M. Podesta-Lerma, V. M. Podstavkov,",,https://www.semanticscholar.org/paper/db90f4c5e7e2fcd9840c36d65fc91e358878df60,
1579,Equal Opportunity and Affirmative Action via Counterfactual Predictions,"Machine learning (ML) can automate decision-making by learning to predict decisions from historical data. However, these predictors may inherit discriminatory policies from past decisions and reproduce unfair decisions. In this paper, we propose two algorithms that adjust fitted ML predictors to make them fair. We focus on two legal notions of fairness: (a) providing equal opportunity (EO) to individuals regardless of sensitive attributes and (b) repairing historical disadvantages through affirmative action (AA). More technically, we produce fair EO and AA predictors by positing a causal model and considering counterfactual decisions. We prove that the resulting predictors are theoretically optimal in predictive performance while satisfying fairness. We evaluate the algorithms, and the trade-offs between accuracy and fairness, on datasets about admissions, income, credit and recidivism.",2019-05-26,https://www.semanticscholar.org/paper/be3d91b978c5691910270ed0de132cf8dc1be62b,arXiv.org
92,QProber: A System for Automatic Classification of Hidden-Web Resources,"The contents of many valuable web-accessible databases are only available through search interfaces and are hence invisible to traditional web “crawlers.” Recently, commercial web sites have started to manually organize web-accessible databases into Yahoo!-like hierarchical classification schemes. Here, we introduce QProber, a modular system that automates this classification process by using a small number of query probes, generated by document classifiers. QProber can use a variety of types of classifiers to generate the probes. To classify a database, QProber does not retrieve or inspect any documents or pages from the database, but rather just exploits the number of matches that each query probe generates at the database in question. We have conducted an extensive experimental evaluation of QProber over collections of real documents, experimenting with different types of document classifiers and retrieval models. We have also tested our system with over one hundred web-accessible databases. Our experiments show that our system has low overhead and achieves high classification accuracy across a variety of databases.",,https://www.semanticscholar.org/paper/77ae43841d7fa86cba93f0d07911d7202acee6be,
3358,"Arachnology, P. Merrett (Ed.), Academic Press, London (1978)",,1980-02-01,https://www.semanticscholar.org/paper/1d7fec32d9fbcf1360c2c37cc1ab924333d0ec3c,
3004,Argus: Debugging Performance Issues in Modern Desktop Applications with Annotated Causal Tracing,"Modern desktop applications involve many asynchronous, concurrent interactions that make performance issues difficult to diagnose. Although prior work has used causal tracing for debugging performance issues in distributed systems, we find that these techniques suffer from high inaccuracies for desktop applications. We present Argus, a fast, effective causal tracing tool for debugging performance anomalies in desktop applications. Argus introduces a novel notion of strong and weak edges to explicitly model and annotate trace graph ambiguities, a new beam-search-based diagnosis algorithm to select the most likely causal paths in the presence of ambiguities, and a new way to compare causal paths across normal and abnormal executions. We have implemented Argus across multiple versions of macOS and evaluated it on 12 infamous spinning pinwheel issues in popular macOS applications. Argus diagnosed the root causes for all issues, 10 of which were previously unknown, some of which have been open for several years. Argus incurs less than 5% CPU overhead when its system-wide tracing is enabled, making always-on tracing feasible.",,https://www.semanticscholar.org/paper/0192b460429fc155035ee895c2a9d3383123fc29,USENIX Annual Technical Conference
3361,Why is Altruism towards Kin so Rare,"When individuals have the opportunity to invest in offspring or siblings who are equally closely related and helpless, they should invest in offspring. Two reasons are proposed. Both depend ultimately on the fact that if Ego invests in kin other individuals may not behave in Ego's best interest.",1980-01-12,https://www.semanticscholar.org/paper/d710072ebc02dad35d9a8185ab31a77594a2e786,
1297,Study of the decay Bs(0)-->Ds(*)Ds(*).,"We report a study of the decay Bs(0)-->Ds(*)Ds(*) using a data sample corresponding to 1.3 fb(-1) of integrated luminosity collected by the D0 experiment in 2002-2006 during run II of the Fermilab Tevatron collider. One Ds(*) meson was partially reconstructed in the decay Ds-->phi mu nu, and the other Ds(*) meson was identified using the decay Ds-->phi pi where no attempt was made to distinguish Ds and Ds(*) states. For the branching fraction Br(Bs(0)-->Ds(*)Ds(*)) we obtain a 90% C.L. range [0.002,0.080] and central value 0.039(-0.017)(+0.019)(stat)(-0.015)(+0.016)(syst). This was subsequently used to make the most precise estimate of the width difference DeltaGamma(s)CP in the Bs(0)-Bs(0) system: DeltaGamma(s)CP/Gamma(s)=0.079(-0.035)(+0.038)(stat)(-0.030)(+0.031)(syst).",2007-12-12,https://www.semanticscholar.org/paper/ec3113786334c084939ac8442613bd817bae969c,Physical Review Letters
1270,Search for stopped gluinos from pp collisions at square root s = 1.96 TeV.,"Long-lived, heavy particles are predicted in a number of models beyond the standard model of particle physics. We present the first direct search for such particles' decays, occurring up to 100 h after their production and not synchronized with an accelerator bunch crossing. We apply the analysis to the gluino (g), predicted in split supersymmetry, which after hadronization can become charged and lose enough momentum through ionization to come to rest in dense particle detectors. Approximately 410 pb(-1) of pp collisions at square root(s) = 1.96 TeV collected with the D0 detector during Run II of the Fermilab Tevatron collider are analyzed in search of such ""stopped gluinos"" decaying into a gluon and a neutralino (chi(1)(0)). Limits are placed on the (gluino cross section) x (probability to stop) x [BR(g --> g chi(1)(0))] as a function of the gluino and chi(1)(0) masses, for gluino lifetimes from 30 micros-100 h.",2007-05-01,https://www.semanticscholar.org/paper/041312bfe9475f4539f4b49666db6013aec15ffa,Physical Review Letters
93,STHoles: a multidimensional workload-aware histogram,"Attributes of a relation are not typically independent. Multidimensional histograms can be an effective tool for accurate multiattribute query selectivity estimation. In this paper, we introduce STHoles, a “workload-aware” histogram that allows bucket nesting to capture data regions with reasonably uniform tuple density. STHoles histograms are built without examining the data sets, but rather by just analyzing query results. Buckets are allocated where needed the most as indicated by the workload, which leads to accurate query selectivity estimations. Our extensive experiments demonstrate that STHoles histograms consistently produce good selectivity estimates across synthetic and real-world data sets and across query workloads, and, in many cases, outperform the best multidimensional histogram techniques that require access to and processing of the full data sets during histogram construction.",2001-05-01,https://www.semanticscholar.org/paper/ed920f7547ce5d0b72ce69393357a323f89c70cf,ACM SIGMOD Conference
2807,Comparative transcriptomic analyses of atopic dermatitis and psoriasis reveal shared neutrophilic inflammation.,,2012-12-01,https://www.semanticscholar.org/paper/70c39850e22935773d4012c7e8b0ff6bde14be34,Journal of Allergy and Clinical Immunology
3067,MediaPod: A Personalized Multimedia Desktop in Your Pocket,"We present MediaPod, a portable system that allows mobile users to maintain the same persistent, personalized multimedia desktop environment on any available computer. Regardless of which computer is being used, MediaPod provides a consistent multimedia desktop session, maintaining all of a user's applications, documents and configuration settings. This is achieved by leveraging rapid improvements in capacity, cost, and size of portable storage devices. MediaPod provides a virtualization and checkpoint-restart mechanism that decouples a desktop environment and its applications from the host, enabling multimedia desktop sessions to be suspended to portable storage, carried around, and resumed from the storage device on another computer. MediaPod virtualization also isolates desktop sessions from the host, protecting the privacy of the user and preventing malicious applications from damaging the host. We have implemented a Linux MediaPod prototype and demonstrate its ability to quickly suspend and resume multimedia desktop sessions, enabling a seamless computing experience for mobile users as they move among computers.",2009-12-14,https://www.semanticscholar.org/paper/0f35a41f62bdb35b9ec3c64e13990a4ede1d70ae,IEEE International Symposium on Multimedia
967,Relationship between 3D-MRI Eyeball shape and Optic Nerve Head Morphology.,,2020-09-08,https://www.semanticscholar.org/paper/9564af6a45630e0c305efbd424094caddcc1a17d,"Ophthalmology (Rochester, Minn.)"
539,Optimal piecewise linear motion of an object among obstacles,,1987-11-01,https://www.semanticscholar.org/paper/cb01578f96bc6046d614d11830aa79d477db6572,Algorithmica
1576,Using Embeddings to Correct for Unobserved Confounding,"We consider causal inference in the presence of unobserved confounding. In particular, we study the case where a proxy is available for the confounder but the proxy has non-iid structure. As one example, the link structure of a social network carries information about its members. As another, the text of a document collection carries information about their meanings. In both these settings, we show how to effectively use the proxy to do causal inference. The main idea is to reduce the causal estimation problem to a semi-supervised prediction of both the treatments and outcomes. Networks and text both admit high-quality embedding models that can be used for this semi-supervised prediction. Our method yields valid inferences under suitable (weak) conditions on the quality of the predictive model. We validate the method with experiments on a semi-synthetic social network dataset. We demonstrate the method by estimating the causal effect of properties of computer science submissions on whether they are accepted at a conference.",2019-02-11,https://www.semanticscholar.org/paper/9c3ab9aa3de816e37778f9514b89355b02e09fad,arXiv.org
2132,Unsteady thermosolutal opposing convection of a liquid-water mixture in a square cavity—I. Flow formation and heat and mass transfer characteristics,,,https://www.semanticscholar.org/paper/037fbd12901aa5b898ff6a5563d1f22605def565,
3592,The C++ programming language - special edition (3. ed.),,,https://www.semanticscholar.org/paper/bd77374506400899df61c24bc88513a695a84975,
235,The Intractability of Dynamic Mechanism Design,"We introduce a dynamic mechanism design problem in which the designer wants to offer for sale an item to an agent, and another item to the same agent at some point in the future. The agent’s joint distribution of valuations for the two items is known, and the agent knows the valuation for the current item (but not for the one in the future). The designer seeks to maximize expected revenue, and the auction must be deterministic, truthful, and ex post individually rational. The optimum mechanism involves a protocol whereby the seller elicits the buyer’s current valuation, and based on the bid makes two take-it-or-leave-it offers, one for now and one for the future. We show that finding the optimum mechanism — arguably the simplest meaningful dynamic mechanism design problem imaginable — is NP-hard. We also prove several positive results, among them a polynomial linear programming-based algorithm for the optimum randomized auction, and we show strong separations in revenue between non-adaptive, adaptive, and randomized auctions. University of California, Berkeley, Computer Science Department. Email: christos@cs.berkeley.edu University of California, Berkeley, Computer Science Department. Email: geopier@gmail.com University of California, Berkeley, Computer Science Department. Email: alexpsomi@cs.berkeley.edu University of California, Berkeley, Computer Science Department. Email: aviad@cs.berkeley.edu 1",2014-07-21,https://www.semanticscholar.org/paper/c48c2bdae11409533fa700a2fe8cfff9aff20272,arXiv.org
2431,SIGCHI Lifetime Research Award Talk-Seeing Past Looking Forward,"I have long been interested in how computers can help people perform skilled tasks-a theme that underlies essentially all of my research. As the intentionally convoluted title of this talk implies, I will take a look back at some of this research to explain what came later, and to speculate on what might be next. My earliest work as a graduate student was as part of a team developing novel hypermedia editing and presentation tools for technical documentation of equipment maintenance procedures. Understanding the effort involved in using these tools manually led to my dissertation, which explored rule-based techniques for the automated generation of 3D graphics that could ultimately replace the pictures found in maintenance manuals. Based on information about the task to be depicted, I designed a system that chose the objects to include, determined the level of detail at which to render them (e.g., adding more detail to disambiguate objects that could otherwise be confused with each other), highlighted important objects for emphasis, and created additional ""metaobjects"" (e.g., arrows to show actions). When I started as a faculty member, several of my students built on this research direction in both 3D and 2D domains, and we were soon collaborating with colleagues to develop generation approaches for coordinated multimedia explanations that combined graphics with text. At the same time, I was becoming excited by the potential of virtual reality (VR) to render objects stereoscopically and interact with them in 3D, in abstract domains as well as physical ones. And it was an easy jump from there to augmented reality (AR), cobbling together a simple monoscopic optical seethrough head-worn display. Our first AR system was a ""hybrid"" desktop window manager that embedded windows displayed on a flat panel display within a much larger virtual surround presented on the AR display. With that AR display now available as a tool, it became stunningly clear that so much of the effort we'd put into carefully crafting stand-alone pictures to explain tasks was unnecessary. If the user could instead look directly at the actual task domain, then a simple highlight or arrow, overlaid in situ, could show which button to push or knob to turn on a panel of controls.",2018-04-20,https://www.semanticscholar.org/paper/18ff79c3c5ca0bfcd1c23c0d01fde781097e4b6b,CHI Extended Abstracts
3409,An Empirical Study of Online Packet Scheduling Algorithms,,2016-03-25,https://www.semanticscholar.org/paper/7b3eadd9a04e44321983f840be56e930a1aae171,The Sea
1111,Title Silicon detector results from the first five-tower run of CDMS II Permalink,,,https://www.semanticscholar.org/paper/ffdfe2de0450a57993a7ca46a2ffea85ca9fba91,
95,Characterizing Web Resources for Improved Search Position Paper,"As an important initial step to exploit such dimensions for web search, we have focused on geographical relevance. Web sites containing information on restaurants or apartment rentals, for instance, are relevant primarily to web users in geographical proximity to these locations. In contrast, an on-line newspaper may be relevant to users across the United States. We have studied how to mine the web and automatically estimate the geographical scope of web resources by using web hyperlinks and the actual content of web pages. For example, we can map every web page to a location based on where its hosting site resides. Then, we can consider the location of all the pages that point to, say, the Stanford Daily home page. By examining the distribution of these pointers, we can conclude that the Stanford Daily is of interest mainly to residents of the Stanford area, while The Wall Street Journal is of nation-wide interest. Similar conclusions can be drawn for other resources by analyzing the geographical locations that are mentioned in their pages.",,https://www.semanticscholar.org/paper/283e8528933549dae671db8a74547e5460bfde9e,
1485,An experimental study of spin 1 mesons produced in two photon reactions,,,https://www.semanticscholar.org/paper/b8343906c9cd764ea64368c9a58beee8dbc01d34,
262,On optimal single-item auctions,"We revisit the problem of designing the profit-maximizing single-item auction, solved by Myerson in his seminal paper for the case in which bidder valuations are independently distributed. We focus on general joint distributions, seeking the optimal deterministic incentive compatible auction. We give a geometric characterization of the optimal auction through a duality theorem, resulting in an efficient algorithm for finding the optimal deterministic auction in the two-bidder case and an inapproximability result for three or more bidders.",2010-11-04,https://www.semanticscholar.org/paper/10e89c74c3565ac20b94454a1051279047a0ad84,Symposium on the Theory of Computing
2106,Managing technologies to enhance and enrich services in high-tech industry,"New information technologies and business models have had a profound effect on how services are created and delivered, in particular with regard to the innovation, contents, delivery methods, systems, enabling technologies and management. This special issue of the International Journal of Services Technology and Management (IJSTM) focuses on all aspects of managing the hard and soft technologies to enhance and enrich services in high-tech industries, e.g., semiconductor manufacturing. This introduction gives an overview of this special issue from different perspectives.",,https://www.semanticscholar.org/paper/4595c2abff770a6d774a320762e6576610c3726f,International Journal of Services Technology and Management
278,On a Network Generalization of the Minmax Theorem,,2009-07-03,https://www.semanticscholar.org/paper/a0feab11362fb168fa4408f00b5c5a2fbbf029aa,"International Colloquium on Automata, Languages and Programming"
736,Appendix to : Model Checking of Recursive Probabilistic Systems,"PROOF. It suffices, by standard facts about probability measure, to prove the claim for cylinders C(w′) ⊆ ′, where w′ = w0, . . . wk. We use induction on k. The base case (k = 0) follows from Lemma 7. Namely, C( ) = ′, and ρ−1( ′) = \ ρ−1( ). Thus Pr (ρ−1( ′)) = 1 − Pr (ρ−1( )) = 1. For the induction step, suppose that the claim holds for the prefix w′ = w0w1 . . . wk. Let D[w′] = ρ−1(C(w′)). Define the event Ji,y ∈ F to be Ji,y = {t ∈ | ρ(t) = w0 . . . wi . . . , and wi = y}. Note that by definition of conditional probability, Pr (D[w′wk+1]) = Pr (D[w′]) Pr (Jk+1,wk+1 | D[w′]). We want to show that Pr (D[w′wk+1]) = Pr ′(C(w′wk+1)). We distinguish three cases, based on what type of edge (wk, wk+1) is in HA , as in the proof of Lemma 7.",,https://www.semanticscholar.org/paper/c27a282e9e8902a3a05eb84491ff85fbbe79d191,
3435,Solving maximum flow problems on real-world bipartite graphs,"In this article, we present an experimental study of several maximum-flow algorithms in the context of unbalanced bipartite networks. Our experiments are motivated by a real-world problem of managing reservation-based inventory in Google content ad systems. We are interested in observing the performance of several push-relabel algorithms on our real-world datasets and also on some generated ones. Previous work suggested an important improvement for push-relabel algorithms on unbalanced bipartite networks: the two-edge push rule. We show how the two-edge push rule improves the running time. While no single algorithm dominates the results, we show there is one that has very robust performance in practice.",2009-01-03,https://www.semanticscholar.org/paper/f888d5f268ae763a47a0fada3ad4b8d8d1f8b1ef,JEAL
1388,Search for large extra dimensions in the monojet+E(T) channel with the DØ detector.,"We present a search for large extra dimensions (ED) in pp collisions at a center-of-mass energy of 1.8 TeV using data collected by the DØ detector at the Fermilab Tevatron in 1994-1996. Data corresponding to 78.8+/-3.9 pb(-1) are examined for events with large missing transverse energy, one high-p(T) jet, and no isolated muons. There is no excess observed beyond expectation from the standard model, and we place lower limits on the fundamental Planck scale of 1.0 and 0.6 TeV for 2 and 7 ED, respectively.",2003-06-24,https://www.semanticscholar.org/paper/97532dd6ccbd122d367d6e2ef09a02c3530843bf,Physical Review Letters
369,Heuristically Optimized Trade-Offs: A New Paradigm for Power Laws in the Internet,,2002-07-08,https://www.semanticscholar.org/paper/46917e113dc095247ac667a9b860a7d8afd84d9c,"International Colloquium on Automata, Languages and Programming"
115,Metadata for digital libraries: architecture and design rationale,"In a distributed, heterogeneous, proxy-based digital library, autonomous services and collections are accessed indirectly via proxies. To facilitate metadata compatibility and interoperability in such a digital library, we have designed a metadata architecture that includes four basic component classes: attribute model proxies, attribute model translators, metadata facilities for search proxies, and metadata repositories. Attribute model proxies elevate both attribute sets and the attributes they define to first-class objects. They also allow relationships among attributes to be captured. Attribute model translators map attributes and attribute values from one attribute model to another (where posMetadata facilities for search proxies provide structured descriptions both of the collections to which the search proxies provide access and of the search capabilities of the proxies. Finally, metadata repositories accumulate selected metadata from local instances of the other three component classes in order to facilitate global metadata queries and local metadata caching. In this paper, we outline further the roles of these component classes, discuss our design rationale, and analyze related work. Keywords: Metadata architecture, interoperability, attribute model, attribute model translation, metadata repository, InfoBus, proxy architecture, heterogeneity, digital libraries, CORBA.",1997-07-01,https://www.semanticscholar.org/paper/273f7bc28571360deb92854c5f55f0ac8d577f34,Digital library
3508,Centralized and distributed algorithms for network scheduling,"In this dissertation we will examine centralized and distributed algorithms for network scheduling. The input to the network scheduling problem is a network of machines and a set of independent jobs such that each job originates on some machine in the network. A job may be processed on the machine it originated or it may be moved to another machine to be processed. Unlike many previous parallel machine scheduling models, our model accounts for communication between processors. If a job is moved from one processor to another processor it will incur a time delay. The delay is proportional to the distance between the two machines in the network. Another aspect of the network scheduling model is that each edge has a capacity which restricts the number of jobs that can be passed over it in one time step. 
We present two polynomial time centralized scheduling algorithms. One is for scheduling jobs optimally in a ring of processors with unit capacity edges. The other is for scheduling jobs optimally in arbitrary networks with infinite capacity edges. 
We also present three distributed approximation algorithms for network scheduling. All three of the distributed algorithms have extremely simple control structures and produce schedules with lengths that are within a small factor of optimal. The first of these results handles infinite capacity rings. We present a 4.22-approximation algorithm as well as provide simulation results that suggest the algorithm performs better than our analysis implies. Furthermore, we give a lower bound on the performance of any distributed scheduling algorithm for rings with infinite capacity links. The next algorithm we present is a simple d-approximation algorithm for scheduling jobs in d-regular networks with unit capacity links. We also show how to improve the analysis for rings; the improved analysis reduces the approximation factor to 5/3. The final algorithm is also for unit capacity networks and is very similar to the algorithm for d-regular networks. We prove that this algorithm is an O(log m)-approximation algorithm for arbitrary m machine networks given that the optimal schedule length is sufficiently large.",,https://www.semanticscholar.org/paper/095de687ecc65971db8976c0e4b78417166b5ece,
1327,Search for R-parity violating supersymmetry via the LL ¯,,,https://www.semanticscholar.org/paper/c24a852c0df14ad8c0347a87823052bcd75cc5a7,
1971,Data Mining to Capture User-Experience: A Case Study in Notebook Product Appearance Design,"— In the era of rapidly increasing notebook market, consumer electronics manufacturers are facing a highly dynamic and competitive environment. In particular, the product appearance is the first part for user to distinguish the product from the product of other brands. Notebook product should differ in its appearance to engage users and contribute to the user experience (UX). The UX evaluates various product concepts to find the design for user needs; in addition, help the designer to further understand the product appearance preference of different market segment. However, few studies have been done for exploring the relationship between consumer background and the reaction of product appearance. This study aims to propose a data mining framework to capture the user’s information and the important relation between product appearance factors. The proposed framework consists of problem definition and structuring, data preparation, rules generation, and results evaluation and interpretation. An empirical study has been done in Taiwan that recruited 168 subjects from different background to experience the appearance performance of 11 different portable computers. The results assist the designers to develop product strategies based on the characteristics of consumers and the product concept that related to the UX, which help to launch the products to the right customers and increase the market shares. The results have shown the practical feasibility of the proposed framework.",2014-03-01,https://www.semanticscholar.org/paper/e3041bf34b08c438f29131e33a2083daee8101d5,
2699,Computer graphics (2nd ed. in C): principles and practice,,1995-08-01,https://www.semanticscholar.org/paper/45b95e5b43ce20f94d446a343bfa7d785769f566,
2801,Galectin-3 regulates the innate immune response of human monocytes.,"Galectin-3 is a β-galactoside-binding lectin widely expressed on epithelial and hematopoietic cells, and its expression is frequently associated with a poor prognosis in cancer. Because it has not been well-studied in human infectious disease, we examined galectin-3 expression in mycobacterial infection by studying leprosy, an intracellular infection caused by Mycobacterium leprae. Galectin-3 was highly expressed on macrophages in lesions of patients with the clinically progressive lepromatous form of leprosy; in contrast, galectin-3 was almost undetectable in self-limited tuberculoid lesions. We investigated the potential function of galectin-3 in cell-mediated immunity using peripheral blood monocytes. Galectin-3 enhanced monocyte interleukin 10 production to a TLR2/1 ligand, whereas interleukin 12p40 secretion was unaffected. Furthermore, galectin-3 diminished monocyte to dendritic cell differentiation and T-cell antigen presentation. These data demonstrate an association of galectin-3 with unfavorable host response in leprosy and a potential mechanism for impaired host defense in humans.",2013-03-15,https://www.semanticscholar.org/paper/fdc5353b1922e431b29e046306566be83077d820,Journal of Infectious Diseases
2375,Formation of myeloperoxidase compound II during aerobic stimulation of rat neutrophils,,1986-03-01,https://www.semanticscholar.org/paper/8df87bce3c6b886cbcdf59f6f78d2ad55f5d5199,Bioscience Reports
1032,Variations on the Role of Principal Connections in Robotic Locomotion,"Diverse problems in robotic locomotion have previously been modeled in terms of connections on principal bundles. Ordinarily, one identifies points in the base manifold of such a bundle with different internal configurations of a robot, identifies points in the fiber over a given base point with different positions and orientations of the robot in its environment, and assumes control to be applied in the former but not the latter. We examine ways in which the ordinary application of this theory may be adapted to problems in aquatic and terrestrial locomotion that fail to accommodate the preceding description.",2016-10-12,https://www.semanticscholar.org/paper/905f075eebc2f3b480401437fc27266e8f294321,
1451,Physics at gamma gamma and e gamma colliders,,,https://www.semanticscholar.org/paper/612828eaef768178e907ab5b494e57d9a2428242,
2500,Poster: Manipulating virtual objects in hand-held augmented reality using stored snapshots,"We describe a set of interaction techniques that allow a user of a magic-lens style augmented reality application to take snapshots of an augmented scene and revisit them virtually for interaction at a later time. By storing a still image of the background along with the camera pose, this approach allows augmentations to remain dynamic and interactive. This makes it possible for the user to manipulate virtual objects from the vantage points of different locations without the overhead of physically traveling between those locations. Preliminary results from a user study show that participants were able to complete an alignment task significantly faster and as accurately when using snapshots as opposed to physical travel. Qualitative questionnaire answers showed that participants preferred using snapshots over walking and found it less demanding.",2012-03-04,https://www.semanticscholar.org/paper/a20cbfea6aad863edeea63b5f61cfac5ee4c3c2b,IEEE Symposium on 3D User Interfaces
2510,Augmented reality in the psychomotor phase of a procedural task,"Procedural tasks are common to many domains, ranging from maintenance and repair, to medicine, to the arts. We describe and evaluate a prototype augmented reality (AR) user interface designed to assist users in the relatively under-explored psychomotor phase of procedural tasks. In this phase, the user begins physical manipulations, and thus alters aspects of the underlying task environment. Our prototype tracks the user and multiple components in a typical maintenance assembly task, and provides dynamic, prescriptive, overlaid instructions on a see-through head-worn display in response to the user's ongoing activity. A user study shows participants were able to complete psychomotor aspects of the assembly task significantly faster and with significantly greater accuracy than when using 3D-graphics-based assistance presented on a stationary LCD. Qualitative questionnaire results indicate that participants overwhelmingly preferred the AR condition, and ranked it as more intuitive than the LCD condition.",2011-10-26,https://www.semanticscholar.org/paper/ab1203db90c05b7c55597c794c522c8d58fb84c1,2011 10th IEEE International Symposium on Mixed and Augmented Reality
1667,Multilingual Topic Models for Unaligned Text,"We develop the multilingual topic model for unaligned text (MuTo), a probabilistic model of text that is designed to analyze corpora composed of documents in two languages. From these documents, MuTo uses stochastic EM to simultaneously discover both a matching between the languages and multilingual latent topics. We demonstrate that MuTo is able to find shared topics on real-world multilingual corpora, successfully pairing related documents across languages. MuTo provides a new framework for creating multilingual topic models without needing carefully curated parallel corpora and allows applications built using the topic model formalism to be applied to a much wider class of corpora. Topic models are a powerful formalism for unsupervised analysis of corpora [1, 8]. They are an important tool in information retrieval [27], sentiment analysis [25], and collaborative filtering [18]. When interpreted as a mixed membership model, similar assumptions have been successfully applied to vision [6], population survey analysis [4], and genetics [5]. In this work, we build on latent Dirichlet allocation (LDA) [2], a generative, probabilistic topic model of text. LDA assumes that documents have a distribution over topics and that these topics are distributions over the vocabulary. Posterior inference discovers the topics that best explain a corpus; the uncovered topics tend to reflect thematically consistent patterns of words [8]. The goal of this paper is to find topics that express thematic coherence across multiple languages. LDA can capture coherence in a single language because semantically similar words tend to be used in similar contexts. This is not the case in multilingual corpora. For example, even though “Hund” and “hound” are orthographically similar and have nearly identical meanings in German and English (i.e., “dog”), they will likely not appear in similar contexts because almost all documents are written in a single language. Consequently, a topic model fit on a bilingual corpus reveals coherent topics but bifurcates the topic space between the two languages (Table 1). In order to build coherent topics across languages, there must be some connection to tie the languages together. Previous multilingual topic models connect the languages by assuming parallelism at either the sentence level [28] or document level [13, 23, 19]. Many parallel corpora are available, but they represent a small fraction of corpora. They also tend to be relatively well annotated and understood, making them less suited for unsupervised methods like LDA. A topic model on unaligned text in multiple languages would allow the exciting applications developed for monolingual topics models to be applied to a broader class of corpora and would help monolingual users to explore and understand multilingual corpora. We propose the MUltilingual TOpic model for unaligned text (MUTO). MUTO does not assume that it is given any explicit parallelism but instead discovers a parallelism at the vocabulary level. To find this parallelism, the model assumes that similar themes and ideas appear in both languages. For example, if the word “Hund” appears in the German side of the corpus, “hound” or “dog” should appear somewhere on the English side. The assumption that similar terms will appear in similar contexts has also been used to build lexicons from nonparallel but comparable corpora. What makes contexts similar can be evaluated through such measures as cooccurrence [20, 24] or tf-idf [7]. Although the emphasis of our work is on building consistent topic spaces and not the task of building dictionaries per se, good translations are required to find consistent topics. However, we can build on successful techniques at building lexicons across languages. This paper is organized as follows. We detail the model and its assumptions in Section 1, develop a stochastic expectation maximization (EM) inference procedure in Section 2, discuss the corpora and other linguistic resources necessary to evaluate the model in Section 3, and evaluate the performance of the model in Section 4.",,https://www.semanticscholar.org/paper/da92a6855f3b7a57b2f799d3c106bc3371504974,
1278,Observation and properties of the orbitally excited B_(s2)(*) meson.,"We report the direct observation of the excited L=1 state B_(s2)(*) in fully reconstructed decays to B+K-. The mass of the B_(s2)(*) meson is measured to be 5839.6+/-1.1(stat)+/-0.7(syst) MeV/c(2), and its production rate relative to the B+ meson is measured to be [1.15+/-0.23(stat)+/-0.13(syst)]%.",2007-11-02,https://www.semanticscholar.org/paper/5328b853d31513c7289d442590e2801bad2af0e6,Physical Review Letters
1575,The Blessings of Multiple Causes: A Reply to Ogburn et al. (2019),"Ogburn et al. (2019, arXiv:1910.05438) discuss ""The Blessings of Multiple Causes"" (Wang and Blei, 2018, arXiv:1805.06826). Many of their remarks are interesting. But they also claim that the paper has ""foundational errors"" and that its ""premise is...incorrect."" These claims are not substantiated. We correct the record here.",2019-10-15,https://www.semanticscholar.org/paper/8a514faeb037eeffbe52b20abb4e4fceb523a67e,arXiv.org
3687,SHIFT3D: Synthesizing Hard Inputs For Tricking 3D Detectors,"We present SHIFT3D, a differentiable pipeline for generating 3D shapes that are structurally plausible yet challenging to 3D object detectors. In safety-critical applications like autonomous driving, discovering such novel challenging objects can offer insight into unknown vulnerabilities of 3D detectors. By representing objects with a signed distanced function (SDF), we show that gradient error signals allow us to smoothly deform the shape or pose of a 3D object in order to confuse a downstream 3D detector. Importantly, the objects generated by SHIFT3D physically differ from the baseline object yet retain a semantically recognizable shape. Our approach provides interpretable failure modes for modern 3D object detectors, and can aid in preemptive discovery of potential safety risks within 3D perception systems before these risks become critical failures.",2023-09-11,https://www.semanticscholar.org/paper/dcd0410e49db0aeac786a4a8700ab27b91f50d52,arXiv.org
3279,"A Free-Ranging, Feral Mare Equus caballus Affords Similar Maternal Care to Her Genetic and Adopted Offspring","Adoption of nongenetic offspring occurs in a variety of species but is rare in equids. We report a case of adoption by a free-ranging, feral mare Equus caballus and compare the maternal care received by her genetic offspring (born 1995) to that of her adopted offspring (born 1996) for the first 30 weeks of development. We compare five measures of care: (1) total time spent suckling, (2) mare aggression during suckling, (3) number of mare-terminated suckling bouts, (4) contact maintenance, and (5) mare-foal distance. For most behaviors, we detected no difference in the mare’s treatment of the two foals; however, mare-foal distance was greater for the genetic offspring. We compare hypotheses regarding the reasons for adoption, offering postpartum physiological state as a potential driver.",2013-09-05,https://www.semanticscholar.org/paper/74a1bc5718be883764e3fd17e2d0979c5a09854f,American Naturalist
388,Algorithmic problems related to the Internet,,,https://www.semanticscholar.org/paper/ea066608655bfd11ec64efbbb7ce63cfea4581a3,Hellenic-European Conference on Computer Mathematics and its Applications
3271,"An Extra Dimension to Decision-Making in Animals: The Three-way Trade-off between Speed, Effort per-Unit-Time and Accuracy","The standard view in biology is that all animals, from bumblebees to human beings, face a trade-off between speed and accuracy as they search for resources and mates, and attempt to avoid predators. For example, the more time a forager spends out of cover gathering information about potential food sources the more likely it is to make accurate decisions about which sources are most rewarding. However, when the cost of time spent out of cover rises (e.g. in the presence of a predator) the optimal strategy is for the forager to spend less time gathering information and to accept a corresponding decline in the accuracy of its decisions. We suggest that this familiar picture is missing a crucial dimension: the amount of effort an animal expends on gathering information in each unit of time. This is important because an animal that can respond to changing time costs by modulating its level of effort per-unit-time does not have to accept the same decrease in accuracy that an animal limited to a simple speed-accuracy trade-off must bear in the same situation. Instead, it can direct additional effort towards (i) reducing the frequency of perceptual errors in the samples it gathers or (ii) increasing the number of samples it gathers per-unit-time. Both of these have the effect of allowing it to gather more accurate information within a given period of time. We use a modified version of a canonical model of decision-making (the sequential probability ratio test) to show that this ability to substitute effort for time confers a fitness advantage in the face of changing time costs. We predict that the ability to modulate effort levels will therefore be widespread in nature, and we lay out testable predictions that could be used to detect adaptive modulation of effort levels in laboratory and field studies. Our understanding of decision-making in all species, including our own, will be improved by this more ecologically-complete picture of the three-way tradeoff between time, effort per-unit-time and accuracy.",2014-12-01,https://www.semanticscholar.org/paper/2e85c130f289abb8530b7176c490778ae8aefa32,PLoS Comput. Biol.
1124,Low-threshold analysis of CDMS shallow-site data,"Data taken during the final shallow-site run of the first tower of the Cryogenic Dark Matter Search (CDMS II) detectors have been reanalyzed with improved sensitivity to small energy depositions. Four {approx}224 g germanium and two {approx}105 g silicon detectors were operated at the Stanford Underground Facility (SUF) between December 2001 and June 2002, yielding 118 live days of raw exposure. Three of the germanium and both silicon detectors were analyzed with a new low-threshold technique, making it possible to lower the germanium and silicon analysis thresholds down to the actual trigger thresholds of {approx}1 and {approx}2 keV, respectively. Limits on the spin-independent cross section for weakly interacting massive particles (WIMPs) to elastically scatter from nuclei based on these data exclude interesting parameter space for WIMPs with masses below 9 GeV/c{sup 2}. Under standard halo assumptions, these data partially exclude parameter space favored by interpretations of the DAMA/LIBRA and CoGeNT experiments data as WIMP signals, and exclude new parameter space for WIMP masses between 3 and 4 GeV/c{sup 2}.",2010-10-20,https://www.semanticscholar.org/paper/228dca39dfbaf4d062666ed10d5afd8a1752952e,
1805,Reading Tea Leaves: How Humans Interpret Topic Models,"Probabilistic topic models are a popular tool for the unsupervised analysis of text, providing both a predictive model of future text and a latent topic representation of the corpus. Practitioners typically assume that the latent space is semantically meaningful. It is used to check models, summarize the corpus, and guide exploration of its contents. However, whether the latent space is interpretable is in need of quantitative evaluation. In this paper, we present new quantitative methods for measuring semantic meaning in inferred topics. We back these measures with large-scale user studies, showing that they capture aspects of the model that are undetected by previous measures of model quality based on held-out likelihood. Surprisingly, topic models which perform better on held-out likelihood may infer less semantically meaningful topics.",2009-12-07,https://www.semanticscholar.org/paper/87156b2e9b7eadd04af1438d0c7d3e733a2ecb84,Neural Information Processing Systems
3420,Online scheduling of packets with agreeable deadlines,"This article concerns an online packet scheduling problem that arises as a natural model for buffer management at a network router. Packets arrive at a router at integer time steps, and are buffered upon arrival. Packets have non-negative weights and integer deadlines that are (weakly) increasing in their arrival times. In each integer time step, at most one packet can be sent. The objective is to maximize the sum of the weights of the packets that are sent by their deadlines. The main results include an optimal (φ := (1 + √ 5)/2 ≈ 1.618)-competitive deterministic online algorithm, a (4/3 ≈ 1.33)-competitive randomized online algorithm against an oblivious adversary, and a 2-speed 1-competitive deterministic online algorithm. The analysis does not use a potential function explicitly, but instead modifies the adversary's buffer and credits the adversary to account for these modifications.",2012-12-01,https://www.semanticscholar.org/paper/b1cce74220e7eb9d79bf0d48f2844f09066160ed,TALG
200,Design and Analysis of Algorithms Following Algorithms,"Johann Gutenberg’s discovery allowing him to print books by putting together metallic pieces revolutionized the world. It made books widely accessible. It affected literacy, education, political thought, humanities and science. But there are others who think that not typography but algorithms was the key development. How to deal with large numbers (of critical importance to accounting, business, trade, science, and engineering) was not a trivial matter. Indeed, consider the question how to add or multiply Roman numerals (say add MCDXII and DCCCXII)?1 And there are more complex problems, too, like finding square roots, approximating irrational numbers, etc. The discovery of positional systems was a major breakthrough. The sexagesimal system was invented by Summerians around 2000 BCE. The decimal system was known (or was in some use) very early on (perhaps as early as 3000 BCE) but in its modern form, with 0 (zero) was invented (popularized) around 600 CE in India (c. 598-670, Brahmagupta explains the Hindu-Arabic numerals). Important to us is the fact that Muhammad ibn Musa al-Kwarizmi (the first half of the 9th century) for the first time described and popularized the decimal system as well as basic procedures for manipulating decimal numbers outside of India. These procedures were mechanical, precise, efficient and correct. Ultimately, a few centuries later, Europe adopted the system and the rest is history. Mathematics and science took off. The terms algorism and more modern algorithm reflect the name of al-Kwarizmi — the Arabic bridge from India to Europe.",,https://www.semanticscholar.org/paper/676b31a01e253b95966cb244ef06312a16a02bae,
1450,Measurement of alpha(s) in e(+)e(-) annihilation at E(cm) = 29 GeV,,1994-07-01,https://www.semanticscholar.org/paper/5b5b82c9525597901302dd93b2771ea83a728dd5,
1953,Multistage semiconductor memory inventory model based on survival analysis,"Inventory management is challenging and critical problem in the semiconductor memory manufacturing industry. Rapid technological development and short product life cycle cause a high risk of product obsolescence. However, manufacturers must still hold a reasonable level of inventory to satisfy the needs of customers when demand is uncertain and lead times are long. In this study, the needs and constraints of this semiconductor manufacturing problem based on inventory days were considered and a linear programming model was constructed with the objective of determining a weighted minimal cost for resolving the problem of multistage inventory management. This study applied the concept of material requirement planning for calculating the inventory information of various stages. In addition, the shortage problem, excessive or inadequate safety stock levels, and capacity balance of technology were considered. Finally, a numerical study was conducted for evaluating the performance of the inventory model, and the results showed that the model can assist decision makers in early preparation of inventories. Under the same condition of demand fulfillment, the proposed model can be used to reduce the unnecessary inventory of downstream banks and avoid the risk of future inventory obsolescence, thereby enhancing competitiveness.",2014-08-01,https://www.semanticscholar.org/paper/1bfa3b8a5ad5473869e5f0ca7d59f2646f97d490,2014 IEEE International Conference on Automation Science and Engineering (CASE)
2573,Evaluation of an Eyes-Free Cursorless Numeric Entry System for Wearable Computers,"We report on the results of a user study to investigate the utility of passive haptics for eyes-free numeric entry. This work targets cursorless user interfaces designed for use with a watch-sized wrist-worn computer. Our study compared three approaches for selecting one of a set of eight numeric parameters and entering its value, both with and without visual feedback. The three selection methods utilized physical buttons alone, buttons with a touch-sensor utilizing passive haptics, and the touch sensor with passive haptics alone. The results show that passive haptics allowed users to perform parameter selection and number entry tasks, with statistically insignificant differences in accuracy and speed when used with and without visual feedback. Furthermore, there was no statistically significant difference in accuracy and speed between the button-based methods and the purely touch-sensor-based approaches.",2006-10-01,https://www.semanticscholar.org/paper/82e39caed1672b5bd0c58395337934d5467a3d55,International Semantic Web Conference
570,UNICATION-TIME TRADEOFFt,"ADSTRACT: We show a nontrivial tradeor betwcen the communication c and time t required to computc a collection of values whose depcndencics form a grid, i.e., value (i,j) depends on the values (i 1 , j ) and ( i , j 1). No matter how we share the responsihility for computing the nodes of the n x n grid among processors, tlie law ct = f2(na) must hold. Further, there must be a single path through the grid along which there arc d communication steps, where dt = fl(nz). Depending on the machine organizatiou, either law may be the more significant.",,https://www.semanticscholar.org/paper/22859ed4e0452bc200d156c1a3fa7b21e6df36e1,
1697,A Filtering Approach to Stochastic Variational Inference,"Stochastic variational inference (SVI) uses stochastic optimization to scale up Bayesian computation to massive data. We present an alternative perspective on SVI as approximate parallel coordinate ascent. SVI trades-off bias and variance to step close to the unknown true coordinate optimum given by batch variational Bayes (VB). We define a model to automate this process. The model infers the location of the next VB optimum from a sequence of noisy realizations. As a consequence of this construction, we update the variational parameters using Bayes rule, rather than a hand-crafted optimization schedule. When our model is a Kalman filter this procedure can recover the original SVI algorithm and SVI with adaptive steps. We may also encode additional assumptions in the model, such as heavy-tailed noise. By doing so, our algorithm outperforms the original SVI schedule and a state-of-the-art adaptive SVI algorithm in two diverse domains.",2014-12-08,https://www.semanticscholar.org/paper/35409ac9b33f2cc074257018c47fe9c373acb55f,Neural Information Processing Systems
2862,"Laminin 5, Netrin–4 and Lumican have Potential to Serve as Counterreceptors of Galectin–3",,2005-05-01,https://www.semanticscholar.org/paper/84fdd0afc9bbb4a007b1661760d776c39076e6ce,
3184,Collective wisdom in polarized groups,"The potential for groups to outperform the cognitive capabilities of even highly skilled individuals, known as the “wisdom of the crowd”, is crucial to the functioning of democratic institutions. In recent years, increasing polarization has led to concern about its effects on the accuracy of electorates, juries, courts, and congress. While there is empirical evidence of collective wisdom in partisan crowds, a general theory has remained elusive. Central to the challenge is the difficulty of disentangling the effect of limited interaction between opposing groups (homophily) from their tendency to hold opposing viewpoints (partisanship). To overcome this challenge, we develop an agent-based model of collective wisdom parameterized by the experimentally-measured behaviour of participants across the political spectrum. In doing so, we reveal that differences across the political spectrum in how individuals express and respond to knowledge interact with the structure of the network to either promote or undermine wisdom. We verify these findings experimentally and construct a more general theoretical framework. Finally, we provide evidence that incidental, context-specific differences across the political spectrum likely determine the impact of polarization. Overall, our results show that whether polarized groups benefit from collective wisdom is generally predictable but highly context-specific.",2022-08-01,https://www.semanticscholar.org/paper/bdd689efbacc2b6e051932cd0243a3e28a194a2b,Collective Intelligence
1151,"Search for next-to-minimal supersymmetric Higgs bosons in the h --> aa --> micromicromicromicro, micromicrotautau channels using pp[over] collisions at sqrt[s] = 1.96 TeV.","We report on a first search for production of the lightest neutral CP-even Higgs boson (h) in the next-to-minimal supersymmetric standard model, where h decays to a pair of neutral pseudoscalar Higgs bosons (a), using 4.2 fb;{-1} of data recorded with the D0 detector at Fermilab. The a bosons are required to either both decay to micro;{+}micro;{-} or one to micro;{+}micro;{-} and the other to tau;{+}tau;{-}. No significant signal is observed, and we set limits on its production as functions of M_{a} and M_{h}.",2009-08-07,https://www.semanticscholar.org/paper/46cdba1e9fc10738a06f58b2f0d2ba569b574917,Physical Review Letters
3703,Revealing Occlusions with 4D Neural Fields,"For computer vision systems to operate in dynamic situations, they need to be able to represent and reason about object permanence. We introduce a framework for learning to estimate 4D visual representations from monocular RGB-D video, which is able to persist objects, even once they become obstructed by occlusions. Unlike traditional video representations, we encode point clouds into a continuous representation, which permits the model to attend across the spatiotemporal context to resolve occlusions. On two large video datasets that we release along with this paper, our experiments show that the representation is able to successfully reveal occlusions for several tasks, without any architectural changes. Visualizations show that the attention mechanism automatically learns to follow occluded objects. Since our approach can be trained end-to-end and is easily adaptable, we believe it will be useful for handling occlusions in many video understanding tasks. Data, code, and models are available at occ1usions. cs. co1umbia. edu.",2022-04-22,https://www.semanticscholar.org/paper/b4a2c2ae8bcefb389a7f9aeab38b90d6f4583fa5,Computer Vision and Pattern Recognition
1567,Poisson-Randomized Gamma Dynamical Systems,"This paper presents the Poisson-randomized gamma dynamical system (PRGDS), a model for sequentially observed count tensors that encodes a strong inductive bias toward sparsity and burstiness. The PRGDS is based on a new motif in Bayesian latent variable modeling, an alternating chain of discrete Poisson and continuous gamma latent states that is analytically convenient and computationally tractable. This motif yields closed-form complete conditionals for all variables by way of the Bessel distribution and a novel discrete distribution that we call the shifted confluent hypergeometric distribution. We draw connections to closely related models and compare the PRGDS to these models in studies of real-world count data sets of text, international events, and neural spike trains. We find that a sparse variant of the PRGDS, which allows the continuous gamma latent states to take values of exactly zero, often obtains better predictive performance than other models and is uniquely capable of inferring latent structures that are highly localized in time.",2019-10-28,https://www.semanticscholar.org/paper/0ee3535732c7fe44ae43e1a6d77ce1ff770bf208,Neural Information Processing Systems
80,Extending SDARTS: extracting metadata from web databases and interfacing with the open archives initiative,"SDARTS is a protocol and toolkit designed to facilitate metasearching. SDARTS combines two complementary existing protocols, SDLIP and STARTS, to define a uniform interface that collections should support for searching and exporting metasearch-related metadata. SDARTS also includes a toolkit with wrappers that are easily customized to make both local and remote document collections SDARTS-compliant. This paper describes two significant ways in which we have extended the SDARTS toolkit. First, we have added a tool that automatically builds rich content summaries for remote web collections bym probing the collections with appropriate queries. These content summaries can then be used by a metasearcher to select over which collections to evaluate a given query. Second, we have enhanced the SDARTS toolkit so that all SDARTS-compliant collections export their metadata under the emerging Open Archives Initiative (OAI) protocol. Conversely, the SDARTS toolkit now also allows all OAI-compliant collections to be made SDARTS-compliant with minimal effort. As a result, we implemented a bridge between SDARTS and OAI, which will facilitate easy interoperability among a potentially large number of collections. The SDARTS toolkit, with all related documentation and source code, is publicly available at http://sdarts.cs.columbia.edu.",2002-07-14,https://www.semanticscholar.org/paper/a8a4502dc05e79de23a587c86071594ac39505de,ACM/IEEE Joint Conference on Digital Libraries
1341,04 05 03 3 v 2 12 O ct 2 00 4 First Results from the Cryogenic Dark Matter Search in the Soudan Underground Lab,"D.S. Akerib, J. Alvaro-Dean, M.S. Armel–Funkhouser, M.J. Attisha, L. Baudis, 5 D.A. Bauer, J. Beaty, P.L. Brink, R. Bunker, S.P. Burke, B. Cabrera, D.O. Caldwell, D. Callahan, J.P. Castle, C.L. Chang, R. Choate, M.B. Crisler, P. Cushman, R. Dixon, M.R. Dragowsky, D.D. Driscoll, L. Duong, J. Emes, R. Ferril, J. Filippini, R.J. Gaitskell, M. Haldeman, D. Hale, D. Holmgren, M.E. Huber, B. Johnson, W. Johnson, S. Kamat, M. Kozlovsky, L. Kula, S. Kyre, B. Lambin, A. Lu, R. Mahapatra, A.G. Manalaysay, V. Mandic, J. May, R. McDonald, B. Merkel, P. Meunier, N. Mirabolfathi, S. Morrison, H. Nelson, R. Nelson, L. Novak, R.W. Ogburn, S. Orr, T.A. Perera, M.C. Perillo Isaac, E. Ramberg, W. Rau, A. Reisetter, R.R. Ross, 2, ∗ T. Saab, B. Sadoulet, 2 J. Sander, C. Savage, R.L. Schmitt, R.W. Schnee, D.N. Seitz, B. Serfass, A. Smith, G. Smith, A.L. Spadafora, K. Sundqvist, J-P.F. Thompson, A. Tomada, G. Wang, J. Williams, S. Yellin, and B.A. Young",,https://www.semanticscholar.org/paper/4d640a22ff3862ebf08ad6b2ab8fb9b5dff9bd70,
3231,How ecology shapes exploitation: a framework to predict the behavioural response of human and animal foragers along exploration-exploitation trade-offs.,"Understanding how humans and other animals behave in response to changes in their environments is vital for predicting population dynamics and the trajectory of coupled social-ecological systems. Here, we present a novel framework for identifying emergent social behaviours in foragers (including humans engaged in fishing or hunting) in predator-prey contexts based on the exploration difficulty and exploitation potential of a renewable natural resource. A qualitative framework is introduced that predicts when foragers should behave territorially, search collectively, act independently or switch among these states. To validate it, we derived quantitative predictions from two models of different structure: a generic mathematical model, and a lattice-based evolutionary model emphasising exploitation and exclusion costs. These models independently identified that the exploration difficulty and exploitation potential of the natural resource controls the social behaviour of resource exploiters. Our theoretical predictions were finally compared to a diverse set of empirical cases focusing on fisheries and aquatic organisms across a range of taxa, substantiating the framework's predictions. Understanding social behaviour for given social-ecological characteristics has important implications, particularly for the design of governance structures and regulations to move exploited systems, such as fisheries, towards sustainability. Our framework provides concrete steps in this direction.",2018-06-01,https://www.semanticscholar.org/paper/c29bc4ac519374f8271f956fd48e6fa053919374,Ecology Letters
17,When Speed Has a Price: Fast Information Extraction Using Approximate Algorithms,"A wealth of information produced by individuals and organizations is expressed in natural language text. This is a problem since text lacks the explicit structure that is necessary to support rich querying and analysis. Information extraction systems are sophisticated software tools to discover structured information in natural language text. Unfortunately, information extraction is a challenging and time-consuming task. In this paper, we address the limitations of state-of-the-art systems for the optimization of information extraction programs, with the objective of producing efficient extraction executions. Our solution relies on exploiting a wide range of optimization opportunities. For efficiency, we consider a wide spectrum of execution plans, including approximate plans whose results differ in their precision and recall. Our optimizer accounts for these characteristics of the competing execution plans, and uses accurate predictors of their extraction time, recall, and precision. We demonstrate the efficiency and effectiveness of our optimizer through a large-scale experimental evaluation over real-world datasets and multiple extraction tasks and approaches.",2013-08-29,https://www.semanticscholar.org/paper/2f770beab965bbc9df0575b9883e83f2e9678583,Proceedings of the VLDB Endowment
266,When the Players Are Not Expectation Maximizers,,2010-10-18,https://www.semanticscholar.org/paper/16d26b11881e7a563ccf2d6d4cf4e866abca46f3,Algorithmic Game Theory
1368,First results from the Cryogenic Dark Matter Search in the Soudan Underground Laboratory.,"We report the first results from a search for weakly interacting massive particles (WIMPs) in the Cryogenic Dark Matter Search experiment at the Soudan Underground Laboratory. Four Ge and two Si detectors were operated for 52.6 live days, providing 19.4 kg d of Ge net exposure after cuts for recoil energies between 10 and 100 keV. A blind analysis was performed using only calibration data to define the energy threshold and selection criteria for nuclear-recoil candidates. Using the standard dark-matter halo and nuclear-physics WIMP model, these data set the world's lowest exclusion limits on the coherent WIMP-nucleon scalar cross section for all WIMP masses above 15 GeV/c2, ruling out a significant range of neutralino supersymmetric models. The minimum of this limit curve at the 90% C.L. is 4 x 10(-43) cm2 at a WIMP mass of 60 GeV/c2.",2004-11-19,https://www.semanticscholar.org/paper/4cbcf135a2adddc02645223fc22c05e631692ea0,Physical Review Letters
1080,Radon daughter plate-out measurements at SNOLAB for polyethylene and copper,,2017-08-30,https://www.semanticscholar.org/paper/4f9c414073a41a0f320d9a3da24950b420698ffd,
3254,DNA metabarcoding illuminates dietary niche partitioning by African large herbivores,"Significance Theory holds that sympatric large mammalian herbivores (LMH) must partition food resources to coexist, and traditional frameworks categorize LMH along a spectrum from grass-eating grazers to non–grass-eating browsers. Yet it has never been clear how finely LMH partition the enormous species diversity subsumed within these two broad plant types. By sequencing plant DNA from LMH fecal samples, we analyzed the diets of an LMH assemblage in Kenya. Diet composition was similar within species and strongly divergent across species, irrespective of feeding guild: Grazers ate similar total amounts of grass but different suites of grass species. These results suggest that species-specific plant traits may be key to understanding the dietary differences thought to underpin LMH diversity. Niche partitioning facilitates species coexistence in a world of limited resources, thereby enriching biodiversity. For decades, biologists have sought to understand how diverse assemblages of large mammalian herbivores (LMH) partition food resources. Several complementary mechanisms have been identified, including differential consumption of grasses versus nongrasses and spatiotemporal stratification in use of different parts of the same plant. However, the extent to which LMH partition food-plant species is largely unknown because comprehensive species-level identification is prohibitively difficult with traditional methods. We used DNA metabarcoding to quantify diet breadth, composition, and overlap for seven abundant LMH species (six wild, one domestic) in semiarid African savanna. These species ranged from almost-exclusive grazers to almost-exclusive browsers: Grass consumption inferred from mean sequence relative read abundance (RRA) ranged from >99% (plains zebra) to <1% (dik-dik). Grass RRA was highly correlated with isotopic estimates of % grass consumption, indicating that RRA conveys reliable quantitative information about consumption. Dietary overlap was greatest between species that were similar in body size and proportional grass consumption. Nonetheless, diet composition differed between all species—even pairs of grazers matched in size, digestive physiology, and location—and dietary similarity was sometimes greater across grazing and browsing guilds than within them. Such taxonomically fine-grained diet partitioning suggests that coarse trophic categorizations may generate misleading conclusions about competition and coexistence in LMH assemblages, and that LMH diversity may be more tightly linked to plant diversity than is currently recognized.",2015-06-01,https://www.semanticscholar.org/paper/486f8b467aec592d848e6e3795c0f0e53dcbc2d4,Proceedings of the National Academy of Sciences of the United States of America
1636,Deep and Hierarchical Implicit Models,"Implicit probabilistic models are a flexible class for modeling data. They define a process to simulate observations, and unlike traditional models, they do not require a tractable likelihood function. In this paper, we develop two families of models: hierarchical implicit models and deep implicit models. They combine the idea of implicit densities with hierarchical Bayesian modeling and deep neural networks. The use of implicit models with Bayesian analysis has been limited by our ability to perform accurate and scalable inference. We develop likelihood-free variational inference (LFVI). Key to LFVI is specifying a variational family that is also implicit. This matches the model's flexibility and allows for accurate approximation of the posterior. Our work scales up implicit models to sizes previously not possible and advances their modeling design. We demonstrate diverse applications: a large-scale physical simulator for predator-prey populations in ecology; a Bayesian generative adversarial network for discrete data; and a deep implicit model for text generation.",2017-02-28,https://www.semanticscholar.org/paper/e57c09d50d67060b18806f9597674fdc28320dd2,arXiv.org
2907,A finite element method to calculate geometrically necessary dislocation density: Accounting for orientation discontinuities in polycrystals,,2022-12-01,https://www.semanticscholar.org/paper/8ba009d5816d07f953d3e5229946efa9237e924a,Acta Materialia
2920,Integrative genetic analysis of the amyotrophic lateral sclerosis spinal cord implicates glial activation and suggests new risk genes,"Amyotrophic lateral sclerosis (ALS) is a progressively fatal neurodegenerative disease affecting motor neurons in the brain and spinal cord. We used 380 post-mortem tissue RNA-seq transcriptomes from 154 ALS cases and 49 control individuals from cervical, thoracic, and lumbar spinal cord segments to investigate the gene expression response to ALS. We observed an increase in microglia and astrocyte expression, accompanied by a decrease in oligodendrocytes. By creating a gene co-expression network in the ALS samples, we identify several activated microglia modules that negatively correlate with retrospective disease duration. We map molecular quantitative trait loci and find several potential ALS risk loci that may act through gene expression or splicing in the spinal cord and assign putative cell-types for FNBP1, ACSL5, SH3RF1 and NFASC. Finally, we outline how repeat expansions that alter splicing of C9orf72 are tagged by common variants, and use this to suggest ATXN3 as a putative risk gene.",2021-09-02,https://www.semanticscholar.org/paper/d649792fe67746960ee38f5ef5ca0fbb674e55eb,medRxiv
275,Internet routing and internet service provision,"The recent development and expansion of the Internet has created many technical challenges in several diverse research areas. In this thesis, we study recent problems arising in the area of Internet routing and Internet service provision. In the area of Internet routing, we analyze properties of the selfish routing model, which is a mathematical model of users selfishly routing traffic in a network without regard to their effect on other users. Additionally, we study the properties of various random graph models which have been used to model the Internet, and utilize the properties of graphs generated by those random models to develop simple compact routing schemes, which can allow network routing without having each node store very much information. In the area of Internet service provision, we study an online bipartite matching problem, in which a set of servers seeks to provide service to arriving clients with as little interruption as possible. The central theme of this thesis is to analyze precise mathematical models of Internet routing and Internet service provision, and in those models, we show certain properties hold or derive algorithms which work with high probability. 
The first model we study is the selfish routing model. In the selfish routing model, we analyze the efficiency of users selfishly routing traffic and study a counterintuitive phenomenon known as Braess's Paradox, which states that adding a link to a network with selfish routing may actually increase the latency for all users. We produce tight and nearly tight bounds on the maximum increase in latency that can occur due to Braess's Paradox in single-commodity and multicommodity networks, respectively. We also produce the first nearly tight bounds on the maximum latency that can occur when traffic is routed selfishly in multicommodity networks, relative to the maximum latency that occurs when traffic is routed optimally. 
In the second part of the thesis, we study random graph models which have been used to model the Internet, and look for properties of graphs generated by those models, which can be used to derive simple compact routing schemes. The goal of compact routing is to derive algorithms which minimize the information stored by nodes in the network, while maintaining the ability of all nodes to route packets to each other along relatively short paths. In this research area, we show that graphs generated by several random graph models used to model the Internet (e.g. the preferential attachment model), can be decomposed in a novel manner, which allows compact routing to be achieved easily. Along the way, we also prove that a Polya urns random process has good load balancing properties, which may be of independent interest. 
In the last part of the thesis, we study an online bipartite matching problem, which models a problem occurring in the area of Internet service provision. In our online bipartite matching problem, we imagine that we have some servers capable of providing some service, and clients arrive one at a time to request service from a subset of servers capable of servicing their request. The goal of the problem is to assign the arriving clients to servers capable of servicing their requests, all while minimizing the number of times that a client needs to be switched from one server to another server. Although prior worst case analysis for this problem has not yielded interesting results, we show tight bounds on the number of times clients need to be switched under a few natural models. 
As we analyze these problems arising in the Internet from a precise mathematical perspective, we also seek to reflect on the process used to solve mathematical problems. Although the thought process can sometimes be difficult to describe, in one case, we attempt to provide a step-by-step account of how the final result was proved, and attempt to describe a high level algorithm, which summarizes the methodology that used to prove it.",,https://www.semanticscholar.org/paper/502bfaebb07c926850850bf0df2119e321309039,
1086,Inclusive D*(plus/minus) production in photon-photon collisions,"Author(s): Alston-Garnjost, M.; Avery, R.E.; Barker, A.R.; Bauer, D.A.; Bay, A.; Buijs, A.; Belcinski, R.; Bingham, H.H.; Bloom, E.D.; Buchanan, C.D.; Caldwell, D.O.; Chao, H-Y.; Chun, S-B.; Clark, A.R.; Crane, D.A.; Dahl, O.I.; Daoudi, M.; Eastman, J.J.; Eberhard, P.H.; Edberg, T.K.; Eisner, A.M.; Erne, F.C.; Fairfield, K.H.; Godfrey, G.; Hauptman, J.M.; Hofmann, W.; Kenney, R.W.; Khacheryan, S.; Knopfle, K.T.; Kofler, R.R.; Lambert, D.J.; Langeveld, W.G.J.; Layter, J.G.; Lin, W.T.; Linde, F.L.; Loken, S.C.; Lu, A.; Lynch, G.R.; Lys, J.E.; Madaras, R.J.; Marsiske, H.; Masek, G.E.; Loken, S.C.; Lu, A.; Lynch, G.R.; Lys, J.E.; Madaras, R.J.; Marsiske, H.; Masek, G.E.; Mathis, L.G.; Miller, E.S.; Nicol, N.A.; Nygren, D.R.; Oddone, P.J.; Oyang, Y.-T.; Paar, H.P.; Palounek, A.P.T.; Park, S.K.; Pellett, D.E.; Pripstein, M.; Ronan, M.T.; Ross, R.R.; Sens, J.C.; Shapiro, G.; Shen, B.C.; Steinman, J.S.; Stephens, R.W.; Stevenson, M.L.; Stork, D.H.; Strauss, M.G.; Sullivan, M.K.; Toutounchi, S.; Vernon, W.; Wang, E.M.; Wang, Y.-X.; Wenzel, W.A.; Yamamoto, H.; Yellin, S.J.; Yost, G.P.; Zapalac, G.; Zeitlin, C.",2017-12-05,https://www.semanticscholar.org/paper/d3e2b71dad1756320d28817e4b0e9bf59967c165,
3643,Run Time Type Identification for C++,,,https://www.semanticscholar.org/paper/a0e0a184e21c9252500aebf2c4f002b0c69a0e75,C++ Conference
1246,Search for Decay of a Fermiophobic Higgs Bosonwith the D0 Detector at,,2008-07-29,https://www.semanticscholar.org/paper/a757a6fea1ce6ac1ec736b01e1717f1ae89cad17,
924,Computing the Minimum Fill-in is NP^Complete,"We show that the following problem is NP-complete. Given a graph, find the minimum number of edges (fill-in) whose addition makes the graph chordal. This problem arises in the solution of sparse symmetric positive definite systems of linear equations by Gaussian elimination.",1981-03-01,https://www.semanticscholar.org/paper/8561d23058501c8f2c245bffb3001e488192a7a3,
3260,Genetic relatedness in two-tiered plains zebra societies suggests that females choose to associate with kin,"How kinship structures alter inclusive fitness benefits or competition costs to members of a group can explain variation in animal societies. We present rare data combining behavioural associations and genetic relatedness to determine the influence of sex differences and kinship in structuring a two-tiered zebra society. We found a significantly positive relationship between the strength of behavioural association and relatedness. Female relatedness within herds was higher than chance, suggesting that female kin drive herd formation, and consistent with evidence that lactating females preferentially group into herds to dilute predation risk. In contrast, male relatedness across harems in a herd was no different from relatedness across herds, suggesting that although stallions benefit from associating to fend off bachelors, they do not preferentially form kin coalitions. Although both sexes disperse, we found that most harems contained adult relatives, implying limited female dispersal distances and inbreeding in this population, with potential conservation consequences.",,https://www.semanticscholar.org/paper/9060b179dcfc37e38cf1ecbd9a2f06c45596287a,
111,International Journal of Digital Libraries Manuscript Nr. the Stanford Digital Library Metadata Architecture ? 2 Our Metadata Requirements,"The overall goal of the Stanford Digital Library project is to provide an infrastructure that a ords interoperability among heterogeneous, autonomous digital library services. These services include both search services and remotely usable information processing facilities. In this paper, we survey and categorize the metadata required for a diverse set of Stanford Digital Library services that we have built. We then propose an extensible metadata architecture that meets these requirements. Our metadata architecture ts into our established infrastructure and promotes interoperability among existing and de-facto metadata standards. Several pieces of this architecture are implemented; others are under construction. The architecture includes attribute model proxies, attribute model translation services, metadata information facilities for search services, and local metadata repositories. In presenting and discussing the pieces of the architecture, we show how they address our motivating requirements. Together, these components provide, exchange, and describe metadata for information objects and metadata for information services. We also consider how our architecture relates to prior, relevant work on these two types of metadata.",,https://www.semanticscholar.org/paper/7e8359716df50fe4973cc87b48dc19d23af0495f,
1339,Exclusion limits on the WIMP-nucleon cross section from the first run of the Cryogenic Dark Matter Search in the Soudan Underground Laboratory,"The Cryogenic Dark Matter Search (CDMS-II) employs low-temperature Ge and Si detectors to seek Weakly Interacting Massive Particles (WIMPs) via their elastic scattering interactions with nuclei. Simultaneous measurements of both ionization and phonon energy provide discrimination against interactions of background particles. For recoil energies above 10 keV, events due to background photons are rejected with > 99.99% efficiency. Electromagnetic events very near the detector surface can mimic nuclear recoils because of reduced charge collection, but these surface events are rejected with > 96% efficiency by using additional information from the phonon pulse shape. Efficient use of active and passive shielding, combined with the 2090 m.w.e. overburden at the experimental site in the Soudan mine, makes the background from neutrons negligible for this first exposure. All cuts are determined in a blind manner from in situ calibrations with external radioactive sources without any prior knowledge of the event distribution in the signal region. Resulting efficiencies are known to {approx}10%. A single event with a recoil of 64 keV passes all of the cuts and is consistent with the expected misidentification rate of surface-electron recoils. Under the assumptions for a standard dark matter halo, these data exclude previously unexplored parameter space for both spin-independent and spin-dependent WIMP-nucleon elastic scattering. The resulting limit on the spin-independent WIMP-nucleon elastic-scattering cross-section has a minimum of 4 x 10{sup -43} cm{sup 2} at a WIMP mass of 60 GeV c{sup -2}. The minimum of the limit for the spin-dependent WIMP-neutron elastic-scattering cross-section is 2 x 10{sup -37} cm{sup 2} at a WIMP mass of 50 GeV c{sup -2}.",2005-07-01,https://www.semanticscholar.org/paper/31b9d998d4560f71b41a827687b7f54694f65939,
1103,Dark Matter Search Results Using the Silicon Detectors of CDMS II,"We report results of a search for Weakly Interacting Massive Particles (WIMPs) with the silicon (Si) detectors of the CDMS II experiment. A blind analysis of data from eight Si detectors, with a total raw exposure of 140.2 kg-days, revealed three WIMP-candidate events with a final surface-event background estimate of 0.41 (-0.08 +0.20)(stat.) (-0.24 +0.28) (syst.). Other known backgrounds from neutrons and 206Pb are limited to < 0.13 and < 0.08 events at the 90% confidence level, respectively. These data place a 90% upper confidence limit on the WIMP-nucleon cross section of 2.4E-41 cm^2 at a WIMP mass of 10 GeV/c^2. Simulations indicate a 5.4% probability that a statistical fluctuation of the known backgrounds would produce three or more events in the signal region. A profile likelihood ratio test that includes the measured recoil energies of the three events gives a 0.19% probability for the known-background-only hypothesis when tested against the alternative WIMP+background hypothesis. The highest likelihood was found for a WIMP mass of 8.6 GeV/c^2 and WIMP-nucleon cross section of 1.9E-41 cm^2.",2013-04-15,https://www.semanticscholar.org/paper/2baa5e4805f5b9cb7b261552fe2ee98936a90daa,
2968,Beta diffusion trees and hierarchical feature allocations,"We define the beta diffusion tree, a random tree structure with a set of leaves that defines a collection of overlapping subsets of objects, known as a feature allocation. A generative process for the tree structure is defined in terms of particles (representing the objects) diffusing in some continuous space, analogously to the Dirichlet diffusion tree (Neal, 2003), which defines a tree structure over partitions (i.e., non-overlapping subsets) of the objects. Unlike in the Dirichlet diffusion tree, multiple copies of a particle may exist and diffuse along multiple branches in the beta diffusion tree, and an object may therefore belong to multiple subsets of particles. We demonstrate how to build a hierarchically-clustered factor analysis model with the beta diffusion tree and how to perform inference over the random tree structures with a Markov chain Monte Carlo algorithm. We conclude with several numerical experiments on missing data problems with data sets of gene expression microarrays, international development statistics, and intranational socioeconomic measurements.",2014-08-14,https://www.semanticscholar.org/paper/bab82ac55ebf42a09f3419dfc158da8423bd629a,
3283,International citizen science: making the local global,"The Earthwatch Institute is an international non-profit organization that works with scientists and scientific institutions to develop citizen-science-based research and environmental monitoring programs. Each year, Earthwatch supports close to 80 different projects in more than 30 countries and recruits over 3000 volunteers to aid scientists in collecting data. Participants recruited by Earthwatch seek to tap into their passion for learning about science by volunteering to act as assistants for authentic research projects.",2012-08-01,https://www.semanticscholar.org/paper/c6d46b32e4932b645ef321ac15d756d1cd198719,
1671,A General Method for Robust Bayesian Modeling,"Robust Bayesian models are appealing alternatives to standard models, providing protection from data that contains outliers or other departures from the model assumptions. Historically, robust models were mostly developed on a case-by-case basis; examples include robust linear regression, robust mixture models, and bursty topic models. In this paper we develop a general approach to robust Bayesian modeling. We show how to turn an existing Bayesian model into a robust model, and then develop a generic strategy for computing with it. We use our method to study robust variants of several models, including linear regression, Poisson regression, logistic regression, and probabilistic topic models. We discuss the connections between our methods and existing approaches, especially empirical Bayes and James-Stein estimation.",2015-10-17,https://www.semanticscholar.org/paper/19de6b41be976f7035fa8927932a0a89bf359a42,Bayesian Analysis
806,Protocol Feature Interactions,,1998-11-03,https://www.semanticscholar.org/paper/2df6ed60549c46121cbc0ce7af6f846a59bc1251,Formal Techniques for (Networked and) Distributed Systems
2620,An extended menu navigation interface using multiple pressure-sensitive strips,"We present extensions and modifications that we have made to a cursorless menu navigation interface that is controlled by multiple pressure-sensitive linear strips. Our approach is based on detecting pressure thresholds and dual-finger motions, allowing us to overcome the physical limitations of the prototype input device and virtually more than triple the number of linear strips that can be used for menu navigation. This allows the user to directly access and navigate in up to fourteen independent multiple-depth menu trees. Our system allows this breadth and depth of navigation without the need for an on-screen cursor, nor the need to navigate a 2D input device, thereby reducing the need for visual feedback. We have tried to design the on-screen graphical interface so that it can be easily used with very small field-of-view display devices, such as eyeglass displays. Additionally, since our input device is physically compact and can be easily positioned on different places on the body, the menu navigation system is especially appropriate for wearable computing systems.",2003-10-21,https://www.semanticscholar.org/paper/8378ff677f0c07b3931d506610a2aeedb89d737d,"Seventh IEEE International Symposium on Wearable Computers, 2003. Proceedings."
1551,Correction to: Counterfactual inference for consumer choice across many product categories,,2021-12-01,https://www.semanticscholar.org/paper/e597faf0a561de858600ccead4e44ff782a37c3d,Quantitative Marketing and Economics
2068,Using Rough Set Theory to Recruit and Retain High-Potential Talents for Semiconductor Manufacturing,"To recruit and retain high-potential talent is critical for semiconductor companies to maintain competitive advantages in a modern knowledge-based economy. Conventional personnel selection methodologies focusing on static work and job analysis will no longer be appropriate for knowledge workers in high-tech industries. This paper aims to develop an effective data mining approach based on Rough Set Theory to explore and analyze human resource data for personnel selection and human capital enhancement. An empirical study was conducted in a leading semiconductor company in Taiwan to estimate the validity of the proposed approach for predicting work behaviors including performance and resignation. The results showed that latent knowledge can be discovered as a basis to derive specific recruitment and human resource management strategies. In particular, 29 rules have been adopted as references for recruiting the right talent. This paper concludes with discussions of empirical findings and future research directions.",2007-11-12,https://www.semanticscholar.org/paper/7ebdcc84a4e7371d7513debcc7d49276b04240cf,IEEE transactions on semiconductor manufacturing
34,Event Identification in Social Media,"Social media sites such as Flickr, YouTube, and Facebook host substantial amounts of user-contributed materials (e.g., photographs, videos, and textual content) for a wide variety of real-world events. These range from widely known events, such as the presidential inauguration, to smaller, community-specific events, such as annual conventions and local gatherings. By identifying these events and their associated user-contributed social media documents, which is the focus of this paper, we can greatly improve local event browsing and search in state-of-the-art search engines. To address our problem of focus, we exploit the rich “context” associated with social media content, including user-provided annotations (e.g., title, tags) and automatically generated information (e.g., content creation time). We form a variety of representations of social media documents using different context dimensions, and combine these dimensions in a principled way into a single clustering solution—where each document cluster ideally corresponds to one event—using a weighted ensemble approach. We evaluate our approach on a large-scale, real-world dataset of event images, and report promising performance with respect to several baseline approaches. Our preliminary experiments suggest that our ensemble approach identifies events, and their associated images, more effectively than the state-of-the-art strategies on which we build.",,https://www.semanticscholar.org/paper/f3a6725548c22d5bea6a0cb0b0a705d2e81475c9,International Workshop on the Web and Databases
2863,Galectin-3 and Regulation of Cell Function,"The galectin family is phylogenically conserved in metazoans, presently consisting of 14 identified members in mammals, and galectin-3 is one of the most abundant, widely distributed, and well-studied members. It is present intracellularly in nuclear and cytoplasmic compartments, but is also secreted through an unconventional mechanism that involves vesicles and exosomes and, consequently, present outside the cell. While galectin-3 shares many features with other galectins, including cellular compartmentalization and functions, it appears to be unique in its structural constituency in the N-terminal domain, which is rich in proline, glycine, and alanine. It is through this domain that galectin-3 is able to form oligomers, and this may be one feature that functionally differentiates it from other galectins. Galectin-3 has been associated with several intracellular and extracellular functions, and recent investigations have uncovered proteins through which this lectin mediates its activities. The availability of targeted mutant mice deficient in galectin- 3 and other proteins has also contributed to our appreciation of the breadth of processes in which this protein is involved. Among cell functions attributable to galectin-3 are some that are associated with neoplastic transformation and invasiveness, but the most extensively documented ones are those related to the immune and inflammatory responses.",2005-03-01,https://www.semanticscholar.org/paper/c04bf72164c8a3a9160b9d152364981e54c0a453,Transfusion Medicine and Hemotherapy
524,Mathematical programming: complexity and applications,,,https://www.semanticscholar.org/paper/88916128a604db43828b742fb524bcb8b1ded9fa,
1483,A measurement of A20 (1320) formation in photon photon collisions,,,https://www.semanticscholar.org/paper/a770c7a653153488ffe865e87517c18d088ea9aa,
1693,Handbook of Mixed Membership Models and Their Applications,"In response to scientific needs for more diverse and structured explanations of statistical data, researchers have discovered how to model individual data points as belonging to multiple groups. Handbook of Mixed Membership Models and Their Applications shows you how to use these flexible modeling tools to uncover hidden patterns in modern high-dimensional multivariate data. It explores the use of the models in various application settings, including survey data, population genetics, text analysis, image processing and annotation, and molecular biology. Through examples using real data sets, youll discover how to characterize complex multivariate data in: Studies involving genetic databases Patterns in the progression of diseases and disabilities Combinations of topics covered by text documents Political ideology or electorate voting patterns Heterogeneous relationships in networks, and much more The handbook spans more than 20 years of the editors and contributors statistical work in the field. Top researchers compare partial and mixed membership models, explain how to interpret mixed membership, delve into factor analysis, and describe nonparametric mixed membership models. They also present extensions of the mixed membership model for text analysis, sequence and rank data, and network data as well as semi-supervised mixed membership models.",2014-11-06,https://www.semanticscholar.org/paper/0affd3ffca1707f6800be3c98202daa3b1912d47,
3100,On the performance of wide-area thin-client computing,"While many application service providers have proposed using thin-client computing to deliver computational services over the Internet, little work has been done to evaluate the effectiveness of thin-client computing in a wide-area network. To assess the potential of thin-client computing in the context of future commodity high-bandwidth Internet access, we have used a novel, noninvasive slow-motion benchmarking technique to evaluate the performance of several popular thin-client computing platforms in delivering computational services cross-country over Internet2. Our results show that using thin-client computing in a wide-area network environment can deliver acceptable performance over Internet2, even when client and server are located thousands of miles apart on opposite ends of the country. However, performance varies widely among thin-client platforms and not all platforms are suitable for this environment. While many thin-client systems are touted as being bandwidth efficient, we show that network latency is often the key factor in limiting wide-area thin-client performance. Furthermore, we show that the same techniques used to improve bandwidth efficiency often result in worse overall performance in wide-area networks. We characterize and analyze the different design choices in the various thin-client platforms and explain which of these choices should be selected for supporting wide-area computing services.",2006-05-01,https://www.semanticscholar.org/paper/aeb049d0a1869827523689a7b8ccddff43aaec0c,TOCS
2058,Horizontal Specialization and Modularity in the Semiconductor Industry,,2008-07-17,https://www.semanticscholar.org/paper/d828f568996031983f570de835cf21018f3f64da,
2365,"The relationship between superoxide generation, cytochrome b and oxygen in activated neutrophils",,1988-01-18,https://www.semanticscholar.org/paper/9b28bdd3ea7f950b68669182fd6df5ea57551be9,
3495,Optimal Time-Critical Scheduling via Resource Augmentation (Extended Abstract),,1997-05-04,https://www.semanticscholar.org/paper/4cf689437066266bc3129fd0667c3418d6bfece3,Symposium on the Theory of Computing
2138,Spatial cross-correlation of acoustic pressures in steady and decaying reverberant sound fields,,1976-09-22,https://www.semanticscholar.org/paper/2c7145a761e42501689a7a53ae43673f48a43569,
1624,SHOPPER: A Probabilistic Model of Consumer Choice with Substitutes and Complements,"We develop SHOPPER, a sequential probabilistic model of market baskets. SHOPPER uses interpretable components to model the forces that drive how a customer chooses products; in particular, we designed SHOPPER to capture how items interact with other items. We develop an efficient posterior inference algorithm to estimate these forces from large-scale data, and we analyze a large dataset from a major chain grocery store. We are interested in answering counterfactual queries about changes in prices. We found that SHOPPER provides accurate predictions even under price interventions, and that it helps identify complementary and substitutable pairs of products.",2017-11-09,https://www.semanticscholar.org/paper/3a4bea2033c86ac1d26f76d1d9c07216c9a1a541,Annals of Applied Statistics
1737,Efficient Online Inference for Bayesian Nonparametric Relational Models,"Stochastic block models characterize observed network relationships via latent community memberships. In large social networks, we expect entities to participate in multiple communities, and the number of communities to grow with the network size. We introduce a new model for these phenomena, the hierarchical Dirichlet process relational model, which allows nodes to have mixed membership in an unbounded set of communities. To allow scalable learning, we derive an online stochastic variational inference algorithm. Focusing on assortative models of undirected networks, we also propose an efficient structured mean field variational bound, and online methods for automatically pruning unused communities. Compared to state-of-the-art online learning methods for parametric relational models, we show significantly improved perplexity and link prediction accuracy for sparse networks with tens of thousands of nodes. We also showcase an analysis of Little-Sis, a large network of who-knows-who at the heights of business and government.",2013-12-05,https://www.semanticscholar.org/paper/91608e4567959f331f3b231f4f8fb5e33ce71a15,Neural Information Processing Systems
933,Testing the Universal Instance Assumption,,1980-02-12,https://www.semanticscholar.org/paper/a25d4cf6ad249170199281569388c785212bd7ff,Information Processing Letters
1975,Semiconductor fault detection and classification for yield enhancement and manufacturing intelligence,,2013-09-01,https://www.semanticscholar.org/paper/105fb5f495415aef2fc8b4300ba327413be6fc36,
193,STDP Forms Associations between Memory Traces in Networks of Spiking Neurons,"Memory traces and associations between them are fundamental for cognitive brain function. Neuron recordings suggest that distributed assemblies of neurons in the brain serve as memory traces for spatial information, real-world items, and concepts. However, there is conflicting evidence regarding neural codes for associated memory traces. Some studies suggest the emergence of overlaps between assemblies during an association, while others suggest that the assemblies themselves remain largely unchanged and new assemblies emerge as neural codes for associated memory items. Here we study the emergence of neural codes for associated memory items in a generic computational model of recurrent networks of spiking neurons with a data-based rule for spike-timing-dependent plasticity (STDP). The model depends critically on two parameters, which control the excitability of neurons and the scale of initial synaptic weights. By modifying these two parameters, the model can reproduce both experimental data from the human brain on the fast formation of associations through emergent overlaps between assemblies, and rodent data where new neurons are recruited to encode the associated memories. Hence our findings suggest that the brain can use both of these two neural codes for associations, and dynamically switch between them during consolidation.",2017-09-14,https://www.semanticscholar.org/paper/ea98f42ac8adb6cefccbc3b33099915a48c44eae,bioRxiv
2457,Providing Assistance for Orienting 3D Objects Using Monocular Eyewear,"Many tasks require that a user rotate an object to match a specific orientation in an external coordinate system. This includes tasks in which one object must be oriented relative to a second prior to assembly and tasks in which objects must be held in specific ways to inspect them. Research has investigated guidance mechanisms for some 6DOF tasks, using wide--field-of-view, stereoscopic virtual and augmented reality head-worn displays (HWDs). However, there has been relatively little work directed toward smaller field-of-view lightweight monoscopic HWDs, such as Google Glass, which may remain more comfortable and less intrusive than stereoscopic HWDs in the near future. We have designed and implemented a novel visualization approach and three additional visualizations representing different paradigms for guiding unconstrained manual 3DOF rotation, targeting these monoscopic HWDs. We describe our exploration of these paradigms and present the results of a user study evaluating the relative performance of the visualizations and showing the advantages of our new approach.",2016-10-15,https://www.semanticscholar.org/paper/62400a70bbb1bc58b24bfafb78df30a07f697714,Symposium on Spatial User Interaction
103,Snowball: extracting relations from large plain-text collections,"Text documents often contain valuable structured data that is hidden Yin regular English sentences. This data is best exploited infavailable as arelational table that we could use for answering precise queries or running data mining tasks.We explore a technique for extracting such tables from document collections that requires only a handful of training examples from users. These examples are used to generate extraction patterns, that in turn result in new tuples being extracted from the document collection.We build on this idea and present our Snowball system. Snowball introduces novel strategies for generating patterns and extracting tuples from plain-text documents.At each iteration of the extraction process, Snowball evaluates the quality of these patterns and tuples without human intervention,and keeps only the most reliable ones for the next iteration. In this paper we also develop a scalable evaluation methodology and metrics for our task, and present a thorough experimental evaluation of Snowball and comparable techniques over a collection of more than 300,000 newspaper documents.",2000-06-01,https://www.semanticscholar.org/paper/cee045e890270abae65455667b292db355d53728,Digital library
2004,Manufacturing Intelligence for Equipment Condition Monitoring in Semiconductor Manufacturing,"For modern semiconductor manufacturing, a large number of interrelated equipment data are automatically collected. These data are usually used for fault detection and classification (FDC). However, unusual measurements may reflect a wafer defect or a change in equipment conditions. Early detection of the equipment condition changes assists with efficient maintenance. This study aimed to develop hierarchical indices that can be used for the conditional-based maintenance (CBM). For convenience, only the highest level index is used for real-time monitoring. Once this index decays, engineers could simply drill down to lower indices to identify the root cause. For validation, the proposed approach is conducted in a leading semiconductor foundry in Taiwan. The result shows that the highest index indicates the change of equipment conditions right after the preventive maintenance (PM).",,https://www.semanticscholar.org/paper/a1b0dc38e21498bdc9a9ea509d5a4f4f62c0670b,
1336,Measurement of the Ratio of Band B 0 Meson Lifetimes,,,https://www.semanticscholar.org/paper/2580a9e81c303e68c02791b5e5b72b048cf5f4a0,
521,Exploring an unknown graph,"It is desired to explore all edges of an unknown directed, strongly connected graph. At each point one has a map of all nodes and edges visited, one can recognize these nodes and edges upon seeing them again, and it is known how many unexplored edges emanate from each node visited. The goal is to minimize the ratio of the total number of edges traversed to the optimum number of traversals had the graph been known. For Eulerian graphs this ratio cannot be better than 2, and 2 is achievable by a simple algorithm. In contrast, the ratio is unbounded when the deficiency of the graph (the number of edges that have to be added to make it Eulerian) is unbounded. The main result is an algorithm that achieves a bounded ratio when the deficiency is bounded; unfortunately the ratio is exponential in the deficiency. It is also shown that, when partial information about the graph is available, minimizing the worst-case ratio is PSPACE-complete.<<ETX>>",1990-10-22,https://www.semanticscholar.org/paper/ffe64fd3019d58fb86915aeb9108c3a7757eef37,Proceedings [1990] 31st Annual Symposium on Foundations of Computer Science
3058,Guaranteeing performance through fairness in peer-to-peer file-sharing and streaming systems,"Over the past decade, Peer-to-Peer (P2P) file-sharing and streaming systems have evolved as a cheap and effective technology in distributing content to users. Guaranteeing a level of performance in P2P systems is, therefore, of utmost importance. However, P2P file-sharing and streaming applications suffer from a fundamental problem of unfairness, where many users have a tendency to free-ride by contributing little or no upload bandwidth while consuming much download bandwidth. By taking away an unfair share of resources, free-riders deteriorate the quality of service experienced by other users, by causing slower download times in P2P file-sharing networks and higher stream updates' miss rates in P2P streaming networks. Previous attempts at addressing fair bandwidth allocation in P2P, such as BitTorrent-like systems, suffer from slow peer discovery, inaccurate predictions of neighboring peers' bandwidth allocations, under-utilization of bandwidth, and complex parameter tuning. 
We present FairTorrent, a new deficit-based distributed algorithm that accurately rewards peers in accordance with their contribution in a file-sharing P2P system. In a nutshell, a FairTorrent peer uploads the next data block to a peer to whom it owes the most data. FairTorrent is resilient to exploitation by free-riders and strategic peers, is simple to implement, requires no bandwidth over-allocation, no prediction of peers' rates, no centralized control, and no parameter tuning. We implemented FairTorrent in a BitTorrent client without modifications to the BitTorrent protocol, and evaluated its performance against other widely-used BitTorrent clients using various scenarios including live BitTorrent swarms. Our results show that FairTorrent provides up to two orders of magnitude better fairness, up to five times better download performance for contributing peers, and 60–100% better performance on average in live BitTorrent swarms. We show analytically that for a number of upload capacity distributions, in an n-node FairTorrent network, no peer is ever owed more than O(log n) data blocks with high probability. 
Achieving fair bandwidth allocation in a P2P streaming scenario is even more difficult, as it comes with an additional constraint: each stream update must be received before its playback deadline P2P live streaming systems require global resource over-provisioning to deliver adequate streaming performance. When there is not enough bandwidth to accommodate all users for a particular stream, such as due to free-riders or low-contributing peers, all users, including high-contributing peers, observe poor performance. We present FairStream, a new P2P streaming system that delivers a good quality stream to peers that upload data at a rate above the stream rate, even in the presence of free-riders or malicious users. FairStream achieves this with three mechanisms. First, it provides a new peer reply policy framework that enables file sharing incentive mechanisms to be adapted for streaming. Second, it uses this framework to incorporate a deficit-based peer reply policy that enables each peer to reply first to the neighbor to whom it owes the most data as measured by a deficit counter. Third, it introduces a collusion-resistant mechanism to ensure effective data distribution of a stream despite a large fraction of free-riders who do not forward received data. We prove that FairStream is resilient to free-riders and rewards peers with streaming performance correlated with their contributions. We have also implemented FairStream as a BitTorrent client and evaluated its performance against other popular streaming systems. Our results on PlanetLab show that FairStream, similar to other systems, provides good quality streaming performance when resources are over-provisioned, but it also provides orders of magnitude better streaming performance for peers uploading above the stream rate when resources are constrained, in the presence of free-riders and low-contributing peers.",,https://www.semanticscholar.org/paper/67e720ce12edb028353688f111a747a681fef654,
191,"8th Innovations in Theoretical Computer Science Conference, ITCS 2017, January 9-11, 2017, Berkeley, CA, USA","For undirected graphs G = (V,E) and G0 = (V0, E0), say that G is a region intersection graph over G0 if there is a family of connected subsets {Ru ⊆ V0 : u ∈ V } of G0 such that {u, v} ∈ E ⇐⇒ Ru ∩Rv 6= ∅. We show if G0 excludes the complete graph Kh as a minor for some h ≥ 1, then every region intersection graph G over G0 with m edges has a balanced separator with at most ch √ m nodes, where ch is a constant depending only on h. If G additionally has uniformly bounded vertex degrees, then such a separator is found by spectral partitioning. A string graph is the intersection graph of continuous arcs in the plane. String graphs are precisely region intersection graphs over planar graphs. Thus the preceding result implies that every string graph with m edges has a balanced separator of size O( √ m). This bound is optimal, as it generalizes the planar separator theorem. It confirms a conjecture of Fox and Pach (2010), and improves over the O( √ m logm) bound of Matoušek (2013). 1998 ACM Subject Classification F.2.2 Nonnumerical Algorithms and Problems, G.1.6 Optimization, G.2.2 Graph Theory",,https://www.semanticscholar.org/paper/cdf6cc8a0fdbff8e266439547b64d8e957bd7c64,Information Technology Convergence and Services
432,Towards a theory of indexability,,,https://www.semanticscholar.org/paper/3bc8f7b350b506b3bfb58e89f9882d897d5e1f7a,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
890,Deadlock-Freedom (and Safety) of Transactions in a Distributed Database,,1986-10-01,https://www.semanticscholar.org/paper/0a6cb89853157e8328b3adb6b1a79cd1c81b5dde,Journal of computer and system sciences (Print)
3674,On unifying module interfaces,"This paper presents the outline of a uniform interface mechanism for activating different kinds of modules, e.g. processes, monitors, and procedures. The usefulness of such an interface in the design of modules and in the tuning of a system is discussed. The overheads involved in using it are explained, together with some implications that its general use has on the system structure.",,https://www.semanticscholar.org/paper/29650ba4640ce69c50ed601039beebd668ce051a,OPSR
3331,Horse signals: The sounds and scents of fury,,1992-05-01,https://www.semanticscholar.org/paper/83b24035107da74706f2251239c5ae7aee9a7532,Evolutionary Ecology
1045,Novel Perspectives for Hadron Physics,"I discuss several novel and unexpected aspects of quantum chromodynamics. These include: (a) the nonperturbative origin of intrinsic strange, charm and bottom quarks in the nucleon at large x; the breakdown of pQCD factorization theorems due to the lensing effects of initialand final-state interactions; (b) important corrections to pQCD scaling for inclusive reactions due to processes in which hadrons are created at high transverse momentum directly in the hard processes and their relation to the baryon anomaly in high-centrality heavy-ion collisions; and (c) the nonuniversality of quark distributions in nuclei. I also discuss some novel theoretical perspectives in QCD: (a) lightfront holography – a relativistic color-confining first approximation to QCD based on the AdS/CFT correspondence principle; (b) the principle of maximum conformality – a method which determines the renormalization scale at finite order in perturbation theory yielding scheme independent results; (c) the replacement of quark and gluon vacuum condensates by “in-hadron condensates” and how this helps to resolves the conflict between QCD vacuum and the cosmological constant.",,https://www.semanticscholar.org/paper/4a6d19265db0dcaa60be752937ccfa8544be5436,
2250,BASIC-ALIMENTARY TRACT Microbial Mannan Inhibits Bacterial Killing by Macrophages: A Possible Pathogenic Mechanism for Crohn's Disease,"Background & Aims: Crohn’s disease (CD) is mimicked by inherited phagocyte disorders and is associated with circulating antibodies against yeast mannan (antiSaccharomyces cerevisiae antibody; ASCA). We speculated that mannans might impair phagocyte function. Methods: S cerevisiae mannan was assessed for its effects on human peripheral blood neutrophils, adherent monocytes, and monocyte-derived macrophages (MDM). Results: Mannan caused dose-related increased survival of CD Escherichia coli HM605 within adherent monocytes from 24% 10.5% (control) to 114% 22.7% with mannan 1 mg/mL at 2 hours (mean SEM, n 9; P .0002). Electron microscopy showed E coli HM605 surviving and probably replicating within macrophage vesicles. Mannan (1 mg/mL) inhibited the respiratory burst in neutrophils and monocytes (both P .002) and bacterial killing within MDM (P < .001). E coli survival was increased within macrophages from TLR4 / (126% 3.5% survival at 2 hours) and MyD88 / (134.8% 6.5%) mice compared with wildtype mice (both P < .0001). Mannan had no additional effect, showing that TLR4 and MyD88 are involved in bacterial killing by macrophages and its inhibition by mannan. Putative CD-associated micro-organisms were screened for the ASCA mannan epitope byGalanthus nivalis lectin (GNA) blotting. ASCA epitope was expressed by Candida albicans and Mycobacterium paratuberculosis but not by Mycobacterium tuberculosis or E coli. Supernatants from M paratuberculosis culture inhibited killing of E coli HM605 by adherent human monocytes and murine macrophages. The inhibitory activity was removed by GNA-affinity chromatography. Conclusions: Suppression of mucosal phagocyte function by microbial mannans, possibly of Mycobacterial origin, may contribute to CD pathogenesis.",,https://www.semanticscholar.org/paper/e0e91b66c886bc2f7f43976e1824fc31e1a66c1b,
53,XML & Data Streams,,,https://www.semanticscholar.org/paper/9c72ac1af5630f2a27eff0e5d7726722424f1be9,Stream Data Management
14,Ranking Deep Web Text Collections for Scalable Information Extraction,"Information extraction (IE) systems discover structured information from natural language text, to enable much richer querying and data mining than possible directly over the unstructured text. Unfortunately, IE is generally a computationally expensive process, and hence improving its efficiency, so that it scales over large volumes of text, is of critical importance. State-of-the-art approaches for scaling the IE process focus on one text collection at a time. These approaches prioritize the extraction effort by learning keyword queries to identify the ""useful"" documents for the IE task at hand, namely, those that lead to the extraction of structured ""tuples."" These approaches, however, do not attempt to predict which text collections are useful for the IE task---and hence merit further processing---and which ones will not contribute any useful output---and hence should be ignored altogether, for efficiency. In this paper, we focus on an especially valuable family of text sources, the so-called deep web collections, whose (remote) contents are only accessible via querying. Specifically, we introduce and study techniques for ranking deep web collections for an IE task, to prioritize the extraction effort by focusing on collections with substantial numbers of useful documents for the task. We study both (adaptations of) state-of-the-art resource selection strategies for distributed information retrieval, and IE-specific approaches. Our extensive experimental evaluation over realistic deep web collections, and for several different IE tasks, shows the merits and limitations of the alternative families of approaches, and provides a roadmap for addressing this critically important building block for efficient, scalable information extraction.",2015-10-17,https://www.semanticscholar.org/paper/767dcce161a6a2a2bb8c404e08b2e169b36e6c1c,International Conference on Information and Knowledge Management
2117,A cutting algorithm for optimizing the wafer exposure pattern,"Semiconductor manufacturing industry competes by increasing yield and lowering die costs, thereby taking advantage of significant capital investments. Many studies focus on defect reduction to improve yield rate. However, the problem of optimizing wafer exposure patterns has received little attention. In this paper, given the specific patterning constraints, we develop a two-dimensional (2-D) cutting algorithm to maximize the gross die yields of the eight-inch wafer and larger circular wafers. The empirical results that we implemented in a wafer fabrication factory in Taiwan validate the practical viability of this approach. Similar approaches can readily be applied to other wafer patterning.",2001-05-01,https://www.semanticscholar.org/paper/837148b66803c3c1e8f0f757dee0f2812cc24de4,
2484,Addressing Information Overload in Urban Augmented Reality Applications,"How can we design effective urban visualizations in augmented reality when there are large numbers of points-ofinterest (POIs) to display? We present three issues we have encountered as we tackle this problem in our own research: inadequate support for browsing, limited visual real estate, and minimal use of abstraction. Author Keywords",,https://www.semanticscholar.org/paper/405de35df202aece538cd67c85abb4e9a9bcdd43,
2760,Seeing the forest for the trees: hierarchical displays of hypertext structures,"Most recent hypertext systems support hierarchy only as a restricted subset of directed graph structure. Consequently they do not provide many of the capabilities for graphical information hiding and structure manipulation that a tree makes possible. This paper describes display techniques developed for IGD, a hypertext system that supports the creation of large graphical documents whose arbitrary directed graph structure is embedded in a strict hierarchy. IGD offers the full generality of arbitrary keyworded links, while simultaneously allowing hierarchies to be easily manipulated and displayed with much of their structural detail selectively abstracted.",1988-04-01,https://www.semanticscholar.org/paper/0759e40a01b100f9d0b67fc6abe126e640a852f9,Conference on Organizational Computing Systems
3578,Runtime concepts for the C++ standard template library,"A key benefit of generic programming is its support for producing modules with clean separation. In particular, generic algorithms are written to work with a wide variety of unmodified types. The Runtime concept idiom extends this support by allowing unmodified concrete types to behave in a runtime polymorphic manner. In this paper, we describe one implementation of the runtime concept idiom, in the domain of the C++ standard template library (STL). We describe and measure the performance of runtime-polymorphic analogs of several STL algorithms. We augment the runtime concept idiom by employing a dispatch mechanism that considers both type and concept information to maximize performance when selecting algorithm implementations. We use our implementation to demonstrate the effects of different compile-time vs. run-time algorithm selection choices, and we indicate where improved language and compiler support would be useful.",2008-03-16,https://www.semanticscholar.org/paper/2184f48ae1ae03292aab3ad069fdf5af266ec5e5,ACM Symposium on Applied Computing
2007,Manufacturing intelligence for Hsinchu Science Park semiconductor sales prediction,"Hsinchu Science Park (HSP) is a high-tech cluster where semiconductor industry plays a decisive role in Taiwan's economy as well as global supply chains. Semiconductor industry is capital intensive, in which capacity utilization significantly affects the capital effectiveness and profitability of semiconductor companies. Thus, demand forecasting provides critical input to support strategic decisions of capacity planning and the associated capital expenditure that require long lead-time. This study aims to predict the sales of semiconductor industry in HSP as a reference signal for supporting the decisions of individual companies and the government to maintain a healthy ecosystem. Empirical data of semiconductor industry in HSP from 1983 to 2010 was collected and analyzed. Furthermore, this study incorporated historical events to adjust the prediction. The results have shown practical viability of this research to support companies to improve the demand forecast as well as to make strategic decisions for semiconductor ecosystem as a whole.",2012-03-01,https://www.semanticscholar.org/paper/fef32337c0ed40c2d0d3104e8f0427e627ccec33,
2917,Estimating damage parameters of a CuCrZr alloy subjected to two varying heat treatments using small punch test,,2021-12-01,https://www.semanticscholar.org/paper/52fd3e20549ac0bac4ba381d934cd7500ca48aaf,
2959,An Empirical Study of Stochastic Variational Algorithms for the Beta Bernoulli Process,"Stochastic variational inference (SVI) is emerging as the most promising candidate for scaling inference in Bayesian probabilistic models to large datasets. However, the performance of these methods has been assessed primarily in the context of Bayesian topic models, particularly latent Dirichlet allocation (LDA). Deriving several new algorithms, and using synthetic, image and genomic datasets, we investigate whether the understanding gleaned from LDA applies in the setting of sparse latent factor models, specifically beta process factor analysis (BPFA). We demonstrate that the big picture is consistent: using Gibbs sampling within SVI to maintain certain posterior dependencies is extremely effective. However, we find that different posterior dependencies are important in BPFA relative to LDA. Particularly, approximations able to model intra-local variable dependence perform best.",2015-06-26,https://www.semanticscholar.org/paper/c0cc5cc0968554d766d3deadbe2fbe5c10b96994,International Conference on Machine Learning
3328,Science advisors in the public schools,"Last September we began a program in which each public school in seven New Jersey districts invited a scientist from the Princeton Chapter of Sigma Xi to serve as Science Advisor. Now, fifty-seven volunteers serve fifty-four schools. Key elements of the program are sustained contact and an integrated network. The Science Advisor visits the school three hours per week to form creative partnerships with teachers that enable the teacher to better convey the process of science. The Advisor is also a teacher`s link to expertise and resource, via a formal network. Members of the network (Advisors plus additional volunteers) communicate by e-mail and meet regularly to share ideas and make inquires on behalf of teachers. At the hub is a paid science Coordinator who organizes information and ideas, and matches requests with resources. Local employers support the program by providing salaries time for employees to be Science Advisors. Training sessions upgrade science advising skills.",1994-12-31,https://www.semanticscholar.org/paper/c6ceda68f7e6a07073d88fd1513c32d0a7a16f67,
2625,"Coarse, inexpensive, infrared tracking for wearable computing","We present a novel, inexpensive, coarse tracking systemthat determines a person's approximate 2D locationand 1D head orientation in an indoor environment. Whilethis coarse tracking cannot support precise registration ofoverlaid material, it can be used to drive user interfacesthat can adapt to the quality of tracking available.Our approach uses a set of strong infrared beacons,each of which broadcasts a unique ID. The beacons aredeployed in the environment such that their zones of influencestrategically overlap, partitioning the area of coverageinto a set of uniquely identifiable fragments. We use acompound, omnidirectional infrared receiver, composedof a set of individual, directional infrared receivers, toinfer 2D position (parallel to the ground plane) and 1Dorientation (azimuth), employing a Kalman-filter-basedarchitecture for smoothing and data integration withother tracking systems available. To test our ideas, wehave applied them to a prototype head tracker, and presentresults from our tests.",2003-10-21,https://www.semanticscholar.org/paper/bcfe1751ce0254239b93c0f5fa63fa855c66eb23,"Seventh IEEE International Symposium on Wearable Computers, 2003. Proceedings."
1396,A testing strategy for the mass production of CDMS II detectors,"The Cryogenic Dark Matter Search (CDMS) employs detectors which are capable of simultaneously measuring the ionization and phonon energies deposited by a particle collision. These detectors are 1-cm-thick, 7-cm-diameter crystals of either germanium or silicon with a thin film of aluminum and tungsten patterned on the surface. This presentation discusses the testing regimen that a typical CDMS detector undergoes before it gets approval for final installation at the CDMS II deep side in Soudan, MN which should be coming online within a year. Now that our technology is relatively stable, the main focus of our test facilities is to provide quality control for the mass production of our detectors. First, the critical temperatures of the tungsten and other basic quantities are measured in preparation for iron implantation, which will bring the Tc down to the desired range (70 mK). The same basic measurements are taken again after implantation to assure that the correct Tc was achieved. Finally, a detailed map o...",2002-03-08,https://www.semanticscholar.org/paper/9ab4694ba1e55651ad31f21dc3f5a80c3cd0de7e,
2501,Quick viewpoint switching for manipulating virtual objects in hand-held augmented reality using stored snapshots,"Magic-lens style augmented reality applications allow users to control camera pose easily by manipulating a portable hand-held device and provide immediate visual feedback. However, strategic vantage points must often be revisited repeatedly, adding time and error and taxing memory. We describe a new approach that allows users to take snapshots of augmented scenes that can be virtually revisited at later times. The system stores still images of scenes along with camera poses, so that augmentations remain dynamic and interactive. Users can manipulate virtual objects while viewing snapshots, instead of moving to real-world views. We present a study comparing performance in snapshot and live mode conditions in a task in which a virtual object must be aligned with two pairs of physical objects. Proper alignment requires sequentially visiting two viewpoints. Participants completed the alignment task significantly faster and more accurately using snapshots than when using the live mode. Moreover, participants preferred manipulating virtual objects using snapshots to the live mode.",2012-11-05,https://www.semanticscholar.org/paper/d965f4444695383e12ecdcb319fffcca7145bd01,International Symposium on Mixed and Augmented Reality
1651,Detecting and Characterizing Events,"Significant events are characterized by interactions between entities (such as countries, organizations, or individuals) that deviate from typical interaction patterns. Analysts, including historians, political scientists, and journalists, commonly read large quantities of text to construct an accurate picture of when and where an event happened, who was involved, and in what ways. In this paper, we present the Capsule model for analyzing documents to detect and characterize events of potential significance. Specifically, we develop a model based on topic modeling that distinguishes between topics that describe “business as usual” and topics that deviate from these patterns. To demonstrate this model, we analyze a corpus of over two million U.S. State Department cables from the 1970s. We provide an open-source implementation of an inference algorithm for the model and a pipeline for exploring its results.",2016-11-01,https://www.semanticscholar.org/paper/56b874006900ade34feb39f1317ebbe6c0b0e1d2,Conference on Empirical Methods in Natural Language Processing
1798,Visualizing Topics with Multi-Word Expressions,"We describe a new method for visualizing topics, the distributions over terms that are automatically extracted from large text corpora using latent variable models. Our method finds significant $n$-grams related to a topic, which are then used to help understand and interpret the underlying distribution. Compared with the usual visualization, which simply lists the most probable topical terms, the multi-word expressions provide a better intuitive impression for what a topic is ""about."" Our approach is based on a language model of arbitrary length expressions, for which we develop a new methodology based on nested permutation tests to find significant phrases. We show that this method outperforms the more standard use of $\chi^2$ and likelihood ratio tests. We illustrate the topic presentations on corpora of scientific abstracts and news articles.",2009-07-06,https://www.semanticscholar.org/paper/2fe0a1994adeee963c895e20566c24eb7b25d516,
876,The input/output complexity of transitive closure,,1990-05-01,https://www.semanticscholar.org/paper/fbee9cc952cebd87aa46245435072fc5013febee,ACM SIGMOD Conference
2730,A history-based macro by example system,"Many tasks performed using computer interfaces are very repetitive. While programmers can write macros or procedures to automate these repetitive tasks, this requires special skills. Demonstrational systems make macro building accessible to all users, but most provide either no visual representation of the macro or only a textual representation. We have developed a history-based visual representation of commands in a graphical user interface. This representation supports the definition of macros by example in several novel ways. At any time, a user can open a history window, review the commands executed in a session, select operations to encapsulate into a macro, and choose objects and their attributes as arguments. The system has facilities to generalize the macro automatically, save it for future use, and edit it.",1992-12-01,https://www.semanticscholar.org/paper/c4e3c03568a88c1497a345a6df023a017f010ef2,ACM Symposium on User Interface Software and Technology
312,Interval scheduling: A survey,"In interval scheduling, not only the processing times of the jobs but also their starting times are given. This article surveys the area of interval scheduling and presents proofs of results that have been known within the community for some time. We first review the complexity and approximability of different variants of interval scheduling problems. Next, we motivate the relevance of interval scheduling problems by providing an overview of applications that have appeared in literature. Finally, we focus on algorithmic results for two important variants of interval scheduling problems. In one variant we deal with nonidentical machines: instead of each machine being continuously available, there is a given interval for each machine in which it is available. In another variant, the machines are continuously available but they are ordered, and each job has a given “maximal” machine on which it can be processed. We investigate the complexity of these problems and describe algorithms for their solution. © 2007 Wiley Periodicals, Inc. Naval Research Logistics, 2007",2007-08-01,https://www.semanticscholar.org/paper/bb0965663c8e7281cd5e074bbbb0835023387b86,
2592,Interacting with hidden content using content-aware free-space transparency,"We present <i>content-aware free-space transparency</i>, an approach to viewing and manipulating the otherwise hidden content of obscured windows through unimportant regions of overlapping windows. Traditional approaches to interacting with otherwise obscured content in a window system render an entire window uniformly transparent. In contrast, content-aware free-space transparency uses opaque-to-transparent gradients and image-processing filters to minimize the interference from overlapping material, based on properties of that material. By increasing the amount of simultaneously visible content and allowing basic interaction with otherwise obscured content, without modifying window geometry, we believe that free-space transparency has the potential to improve user productivity.",2004-10-24,https://www.semanticscholar.org/paper/18868cc02732042da589d0206322aab463f92dfa,ACM Symposium on User Interface Software and Technology
3278,Fusing enacted and expected mimicry generates a winning strategy that promotes the evolution of cooperation,"Although cooperation and trust are essential features for the development of prosperous populations, they also put cooperating individuals at risk for exploitation and abuse. Empirical and theoretical evidence suggests that the solution to the problem resides in the practice of mimicry and imitation, the expectation of opponent’s mimicry and the reliance on similarity indices. Here we fuse the principles of enacted and expected mimicry and condition their application on two similarity indices to produce a model of mimicry and relative similarity. Testing the model in computer simulations of behavioral niches, populated with agents that enact various strategies and learning algorithms, shows how mimicry and relative similarity outperforms all the opponent strategies it was tested against, pushes noncooperative opponents toward extinction, and promotes the development of cooperative populations. The proposed model sheds light on the evolution of cooperation and provides a blueprint for intentional induction of cooperation within and among populations. It is suggested that reducing conflict intensities among human populations necessitates (i) instigation of social initiatives that increase the perception of similarity among opponents and (ii) efficient lowering of the similarity threshold of the interaction, the minimal level of similarity that makes cooperation advisable.",2013-06-03,https://www.semanticscholar.org/paper/51bbb26244e0a7f18bb467f13700cd321723fb5f,Proceedings of the National Academy of Sciences of the United States of America
3364,On Being Socialized Out of the Human Sexual Response in the Later Years,,1978-11-01,https://www.semanticscholar.org/paper/8471a6d262a6fb6c90ad391336b709ccf8d57665,The Journal of Sociology &amp; Social Welfare
3465,Scheduling Algorithms,,2004-12-01,https://www.semanticscholar.org/paper/f78cab3af5b4a54135e8bb56de9acc7108753e41,Algorithms and Theory of Computation Handbook
3378,Scheduling with Speed Predictions,"Algorithms with predictions is a recent framework that has been used to overcome pessimistic worst-case bounds in incomplete information settings. In the context of scheduling, very recent work has leveraged machine-learned predictions to design algorithms that achieve improved approximation ratios in settings where the processing times of the jobs are initially unknown. In this paper, we study the speed-robust scheduling problem where the speeds of the machines, instead of the processing times of the jobs, are unknown and augment this problem with predictions. Our main result is an algorithm that achieves a $\min\{\eta^2(1+\alpha), (2 + 2/\alpha)\}$ approximation, for any $\alpha \in (0,1)$, where $\eta \geq 1$ is the prediction error. When the predictions are accurate, this approximation outperforms the best known approximation for speed-robust scheduling without predictions of $2-1/m$, where $m$ is the number of machines, while simultaneously maintaining a worst-case approximation of $2 + 2/\alpha$ even when the predictions are arbitrarily wrong. In addition, we obtain improved approximations for three special cases: equal job sizes, infinitesimal job sizes, and binary machine speeds. We also complement our algorithmic results with lower bounds. Finally, we empirically evaluate our algorithm against existing algorithms for speed-robust scheduling.",2022-05-02,https://www.semanticscholar.org/paper/2ec801cd4d3daf636dbbafd49bc100ee8781b95b,arXiv.org
183,The EATCS Award 2019 - Call for Nominations,,,https://www.semanticscholar.org/paper/c55dc19a0370d17c162fbd01bd0a2bd40e6bd716,Bull. EATCS
1309,Direct limits on the oscillation frequency.,"We report results of a study of the B(s)(0) oscillation frequency using a large sample of B(s)(0) semileptonic decays corresponding to approximately 1 fb(-1) of integrated luminosity collected by the D0 experiment at the Fermilab Tevatron Collider in 2002-2006. The amplitude method gives a lower limit on the B(s)(0) oscillation frequency at 14.8 ps(-1) at the 95% C.L. At delta m(s) = 19 ps(-1), the amplitude deviates from the hypothesis A= 0(1) by 2.5 (1.6) standard deviations, corresponding to a two-sided C.L. of 1% (10%). A likelihood scan over the oscillation frequency, delta m(s), gives a most probable value of 19 ps(-1) and a range of 17 < delta m(s) < 21 ps(-1)at the 90% C.L., assuming Gaussian uncertainties. This is the first direct two-sided bound measured by a single experiment. If delta m(s) lies above 22 ps(-1), then the probability that it would produce a likelihood minimum similar to the one observed in the interval 16-22 ps(-1) is (5.0 +/- 0.3)%.",,https://www.semanticscholar.org/paper/397552f21719e92a0152bf540bc19e45c6a1ec8d,Physical Review Letters
1273,Search for Randall-Sundrum gravitons with 1 fb(-1) of data from pp collisions at sqrt(s)=1.96 TeV.,"We search for decays of Kaluza-Klein excitations of the graviton in the Randall-Sundrum model of extra dimensions to e+ e(-) and gamma gamma in 1 fb(-1) of pp collisions at sqrt(s)=1.96 TeV collected by the D0 detector at the Fermilab Tevatron. We set 95% confidence level upper limits on the production cross section times branching fraction, which translate into lower limits on the mass of the lightest excitation between 300 and 900 GeV for values of the coupling k/MPl between 0.01 and 0.1.",2007-10-17,https://www.semanticscholar.org/paper/35137ab8edfe693010c440dd2fd6101f5c096f7d,Physical Review Letters
1718,Hierarchical Regression,"There isn’t a single authorative definition of a hierarchical model. Gelman et al. (1995) discuss two definitions: 1. “Estimating the population distribution of unonobserved parameters” 2. “Multiple parameters related by the structure of the problem” Intuitively, knowing something about one “experiment” tells us something about another. For example: Multiple similar experiments Similar measurements from different locations Several tasks to perform on the same set of images We’ve seen the last case when we talked about mixed-membership models. These are one type of hierarchical model. When talking about hierarchical models, statiticians sometimes use the phrase “sharing statistical strength.” The idea is that something we can infer well in one group of data can help us with something we cannot infer well in another. For example, we may have a lot of data from California but much less data from Oregon. What we learn from California should help us learn in Oregon. The key idea is: Inference about one unobserved quantity affects inference about another unobserved quantity.",,https://www.semanticscholar.org/paper/d78ebd47d60675b89853bd362051e4d9b1ca09ee,
2735,Dynamic 3D illustrations with visibility constraints,,1991-03-01,https://www.semanticscholar.org/paper/1b18e627b009ebc9c71fcab5417b6e61c058db17,
1262,Measurement of B 0 s Mixing Parameters from the Flavor-Tagged Decay B 0 s ! J,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, S. H. Ahn, M. Ahsan, G.D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G.A. Alves, M. Anastasoaie, L. S. Ancu, T. Andeen, S. Anderson, B. Andrieu, M. S. Anzelc, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, A. C. S. Assis Jesus, O. Atramentov, C. Autermann, C. Avila, C. Ay, F. Badaud, A. Baden, L. Bagby, B. Baldin, D.V. Bandurin, P. Banerjee, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, C. Biscarat, G. Blazey, F. Blekman, S. Blessing, D. Bloch, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, S. Burke, T. H. Burnett, C. P. Buszello, J.M. Butler, P. Calfayan, S. Calvet, J. Cammin, W. Carvalho, B. C. K. Casey, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K. Chan, K.M. Chan, A. Chandra, F. Charles,** E. Cheu, F. Chevallier, D. K. Cho, S. Choi, B. Choudhary, L. Christofek, T. Christoudias, S. Cihangir, D. Claes, Y. Coadou, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, D. Cutts, M. Ćwiok, H. da Motta, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, J. D. Degenhardt, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, H. Dong, L. V. Dudko, L. Duflot, S. R. Dugad, D. Duggan, A. Duperrin, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V. D. Elvira, Y. Enari, S. Eno, P. Ermolov, H. Evans, A. Evdokimov, V.N. Evdokimov, A.V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Ford, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, E. Gallas, C. Garcia, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, D. Gelé, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, N. Gollub, B. Gómez, A. Goussiou, P. D. Grannis, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Harder, A. Harel, R. Harrington, J.M. Hauptman, R. Hauser, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, J.M. Heinmiller, A. P. Heinson, U. Heintz, C. Hensel, K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, J. D. Hobbs, B. Hoeneisen, H. Hoeth, M. Hohlfeld, S. J. Hong, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, C. Jarvis, R. Jesik, K. Johns, C. Johnson, M. Johnson, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, A.M. Kalinin, J.M. Kalk, S. Kappler, D. Karmanov, P. A. Kasper, I. Katsanos, D. Kau, R. Kaur, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y.M. Kharzheev, D. Khatidze, T. J. Kim, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, J.-P. Konrath, V.M. Korablev, A. V. Kozelov, J. Kraus, D. Krop, T. Kuhl, A. Kumar, A. Kupco, T. Kurča, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, W.M. Lee, A. Leflat, J. Lellouch, J. Leveque, J. Li, L. Li, Q. Z. Li, S.M. Lietti, J. G. R. Lima, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna, A. L. Lyon, A. K.A. Maciel, D. Mackin, R. J. Madaras, P. Mättig, C. Magass, A. Magerkurth, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, H. S. Mao, Y. Maravin, B. Martin, R. McCarthy, A. Melnitchouk, L. Mendoza, P. G. Mercadante, M. Merkin, K.W. Merritt, A. Meyer, J. Meyer,22,x T. Millet, J. Mitrevski, J. Molina, R. K. Mommsen, N.K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulders, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, N. A. Naumann, H.A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, V. O’Dell, D. C. O’Neil, G. Obrant, C. Ochando, D. Onoprienko, N. Oshima, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park, S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, M. Petteni, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma, V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, B.G. Pope, A.V. Popov, C. Potter, W. L. Prado da Silva, H. B. Prosper, S. Protopopescu, J. Qian, A. Quadt,22,x B. Quinn, A. Rakitine, PRL 101, 241801 (2008) P HY S I CA L R EV I EW LE T T E R S week ending 12 DECEMBER 2008",,https://www.semanticscholar.org/paper/dd19bcaf8a100e7a55d1e45a5f0ebc654a765f00,
3220,Knowledgeable Lemurs Be come More Central in Social Networks Highlights,,,https://www.semanticscholar.org/paper/1bf7b71399342376df1f39e49d8c8cb67f6920a0,
409,PROBLEM SET #3,"1. Figure PS3.1-1 presents a 2μm-thick polysilicon film atop a 2μm-thick sacrificial oxide film. The polysilicon beam is initially uniformly doped with phosphorous to a concentration ND = 1 × 10cm. Suppose you want to make the beam more conductive by diffusing boron atoms into the n-type polysilicon material. To do so, you first place the wafer into a predeposition furnace alongside solid-source boron wafers for 30min at 1000C. You then cap the film with an undoped oxide and drive in the dopants (with no boron source) for 60min at the same temperature. [Assume for this problem that the diffusion coefficient Do of polysilicon is 10 times larger than that of single crystal silicon (SCS). Also, assume that the solid-solubility limit and electrically active concentration limits, as well as carrier mobility of polysilicon, are the same as SCS. Some of this is not entirely true, but it makes the problem more tractable.]",,https://www.semanticscholar.org/paper/89afe93ef1428f38017f359daab43a8c49c4029e,
3133,Group Ratio Round-Robin: An O(1) Proportional Share Scheduler,"Proportional share resource management provides a flexible and useful abstraction for multiplexing time-shared resources. We present Group Ratio Round-Robin (GR), a proportional share scheduler that combines accurate proportional fairness scheduling behavior with O(1) scheduling overhead. GR uses a novel client grouping strategy to organize clients into groups of similar processor allocations which can be more easily scheduled. Using this grouping strategy, GR combines the benefits of low overhead round-robin execution with a novel ratio-based scheduling algorithm. We analyze the behavior of GR and show that it can provide fairness within a constant factor of the ideal generalized processor sharing model for client weights with a fixed upper bound. GR can be easily implemented using simple data structures. We have implemented GR in Linux and measured its performance against other schedulers commonly used in research and practice, including the standard Linux scheduler, Weighted Fair Queueing, Virtual-Time Round-Robin, and Smoothed Round-Robin. Our experimental results demonstrate that GR can provide much lower scheduling overhead and much better scheduling accuracy in practice than these other approaches.",,https://www.semanticscholar.org/paper/8b4a9d18780900a420ff432761e8880cc6a7da13,
3467,"Existence theorems, lower bounds and algorithms for scheduling to meet two objectives","We give general results about the existence of schedules which simultaneously minimize two criteria. Our results are general in that (i) they apply to any scheduling environment and (ii) they apply to all pairs of metrics in which the first metric is one of maximum flow time, makespan, or maximum lateness and the second metric is one of average flow time, average completion time, average lateness, or number of on-time jobs. For most of the pairs of metrics we consider, we show the existence of near-optimal schedules for both metrics as well as some lower bound results. For some pairs of metrics such as (maximum flow time, average weighted flow time) and (maximum flow time, number of on-time jobs), we prove negative results on the ability to approximate both criteria within a constant factor of optimal. For many other criteria we present lower bounds that match or approach our bicriterion existence results.",2002-01-06,https://www.semanticscholar.org/paper/2ee853778d42ee7e14f89fc776a4fe581596f9e2,ACM-SIAM Symposium on Discrete Algorithms
3020,AnDrone: Virtual Drone Computing in the Cloud,"With the continued proliferation of drones, unmanned aerial vehicles, additional uses for them are growing and the demand for their services is on the rise. We present AnDrone, a drone-as-a-service solution that makes drones accessible in the cloud. AnDrone pairs a cloud service with the first drone virtualization architecture. This enables a physical drone to run multiple virtual drones simultaneously in an isolated and secure manner at little additional cost, as computational costs are cheap compared to the operational and energy costs of putting a drone in the air. AnDrone virtualizes drones using a novel Linux container architecture. Android Things virtual drone containers provide a familiar user and development environment that can run existing Android apps. A real-time Linux flight controller container supports existing drone flight software and provides virtual drones with geofenced flight control. A device container transparently multiplexes access from virtual drones to a full range of drone hardware devices, including cameras and other sensors. Upon flight completion, virtual drones and their data can be uploaded to the cloud for offline access. We have implemented an AnDrone prototype based on Raspberry Pi 3 drone hardware. We demonstrate that it incurs minimal runtime performance and energy overhead, supports real-time virtual drone flight control, and runs untrusted third-party software in virtual drones in a secure manner while ensuring that the service provider maintains control of the drone hardware.",2019-03-25,https://www.semanticscholar.org/paper/736801135400eceded045b64b356fa038fa4a89c,European Conference on Computer Systems
3429,Proceedings of 9th Workshop on Models and Algorithms for Planning and Scheduling Problems,,,https://www.semanticscholar.org/paper/4a4a4aefb65d88c2b77f39b0f658dc6bf9f7acc2,
1069,Projected WIMP sensitivity of the LUX-ZEPLIN dark matter experiment,"Author(s): Akerib, DS; Akerlof, CW; Alsum, SK; Araujo, HM; Arthurs, M; Bai, X; Bailey, AJ; Balajthy, J; Balashov, S; Bauer, D; Belle, J; Beltrame, P; Benson, T; Bernard, EP; Biesiadzinski, TP; Boast, KE; Boxer, B; Bras, P; Buckley, JH; Bugaev, VV; Burdin, S; Busenitz, JK; Carels, C; Carlsmith, DL; Carlson, B; Carmona-Benitez, MC; Chan, C; Cherwinka, JJ; Cole, A; Cottle, A; Craddock, WW; Currie, A; Cutter, JE; Dahl, CE; De Viveiros, L; Dobi, A; Dobson, JEY; Druszkiewicz, E; Edberg, TK; Edwards, WR; Fan, A; Fayer, S; Fiorucci, S; Fruth, T; Gaitskell, RJ; Genovesi, J; Ghag, C; Gilchriese, MGD; Van Der Grinten, MGD; Hall, CR; Hans, S; Hanzel, K; Haselschwardt, SJ; Hertel, SA; Hillbrand, S; Hjemfelt, C; Hoff, MD; Hor, JYK; Huang, DQ; Ignarra, CM; Ji, W; Kaboth, AC; Kamdin, K; Keefner, J; Khaitan, D; Khazov, A; Kim, YD; Kocher, CD; Korolkova, EV; Kraus, H; Krebs, HJ; Kreczko, L; Krikler, B; Kudryavtsev, VA; Kyre, S; Lee, J; Lenardo, BG; Leonard, DS; Lesko, KT; Levy, C; Li, J; Liao, J; Liao, FT; Lin, J; Lindote, A | Abstract: © 2020 American Physical Society. LUX-ZEPLIN (LZ) is a next-generation dark matter direct detection experiment that will operate 4850 feet underground at the Sanford Underground Research Facility (SURF) in Lead, South Dakota, USA. Using a two-phase xenon detector with an active mass of 7 tonnes, LZ will search primarily for low-energy interactions with weakly interacting massive particles (WIMPs), which are hypothesized to make up the dark matter in our galactic halo. In this paper, the projected WIMP sensitivity of LZ is presented based on the latest background estimates and simulations of the detector. For a 1000 live day run using a 5.6-tonne fiducial mass, LZ is projected to exclude at 90% confidence level spin-independent WIMP-nucleon cross sections above 1.4×10-48 cm2 for a 40 GeV/c2 mass WIMP. Additionally, a 5σ discovery potential is projected, reaching cross sections below the exclusion limits of recent experiments. For spin-dependent WIMP-neutron(-proton) scattering, a sensitivity of 2.3×10-43 cm2 (7.1×10-42 cm2) for a 40 GeV/c2 mass WIMP is expected. With underground installation well underway, LZ is on track for commissioning at SURF in 2020.",2018-02-16,https://www.semanticscholar.org/paper/1ea18173154ea7876c2166f4143d0ff7e16a181f,Physical Review D
236,Optimum Statistical Estimation with Strategic Data Sources,"We propose an optimum mechanism for providing monetary incentives to the data sources of a statistical estimator such as linear regression, so that high quality data is provided at low cost, in the sense that the sum of payments and estimation error is minimized. The mechanism applies to a broad range of estimators, including linear and polynomial regression, kernel regression, and, under some additional assumptions, ridge regression. It also generalizes to several objectives, including minimizing estimation error subject to budget constraints. Besides our concrete results for regression problems, we contribute a mechanism design framework through which to design and analyze statistical estimators whose examples are supplied by workers with cost for labeling said examples.",2014-08-11,https://www.semanticscholar.org/paper/c7e3a344cacf01214382ec7c16edcf18a634c9c3,Annual Conference Computational Learning Theory
184,About Place Cells and Grid Cells - About Place Cells and Grid Cells,,,https://www.semanticscholar.org/paper/c96650186b5f28b975d67d6e72ffa32140193cd5,Adventures Between Lower Bounds and Higher Altitudes
2710,Research frontiers in virtual reality,"The emergence of teleoperation and virtual environments has greatly increased interest in ""synthetic experience"", a mode of experience made possible by both these newer technologies and earlier ones, such as telecbrnmunicarion and sensory prosthetics. I maintain that understanding synthetic experience must begin by recognizing the fallacy of naive realism and with the recognition that the phenomenology of synthetic experience is conrinuous with that of ordinary experience. I demonstrate the continuity of synrhetic experience and normal perceptual experience with respect to two issues: the determination of' a person's phenomenal location in space and the experience of ""being in touch with"" near and remote objects. The emergence of teleoperation and virtual environments has greatly increased interest in ""synthetic experience"" [I], those forms of experience which are made possible both by these newer technologies and by earlier ones, such as telecommunication and sensory prosthetics. Recently, a number of authors have offered a variety of taxonomies and conceptual schemes for thinking about the experiential states associated with synthetic experience (e.g., presence. externalization) and the properties of the effectoridisplay arrangement that promote various degrees of perceptual realism [I, 2-91. Here I assert that an understanding of synthetic experience must begin by acknowledging that the phenomenology of synthetic experience is continuous with that of ordinary experience. In previous articles [6, 71, I have argued that in seeking to understand the phenomenology associated with the use of teleoperators and virtual environments, we must recognize the fallacy of naive realism. the unreflective view that the world we experience around us is one and the same as the ""physical world."" Vision, for example. is experienced as a transaction between observer and environment in which the eyes are mere windows on the physical world. This view fails to recognize that ordinary experience is mediate-that what we experience is an elaborate construction of o w senses and nervous system that is so highly functional a representation of the surrounding environment that we unsuspectingly act upon the former as if it were the latter. In its place, we need to substitute a form of representative realism that makes the distinction between the phenomenal world. that of which we are directly aware, and the physical world. that which underlies our phenomenal awareness but can only be known through inference. Among the facts that demand this alternate view is the mchromacy of human color vision-while color is part of the very fabric of the …",1994-07-24,https://www.semanticscholar.org/paper/fe4df9c4d855a94f0458e315298f60e2163fcac9,International Conference on Computer Graphics and Interactive Techniques
1025,Kinematic Cartography and the Efficiency of Viscous Swimming,"The apparent “distance” between two configurations of a system and the “length” of trajectories through its configuration space can be significantly distorted by plots that use “natural” or intuitively selected coordinates. This effect is similar to the way that a latitude–longitude plot of the Earth distorts the size and shape of the continents. In this paper, we explore how ideas from cartography can be used to identify system parameterizations that better reflect the effort costs of changing configuration. We then apply these new parameters to provide geometric insight about two aspects of moving in dissipative environments such as low Reynolds number fluids: The shape of the optimal gait cycle for a three-link swimmer and the fundamentally superior efficiency of a serpenoid swimmer as compared to the classic three-link system.",2017-02-20,https://www.semanticscholar.org/paper/0292514b7d432eb14af33a6e5673c3b6aaf1a07b,IEEE Transactions on robotics
3642,A history of C++: 1979–1991,"This paper outlines the history of the C++ programming language. The emphasis is on the ideas, constraints, and people that shaped the language, rather than the minuitiae of language features. Key design decisions relating to language features are discussed, but the focus is on the overall design goals and practical constraints. The evolution of C++ is traced from C with Classes to the current ANSI and ISO standards work and the explosion of use, interest, commercial activity, compilers, tools, environments, and libraries.",1993-03-01,https://www.semanticscholar.org/paper/e94286ad503414eb85fecd8164264ee2a0b7927e,HOPL-II
2125,A framework of modularized heuristics for determining the container loading patterns,,1999-10-01,https://www.semanticscholar.org/paper/f13a339edf1081278afc93a1bc965ec3d14b2d13,
523,Corrigendum: The Complexity of Cubical Graphs,,,https://www.semanticscholar.org/paper/0c24781a67680874a3d0cdd51e0328acbef30aed,Information and Computation
2155,Balls and bins models with feedback,"We examine generalizations of the classical balls and bins models, where the probability a ball lands in a bin is proportional to the number of balls already in the bin raised to some exponent p. Such systems exhibit positive or negative feedback, depending on the exponent p, with a phase transition occurring at p = 1. Similar models have proven useful in economics and chemistry; for example, systems with positive feedback (p > 1) tend naturally toward monopoly. We provide several results and useful heuristics for these models, including showing a bound on the time to achieve monopoly with high probability.",2002-01-06,https://www.semanticscholar.org/paper/e305e18a2f42bbe01aabc44392e93b86191723df,ACM-SIAM Symposium on Discrete Algorithms
1771,Probabilistic topic models,"Probabilistic topic modeling provides a suite of tools for the unsupervised analysis of large collections of documents. Topic modeling algorithms can uncover the underlying themes of a collection and decompose its documents according to those themes. This analysis can be used for corpus exploration, document search, and a variety of prediction problems.
 In this tutorial, I will review the state-of-the-art in probabilistic topic models. I will describe the three components of topic modeling:
 (1) Topic modeling assumptions
 (2) Algorithms for computing with topic models
 (3) Applications of topic models
 In (1), I will describe latent Dirichlet allocation (LDA), which is one of the simplest topic models, and then describe a variety of ways that we can build on it. These include dynamic topic models, correlated topic models, supervised topic models, author-topic models, bursty topic models, Bayesian nonparametric topic models, and others. I will also discuss some of the fundamental statistical ideas that are used in building topic models, such as distributions on the simplex, hierarchical Bayesian modeling, and models of mixed-membership.
 In (2), I will review how we compute with topic models. I will describe approximate posterior inference for directed graphical models using both sampling and variational inference, and I will discuss the practical issues and pitfalls in developing these algorithms for topic models. Finally, I will describe some of our most recent work on building algorithms that can scale to millions of documents and documents arriving in a stream.
 In (3), I will discuss applications of topic models. These include applications to images, music, social networks, and other data in which we hope to uncover hidden patterns. I will describe some of our recent work on adapting topic modeling algorithms to collaborative filtering, legislative modeling, and bibliometrics without citations.
 Finally, I will discuss some future directions and open research problems in topic models.",2011-08-21,https://www.semanticscholar.org/paper/87f553e5b5cd1f1cc833cb28235889ee8c08be36,KDD '11 Tutorials
326,Hide-and-Seek,,,https://www.semanticscholar.org/paper/1336fda61e7814f2450d83a1b86ed9131e690976,
3665,An overview of C++,"C++ is a general purpose programming language3 designed to make programming more enjoyable for the serious programmer. Except for minor details, C++ is a superset of the C language*. C++ was designed to [l] be a better C. [2] support data abstraction. [3] support object-oriented programming. This paper describes the features added to C to achieve this. In addition to C, the main influences of the design of C++ were Simula67’ and Algo1684. C++ has been in use for about four years and has been applied to mpst branches of systems programming including compiler construction, data base management, graphics, image processing, music synthesis, networking, numerical software, programming environments, robotics, simulation, and switching. It has a highly portable implementation and there are now at least 1500 installations including AT&T 3B, DEC VAX, Intel 80286, Motorola 68000, and Amdahl machines running UNlXt and other operating systems*.",1986-10-01,https://www.semanticscholar.org/paper/e264da9ced2871d28806b331876c91f76e59f97d,OOPWORK '86
207,Optimizing the diamond lane: A more tractable carpool problem and algorithms,"Carpooling has been long deemed a promising approach to better utilizing existing transportation infrastructure. However, there are several reasons carpooling is still not the preferred mode of commute in the United States: first, complex human factors, including time constraints and not having right incentive structures, discourage the sharing of rides; second, algorithmic and technical barriers inhibit the development of online services for matching riders. In this work, we study algorithms for 3+ high-occupancy vehicle (HOV) lanes, which permit vehicles that hold three or more people. We focus on the technical barriers but also address the aforementioned human factors. We formulate the HOV3 Carpool problem, and show that it is NP-Complete. We thus pose the relaxed problem HOV3- Carpool problem, allowing groups of up to size three, and propose several methods for solving the problem of finding globally optimal carpool groups that may utilize these 3- HOV lanes. Our methods include local search, integer programming, and dynamic programming. Our local search methods include sampling-based (hill-climbing and simulated annealing), classical neighborhood search, and a hybrid random neighborhood search. We assess the methods numerically in terms of objective value and scalability. Our findings show that our sampling-based local search methods scale up to 100K agents, thereby improving upon related previous work (which studies up to 1000 agents). The hill climbing local search method converges significantly closer and faster towards a naive lower bound on cumulative carpooling cost.",2016-11-01,https://www.semanticscholar.org/paper/a8103c9129b3f23085ab4bf6818f97ff74cf7fae,2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)
1856,Sharing Clusters among Related Groups: Hierarchical Dirichlet Processes,"We propose the hierarchical Dirichlet process (HDP), a nonparametric Bayesian model for clustering problems involving multiple groups of data. Each group of data is modeled with a mixture, with the number of components being open-ended and inferred automatically by the model. Further, components can be shared across groups, allowing dependencies across groups to be modeled effectively as well as conferring generalization to new groups. Such grouped clustering problems occur often in practice, e.g. in the problem of topic discovery in document corpora. We report experimental results on three text corpora showing the effective and superior performance of the HDP over previous models.",2004-12-01,https://www.semanticscholar.org/paper/adcec120a442af0d58f7a1d2dc175b58ff5a32e2,Neural Information Processing Systems
3411,Experimental Analysis of Algorithms for Coflow Scheduling,,2016-03-25,https://www.semanticscholar.org/paper/a1c78027e41b73b0c38f3578a9dfae323c25cbeb,The Sea
3774,HOGgles: Visualizing Object Detection Features,"We introduce algorithms to visualize feature spaces used by object detectors. The tools in this paper allow a human to put on 'HOG goggles' and perceive the visual world as a HOG based object detector sees it. We found that these visualizations allow us to analyze object detection systems in new ways and gain new insight into the detector's failures. For example, when we visualize the features for high scoring false alarms, we discovered that, although they are clearly wrong in image space, they do look deceptively similar to true positives in feature space. This result suggests that many of these false alarms are caused by our choice of feature space, and indicates that creating a better learning algorithm or building bigger datasets is unlikely to correct these errors. By visualizing feature spaces, we can gain a more intuitive understanding of our detection systems.",2013-12-01,https://www.semanticscholar.org/paper/854994253119aa3dbae827a42ca3a6d91d46f215,IEEE International Conference on Computer Vision
1973,Hybrid estimation of distribution algorithm with multiple subpopulations for semiconductor manufacturing scheduling problem with limited waiting-time constraint,"This paper considers a semiconductor manufacturing scheduling problem (SMSP), subjected to all the practical constraints such as limited waiting time, machine status, different process time on different machines, setup time and arrival time in wafer fabrication facilities (fabs) of semiconductor manufacturing industry. A hybrid estimation of distribution algorithm with multiple subpopulations (HEDA-MS) is proposed to solve SMSP effectively within several specified minutes for an online scheduling requirement. An empirical study simulates eight scenarios from practical data to compare the performance of HEDA-MS and GA, not only to minimize the makespan, but to make total exceeded of limited waiting time into zero. For all the scenarios, the proposed HEDA-MS obtains a smaller makespan than GA with less total exceeded limited waiting time.",2014-10-30,https://www.semanticscholar.org/paper/fc75b55760ce5a1328834a1af67f28da149c81aa,2014 IEEE International Conference on Automation Science and Engineering (CASE)
3060,VMtorrent: virtual appliances on-demand,"Virtual Appliances (VAs) are Virtual Machines (VMs) geared towards a specific set of tasks. They require little or no configuration, working out-of-the-box. VAs fit neatly into the Cloud Computing paradigm - many copies of an identical machine can be launched in a data center, or home/business users can grab the appliance they need from the cloud to run locally just for so long as required. Companies and projects whose sole offerings are VAs ready for either desktop or data center use [3, 11] attest to the growing popularity of VAs. VMware's Appliance directory alone currently lists over 1400 VAs available for the VMware family of Virtual Machine Monitors (VMMs) [13].
 Current VA distribution generally requires download of the complete virtual disk image, only after which the VA can be run. Given that compressed VA sizes run anywhere from several hundred MB to a few GB, there can be significant delays from the time a user decides he/she wants to run a particular VA until the time that VA can be used. These problems are only exacerbated when demand for particular VAs spikes and server bandwidth resources become the distribution bottleneck.",2010-08-16,https://www.semanticscholar.org/paper/738018d8ebb9fa875bd3b5575e19a080d71a24fd,"Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication"
408,The Daniel H. Wagner Prize for Excellence in Operations Research Practice,,1999-05-01,https://www.semanticscholar.org/paper/877c4340f9825d2ab73e0e4bd75a87a8156a3c76,
1016,Pertussis toxin lesioning of the nucleus caudate-putamen attenuates adenylate cyclase inhibition and alters neuronal electrophysiological activity,,1989-08-21,https://www.semanticscholar.org/paper/00fad007255b3c960f1e29cc6a23a190ef6f7bdb,Brain Research
384,On Approximating a Scheduling Problem,,,https://www.semanticscholar.org/paper/4b5e7737ab3707bdf2655065c3b11c72358a3873,Journal of combinatorial optimization
1395,Search for the production of single sleptons through R-parity violation in pp; collisions at square root (s) =1.8 TeV.,"We report the first search for supersymmetric particles via s-channel production and decay of smuons or muon sneutrinos at hadronic colliders. The data for the two-muon and two-jets final states were collected by the D0 experiment and correspond to an integrated luminosity of 94+/-5 pb(-1). Assuming that R parity is violated via the single coupling lambda'211, the number of candidate events is in agreement with expectation from the standard model. Exclusion contours are given in the (m(0),m(1/2)) and (m(x),m(v)) planes for lambda(')(211)=0.09, 0.08, and 0.07.",,https://www.semanticscholar.org/paper/95d27ae37d1ebc1b813f2d53ab8d02ccaf1ebc80,Physical Review Letters
3706,Forget-me-not! Contrastive Critics for Mitigating Posterior Collapse,"Variational autoencoders (VAEs) suffer from posterior collapse, where the powerful neural networks used for modeling and inference optimize the objective without meaningfully using the latent representation. We introduce inference critics that detect and incentivize against posterior collapse by requiring correspondence between latent variables and the observations. By connecting the critic's objective to the literature in self-supervised contrastive representation learning, we show both theoretically and empirically that optimizing inference critics increases the mutual information between observations and latents, mitigating posterior collapse. This approach is straightforward to implement and requires significantly less training time than prior methods, yet obtains competitive results on three established datasets. Overall, the approach lays the foundation to bridge the previously disconnected frameworks of contrastive learning and probabilistic modeling with variational autoencoders, underscoring the benefits both communities may find at their intersection.",2022-07-19,https://www.semanticscholar.org/paper/f354354d32e820ce55f26f2cb6508599df8cc698,Conference on Uncertainty in Artificial Intelligence
3718,Learning Goals from Failure,"We introduce a framework that predicts the goals behind observable human action in video. Motivated by evidence in developmental psychology, we leverage video of unintentional action to learn video representations of goals without direct supervision. Our approach models videos as contextual trajectories that represent both low-level motion and high-level action features. Experiments and visualizations show our trained model is able to predict the underlying goals in video of unintentional action. We also propose a method to ""automatically correct"" unintentional action by leveraging gradient signals of our model to adjust latent trajectories. Although the model is trained with minimal supervision, it is competitive with or outperforms baselines trained on large (supervised) datasets of successfully executed goals, showing that observing unintentional action is crucial to learning about goals in video.",2020-12-16,https://www.semanticscholar.org/paper/1193fc121f9be24a5da562745dd3a07a1e1a7269,Computer Vision and Pattern Recognition
932,Equivalences Among Relational Expressions with the Union and Difference Operators,"Queries in relational databases can be formulated in terms of relational expressions using the relational operations select, project, join, union, and difference The equivalence problem for these queries is studied with query optimization m mind It ts shown that testmg eqmvalence of relational expressions with the operators select, project, join, and union is complete m the class FIt of the polynomial-time hierarchy A nonprocedural representation for queries formulated by these expressions is proposed This method of query representation can be viewed as a generahzatlon of tableaux or conjunctive queries (which are used to represent expressions with only select, project, and join) Furthermore, this method is extended to queries formulated by relatmnal expressions that also contain the difference operator, provided that the project operator is not applied to subexpresstons with the difference operator A procedure for testing eqmvalence of these queries is given It ts shown that testmg containment of tableaux is a necessary step in testing equivalence of queries with union and difference Three important cases m which containment of tableaux can be tested m polynomial time are described, although the containment problem is shown to be NP-complete even for tableaux that correspond to expressions with only one project and several join operators",1980-10-01,https://www.semanticscholar.org/paper/4e60a72a0b58f62b405ab5eb43b184f5fff77710,Journal of the ACM
2274,Microbial mannan suppresses neutrophil and monocyte respiratory burst and enhances myeloperoxidase release: Possible mechanisms for granulomatous inflammation in Crohn's disease,,,https://www.semanticscholar.org/paper/d0aa35e2e3577b1ae19f99c793e93b0254fd8ce6,
761,Explorer Recursive Concurrent Stochastic Games,"We study Recursive Concurrent Stochastic Games (RCSGs), extending our recent analysis of recursive simple stochastic games [16, 17] to a concurrent setting where the two players choose moves simultaneously and independently at each state. For multi-exit games, our earlier work already showed undecidability for basic questions like termination, thus we focus on the important case of single-exit RCSGs (1-RCSGs). We first characterize the value of a 1-RCSG termination game as the least fixed point solution of a system of nonlinear minimax functional equations, and use it to show PSPACE decidability for the quantitative termination problem. We then give a strategy improvement technique, which we use to show that player 1 (maximizer) has -optimal randomized Stackless & Memoryless (r-SM) strategies for all > 0, while player 2 (minimizer) has optimal r-SM strategies. Thus, such games are r-SM-determined. These results mirror and generalize in a strong sense the randomized memoryless determinacy results for finite stochastic games, and extend the classic Hoffman-Karp [22] strategy improvement approach from the finite to an infinite state setting. The proofs in our infinite-state setting are very different however, relying on subtle analytic properties of certain power series that arise from studying 1-RCSGs. We show that our upper bounds, even for qualitative (probability 1) termination, can not be improved, even to NP, without a major breakthrough, by giving two reductions: first a P-time reduction from the long-standing square-root sum problem to the quantitative termination decision problem for finite concurrent stochastic games, and then a P-time reduction from the latter problem to the qualitative termination problem for 1-RCSGs.",,https://www.semanticscholar.org/paper/03a10ca93b61b49649e9b2a179f4fa31202adbe3,
2367,Myeloperoxidase secretion during phagocytosis: a case of a patient with impaired bactericidal activity.,"We describe a case of a 5-year-old male patient with prolonged and extensive osteomyelitis of the left femur. Staphylococcus aureus was grown from blood cultures taken upon admission and also from pus drained from an incised hip joint. A defect in immune function was suspected and neutrophil function was assessed. Chemotaxis and phagocytosis were normal, but phagocytosed S. aureus were not killed as efficiently as in control neutrophils. No inherent defect in the ability of these neutrophils to generate reactive oxidants was observed, but an unusual luminol-dependent chemiluminescence response was obtained during phagocytosis of latex beads or opsonized S. aureus: This was characterized by an initial rapid, but transient increase occurring within 1 min of addition of phagocytic stimulus. Whereas during phagocytosis of latex beads by control neutrophils less than 1% of the total myeloperoxidase activity was detected extracellularly, up to 15% was released from the patient's neutrophils. We propose that release of myeloperoxidase from the patient's neutrophils during phagocytosis reduces the intraphagosomal concentration of this enzyme and thus impairs the efficiency of intracellular killing of S. aureus.",1988-10-01,https://www.semanticscholar.org/paper/fbd28b87aad15f7c32baa1f08c378483b4164b9f,Journal of clinical & laboratory immunology
2210,The protective effect of GM-CSF on serum-induced neutrophil apoptosis in juvenile systemic lupus erythematosus patients,,,https://www.semanticscholar.org/paper/a4c621a2ec807d12a2948c704b92a987f5dfae4e,Clinical Rheumatology
2398,Carbon monoxide-reacting haemoproteins in the mitochondrial fraction of Acanthamoeba castellanii.,"1. Room-temperature (18 degrees C) CO difference spectra of mitochondrial fractions from the amoeba Acanthamoeba castellanii reveal the presence of at least four CO-reacting haemoproteins. As well as cytochrome a3, other components reacting with CO are: (i) a c-type cytochrome; (ii) a b-type cytochrome; and (iii) another a-type cytochrome. 2. The same components can be identified in low-temperature photodissociation experiments with intact cells or mitochondria. 3. The time of exposure to CO and the nature of the reductant are both important in identifying all the components present, in that the b-type cytochrome is more readily distinguished after longer exposure to CO and more of the c-type cytochrome is detectable when NADH is the reductant 4. Treatment of mitochondria with ultrasound releases two components, identifiable in low-temperature difference spectra as a c-type and a b-type cytochrome; only the latter appears to have any reaction with CO, and the CO-reacting c-type cytochrome is retained in submitochondrial particles. 5. The complexity of the CO-reacting haemoproteins in this organism is compared with the simpler systems found in other eukaryotic organisms.",1980-03-15,https://www.semanticscholar.org/paper/843244fef0dcfb9d93ec66303dd3d234ae462ddd,Biochemical Journal
2163,Persistent advanced periductal fibrosis is associated with cagA‐positive Helicobacter pylori infection in post‐praziquantel treatment of opisthorchiasis,"Liver fluke infection caused by Opisthorchis viverrini is associated with several hepatobiliary diseases including advanced periductal fibrosis (APF) and cholangiocarcinoma. Recently, we demonstrated a persistent APF in over one‐third of opisthorchiasis patients after worm removal by praziquantel (PZQ) treatment. However, the underlying mechanism(s) of this phenomena is unclear. Given a co‐infection with Helicobacter pylori (H. pylori) especially cagA‐positive strain enhances APF, we hypothesized that H. pylori with CagA virulent factor contributes to persistent APF.",2022-05-09,https://www.semanticscholar.org/paper/91d88975e18941564cc8a529c9ffa6d21c57030f,Helicobacter
731,"A Note on the Complexity of Comparing Succinctly Represented Integers, with an Application to Maximum Probability Parsing","The following two decision problems capture the complexity of comparing integers or rationals that are succinctly represented in product-of-exponentials notation, or equivalently, via arithmetic circuits using only multiplication and division gates, and integer inputs. <i>Input instance:</i> Four lists of positive integers:
 <i>a</i>1,..., <i>an</i>∈N+<i>n</i>; <i>b</i>1,...,<i>bn</i>∈N+<i>n</i>; <i>c</i>1,...,<i>cm</i>∈N+<i>m</i>; <i>d</i>1, ..., <i>dm</i>∈N+<i>m</i>;
 where each of the integers is represented in binary.
 <i>Problem 1 (equality testing):</i> Decide whether <i>a</i>1<i>b</i>1 <i>a</i>2<i>b</i>2⋯<i>anbn</i>=<i>c</i>1<i>d</i>1 <i>c</i>2<i>d</i>2⋯<i>cmdm</i>.
 <i>Problem 2 (inequality testing):</i> Decide whether <i>a</i>1<i>b</i>1 <i>a</i>2<i>b</i>2⋯<i>anbn</i>≥<i>c</i>1<i>d</i>1 <i>c</i>2<i>d</i>2⋯<i>cmdm</i>.
 Problem 1 is easily decidable in polynomial time using a simple iterative algorithm. Problem 2 is much harder. We observe that the complexity of Problem 2 is intimately connected to deep conjectures and results in number theory. In particular, if a refined form of the <i>ABC conjecture</i> formulated by Baker in 1998 holds, or if the older <i>Lang-Waldschmidt conjecture</i> (formulated in 1978) on linear forms in logarithms holds, then Problem 2 is decidable in P-time (in the standard Turing model of computation). Moreover, it follows from the best available quantitative bounds on linear forms in logarithms, namely, by Baker and Wüstholz [1993] or Matveev [2000], that if <i>m</i> and <i>n</i> are fixed universal constants then Problem 2 is decidable in P-time (without relying on any conjectures). This latter fact was observed earlier by Shub [1993].
 We describe one application: P-time maximum probability parsing for arbitrary stochastic context-free grammars (where <i>ε</i>-rules are allowed).",2013-04-19,https://www.semanticscholar.org/paper/e1f40198836f804b0efb555968c4c357736b7d25,TOCT
2811,Galectins in acute and chronic inflammation,"Galectins are animal lectins that bind to β‐galactosides, such as lactose and N‐acetyllactosamine, in free form or contained in glycoproteins or glycolipids. They are located intracellularly or extracellularly. In the latter they exhibit bivalent or multivalent interactions with glycans on cell surfaces and induce various cellular responses, including production of cytokines and other inflammatory mediators, cell adhesion, migration, and apoptosis. Furthermore, they can form lattices with membrane glycoprotein receptors and modulate receptor properties. Intracellular galectins can participate in signaling pathways and alter biological responses, including apoptosis, cell differentiation, and cell motility. Current evidence indicates that galectins play important roles in acute and chronic inflammatory responses, as well as other diverse pathological processes. Galectin involvement in some processes in vivo has been discovered, or confirmed, through studies of genetically engineered mouse strains, each deficient in a given galectin. Current evidence also suggests that galectins may be therapeutic targets or employed as therapeutic agents for these inflammatory responses.",2012-04-01,https://www.semanticscholar.org/paper/ccc9d779756383e39c1f75771a60a4fbdb3a709b,Annals of the New York Academy of Sciences
338,The Complexity of Games on Highly Regular Graphs,,2005-10-03,https://www.semanticscholar.org/paper/bb7288850d42303f2282ed7299b24bf8e10adf16,Embedded Systems and Applications
1201,Observation of ZZ production in p-p collisions at sqrt s=1.96 TeV.,"We present an observation for ZZ-->l+l-l'+l'- (l, l'=e or mu) production in p[over]p collisions at a center-of-mass energy of sqrt[s]=1.96 TeV. Using 1.7 fb(-1) of data collected by the D0 experiment at the Fermilab Tevatron Collider, we observe three candidate events with an expected background of 0.14(+0.03)_(-0.02) events. The significance of this observation is 5.3 standard deviations. The combination of D0 results in this channel, as well as in ZZ-->l+l- nu[over]nu, yields a significance of 5.7 standard deviations and a combined cross section of sigma(ZZ)=1.60+/-0.63(stat)+0.16_-0.17(syst) pb.",2008-08-05,https://www.semanticscholar.org/paper/151d7ddd904150ec3c18c0c262a3343cb3ace085,Physical Review Letters
828,Distinguishing tests for nondeterministic and probabilistic machines,"We study the problem of uniquely identifying the initial state of a given finite-state machine from among a set of possible choices, based on the input-output behavior. Equivalently, given a set of machines, the problem is to design a test that distinguishes among them. We consider nondeterministic machines as well as probabilistic machines. In both cases, we show that it is PsPAcE-complete to decide whether there is a preset distinguishing strategy (i.e. a sequence of inputs fixed in advance), and it is ExPTIME-complete to decide whether there is an adaptive distinguishing strategy (i.e. when the next input can be chosen based on the outputs observed so far). The probabilistic testing is closely related to probabilistic games, or Markov Decision Processes, with incomplete information. We also provide optimal bounds for deciding whether such games have strategies winning with probability 1.",1995-05-29,https://www.semanticscholar.org/paper/b9907976c3ac7f6bd63f18db3459f59a04b852e4,Symposium on the Theory of Computing
1572,Hierarchical recurrent state space models reveal discrete and continuous dynamics of neural activity in C. elegans,"Modern recording techniques enable large-scale measurements of neural activity in a variety of model organisms. The dynamics of neural activity shed light on how organisms process sensory information and generate motor behavior. Here, we study these dynamics using optical recordings of neural activity in the nematode C. elegans. To understand these data, we develop state space models that decompose neural time-series into segments with simple, linear dynamics. We incorporate these models into a hierarchical framework that combines partial recordings from many worms to learn shared structure, while still allowing for individual variability. This framework reveals latent states of population neural activity, along with the discrete behavioral states that govern dynamics in this state space. We find stochastic transition patterns between discrete states and see that transition probabilities are determined by both current brain activity and sensory cues. Our methods automatically recover transition times that closely match manual labels of different behaviors, such as forward crawling, reversals, and turns. Finally, the resulting model can simulate neural data, faithfully capturing salient patterns of whole brain dynamics seen in real data.",2019-04-29,https://www.semanticscholar.org/paper/8160f14cb60f8decfaf18c1e0f1597f872f7779d,bioRxiv
1744,The Issue-Adjusted Ideal Point Model,"We develop a model of issue-specific voting behavior. This model can be used to explore lawmakers' personal voting patterns of voting by issue area, providing an exploratory window into how the language of the law is correlated with political support. We derive approximate posterior inference algorithms based on variational methods. Across 12 years of legislative data, we demonstrate both improvement in heldout prediction performance and the model's utility in interpreting an inherently multi-dimensional space.",2012-09-26,https://www.semanticscholar.org/paper/1658c6306d019819abe8f70eb2cb4df1465745dd,arXiv.org
3396,Approximate Matchings in Massive Graphs via Local Structure (Invited Talk),"Finding a maximum matching is a fundamental algorithmic problem and is fairly well understood in traditional sequential computing models. Some modern applications require that we handle massive graphs and hence we need to consider algorithms in models that do not allow the entire input graph to be held in the memory of one computer, or models in which the graph is evolving over time. We introduce a new concept called an “Edge Degree Constrained Subgraph (EDCS)”, which is a subgraph that is guaranteed to contain a large matching, and which can be identified via local conditions. We then show how to use an EDCS to find 1.5-approximate matchings in several different models including Map Reduce, streaming and distributed computing. We can also use an EDCS to maintain a 1.5-optimal matching in a dynamic graph. This work is joint with Sepehr Asadi, Aaron Bernstein, Mohammad Hossein Bateni and Vahab Marrokni. 2012 ACM Subject Classification Theory of computation → Parallel algorithms, Theory of computation → Online algorithms",,https://www.semanticscholar.org/paper/400e667e909e8d4ffbd67773d5d786104a636482,International Symposium on Algorithms and Computation
2018,Evaluating capacity pooling strategy in semiconductor manufacturing: a productivity perspective study,"Recently, increasing attention has been focusing on the concept of the borderless fab, which expands capacity through a manufacturing strategy rather than capital investments. In a borderless fab, the capacity of several wafer fabs is pooled, and partially completed wafers are allowed to move from one fab to another. This paper proposes a model to evaluate the potential benefits of adopting capacity pooling from the macro-viewpoint. We demonstrate our model using actual full-scale fab-level operational data, and the result reveals that capacity pooling can improve monthly capacity by 3% on average.",2011-06-15,https://www.semanticscholar.org/paper/c333a14052c46092b0d75b50a82481c48dccd653,
2043,System on a Chip 2008: Ardentec Corporation,,2008-08-25,https://www.semanticscholar.org/paper/2f88b80af9099dc723c9ba3ff60da7d723ad2856,
2459,Personalized Compass: A Demonstration of a Compact Visualization for Direction and Location,"Maps on mobile/wearable devices often make it difficult to determine the location of a point of interest (POI). For example, a POI may exist outside the map or on a background with no meaningful cues. To address this issue, we present Personalized Compass, a self-contained compact graphical location indicator. Personalized Compass uses personal a priori POIs to establish a reference frame, within which a POI in question can then be localized. Graphically, a personalized compass combines a multi-needle compass with an abstract overview map. We analyze the characteristics of Personalized Compass and the existing Wedge technique, and report on a user study comparing them. Personalized Compass performs better for four inference tasks, while Wedge is better for a locating task. Based on our analysis and study results, we suggest the two techniques are complementary and offer design recommendations. In this demonstration, we present an iOS application comparing Personalized Compass with Wedge for map-based location and direction tasks.",2016-05-07,https://www.semanticscholar.org/paper/98713199ed1966d08437b0586eb478dbeb76366e,CHI Extended Abstracts
949,Change of peripapillary retinal nerve fiber layer and choroidal thickness during 4-year myopic progress: Boramae Myopia Cohort Study Report 4,"Aims To investigate the longitudinal changes of peripapillary retinal nerve fibre layer (RNFL) and choroidal thickness during myopic axial elongation. Methods Peripapillary RNFL and choroidal thickness were prospectively evaluated by spectral-domain optical coherence tomography (SD-OCT) in 46 eyes of 23 myopic children over the course of 4 years. Using serial OCT images acquired based on a fixed scan circle in the glaucoma progression analysis mode, general and sectoral RNFL thicknesses were acquired at the same position and the angular location of the peak was measured. The peripapillary choroidal thickness likewise was measured at eight positions in serial OCT images. Results The mean age at the baseline was 9.6±1.7 years. The mean axial length increased from 24.80±1.28 mm to 25.64±1.35 mm. The global peripapillary RNFL thickness was 98.54±12.06 µm at baseline. The global and sectoral RNFL thicknesses did not change during the 4 years. The angular location of RNFL peaks was also stable and was located in the superotemporal (64.18±10.85°) and inferotemporal (293.98±11.62°) sectors. The global peripapillary choroidal thickness was 145.40±28.67 µm at the baseline. The global and sectoral choroidal thicknesses did not change during the 4 years. Conclusions The peripapillary RNFL and choroidal thicknesses as well as the locations of the RNFL peaks had been preserved, during the 4-year follow-up on myopic children, when traced and measured from the same location.",2022-04-05,https://www.semanticscholar.org/paper/fc8b71d990189adec23fdad4ad2fb0b3274586e8,British Journal of Ophthalmology
214,Approximate Nash equilibria in anonymous games,,2015-03-01,https://www.semanticscholar.org/paper/06e4ff025e8c0979f715eebb1e0b808857101593,Journal of Economics Theory
2665,The importance of being mobile: some social consequences of wearable augmented reality systems,"What are the consequences of mobility for augmented reality? This paper explores some of the issues that I believe will be raised by the development and future commonplace adoption of mobile, wearable, augmented reality systems. These include: social influences on tracking accuracy, the importance of appearance and comfort, an increase in collaborative applications, integration with other devices, and implications for personal privacy.",1999-10-20,https://www.semanticscholar.org/paper/917356f2ed3c0a97997c012476787695b6e2e5bd,International Workshop on Automated Reasoning
1842,Mixed Membership Stochastic Block Models for Relational Data with Application to Protein-Protein Interactions,"Modeling relational data is an important problem for modern data analysis and machine learning. In this paper we propose a Bayesian model that uses a hierarchy of probabilistic assumptions about the way objects interact with one another in order to learn latent groups, their typical interaction patterns, and the degree of membership of objects to groups. Our model explains the data using a small set of parameters that can be reliably estimated with an efficient inference algorithm. In our approach, the set of probabilistic assumptions may be tailored to a specific application domain in order to incorporate intuitions and/or semantics of interest. We demonstrate our methods on simulated data, where they outperform spectral clustering techniques, and we apply our model to a data set of protein-to-protein interactions, to reveal proteins’ diverse functional roles.",,https://www.semanticscholar.org/paper/4d63618acc0bc6ecb1b3e88d5050b1cef06c3bed,
3261,Concordance on zebra stripes is not black and white: response to comment by Caro & Stankowich (2015),"We agree that the results of Larison et al . [1] and Caro et al . [2] are largely congruent—however, we remain divided on their interpretation. Both papers assessed a number of variables for an association with striping. Larison et al . [1] found temperature, specifically isothermality and the coldest temperature of the coldest quarter, to be the primary predictor of the degree of striping in plains zebra, with other climate and habitat variables playing very minor roles. Caro et al . [2] purport to have found a strong correlation between tabanid abundance and the degree of striping across equids. Caro and Stankowich would like readers to believe that both sets of data strongly support the notion that the evolution of striping has been driven by tabanid flies. However, we believe both sets …",2015-09-01,https://www.semanticscholar.org/paper/9262bff3704afd6dca1e4023e0a1d3f3e028913a,Royal Society Open Science
723,Joint Cyber and Physical Attacks on Power Grids,"Recent events demonstrated the vulnerability of power grids to cyber attacks and to physical attacks. Therefore, we focus on joint cyber and physical attacks and develop methods to retrieve the grid state information following such an attack. We consider a model in which an adversary attacks a zone by physically disconnecting some of its power lines and blocking the information flow from the zone to the grid's control center. We use tools from linear algebra and graph theory and leverage the properties of the power flow DC approximation to develop methods for information recovery. Using information observed outside the attacked zone, these methods recover information about the disconnected lines and the phase angles at the buses. We identify sufficient conditions on the zone structure and constraints on the attack characteristics such that these methods can recover the information. We also show that it is NP-hard to find an approximate solution to the problem of partitioning the power grid into the minimum number of attack-resilient zones. However, since power grids can often be represented by planar graphs, we develop a constant approximation partitioning algorithm for these graphs. Finally, we numerically study the relationships between the grid's resilience and its structural properties, and demonstrate the partitioning algorithm on real power grids. The results can provide insights into the design of a secure control network for the smart grid.",2015-06-15,https://www.semanticscholar.org/paper/2c69e498329378f828f7aec28d80f99b159ff433,Measurement and Modeling of Computer Systems
1038,Nonlinear dimensionality reduction for kinematic cartography with an application toward robotic locomotion,"Planning robot motions often requires a notion of the “distance” between configurations or the “length” of a trajectory connecting them in the configuration space. If these quantities are defined so as to correspond to the effort required to change configurations, then they would likely differ from the Euclidean distance or arclength in the system's configuration parameters, distorting the visual representation of the relative costs of executing the motions. This problem is fundamentally similar to that of producing map projections with minimal distortion in cartography. A separate problem is that of nonlinear dimensionality reduction (NLDR), which, given a set of data, projects it into a lower-dimensional space while seeking to retain the geometric relationship between data points. In this paper, we show that NLDR can be applied to the kinematic cartography problem, allowing us to generate system parameterizations in which distance and arclength correspond to the effort of motion.",2014-09-01,https://www.semanticscholar.org/paper/b6af3377a3f58507c6f489581b8624ac02f99821,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems
1499,Search for pair production of first-generation leptoquarks in pp̄ collisions at √ s = 1 . 96 TeV,,,https://www.semanticscholar.org/paper/46032bfebabf357b1e98e6171d5a47093b305def,
1784,Stochastic Search with an Observable State Variable,"In this paper we study convex stochastic search problems where a noisy objective function value is observed after a decision is made. There are many stochastic search problems whose behavior depends on an exogenous state variable which affects the shape of the objective function. Currently, there is no general purpose algorithm to solve this class of problems. We use nonparametric density estimation to take observations from the joint state-outcome distribution and use them to infer the optimal decision for a given query state. We propose two solution methods that depend on the problem characteristics: function-based and gradient-based optimization. We examine two weighting schemes, kernel-based weights and Dirichlet process-based weights, for use with the solution methods. The weights and solution methods are tested on a synthetic multi-product newsvendor problem and the hour-ahead wind commitment problem. Our results show that in some cases Dirichlet process weights offer substantial benefits over kernel based weights and more generally that nonparametric estimation methods provide good solutions to otherwise intractable problems.",2010-06-22,https://www.semanticscholar.org/paper/7c25a758844bf2adfbb348806ff12f20a049e796,
3460,Group Ratio Round-Robin: O(1) Proportional Share Scheduling for Uniprocessor and Multiprocessor Systems,"We present Group Ratio Round-Robin (GR3), the first proportional share scheduler that combines accurate proportional fairness scheduling behavior with O(1) scheduling overhead on both uniprocessor and multiprocessor systems. GR3 uses a simple grouping strategy to organize clients into groups of similar processor allocations which can be more easily scheduled. Using this strategy, GR3 combines the benefits of low overhead round-robin execution with a novel ratio-based scheduling algorithm. GR3 introduces a novel frontlog mechanism and weight readjustment algorithm to operate effectively on multiprocessors. GR3 provides fairness within a constant factor of the ideal generalized processor sharing model for client weights with a fixed upper bound and preserves its fairness properties on multiprocessor systems. We have implemented GR3 in Linux and measured its performance. Our experimental results show that GR3 provides much lower scheduling overhead and much better scheduling accuracy than other schedulers commonly used in research and practice.",2005-04-10,https://www.semanticscholar.org/paper/f260606d743bcf066eaf7a3c99c41fc10d39a822,"USENIX Annual Technical Conference, General Track"
1300,Search for the standard model Higgs Boson in the pp[over]-->ZH-->nunu[over]bb[over] channel.,"We report a search for the standard model (SM) Higgs boson based on data collected by the D0 experiment at the Fermilab Tevatron Collider, corresponding to an integrated luminosity of 260 pb(-1). We study events with missing transverse energy and two acoplanar b jets, which provide sensitivity to the ZH production cross section in the nunu[over]bb[over] channel, and to WH production when the lepton from the W-->lnu decay is undetected. The data are consistent with the SM background expectation, and we set 95% C.L. upper limits on sigma(pp[over]-->ZH/WH)xB(H-->bb[over]) from 3.4/8.3 to 2.5/6.3 pb, for Higgs-boson masses between 105 and 135 GeV.",2006-07-01,https://www.semanticscholar.org/paper/089ca28a8809809a1652d6bca849fd575ba88a0a,Physical Review Letters
3530,A Parallel Algorithm for Eliminating Cycles in Undirected Graphs,,1990-05-28,https://www.semanticscholar.org/paper/18ce185cff1d04deb38229aa9b33653704f1de19,Information Processing Letters
936,Algebraic dependencies,"The relational model for databases [Codd 1970, Ullman 1979] has gained recognition as a valuable formal framework for understanding the semantics, design, and even implementation, of databases. At the heart of the research on relational databases lies the notion of data dependency. Data dependencies are domain-independent (Le., invariant under consistent renamings of domain elements) predicates on databases. Starting ,vith functional [Armstrong 1974] and muttivalued [Fagin 1977] dependencies, a dozen of different kinds of data dependencies have been proposed in the literature [Nicolas 1978, Paradaens 1979, Sagiv and Walecka 1979, and others]. New, more and more general, kinds of data dependencies have been put forward in a rather arbitrary and heuristic fashion. This reflected two major frustrations of the research in this area: First, no natural, stable closure of this process was in sight. Secondly, the elegant complete axiomatizations of functional [Armstrong 1974] and multivalued dependencies [Beeri et ale 1977] did not appear to carry over to the more general kinds; thus the further generalizations were futile attempts at ""enriching the language"" enough so as to obtain a complete axiomatization.",1980-10-13,https://www.semanticscholar.org/paper/fbd716e7164f5d5b12ba4608421d9d3aa88ccb2b,21st Annual Symposium on Foundations of Computer Science (sfcs 1980)
1007,Optic disc change with incipient myopia of childhood.,,,https://www.semanticscholar.org/paper/f1c0c6464024f76abfb76e9dada081aa9588bb7f,"Ophthalmology (Rochester, Minn.)"
2661,"Erratum to ""Efficiently planning coherent visual discourse"" [Knowledge-Based Systems 10 (1998) 275-286]",,1999-06-01,https://www.semanticscholar.org/paper/5a82c961b67a969fdb0ded211f8bd32552c4bc7f,Knowledge-Based Systems
923,The Complexity of Testing Whether a Graph is a Superconcentrator,,,https://www.semanticscholar.org/paper/840694d1906eb3615479e13e6afa28313d10118a,Information Processing Letters
3510,Scheduling Jobs that Arrive Over Time (Extended Abstract),,1995-08-16,https://www.semanticscholar.org/paper/36bbfc2de85b3dd268b78b8774dd19148dd6e58c,Workshop on Algorithms and Data Structures
2692,Adding insight through animation in augmented reality,"Most of the virtual world systems that have been so well publicized over the past ten years use opaque head mounted displays that block off the wearer from the surrounding real world, effectively immersing her within a synthesized environment. These systems hold tremendous promise for certain applications ranging from fantasy games to scientific research. In contrast, we believe that the most powerful and commonplace virtual worlds of the future will not replace the real world, but will rather augment it with additional information. This approach is called augmented reality and was pioneered by Ivan Sutherland, who, over a quarter century ago, developed the first see-through head mounted display (I. Sutherland, 1968). When completed, his system presented graphics to the user on a pair of stereo displays, worn on the user's head. The image produced by the displays was combined with the user's view of the world using mirror beam splitters. A 3D tracking system determined the position and orientation of the user's head. This enabled the system to change the view, based on the direction in which the wearer was looking.",1996-06-03,https://www.semanticscholar.org/paper/35f8ffb33d48224df524ad289527fcb2b320f206,Proceedings Computer Animation '96
3383,Matching Drivers to Riders: A Two-Stage Robust Approach,"Matching demand (riders) to supply (drivers) efficiently is a fundamental problem for ride-sharing platforms who need to match the riders (almost) as soon as the request arrives with only partial knowledge about future ride requests. A myopic approach that computes an optimal matching for current requests ignoring future uncertainty can be highly sub-optimal. In this paper, we consider a two-stage robust optimization framework for this matching problem where future demand uncertainty is modeled using a set of demand scenarios (specified explicitly or implicitly). The goal is to match the current request to drivers (in the first stage) so that the cost of first stage matching and the worst case cost over all scenarios for the second stage matching is minimized. We show that the two-stage robust matching is NP-hard under various cost functions and present constant approximation algorithms for different settings of our two-stage problem. Furthermore, we test our algorithms on real-life taxi data from the city of Shenzhen and show that they substantially improve upon myopic solutions and reduce the maximum wait time of the second-stage riders by an average of $30\%$ in our experimental results.",2020-11-06,https://www.semanticscholar.org/paper/1d0638fe19b3f006122b1582d47781e60986aec7,"International Workshop and International Workshop on Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques"
3621,Analytic Tests for Relative Stability and Strict Aperiodicity,"In this paper, simple numerical procedures are proposed, which use the Routh test to determine the relative stability and strict aperiodicity of linear time-invariant systems.",,https://www.semanticscholar.org/paper/10364be0ec22f93a064e71bcb3fb85cc92efeb28,
3735,Relational Action Forecasting,"This paper focuses on multi-person action forecasting in videos. More precisely, given a history of H previous frames, the goal is to detect actors and to predict their future actions for the next T frames. Our approach jointly models temporal and spatial interactions among different actors by constructing a recurrent graph, using actor proposals obtained with Faster R-CNN as nodes. Our method learns to select a subset of discriminative relations without requiring explicit supervision, thus enabling us to tackle challenging visual data. We refer to our model as Discriminative Relational Recurrent Network (DRRN). Evaluation of action prediction on AVA demonstrates the effectiveness of our proposed method compared to simpler baselines. Furthermore, we significantly improve performance on the task of early action classification on J-HMDB, from the previous SOTA of 48% to 60%.",2019-04-08,https://www.semanticscholar.org/paper/6edfe8350da54cd563158b0d7d0c664f16cb91a8,Computer Vision and Pattern Recognition
35,Introduction to the Special Issue on Managing Information Extraction,"The field of information extraction (IE) focuses on extracting structured data, such as person names and organizations, from unstructured text. This field has had a long history. It attracted steady attention in the 80s and 90s, largely in the AI community. In the past decade, however, spurred on by the explosion of unstructured data on the World-Wide Web, this attention has turned into a torrent, gathering the efforts of researchers in the AI, DB, WWW, KDD, Semantic Web and IR communities. New IE problems have been identified, new IE techniques developed, many workshops organized, tutorials presented, companies founded, academic and industrial products deployed, and opensource prototypes developed (e.g., [5, 4, 3, 1, 2]; see [5] for the latest survey). The next few years are poised to witness even more accelerated activities in these areas. It is against this vibrant backdrop that we assemble this special issue. Our objective is threefold. First, we want to provide a glimpse into the current state of the field, highlighting in particular the wide range of IE problems. Second, we want to show that many IE problems can significantly benefit from the wealth of work on managing structured data in the database community. We believe therefore that our community can make a substantial contribution to the IE field. Finally, we hope that examining IE problems can in turn help us gain valuable insights into managing data in this Internet-centric world, a long-term goal of our community. Keeping in mind the above goals, we end this introduction by briefly describing the nine papers assembled for the issue. These papers fall into four broad categories.",,https://www.semanticscholar.org/paper/1714b50567728933b261d072b5b6ffdcafd76935,
2003,A new morphology-based approach for similarity searching on wafer bin maps in semiconductor manufacturing,"Due to increases in the complexity of processes involved in semiconductor manufacturing, increasingly high inspection costs associated with defective wafers has become a critical concern of modern manufacturers. More importantly, because of high-dimensional wafer bin maps (WBMs), it is difficult to capture the variations of each dimension via traditional pattern recognition or classification methods. By contrast, this work proposes a novel two-phase morphology-based similarity search consisting of: (1) training sample generation based on the morphological method and (2) SVM categorization for test datasets according to the variant degrees of similarities. The morphology-based samples contain five kinds of features, including original morphology definitions in addition to our proposed features. The second phase, using SVM for similarity searches, extends the usage of pattern recognition to real applications in large sample dimensions. The preliminary results demonstrate the usefulness of our approach in the context of yield improvements in semiconductor manufacturing.",2012-05-23,https://www.semanticscholar.org/paper/9d72a85f69ec4811db36141b069ed9dfdc0df732,International Conference on Computer Supported Cooperative Work in Design
1750,Nonparametric variational inference,"Variational methods are widely used for approximate posterior inference. However, their use is typically limited to families of distributions that enjoy particular conjugacy properties. To circumvent this limitation, we propose a family of variational approximations inspired by nonparametric kernel density estimation. The locations of these kernels and their bandwidth are treated as variational parameters and optimized to improve an approximate lower bound on the marginal likelihood of the data. Unlike most other variational approximations, using multiple kernels allows the approximation to capture multiple modes of the posterior. We demonstrate the efficacy of the nonparametric approximation with a hierarchical logistic regression model and a nonlinear matrix factorization model. We obtain predictive performance as good as or better than more specialized variational methods and MCMC approximations. The method is easy to apply to graphical models for which standard variational methods are difficult to derive.",2012-06-18,https://www.semanticscholar.org/paper/6ba0491f9dde8ea042ea4a49df34838b345f23c2,International Conference on Machine Learning
3586,for Hard Real-Time Systems,,,https://www.semanticscholar.org/paper/ecbcfc899df265f6c993302f70fef25efd12ed35,
2015,Guest Editorial Equipment and Operations Automation in the Semiconductor Industry,"The nine The ten papers in this special issue focus on three areas: equipment automation, operations automation, and modeling.",,https://www.semanticscholar.org/paper/80021c81c9365ffb80acdfe7528a7b66f73ceae6,IEEE Transactions on Automation Science and Engineering
3600,Rules of thumb for the design of C++0x,"programming language is far more than a simple collection of features. My ideal is to provide a set of facilities that smoothly work together to support design and programming styles of a generality beyond my imagination. Here, I outline rules of thumb (guidelines, principles) that are being applied in the design of C++0x. For example, generality is preferred over specialization, novices as well as experts are supported, library extensions are preferred over language changes, compatibility with C++98 is emphasized, and evolution is preferred over radical breaks with the past. Since principles cannot be understood in isolation, I very briefly present a few of the proposals being considered in the ISO C++ standards committee.",,https://www.semanticscholar.org/paper/051a121ad6daddc18fe8dd08c633fdc3bfb224c6,
1252,"Erratum to: ""Measurement of the isolated photon cross section in p over(p, ̄) collisions at sqrt(s) = 1.96 TeV"" [Phys. Lett. B 639 (2006) 151] (DOI:10.1016/j.physletb.2006.04.048)",,2008-01-10,https://www.semanticscholar.org/paper/c8828012a52e739df91b808706845228d53f17cd,
2896,Cas13d-mediated isoform-specific RNA knockdown with a unified computational and experimental toolbox,"Alternative splicing is an essential mechanism for diversifying proteins, in which mature RNA isoforms produce proteins with potentially distinct functions. Two major challenges in characterizing the cellular function of isoforms are the lack of experimental methods to specifically and efficiently modulate isoform expression and computational tools for complex experimental design. To address these gaps, we developed and methodically tested a strategy which pairs the RNA-targeting CRISPR/Cas13d system with guide RNAs that span exon-exon junctions in the mature RNA. We performed a high-throughput essentiality screen, quantitative RT-PCR assays, and PacBio long read sequencing to affirm our ability to specifically target and robustly knockdown individual RNA isoforms. In parallel, we provide computational tools for experimental design and screen analysis. Considering all possible splice junctions annotated in GENCODE for multi-isoform genes and our gRNA efficacy predictions, we estimate that our junction-centric strategy can uniquely target up to 89% of human RNA isoforms, including 50,066 protein-coding and 11,415 lncRNA isoforms. Importantly, this specificity spans all splicing and transcriptional events, including exon skipping and inclusion, alternative 5’ and 3’ splice sites, and alternative starts and ends.",2023-09-13,https://www.semanticscholar.org/paper/cfb0b138430322512df115dfd0f51f230f70b072,bioRxiv
3557,Design of Concept Libraries for C++,,2011-07-03,https://www.semanticscholar.org/paper/650f103dc99e3907028af458051a5dd241b58aab,Software Language Engineering
2151,A Simple Lower Bound for the Capacity of the Deletion Channel,"We present a simple proof that the capacity of the binary independent and identically distributed (i.i.d.) deletion channel, where each bit is deleted independently with probability d, is at least (1-d)/9, by developing a correspondence between the deletion channel and an insertion/deletion channel that we call a Poisson-repeat channel",2006-10-01,https://www.semanticscholar.org/paper/9a267dcf9a400f9ad02c6f72b68a2a44a54985a6,IEEE Transactions on Information Theory
767,Probability and Recursion,,2005-12-19,https://www.semanticscholar.org/paper/2c66f7fb9311cab3fe117a533ab2880ba5c0fd3f,International Symposium on Algorithms and Computation
1317,The SuperCDMS proposal for dark matter detection,,2006-04-15,https://www.semanticscholar.org/paper/61d6d5041d54f35ca6387ec77b1505a10d7c6514,
1981,An empirical study of design-of-experiment data mining for yield-loss diagnosis for semiconductor manufacturing,,2013-05-28,https://www.semanticscholar.org/paper/af13de380d4496c89d52f3d0a03a06e5289ef4c4,Journal of Intelligent Manufacturing
3002,Cloud Computing Security: Foundations and Research Directions,,,https://www.semanticscholar.org/paper/86a301c4fcd85ae6e003c34087d25df812b9da0a,Found. Trends Priv. Secur.
3545,The C++ Programming Language (hardcover),"The new C++11 standard allows programmers to express ideas more clearly, simply, and directly, and to write faster, more efficient code. Bjarne Stroustrup, the designer and original implementer of C++, has reorganized, extended, and completely rewritten his definitive reference and tutorial for programmers who want to use C++ most effectively. The C++ Programming Language, Fourth Edition, delivers meticulous, richly explained, and integrated coverage of the entire languageits facilities, abstraction mechanisms, standard libraries, and key design techniques. Throughout, Stroustrup presents concise, pure C++11 examples, which have been carefully crafted to clarify both usage and program design. To promote deeper understanding, the author provides extensive cross-references, both within the book and to the ISO standard. New C++11 coverage includes Support for concurrency Regular expressions, resource management pointers, random numbers, and improved containers General and uniform initialization, simplified for-statements, move semantics, and Unicode support Lambdas, general constant expressions, control over class defaults, variadic templates, template aliases, and user-defined literals Compatibility issues Topics addressed in this comprehensive book include Basic facilities: type, object, scope, storage, computation fundamentals, and more Modularity, as supported by namespaces, source files, and exception handling C++ abstraction, including classes, class hierarchies, and templates in support of a synthesis of traditional programming, object-oriented programming, and generic programming Standard Library: containers, algorithms, iterators, utilities, strings, stream I/O, locales, numerics, and more The C++ basic memory model, in depth This fourth edition makes C++11 thoroughly accessible to programmers moving from C++98 or other languages, while introducing insights and techniques that even cutting-edge C++11 programmers will find indispensable. This is a hardcover version of the Fourth Edition. Content in this hardcover and the paperback version is identical. This book features an enhanced, layflat binding, which allows the book to stay open more easily when placed on a flat surface. This special binding methodnoticeable by a small space inside the spinealso increases durability.",2013-08-03,https://www.semanticscholar.org/paper/9952059f76e084d1cdee7bd4188e921f97654cb2,
1277,Measurement of the shape of the boson rapidity distribution for p p ! Z,"V. M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, S. H. Ahn, M. Ahsan, G. D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G. A. Alves, M. Anastasoaie, L. S. Ancu, T. Andeen, S. Anderson, B. Andrieu, M. S. Anzelc, Y. Arnoud, M. Arov, A. Askew, B. Åsman, A. C. S. Assis Jesus, O. Atramentov, C. Autermann, C. Avila, C. Ay, F. Badaud, A. Baden, L. Bagby, B. Baldin, D. V. Bandurin, P. Banerjee, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, L. Berntzon, I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, M. Binder, C. Biscarat, G. Blazey, F. Blekman, S. Blessing, D. Bloch, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, G. Borissov, K. Bos, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, S. Burdin, S. Burke, T. H. Burnett, E. Busato, C. P. Buszello, J. M. Butler, P. Calfayan, S. Calvet, J. Cammin, S. Caron, W. Carvalho, B. C. K. Casey, N. M. Cason, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K. Chan, K. M. Chan, A. Chandra, F. Charles, E. Cheu, F. Chevallier, D. K. Cho, S. Choi, B. Choudhary, L. Christofek, T. Christoudias, S. Cihangir, D. Claes, B. Clément, C. Clément, Y. Coadou, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, D. Cutts, M. Ćwiok, H. da Motta, A. Das, G. Davies, K. De, P. de Jong, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, J. D. Degenhardt, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, H. Dong, L. V. Dudko, L. Duflot, S. R. Dugad, D. Duggan, A. Duperrin, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V. D. Elvira, Y. Enari, S. Eno, P. Ermolov, H. Evans, A. Evdokimov, V. N. Evdokimov, A. V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Ford, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, E. Gallas, E. Galyaev, C. Garcia, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, D. Gelé, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, N. Gollub, B. Gómez, A. Goussiou, P. D. Grannis, H. Greenlee, Z. D. Greenwood, E. M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M. W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Hanagaki, P. Hansson, K. Harder, A. Harel, R. Harrington, J. M. Hauptman, R. Hauser, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, J. M. Heinmiller, A. P. Heinson, U. Heintz, C. Hensel, K. Herner, G. Hesketh, M. D. Hildreth, R. Hirosky, J. D. Hobbs, B. Hoeneisen, H. Hoeth, M. Hohlfeld, S. J. Hong, R. Hooper, P. Houben, Y. Hu, Z. Hubacek, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, C. Jarvis, R. Jesik, K. Johns, C. Johnson, M. Johnson, A. Jonckheere, P. Jonsson, A. Juste, D. Käfer, S. Kahn, E. Kajfasz, A. M. Kalinin, J. M. Kalk, J. R. Kalk, S. Kappler, D. Karmanov, J. Kasper, P. Kasper, I. Katsanos, D. Kau, R. Kaur, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y. M. Kharzheev, D. Khatidze, H. Kim, T. J. Kim, M. H. Kirby, B. Klima, J. M. Kohli, J.-P. Konrath, M. Kopal, V. M. Korablev, J. Kotcher, B. Kothari, A. Koubarovsky, A. V. Kozelov, D. Krop, A. Kryemadhi, T. Kuhl, A. Kumar, S. Kunori, A. Kupco, T. Kurča, J. Kvita, D. Lam, S. Lammers, G. Landsberg, J. Lazoflores, P. Lebrun, W. M. Lee, A. Leflat, F. Lehner, V. Lesne, J. Leveque, P. Lewis, J. Li, L. Li, Q. Z. Li, S. M. Lietti, J. G. R. Lima, D. Lincoln, J. Linnemann, V. V. Lipaev, R. Lipton, Z. Liu, L. Lobo, A. Lobodenko, M. Lokajicek, A. Lounis, P. Love, H. J. Lubatti, M. Lynker, A. L. Lyon, A. K. A. Maciel, R. J. Madaras, P. Mättig, C. Magass, A. Magerkurth, N. Makovec, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, J. Mans, H. S. Mao, Y. Maravin, B. Martin, R. McCarthy, A. Melnitchouk, A. Mendes, L. Mendoza, P. G. Mercadante, M. Merkin, K. W. Merritt, A. Meyer, J. Meyer, M. Michaut, H. Miettinen, T. Millet, J. Mitrevski, J. Molina, R. K. Mommsen, N. K. Mondal, J. Monk, R. W. Moore, T. Moulik, G. S. Muanza, M. Mulders, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, N. A. Naumann, H. A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, C. Noeding, A. Nomerotski, S. F. Novaes, T. Nunnemann, V. O’Dell, D. C. O’Neil, G. Obrant, C. Ochando, V. Oguri, N. Oliveira, D. Onoprienko, N. Oshima, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park, S. K. Park, J. Parsons, R. Partridge, N. Parua, PHYSICAL REVIEW D 76, 012003 (2007)",,https://www.semanticscholar.org/paper/51aa050eb7ce649cb9d3322fe48d637b0f4c5744,
1123,Search for Higgs Boson Production in Dilepton and Missing Energy Final States withofCollisions at,,2010-02-12,https://www.semanticscholar.org/paper/1efd3e76f2a7caa12480e5c60ef0c0cd973ae7a2,
971,Optic Disc-guided Optical Coherence Tomography Interpretation for Diagnosis of Early-glaucoma: Selecting the Optimal Parameters,,2019-06-01,https://www.semanticscholar.org/paper/4cc9d080731b41608a328173082945fdc6c3a9f5,Journal of the Korean Glaucoma Society
1733,Efficient discovery of overlapping communities in massive networks,"Detecting overlapping communities is essential to analyzing and exploring natural networks such as social networks, biological networks, and citation networks. However, most existing approaches do not scale to the size of networks that we regularly observe in the real world. In this paper, we develop a scalable approach to community detection that discovers overlapping communities in massive real-world networks. Our approach is based on a Bayesian model of networks that allows nodes to participate in multiple communities, and a corresponding algorithm that naturally interleaves subsampling from the network and updating an estimate of its communities. We demonstrate how we can discover the hidden community structure of several real-world networks, including 3.7 million US patents, 575,000 physics articles from the arXiv preprint server, and 875,000 connected Web pages from the Internet. Furthermore, we demonstrate on large simulated networks that our algorithm accurately discovers the true community structure. This paper opens the door to using sophisticated statistical models to analyze massive networks.",2013-08-15,https://www.semanticscholar.org/paper/7b3373f90e691c2ba1a2f383ae38334a1f74e651,Proceedings of the National Academy of Sciences of the United States of America
54,Classifying and searching hidden-web text databases,"The World-Wide Web continues to grow rapidly, which makes exploiting all available information a challenge. Search engines such as Google index an unprecedented amount of information, but still do not provide access to valuable content in text databases “hidden” behind search interfaces. For example, current search engines largely ignore the contents of the Library of Congress, the US Patent and Trademark database, newspaper archives, and many other valuable sources of information because their contents are not “crawlable.” However, users should be able to find the information that they need with as little effort as possible, regardless of whether this information is crawlable or not. As a significant step towards this goal, we have designed algorithms that support browsing and searching—the two dominant ways of finding information on the web—over “hidden-web” text databases. 
To support browsing, we have developed QProber, a system that automatically categorizes hidden-web text databases in a classification scheme, according to their topical focus. QProber categorizes databases without retrieving any document. Instead, QProber uses just the number of matches generated from a small number of topically focused query probes. The query probes are automatically generated using state-of-the-art supervised machine learning techniques and are typically short. QProber's classification approach is sometimes orders of magnitude faster than approaches that require document retrieval. 
To support searching, we have developed crucial building blocks for constructing sophisticated metasearchers, which search over many text databases at once through a unified query interface. For scalability and effectiveness, it is crucial for a metasearcher to have a good database selection component and send queries only to databases with relevant content. Usually, database selection algorithms rely on statistics that characterize the contents of each database. Unfortunately, many hidden-web text databases are completely autonomous and do not report any summaries of their contents. To build content summaries for such databases, we extract a small, topically focused document sample from each database during categorization and use it to build the respective content summaries. A potential problem with content summaries derived from document samples is that any reasonably small sample will suffer from data sparseness and will riot contain many words that appear in the database. (Abstract shortened by UMI.)",,https://www.semanticscholar.org/paper/26790b8ed0c5df8a11cb931e3eb58e5661b6f7f2,
1625,Multilingual Topic Models for Unaligned Text,"We develop the multilingual topic model for unaligned text (MuTo), a probabilistic model of text that is designed to analyze corpora composed of documents in two languages. From these documents, MuTo uses stochastic EM to simultaneously discover both a matching between the languages and multilingual latent topics. We demonstrate that MuTo is able to find shared topics on real-world multilingual corpora, successfully pairing related documents across languages. MuTo provides a new framework for creating multilingual topic models without needing carefully curated parallel corpora and allows applications built using the topic model formalism to be applied to a much wider class of corpora. Topic models are a powerful formalism for unsupervised analysis of corpora [1, 8]. They are an important tool in information retrieval [27], sentiment analysis [25], and collaborative filtering [18]. When interpreted as a mixed membership model, similar assumptions have been successfully applied to vision [6], population survey analysis [4], and genetics [5]. In this work, we build on latent Dirichlet allocation (LDA) [2], a generative, probabilistic topic model of text. LDA assumes that documents have a distribution over topics and that these topics are distributions over the vocabulary. Posterior inference discovers the topics that best explain a corpus; the uncovered topics tend to reflect thematically consistent patterns of words [8]. The goal of this paper is to find topics that express thematic coherence across multiple languages. LDA can capture coherence in a single language because semantically similar words tend to be used in similar contexts. This is not the case in multilingual corpora. For example, even though “Hund” and “hound” are orthographically similar and have nearly identical meanings in German and English (i.e., “dog”), they will likely not appear in similar contexts because almost all documents are written in a single language. Consequently, a topic model fit on a bilingual corpus reveals coherent topics but bifurcates the topic space between the two languages (Table 1). In order to build coherent topics across languages, there must be some connection to tie the languages together. Previous multilingual topic models connect the languages by assuming parallelism at either the sentence level [28] or document level [13, 23, 19]. Many parallel corpora are available, but they represent a small fraction of corpora. They also tend to be relatively well annotated and understood, making them less suited for unsupervised methods like LDA. A topic model on unaligned text in multiple languages would allow the exciting applications developed for monolingual topics models to be applied to a broader class of corpora and would help monolingual users to explore and understand multilingual corpora. We propose the MUltilingual TOpic model for unaligned text (MUTO). MUTO does not assume that it is given any explicit parallelism but instead discovers a parallelism at the vocabulary level. To find this parallelism, the model assumes that similar themes and ideas appear in both languages. For example, if the word “Hund” appears in the German side of the corpus, “hound” or “dog” should appear somewhere on the English side. The assumption that similar terms will appear in similar contexts has also been used to build lexicons from nonparallel but comparable corpora. What makes contexts similar can be evaluated through such measures as cooccurrence [20, 24] or tf-idf [7]. Although the emphasis of our work is on building consistent topic spaces and not the task of building dictionaries per se, good translations are required to find consistent topics. However, we can build on successful techniques at building lexicons across languages. This paper is organized as follows. We detail the model and its assumptions in Section 1, develop a stochastic expectation maximization (EM) inference procedure in Section 2, discuss the corpora and other linguistic resources necessary to evaluate the model in Section 3, and evaluate the performance of the model in Section 4.",,https://www.semanticscholar.org/paper/3f9bfa1c5cce02b86667c53ddfd34902d8bd0eee,
2769,An experimental system for creating and presenting interactive graphical documents,"An experimental system is described for the design, development, and presentation of computer-based documents that combine pictures and text on a high-resolution color raster display. Such documents can be used, for example, for maintenance and repair tasks, videotex databases, or computer-aided instruction. Documents are directed graphs whose nodes we refer to as pages, in analogy to the pages of a paper book. A page includes a set of simultaneously displayed pictures, actions (procedures and processes), and indexing information. Pages may be nested arbitrarily deeply in chapters that serve much the same organizing function as those of conventional books. The system is comprised of separate programs for laying out and drawing pictures, for graphically specifying the contents of pages, chapters, and their interconnections, and for displaying the document for user interaction. Examples are given from a prototype maintenance and repair manual in which emphasis was placed on designing actions that allow simple real-time animation and assist in finding one's way around the document.",,https://www.semanticscholar.org/paper/dfe3aeabf4dcf3e1e1223bb1455eb46e6a9f2f87,TOGS
783,Adaptive Model Checking,"We consider the case where inconsistencies are present between a system and its corresponding model, used for automatic verification. Such inconsistencies can be the result of modeling errors or recent modifications of the system. Despite such discrepancies we can still attempt to perform automatic verification. In fact, as we show, we can sometimes exploit the verification results to assist in automatically learning the required updates to the model. In a related previous work, we have suggested the idea of black box checking, where verification starts without any model, and the model is obtained while repeated verification attempts are performed. Under the current assumptions, an existing inaccurate (but not completely obsolete) model is used to expedite the updates. We use techniques from black box testing and machine learning. We present an implementation of the proposed methodology called AMC (for Adaptive Model Checking). We discuss some experimental results, comparing various tactics of updating a model while trying to perform model checking.",2002-04-08,https://www.semanticscholar.org/paper/09fd5633e393d214a7fa7c2a3adfa354e2179f82,Logic Journal of the IGPL
3582,C++ Dynamic Cast in Autonomous Space Systems,"The dynamic cast operation allows flexibility in the design and use of data management facilities in object- oriented programs. Dynamic cast has an important role in the implementation of the data management services (DMS) of the mission data system project (MDS), the jet propulsion laboratory's experimental work for providing a state-based and goal-oriented unified architecture for testing and development of mission software. DMS is responsible for the storage and transport of control and scientific data in a remote autonomous spacecraft. Like similar operators in other languages, the C++ dynamic cast operator does not provide the timing guarantees needed for hard real-time embedded systems. In a recent study, Gibbs and Stroustrup (G&S) devised a dynamic cast implementation strategy that guarantees fast constant-time performance. This paper presents the definition and application of a co-simulation framework to formally verify and evaluate the G&S fast dynamic casting scheme and its applicability in the mission data system DMS application. We describe the systematic process of model-based simulation and analysis that has lead to performance improvement of the G&S algorithm's heuristics by about a factor of 2.",2008-05-05,https://www.semanticscholar.org/paper/67a7239fca42015fa4e7f59f894239e2b40d01b0,IEEE International Symposium on Real-Time Distributed Computing
1218,Search for anomalous Wtb couplings in single top quark production.,"In 0.9 fb(-1) of pp[over] collisions, the D0 Collaboration presented evidence for single top quark production in events with an isolated lepton, missing transverse momentum, and two to four jets. We examine these data to study the Lorentz structure of the Wtb coupling. The standard model predicts a left-handed vector coupling at the Wtb vertex. The most general lowest dimension, CP-conserving Lagrangian admits right-handed vector and left- or right-handed tensor couplings as well. We find that the data prefer the left-handed vector coupling and set upper limits on the anomalous couplings. These are the first direct constraints on a general Wtb interaction and the first direct limits on left- and right-handed tensor couplings.",2008-07-10,https://www.semanticscholar.org/paper/4d06eb19a518cd34052cbbff035ecd9e6d3633e3,Physical Review Letters
832,On the hardness of approximating minimization problems,"We prove results indicating that it is hard to compute efficiently good approximate solutions to the Graph Coloring, Set Covering and other related minimization problems. Specifically, there is an e > 0 such that Graph Coloring cannot be approximated with ratio n e unless P = NP. Set Covering cannot be approximated with ratio c log n for any c < 1/4 unless NP is contained in DTIME(n poly log n ). Similar results follow for related problems such as Clique Cover, Fractional Chromatic Number, Dominating Set, and others",1994-09-01,https://www.semanticscholar.org/paper/67762ce2c7a85dbf55cdf86fedee2610229d91eb,JACM
3150,Performance of Size-Changing Algorithms in Stackable File Systems,"Stackable file systems can provide extensible file system functionality with minimal performance overhead and development cost. However, previous approaches are limited in the functionality they provide. In particular, they do not support size-changing algorithms, which are important and useful for many applications, such as compression and security. We propose fast index files, a technique for efficient support of size-changing algorithms in stackable file systems. Fast index files provide a page mapping between file system layers in a way that can be used with any size-changing algorithm. Index files are designed to be recoverable if lost and add less than 0.1% disk space overhead. We have implemented fast indexing using portable stackable templates, and we have used this system to build several example file systems with size-changing algorithms. We demonstrate that fast index files have very low overhead for typical workloads, only 2.3% over other stacked file systems. Our system can deliver much better performance on size-changing algorithms than user-level applications, as much as five times faster.",,https://www.semanticscholar.org/paper/2185d23a7930ebebe3a44bb9b5fa13a141db96d6,
978,Glaucoma Change of b-Zone Parapapillary Atrophy During Axial Elongation : Boramae Myopia Cohort Study Report 3,"Kyoung Min Lee, Ho-Kyung Choung, Martha Kim, Sohee Oh, and Seok Hwan Kim Department of Ophthalmology, Seoul National University College of Medicine, Seoul, Korea Department of Ophthalmology, Seoul National University Boramae Medical Center, Seoul, Korea Department of Ophthalmology, Dongguk University Ilsan Hospital, Goyang, Korea Department of Biostatistics, Seoul National University Boramae Medical Center, Seoul, Korea",,https://www.semanticscholar.org/paper/30160b2f749ddd70184adefb4e2c6e1070ee66bf,
1170,"Search for Next-to-Minimal Supersymmetric Higgs Bosons in the h ! aa ! , Channels Using p p Collisions at ffiffi s p 1⁄4 1 : 96 TeV","V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, M. Ahsan, G.D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G. A. Alves, L. S. Ancu, T. Andeen, M. S. Anzelc, M. Aoki, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, O. Atramentov, C. Avila, J. BackusMayes, F. Badaud, L. Bagby, B. Baldin, D.V. Bandurin, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V.A. Bezzubov, P. C. Bhat, V. Bhatnagar, G. Blazey, S. Blessing, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, E. E. Boos, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, X. B. Bu, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, T. H. Burnett, C. P. Buszello, P. Calfayan, B. Calpas, S. Calvet, J. Cammin, M.A. Carrasco-Lizarraga, E. Carrera, W. Carvalho, B. C. K. Casey, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K.M. Chan, A. Chandra, E. Cheu, D. K. Cho, S. Choi, B. Choudhary, T. Christoudias, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, D. Cutts, M. Ćwiok, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, K. DeVaughan, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, T. Dorland, A. Dubey, L. V. Dudko, L. Duflot, D. Duggan, A. Duperrin, S. Dutt, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V. D. Elvira, Y. Enari, S. Eno, M. Escalier, H. Evans, A. Evdokimov, V.N. Evdokimov, G. Facini, A. V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, W. Geng, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, B. Gómez, A. Goussiou, P. D. Grannis, S. Greder, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Harder, A. Harel, J.M. Hauptman, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, A. P. Heinson, U. Heintz, C. Hensel, I. Heredia-De La Cruz, K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, T. Hoang, J. D. Hobbs, B. Hoeneisen, M. Hohlfeld, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, N. Huske, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, D. Jamin, R. Jesik, K. Johns, C. Johnson, M. Johnson, D. Johnston, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, D. Karmanov, P. A. Kasper, I. Katsanos, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y. N. Kharzheev, D. Khatidze, T. J. Kim, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, J.-P. Konrath, A.V. Kozelov, J. Kraus, T. Kuhl, A. Kumar, A. Kupco, T. Kurča, V. A. Kuzmin, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, W.M. Lee, A. Leflat, J. Lellouch, J. Li, L. Li, Q. Z. Li, S.M. Lietti, J. K. Lim, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna-Garcia,34,x A.L. Lyon, A.K.A. Maciel, D. Mackin, P. Mättig, R. Magaña-Villalba, A. Magerkurth, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, Y. Maravin, B. Martin, R. McCarthy, C. L. McGivern, M.M. Meijer, A. Melnitchouk, L. Mendoza, D. Menezes, P. G. Mercadante, M. Merkin, K.W. Merritt, A. Meyer, J. Meyer, J. Mitrevski, N.K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, H.A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, G. Obrant, C. Ochando, D. Onoprienko, J. Orduna, N. Oshima, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, M. Padilla, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park, S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma,34,k V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, A. V. Popov, W. L. Prado da Silva, S. Protopopescu, J. Qian, A. Quadt, B. Quinn, A. Rakitine, M. S. Rangel, K. Ranjan, P. N. Ratoff, P. Renkel, P. Rich, M. Rijssenbeek, I. Ripp-Baudot, F. Rizatdinova, S. Robinson, M. Rominsky, C. Royon, P. Rubinov, R. Ruchti, G. Safronov, G. Sajot, A. Sánchez-Hernández, M. P. Sanders, B. Sanghi, G. Savage, L. Sawyer, T. Scanlon, D. Schaile, R.D. Schamberger, Y. Scheglov, PRL 103, 061801 (2009) P HY S I CA L R EV I EW LE T T E R S week ending 7 AUGUST 2009",,https://www.semanticscholar.org/paper/991f30fde7a219b7bffa8e5bec67aa093e0a2d2a,
2517,ARmonica: a collaborative sonic environment,"ARmonica is a 3D audiovisual augmented reality environment in which players can position and edit virtual bars that play sounds when struck by virtual balls launched under the influence of physics. Players experience ARmonica through head-tracked head-worn displays and tracked hand-held ultramobile personal computers, and interact through tracked Wii remotes and touch-screen taps. The goal is for players to collaborate in the creation and editing of an evolving sonic environment. Research challenges include supporting walk-up usability without sacrificing deeper functionality.",2010-10-03,https://www.semanticscholar.org/paper/15a680b23e34c28ffb21098a40e5becf440c4645,ACM Symposium on User Interface Software and Technology
1630,Implicit Causal Models for Genome-wide Association Studies,"Progress in probabilistic generative models has accelerated, developing richer models with neural architectures, implicit densities, and with scalable algorithms for their Bayesian inference. However, there has been limited progress in models that capture causal relationships, for example, how individual genetic factors cause major human diseases. In this work, we focus on two challenges in particular: How do we build richer causal models, which can capture highly nonlinear relationships and interactions between multiple causes? How do we adjust for latent confounders, which are variables influencing both cause and effect and which prevent learning of causal relationships? To address these challenges, we synthesize ideas from causality and modern probabilistic modeling. For the first, we describe implicit causal models, a class of causal models that leverages neural architectures with an implicit density. For the second, we describe an implicit causal model that adjusts for confounders by sharing strength across examples. In experiments, we scale Bayesian inference on up to a billion genetic measurements. We achieve state of the art accuracy for identifying causal factors: we significantly outperform existing genetics methods by an absolute difference of 15-45.3%.",2017-10-01,https://www.semanticscholar.org/paper/83cffda7d9b47d0927d03fdc574a019487a3d5d8,International Conference on Learning Representations
3272,African Vultures Don’t Follow Migratory Herds: Scavenger Habitat Use Is Not Mediated by Prey Abundance,"The ongoing global decline in vulture populations raises major conservation concerns, but little is known about the factors that mediate scavenger habitat use, in particular the importance of abundance of live prey versus prey mortality. We test this using data from the Serengeti-Mara ecosystem in East Africa. The two hypotheses that prey abundance or prey mortality are the main drivers of vulture habitat use provide alternative predictions. If vultures select areas based only on prey abundance, we expect tracked vultures to remain close to herds of migratory wildebeest regardless of season. However, if vultures select areas where mortality rates are greatest then we expect vultures to select the driest regions, where animals are more likely to die of starvation, and to be attracted to migratory wildebeest only during the dry season when wildebeest mortality is greatest. We used data from GSM-GPS transmitters to assess the relationship between three vulture species and migratory wildebeest in the Mara-Serengeti ecosystem. Results indicate that vultures preferentially cluster around migratory herds only during the dry season, when herds experience their highest mortality. Additionally during the wet season, Ruppell’s and Lappet-faced vultures select relatively dry areas, based on Normalized Difference Vegetation Index, whereas White-backed vultures preferred wetter areas during the wet season. Differences in habitat use among species may mediate coexistence in this scavenger guild. In general, our results suggest that prey abundance is not the primary driver of avian scavenger habitat use. The apparent reliance of vultures on non-migratory ungulates during the wet season has important conservation implications for vultures in light of on-going declines in non-migratory ungulate species and use of poisons in unprotected areas.",2014-01-08,https://www.semanticscholar.org/paper/33fcacb076caa7cd19b72af12443e2dde9a1ab4f,PLoS ONE
3425,Feasible and Accurate Algorithms for Covering Semidefinite Programs,,2010-06-21,https://www.semanticscholar.org/paper/b47164586799d8a37b72095c98d4120fa92759d2,Scandinavian Workshop on Algorithm Theory
3519,Long tours and short superstrings,"This paper considers weight-maximizing variants of the classical symmetric and asymmetric traveling-salesman problems. Like their weight-minimizing counterparts, these variants are MAX SNP-hard. We present the first nontrivial approximation algorithms for these problems. Our algorithm for directed graphs finds a tour whose weight is at least 38/63/spl ap/0.603 times the weight of a maximum-weight tour, and our algorithm for undirected graphs finds a tour whose weight is at least 5/7/spl ap/0.714 times optimal. These bounds compare favorably with the 1/2 and 2/3 bounds that can be obtained for undirected and directed graphs, respectively, by simply deleting the minimum-weight edge from each cycle of a maximum-weight cycle cover. Our algorithm for directed graphs can be used to improve several recent approximation results for the shortest-superstring problem.<<ETX>>",1994-11-20,https://www.semanticscholar.org/paper/d5cbeb2321ba9b9d3fa2d8a5b2484bab9408200b,Proceedings 35th Annual Symposium on Foundations of Computer Science
1194,Study of DirectCP Violation inB !J= K Decays,,,https://www.semanticscholar.org/paper/009d2a29076f3bb1da31dd75c43ca3586c6748cf,
585,Games against nature,"In Com,puter Science, important concepts usually come with a plethora of alternative characterizations. The class PSPACE, for example, can be defined either as the class of problelns solvable in polynomially bounded space by a multitape Turing machine or some similar model, or, equivalently, as the class of problems reducible to some polynomial-depth combinatorial two-person game [Stocklneyer and Meyer, Schaefer]. Alternation [Chandra and Stockmeyer] is an interesting variant of the latter point of view. A more recent, also ""problem-oriented"" characterization of PSPACE is the one in terms of problems involving periodic objects [Orlin]. In this paper, we propose a new characterization of PSPACE, based on some of the most classical and well-looked at problems in Optimization: decision-making under uncertainty. Problems in this class are usually characterized by a discretetime random process, the parameters of which can be influenced by dynamic decisions. Decisions are based on the current state. The goal is to minimize thge expectation of some cost functional of the history of states and decisions. There is a vast .literature on the numerous variants of this problem; the reader is referred for a start to the books by [Denardo, Der.man, IIoward, Bertsekas]. Typically, such a problem is solved by dynamic programming (ill fact, decision-making under uncertainty. was the original and intend.ed application of this technique), with a time and space cost which are usually exponential in the description of the input. In a handful of now classical cases, more clever special techniques have yielded polynomialtime algorithms [Howard, Derman]. Linear programming is sometimes employed. We can formulate a decision problem under uncertain.ty as a new sort of game, in which one",1983-11-07,https://www.semanticscholar.org/paper/edd8c619a47ccb3c3d7f79cd29c95b7ca682413e,24th Annual Symposium on Foundations of Computer Science (sfcs 1983)
1827,A Topic Model for Word Sense Disambiguation,"We develop latent Dirichlet allocation with WORDNET (LDAWN), an unsupervised probabilistic topic model that includes word sense as a hidden variable. We develop a probabilistic posterior inference algorithm for simultaneously disambiguating a corpus and learning the domains in which to consider each word. Using the WORDNET hierarchy, we embed the construction of Abney and Light (1999) in the topic model and show that automatically learned domains improve WSD accuracy compared to alternative contexts.",2007-06-01,https://www.semanticscholar.org/paper/a91760aca33559a6c7703c0fccf3289e1c4dd729,Conference on Empirical Methods in Natural Language Processing
3145,Proceedings of the 11th international workshop on Network and operating systems support for digital audio and video,,,https://www.semanticscholar.org/paper/35fc6d70a555d66dc06bd53bb4f24922f1d9da09,
3308,"Network metrics reveal differences in social organization between two fission–fusion species, Grevy’s zebra and onager",,2007-01-05,https://www.semanticscholar.org/paper/6797f2ae05d31bc271b29ee75782a1319fa1e971,Oecologia
2191,241. TYPE I INTERFERONS ALTER THE RESPONSE OF NEUTROPHILS TO INFLAMMATORY CYTOKINES,,2017-04-01,https://www.semanticscholar.org/paper/7b2a567952c83625744999cc8b6e650c52e91742,
707,REACT to Cyber-Physical Attacks on Power grids (Extended Abstract),"We study cyber attacks on power grids that affect both the physical infrastructure and the data at the control center? which therefore are cyber-physical in nature. In particular, we assume that an adversary attacks an area by: (i) remotely disconnecting some lines within the attacked area, and (ii) modifying the information received from the attacked area to mask the line failures and hide the attacked area from the control center. For the latter, we consider two types of attacks: (i) data distortion: which distorts the data by adding powerful noise to the actual data, and (ii) data replay: which replays a locally consistent old data instead of the actual data. We use the DC power flow model and prove that the problem of finding the set of line failures given the phase angles of the nodes outside of the attacked area is strongly NP-hard, even when the attacked area is known. However, we introduce the polynomial time REcurrent Attack Containment and deTection (REACT) Algorithm to approximately detect the attacked area and line failures after a cyber-physical attack.",2019-01-18,https://www.semanticscholar.org/paper/af0abdcff7ee588260931ad75b52ad80eb9e3c87,PERV
1648,Deep Survival Analysis,"The electronic health record (EHR) provides an unprecedented opportunity to build actionable tools to support physicians at the point of care. In this paper, we investigate survival analysis in the context of EHR data. We introduce deep survival analysis, a hierarchical generative approach to survival analysis. It departs from previous approaches in two primary ways: (1) all observations, including covariates, are modeled jointly conditioned on a rich latent structure; and (2) the observations are aligned by their failure time, rather than by an arbitrary time zero as in traditional survival analysis. Further, it (3) scalably handles heterogeneous (continuous and discrete) data types that occur in the EHR. We validate deep survival analysis model by stratifying patients according to risk of developing coronary heart disease (CHD). Specifically, we study a dataset of 313,000 patients corresponding to 5.5 million months of observations. When compared to the clinically validated Framingham CHD risk score, deep survival analysis is significantly superior in stratifying patients according to their risk.",2016-08-06,https://www.semanticscholar.org/paper/3b41bb3a470fbfba54283331f31256cc09f0f37e,Machine Learning in Health Care
3155,"The design, implementation and evaluation of SMART: a scheduler for multimedia applications","Real-time applications such as multimedia audio and video are increasingly populating the workstation desktop. To support the execution of these applications in conjunction with traditional non-realtime applications, we have created SMART, a Scheduler for Multimedia And Real-Time applications. SMART supports applications with time constraints, and provides dynamic feedback to applications to allow them to adapt to the current load. In addition, the support for real-time applications is inte grated with the support for conventional computations. This allows the user to prioritize across real-time and conventional computations, and dictate how the processor is to be shared among applications of the same priority . As the system load changes, SMART adjusts the allocation of resources dynamically and seamlessly. SMAR T is unique in its ability to automatically shed real-time tasks and re gulate their execution rates when the system is overloaded, while providing better value in underloaded conditions than previously proposed schemes. We have implemented SMART in the Solaris UNIX operating system and measured its performance against other schedulers in e xecuting real-time, interacti ve, and batch applications. Our results demonstrate SMART’s superior performance in supporting multimedia applications.",1997-10-01,https://www.semanticscholar.org/paper/928e56d819a7a9fb64f800bba2c2d23a875d6794,Symposium on Operating Systems Principles
1365,Measurement of the ratio of B+ and B0 meson lifetimes.,"The ratio of the B+ and B0 meson lifetimes was measured using data collected in 2002-2004 by the D0 experiment in Run II of the Fermilab Tevatron Collider. These mesons were reconstructed in B-->mu(+)nuD(*-)X decays, which are dominated by B0 and B-->mu(+)nuD 0X decays, which are dominated by B+. The ratio of lifetimes is measured to be tau(+)/tau(0)=1.080+/-0.016(stat)+/-0.014(syst).",2004-10-19,https://www.semanticscholar.org/paper/33b236bdf7e68a49bb39ee46b473a93e823343cb,Physical Review Letters
3449,"On the Complexity of Processing Massive, Unordered, Distributed Data","An existing approach for dealing with massive data sets is to stream over the input in few passes and perform computations with sublinear resources. This method does not work for truly massive data where even making a single pass over the data with a processor is prohibitive. Successful log processing systems in practice such as Google's MapReduce and Apache's Hadoop use multiple machines. They efficiently perform a certain class of highly distributable computations defined by local computations that can be applied in any order to the input. 
Motivated by the success of these systems, we introduce a simple algorithmic model for massive, unordered, distributed (mud) computation. We initiate the study of understanding its computational complexity. Our main result is a positive one: any unordered function that can be computed by a streaming algorithm can also be computed with a mud algorithm, with comparable space and communication complexity. We extend this result to some useful classes of approximate and randomized streaming algorithms. We also give negative results, using communication complexity arguments to prove that extensions to private randomness, promise problems and indeterminate functions are impossible. 
We believe that the line of research we introduce in this paper has the potential for tremendous impact. The distributed systems that motivate our work successfully process data at an unprecedented scale, distributed over hundreds or even thousands of machines, and perform hundreds of such analyses each day. The mud model (and its generalizations) inspire a set of complexity-theoretic questions that lie at their heart.",2006-11-21,https://www.semanticscholar.org/paper/31f27ef6ed49a27ac0ff91bc3f776e72e197009f,arXiv.org
2973,An Infinite Latent Attribute Model for Network Data,"Latent variable models for network data extract a summary of the relational structure underlying an observed network. The simplest possible models subdivide nodes of the network into clusters; the probability of a link between any two nodes then depends only on their cluster assignment. Currently available models can be classified by whether clusters are disjoint or are allowed to overlap. These models can explain a ""flat"" clustering structure. Hierarchical Bayesian models provide a natural approach to capture more complex dependencies. We propose a model in which objects are characterised by a latent feature vector. Each feature is itself partitioned into disjoint groups (subclusters), corresponding to a second layer of hierarchy. In experimental comparisons, the model achieves significantly improved predictive performance on social and biological link prediction tasks. The results indicate that models with a single layer hierarchy over-simplify real networks.",2012-06-26,https://www.semanticscholar.org/paper/425c51b95476e5ffa39978ae9bf76b729b9db782,International Conference on Machine Learning
825,The complexity of probabilistic verification,"We determine the complexity of testing whether a finite state, sequential or concurrent probabilistic program satisfies its specification expressed in linear-time temporal logic. For sequential programs, we present an algorithm that runs in time linear in the program and exponential in the specification, and also show that the problem is in PSPACE, matching the known lower bound. For concurrent programs, we show that the problem can be solved in time polynomial in the program and doubly exponential in the specification, and prove that it is complete for double exponential time. We also address these questions for specifications described by ω-automata or formulas in extended temporal logic.",1995-07-01,https://www.semanticscholar.org/paper/561a79c9309d9e0338c06e4939056bb931d080ea,JACM
1999,Mini–max regret strategy for robust capacity expansion decisions in semiconductor manufacturing,,2012-12-01,https://www.semanticscholar.org/paper/5ae103f2e690ea6878482eb269ef926eccd06f12,Journal of Intelligent Manufacturing
1642,"Discussion of ""Fast Approximate Inference for Arbitrarily Large Semiparametric Regression Models via Message Passing""","Discussion paper on ""Fast Approximate Inference for Arbitrarily Large Semiparametric Regression Models via Message Passing"" by Wand [arXiv:1602.07412].",2016-09-19,https://www.semanticscholar.org/paper/057496a0154947d112ecb8b6f4d8272c6409bd69,
2120,A cost-based heuristic for statistically determining sampling frequency in a wafer fab,"In wafer fabrication, because of the long cycle time, the high yield uncertainty and the high manufacturing cost, earlier process monitoring and control are critical. Thus, a number of inspection and measurement stations are set in the fabrication process to assure that the wafer quality meets the specific requirements. Researchers have applied the acceptance sampling plan to determine whether a lot is accepted or not. Due to the limited capacities and costs for in-line wafer inspections, only certain wafers are inspected among a specific number of lots. Thus, it is important to determine the sampling strategy that minimizes the total expected costs, including the inspection costs, false-alarm costs, out-of-control costs, in-control costs, and the costs from the false-passed wafers. In this study, we developed a cost-based heuristic for statistically determining the sampling frequency in wafer fab based on the economics, control chart design, Bayesian decision analysis, and the acceptance sampling strategy. We aimed to determine the optimal sampling frequency that trades off the various risks (i.e. the aggregation of cost and probability).",2000-06-14,https://www.semanticscholar.org/paper/42353a948a9a25b01e0f1381f095f1184933a680,2000 Semiconductor Manufacturing Technology Workshop (Cat. No.00EX406)
2396,Carbon monoxide- and oxygen-reacting haemoproteins in the mitochondrial fraction from the soil amoeba Acanthamoeba castellanii. Studies at subzero temperatures.,"1. Mitochondria-enriched fractions of the soil amoeba Acanthamoeba castellanii contained four haemoproteins that in their reduced forms reacted with CO to give photodissociable CO complexes; these were cytochromes a 3, a 614, b- and c-type cytochromes. 2. Non-photodissociable oxygen-containing compounds were formed at temperatures between -130 and -150 degrees C after photodissociation of CO in the presence of 200 microM-O2, 3. Electron transport, indicated by the oxidation of cytochromes a + a3 and cytochrome c, did not occur until the temperature was raised to -80 degrees C.",1981-11-15,https://www.semanticscholar.org/paper/daac4b6de967447485c182114ab3de15c43e8ad1,Biochemical Journal
1691,Hierarchical Variational Models,"Black box variational inference allows researchers to easily prototype and evaluate an array of models. Recent advances allow such algorithms to scale to high dimensions. However, a central question remains: How to specify an expressive variational distribution that maintains efficient computation? To address this, we develop hierarchical variational models (HVMs). HVMs augment a variational approximation with a prior on its parameters, which allows it to capture complex structure for both discrete and continuous latent variables. The algorithm we develop is black box, can be used for any HVM, and has the same computational efficiency as the original approximation. We study HVMs on a variety of deep discrete latent variable models. HVMs generalize other expressive variational distributions and maintains higher fidelity to the posterior.",2015-11-07,https://www.semanticscholar.org/paper/f31ac36adbd24c43dcd28397081702e98e026b34,International Conference on Machine Learning
475,The power of reflective relational machines,"A model of database programming with reflection, called reflective relational machine, is introduced and studied. The reflection consists here of dynamic generation of queries in a host programming language. The main results characterize the power of the machine in terms of known complexity classes. In particular, the polynomial-time restriction of the machine is shown to express PSPACE, and to correspond precisely to uniform circuits of polynomial depth and exponential size. This provides an alternative, logic-based formulation of the uniform circuit model, more convenient for problems naturally formulated in logic terms. Since time in the polynomially-bounded machine coincides with time in the uniform circuit model, this also shows that reflection allows for more ""intense"" parallelism, which is not attainable otherwise (unless P=PSPACE). Other results concern the power of the reflective relational machine subject to restrictions on the number of variables used.<<ETX>>",1994-07-04,https://www.semanticscholar.org/paper/c6de23a1189d30848e8d94c39fac12c42dc6ad25,Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
3609,Untangling the balancing and searching of balanced binary search trees,"A balanced binary search tree can be characterized by two orthogonal issues: its search strategy and its balancing strategy. In this paper, we show how to decouple search and balancing strategies so that they can be expressed independently of each other, communicating only by basic operations such as rotations. Different balancing strategies, such as red–black trees and splay trees, and different search applications, such as key search and rank search, can be combined arbitrarily. As a new result, we show how optimal string search can be expressed as a search application on any balanced binary tree.",2003-11-10,https://www.semanticscholar.org/paper/a2be43ce0ad84d77cfc88d535a61f765e9442f0e,"Software, Practice & Experience"
804,Communicating Hierarchical State Machines,,1999-07-11,https://www.semanticscholar.org/paper/8384b2063fdf5106e64013251b06d771cc7b9b44,"International Colloquium on Automata, Languages and Programming"
37,Answering General Time-Sensitive Queries,"Time is an important dimension of relevance for a large number of searches, such as over blogs and news archives. So far, research on searching over such collections has largely focused on locating topically similar documents for a query. Unfortunately, topic similarity alone is not always sufficient for document ranking. In this paper, we observe that, for an important class of queries that we call time-sensitive queries, the publication time of the documents in a news archive is important and should be considered in conjunction with the topic similarity to derive the final document ranking. Earlier work has focused on improving retrieval for “recency” queries that target recent documents. We propose a more general framework for handling time-sensitive queries and we automatically identify the important time intervals that are likely to be of interest for a query. Then, we build scoring techniques that seamlessly integrate the temporal aspect into the overall ranking mechanism. We present an extensive experimental evaluation using a variety of news article data sets, including TREC data as well as real web data analyzed using the Amazon Mechanical Turk. We examine several techniques for detecting the important time intervals for a query over a news archive and for incorporating this information in the retrieval process. We show that our techniques are robust and significantly improve result quality for time-sensitive queries compared to state-of-the-art retrieval techniques.",2008-10-26,https://www.semanticscholar.org/paper/62baadac0b75c742bb5e63314cc41c4a5aaeddbc,IEEE Transactions on Knowledge and Data Engineering
1470,"PROGRESSREPORTON THESLD6ERENKOV RINGIMAGINGDETECTOR* V. ASHFORD,tT.BIENZ,F.BIRD,G.CRAWFORD,$M. GAILLARD, G. HALLEWELL, D. LEITH,",,,https://www.semanticscholar.org/paper/1eae364e74a1af1c0c5ed7f073120e8a7a8f3e31,
1525,Starfysh reveals heterogeneous spatial dynamics in the breast tumor microenvironment,"Spatially-resolved gene expression profiling provides valuable insight into tissue organization and cell-cell crosstalk; however, spatial transcriptomics (ST) lacks single-cell resolution. Current ST analysis methods require single-cell RNA sequencing data as a reference for a rigorous interpretation of cell states and do not utilize associated histology images. Significant sample variation further complicates the integration of ST datasets, which is essential for identifying commonalities across tissues or altered cellular wiring in disease. Here, we present Starfysh, the first comprehensive computational toolbox for joint modeling of ST and histology data, dissection of refined cell states, and systematic integration of multiple ST datasets from complex tissues. Starfysh uses an auxiliary deep generative model that incorporates archetypal analysis and any known cell state markers to avoid the need for a single-cell-resolution reference in characterizing known or novel tissue-specific cell states. Additionally, Starfysh improves the characterization of spatial dynamics in complex tissues by leveraging histology images and enables the comparison of niches as spatial “hubs” across tissues. Integrative analysis of primary estrogen receptor-positive (ER+) breast cancer, triple-negative breast cancer (TNBC), and metaplastic breast cancer (MBC) tumors using Starfysh led to the identification of heterogeneous patient- and disease-specific hubs as well as a shared stromal hub with varying spatial orientation. Our results show the ability to delineate the spatial co-evolution of tumor and immune cell states and their crosstalk underlying intratumoral heterogeneity in TNBC and revealed metabolic reprogramming shaping immunosuppressive hubs in aggressive MBC. Starfysh is publicly available (https://github.com/azizilab/starfysh).",2022-11-24,https://www.semanticscholar.org/paper/76057f3f3a5816e004477837b25e742b1fa7d7f1,bioRxiv
3451,Bidding strategically with budget-constraints in sequential auctions,"We examine models of sequential auctions with budget-constrained bidders. These types of auctions are of particular importance in e-commerce. Our models are simple, but rich enough to posess interesting features such as bid-jamming, which is also found in internet search engine auctions. We apply adversarial analysis to find fixed-point bidding strategies which are distribution-free and randomized strategies for when the wealth of the bidder is low relative to her competitors.",,https://www.semanticscholar.org/paper/bc0141dff607c12957b94885569cd859134cf087,
516,EXPLORING AN UNKNOWN GRAPH (Extended Abstract),"We wish to explore all edges of an unknown directed, strongly connected graph. At each point we have a map of all nodes and edges we have visited, we can recognize these nodes and edges if we see them again, and we know how many unexplored edges emanate from each node we have visited (but we cannot tell where each leads until we follow it). We wish to minimize the ratio of the total number of edges traversed divided by the optimum number of traversals, had we known the graph. For Eulerian graphs this ratio cannot be better than two, and two is achievable by a simple algorithm. In contrast, the ratio is unbounded when the deficiency of the graph (the number of edges that have to be added to make it Eulerian) is unbounded. Our main result is an algorithm that achieves a bounded ratio when the deficiency is bounded; unfortunately, the ratio is ex- ponential in the deficiency. We also show that, when partial information about the graph is available, min- imizing the worst-case ratio is PSPACE-complete.",,https://www.semanticscholar.org/paper/9945344efd5e75b0e371b56fc42e65885b2ebe64,IEEE Annual Symposium on Foundations of Computer Science
1741,Applications of latent variable models in modeling influence and decision making,"The past twenty years have seen an avalanche of digital information which is overwhelming people in industry, government, and academics. This avalanche is two-sided: while the past decade has seen an onslaught of digitized records – as governments, publishers, and researchers race to make their records digital, the electronic and software tools for computationally analyzing this data have quickly evolved to face this challenge. 
Many of these challenges evolve around recurring patterns, including the presence of text, bits of information about pairs of items, and sequential observations. In this work we present several methods to address these challenges in data analysis which take advantage of these recurring patterns. 
We begin with a method for identifying influential documents in a collection which evolves over time. We demonstrate that by encoding our assumptions about influential documents in a statistical model of the changes in textual themes, we are able to provide an alternative bibliometric which provides results consistent with—yet different from—traditional metrics of influence such as citation counts. 
We then introduce a model for measuring the relationships between pairs of countries over time. We will demonstrate that this model is able to learn meaningful relationships between countries which is extraordinarily consistent across different human labels. 
We next address limitations in existing models of legislative voting. In one extention we predict legislators' votes by using the text of the bills they are voting on combined with individual legislators' past voting behavior. We then introduce a method for inferring these lawmakers' positions on specific issues. 
A recurring theme in the methods we present is that by using a small set of statistical primitives, we are able to apply known (or mildly adapted) methods to new problems. Several advances in the past few decades in statistical modeling will make the development and discussion of our models easier, as they will provide both this set of primitives (which can be interchanged easily) and the tools for working with them. As a final contribution, we describe a new method for fitting a statistical model with variational inference, without the time investment typically required of practitioners.",,https://www.semanticscholar.org/paper/e5d1b7dfe1327599a871f73431ced4cf444ab03b,
882,Expressing Combinatorial Optimization Problems by Linear Programs (Extended Abstract),,,https://www.semanticscholar.org/paper/37f59817e1bff35eb8c68f8b73a9781746075efb,Symposium on the Theory of Computing
2314,Interleukin-1 expression by neutrophils in rheumatoid arthritis.,"OBJECTIVE--To determine if neutrophils from blood and synovial fluid of patients with rheumatoid arthritis and other joint arthropathies express interleukin-1 beta mRNA. METHODS--RNA was isolated from neutrophils from patient and control blood, and synovial fluid of patients, probed in northern blots, and quantified by densitometry. It was also isolated and analysed from control blood neutrophils after incubation in vitro with granulocyte macrophage colony stimulating factor (GM-CSF). RESULTS--Neutrophils from the synovial fluid of patients with rheumatoid arthritis contained low levels of mRNA for interleukin-1 beta--between 0.1 and 2% of those observed during stimulation of control neutrophils with GM-CSF for one hour. Higher levels (4-40% of the maximal GM-CSF values) were observed in blood neutrophils from patients with rheumatoid arthritis. CONCLUSIONS--Neutrophils contribute to the cytokine network in rheumatoid arthritis. In some circumstances, activation of transcription may occur within the circulation of these patients.",1995-11-01,https://www.semanticscholar.org/paper/949adcc803a7c3a9c15ba40b07cba056b376fa8c,Annals of the Rheumatic Diseases
3459,An O(n5/2log n) Algorithm for the Rectilinear Minimum Link-Distance Problem,"In this paper we consider the Rectilinear Minimum Link-Distance Problem in Three Dimensions. The problem is well studied in two dimensions, but is relatively unexplored in higher dimensions. We solve the problem in O(βn log n) time, where n is the number of corners among all obstacles, and β is the size of a BSP decomposition of the space containing the obstacles. It has been shown that in the worst case β = Θ(n), giving us an overall worst case time of O(n log n). Previously known algorithms have had worst-case running times of Ω(n).",,https://www.semanticscholar.org/paper/dc090a82008c8cacf08ce67142a0f875e7fd484d,Canadian Conference on Computational Geometry
952,"Offset of openings in optic nerve head canal at level of Bruch’s membrane, anterior sclera, and lamina cribrosa",,2021-04-12,https://www.semanticscholar.org/paper/4ff9886ebcb0a816da68b077ba70b279382ced7c,Scientific Reports
1424,Results of the Cryogeni Dark Matter,,,https://www.semanticscholar.org/paper/a90ca36b36d2c47cd265d509582e5dbc8c4a6f1b,
774,Checking LTL properties of recursive Markov chains,"We present algorithms for the qualitative and quantitative model checking of linear temporal logic (LTL) properties for recursive Markov chains (RMCs). Recursive Markov chains are a natural abstract model of procedural probabilistic programs and related systems involving recursion and probability. For the qualitative problem (""given a RMC A and an LTL formula /spl phi/, do the computations of A satisfy /spl phi/ almost surely?) we present an algorithm that runs in polynomial space in A and exponential time in /spl phi/. For several classes of RMCs, including RMCs with one exit (a special case that corresponds to well-studied probabilistic systems, e.g., multi-type branching processes and stochastic context-free grammars) the algorithm runs in polynomial time in A and exponential time in /spl phi/. On the other hand, we also prove that the problem is EXPTIME-hard, and hence it is EXPTlME-complete. For the quantitative problem (""does the probability that a computation of A satisfies /spl phi/ exceed a given threshold p?"", or approximate the probability within a desired precision) we present an algorithm that runs in polynomial space in A and exponential space in /spl phi/. For linearly-recursive RMCs, we can compute the exact probability in time polynomial in A and exponential in /spl phi/. These results improve by one exponential, in both the qualitative and quantitative case, the complexity that one would obtain if one first translated the LTL formula to a Buchi automaton and then applied the model checking algorithm for Buchi automata from K. Etessami and M. Yannakakis (2005). Our results combine techniques developed in A. Pnueli and L. D. Zuck. (1993) for analysts of RMCs and in C. Courcoubetis and M. Yannakakis (1995) for LTL model checking of flat Markov Chains, and extend them with new techniques.",2005-09-19,https://www.semanticscholar.org/paper/f5056b97254aa6926c96ba52667ef5945bb2cdc0,International Conference on Quantitative Evaluation of Systems
1541,Conformal Sensitivity Analysis for Individual Treatment Effects,"Estimating an individual treatment effect (ITE) is essential to personalized decision making. However, existing methods for estimating the ITE often rely on unconfoundedness, an assumption that is fundamentally untestable with observed data. To assess the robustness of individual-level causal conclusion with unconfoundedness, this paper proposes a method for sensitivity analysis of the ITE, a way to estimate a range of the ITE under unobserved confounding. The method we develop quantifies unmeasured confounding through a marginal sensitivity model [Ros2002, Tan2006], and adapts the framework of conformal inference to estimate an ITE interval at a given confounding strength. In particular, we formulate this sensitivity analysis problem as a conformal inference problem under distribution shift, and we extend existing methods of covariate-shifted conformal inference to this more general setting. The result is a predictive interval that has guaranteed nominal coverage of the ITE, a method that provides coverage with distribution-free and nonasymptotic guarantees. We evaluate the method on synthetic data and illustrate its application in an observational study.",2021-12-07,https://www.semanticscholar.org/paper/5645f1cc9c3c86091b1eeb58150a68e4f062de27,Journal of the American Statistical Association
2436,Hands-Free Interaction for Augmented Reality in Vascular Interventions,"Vascular interventions are minimally invasive surgical procedures in which a physician navigates a catheter through a patient's vasculature to a desired destination in the patient's body. Since perception of relevant patient anatomy is limited in procedures of this sort, virtual reality and augmented reality systems have been developed to assist in 3D navigation. These systems often require user interaction, yet both of the physician's hands may already be busy performing the procedure. To address this need, we demonstrate hands-free interaction techniques that use voice and head tracking to allow the physician to interact with 3D virtual content on a head-worn display while making both hands available intraoperatively. Our approach supports rotation and scaling of 3D anatomical models that appear to reside in the surrounding environment through small head rotations using first-order control, and rigid body transformation of those models using zero-order control. This allows the physician to easily manipulate a model while it stays close to the center of their field of view.",2018-03-01,https://www.semanticscholar.org/paper/78f728321e5547a472356deb49f94fda0bab6ad6,IEEE Conference on Virtual Reality and 3D User Interfaces
3576,The Design of C++0x,Mixtures of particulate glass are separated into their species by magnetic forces or a combination of magnetic and acceleration forces such as gravity or centripetal acceleration.,,https://www.semanticscholar.org/paper/d0dc7cc39d0f8f2b8bf3e4eca2e457d96ae8e702,
2182,The clinical significance of antinuclear antibodies and specific autoantibodies in juvenile and adult systemic lupus erythematosus patients.,"BACKGROUND
Juvenile systemic lupus erythematosus (JSLE) and adult SLE (ASLE) patients present with different clinical manifestations, but it is unknown if there are differences in their antinuclear autoantibody (ANA) profiles or if staining patterns are associated with specific autoantibodies and clinical manifestations.


OBJECTIVE
To determine whether distinct types and numbers of ANA-staining patterns are associated with specific autoantibodies and clinical manifestations in JSLE and ASLE patients.


METHODS
A retrospective study was performed in Thai children (n = 146) and adults (n = 180) diagnosed with SLE using the Systemic Lupus International Collaborating Clinics classification criteria.


RESULTS
JSLE patients with a homogeneous pattern of staining and anti-dsDNA or anti-nucleosome antibodies in serum, developed renal involvement, leukopenia and acute/subacute cutaneous LE. Coarse speckled pattern with anti-RNP or anti-Sm showed thrombocytopenia and renal involvement in JSLE patients, but leukopenia in both groups. JSLE patients with fine-coarse speckled pattern and anti-RNP, anti-Sm, anti-Ro-52 or anti-SSA developed leukopenia, thrombocytopenia and renal involvement, whilst hemolytic anemia and serositis were commonly found in those with anti-Ro-52. Median SLEDAI score was higher in JSLE than ASLE patients.


CONCLUSION
Detailed ANA-staining patterns with specific autoantibodies show particular clinical manifestations and hence prompt further clinical investigations in both JSLE and ASLE patients. Therefore, this study demonstrates that distinct patterns of ANA staining and specific autoantibodies are clinically important in both children and adults with SLE.",2019-04-23,https://www.semanticscholar.org/paper/99efac3a8d9b76843d9dc128aab60ab8eef16065,Asian Pacific Journal of Allergy and Immunology
1129,Double parton interactions in γ+3 jet events in pp̄ collisions at √s=1.96TeV,We have used a sample of gamma + 3 jets events collected by the D0 experiment with an integrated luminosity of about 1 fb(-1) to determine the fraction of events with double parton scattering (f(DP ...,2010-03-01,https://www.semanticscholar.org/paper/5b07b66c96c70a5787fe9d4bfd01ec972f147486,
2215,Interferon gene expression signature in neutrophils from RA patients pre- and post- anti-TNF therapy.,,,https://www.semanticscholar.org/paper/bff667bfd0a846682864737c995dd31204b3eeb4,
670,Solving Probability and Statistics Problems by Program Synthesis,"We solve university level probability and statistics questions by program synthesis using OpenAI's Codex, a Transformer trained on text and fine-tuned on code. We transform course problems from MIT's 18.05 Introduction to Probability and Statistics and Harvard's STAT110 Probability into programming tasks. We then execute the generated code to get a solution. Since these course questions are grounded in probability, we often aim to have Codex generate probabilistic programs that simulate a large number of probabilistic dependencies to compute its solution. Our approach requires prompt engineering to transform the question from its original form to an explicit, tractable form that results in a correct program and solution. To estimate the amount of work needed to translate an original question into its tractable form, we measure the similarity between original and transformed questions. Our work is the first to introduce a new dataset of university-level probability and statistics problems and solve these problems in a scalable fashion using the program synthesis capabilities of large language models.",2021-11-16,https://www.semanticscholar.org/paper/f7987fa2aadc0b368c185dc4d2fdb1337a202c32,arXiv.org
1849,Generative Models for Decoding Real-Valued Natural Experience in FMRI,"Functional Magnetic Resonance Imaging (FMRI) provides an unprecedented window into the complex functioning of the human brain, typically detailing the activity of thousands of voxels for hundreds of time points. The interpretation of FMRI is complicated, however, because of the unknown connection between the hemodynamic response and neural activity, and the unknown spatiotemporal characteristics of the cognitive patterns themselves.",,https://www.semanticscholar.org/paper/b27f9ee1d24407a88681e1346b6a9075d43e05a6,
2978,Distinct Epigenomic Features in End-Stage Failing Human Hearts,"Background— The epigenome refers to marks on the genome, including DNA methylation and histone modifications, that regulate the expression of underlying genes. A consistent profile of gene expression changes in end-stage cardiomyopathy led us to hypothesize that distinct global patterns of the epigenome may also exist. Methods and Results— We constructed genome-wide maps of DNA methylation and histone-3 lysine-36 trimethylation (H3K36me3) enrichment for cardiomyopathic and normal human hearts. More than 506 Mb sequences per library were generated by high-throughput sequencing, allowing us to assign methylation scores to ≈28 million CG dinucleotides in the human genome. DNA methylation was significantly different in promoter CpG islands, intragenic CpG islands, gene bodies, and H3K36me3-enriched regions of the genome. DNA methylation differences were present in promoters of upregulated genes but not downregulated genes. H3K36me3 enrichment itself was also significantly different in coding regions of the genome. Specifically, abundance of RNA transcripts encoded by the DUX4 locus correlated to differential DNA methylation and H3K36me3 enrichment. In vitro, Dux gene expression was responsive to a specific inhibitor of DNA methyltransferase, and Dux siRNA knockdown led to reduced cell viability. Conclusions— Distinct epigenomic patterns exist in important DNA elements of the cardiac genome in human end-stage cardiomyopathy. The epigenome may control the expression of local or distal genes with critical functions in myocardial stress response. If epigenomic patterns track with disease progression, assays for the epigenome may be useful for assessing prognosis in heart failure. Further studies are needed to determine whether and how the epigenome contributes to the development of cardiomyopathy.",2011-11-29,https://www.semanticscholar.org/paper/293a1b0812f5dc2b130927873646f0828137dcfe,Circulation
772,Efficiently computing succinct trade-off curves,,2005-12-08,https://www.semanticscholar.org/paper/9fef816c3eebd04071bd8a9ab3524ea507eab8b1,Theoretical Computer Science
1705,Supplementary Materials for Distance Dependent Infinite Latent Feature Models,"In Section 1, we present proofs of the propositions and lemmas that appeared in the main paper. In Section 2, we present a Markov chain Monte Carlo algorithm for approximate inference. Finally, in Section 3, we present analysis of data in which a non-exchangeable model might be expected to help, but does not.",,https://www.semanticscholar.org/paper/84435b23acdd60cd6219bb7fe90405efa4b85d03,
1054,Simulations of events for the LUX-ZEPLIN (LZ) dark matter experiment,,2020-01-25,https://www.semanticscholar.org/paper/bc42e1127b1dcbd11146d8a829cf9f5e0bd1e3a2,Astroparticle physics
2121,建構半導體製程改善之失效模式與效應分析架構及其應用硏究,摘要 本文整合失效模式、效應與關鍵性分析、故障樹及事件樹等三種分析方法，建立半導體製程改善研究架構，並探討其中每個步驟的執行方式與所需資訊。並以某半導體廠爲實證研究對象，利用三個實例，探討如何利用本研究架構以改善半導體製程技術，以及討論實際推動時，所需條件及其效益，最後則以後續研究作爲結論。本研究成果除了作爲半導體製程技術研發與改善之輔助，並將各個製程失效機率及失效後之成本損失計算納入分析架構當中，用以定義出那些是關鍵性製程及估算製程進行改善後之成本-效益，因此，可以當成半導體製程技術知識整理與管理之重要工具。,2000-03-01,https://www.semanticscholar.org/paper/6377f3553b9743c37e5b78a9d338ed084e44d149,
1275,Surface Event Rejection Using Phonon Information in CDMS,,2007-11-01,https://www.semanticscholar.org/paper/425a453b975612cbfd548a7a9f32f02f1efb3e8b,
1546,Assessing the Effects of Friend-to-Friend Texting onTurnout in the 2018 US Midterm Elections,"Recent mobile app technology lets people systematize the process of messaging their friends to urge them to vote. Prior to the most recent US midterm elections in 2018, the mobile app Outvote randomized an aspect of their system, hoping to unobtrusively assess the causal effect of their users’ messages on voter turnout. However, properly assessing this causal effect is hindered by multiple statistical challenges, including attenuation bias due to mismeasurement of subjects’ outcomes and low precision due to two-sided non-compliance with subjects’ assignments. We address these challenges, which are likely to impinge upon any study that seeks to randomize authentic friend-to-friend interactions, by tailoring the statistical analysis to make use of additional data about both users and subjects. Using meta-data of users’ in-app behavior, we reconstruct subjects’ positions in users’ queues. We use this information to refine the study population to more compliant subjects who were higher in the queues, and we do so in a systematic way which optimizes a proxy for the study’s power. To mitigate attenuation bias, we then use ancillary data of subjects’ matches to the voter rolls that lets us refine the study population to one with low rates of outcome mismeasurement. Our analysis reveals statistically significant treatment effects from friend-to-friend mobilization efforts ( 8.3, CI = (1.2, 15.3)) that are among the largest reported in the get-out-the-vote (GOTV) literature. While social pressure from friends has long been conjectured to play a role in effective GOTV treatments, the present study is among the first to assess these effects experimentally.",2021-04-19,https://www.semanticscholar.org/paper/933393df9068059dd49f555eaa67f5f9ce58aeec,The Web Conference
1518,On the Misspecification of Linear Assumptions in Synthetic Control,"The synthetic control (SC) method is a popular approach for estimating treatment effects from observational panel data. It rests on a crucial assumption that we can write the treated unit as a linear combination of the untreated units. This linearity assumption, however, can be unlikely to hold in practice and, when violated, the resulting SC estimates are incorrect. In this paper we examine two questions: (1) How large can the misspecification error be? (2) How can we limit it? First, we provide theoretical bounds to quantify the misspecification error. The bounds are comforting: small misspecifications induce small errors. With these bounds in hand, we then develop new SC estimators that are specially designed to minimize misspecification error. The estimators are based on additional data about each unit, which is used to produce the SC weights. (For example, if the units are countries then the additional data might be demographic information about each.) We study our estimators on synthetic data; we find they produce more accurate causal estimates than standard synthetic controls. We then re-analyze the California tobacco-program data of the original SC paper, now including additional data from the US census about per-state demographics. Our estimators show that the observations in the pre-treatment period lie within the bounds of misspecification error, and that the observations post-treatment lie outside of those bounds. This is evidence that our SC methods have uncovered a true effect.",2023-02-24,https://www.semanticscholar.org/paper/b7a9a235112ad1b3712d97a740704f742ffbfac1,
2530,Poster: Shake menus: Towards activation and placement techniques for prop-based 3D graphical menus,"Shake menus are a novel method for activating, displaying, and selecting options presented relative to a tangible object or manipulator in a 3D user interface. They provide ready-to-hand interaction, including facile selection and placement of objects. We present the technique, several alternative methods for presenting shake menus (world-referenced, display-referenced, and object-referenced), and an evaluation of menu placement.",2009-03-14,https://www.semanticscholar.org/paper/2df9639cea73c98390f6c8dd152cb4888cbd835b,IEEE Symposium on 3D User Interfaces
1283,Search for scalar neutrino superpartners in e+mu final states in pp collisions at sqrt[s]=1.96 TeV.,"We report a search for R-parity-violating production and decay of sneutrino particles in the emu final state with 1.04+/-0.06 fb-1 of data collected with the D0 detector at the Fermilab Tevatron Collider in 2002-2006. Good agreement between the data and the standard model prediction is observed. With no evidence for new physics, we set limits on the R-parity-violating couplings lambda'311 and lambda312 as a function of the sneutrino mass.",2007-11-01,https://www.semanticscholar.org/paper/895a6500e064a5afe6f5772af548aa8ba5fbafb1,Physical Review Letters
239,The Complexity of Fairness Through Equilibrium,"Competitive equilibrium from equal incomes (CEEI) is a well-known fair allocation mechanism with desirable fairness and efficiency properties; however, with indivisible resources, a CEEI may not exist [Foley 1967; Varian 1974; Thomson and Varian 1985]. It was shown in Budish [2011] that in the case of indivisible resources, there is always an allocation, called A-CEEI, that is approximately fair, approximately truthful, and approximately efficient for some favorable approximation parameters. A heuristic search that attempts to find this approximation is used in practice to assign business school students to courses. In this article, we show that finding the A-CEEI allocation guaranteed to exist by Budish’s theorem is PPAD-complete. We further show that finding an approximate equilibrium with better approximation guarantees is even harder: NP-complete.",2013-12-21,https://www.semanticscholar.org/paper/8451b013e29d325e795d45b2f9b2105b55d49a9c,ACM Trans. Economics and Comput.
1042,"The Golfer's Handbook: Tips, Wit, and Wisdom to Inform and Entertain",,2008-09-22,https://www.semanticscholar.org/paper/2293242a24cc208b1d50aa9dfdd477b9083fbe6c,
2689,A touring machine: Prototyping 3D mobile augmented reality systems for exploring the urban environment,,1997-10-13,https://www.semanticscholar.org/paper/dc9404cb021d7f859271de89aec145dd8b0fee87,Digest of Papers. First International Symposium on Wearable Computers
2793,Galectin‐3 regulates inflammasome activation in cholestatic liver injury,"Macrophage activation is an important feature of primary biliary cholangitis (PBC) pathogenesis and other cholestatic liver diseases. Galectin‐3 (Gal3), a pleiotropic lectin, is produced by monocytic cells and macrophages. However, its role in PBC has not been addressed. We hypothesized that Gal3 is a key to induce NOD‐like receptor family, pyrin domain containing 3 (NLRP3) inflammasome in macrophages and in turn to propagate proinflammatory IL‐17 signaling. In liver tissues from patients with PBC and dnTGF‐βRII mice, a model of autoimmune cholangitis, the expression of Gal3, NLRP3, and the adaptor protein adaptor apoptosis‐associated speck like protein was induced, with the downs tream activation of caspase‐1 and IL‐1β. Inwild‐typehepaticmacrophages, deoxycholic acid induced the association of Gal3 and NLRP3with direct activation of the inflammasome, resulting in an increase in IL‐1β. Downstreamretinoid‐related orphan receptor CmRNA, IL‐17A, and IL‐17Fwere induced. In Gal3‐/‐ macrophages, no inflammasome activation was detected. To confirm the key role of Gal3 in the pathogenesis of cholestatic liver injury, we generated dnTGF‐βRII/galectin‐3‐/ (dn/Gal3‐/) mice, which showed impaired inflammasome activation alongwith significantly improved inflammation and fibrosis. Taken together, our data point to a novel role of Gal3 as an initiator of inflammatory signaling in autoimmune cholangitis, mediating the activation of NLRP3 inflammasome and inducing IL‐17 proinflammatory cascades. These studies provide a rationale to target Gal3 in autoimmune cholangitis and potentially other cholestatic diseases.—Tian, J., Yang, G., Chen, H.‐Y., Hsu, D. K., Tomilov, A., Olson, K.A., Dehnad, A., Fish, S. R., Cortopassi, G.,Zhao, B., Liu, F.‐T., Gershwin, M.E., Török, N. J., Jiang, J. X. Galectin‐3 regulates inflammasome activation in cholestatic liver injury. FASEB J. 30, 4202–4213 (2016). www.fasebj.org",2016-09-14,https://www.semanticscholar.org/paper/56e91c5299d90f6d375625def0937cc7b195f2d7,The FASEB Journal
2950,An Efficient Multiple-Testing Adjustment for eQTL Studies that Accounts for Linkage Disequilibrium between Variants.,,2016-01-07,https://www.semanticscholar.org/paper/72ebcb025662d71d3d67f1d3776aea2d85af1dd5,American Journal of Human Genetics
3329,"The ecology of female social behavior in horses, zebras, and asses",,,https://www.semanticscholar.org/paper/8e7b662a55c5d87cc775d55bbf5c387c7f7f751a,
3651,Parametrized Types for C++,"Type parameterization is the ability to defrne a type in terms of another, unspecifled, type. Versions of the parameterized type may then be created for several particular parameter types. A language supporting type parameterization allows specification ofgeneral container types such as list, vector, and associative array where the specific type of the elements is left as a parameter. Thus, a parameterized class specifies an unbounded set of related types; for example: list of int, list of name, list of shape, etc. Type parameterization is one way of making a language more extensible. In the context of C++, the problems are 1. Can type parameterization be easy to use? 2. Can objects of a parameterized type be used as efficiently as objects of a ""hand-coded"" type? 3. Can a general form of parameterized types be integrated into C++? 4. Can parameterized types be implemented so that the compilation and linking speed is similar to that achieved by a compilation system that does not support type parameterization? 5. Can such a compilation system be simple and portable? @ Computing Systems,Yol.2. No. I . Winter 1989 55 56 A design is presented for which the answer to all of these questions is yes. The implementation of this scheme is a fairly simple extension of current C++ implementations. v/ARNING: The scheme for providing parameterized types described here is not implemented. It is not part ofthe C++ language, nor is there any guarantee that it ever will be.",,https://www.semanticscholar.org/paper/7386ca6873e002ea50d0f108391f667ab4adbd1a,Computing Systems
3659,The Evolution of C,,,https://www.semanticscholar.org/paper/639aedc1ddda36feaeed6640f1f00f8033fe05e0,
3743,“ I Like the Way You Think ! ” Inspecting the Internal Logic of Recurrent Neural Networks,,,https://www.semanticscholar.org/paper/4974f16af328e774d0a9e53a366bfdd738488b90,
3003,Design and Verification of the Arm Confidential Compute Architecture,"The increasing use of sensitive private data in computing is matched by a growing concern regarding data privacy. System software such as hypervisors and operating systems are supposed to protect and isolate applications and their private data, but their large codebases contain many vulnerabilities that can risk data conﬁdentiality and integrity. We introduce Realms, a new abstraction for conﬁdential computing to protect the data conﬁdentiality and integrity of virtual machines. Hardware creates and enforces Realm world, a new physical address space for Realms. Firmware controls the hardware to secure Realms and handles requests from untrusted system software to manage Realms, including creating and running them. Untrusted system software retains control of the dynamic allocation of memory to Realms, but cannot access Realm memory contents, even if run at a higher privileged level. To guarantee the security of Realms, we veriﬁed the ﬁrmware, introducing novel veriﬁcation techniques that enable us to prove, for the ﬁrst time, the security and correctness of concurrent software with hand-over-hand locking and dynamically allocated shared page tables, data races in kernel code running on relaxed memory hardware, integrated C and Arm assembly code calling one another, and untrusted software being in full control of allocating system resources. Realms are included in the Arm Conﬁdential Compute Architecture.",,https://www.semanticscholar.org/paper/882cc7dfb01a96ae08388e4bac3bdcc5caffdf01,USENIX Symposium on Operating Systems Design and Implementation
1660,Operator Variational Inference,"Variational inference is an umbrella term for algorithms which cast Bayesian inference as optimization. Classically, variational inference uses the Kullback-Leibler divergence to define the optimization. Though this divergence has been widely used, the resultant posterior approximation can suffer from undesirable statistical properties. To address this, we reexamine variational inference from its roots as an optimization problem. We use operators, or functions of functions, to design variational objectives. As one example, we design a variational objective with a Langevin-Stein operator. We develop a black box algorithm, operator variational inference (OPVI), for optimizing any operator objective. Importantly, operators enable us to make explicit the statistical and computational tradeoffs for variational inference. We can characterize different properties of variational objectives, such as objectives that admit data subsampling---allowing inference to scale to massive data---as well as objectives that admit variational programs---a rich class of posterior approximations that does not require a tractable density. We illustrate the benefits of OPVI on a mixture model and a generative model of images.",2016-10-27,https://www.semanticscholar.org/paper/97fcee01d9777372a3d8966ab7cd4c17e3a6a5ca,Neural Information Processing Systems
1132,Search for the Standard Model Higgs Boson in theChannel inofCollisions at,,2010-02-18,https://www.semanticscholar.org/paper/7fdc399d88d769dfc5c75cbf0bc098567a07a067,
271,Comment on “Computing Correlated Equilibria in Multi-Player Games”,"Noah Stein, Pablo Parrilo, and Asu Ozdaglar pointed out an error on page 10, lines 13-14 of our paper “Computing Correlated Equilibria in Multi-Player Games” (Journal of the ACM, 2008). The incorrect phrase is “...which contradicts our assumption that the violating y is within the current ellipsoid”. This conclusion would be valid for the bounding ellipsoid used for the original dual program (D), but could be incorrect for the larger bounding ellipsoid that is required for the modified dual program (D’) because of its increased bit complexity. This error is not serious and can be rectified in various ways. Stein, Parillo, and Ozdaglar proposed explicitly bounding the variables of the original dual program (D) by an appropriately large number. The most elegant fix, described next, was suggested by Albert Xin Jiang and Kevin Leyton-Brown (see their arXiv article 1011.0253). Recall that Lemma 3.2 shows that, given a candidate dual solution y ≥ 0, one can compute efficiently a product distribution x over outcomes such that xU y = 0. Then, by going through the players one at a time and repeatedly using the method of conditional expectations, x can be converted efficiently into a pure strategy profile s such that U s y ≥ 0 (where U s is the constraint of (D) that corresponds to s). This constraint is violated at y. Proceeding as in the paper but with these “purified” violated constraints yields a modified dual (D’) with bit complexity no larger than that of (D), and the bounding ellipsoid for (D) can now be safely reused for (D’). Solving the new modified primal (P’) yields a correlated equilibrium. This corrected algorithm computes a correlated equilibrium that has polynomial support, an improvement over the less explicit “polynomial combination of products” representation that was produced by the original algorithm.",,https://www.semanticscholar.org/paper/ffc12169b4b58770e57937426e4dd1c9248acb85,
2851,Galectin‐3 Stimulates Preadipocyte Proliferation and Is Up‐regulated in Growing Adipose Tissue,,2007-01-01,https://www.semanticscholar.org/paper/844010c5c73ad83c601bebddc752c3d0cf2be3fd,Obesity
1941,Overall Space Effectiveness (OSE) for Enhancing Fab Space Productivity,"Due to increasing global competition, effective resource utilization is critical for maintaining competitive advantages. However, little research has been done to address space utilization of wafer fabrication facility. This paper aims to design a novel index, overall space effectiveness (OSE), to diagnose the fab layouts and identify directions for improving space usage effectiveness to enhance the overall space productivity as partial effort for total resources management. Furthermore, the proposed OSE can be extended to incorporate other critical performance indices such as cycle time, throughput, and revenue for effective management. Focusing on real settings of a leading semiconductor manufacturing company, a number of case studies were conducted and compared. The results have shown OSE gaps among various fabs and the proposed OSE can effectively derive improvement directions. This paper concludes with discussions on value propositions and future research directions.",2016-07-07,https://www.semanticscholar.org/paper/ff4867b1fe2f256e40e61e283b737aef2843b4f0,IEEE transactions on semiconductor manufacturing
2540,Lets go out: Research in outdoor mixed and augmented reality,,2009-10-19,https://www.semanticscholar.org/paper/fc0c54d72ba200268c9769469f178f134bba376b,2009 8th IEEE International Symposium on Mixed and Augmented Reality
1371,Search for 3- and 4-body decays of the scalar top quark in pp̄ collisions at √s=1.8 TeV,,2004-02-19,https://www.semanticscholar.org/paper/63c4451630c61c91b0974d4e5da79fac49032ed3,
3747,Deep Neural Inspection Using DeepBase,"There is currently excellent software and hardware infrastructure for every part of the neural network (NN) development lifecycle—creating models, training them, evaluating their accuracy, and deploying them. This has helped drive the excitement towards developing and deploying NN models in nearly every discipline and industry. Although neural networks today are largely evaluated on held-out test data, this does not guarantee models will behave reliably and correctly when deployed in practice. Models may encounter new situations that are statistically different from their training set and testing set, and researchers need to understand how their trained models will behave.",,https://www.semanticscholar.org/paper/dad2459b0488560ec9ce351e6b797e4beee29f85,
313,Balancing traffic load in wireless networks with curveball routing,"We address the problem of balancing the traffic load in multi-hop wireless networks. We consider a point-to-point communicating network with a uniform distribution of source-sink pairs. When routing along shortest paths, the nodes that are centrally located forward a disproportionate amount of traffic. This translates into increased congestion and energy consumption. However, the maximum load can be decreased if the packets follow curved paths. We show that the optimum such routing scheme can be expressed in terms of geometric optics and computed by linear programming. We then propose a practical solution, which we call Curveball Routing which achieves results not much worse than the optimum.
 We evaluate our solution at three levels of fidelity: a Java high-level simulator, the ns2 simulator, and the Intel Mirage Sensor Network Testbed. Simulation results using the high-level simulator show that our solution successfully avoids the crowded center of the network, and reduces the maximum load by up to 40%. At the same time, the increase of the expected path length is minimal, i.e., only 8% on average. Simulation results using the ns2 simulator show that our solution can increase throughput on moderately loaded networks by up to 15%, while testbed results show a reduction in peak energy usage by up to 25%. Our prototype suggests that our solution is easily deployable.",2007-09-09,https://www.semanticscholar.org/paper/d44805a895d8371526b226a3dbb1890d3974a03a,ACM Interational Symposium on Mobile Ad Hoc Networking and Computing
2316,The cell biology of phagocytes.,,1995-11-01,https://www.semanticscholar.org/paper/f6ed9047503d7b668ce5112362c20c616683db6a,Immunology today (Amsterdam. Regular ed.)
2697,Language-level support for exploratory programming of distributed virtual environments,"We describe COTERIE, a toolkit that provides languagelevel support for building distributed virtual environments. COTERIE is based on the distributed data-object paradigm for distributed shared memory. Any data object in COTERIE can be declared to be a Shared Object that is replicated fully in any process that is interested in it. These Shared Objects support asynchronous data propagation with atomic serializable updates, and asynchronous notification of updates. COTERIE is built in Modula-3 and uses existing Modula-3 packages that support an integrated interpreted language, multithreading, and 3D animation. Unlike other VE toolkits, COTERIE is based on a set of general-purpose parallel and distributed language concepts designed with the needs of virtual environments in mind. We summarize the requirements that we identified for COTERIE, describe its implementation, compare it with other toolkits, and provide examples that show COTERIE’s advantages.",1996-11-01,https://www.semanticscholar.org/paper/cc6a82c166bf7098eb7fc9152c4f485065c34582,ACM Symposium on User Interface Software and Technology
1385,PERFORMANCE AND BACKGROUND MEASUREMENTS OF THE CDMS II TOWER I DETECTORS AT THE STANFORD UNDERGROUND FACILITY,"T. SAAB, P.L. BRINK, L. BAUDIS, B. CABRERA, J.P. CASTLE, ANDC. CHANGDepartment of Physics, Stanford University, Stanford, CA 94350, USAR. J. GAITSKELL AND J.P. THOMSONDepartment of Physics, Brown University, Providence, RI 02912, USAD.S. AKERIB, D. DRISCOLL, S. KAMAT, T.A. PERERA, R.W. SCHNEEAND G. WANGDepartment of Physics, Case Western Reserve University, Cleveland, OH44106, USAM. B. CRISLER, R. DIXON AND D. HOLMGRENFermi National Accelerator Laboratory, Batavia, IL 60510, USAJ.H. EMES, R.R. ROSS, A. SMITH AND G.W. SMITHLawrence Berkeley National Laboratory, Berkeley, CA 94720, USAJ.M. MARTINISNational Institute of Standards and Technology, Boulder, CO 80303, USAT. SHUTTDepartment of Physics, Princeton University, Princeton, NJ 08544, USAB.A. YOUNGDepartment of Physics, Santa Clara University, Santa Clara, CA 95053, USAM.S. ARMEL, V. MANDIC, P. MEUNIER, W. RAU, B. SADOULET ANDD.N. SEITZDepartment of Physics, University of California, Berkeley, Berkeley, CA 94720,",2003-05-01,https://www.semanticscholar.org/paper/6c3397a3c6d4df1a989c715ccfa0b472fea6c048,
1369,"UvA-DARE (Digital Academic Repository) Search for narrow tt-bar resonances in pp-bar collisions at sqrt(s) = 1.8 TeV Abazov,","Disclaimer/Complaints regulations If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. In case of a legitimate complaint, the Library will make the material inaccessible and/or remove it from the website. Please Ask the Library: https://uba.uva.nl/en/contact, or a letter to: Library of the University of Amsterdam, Secretariat, Singel 425, 1012 WP Amsterdam, The Netherlands. You will be contacted as soon as possible.",,https://www.semanticscholar.org/paper/5609e0d6d86812f56d53b28d8f73b5d3a2703d45,
751,"Equilibria, Fixed Points, and Complexity Classes","Many models from a variety of areas involve the computation of an equilibrium or fixed point of some kind. Examples include Nash equilibria in games; market equilibria; computing optimal strategies and the values of competitive games (stochastic and other games); stable configurations of neural networks; analysing basic stochastic models for evolution like branching processes and for language like stochastic context-free grammars; and models that incorporate the basic primitives of probability and recursion like recursive Markov chains. It is not known whether these problems can be solved in polynomial time. There are certain common computational principles underlying different types of equilibria, which are captured by the complexity classes PLS, PPAD, and FIXP. Representative complete problems for these classes are, respectively, pure Nash equilibria in games where they are guaranteed to exist, (mixed) Nash equilibria in two-player normal form games, and (mixed) Nash equilibria in normal form games with three (or more) players. This paper reviews the underlying computational principles and the corresponding classes.",2008-02-01,https://www.semanticscholar.org/paper/38a305e7255b1a9a448741a60dbfd3ce290ca910,Symposium on Theoretical Aspects of Computer Science
870,The Analysis of Local Search Problems and Their Heuristics,,1990-02-01,https://www.semanticscholar.org/paper/73de51c19c60539be5aa3d96288676468607d62a,Symposium on Theoretical Aspects of Computer Science
1441,The Liquid Scintillator Neutrino Detector and LAMPF Neutrino Source,,1996-05-07,https://www.semanticscholar.org/paper/a0a73d04f5f3fb2a12258ab8edd9a256d94d70e4,
2705,"Virtual Reality Software and Technology 94, (VRST '94) Held at Institute of Systems Science (ISS), Kent Ridge, Singapore on 23-26 August 1994.","Abstract : A summary of the Virtual Reality Software and Technology 94 conference, conducted August 22-26, 1994 at the National Institute of Science and Technology of Singapore is presented. Abstracts of all presented papers are included, as is a complete list of conference registrants This report is based upon information collected via conference attendance, review of the proceedings, and conversations with other attendees. (AN)",1994-08-23,https://www.semanticscholar.org/paper/346a38d909b05a984f8dfc23d0d6643ba28c7e40,
2227,Relative α1-anti-trypsin deficiency in systemic sclerosis,"Objective. Neutrophil elastase is secreted by neutrophils during activation and circulates in the plasma where it can play a role in inflammation and fibrosis. This study examines the role of neutrophil elastase in SSc, a systemic CTD that is typified by vascular dysfunction, tissue fibrosis and inflammation. Methods. Serum neutrophil elastase and α1-anti-trypsin concentrations were assessed in SSc patients and healthy controls by ELISA. Serum neutrophil elastase activity was assessed by the elastase-dependent conversion of methoxy-succinyl-alanyl-alanyl-prolyl-valyl-p-nitroanilide to p-nitroanilide using a colourimetric assay. Elastase concentration and activity were correlated with clinical disease features. Results. Serum neutrophil elastase concentration and activity were equivalent in patients and controls; however, in SSc serum, there was an increase in elastase activity for each unit of elastase concentration (P = 0.03). This was due to a decrease in serum α1-anti-trypsin concentrations (P = 0.04). Serum elastase concentration (P = 0.03) and activity (P = 0.02) were significantly lower in RNP-positive patients and serum elastase concentrations were lower in ANA-positive patients (P = 0.003). Conclusions. Relative deficiency in serum α1-anti-trypsin concentrations in SSc could have important and pathogenically relevant effects since elastase has pro-inflammatory and pro-fibrotic roles. Elastase inhibitors are available in clinical practice and could represent potential therapeutic options in SSc.",2011-03-30,https://www.semanticscholar.org/paper/22933f51054d844e747fc011821721c263a21ef4,Rheumatology
2381,The cytochromes of Dictyostelium discoideum.,,,https://www.semanticscholar.org/paper/1c6ba45b6b7345bc32df8de227c4beafd987cb95,"Comparative biochemistry and physiology. B, Comparative biochemistry"
682,Learning from data with low intrinsic dimension,"The information explosion of the past few decades has created tremendous opportunities for Machine Learning-based data analysis. Modern data typically possesses a large number of features. Consider the task of predicting the effectiveness of a particular treatment by analyzing a patient's genome. One hopes that by measuring several gene expression levels one can capture relevant information, leading to better predictions. However, the presence of a large number of irrelevant features adds to the statistical and computational complexity of the learning algorithm, without helping the practitioner to solve the task at hand. Indeed, conventional statistical wisdom suggests that in a general setting the learning task becomes significantly more difficult with an increase in the number of features, making it especially difficult to design and analyze learning algorithms for modern, high-dimensional data. 
This dissertation explores a specific way one can cope with this curse of dimension. The key observation is that while modern datasets are represented in high dimensions, they often adhere to some low-dimensional intrinsic structure. This intrinsic structure can manifest itself in several forms: some datasets such as text data have a sparse structure; other datasets such as speech and image articulation data follow a manifold structure. If this intrinsic structure is in fact low-dimensional (that is, has few degrees of freedom), then the complexity of learning algorithms should scale only with data's intrinsic dimensionality. 
In the first part of this dissertation we study how the performance of learning algorithms is affected when the data have a low-dimensional manifold structure. We provide sharp bounds for unsupervised dimensionality reduction, and an improved PAC-learning framework for multiple instance learning in this setting. 
The second part of this dissertation focuses on understanding and formalizing the general phenomenon of low intrinsic dimension. We explore a few notions that can effectively quantify low-dimensional geometric structure in data. We show that unlike traditional notions, some of the new notions are algorithmically verifiable. We can thus test a given dataset and guarantee a learning rate that scales only with its intrinsic dimension.",,https://www.semanticscholar.org/paper/ba99792c31e0cd897eebbeec7f7101c57e1feb16,
2780,Galectin-3 facilitates cell-to-cell HIV-1 transmission by altering the composition of membrane lipid rafts in CD4 T cells.,"Galectin-3 (GAL3) is a β-galactoside-binding lectin expressed in CD4 T cells infected with human immunodeficiency virus-1 (HIV-1). GAL3 promotes HIV-1 budding by associating with ALIX and Gag p6. GAL3 has been shown to localize in membrane lipid rafts in dendritic cells and positively regulate cell migration. HIV-1 spreads between T cells by forming supramolecular structures (virological synapses [VSs]), whose integrity depends on lipid rafts. Here, we addressed the potential role of GAL3 in cell-to-cell transmission of HIV-1 in CD4 T cells. GAL3 expressed in donor cells was more important for facilitating HIV-1 cell-to-cell transfer than GAL3 expressed in target cells. GAL3 was found to be co-transferred with Gag from HIV-1-positive donor to HIV-1-negative target T cells. HIV-1 infection induced translocation of GAL3 together with Gag to the cell-cell interfaces and colocalize with GM1, where GAL3 facilitated VS formation. GAL3 regulated the coordinated transfer of Gag and flotillin-1 into plasma membrane fractions. Finally, depletion of GAL3 reduced the cholesterol levels in membrane lipid rafts in CD4 T cells. These findings provide evidence that endogenous GAL3 stimulates lipid raft components and facilitates intercellular HIV-1 transfer among CD4 T cells, offering another pathway by which GAL3 regulates HIV-1 infection. These findings may inform the treatment of HIV-1 infection based on targeting GAL3 to modulate lipid rafts.",2022-07-05,https://www.semanticscholar.org/paper/61d06c295c147b03cd6d0ee258d9b87ffa28ab0a,Glycobiology
358,Cs294-1 Algorithmic Aspects of Game Theory 4.1 Overview 4.2 Social Choice Theory,"• Dictatorship: ( 1, . . . , n) = 1 • Democracy: When |C| = 2, c1 ( 1, . . . , n) c2 iff |{i : c1 i c2}| ≥ |{i : c2 i c1}|. Theorem 4.3. When |C| = 2, majority voting is the only social welfare functional that is monotone (an agent’s preference change from c1 to c2 does not cause the global preference to change from c2 to c1) and symmetric with respect to agents (permuting the agents does not change the result) and outcomes (reversing the role of the two choices in the input results in the same reversal in the output).",,https://www.semanticscholar.org/paper/a27e17ebab6743876fb9a18d282ee936ea5a6192,
2698,Architectural Anatomy,"We provide an overview of the early stages of three related research projects whose goals are to exploit augmented reality, virtual worlds, and artificial intelligence to explore relationships between perceived architectural space and the structural systems that support it. In one project, we use a see-through head-mounted display to overlay a graphic representation of a building's structural systems on the user's view of a room within the building. This overlaid virtual world shows the out-lines of the concrete joists, beams, and columns surrounding the room, as well as the reinforcing steel inside them, and includes displays from a commercially available structural analysis program. In a related project, the structural view is exposed by varying the opacity of room finishes and concrete in a 3D model of the room and surrounding structure rendered on a conventional CRT. We also describe a hypermedia database, currently under construction, depicting major, twentieth-century American buildings. The interactive, multidisciplinary elements of the database—including structural and thermal analyses, free body diagrams (which show how forces are resisted by portions of a structure under various loading conditions), facsimiles of construction documents, and critical essays—are bound together and made available over the World-Wide Web. Finally, we discuss the relationships among all these projects, and their potential applications to teaching architecture students and to construction, assembly, and repair of complex structures.",,https://www.semanticscholar.org/paper/3ee68de062826570530cd53d2f727054d7f57a5a,Presence: Teleoperators & Virtual Environments
2843,Targeted disruption of the galectin-3 gene results in decreased susceptibility to NNK-induced lung tumorigenesis: an oligonucleotide microarray study,,2008-01-17,https://www.semanticscholar.org/paper/919e2d9d923884b364f5557b3e04140c42d32f5b,Journal of Cancer Research and Clinical Oncology
2678,Of Vampire mirrors and privacy lamps: privacy management in multi-user augmented environments,"We consider the problem of privacy in a 3D multi-user collaborative environment. We assume that information objects are represented by visual icons, and can either be public or private, and that users need effective methods for viewing and manipulating that state. We suggest two methods, which we call vampire mirrorsand privacy lamps, that are unobtrusive, simple, and natural.",1998-11-01,https://www.semanticscholar.org/paper/9ecd146bc3e4df3c39089e3b72ec223667f79076,ACM Symposium on User Interface Software and Technology
3128,Reducing Storage Management Costs via Informed User-Based Policies,"Storage consumption continues to grow rapidly, especially with the popularity of multimedia files. Storage hardware costs represent a small fraction of overall management costs, which include frequent maintenance and backups. Our key approach to reducing total storage management costs is to reduce actual storage consumption. We achieve this in two ways. First, we classify files into categories of importance. Based on these categories, files can be backed up with various frequencies, or even not at all. Second, the system may also reclaim space based on a file’s importance (e.g., transparently compress old files). Our system provides a rich set of policies. We allow users to tailor their disk usage policies, offloading some of the management burdens from the system and its administrators. We have implemented the system and evaluated it. Performance overheads under normal use are negligible. We report space savings on modern systems ranging from 25% to 76%, which result in extending storage lifetimes by 72%.",,https://www.semanticscholar.org/paper/faac81887d6d7db83eda5e43b24c45d9261ef6a9,IEEE Conference on Mass Storage Systems and Technologies
1643,Reparameterization Gradients through Acceptance-Rejection Sampling Algorithms,"Variational inference using the reparameterization trick has enabled large-scale approximate Bayesian inference in complex probabilistic models, leveraging stochastic optimization to sidestep intractable expectations. The reparameterization trick is applicable when we can simulate a random variable by applying a differentiable deterministic function on an auxiliary random variable whose distribution is fixed. For many distributions of interest (such as the gamma or Dirichlet), simulation of random variables relies on acceptance-rejection sampling. The discontinuity introduced by the accept-reject step means that standard reparameterization tricks are not applicable. We propose a new method that lets us leverage reparameterization gradients even when variables are outputs of a acceptance-rejection sampling algorithm. Our approach enables reparameterization on a larger class of variational distributions. In several studies of real and synthetic data, we show that the variance of the estimator of the gradient is significantly lower than other state-of-the-art methods. This leads to faster convergence of stochastic gradient variational inference.",2016-10-18,https://www.semanticscholar.org/paper/0998c939e00af09b49ae04fc78aaca7625a0c895,International Conference on Artificial Intelligence and Statistics
1359,The SuperCDMS Experiment,,,https://www.semanticscholar.org/paper/d3abfdfafe5a48e24c122bbba4b81ff75089a880,
1722,Profile Predictive Inference,"Predictive inference uses a model to analyze a dataset and make predictions about new observations. When a model does not match the data, predictive accuracy suffers. To mitigate this effect, we develop the profile predictive, a predictive density that incorporates the population distribution of data into Bayesian inference. This leads to a practical method for reducing the effect of model mismatch. We extend this method into variational inference and propose a stochastic optimization algorithm, called bumping variational inference (bump-vi). We demonstrate improved predictive accuracy over classical variational inference in two models: a Bayesian mixture model of image histograms and a latent Dirichlet allocation topic model of a text corpus.",2014-11-02,https://www.semanticscholar.org/paper/ef2911c4a5b458ac57c2a30c2e2446ed0af7e762,arXiv.org
242,Alan and I,A personal account of Alan Turing's life and impact.,2012-09-01,https://www.semanticscholar.org/paper/1c0230cc790ab89e3cf197014d960e45aeecc1ed,CACM
3059,"Transparent, lightweight application execution replay on commodity multiprocessor operating systems","We present Scribe, the first system to provide transparent, low-overhead application record-replay and the ability to go live from replayed execution. Scribe introduces new lightweight operating system mechanisms, rendezvous and sync points, to efficiently record nondeterministic interactions such as related system calls, signals, and shared memory accesses. Rendezvous points make a partial ordering of execution based on system call dependencies sufficient for replay, avoiding the recording overhead of maintaining an exact execution ordering. Sync points convert asynchronous interactions that can occur at arbitrary times into synchronous events that are much easier to record and replay.
 We have implemented Scribe without changing, relinking, or recompiling applications, libraries, or operating system kernels, and without any specialized hardware support such as hardware performance counters. It works on commodity Linux operating systems, and commodity multi-core and multiprocessor hardware. Our results show for the first time that an operating system mechanism can correctly and transparently record and replay multi-process and multi-threaded applications on commodity multiprocessors. Scribe recording overhead is less than 2.5% for server applications including Apache and MySQL, and less than 15% for desktop applications including Firefox, Acrobat, OpenOffice, parallel kernel compilation, and movie playback.",2010-06-12,https://www.semanticscholar.org/paper/72657b0428f9b8f705546eb5a9147203a534d8f6,Measurement and Modeling of Computer Systems
1837,The nested Chinese restaurant process and hierarchical topic models,"We present the nested Chinese restaurant process (nCRP), a stochastic process which assigns probability distributions to infinitely-deep, infinitely-branching trees. We show how this stochastic process can be used as a prior distribution in a Bayesian nonparametric model of document collections. Specifically, we present an application to information retrieval in which documents are modeled as paths down a random tree, and the preferential attachment dynamics of the nCRP leads to clustering of documents according to sharing of topics at multiple levels of abstraction. Given a corpus of documents, a posterior inference algorithm finds an approximation to a posterior distribution over trees, topics and allocations of words to levels of the tree. We demonstrate this algorithm on collections of scientific abstracts from several journals. This model exemplifies a recent trend in statistical machine learning--the use of Bayesian nonparametric methods to infer distributions on flexible data structures.",2007-10-03,https://www.semanticscholar.org/paper/ff81ed2ee2d5a67a95d371240f4ba8d01c0ff6da,
2660,Situated documentaries: embedding multimedia presentations in the real world,"We describe an experimental wearable augmented reality system that enables users to experience hypermedia presentations that are integrated with the actual outdoor locations to which they are relevant. Our mobile prototype uses a tracked see-through head-worn display to overlay 3D graphics, imagery, and sound on top of the real world, and presents additional, coordinated material on a hand-held pen computer. We have used these facilities to create several situated documentaries that tell the stories of events that took place on our campus. We describe the software and hardware that underly our prototype system and explain the user interface that we have developed for it.",1999-10-18,https://www.semanticscholar.org/paper/54443021bdc5f11587ecf4406b53835e53a030c9,Digest of Papers. Third International Symposium on Wearable Computers
3693,Muscles in Action,"Human motion is created by, and constrained by, our muscles. We take a first step at building computer vision methods that represent the internal muscle activity that causes motion. We present a new dataset, Muscles in Action (MIA), to learn to incorporate muscle activity into human motion representations. The dataset consists of 12.5 hours of synchronized video and surface electromyography (sEMG) data of 10 subjects performing various exercises. Using this dataset, we learn a bidirectional representation that predicts muscle activation from video, and conversely, reconstructs motion from muscle activation. We evaluate our model on in-distribution subjects and exercises, as well as on out-of-distribution subjects and exercises. We demonstrate how advances in modeling both modalities jointly can serve as conditioning for muscularly consistent motion generation. Putting muscles into computer vision systems will enable richer models of virtual humans, with applications in sports, fitness, and AR/VR.",2022-12-05,https://www.semanticscholar.org/paper/326cbf7c9891dff720bd1f57bcbe6dc0b5d327a1,arXiv.org
3736,VideoBERT: A Joint Model for Video and Language Representation Learning,"Self-supervised learning has become increasingly important to leverage the abundance of unlabeled data available on platforms like YouTube. Whereas most existing approaches learn low-level representations, we propose a joint visual-linguistic model to learn high-level features without any explicit supervision. In particular, inspired by its recent success in language modeling, we build upon the BERT model to learn bidirectional joint distributions over sequences of visual and linguistic tokens, derived from vector quantization of video data and off-the-shelf speech recognition outputs, respectively. We use VideoBERT in numerous tasks, including action classification and video captioning. We show that it can be applied directly to open-vocabulary classification, and confirm that large amounts of training data and cross-modal information are critical to performance. Furthermore, we outperform the state-of-the-art on video captioning, and quantitative results verify that the model learns high-level semantic features.",2019-04-03,https://www.semanticscholar.org/paper/c41a11c0e9b8b92b4faaf97749841170b760760a,IEEE International Conference on Computer Vision
3351,A Provocative Look at Chromosomal Evolution,,,https://www.semanticscholar.org/paper/82f98fde5d00ce990b2184c8cad66d81811299dc,
2340,Stimulation of neutrophils by insoluble immunoglobulin aggregates from synovial fluid of patients with rheumatoid arthritis,"Abstract. Insoluble immunoglobulin aggregates present in the synovial fluid of patients with rheumatoid arthritis have been examined for their ability to activate reactive oxidant and granule enzyme secretion from bloodstream neutrophils. These insoluble complexes activated luminol chemiluminescence, but did not activate O2‐, H2O2 or granule enzyme secretion and did not activate lucigenin chemiluminescence, which also measures reactive oxidant secretion. Hence, the luminol chemiluminescence detected after activation by insoluble immunoglobulin aggregates must be due to intracellularly generated reactive oxidants, i.e. produced within phagolysosomes. Because reactive oxidant and granule enzyme secretion has occurred within rheumatoid joints, other mechanisms of neutro‐phil activation must exist.",1992-05-01,https://www.semanticscholar.org/paper/54e8621b2c5037d06f3b8e05b0a93ed553d97ecf,European Journal of Clinical Investigation
627,Optimality of the Fast Fourier transform,"A graph-theoretic model for a class of linear algorithms computing the discrete Fourier transform of sequences of length a power of 2, the mformat~on flow network, is presented The information flow network correspondmg to the fast Fourier transform IS shown to be umquely optimal in tim class with respect to a naturally defined cost",,https://www.semanticscholar.org/paper/c11879cb3dfc01758672d149063d9133c1aff4e7,JACM
3440,Can P2P Replace Direct Download for Content Distribution,"While peer-to-peer (P2P) file-sharing is a powerful and cost-effective content distribution model, most paid-for digital-content providers (CPs) rely on direct download to deliver their content. CPs such as Apple iTunes that command a large base of paying users are hesitant to use a P2P model that could easily degrade their user base into yet another free file-sharing community. We present TP2, a system that makes P2P file sharing a viable delivery mechanism for paid digital content by providing the same security properties as the currently used direct-download model. TP2 introduces the novel notion of trusted auditors (TAs) – P2P peers that are controlled by the system operator. TAs monitor the behavior of other peers and help detect and prevent formation of illegal file-sharing clusters among the CP’s user base. TAs both complement and exploit the strong authentication and authorization mechanisms that are used in TP2 to control access to content. It is important to note that TP2 does not attempt to solve the out-of-band file-sharing or DRM problems, which also exist in the direct-download systems currently in use. We analyze TP2 by modeling it as a novel game between misbehaving users who try to form unauthorized file-sharing clusters and TAs who curb the growth of such clusters. Our analysis shows that a small fraction of TAs is sufficient to protect the P2P system against unauthorized file sharing. In a system with as many as 60% of misbehaving users, even a small fraction of TAs can detect 99% of unauthorized cluster formation. We developed a simple economic model to show that even with such a large fraction of malicious nodes, TP2 can improve CP’s profits (which could translate to user savings) by 62 to 122%, even while assuming conservative estimates of content and bandwidth costs. We implemented TP2 as a layer on top of BitTorrent and demonstrated experimentally using PlanetLab that our system provides trusted P2P file sharing with negligible performance overhead.",,https://www.semanticscholar.org/paper/69d17c87450c07e79ae45eb946857ce93353cf8f,
3373,Migration and species diversity in the tropics.,"If the young of a dominant species are subjected to disproportionately heavy predation, this, together with a limitation on food, can promote a high species diversity. This is seen among tropical birds, which are simultaneously exposed to both conditions to a far greater degree than are Temperate Zone species. Migration to the Temperate Zones during the spring provides a release from these restraints, while also precluding breeding in the Tropics.",1974-02-01,https://www.semanticscholar.org/paper/cc71b265e4a3aec2a97b5bfb6eef31be3c08a667,Proceedings of the National Academy of Sciences of the United States of America
2954,Characterization of functional methylomes by next-generation capture sequencing identifies novel disease-associated variants,,2015-05-29,https://www.semanticscholar.org/paper/1d1fa74d6a9d3e9c7adf1907ca78162020550591,Nature Communications
2947,LeafCutter: annotation-free quantification of RNA splicing,"The excision of introns from pre-mRNA is an essential step in mRNA processing. We developed LeafCutter to study sample and population variation in intron splicing. LeafCutter identifies variable intron splicing events from short-read RNA-seq data and finds alternative splicing events of high complexity. Our approach obviates the need for transcript annotations and circumvents the challenges in estimating relative isoform or exon usage in complex splicing events. LeafCutter can be used both for detecting differential splicing between sample groups, and for mapping splicing quantitative trait loci (sQTLs). Compared to contemporary methods, we find 1.4–2.1 times more sQTLs, many of which help us ascribe molecular effects to disease-associated variants. Strikingly, transcriptome-wide associations between LeafCutter intron quantifications and 40 complex traits increased the number of associated disease genes at 5% FDR by an average of 2.1-fold as compared to using gene expression levels alone. LeafCutter is fast, scalable, easy to use, and available at https://github.com/davidaknowles/leafcutter.",2016-03-16,https://www.semanticscholar.org/paper/30220ed3a861a5164a836f3af5b74b1c0c104d9b,bioRxiv
65,Modeling Query-Based Access to Text Databases,"Searchable text databases abound on the web. Applications that require access to such databases often resort to querying to extract relevant documents because of two main reasons. First, some text databases on the web are not “crawlable,” and hence the only way to retrieve their documents is via querying. Second, applications often require only a small fraction of a database’s contents, so retrieving relevant documents via querying is an attractive choice from an efficiency viewpoint, even for crawlable databases. Often an application’s query-based strategy starts with a small number of user-provided queries. Then, new queries are extracted ‐in an application-dependent way‐ from the documents in the initial query results, and the process iterates. The success of this common type of strategy relies on retrieved documents “contributing” new queries. If new documents fail to produce new queries, then the process might stall before all relevant documents are retrieved. In this paper, we develop a graph-based “reachability” metric that allows to characterize when an application’s query-based strategy will successfully “reach” all documents that the application needs. We complement our metric with an efficient sampling-based technique that accurately estimates the reachability associated with a text database and an application’s query-based strategy. We report preliminary experiments backing the usefulness of our metric and the accuracy of the associated estimation technique over real text databases and for two applications.",,https://www.semanticscholar.org/paper/1c474ca9904e9915a85a18683c6be1aa86631375,International Workshop on the Web and Databases
274,The complexity of computing a Nash equilibrium,"How long does it take until economic agents converge to an equilibrium? By studying the complexity of the problem of computing a mixed Nash equilibrium in a game, we provide evidence that there are games in which convergence to such an equilibrium takes prohibitively long. Traditionally, computational problems fall into two classes: those that have a polynomial-time algorithm and those that are NP-hard. However, the concept of NP-hardness cannot be applied to the rare problems where ""every instance has a solution""---for example, in the case of games Nash's theorem asserts that every game has a mixed equilibrium (now known as the Nash equilibrium, in honor of that result). We show that finding a Nash equilibrium is complete for a class of problems called PPAD, containing several other known hard problems; all problems in PPAD share the same style of proof that every instance has a solution.",2009-02-01,https://www.semanticscholar.org/paper/469133e860a5c46d524e83a1418420d138f97aea,CACM
1226,Erratum: Measurement of σ(pp̄→Z)•Br(Z→ττ) at s=1.96TeV (Physical Review D (2005) 71 (072004)),,2008-02-05,https://www.semanticscholar.org/paper/74a2f5612b010916e7d4120481210b13e46a30e4,
1570,"Bayesian Tensor Filtering: Smooth, Locally-Adaptive Factorization of Functional Matrices","We consider the problem of functional matrix factorization, finding low-dimensional structure in a matrix where every entry is a noisy function evaluated at a set of discrete points. Such problems arise frequently in drug discovery, where biological samples form the rows, candidate drugs form the columns, and entries contain the dose-response curve of a sample treated at different concentrations of a drug. We propose Bayesian Tensor Filtering (BTF), a hierarchical Bayesian model of matrices of functions. BTF captures the smoothness in each individual function while also being locally adaptive to sharp discontinuities. The BTF model is agnostic to the likelihood of the underlying observations, making it flexible enough to handle many different kinds of data. We derive efficient Gibbs samplers for three classes of likelihoods: (i) Gaussian, for which updates are fully conjugate; (ii) Binomial and related likelihoods, for which updates are conditionally conjugate through P{\'o}lya--Gamma augmentation; and (iii) Black-box likelihoods, for which updates are non-conjugate but admit an analytic truncated elliptical slice sampling routine. We compare BTF against a state-of-the-art method for dynamic Poisson matrix factorization, showing BTF better reconstructs held out data in synthetic experiments. Finally, we build a dose-response model around BTF and show on real data from a multi-sample, multi-drug cancer study that BTF outperforms the current standard approach in biology. Code for BTF is available at https://github.com/tansey/functionalmf.",2019-06-10,https://www.semanticscholar.org/paper/47f247ef2fe0308087bc63dc8011e7b63f3d3aa6,arXiv.org
2146,"CS 222 Lecture 3 : September 30 , 1999 Fall","Pagerank is computed offline (preprocessing). PageRank could be considered as a ”1-dimensional” process ( ompared to the distinction in hubs and authorities): we simply assign a score to every page. Kleinberg’s algorithm first invokes a text-based search and then computes numerical scores for the pages in a relatively small subgraph constructed from the initial search results; instead, the PageRank algorithm computes ranks for all the nodes in the index of the search eng in .",,https://www.semanticscholar.org/paper/c0f643153a92fafb6a3bb31a9b0418277c53dc38,
2826,"Comparative Gene Expression Analyses Reveal Differential Helper T cell Polarization in Atopic Dermatitis, Contact Dermatitis, and Psoriasis",,2010-02-01,https://www.semanticscholar.org/paper/1c9884d2b87b0536d6360d20bafb757409bebe67,
3540,Programming: Principles and Practice Using C++ (2nd Edition),"An Introduction to Programming by the Inventor of C++ Preparation for Programming in the Real World The book assumes that you aim eventually to write non-trivial programs, whether for work in software development or in some other technical field. Focus on Fundamental Concepts and Techniques The book explains fundamental concepts and techniques in greater depth than traditional introductions. This approach will give you a solid foundation for writing useful, correct, maintainable, and efficient code. Programming with Todays C++ (C++11 and C++14) The book is an introduction to programming in general, including object-oriented programming and generic programming. It is also a solid introduction to the C++ programming language, one of the most widely used languages for real-world software. The book presents modern C++ programming techniques from the start, introducing the C++ standard library and C++11 and C++14 features to simplify programming tasks. For Beginners And Anyone Who Wants to Learn Something New The book is primarily designed for people who have never programmed before, and it has been tested with many thousands of first-year university students. It has also been extensively used for self-study. Also, practitioners and advanced students have gained new insight and guidance by seeing how a master approaches the elements of his art. Provides a Broad View The first half of the book covers a wide range of essential concepts, design and programming techniques, language features, and libraries. Those will enable you to write programs involving input, output, computation, and simple graphics. The second half explores more specialized topics (such as text processing, testing, and the C programming language) and provides abundant reference material. Source code and support supplements are available from the authors website.",2014-06-02,https://www.semanticscholar.org/paper/363b5e14a67440746fc7ee091ce28d34e49cef87,
3714,Learning the Predictability of the Future,"We introduce a framework for learning from unlabeled video what is predictable in the future. Instead of committing up front to features to predict, our approach learns from data which features are predictable. Based on the observation that hyperbolic geometry naturally and compactly encodes hierarchical structure, we propose a predictive model in hyperbolic space. When the model is most confident, it will predict at a concrete level of the hierarchy, but when the model is not confident, it learns to automatically select a higher level of abstraction. Experiments on two established datasets show the key role of hierarchical representations for action prediction. Although our representation is trained with unlabeled video, visualizations show that action hierarchies emerge in the representation.",2021-01-01,https://www.semanticscholar.org/paper/8ce65937232b5083f0e9da47ce1d6220bc385c49,Computer Vision and Pattern Recognition
3490,Minimizing average completion time in the presence of release dates,,1998-06-01,https://www.semanticscholar.org/paper/6ba26104c8c73f384b614fcdada123de4778af8f,Mathematical programming
482,ON HORN ENVELOPES AND HYPERGRAPH TRANSVERSALS ( Extended Abstract for ISAAC ),"We study the problem of bounding from above and below a given set of bit vectors by the set of satisfying truth assignments of a Horn formula. We point out a rather unexpected connection between the upper bounding problem and the problem of generating all transversals of a hypergraph, and settle several related complexity questions.",,https://www.semanticscholar.org/paper/b0ace9f2d95404621d0faa9c082730822c0eab42,
2095,Decision support system for delivery mode of backend,"This study develops a decision support system for delivery mode based on the relationship of entire supply chain of backend in semiconductor industry. In particular, it is a critical decision for delivery mode including quantity and timing in the supply chain operations for semiconductor industry. In practice, the existing way relies on engineer's experience to making decisions and taking more than 4 hours to dispatch. This study aims to develop a decision support system for delivery mode embedded optimal dispatching model. And it enables to confirm relationship of entire supply chain having on game theory. We apply the DSS at a semiconductor backend to verify it in real setting. The results show that it can reduce efficiently either total cycle time or implement time of staff with cost-effective assignment. The developed DSS assists decision makers in making rapid and accurate decisions in real time given the circumstances of limited information of various order mix",2004-12-08,https://www.semanticscholar.org/paper/5488b9bd11af1ed1c821ef57de331b3bbed3dc64,Electronic Packaging Technology Conference
776,Guest Editors' foreword,,,https://www.semanticscholar.org/paper/8b95445907f1f09399a072eb495bfa8212ca18ff,Journal of computer and system sciences (Print)
281,Some Recent Results in Algorithmic Game Theory,,2008-12-17,https://www.semanticscholar.org/paper/0a42d279385ee619ed7033707ed13d62f52d156e,Workshop on Internet and Network Economics
660,The Gianturco-Roubin flexible intracoronary stent: clinical application and initial results.,,1991-11-01,https://www.semanticscholar.org/paper/ab876e43c6d76bf171ae9163e8c36b8e529b3add,Indian Heart Journal
3488,Finding Real-Valued Single-Source Shortest Paths in o(n3) Expected Time,"Given ann-vertex,m-edge directed networkGwith real costs on the edges and a designated source vertexs, we give a new algorithm to compute shortest paths froms. Our algorithm is a simple deterministic one withO(n2logn) expected running time over a large class of input distributions. This is the first strongly polynomial algorithm in over 35 years to improve upon some aspect of theO(nm) running time of the Bellman?Ford algorithm. The result extends to anO(n2logn) expected running time algorithm for finding the minimum mean cycle, an improvement over Karp'sO(nm) worst-case time bound when the underlying graph is dense. Both of our time bounds are shown to be achieved with high probability.",1998-07-01,https://www.semanticscholar.org/paper/2e2db4c0a2884739fdf54bea78236348a94cf5fa,J. Algorithms
16,REEL: A Relation Extraction Learning framework,"We introduce the REEL (RElation Extraction Learning) framework, an open source framework that facilitates the development and evaluation of relation extraction systems over text collections. To define a relation extraction system for a new relation and text collection, users only need to specify the parsers to load the collection, the relation and its constraints, and the learning and extraction techniques to be used. This makes REEL a powerful framework to enable the deployment and evaluation of relation extraction systems for both application building and research.",2014-09-08,https://www.semanticscholar.org/paper/f28f1dc630b73175c331aa8857dd32fd8737c2a8,IEEE/ACM Joint Conference on Digital Libraries
2744,Generating coordinated multimedia explanations,"The coordinated multimedia explanation testbed (COMET) is a research system being developed to explore the coordinated generation of multimedia explanations of equipment maintenance and repair procedures. The form and content of all material presented is generated interactively, allowing explanations to be customized for the individual user and situation. COMET's architecture includes multiple static and dynamic knowledge sources, a content planner, a media coordinator, media generators and a media layout manager. Coordinating multiple media through the development of a single content planner that generates a common content description for both media is emphasized. This content description is annotated by the media coordinator to indicate the assignment of the concepts to be expressed to the media generators. This will ultimately allow cross-references between media and coordinated display layouts that reflect fine-grain relationships among the material presented.<<ETX>>",,https://www.semanticscholar.org/paper/069dc786d8a814286e32678a51d63ca88a08bbca,Sixth Conference on Artificial Intelligence for Applications
1155,Combined measurements of anomalous charged trilinear gauge-boson couplings from diboson production in pp̄ collisions at √ s = 1 . 96 TeV,,,https://www.semanticscholar.org/paper/66092b339ee57c16afcca2c33b25b84ccbda4fad,
3585,Verification and semantic parallelization of goal-driven autonomous software,"Future space missions such as the Mars Science Laboratory demand the engineering of some of the most complex man-rated autonomous software systems. According to some recent estimates, the certification cost for mission-critical software exceeds its development cost. The current process-oriented methodologies do not reach the level of detail of providing guidelines for the development and validation of concurrent software. Time and concurrency are the most critical notions in an autonomous space system. In this work we present the design and implementation of a first concurrency and time centered framework for verification and semantic parallelization of real-time C++ within the JPL Mission Data System Framework (MDS). The end goal of the industrial project that motivated our work is to provide certification artifacts and accelerated testing of the complex software interactions in autonomous flight systems. As a case study we demonstrate the verification and semantic parallelization of the MDS Goal Networks.",2008-09-23,https://www.semanticscholar.org/paper/e8cfacb4856a73be75118525fa394177b669bae6,Autonomic Computing and Communication Systems
1659,Reweighted Data for Robust Probabilistic Models,"Probabilistic models analyze data by relying on a set of assumptions. When a model performs poorly, we challenge its assumptions. This approach has led to myriad hand-crafted robust models; they offer protection against small deviations from their assumptions. We propose a simple way to systematically mitigate mismatch of a large class of probabilistic models. The idea is to raise the likelihood of each observation to a weight. Inferring these weights allows a model to identify observations that match its assumptions; down-weighting others enables robust inference and improved predictive accuracy. We study four different forms of model mismatch, ranging from missing latent groups to structure misspecification. A Poisson factorization analysis of the Movielens dataset shows the benefits of reweighting in a real data scenario.",2016-06-13,https://www.semanticscholar.org/paper/9574b281c8d4879aceec428e3cc3d6714efc989a,arXiv.org
84,PERSIVAL demo: categorizing hidden-web resources,"The information available in electronic form continues to grow at an exponential rate and this trend is expected to continue. Although traditional search engines like AltaVista can address common information needs, they ignore the often valuable information that is “hidden” behind search interfaces, the so-called “hidden web.” Automating the classification of “hidden web” resources is challenging, since the contents of these collections are available only by querying, not by traditional crawling. For example, consider the PubMed medical database from the National Library of Medicine, which stores medical bibliographic information and links to full-text journals accessible through the web. This database is accessible through a query interface. A query to PubMed with keyword “cancer” returns 1,313,266 matches, which are high-quality citations to medical articles, stored locally at the PubMed site. The contents of PubMed are not “crawlable” by traditional search engines. Thus, a query on AltaVista for all the pages in the PubMed site with keyword “cancer” returns only 16,380 matches. Hence, techniques that need to have the documents available for inspection are not applicable to analyze and classify the “hidden web” resources. The ability to access these resources and organize them for subsequent use is a central component of the Digital Libraries Initiative – Phase 2 (DLI2) project at Columbia University. The project is named PERSIVAL and its main goal is to provide personalized access to a distributed patient care digital library with all kinds of collections. The manual inspection and classification of these resources is a non-scalable solution, so we developed a novel technique to automate this task.",,https://www.semanticscholar.org/paper/345dfe61c6932e0c0c6040fd8e00b4b55d603de6,ACM/IEEE Joint Conference on Digital Libraries
3639,A History of C++: 1979-1991,,,https://www.semanticscholar.org/paper/14d1f59cbd20a813f4f6145844a9ebab2c6c3c98,HOPL Preprints
1673,Dynamic Poisson Factorization,"Models for recommender systems use latent factors to explain the preferences and behaviors of users with respect to a set of items (e.g., movies, books, academic papers). Typically, the latent factors are assumed to be static and, given these factors, the observed pref- erences and behaviors of users are assumed to be generated without order. These assumptions limit the explorative and predictive capabilities of such models, since users' interests and item popularity may evolve over time. To address this, we propose dPF, a dynamic matrix factorization model based on the recent Poisson factorization model for recommendations. dPF models the time evolving latent factors with a Kalman filter and the actions with Poisson distributions. We derive a scalable variational inference algorithm to infer the latent factors. Finally, we demonstrate dPF on 10 years of user click data from arXiv.org, one of the largest repository of scientific papers and a formidable source of information about the behavior of scientists. Empirically we show performance improvement over both static and, more recently proposed, dynamic recommendation models. We also provide a thorough exploration of the inferred posteriors over the latent variables.",2015-09-15,https://www.semanticscholar.org/paper/39f249d4095fcb875f0b23655d1e734bd8c71b71,ACM Conference on Recommender Systems
96,Simplifying data access: the energy data collection (EDC) project,"The massive amount of statistical and text data available from government agencies has created a set of daunting challenges to both research and analysis communities. These problems include heterogeneity, size, distribution, and control of terminology. At the Digital Government Research Center we are investigating solutions to these key problems. In this paper we focus on (1) ontological mappings for terminology standardization, (2) data integration across data bases with high speed query processing, and (3) interfaces for query input and presentation of results. This collaboration between researchers from Columbia University and the Information Sciences Institute of the University of Southern California employs technology developed at both locations, in particular the SENSUS ontology, the SIMS multi-database access planner, the LKB automated dictionary and terminology analysis system, and others. The pilot application targets gasoline data from the Bureau of Labor Statistics, the Energy Information Administration of the Department of Energy, the Census Bureau, and other government agencies.",2000-05-15,https://www.semanticscholar.org/paper/313e69f0df162ac2f791550a35d43d3e7b5eeae7,Digital Government Research
2555,AFRL-RH-WP-TR-2007-0112 Augmented Reality for Maintenance and Repair ( ARMAR ),"NOTICE Using Government drawings, specifications, or other data included in this document for any purpose other than Government procurement does not in any way obligate the U.S. Government. The fact that the Government formulated or supplied the drawings, specifications, or other data does not license the holder or any other person or corporation; or convey any rights or permission to manufacture, use, or sell any patented invention that may relate to them. This report was cleared for public release by the 88 th Air Base Wing Public Affairs Office and is available to the general public, including foreign nationals. Copies may be obtained from the Defense Technical Information Center (DTIC) This report is published in the interest of scientific and technical information exchange, and its publication does not constitute the Government's approval or disapproval of its ideas or findings. Public reporting burden for this collection of information is estimated to average 1 hour per response, including the time for reviewing instructions, searching existing data sources, gathering and maintaining the data needed, and completing and reviewing this collection of information. Send comments regarding this burden estimate or any other aspect of this collection of information, including suggestions for reducing Respondents should be aware that notwithstanding any other provision of law, no person shall be subject to any penalty for failing to comply with a collection of information if it does not display a currently valid OMB control number. The purpose of this research, Augmented Reality for Maintenance and Repair (ARMAR), was to research the design and development of experimental augmented reality systems for maintenance job aiding. The goal was to explore and evaluate the feasibility of developing prototype adaptive augmented reality systems that can be used to investigate how real time computer graphics, overlaid on and registered with the actual equipment being maintained, can significantly increase the productivity of maintenance personnel, both during training and in the field.",,https://www.semanticscholar.org/paper/536798b2d2a77e92ffc0f81da7ed5eb007e83c20,
2315,Potentiation of the respiratory burst of human neutrophils by cycloheximide: Regulation of reactive oxidant production by a protein(s) with rapid turnover,,1995-04-01,https://www.semanticscholar.org/paper/f56875016f71e381cd31d4fd31b823cd6b3717a7,Inflammation Research
778,"Protocol System Integration, Interface and Interoperability",,2004-12-15,https://www.semanticscholar.org/paper/a63f33aed2e3e686fcd87467dd9c8e7ac7e5ee33,International Conference on Principles of Distributed Systems
2844,Regulation of Immune Responses by Galectin-3,,2008-10-09,https://www.semanticscholar.org/paper/9fe9f26715fd4762bb7386bb35597cdea9dc1892,
3012,Tap,,2021-06-24,https://www.semanticscholar.org/paper/e530f36019b32bc0eb456a3e70632ac948f080a8,"Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services"
1458,Possibilities at a Photon Linear Collider,"With the convergence of linear collider and laser technology, a new type of facility may soon be made available for research in fundamental particle physics: a Photon Linear Collider where high energy photon beams, produced by the Compton backscattering of laser photons off linac electrons, are brought into collision with electron beams or with other photon beams. Control over both the spectral distribution and mean helicity of the photon beam is possible by changing the polarization states of the linac electron beam and laser. In the resulting ey or 33/ collisions, such control allows one to vary the ey or 33/ luminosity distribution as well as to produce selectively one particle type over another. Additionally, high luminosities-potentially higher than in e+ecollisions-are possible in such a facility, providing an opportunity for a broad and diverse physics program. In particular, a Photon Linear Collider offers a unique environment for the exploration of the Higgs sector of the Standard Model. Tuned to provide a broad luminosity distribution, a 33/ collider permits the search for an intermediate mass Higgs boson as a resonance in yy + b6 production. Tuned for a more monochromatic spectrum, a 33/ collider allows a measurement of the two-photon width of the Higgs, a sensitive probe of physics beyond the Standard Model. Clean channels are made available for the discovery of new particles, such as excited electron states, supersymmetric particles, heavy charged particle pairs, or any particles with appreciable two-photon couplings. Precision electroweak tests also benefit from such a machine. Photons in the initial state allow a test of the three-gauge-boson coupling without the complicating effect of FZ interference. Both ey+ WV and w+ WW offer information on the W boson complementary to that available from e+e-+ WW; ey+ eZ allows a search for anomalous yyZ and rZZ couplings. Finally, a Photon Linear Collider serves as an excellent laboratory for Quantum Chromodynamics tests. Studies of photon structure functions, jet and hadron production, and bb and t? resonances are all made available at such a facility. In this paper, we review some of the technical aspects of a Photon Linear Collider and utilize Monte Carlo studies to explore some of the physics which might result from high energy ey and yy collisions.",,https://www.semanticscholar.org/paper/b933954d219d4e4ea086d948591519eb4911b538,
2327,Stimulation of reactive oxidant production in neutrophils by soluble and insoluble immune complexes occurs via different receptors/signal transduction systems.,"Cell-free synovial fluid from patients with rheumatoid arthritis contains soluble and insoluble IgG-containing immune complexes which activate reactive oxidant production in human neutrophils. In this report we have measured the effects of inhibitors of signal transduction pathways on neutrophil activation by these complexes and also following activation by synthetic soluble and insoluble immune complexes made from human serum albumin (HSA) and anti-(HSA) antibodies. In all aspects studied, the soluble rheumatoid complexes and the soluble synthetic complexes were indistinguishable in the ways in which they activated neutrophils. Activation of reactive oxidant production in response to these soluble complexes was completely inhibited by pertussis toxin (indicating G-protein coupling of receptor occupancy), completely insensitive to staurosporine (indicating that oxidant production did not require protein kinase C activity), only marginally (< 30%) inhibited by butanol (indicating that dependence upon activity of phospholipase D was minimal), and completely inhibited by chloracysine, an inhibitor of phospholipase A2. In contrast, activation of reactive oxidant production in response to the insoluble rheumatoid or insoluble synthetic immune complexes was largely pertussis toxin insensitive, inhibited by > 50% by staurosporine, inhibited by > 50% by butanol, and completely inhibited by chloracysine. These results show that the receptor-mediated signal transduction systems activated by the soluble and insoluble immune complexes are different. Because the soluble complexes activate a transient burst of reactive oxidant secretion from primed neutrophils, the mechanisms regulating either the release or the intracellular production of oxidants within rheumatoid joints are distinct and hence may be pharmacologically modified independently of each other.",1994-03-01,https://www.semanticscholar.org/paper/95bb35abd40797b825f1e0d63037c0097f7f6821,FEMS Immunology & Medical Microbiology
372,"The Internet, the Web, and Algorithms",,2002-04-03,https://www.semanticscholar.org/paper/7addbcc81bdaf134cee73cd945465d52e9961376,Latin American Symposium on Theoretical Informatics
2070,Structuring Manufacturing Strategy,"Manufacturing strategy comprises decisionmaking problems in terms of manufacturing practices to achieve manufacturing objectives through linkages of performance measurement. It is pervasively influential, long-term, and dynamic owing to the conformance with corporate strategy, business strategy, and marketing strategy. Therefore, there are many underlying sub-problems which can be expressed in a wide spectrum of forms. In this study, we will firstly define the spectrum of problem-structuring. After that, a decision analysis framework as a guide for modeling problems in different forms is introduced. Finally, a realistic problem is illustrated for discussions.",2007-10-08,https://www.semanticscholar.org/paper/8a55fb217fbe8318e00cade34f41fbf2ff0335a7,IEEE International Conference on Automation Science and Engineering
1304,Latest Results From The CDMS‐II Cold Dark Matter Search,"The CDMS‐II collaboration’s Cold Dark Matter search presently sets the most competitive exclusion limit in the world for the direct detection of the hypothesized Weakly Interacting Massive Particles (WIMPs) that constitute the cold dark matter of the Universe. Our experiment utilizes Ge (and Si) crystals as the target detectors, each with a mass of 250 g (100 g) and cooled to 30 mK. To eliminate natural radioactive sources as background the experiment is conducted in a well‐shielded environment in the Soudan Mine, Minnesota, and has been operating for the last two years. To aid in the identification of a possible WIMP‐candidate event, the detectors are designed to measure both the ionization and athermal phonon signals produced by each candidate event. The athermal phonon signal is measured using superconducting aluminum films on the crystal surface connected to tungsten transition edge sensors. The latest WIMP‐search results from Soudan will be presented, along with projections for the future.",2006-12-01,https://www.semanticscholar.org/paper/2537164165caa49e21e78e01b24c545366fd0d30,
2356,Stimulation of protein synthesis in human neutrophils by gamma-interferon.,"Treatment of human, peripheral blood neutrophils with gamma-interferon both ""primed"" their ability to generate reactive oxidants and increased their rate of protein synthesis. This increased rate of protein synthesis was greatest 60 min after the addition of 100 U/ml gamma-interferon and was not due to an increased intracellular pool of radiolabelled amino acid. Analysis of the newly-synthesized polypeptides by two-dimensional polyacrylamide gel electrophoresis (PAGE) revealed two classes of proteins which were regulated by this agent. The first of these represented proteins whose rate of labelling increased very little (1-2-fold) whereas the rate of biosynthesis of a second group of proteins increased more markedly (10-20-fold). We propose that these newly-synthesized, gamma-interferon regulated proteins play an important role in the function of these cells during an acute inflammatory response.",,https://www.semanticscholar.org/paper/617bac5882bde4e1a01dff53ff3f11e4e8ec3c28,Biochemical Pharmacology
1531,Mapping interstellar dust with Gaussian processes,"Interstellar dust corrupts nearly every stellar observation, and accounting for it is crucial to measuring physical properties of stars. We model the dust distribution as a spatially varying latent field with a Gaussian process (GP) and develop a likelihood model and inference method that scales to millions of astronomical observations. Modeling interstellar dust is complicated by two factors. The first is integrated observations. The data come from a vantage point on Earth and each observation is an integral of the unobserved function along our line of sight, resulting in a complex likelihood and a more difficult inference problem than in classical GP inference. The second complication is scale; stellar catalogs have millions of observations. To address these challenges we develop ziggy, a scalable approach to GP inference with integrated observations based on stochastic variational inference. We study ziggy on synthetic data and the Ananke dataset, a high-fidelity mechanistic model of the Milky Way with millions of stars. ziggy reliably infers the spatial dust map with well-calibrated posterior uncertainties.",2022-02-14,https://www.semanticscholar.org/paper/cde5bd28b06c8d89af4c372bc74311ae44e4de78,Annals of Applied Statistics
2181,014 APPA inhibits neutrophil pro-inflammatory functions without impairing host defence: is this a potential new therapy for arthritis?,,2019-04-01,https://www.semanticscholar.org/paper/75d7d783500aa3071fa332f5c43a65fc9371850e,Rheumatology
2452,Personalized Compass: A Compact Visualization for Direction and Location,"Maps on mobile/wearable devices often make it difficult to determine the location of a point of interest (POI). For example, a POI may exist outside the map or on a background with no meaningful cues. To address this issue, we present Personalized Compass, a self-contained compact graphical location indicator. Personalized Compass uses personal a priori POIs to establish a reference frame, within which a POI in question can then be localized. Graphically, a personalized compass combines a multi-needle compass with an abstract overview map. We analyze the characteristics of Personalized Compass and the existing Wedge technique, and report on a user study comparing them. Personalized Compass performs better for four inference tasks, while Wedge is better for a locating task. Based on our analysis and study results, we suggest the two techniques are complementary and offer design recommendations.",2016-05-07,https://www.semanticscholar.org/paper/222224c3866d418cb323a7455dd354de6f634306,International Conference on Human Factors in Computing Systems
2234,Active Replication Of RSV In Neutrophils From Airways And Blood Of Infants With Severe Bronchiolitis,,2010-05-01,https://www.semanticscholar.org/paper/cfb7843ab401caa17048b854115d8ce74a3c51cb,Asian Test Symposium
1924,ANALYZING TFT-LCD ARRAY BIG DATA FOR YIELD ENHANCEMENT AND AN EMPIRICAL STUDY OF TFT-LCD MANUFACTURING IN TAIWAN,"The flat panel display industry has invested considerable resources in constructing large-size panels and rendered the process more complex, resulting in various defects and low yield. Engineers rely on their domain knowledge or rules of thumb for troubleshooting; however, limited domain knowledge, insufficient experience, faulty generalization, and bounded rationality lead to ineffective judgment. The objective of this study was to develop a framework for data mining and knowledge discovery from a database; the Kruskal–Wallis test and a decision tree were used to investigate a large amount of thin film transistor-liquid crystal display (TFT-LCD) manufacturing data and determine the possible causes of faults and manufacturing process variations. An empirical study was conducted at a TFT-LCD company in Taiwan, and the results demonstrated the practical viability of the framework.",2017-01-06,https://www.semanticscholar.org/paper/c3394ebe4ba98555984e01ca4f68da32c5b6b660,
1114,Low-Mass WIMP Sensitivity and Statistical Discrimination of Electron and Nuclear Recoils by Varying Luke-Neganov Phonon Gain in Semiconductor Detectors,,2012-01-18,https://www.semanticscholar.org/paper/afa01a0f9c8fad82896ae1bdc4152c72385c4dbc,
2328,Phospholipase D-dependent and-independent activation of the neutrophil NADPH oxidase,,1994-04-01,https://www.semanticscholar.org/paper/983bcb6372b2ae1c1e7efe036fb507fb490d3e44,Bioscience Reports
451,Database metatheory: asking the big queries,"Is “database theory” an oxymoron? Or is ata platitude? What is the fitness measure that decides the surviva! of ideas (and areas) in mathematics, in applted science, and in computer science? Which ideas from database theory during the past twenty-five years have influenced research in other fields of computer science? How many were encapsulated in actual products? Was the relational model the on[y true paradigm sh@ m computer science ? Is applicability the only and ultimate justification of theoretical research in an applied science? Are applicability pressures rea!ly exogenous and unwelcome? Are negattve results appropriate goals of theoretical research in an appiied science —or are they the on[y possibie such research goals? If scientific theories must be refutab!e, what are the “hard facts” that provide the possibility of refutation in the case of database theory?",1995-05-22,https://www.semanticscholar.org/paper/0e76f58b096f7d9a3e04e762d87fe879f1feac85,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
981,Position of Central Retinal Vascular Trunk and Preferential Location of Glaucomatous Damage in Myopic Normal-Tension Glaucoma.,,2018-07-01,https://www.semanticscholar.org/paper/ac8301eba9fb51668161612d088274e0c181a597,Ophthalmology Glaucoma
465,OF KNOWLEDGE (Extended Abstract),"Approximating a general formula from above and below by Horn formulas (its Horn envelope and Horn core, respectively) was proposed in (SIC) as a form of ""'knowledge compilation,"" sup- porting rapid approximate reasoning; on the nega- tive side, this scheme is static in that it supports no updates, and has certain complexity drawbacks pointed out in (KPS). On the other hand, the many frameworks and schemes proposed in the literature for theory update and revision are plagued by serious complexity-theoretic impediments, even in the Horn case, as was pointed out in (EGZ?) and the present paper. More fundamentally, these schemes are not inductive, in that they lose in a single update any positive properties of the represented sets of formu- las (small size, Horn, etc.). In this paper we propose a new scheme, incremental recompilation, combin- ing Horn approximation and model-based updates; this scheme is inductive and very efficient, free of the problems facing its constituents. A set of formulas is represented by an upper and lower Horn approxima- tion. To update, we replace the upper Horn formula by the Horn envelope of its minimum-change update, and similarly the lower one by the Horn core of its update; the key fact is that Horn envelopes and cores are easy to compute when the underlying formula is the result of a minimum-change update of a Horn formula by a clause. We conjecture that eficient al- gorithms are possible for more complex updates.",,https://www.semanticscholar.org/paper/3412fef89340bc69fc13cf84edc7bdc515340f26,
2447,Travel in large-scale head-worn VR: Pre-oriented teleportation with WIMs and previews,"We demonstrate an interaction technique that allows a user to point at a world-in-miniature representation of a city-scale virtual environment and perform efficient and precise teleportation by pre-orienting an avatar. A preview of the post-teleport view of the full-scale virtual environment updates interactively as the user adjusts the position, yaw, and pitch of the avatar's head with a pair of 6DoF-tracked controllers. We describe design decisions and contrast with alternative approaches to virtual travel.",2017-03-18,https://www.semanticscholar.org/paper/904f9c396af32e8d415989b51af5aeb2a17d29f5,IEEE Conference on Virtual Reality and 3D User Interfaces
61,"Proceedings of the Seventh International Workshop on the Web and Databases, WebDB 2004, June 17-18, 2004, Maison de la Chimie, Paris, France, Colocated with ACM SIGMOD/PODS 2004",,,https://www.semanticscholar.org/paper/c88d258d8820bd2c2d227794382b07fa4b933919,International Workshop on the Web and Databases
1513,Amortized Variational Inference: When and Why?,"Amortized variational inference (A-VI) is a method for approximating the intractable posterior distributions that arise in probabilistic models. The defining feature of A-VI is that it learns a global inference function that maps each observation to its local latent variable's approximate posterior. This stands in contrast to the more classical factorized (or mean-field) variational inference (F-VI), which directly learns the parameters of the approximating distribution for each latent variable. In deep generative models, A-VI is used as a computational trick to speed up inference for local latent variables. In this paper, we study A-VI as a general alternative to F-VI for approximate posterior inference. A-VI cannot produce an approximation with a lower Kullback-Leibler divergence than F-VI's optimal solution, because the amortized family is a subset of the factorized family. Thus a central theoretical problem is to characterize when A-VI still attains F-VI's optimal solution. We derive conditions on both the model and the inference function under which A-VI can theoretically achieve F-VI's optimum. We show that for a broad class of hierarchical models, including deep generative models, it is possible to close the gap between A-VI and F-VI. Further, for an even broader class of models, we establish when and how to expand the domain of the inference function to make amortization a feasible strategy. Finally, we prove that for certain models -- including hidden Markov models and Gaussian processes -- A-VI cannot match F-VI's solution, no matter how expressive the inference function is. We also study A-VI empirically. On several examples, we corroborate our theoretical results and investigate the performance of A-VI when varying the complexity of the inference function. When the gap between A-VI and F-VI can be closed, we find that the required complexity of the function need not scale with the number of observations, and that A-VI often converges faster than F-VI.",2023-07-20,https://www.semanticscholar.org/paper/376f88d661e1b299bfdef13c9a404cbc76b9566b,arXiv.org
851,"Suboptimal Cuts: Their Enumeration, Weight and Number (Extended Abstract)",,1992-07-13,https://www.semanticscholar.org/paper/be762c0fcbf2f3924b266d07551eea893e0630c0,"International Colloquium on Automata, Languages and Programming"
765,Recursion and Probability,,,https://www.semanticscholar.org/paper/eb1c8d54bcdf24c41226bf3e57a0356089e225da,IFIP TCS
1094,Search for Low-Mass WIMPs with SuperCDMS,"We report a first search for weakly interacting massive particles (WIMPs) using the background rejection capabilities of SuperCDMS. An exposure of 577 kg-days was analyzed for WIMPs with mass < 30 GeV/c2, with the signal region blinded. Eleven events were observed after unblinding. We set an upper limit on the spin-independent WIMP-nucleon cross section of 1.2e-42 cm2 at 8 GeV/c2. This result is in tension with WIMP interpretations of recent experiments and probes new parameter space for WIMP-nucleon scattering for WIMP masses < 6 GeV/c2.",2014-02-28,https://www.semanticscholar.org/paper/988c87eb68560468c97d1854ec47d655a248a8a6,
671,Metric Learning on Manifolds,"Recent literature has shown that symbolic data, such as text and graphs, is often better represented by points on a curved manifold, rather than in Euclidean space. However, geometrical operations on manifolds are generally more complicated than in Euclidean space, and thus many techniques for processing and analysis taken for granted in Euclidean space are difficult on manifolds. A priori, it is not obvious how we may generalize such methods to manifolds. We consider specifically the problem of distance metric learning, and present a framework that solves it on a large class of manifolds, such that similar data are located in closer proximity with respect to the manifold distance function. In particular, we extend the existing metric learning algorithms, and derive the corresponding sample complexity rates for the case of manifolds. Additionally, we demonstrate an improvement of performance in $k$-means clustering and $k$-nearest neighbor classification on real-world complex networks using our methods.",2019-02-05,https://www.semanticscholar.org/paper/4ab0129dd9d579bc8e9cbd46325559fa9e06e44d,arXiv.org
1355,Limits on spin-independent WIMP-nucleon interactions from the two-tower run of the Cryogenic Dark Matter Search,"D.S. Akerib, M.J. Attisha, C.N. Bailey, L. Baudis, D.A. Bauer, P.L. Brink, P.P. Brusov, R. Bunker, B. Cabrera, D.O. Caldwell, C.L. Chang, J. Cooley, M.B. Crisler, P. Cushman, M. Daal, R. Dixon, M.R. Dragowsky, D.D. Driscoll, L. Duong, R. Ferril, J. Filippini, R.J. Gaitskell, S.R. Golwala, D.R. Grant, R. Hennings-Yeomans, D. Holmgren, M.E. Huber, S. Kamat, S. Leclercq, A. Lu, R. Mahapatra, V. Mandic, P. Meunier, N. Mirabolfathi, H. Nelson, R. Nelson, R.W. Ogburn, T.A. Perera, M. Pyle, E. Ramberg, W. Rau, A. Reisetter, R.R. Ross, 8, ∗ B. Sadoulet, 8 J. Sander, C. Savage, R.W. Schnee, D.N. Seitz, B. Serfass, K.M. Sundqvist, J-P.F. Thompson, G. Wang, 2 S. Yellin, 9 J. Yoo, and B.A. Young",,https://www.semanticscholar.org/paper/a8958daa3e143657fb9a60c80afcd60bb4b15e4c,
1601,Dose-response modeling in high-throughput cancer drug screenings: A case study with recommendations for practitioners,"Personalized cancer treatments based on the molecular profile of a patient's tumor are becoming a standard of care in oncology. Experimentalists and pharmacologists rely on high-throughput, \textit{in vitro} screenings of many compounds against many different cell lines to build models of drug response. These models help them discover new potential therapeutics that may apply to broad classes of tumors matching some molecular pattern. We propose a hierarchical Bayesian model of how cancer cell lines respond to drugs in these experiments and develop a method for fitting the model to real-world data. Through a case study, the model is shown both quantitatively and qualitatively to capture nontrivial associations between molecular features and drug response. Finally, we draw five conclusions and recommendations that may benefit experimentalists, analysts, and clinicians working in the field of personalized medicine for cancer therapeutics.",2018-12-13,https://www.semanticscholar.org/paper/7e99908dff899e1c744cdf928a1f1ab3ec58cdd4,
382,"Game theory, algorithms, and the Internet","Among the many characteristics of the Internet (huge and growing, available and unstructured, dynamic and chaotic), perhaps the most novel, distinguishing, and intellectually challenging one is that, unlike previous computational artifacts and systems, the Internet is built, operated, and used by a dazzling diversity of economic interests, in various degrees of collaboration and competition with each other. Consequently, it can be argued that the mathematical arsenal necessary for attaining an algorithmic and conceptual understanding of the Internet must include some kind of fusion between mathematical economics (especially game theory and its inverse problem, mechanism design) and algorithmic thinking. In this talk I shall survey recent formalisms and results aiming in this general direction, and discuss the research agenda that appears to be emerging.",2001-01-09,https://www.semanticscholar.org/paper/2a7d35c80cd6ba315c9bf42c459d87aa9eb89ce3,ACM-SIAM Symposium on Discrete Algorithms
1216,Search for decay of a fermiophobic Higgs boson hf-->gammagamma with the D0 detector at sqrt s=1.96 TeV.,We report the results of a search for a narrow resonance decaying into two photons in 1.1 fb;{-1} of data collected by the D0 experiment at the Fermilab Tevatron Collider during the period 2002-2006. We find no evidence for such a resonance and set a lower limit on the mass of a fermiophobic Higgs boson of m_{h_{f}}>100 GeV at the 95% C.L. This exclusion limit exceeds those obtained in previous searches at the Fermilab Tevatron and covers a significant region of the parameter space B(h_{f}-->gammagamma) vs m_{h_{f}} which was not accessible at the CERN Large Electron-Positron Collider.,2008-07-29,https://www.semanticscholar.org/paper/4b7170d983febb0f8db5e0067a4b60fdb12453e7,Physical Review Letters
2192,"Low‐density granulocytes: functionally distinct, immature neutrophils in rheumatoid arthritis with altered properties and defective TNF signalling","Our aim was to determine whether rheumatoid arthritis (RA) low‐density granulocytes (LDGs) are functionally different from RA neutrophils. LDGs from 32 RA patients were characterized using flow cytometry and quantitative PCR (qPCR). RNA sequencing (RNA‐Seq) was carried out on paired RA LDGs and neutrophils (n = 4) and validated using qPCR. Functional assays included chemotaxis, phagocytosis, reactive oxygen species (ROS) production, cell‐cycle analysis, apoptosis, neutrophil extracellular trap (NET)osis, and measurement of cytokine production (n ≥ 5 paired RA LDGs/neutrophils). RA LDGs had a substantially altered transcriptome, expressing >5000 genes at significantly different levels compared with RA neutrophils, including elevated levels of transcripts for granule proteins [including elastase and myeloperoxidase (MPO)] and cell‐cycle genes [including cyclin‐dependent kinase (CDK)2, CDK4, and CDK6]. Approximately 1% of RA LDGs stained positive for the G2/S phase of the cell cycle. RA LDGs had a significantly lower constitutive rate of apoptosis compared with RA neutrophils and did not respond to TNF‐α in culture. Expression of transcripts for cytokines and cytokine receptors was lower in RA LDGs. NET formation was lower in LDGs in response to PMA compared with RA neutrophils. Chemotaxis and phagocytosis was lower in RA LDGs compared with neutrophils. RA LDGs produced significantly lower amounts of ROS in response to fMLP following priming with TNF‐α. Expression of TNFR1 and ‐2 mRNA and protein was significantly lower in LDGs. We conclude that RA LDGS are functionally different from RA neutrophils, representing an immature neutrophil population within peripheral blood. Their enhanced survival properties and decreased TNF signaling are likely to have important consequences for disease pathology and response to therapy.",2017-02-01,https://www.semanticscholar.org/paper/8ac0de14582575f30347e5cb2fc99e2c8121534e,Journal of Leukocyte Biology
2717,A history of editable graphical histories,,1993-08-30,https://www.semanticscholar.org/paper/7947bbbfcf70be50aadc598335f226a84c1a5667,
3010,Tap: an app framework for dynamically composable mobile systems,"As smartphones and tablets have become ubiquitous, there is a growing demand for apps that can enable users to collaboratively use multiple mobile systems. We present Tap, a framework that makes it easy for users to dynamically compose collections of mobile systems and developers to write apps that make use of those impromptu collections. Tap users control the composition by simply tapping systems together for discovery and authentication. The physical interaction mimics and supports ephemeral user interactions without the need for tediously exchanging user contact information such as phone numbers or email addresses. Tapping triggers a simple NFC-based mechanism to exchange connectivity information and security credentials that works across heterogeneous networks and requires no user accounts or cloud infrastructure support. Tap makes it possible for apps to use existing mobile platform APIs across multiple mobile systems by virtualizing data sources so that local and remote data sources can be combined together upon tapping. Virtualized data sources can be hardware or software features, including media, clipboard, calendar events, and devices such as cameras and microphones. Leveraging existing mobile platform APIs makes it easy for developers to write apps that use hardware and software features across dynamically composed collections of mobile systems. We have implemented a Tap prototype that allows apps to make use of both unmodified Android and iOS systems. We have modified and implemented various apps using Tap to demonstrate that it is easy to use and can enable apps to provide powerful new functionality by leveraging multiple mobile systems. Our results show that Tap has good performance, even for high-bandwidth features, and is user and developer friendly.",2021-06-24,https://www.semanticscholar.org/paper/95dc1272a354aa822320a39ae0369e7dffa2a892,"ACM SIGMOBILE International Conference on Mobile Systems, Applications, and Services"
3653,Parameterized Types for C++,"Type parameterization is the ability to defrne a type in terms of another, unspecifled, type. Versions of the parameterized type may then be created for several particular parameter types. A language supporting type parameterization allows specification ofgeneral container types such as list, vector, and associative array where the specific type of the elements is left as a parameter. Thus, a parameterized class specifies an unbounded set of related types; for example: list of int, list of name, list of shape, etc. Type parameterization is one way of making a language more extensible. In the context of C++, the problems are",1989-01-03,https://www.semanticscholar.org/paper/b176b1368c966f248e906379b831df5d1b51a7c7,C++ Conference
2026,Modeling order assignment for semiconductor assembly hierarchical outsourcing and developing the decision support system,,2010-06-01,https://www.semanticscholar.org/paper/849cdca6b7100c2b1c102037c3aac17f4dd24f4c,
1731,Comment,"Republican and Democratic representatives, the goal appears to be to measure words that are indicative of partisan conflict. But because Republicans and Democrats tend to come from different parts of the country, the party labels are conflated with language that is particular to the geographic region. The author recommends including covariates to mitigate this particular problem, but without clarifying the goal of measurement, it is hard to know what covariates should be included or excluded from the model. The obscured goals also complicate the evaluation of any covariate’s value to the model. Thanks to impressive articles like the author’s, the application of machine learning techniques in the social sciences is growing. With the application of the methods there has also been an impressive number of new methods introduced. My hope is that social scientists will develop a parallel literature on the evaluation of the models. Together, this will lead to the accurate measurement of sentiment across large datasets and facilitate the discovery of new facts about the world.",2013-09-01,https://www.semanticscholar.org/paper/682000be6be3094c97d64e9a33921abc1fb5b1ca,
3385,HALLUCINATION HELPS: ENERGY EFFICIENT VIRTUAL,"We consider virtual circuit routing protocols with an objective of minimizing energy in a network of components that are speed scalable, and that may be shut down when idle. We assume the standard model for component power: the power consumed by a component with load (speed) s is \sigma + s\alpha , where \sigma is the static power and the exponent \alpha > 1. We obtain a very simple O(logk)approximation algorithm for multicommodity routing, where k is the number of demand pairs. This improves upon previous results by several logarithmic factors. The key step in our algorithm is a random sampling technique that we call hallucination, which is reminiscent of the sample-augment framework for buy-at-bulk problems, and sampling in cut-sparsification algorithms. We also consider the online setting of the problem, where demand pairs arrive over time. We show that our offline algorithm naturally extends to the online setting, and obtain a randomized competitive ratio of \~ O(log k), which is the first nontrivial bound. The analysis of this algorithm involves the study of priority multicommodity flows, where edges and demand-pairs have priorities and each demandpair must route its flow only on edges of lower priority. We establish a polylogarithmic flow-cut gap for these priority flows, which we believe is of independent interest. Finally, we show how our technique can be used to achieve a randomized (O(logm), O(log m)) bicriteria competitive algorithm for the uniform capacitated network design problem, where m is the number of edges. Here, every edge has a cost ce and uniform capacity q, and the goal is to choose the minimum cost subgraph that can support the given multicommodity demand. This is the first online algorithm for this problem. In fact, our approach also improves prior results in the offline setting by several logarithmic factors.",,https://www.semanticscholar.org/paper/a5e19426740561375cf7ea9db30aa6035f6489c9,
3566,ViewpointWhat should we teach new software developers? Why?,Fundamental changes to computer science education are required to better address the needs of industry.,,https://www.semanticscholar.org/paper/eda811221528156924ab2eb95b578c92fab609e0,CACM
2290,Regulation of neutrophil FcγRIIIb (CD16) surface expression following delayed apoptosis in response to GM‐CSF and sodium butyrate,"When neutrophils undergo apoptosis, they lose expression of the surface receptor CD16 (FcγRIIIb). Thus levels of surface CD16 are good indicators of apoptotic or non‐apoptotic neutrophils. Shedding of CD16 occurs via the activity of a metalloproteinase that cleaves the receptor from the plasma membrane. Granulocyte‐macrophage colony‐stimulating factor (GM‐CSF) and sodium butyrate both stimulate neutrophil gene expression, protect these cells from apoptosis, and maintain expression of surface CD16. In this report we have investigated whether these agents maintain surface expression of CD16 via (1) decreased shedding (2) increased mobilization of the internal pool of pre‐formed CD16, or (3) via de novo biosynthesis of new receptor molecules. Although GM‐CSF and sodium butyrate both preserved surface expression of CD16, GM‐CSF actually accelerated the rate of shedding of this receptor. Maintenance of surface levels was achieved by substantial mobilization of the internal pool of CD16. Sodium butyrate, on the other hand, maintained surface expression without extensive store depletion via a mechanism that appeared to involve a decreased rate of shedding. In these experiments we could find no evidence for de novo biosynthesis of CD16 stimulated by either GM‐CSF or sodium butyrate. These experiments indicate that multiple mechanisms exist for the maintenance of surface CD16 during rescue of neutrophils from apoptosis by different agents. J. Leukoc. Biol. 65: 875–882; 1999.",1999-06-01,https://www.semanticscholar.org/paper/53588395da6c61f88d9e169e17a0549af241cfbf,Journal of Leukocyte Biology
550,The synthesis of communication protocols,,1986-11-01,https://www.semanticscholar.org/paper/92d5d014da5dcac7c39e6fc50b81e50bdc3ae625,ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing
2264,Granulocyte Macrophage Colony-stimulating Factor Signaling and Proteasome Inhibition Delay Neutrophil Apoptosis by Increasing the Stability of Mcl-1*,"Human neutrophils normally have a very short half-life and die by apoptosis. Cytokines such as granulocyte-macrophage colony-stimulating factor (GM-CSF) can delay this apoptosis via increases in the cellular levels of Mcl-1, an anti-apoptotic protein of the Bcl-2 family with a rapid turnover rate. Here we have shown that inhibition of the proteasome (a) decreases the rate of Mcl-1 turnover within neutrophils and (b) significantly delays apoptosis. This led us to determine whether GM-CSF could enhance neutrophil survival by altering the rate of Mcl-1 turnover. Addition of GM-CSF to neutrophils enhanced Mcl-1 stability and delayed apoptosis by signaling pathways requiring PI3K/Akt and p44/42 Erk/Mek, because inhibitors of these pathways completely abrogated the GM-CSF-mediated effect on both Mcl-1 stability and apoptosis delay. Conversely, induction of Mcl-1 hyperphosphorylation by the phosphatase inhibitor, okadaic acid, significantly accelerated both Mcl-1 turnover and apoptosis. Neither the calpain inhibitor, carbobenzoxy-valinyl-phenylalaninal, nor the pan caspase inhibitor, benzyloxycarbonyl-VAD-fluoromethylketone, had any effect on Mcl-1 stability under these conditions. These observations indicate that profound changes in the rate of neutrophil apoptosis following cytokine signaling occur via dynamic changes in the rate of Mcl-1 turnover via the proteasome.",2004-06-25,https://www.semanticscholar.org/paper/cebcb1108cdfad92ebcbb37ecf89466006f3d2e4,Journal of Biological Chemistry
415,THE COMPLEXITY OF OPTIMAL QUEUING NETWORK CONTROL1,"We show that several well-known optimization problems related to the optimal control of queues are provably intractable |independently of any unproven conjecture such as P6 =NP. In particular, we show that several versions of the problem of optimally controlling a simple network of queues with simple arrival and service distributions and multiple customer classes is complete for exponential time. This is perhaps the rst such intractability result for a well-known optimization problem. We also show that the restless bandit problem (the generalization of the multi-armed bandit problem to the case in which the unselected processes are not quiescent) is complete for polynomial space.",,https://www.semanticscholar.org/paper/fc7f886fc87ffb5076a84d3d4c7da6c3af0d9693,
1639,Bayesian Learning and Inference in Recurrent Switching Linear Dynamical Systems,"Many natural systems, such as neurons firing in the brain or basketball teams traversing a court, give rise to time series data with complex, nonlinear dynamics. We can gain insight into these systems by decomposing the data into segments that are each explained by simpler dynamic units. Building on switching linear dynamical systems (SLDS), we develop a model class and Bayesian inference algorithms that not only discover these dynamical units but also, by learning how transition probabilities depend on observations or continuous latent states, explain their switching behavior. Our key innovation is to design these recurrent SLDS models to enable recent Pólya-gamma auxiliary variable techniques and thus make approximate Bayesian learning and inference in these models easy, fast, and scalable.",,https://www.semanticscholar.org/paper/fdb0543229042854dee3cfbe67e3742518bda4be,International Conference on Artificial Intelligence and Statistics
2237,Evidence That RSV Directly Infects Neutrophils in the Airways and Blood of Infants with Severe Bronchiolitis.,,2009-04-01,https://www.semanticscholar.org/paper/3fe7018a983f41c8e1195059e35a94fe59008698,Asian Test Symposium
2370,Oxygen-dependent killing of Staphylococcus aureus by human neutrophils.,Luminol-dependent chemiluminescence was used as a monitor of reactive oxidant generation during phagocytosis of Staphylococcus aureus by human neutrophils. Reactive oxidants play a crucial role in the killing of this organism because: (a) S. aureus was killed most rapidly when the rate of increase of chemiluminescence was greatest; (b) neutrophils which had been activated to generate reactive oxidants by re-aeration of anaerobic suspensions killed this bacterium more efficiently than control suspensions; and (c) neutrophils from a patient with chronic granulomatous disease could neither generate reactive oxidants nor kill S. aureus.,1987-12-01,https://www.semanticscholar.org/paper/2e288fc22119228b81c8d08173c748a19229b483,Journal of General Microbiology
2273,Control of Neutrophil Apoptosis in Rheumatoid Arthritis,,,https://www.semanticscholar.org/paper/cc8d09b4ef76ebd75c28b35ed014ae48523f5462,
1690,Variational Gaussian Process,"Abstract: Representations offered by deep generative models are fundamentally tied to their inference method from data. Variational inference methods require a rich family of approximating distributions. We construct the variational Gaussian process (VGP), a Bayesian nonparametric model which adapts its shape to match complex posterior distributions. The VGP generates approximate posterior samples by generating latent inputs and warping them through random non-linear mappings; the distribution over random mappings is learned during inference, enabling the transformed outputs to adapt to varying complexity. We prove a universal approximation theorem for the VGP, demonstrating its representative power for learning any model. For inference we present a variational objective inspired by autoencoders and perform black box inference over a wide class of models. The VGP achieves new state-of-the-art results for unsupervised learning, inferring models such as the deep latent Gaussian model and the recently proposed DRAW.",2015-11-20,https://www.semanticscholar.org/paper/ed032736652ac7e1f36ea17bd253cd1bfdcc3864,International Conference on Learning Representations
3769,Predicting Motivations of Actions by Leveraging Text,"Understanding human actions is a key problem in computer vision. However, recognizing actions is only the first step of understanding what a person is doing. In this paper, we introduce the problem of predicting why a person has performed an action in images. This problem has many applications in human activity understanding, such as anticipating or explaining an action. To study this problem, we introduce a new dataset of people performing actions annotated with likely motivations. However, the information in an image alone may not be sufficient to automatically solve this task. Since humans can rely on their lifetime of experiences to infer motivation, we propose to give computer vision systems access to some of these experiences by using recently developed natural language models to mine knowledge stored in massive amounts of text. While we are still far away from fully understanding motivation, our results suggest that transferring knowledge from language into vision can help machines understand why people in images might be performing an action.",2014-06-20,https://www.semanticscholar.org/paper/03c48850373b40f32b2bc0b1fbf7c13ccf0c8063,Computer Vision and Pattern Recognition
652,1017-74 Length of Hospital Stay After Percutaneous Transluminal Coronary Angioplasty: Clinical and Angiographic Predictors,,1995-02-01,https://www.semanticscholar.org/paper/9ed8eec6cc7a45e8c9eb278dd8cfe19416e63a57,
1060,Measurement of the Îłb Lifetime in the Exclusive Decay ÎłbâƒTM J/Ï‹Îł,,,https://www.semanticscholar.org/paper/7f7800c4be287ba3f5eeda6567ac568df7d69460,
1726,Foundations of Graphical Models,"Description. Foundations of Graphical Models is a PhD-level course about how to design and use probability models. We study their mathematical properties, algorithms for computing with them, and applications to real problems. We study both the foundations and modern methods in this ﬁeld. Our goals are to understand probabilistic modeling, to begin research that makes contributions to this ﬁeld, and to develop good practices for building and applying probabilistic models. Prerequisites. The prerequisites are: knowledge of basic probability and statistics, calculus, and some optimization; comfort writing software to analyze data; familiarity with a good programming language for statistics and machine learning, such as R or Python.",,https://www.semanticscholar.org/paper/f5c4c718a0d1705dd9960cd4d3768c0697c5a604,
3090,REPETE2: A next generation home telemedicine architecture.,"As the availability of home broadband increases, there is an increasing need for a broadband-based home telemedicine architecture. A home tele-medicine architecture supporting broadband and remote training is presented.",2007-10-11,https://www.semanticscholar.org/paper/c6f723b51cf6291288cc4566d6df58ccb7665f85,AMIA ... Annual Symposium proceedings. AMIA Symposium
3450,Proceedings of the Seventeenth Annual ACM-SIAM Symposium on Discrete Algorithms: Preface,,2006-02-28,https://www.semanticscholar.org/paper/4858290dadeb822edc1cd9a6a16def33a468efe7,ACM-SIAM Symposium on Discrete Algorithms
2664,Worlds within worlds: metaphors for exploring n -dimensional virtual worlds,,,https://www.semanticscholar.org/paper/8bf266129ee17e99f11639107d2eee473f2bd5eb,
2173,Enhanced neutrophil functions during Opisthorchis viverrini infections and correlation with advanced periductal fibrosis.,,2020-01-29,https://www.semanticscholar.org/paper/76a0604294d5983dc48e4767591cd252570ce2ef,International Journal of Parasitology
763,Analysis of Recursive Probabilistic Models,,2006-10-23,https://www.semanticscholar.org/paper/723a564507f1fcb1f0ce3043c3b67f9d958d55ff,Automated Technology for Verification and Analysis
1792,Variational Inference for Adaptor Grammars,"Adaptor grammars extend probabilistic context-free grammars to define prior distributions over trees with ""rich get richer"" dynamics. Inference for adaptor grammars seeks to find parse trees for raw text. This paper describes a variational inference algorithm for adaptor grammars, providing an alternative to Markov chain Monte Carlo methods. To derive this method, we develop a stick-breaking representation of adaptor grammars, a representation that enables us to define adaptor grammars with recursion. We report experimental results on a word segmentation task, showing that variational inference performs comparably to MCMC. Further, we show a significant speed-up when parallelizing the algorithm. Finally, we report promising results for a new application for adaptor grammars, dependency grammar induction.",2010-06-02,https://www.semanticscholar.org/paper/ebcd8b40a3d1d08bade75a30a5adddea423dd073,North American Chapter of the Association for Computational Linguistics
955,Nitric oxide attenuated transforming growth factor-β induced myofibroblast differentiation of human keratocytes,,2021-04-14,https://www.semanticscholar.org/paper/b137928bffe575226ef5b98f6c8da75b933ee24d,Scientific Reports
1263,production incollisions at,,2008-10-06,https://www.semanticscholar.org/paper/e6b20f20df54b857ca953714e994cd4c3f1621e6,
2036,A hybrid approach of data mining and genetic algorithms for rehabilitation scheduling,"To enhance the medical care quality and patient satisfaction, the hospital management has received considerable attention. This research aims to develop an intelligent approach that integrates Genetic Algorithm (GA) and Data Mining (DM) approaches to resolve the physical therapy scheduling problems to reduce patient waiting time and thus enhance service quality. In particular, this approach employed the attribute-oriented induction method to extract the patterns of the solutions generated from the GA approach. Thus, the decision rules derived from the patterns can be applied to resolve similar therapy scheduling problems with much lesser computational effort. The results of an empirical study conducted in a general hospital validated the practical viability of this approach.",,https://www.semanticscholar.org/paper/bdc12e94e3a01272ac3f28f632735af2ae8eb6fd,International Journal of Manufacturing Technology and Management (IJMTM)
3777,Inverting and Visualizing Features for Object Detection,"Abstract : This paper presents methods to visualize feature spaces commonly used in object detection. The tools in this paper allow a human to put on feature space glasses and see the visual world as a computer might see it. We found that these glasses allow us to gain insight into the behavior of computer vision systems. We show a variety of experiments with our visualizations, such as examining the linear separability of recognition in HOG space, generating high scoring super objects for an object detector, and diagnosing false positives. We pose the visualization problem as one of feature inversion, i.e. recovering the natural image that generated a feature descriptor. We describe four algorithms to tackle this task, with different trade-offs in speed accuracy, and scalability. Our most successful algorithm uses ideas from sparse coding to learn a pair of dictionaries that enable regression between HOG features and natural images, and can invert features at interactive rates. We believe these visualizations are useful tools to add to an object detector researcher's toolbox, and code is available.",2012-12-10,https://www.semanticscholar.org/paper/dc4ea16406f985b7a045cf0fa6254c8b12accf9d,arXiv.org
1446,Gamma-Ray Bursts: Detection and Distance Estimates with Milagro,,,https://www.semanticscholar.org/paper/5424a8c75d4cc3a82dd8e4724de6c98d2ae61fc5,
2797,Galectin-7 regulates keratinocyte proliferation and differentiation through JNK-miR-203-p63 signaling,,2015-09-29,https://www.semanticscholar.org/paper/c4651afa0403ef0ce6aa353b8bc69ae668b3fe86,Journal of Investigative Dermatology
1073,Production rate measurement of Tritium and other cosmogenic isotopes in Germanium with CDMSlite,,2018-06-19,https://www.semanticscholar.org/paper/aa29bcb69d2d4e84c26c86fe2ea0a3dbc9864e7f,Astroparticle physics
1162,"Relative rates of B meson decays into Sigma(2S) and J/Sigma mesons (vol 79, 111102, 2009)",,,https://www.semanticscholar.org/paper/7dd324ecf13b233633cd2f9fb9dbb80452390414,
3595,Fast dynamic casting,"We describe a scheme for implementing dynamic casts suitable for systems where the performance and predictability of performance is essential. A dynamic cast from a base class to a derived class in an object‐oriented language can be performed quickly by having the linker assign an integer type ID to each class. A simple integer arithmetic operation verifies whether the cast is legal at run time. The type ID scheme presented uses the modulo function to check that one class derives from another. A 64‐bit type ID is sufficient to handle class hierarchies of large size at least nine levels of derivation deep. We also discuss the pointer adjustments required for a C++ dynamic_cast. All examples will be drawn from the C++ language. Copyright © 2005 John Wiley & Sons, Ltd.",2006-02-01,https://www.semanticscholar.org/paper/3f566ae993364bfc435e9ef34e995af8a1a079e8,"Software, Practice & Experience"
2974,Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression,"textabstractWe propose a general algorithm for approximating nonstandard Bayesian posterior distributions. The algorithm minimizes the Kullback-Leibler divergence of an approximating distribution to the intractable posterior distribu- tion. Our method can be used to approximate any posterior distribution, provided that it is given in closed form up to the proportionality constant. The approxi- mation can be any distribution in the exponential family or any mixture of such distributions, which means that it can be made arbitrarily precise. Several exam- ples illustrate the speed and accuracy of our approximation method in practice.",2012-06-28,https://www.semanticscholar.org/paper/51336c08ea621d9c1c724607daf86991b2931fa3,arXiv.org
2336,"Changes in mechanisms of monocyte/macrophage-mediated cytotoxicity during culture. Reactive oxygen intermediates are involved in monocyte-mediated cytotoxicity, whereas reactive nitrogen intermediates are employed by macrophages in tumor cell killing.","Freshly isolated human blood monocytes were spontaneously cytotoxic toward K562 tumor cells. During culture of the monocytes in vitro cytotoxicity decreased during the first 48 h but tumoricidal competence was restored after 3 to 4 days in vitro. These changes were accompanied by changes in both reactive oxygen intermediate generating capacity and reactive nitrogen intermediate production. Lucigenin-dependent chemiluminescence stimulated with either FMLP or PMA declined during the first 2 days in culture and was negligible during the later days in culture. Superoxide radical production in response to either FMLP or PMA remained fairly constant for the first few days in vitro and then declined. NO2- concentration in monocyte-conditioned medium was fairly constant during the first few days in vitro but increased after 6 days. The return to tumoricidal competence after 3 to 4 days in culture was decreased by the addition of NG-monomethyl-L-arginine. These results indicate that reactive oxygen intermediates are employed by monocytes in the killing of tumor cells. However, after maturation of monocytes to macrophages, this mechanism becomes less important and reactive nitrogen intermediates are employed in mediating macrophage cytotoxicity.",1993-04-15,https://www.semanticscholar.org/paper/87227c615cc851d553e5114c1aab74ec6daa37e1,Journal of Immunology
2809,Galectins and cutaneous immunity,,2012-12-01,https://www.semanticscholar.org/paper/a8647aac6ed8cd32b6b13d5b76b2ed40c5874065,
785,Testing and Checking of Finite State Systems Invited Talk,"Finite state machines have been used to model a wide variety of systems, including sequential circuits, communication protocols, and other types of reactive systems, i.e., systems that interact with their environment. In testing problems we are given a system, which we may test by providing inputs and observing the outputs produced. The goal is to design test sequences so that we can deduce desired information about the given system under test, such as whether it implements correctly a given specification machine (conformance testing), or whether it satisfies given requirement properties (black-box checking). In this talk we will review some of the theory and algorithms on basic testing problems for systems modeled by different types of finite state machines. Conformance testing of deterministic machines has been investigated for a long time; we will discuss various efficient methods. Testing of nondeterministic and probabilistic machines is related to games with incomplete information and to partially observable Markov decisions processes. The verification of properties for finite state systems with a known structure (i.e., ”white box” checking) is known as the model-checking problem, and has been thoroughly studied for many years, yielding a rich theory, algorithms and tools. Black-box checking, i.e., the verification of properties for systems with an unknown structure, combines elements from model checking, conformance testing and learning.",,https://www.semanticscholar.org/paper/331cb6482a6d9490355c948bbf209b1fd7d70fec,
2239,The role of neutrophil apoptosis in juvenile-onset systemic lupus erythematosus.,"OBJECTIVE
Accumulation of apoptotic cells may lead to the development of systemic lupus erythematosus (SLE) through a breakdown in immune tolerance. Altered neutrophil apoptosis may contribute to nuclear autoantigen exposure, ultimately leading to autoantibody generation. This study aimed to determine whether neutrophil apoptosis is altered in patients with juvenile-onset SLE as compared with controls.


METHODS
Apoptosis was measured in neutrophils from patients with juvenile-onset SLE (n=12), adult-onset SLE (n=6), and pediatric patients with inflammatory (n=12) and noninflammatory (n=12) conditions. Annexin V staining and flow cytometry were used to determine neutrophil apoptosis. Proapoptotic and antiapoptotic proteins were measured in sera and in neutrophil cell lysates.


RESULTS
Neutrophil apoptosis was significantly increased in patients with juvenile-onset SLE as compared with the noninflammatory controls at time 0. Incubation of neutrophils with sera from patients with juvenile-onset SLE further increased neutrophil apoptosis as compared with incubation with sera from pediatric controls. Concentrations of TRAIL and FasL were significantly increased in sera from patients with juvenile-onset SLE, whereas interleukin-6, tumor necrosis factor alpha, and granulocyte-macrophage colony-stimulating factor (GM-CSF) were significantly decreased. Addition of GM-CSF to sera from patients with juvenile-onset SLE significantly decreased neutrophil apoptosis as compared with juvenile-onset SLE sera alone. The expression of proapoptotic proteins (caspase 3, Fas, and FADD) was elevated in juvenile-onset SLE neutrophils, whereas the expression of antiapoptotic proteins (cellular inhibitor of apoptosis 1 and 2 and X-linked inhibitor of apoptosis) was decreased. Neutrophil apoptosis correlated with biomarkers of disease activity (erythrocyte sedimentation rate and double-stranded DNA concentration) and the British Isles Lupus Assessment Group disease activity score.


CONCLUSION
Our data demonstrate an imbalance in proapoptotic and antiapoptotic factors in both neutrophils and sera from patients with juvenile-onset SLE. This imbalance results in increased neutrophil apoptosis in these patients. Correlations with markers of disease activity indicate that altered neutrophil apoptosis in juvenile-onset SLE patients may play a pathogenic role in this condition.",2009-08-01,https://www.semanticscholar.org/paper/f64d398f6adeeaed3a15c0f7fe14ccd617ad1477,Arthritis & Rheumatism
1874,An integrated framework of Industry 3.5 and an empirical study of simulation-based automated material handling system for semiconductor manufacturing,,2022-06-17,https://www.semanticscholar.org/paper/6f9f0d85b98d526e125b506dc8be29078a32bd42,International Journal of Logistics Research and Applications
1810,Decoupling Sparsity and Smoothness in the Discrete Hierarchical Dirichlet Process,"We present a nonparametric hierarchical Bayesian model of document collections that decouples sparsity and smoothness in the component distributions (i.e., the ""topics""). In the sparse topic model (sparseTM), each topic is represented by a bank of selector variables that determine which terms appear in the topic. Thus each topic is associated with a subset of the vocabulary, and topic smoothness is modeled on this subset. We develop an efficient Gibbs sampler for the sparseTM that includes a general-purpose method for sampling from a Dirichlet mixture with a combinatorial number of components. We demonstrate the sparseTM on four real-world datasets. Compared to traditional approaches, the empirical results will show that sparseTMs give better predictive performance with simpler inferred models.",2009-12-07,https://www.semanticscholar.org/paper/b5026e3fc62a9d7b244fe9a88d22907aa976a7e4,Neural Information Processing Systems
3424,How to Schedule When You Have to Buy Your Energy,,2010-09-01,https://www.semanticscholar.org/paper/98d9e84dde13a349b5dca5e2eb5239a5895df60a,"International Workshop and International Workshop on Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques"
472,Motion planning on a graph,"We are given a connected, undirected graph G on n vertices. There is a mobile robot on one of the vertices; this vertex is labeled s. Each of several other vertices contains a single movable obstacle. The robot and the obstacles may only reside at vertices, although they may be moved across edges. A vertex may never contain more than one object (robot/obstacle). In one step, we may move either the robot or one of the obstacles from its current position /spl upsi/ to a vacant vertex adjacent to v. Our goal is to move the robot to a designated vertex t using the smallest number of steps possible. The problem is a simple abstraction of a robot motion planning problem, with the geometry replaced by the adjacencies in the graph. We point out its connections to robot motion planning. We study its complexity, giving exact and approximate algorithms for several cases.<<ETX>>",1994-11-20,https://www.semanticscholar.org/paper/acae14ccf64df5bff042db74b4bbbb56471d8f58,Proceedings 35th Annual Symposium on Foundations of Computer Science
3587,Using ownership types to support library aliasing boundaries,"This paper describes a library for concurrency used in a 10developer videogame project. The developers were inexperienced, yet there were no problems with data races in the multi-threaded application. We credit this to the explicit representation of ownership in the design of the library. Correct library usage implies aliasing boundaries which bear a strong resemblance to the ownersas-dominators property enforced by ownership types. We explore other situations where analogous aliasing boundaries exist and discuss a family of related libraries that could benefit from a design explicitly representing ownership. The ownership relations in the library currently have no support from the type system. We examine approaches to embed static checking of the aliasing boundaries in our implementation language, C ++.",,https://www.semanticscholar.org/paper/126538e02b2a0880b0c42ec253bd5ac57ef45760,
839,The Traveling Salesman Problem with Distances One and Two,"We present a polynomial-time approximation algorithm with worst-case ratio 7/6 for the special case of the traveling salesman problem in which all distances are either one or two. We also show that this special case of the traveling salesman problem is MAX SNP-hard, and therefore it is unlikely that it has a polynomial-time approximation scheme.",1993-02-01,https://www.semanticscholar.org/paper/85502d9b5621594d6c71d01cd5cfee5f903d69cf,Mathematics of Operations Research
2468,From GPS and virtual globes to spatial computing - 2020,,2015-10-01,https://www.semanticscholar.org/paper/6e36881442c538c7273554eddde473bf4ef5c8c8,GeoInformatica
3316,Natural and sexual selection and the evolution of multi-level societies: insights from zebras with comparisons to primates,"INTRODUCTION Animal societies derive from the social relationships that exist among its members (Hinde, 1983). Behavioural ecologists have traditionally focused on the core relationships defining a mating system as a means toward understanding the role of ecology in the evolution of sociality (e.g. Jarman, 1974; Bradbury & Vehrencamp, 1977). Typically, these core relationships emerge from the operation of both natural and sexual selection and how they differently affect the behaviour of females and males (Rubenstein, 1986; van Schaik, 1989). However, emphasis on mating systems has tended to marginalise the importance to social evolution of interactions and relationships that extend beyond the basic breeding unit. This is even true for the small subset of species with multi-level societies, where breeding units and other social subgroups are themselves organised into more complex social groups within a population. By examining how natural and sexual selection operate within multi-level societies, however, a more complete understanding of the function and evolution of sociality emerges than would by investigating the dynamics of mating systems alone (e.g. Dunbar, 1988). Although the societies of many primate species are multi-levelled, the relative simplicity of societies of plains zebras ( Equus burchelli ) where only two tiers exist – the core breeding units and the herds they often comprise – can provide insights into the rules that give form to multi-level societies. In this chapter we begin by highlighting the environmental and sociosexual factors that shape zebra mating systems and herd dynamics.",2004-05-01,https://www.semanticscholar.org/paper/a42a9297e9913e426d9f1de2e679cbb285748604,
3359,CHAPTER 3 – On the Evolution of Alternative Mating Strategies,,,https://www.semanticscholar.org/paper/6a542dc1ea88ddbb5c10c864bd0fb572a03e2692,
527,Probabilistic satisfiability,,1988-03-01,https://www.semanticscholar.org/paper/4005f6485750a2b6b922a6af9d2be6aa3c42b40d,Journal of Complexity
133,"Adaptive, Deadlock-Free Packet Routing in Torus Networks with Minimal Storage",,,https://www.semanticscholar.org/paper/fa198c2e553847f637d237944459fe1b8eb5540f,International Conference on Parallel Processing
1009,Retinal Oximetry Based on Nonsimultaneous Image Acquisition Using a Conventional Fundus Camera,"To measure the retinal arteriole and venule oxygen saturation (SO2) using a conventional fundus camera, retinal oximetry based on nonsimultaneous image acquisition was developed and evaluated. Two retinal images were sequentially acquired using a conventional fundus camera with two bandpass filters (568 nm: isobestic, 600 nm: nonisobestic wavelength), one after another, instead of a built-in green filter. The images were registered to compensate for the differences caused by eye movements during the image acquisition. Retinal SO2 was measured using two wavelength oximetry. To evaluate sensitivity of the proposed method, SO2 in the arterioles and venules before and after inhalation of 100% O2 were compared, respectively, in 11 healthy subjects. After inhalation of 100% O2, SO2 increased from 96.0 ± 6.0% to 98.8% ± 7.1% in the arterioles (p = 0.002) and from 54.0 ± 8.0% to 66.7% ± 7.2% in the venules (p = 0.005) (paired t-test, n = 11). Reproducibility of the method was 2.6% and 5.2% in the arterioles and venules, respectively (average standard deviation of five measurements, n = 11).",2011-04-07,https://www.semanticscholar.org/paper/5627936cb807ddb7d18949bccdf868db9f258e10,IEEE Transactions on Medical Imaging
3073,GamePod: Persistent Gaming Sessions on Pocketable Storage Devices,"We present GamePod, a portable system that enables mobile users to use the same persistent, gaming environment on any available computer. No matter what computer is being used, GamePod provides a consistent gaming environment, maintaining all of a user's games, including active game state. This is achieved by leveraging rapid improvements in capacity, cost, and size of portable storage devices. GamePod provides a middleware layer that enables virtualization and checkpoint/restart functionality that decouples the gaming environment from a host machine. This enables gaming sessions to be suspended to portable storage, carried around, and resumed from the storage device on another computer. GamePod's middleware layer also isolates gaming sessions from the host, protecting the host by preventing malicious executable content from damaging the host. We have implemented a Linux GamePod prototype and demonstrate its ability to quickly suspend and resume gaming sessions, enabling a seamless gaming experience for mobile users as they move among computers.",2009-10-11,https://www.semanticscholar.org/paper/69e8214ef4a374299f3ce1abddb7aeddc79514fb,"2009 Third International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies"
436,Maximizing throughput of reliable bulk network transmissions,"We study combinatorial optimization and on-line scheduling problems which arise in the context of supporting applications which transmit bulk data over high-speed networks. One of our primary objectives in this thesis work is to formulate appropriate theoretical models in which to develop and analyze efficient algorithms for these problems--models which reflect both the experience of network architects, the design of network protocols, and contributions of theoretical research. 
We first consider the optimization problem of maximizing the utilization of a shared resource, network bandwidth, across a set of point-to-point connections. A feasible solution to this allocation problem is an assignment of transmission rates to the connections which does not violate the capacity constraints of the network links. The connections and routers which are responsible for establishing this allocation must do so with incomplete information and limited communication capabilities. We develop a theoretical model which addresses these considerations and study the tradeoff between the quality of the solution we can obtain and the distributed running time. Our main theoretical result is a distributed algorithm for this problem which generates a feasible $(1+\epsilon)$-approximation to the optimal allocation in a polylogarithmic number of distributed rounds. A sequential implementation of our distributed algorithm gives a simple, efficient approximation algorithm for general positive linear programming. Subsequent experience with an implementation of the algorithm indicates that it is well suited to future deployment in high-speed networks. 
The next problem we consider is the following on-line scheduling problem, which the sender of a point-to-point bulk transmission must address: Given an on-line sequence of transmission times, determine which data item to transmit at each transmission time, so as to maximize effective throughput to the receiver at all points in time. For this application, we measure effective throughput as the length of the intact prefix of the message at the receiver. This problem is made difficult in practice by factors beyond the sender's control, such as packet loss and wide variance in packet round-trip times. Using the method of competitive analysis, we compare the performance of our algorithm to that of an omniscient algorithm. We prove that while all deterministic policies perform poorly in this model, a simple randomized policy delivers near-optimal performance at any given point in time with high probability. Moreover, our theoretical result ensures that typical performance does not degrade significantly--a claim which our empirical studies bear out. 
Using the models and tools developed for these problems, we then consider analogous problems which arise for multicast bulk transmissions, transmissions targeted to multiple destinations. We show how to tune our bandwidth allocation policy to still deliver a $(1+\epsilon)$ approximation to the optimal allocation in a polylogarithmic number of distributed rounds. For the scheduling problem, we prove that no on-line scheduling policy can deliver high performance which scales with the number of receivers without using encoding. We then show that by using forward error correction coding techniques, a simple multicast policy delivers effective throughput within a constant factor of optimal independent of the number of receivers.",,https://www.semanticscholar.org/paper/64995b895b61a59072fbf4a1f42238ca3fe1bad1,
1239,Measurement of σ ( p ¯ p → Z ) · Br( Z → τ τ ) at √ s =1.96 TeV,"We present a measurement of the cross section for Z production times the branching fraction to τ leptons, σ · Br( Z → τ + τ − ), in p ¯ p collisions at √ s =1.96 TeV in the channel in which one τ decays into µν µ ν τ , and the other into hadrons+ ν τ or eν e ν τ . The data sample corresponds to an integrated luminosity of 226 pb − 1 collected with the DØ detector at the Fermilab Tevatron collider. The ﬁnal sample contains 2008 candidate events with an estimated background of 55%. From this we obtain σ · Br( Z → τ + τ − ) = 237 ± 15(stat) ± 18(sys) ± 15(lum) pb, in agreement with the standard model prediction.",,https://www.semanticscholar.org/paper/90b65993745c65d4391d99b1e62d2717b970f8c1,
2864,"Cardiovascular, Pulmonary and Renal Pathology Critical Role for Galectin-3 in Airway Inflammation and Bronchial Hyperresponsiveness in a Murine Model of Asthma","From the Division of Allergy,* La Jolla Institute for Allergy and Immunology, San Diego, California; the Department of Dermatology, University of California, Davis, School of Medicine, Sacramento, California; the Department of Molecular and Experimental Medicine, The Scripps Research Institute, La Jolla, California; and the Department of Medicine, Harvard Medical School, Brigham and Women’s Hospital, Boston, Massachusetts",,https://www.semanticscholar.org/paper/29ef1d2fd282524e79935bd9f7f263652ee2df40,
427,"Elements of the theory of computation, 2nd Edition",,,https://www.semanticscholar.org/paper/a7c5cf0936f7711e8fbf71d37cfd61a1e5e92290,
568,Intractable problems in control theory,"This paper is a study of the apparent intractability of problems in decentralized decision-making, using the concepts and methods of Complexity Theory. We first establish that the discrete version of an important paradigm for this area, proposed by Witsenhausen, is NP-complete, thus explaining the failures reported in the literature to attack it computationally. In the rest of the paper we show that the computational intractability of the discrete version of a control problem can imply that there are no satisfactory (continuous) algorithms for the continuous version. To this effect, we develop a theory of continuous algorithms and their complexity, and an analytical methodology, which can prove quite interesting by themselves.",1985-12-01,https://www.semanticscholar.org/paper/f76fc150541640fc710990606a69ba79863282c4,IEEE Conference on Decision and Control
2170,The Inhibitory Effect of Human Beta-defensin-3 on Candida Glabrata Isolated from Patients with Candidiasis,"ABSTRACT Candida glabrata is a common non-albicans Candida species found in patients with candidiasis and it sometimes develops antifungal resistance. Human beta-defensin-3 (hBD-3) is an antimicrobial peptide of immune system active against various types of microbes including Candida spp. This study investigated antifungal activity of hBD-3 and its synergistic effect with a first-line antifungal agent on C. glabrata clinical isolates. Candida spp. were characterised in patients with candidiasis. The antifungal activities of hBD-3 and fluconazole against C. glabrata were evaluated using Broth microdilution assay. The synergistic activity of these two agents was determined by checkerboard microdilution and time-killing assays. The cytotoxicity of hBD-3 was evaluated using LDH-cytotoxicity colorimetric assay. Of 307 episodes from 254 patients diagnosed with candidiasis, C. glabrata was found in 21 clinical isolates. Antifungal susceptibility tests of C. glabrata were performed, fluconazole demonstrated an inhibitory effect at concentrations of 0.25-8 μg/ml, but one antifungal resistant strain was identified (>64 μg/ml). hBD-3 showed an inhibitory effect against all selected strains at concentrations of 50-75 μg/ml and exhibited a synergistic effect with fluconazole at the fractional inhibitory concentration index (FICI) of 0.25-0.50. A concentration of 25 μg/ml of hBD-3 alone showed no cytotoxicity but synergistic activity was seen with fluconazole. In conclusion, hBD-3 has antifungal activity against C. glabrata and synergistic effects with fluconazole at concentrations that alone, have no cytotoxicity. hBD-3 could be used as an adjunctive therapy with first-line antifungal agents for patients with C. glabrata infection particularly those infected with fluconazole-resistant strains.",2020-04-22,https://www.semanticscholar.org/paper/4aae600730758b948a5a6897b3c5c659baad395e,Immunological Investigations
1626,Frequentist Consistency of Variational Bayes,"ABSTRACT A key challenge for modern Bayesian statistics is how to perform scalable inference of posterior distributions. To address this challenge, variational Bayes (VB) methods have emerged as a popular alternative to the classical Markov chain Monte Carlo (MCMC) methods. VB methods tend to be faster while achieving comparable predictive performance. However, there are few theoretical results around VB. In this article, we establish frequentist consistency and asymptotic normality of VB methods. Specifically, we connect VB methods to point estimates based on variational approximations, called frequentist variational approximations, and we use the connection to prove a variational Bernstein–von Mises theorem. The theorem leverages the theoretical characterizations of frequentist variational approximations to understand asymptotic properties of VB. In summary, we prove that (1) the VB posterior converges to the Kullback–Leibler (KL) minimizer of a normal distribution, centered at the truth and (2) the corresponding variational expectation of the parameter is consistent and asymptotically normal. As applications of the theorem, we derive asymptotic properties of VB posteriors in Bayesian mixture models, Bayesian generalized linear mixed models, and Bayesian stochastic block models. We conduct a simulation study to illustrate these theoretical results. Supplementary materials for this article are available online.",2017-05-09,https://www.semanticscholar.org/paper/534403a65fa011cc29a09e29864a88cd6216a0dd,Journal of the American Statistical Association
724,Joint Cyber and Physical Attacks on Power Grids: Graph Theoretical Approaches for Information Recovery,"Recent events demonstrated the vulnerability of power grids to cyber attacks and to physical attacks. Therefore, we focus on joint cyber and physical attacks and develop methods to retrieve the grid state information following such an attack. We consider a model in which an adversary attacks a zone by physically disconnecting some of its power lines and blocking the information flow from the zone to the grid's control center. We use tools from linear algebra and graph theory and leverage the properties of the power flow DC approximation to develop methods for information recovery. Using information observed outside the attacked zone, these methods recover information about the disconnected lines and the phase angles at the buses. We identify sufficient conditions on the zone structure and constraints on the attack characteristics such that these methods can recover the information. We also show that it is NP-hard to find an approximate solution to the problem of partitioning the power grid into the minimum number of attack-resilient zones. However, since power grids can often be represented by planar graphs, we develop a constant approximation partitioning algorithm for these graphs. Finally, we numerically study the relationships between the grid's resilience and its structural properties, and demonstrate the partitioning algorithm on real power grids. The results can provide insights into the design of a secure control network for the smart grid.",2015-06-15,https://www.semanticscholar.org/paper/851ad77e848f708bc42dd8e885420fe7493308ef,Measurement and Modeling of Computer Systems
1302,"Search for neutral, long-lived particles decaying into two muons in pp[over] collisions at sqrt[s]=1.96 TeV.","We present a search for a neutral particle, pair produced in pp[over] collisions at sqrt[s]=1.96 TeV, which decays into two muons and lives long enough to travel at least 5 cm before decaying. The analysis uses approximately 380 pb(-1) of data recorded with the D0 detector. The background is estimated to be about one event. No candidates are observed, and limits are set on the pair-production cross section times branching fraction into dimuons + X for such particles. For a mass of 10 GeV and lifetime of 4x10(-11) s, we exclude values greater than 0.14 pb (95% C.L.). These results are used to limit the interpretation of NuTeV's excess of dimuon events.",2006-07-17,https://www.semanticscholar.org/paper/10d0edeef8eb4c4bb0331eca5d6164d022df86a8,Physical Review Letters
1897,A UNISON framework for knowledge management of university-industry collaboration and an illustration,,2019-03-01,https://www.semanticscholar.org/paper/aa81a441b01bbe3225bc1d4f217c3229c0f3d597,Computers & industrial engineering
2832,Role of galectin-3 in macrophage response to Listeria monocytogenes infection (133.34),"
 Galectin-3 is a β-galactoside-binding animal lectin expressed in various immune cell types including macrophages. It has been implicated as a positive regulator of macrophage phagocytosis and as a negative regulator of LPS-mediated inflammation. However, its role in macrophage antibacterial function has not been fully elucidated. The aim of this study was to investigate the role of galectin-3 in macrophage antibacterial function against Listeria monocytogenes (LM) infection by studying bone marrow-derived macrophages (BMM) from galectin-3-deficient (gal3-/-) and wild-type (gal3+/+) mice. After in vitro infection, gal3-/- BMM contained significantly fewer viable intracellular bacteria than gal3+/+ BMM. Consistently, immunofluorescent staining of infected BMM revealed a significantly lower percentage of cytosolic LM escaped from phagosomes in gal3-/- BMM compared to gal3+/+ BMM. Higher levels of reactive nitrogen intermediate nitric oxide (NO) but lower levels of inflammatory cytokine IL-1β were detected in LM-infected gal3-/- BMM compared to gal3+/+ cells. In addition, we noted elevated levels of NAD(P)H in gal3-/- BMM which may contribute to higher amounts of NO in gal3-/- BMM. We conclude that galectin-3 plays a regulatory role in macrophage antibacterial function by interfering with the production of NO, thereby facilitating the survival and replication of intracellular bacteria.",2009-04-01,https://www.semanticscholar.org/paper/972f323f0545fd93072011a81b64810f5b0cc372,Journal of Immunology
1714,Interpretability Constraints and Trade-offs in Using Mixed Membership Models,8.,,https://www.semanticscholar.org/paper/c3c3e2e0f6e54b4da70ceeb81cc5c274731c88b6,
2024,A simulation optimization-based framework for capacity planning under uncertainty,"Capacity planning in semiconductor manufacturing industry is a challenging task due to its high capital investments, volatile demands, and the long lead time. Current approaches to handle this problem are to model it as an optimization problem where the uncertain demand is either based on a single forecast, or is decomposed via a finite-scenario structure with an assigned probability for each scenario to reflect the likelihood of occurrence. However, when the uncertainty cannot be decomposed into finite scenarios or when the number of possible scenarios is extremely large, traditional approaches such as the mathematical programming either cannot deal with the problem or may require unreasonable computing time. In this paper, we consider a multiple-period capacity planning problem where the uncertain demand is modeled as a continuous stochastic process over the planning horizon. Moreover, the long lead time and capacity migrations between different products are taken into account to accurately determine the optimal capacity plan. A new framework based on sample path method in simulation optimization is proposed to solve the problem. Comparing to traditional methods, the new framework is much more efficient in terms of the required computing time, as is demonstrated in the computational study.",2010-07-25,https://www.semanticscholar.org/paper/4e8f4e402f7a40171de71b98de8200a2ac494813,The 40th International Conference on Computers & Indutrial Engineering
2217,Inhibition of pre‐B cell colony‐enhancing factor (PBEF/NAMPT/visfatin) decreases the ability of human neutrophils to generate reactive oxidants but does not impair bacterial killing,"NAMPT, also known as PBEF and visfatin, can act extracellularly as a cytokine‐like molecule or intracellularly as a NAMPT, regulating NAD biosynthesis in the NAD salvage pathway. Inhibitors of NAMPT have anti‐inflammatory and anticancer activity and are finding use as therapeutic agents. In view of the importance of NAD metabolism in neutrophil function, we determined the effects of NAMPT inhibition on a variety of neutrophil functions associated with their role in host protection against infections. Incubation of human neutrophils with the NAMPT inhibitor APO866 decreased neutrophil NAD(P)/H levels in a dose‐ and time‐dependent manner but without a concomitant change in cell viability. NAMPT inhibition did not affect the expression of a number of cell‐surface receptors involved in adhesion and opsono‐phagocytosis, but the respiratory burst was decreased significantly. Whereas opsono‐phagocytosis of Staphylococcus aureus was unaffected by NAMPT inhibition, intraphagosomal oxidant production was decreased. However, the killing efficiency of neutrophils was unaffected. These data indicate that therapeutic NAMPT inhibition is unlikely to have deleterious effects on host protection against infections, in spite of this ability to down‐regulate neutrophil respiratory burst activity significantly.",2013-09-01,https://www.semanticscholar.org/paper/ed69abace0d4e8a2918f69502ee336d083c24263,Journal of Leukocyte Biology
2566,Virtual Vouchers: Prototyping a Mobile Augmented Reality User Interface for Botanical Species Identification,"the tools that botanists require for field-work must evolve and take on new forms. Of particular importance is the ability to identify existing and new species in the field. Mobile augmented reality systems can make it possible to access, view, and inspect a large database of virtual species examples side-by-side with physical specimens. In this paper, we present prototypes of a mobile augmented reality electronic field guide and techniques for displaying and inspecting computer vision-based visual search results in the form of virtual vouchers. Our work addresses head-movement controlled augmented reality for hands-free interaction and tangible augmented reality. We describe results from our design and investigation process and discuss observations and feedback from lab trials by botanists.",2006-03-25,https://www.semanticscholar.org/paper/069d63cd6d9a8d6a68df2949e1904bdea48c88c6,IEEE Symposium on 3D User Interfaces
2413,Synesthesia AR: Creating Sound-to-Color Synesthesia in Augmented Reality,"Sound-to-color synesthesia is a neurological condition in which people experience different colors and shapes when listening to music. We present an augmented reality application that aims to create an interactive synesthesia experience for non-synesthetes. In this application, users can visualize colors corresponding to each unique note in the 12-tone equal-temperament tuning system, and the auditory input can be selected from audio files or real-time microphone. A gestural hand-tracking interface allows users to paint the world space in visualized synesthetic colors.",2022-03-01,https://www.semanticscholar.org/paper/64f976c39f2dff85a0f68f25e89fe0a4758f8d55,2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)
3716,Adversarial Attacks are Reversible with Natural Supervision,"We find that images contain intrinsic structure that enables the reversal of many adversarial attacks. Attack vectors cause not only image classifiers to fail, but also collaterally disrupt incidental structure in the image. We demonstrate that modifying the attacked image to restore the natural structure will reverse many types of attacks, providing a defense. Experiments demonstrate significantly improved robustness for several state-of-the-art models across the CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets. Our results show that our defense is still effective even if the attacker is aware of the defense mechanism. Since our defense is deployed during inference instead of training, it is compatible with pre-trained networks as well as most other defenses. Our results suggest deep networks are vulnerable to adversarial examples partly because their representations do not enforce the natural structure of images.",2021-03-26,https://www.semanticscholar.org/paper/d59fb7b76578e725d3179aa236ba8a26c5e7b844,IEEE International Conference on Computer Vision
2840,Lack of galectin‐3 alters the balance of innate immune cytokines and confers resistance to Rhodococcus equi infection,"Galectin‐3 is a β‐galactoside‐binding lectin implicated in the fine‐tuning of innate immunity. Rhodococcus equi, a facultative intracellular bacterium of macrophages, causes severe granulomatous bronchopneumonia in young horses and immunocompromised humans. The aim of this study is to investigate the role of galectin‐3 in the innate resistance mechanism against R. equi infection. The bacterial challenge of galectin‐3‐deficient mice (gal3−/−) and their wild‐type counterpart (gal3+/+) revealed that the LD50 for the gal3−/− mice was about seven times higher than that for the gal3+/+ mice. When challenged with a sublethal dose, gal3−/− mice showed lower bacteria counts and higher production of IL‐12 and IFN‐γ production, besides exhibiting a delayed although increased inflammatory reaction. Gal3−/− macrophages exhibited a decreased frequency of bacterial replication and survival, and higher transcript levels of IL‐1β, IL‐6, IL‐10, TLR2 and MyD88. R. equi‐infected gal3+/+ macrophages showed decreased expression of TLR2, whereas R. equi‐infected gal3−/− macrophages showed enhanced expression of this receptor. Furthermore, galectin‐3 deficiency in macrophages may be responsible for the higher IL‐1β serum levels detected in infected gal3−/− mice. Therefore galectin‐3 may exert a regulatory role in innate immunity by diminishing IL‐1β production and thus affecting resistance to R. equi infection.",2008-10-01,https://www.semanticscholar.org/paper/4cf31d4d82136ea0fed05cb06f16ba6c74164eed,European Journal of Immunology
2507,Awareness of the Care Team in Electronic Health Records,"Summary Objective: To support collaboration and clinician-targeted decision support, electronic health records (EHRs) must contain accurate information about patients’ care providers. The objective of this study was to evaluate two approaches for care provider identification employed within a commercial EHR at a large academic medical center. Methods: We performed a retrospective review of EHR data for 121 patients in two cardiology wards during a four-week period. System audit logs of chart accesses were analyzed to identify the clinicians who were likely participating in the patients’ hospital care. The audit log data were compared with two functions in the EHR for documenting care team membership: 1) a vendor-supplied module called “Care Providers”, and 2) a custom “Designate Provider” order that was created primarily to improve accuracy of the attending physician of record documentation. Results: For patients with a 3–5 day hospital stay, an average of 30.8 clinicians accessed the electronic chart, including 10.2 nurses, 1.4 attending physicians, 2.3 residents, and 5.4 physician assistants. The Care Providers module identified 2.7 clinicians/patient (1.8 attending physicians and 0.9 nurses). The Designate Provider order identified 2.1 clinicians/patient (1.1 attending physicians, 0.2 resident physicians, and 0.8 physician assistants). Information about other members of patients’ care teams (social workers, dietitians, pharmacists, etc.) was absent. Conclusions: The two methods for specifying care team information failed to identify numerous individuals involved in patients’ care, suggesting that commercial EHRs may not provide adequate tools for care team designation. Improvements to EHR tools could foster greater collaboration among care teams and reduce communication-related risks to patient safety.",,https://www.semanticscholar.org/paper/5cd5ba3dbe58348497f9000f687e6789c3fe0340,Applied Clinical Informatics
1247,1 2 0 N ov 2 00 0 A Quasi-Model-Independent Search for New Physics at Large Transverse Momentum,"We apply a quasi-model-independent strategy (“Sleuth”) to search for new high pT physics in ≈ 100 pb of pp̄ collisions at √ s = 1.8 TeV collected by the DØ experiment during 1992–1996 at the Fermilab Tevatron. Over thirty-two eμX, W+jets-like, Z+jets-like, and (l/γ)(l/γ)(l/γ)X exclusive final states are systematically analyzed for hints of physics beyond the standard model. Simultaneous sensitivity to a variety of models predicting new phenomena at the electroweak scale is demonstrated by testing the method on a particular signature in each set of final states. No evidence of new high pT physics is observed in the course of this search, and we find that 89% of an ensemble of hypothetical similar experimental runs would have produced a final state with a candidate signal more interesting than the most interesting observed in these data.",,https://www.semanticscholar.org/paper/ac1196595cc4193ae907e80528a2a4ffe2650942,
2695,Data characterization for automatically visualizing heterogeneous information,"Automated graphical generation systems should be able to design effective presentations for heterogeneous (quantitative and qualitative) information in static or interactive environments. When building such a system, it is important to thoroughly understand the presentation-related characteristics of domain-specific information. We define a data-analysis taxonomy that can be used to characterize heterogeneous information. In addition to capturing the presentation-related properties of data, our characterization takes into account the user's information-seeking goals and visual-interpretation preferences. We use automatically-generated examples from two different application domains to demonstrate the coverage of the proposed taxonomy and its utility for selecting effective graphical techniques.",1996-10-28,https://www.semanticscholar.org/paper/c430e684e5f99874cb8abb49cc89812193ab4bfa,Proceedings IEEE Symposium on Information Visualization '96
586,Communication complexity,"In this paper we prove several results concerning this complexity measure. First we establish (in a non-constructive manner) that there exist languages which cannot be recognized with less than <italic>n</italic> communication (obviously, communication <italic>n</italic> is always enough for recognizing any language). In fact, we show that for any function<italic>f(n)-&-lt; n,</italic> there are languages recognizable with communication<italic>f(n)</italic> but not with communication<italic>f (n)</italic>-&-minus;1. In other words, this complexity measure possesses a very dense hierarchy or complexity classes, as miniscule increments in communication add to the languages that can be recognized.",1982-05-05,https://www.semanticscholar.org/paper/0ef9546e001dbdb7ba13818feb1f9b2f442f2ce5,Symposium on the Theory of Computing
1220,Search for neutral Higgs bosons in multi-b-jet events in pp[over] collisions at sqrt[s]=1.96 TeV.,Data recorded by the D0 experiment at the Fermilab Tevatron Collider are analyzed to search for neutral Higgs bosons produced in association with b quarks. This production mode can be enhanced in the minimal supersymmetric standard model (MSSM). The search is performed in the three b quark channel using multijet triggered events corresponding to an integrated luminosity of 1 fb(-1). No statistically significant excess of events with respect to the predicted background is observed and limits are set in the MSSM parameter space.,,https://www.semanticscholar.org/paper/5402271e59ac2c36c89e5098da6bae6cc47025bc,Physical Review Letters
3026,Binary compatible graphics support in Android for running iOS apps,"Mobile apps make extensive use of GPUs on smartphones and tablets to access Web content. To support pervasive Web content, we introduce three key OS techniques for binary graphics compatibility necessary to build a real-world system to run iOS and Android apps together on the same smartphone or tablet. First diplomat usage patterns manage resources to bridge proprietary iOS and Android graphics implementations. Second, thread impersonation allows a single thread-specific context to be shared amongst multiple threads using multiple iOS and Android personas. Third, dynamic library replication allows multiple, independent instances of the same library to be loaded in a single process to support iOS apps on Android while using multiple graphics API versions at the same time. We use these techniques to build a system prototype, and demonstrate that it runs widely-used iOS apps, including apps such as Safari that use the popular GPU-accelerated WebKit framework, using a Google Nexus tablet running Android.",2017-12-11,https://www.semanticscholar.org/paper/3416a5227b1e1956acfacba812081c2686367471,International Middleware Conference
64,Efficient IR-Style Keyword Search over Relational Databases,,2003-09-09,https://www.semanticscholar.org/paper/15c71e9d0b467796ecc0519fe64203a4a79f76e5,Very Large Data Bases Conference
2492,3D referencing techniques for physical objects in shared augmented reality,"We introduce an augmented reality referencing technique for shared environments that is designed to improve the accuracy with which one user can point out a real physical object to another user. Our technique, GARDEN (Gesturing in an Augmented Reality Depth-mapped ENvironment), is intended for use in otherwise unmodeled environments in which objects in the environment, and the hand of the user performing a selection, are interactively observed by a depth camera, and users wear tracked see-through displays. We present the results of a user study that compares GARDEN against existing augmented reality referencing techniques, as well as the use of a physical laser pointer. GARDEN performed significantly more accurately than all the comparison techniques when the participating users have sufficiently different views of the scene, and significantly more accurately than one of these techniques when the participating users have similar perspectives.",2012-11-05,https://www.semanticscholar.org/paper/1c5ae751e49b49926c21518c962a7a3dc8696234,International Symposium on Mixed and Augmented Reality
3225,Knowledgeable Lemurs Become More Central in Social Networks,,2018-04-23,https://www.semanticscholar.org/paper/61b3cfe5cc085225312adf897fb61014d9339bd1,Current Biology
280,On oblivious PTAS's for nash equilibrium,"If a class of games is known to have a Nash equilibrium with probability values that are either zero or Ω(1) -- and thus with support of bounded size -- then obviously this equilibrium can be found exhaustively in polynomial time. Somewhat surprisingly, we show that there is a PTAS for the class of games whose equilibria are guaranteed to have small --- O(1/n) -- values, and therefore large -- Ω(n) -- supports. We also point out that there is a PTAS for games with sparse payoff matrices, a family for which the exact problem is known to be PPAD-complete [Chen, Deng, Teng 2006]. Both algorithms are of a special kind that we call oblivious: The algorithm just samples a fixed distribution on pairs of mixed strategies, and the game is only used to determine whether the sampled strategies comprise an ε-Nash equilibrium; the answer is ""yes"" with inverse polynomial probability (in the second case, the algorithm is actually deterministic). These results bring about the question: Is there an oblivious PTAS for finding a Nash equilibrium in general games? We answer this question in the negative; our lower bound comes close to the quasi-polynomial upper bound of [Lipton, Markakis, Mehta 2003]. Another recent PTAS for anonymous games [Daskalakis, Papadimitriou 2007 and 2008, Daskalakis 2008] is also oblivious in a weaker sense appropriate for this class of games (it samples from a fixed distribution on unordered collections of mixed strategies), but its running time is exponential in 1/ε. We prove that any oblivious PTAS for anonymous games with two strategies and three player types must have 1/εα in the exponent of the running time for some α ≥ 1/3, rendering the algorithm in [Daskalakis 2008] (which works with any bounded number of player types) essentially optimal within oblivious algorithms. In contrast, we devise a poly n • (1/ε)O(\log2(1/ε)) non-oblivious PTAS for anonymous games with two strategies and any bounded number of player types. The key idea of our algorithm is to search not over unordered sets of mixed strategies, but over a carefully crafted set of collections of the first O(log 1/ε) moments of the distribution of the number of players playing strategy 1 at equilibrium. The algorithm works because of a probabilistic result of more general interest that we prove: the total variation distance between two sums of independent indicator random variables decreases exponentially with the number of moments of the two sums that are equal, independent of the number of indicators.",2009-05-31,https://www.semanticscholar.org/paper/d41b5308fe2cbbd3e653951c3362e7b32841c5a1,Symposium on the Theory of Computing
684,Multiple Instance Learning with Manifold Bags,"In many machine learning applications, labeling every instance of data is burdensome. Multiple Instance Learning (MIL), in which training data is provided in the form of labeled bags rather than labeled instances, is one approach for a more relaxed form of supervised learning. Though much progress has been made in analyzing MIL problems, existing work considers bags that have a finite number of instances. In this paper we argue that in many applications of MIL (e.g. image, audio, etc.) the bags are better modeled as low dimensional manifolds in high dimensional feature space. We show that the geometric structure of such manifold bags affects PAC-learnability. We discuss how a learning algorithm that is designed for finite sized bags can be adapted to learn from manifold bags. Furthermore, we propose a simple heuristic that reduces the memory requirements of such algorithms. Our experiments on real-world data validate our analysis and show that our approach works well.",2011-06-28,https://www.semanticscholar.org/paper/097968d3115689d1df054b8678bc290df5d63bc5,International Conference on Machine Learning
1228,Measurement of the Polarization of theandStates inCollisions at,,2008-10-31,https://www.semanticscholar.org/paper/790bb319954bcc56485c448431c10ffc5ccb32e7,
41,Optimizing SQL Queries over Text Databases,"Text documents often embed data that is structured in nature, and we can expose this structured data using information extraction technology. By processing a text database with information extraction systems, we can materialize a variety of structured ""relations,"" over which we can then issue regular SQL queries. A key challenge to process SQL queries in this text-based scenario is efficiency: information extraction is time-consuming, so query processing strategies should minimize the number of documents that they process. Another key challenge is result quality: in the traditional relational world, all correct execution strategies for a SQL query produce the same (correct) result; in contrast, a SQL query execution over a text database might produce answers that are not fully accurate or complete, for a number of reasons. To address these challenges, we study a family of select-project-join SQL queries over text databases, and characterize query processing strategies on their efficiency and - critically - on their result quality as well. We optimize the execution of SQL queries over text databases in a principled, cost-based manner, incorporating this tradeoff between efficiency and result quality in a user-specific fashion. Our large-scale experiments- over real data sets and multiple information extraction systems - show that our SQL query processing approach consistently picks appropriate execution strategies for the desired balance between efficiency and result quality.",2008-04-07,https://www.semanticscholar.org/paper/c81a0b8e4bb79cd72dc22bcf966a58504a04e979,IEEE International Conference on Data Engineering
992,The effect of Vaccinium uliginosum extract on tablet computer-induced asthenopia: randomized placebo-controlled study,,2016-08-18,https://www.semanticscholar.org/paper/7f3eb8acc1828c7104577971c14106f2234bdef1,BMC Complementary and Alternative Medicine
1167,Search for the lightest scalar top quark in events with two leptons in pp̄ collisions at =1.96\mbox TeV,"V.M. Abazov aj, B. Abbott bw, M. Abolins bm, B.S. Acharya ac, M. Adams ay, T. Adams aw, E. Aguilo f, M. Ahsan bg, G.D. Alexeev aj, G. Alkhazov an, A. Alton bl,1, G. Alverson bk, G.A. Alves b, M. Anastasoaie ai, L.S. Ancu ai, T. Andeen ba, B. Andrieu q, M.S. Anzelc ba, M. Aoki ax, Y. Arnoud n, M. Arov bh, M. Arthaud r, A. Askew aw,2, B. Asman ao, A.C.S. Assis Jesus c, O. Atramentov aw, C. Avila h, F. Badaudm, L. Bagby ax, B. Baldin ax, D.V. Bandurin bg, P. Banerjee ac, S. Banerjee ac, E. Barberis bk, A.-F. Barfuss o, P. Bargassa cb, P. Baringer bf, J. Barreto b, J.F. Bartlett ax, U. Bassler r, D. Bauer aq, S. Beale f, A. Bean bf, M. Begalli c, M. Begel bu, C. Belanger-Champagne ao, L. Bellantoni ax, A. Bellavance ax, J.A. Benitez bm, S.B. Beri aa, G. Bernardi q, R. Bernhardw, I. Bertram ap, M. Besancon r, R. Beuselinck aq, V.A. Bezzubov am, P.C. Bhat ax, V. Bhatnagar aa, G. Blazey az, F. Blekman aq, S. Blessing aw, K. Bloombo, A. Boehnlein ax, D. Boline bj, T.A. Bolton bg, E.E. Boos al, G. Borissov ap, T. Bose by, A. Brandt bz, R. Brock bm, G. Brooijmans br, A. Bross ax, D. Brown cc, X.B. Bu g, N.J. Buchanan aw, D. Buchholz ba, M. Buehler cc, V. Buescher v, V. Bunichev al, S. Burdin ap,3, T.H. Burnett cd, C.P. Buszello aq, P. Calfayan y, S. Calvet p, J. Cammin bs, M.A. Carrasco-Lizarraga ag, E. Carrera aw, W. Carvalho c, B.C.K. Casey ax, H. Castilla-Valdez ag, S. Chakrabarti bt, D. Chakraborty az, K.M. Chan bc, A. Chandra av, E. Cheu as, D.K. Cho bj, S. Choi af, B. Choudhary ab, L. Christofek by, T. Christoudias aq, S. Cihangir ax, D. Claes bo, J. Clutter bf, M. Cooke ax, W.E. Cooper ax, M. Corcoran cb, F. Couderc r, M.-C. Cousinou o, S. Crepe-Renaudin n, V. Cuplov bg, D. Cutts by, M. Cwiok ad, H. da Motta b, A. Das as, G. Davies aq, K. De bz, S.J. de Jong ai, E. De La Cruz-Burelo ag, C. De Oliveira Martins c, K. DeVaughan bo, F. Deliot r, M. Demarteau ax, R. Demina bs, D. Denisov ax, S.P. Denisov am, S. Desai ax, H.T. Diehl ax, M. Diesburg ax, A. Dominguez bo, T. Dorland cd, A. Dubey ab, L.V. Dudko al, L. Duflot p, S.R. Dugad ac, D. Duggan aw, A. Duperrin o, S. Dutt aa, J. Dyer bm, A. Dyshkant az, M. Eads bo, D. Edmunds bm, J. Ellison av, V.D. Elvira ax, Y. Enari by, S. Eno bi, P. Ermolov al,4, H. Evans bb, A. Evdokimov bu, V.N. Evdokimov am, A.V. Ferapontov bg, T. Ferbel bi,bs, F. Fiedler x, F. Filthaut ai, W. Fisher ax, H.E. Fisk ax, M. Fortner az, H. Fox ap, S. Fu ax, S. Fuess ax, T. Gadfort br, C.F. Galea ai, C. Garcia bs, A. Garcia-Bellido bs, V. Gavrilov ak, P. Gaym, W. Geist s, W. Geng o,bm, C.E. Gerber ay, Y. Gershtein aw,2, D. Gillberg f, G. Ginther bs, B. Gomez h, A. Goussiou cd, P.D. Grannis bt, H. Greenlee ax, Z.D. Greenwood bh, E.M. Gregores d, G. Grenier t, Ph. Grism,∗, J.-F. Grivaz p, A. Grohsjean y, S. Grunendahl ax, M.W. Grunewald ad, F. Guo bt, J. Guo bt, G. Gutierrez ax, P. Gutierrez bw, A. Haas br, N.J. Hadley bi, P. Haefner y, S. Hagopian aw, J. Haley bp, I. Hall bm, R.E. Hall au, L. Han g, K. Harder ar, A. Harel bs, J.M. Hauptman be, J. Hays aq, T. Hebbeker u, D. Hedin az, J.G. Hegeman ah, A.P. Heinson av, U. Heintz bj, C. Hensel v,5, K. Herner bt, G. Hesketh bk, M.D. Hildreth bc, R. Hirosky cc, T. Hoang aw, J.D. Hobbs bt, B. Hoeneisen l, M. Hohlfeld v, S. Hossain bw, P. Houben ah, Y. Hu bt, Z. Hubacek j, V. Hynek i, I. Iashvili bq, R. Illingworth ax, A.S. Ito ax, S. Jabeen bj, M. Jaffre p, S. Jain bw, K. Jakobsw, C. Jarvis bi, R. Jesik aq, K. Johns as, C. Johnson br, M. Johnson ax, D. Johnston bo, A. Jonckheere ax, P. Jonsson aq, A. Juste ax, E. Kajfasz o, D. Karmanov al, P.A. Kasper ax, I. Katsanos br, V. Kaushik bz, R. Kehoe ca, S. Kermiche o, N. Khalatyan ax, A. Khanov bx, A. Kharchilava bq, Y.N. Kharzheev aj, D. Khatidze br, T.J. Kim ae, M.H. Kirby ba, M. Kirsch u, B. Klima ax, J.M. Kohli aa, J.-P. Konrathw, A.V. Kozelov am, J. Kraus bm, T. Kuhl x, A. Kumar bq, A. Kupco k, T. Kurca t, V.A. Kuzmin al, J. Kvita i, F. Lacroixm, D. Lambc, S. Lammers br, G. Landsberg by, P. Lebrun t, W.M. Lee ax, A. Leflat al, J. Lellouch q, J. Li bz,4, L. Li av, Q.Z. Li ax, S.M. Lietti e, J.K. Lim ae, J.G.R. Lima az, D. Lincoln ax, J. Linnemann bm, V.V. Lipaev am, R. Lipton ax, Y. Liu g, Z. Liu f, A. Lobodenko an, M. Lokajicek k, P. Love ap, H.J. Lubatti cd, R. Luna-Garcia ag,6, A.L. Lyon ax, A.K.A. Maciel b, D. Mackin cb, R.J. Madaras at, P. Mattig z, A. Magerkurth bl, P.K. Mal cd, H.B. Malbouisson c, S. Malik bo, V.L. Malyshev aj, Y. Maravin bg, B. Martin n, R. McCarthy bt, M.M. Meijer ai, A. Melnitchouk bn, L. Mendoza h, P.G. Mercadante e, M. Merkin al, K.W. Merritt ax, A. Meyer u, J. Meyer v,5, J. Mitrevski br, R.K. Mommsen ar, N.K. Mondal ac, R.W. Moore f, T. Moulik bf, G.S. Muanza o,",,https://www.semanticscholar.org/paper/84c1c320de4953745fc7c0362a701746706e8c99,
3685,ViperGPT: Visual Inference via Python Execution for Reasoning,"Answering visual queries is a complex task that requires both visual processing and reasoning. End-to-end models, the dominant approach for this task, do not explicitly differentiate between the two, limiting interpretability and generalization. Learning modular programs presents a promising alternative, but has proven challenging due to the difficulty of learning both the programs and modules simultaneously. We introduce ViperGPT, a framework that leverages code-generation models to compose vision-and-language models into subroutines to produce a result for any query. ViperGPT utilizes a provided API to access the available modules, and composes them by generating Python code that is later executed. This simple approach requires no further training, and achieves state-of-the-art results across various complex visual tasks.",2023-03-14,https://www.semanticscholar.org/paper/6e754273d54a91371efbc928cd6b156364d517da,arXiv.org
2544,Proceedings of the 2nd international conference on INtelligent TEchnologies for interactive enterTAINment,"The conference intends to stimulate interaction among academic researchers and commercial developers of interactive entertainment systems. In addition to paper presentations, posters and demos, the conference will foster discussions in topic centered workshops and special events such as the design garage. Underlying Interactive Device Technologies (mobile devices, home entertainment centers, haptic devices, wall screen displays, information kiosks, holographic displays, fog screens, distributed smart sensors, immersive screens and wearable devices), can provide through a variety of Media Delivery Infrastructures (multimedia networks, interactive radio, streaming technologies, DVB-T/M, ITV, P2P, satellite broadcasting, UMTS, Bluetooth, Broadband, VoIP) and a series of user centered Intelligent Computational Technologies and Interactive Applications for Entertainment as described.",2008-01-08,https://www.semanticscholar.org/paper/86abac22c2208d6e2709b306bb4e4064999f5c44,Intelligent Technologies for Interactive Entertainment
3607,Literals for user-defined types,"This note proposes a notion of user-defined literals based on literal constructors without requiring new syntax. If combined with the separate proposal for generalized initializer lists, it becomes a generalization of the C99 notion of compound literals. Basically, a constructor defines a user-defined literal if it is inline and specifies a simple mapping of its arguments to object representation values and is invoked with constant expressions or objects that can be trivially copied (such as pointers). The Problem C++ does not provide a way of defining literals for user-defined types. Instead, constructors are used. For example: 15 // int literal ""15"" // string literal (zero terminated array of characters) complex(15) // “sort of complex literal” When a constructor is simple and inlining is done well, such constructor calls provide a reasonable substitute for literals. However, a constructor is a very general construct and there have been many requests for a way to express literals for user-defined types in such a way that a programmer can be confident that a value will be constructed at compile time and potentially stored in ROM. For example: complex z(1,2); // the variable z can be constructed at compile time const complex cz(1,2); // the const cz can potentially be put in ROM A Solution The most direct and obvious solution would be to introduce syntax to distinguish a literal constructor and to distinguish literals of user-defined types. For example: class X { int x,y,z; public: literal X(int a, int b) :x(a+1),y(0),z(b) {} // literal constructor // ... }; X""1,2"" // a literal of type X This syntax is just for the illustration of the idea; a better syntax is suggested below. This “literal constructor” illustrates the requirements for any specification of a literal for a userdefined type. It specifies a (simple) mapping from a set of arguments to the representation of the type. Often, that will simply specify a value for each member of the type's representation, but slight generalizations are possible and sometimes useful. Here, I have indicated that the member y's value need not be specified by the user and that a slight transformation takes place on the argument used to specify a (x becomes a+1). The body is empty. Since the construction of the representation of a value takes place at compile time, very few constructs could reasonably be allowed in a literal constructor body. The simplest rule would be to require that body to be empty. That is, the mapping of arguments to representation (member values) must be specified as member initializers. In addition, a literal constructor must be inline. What can be accepted as an argument type? An argument must of a type that can be copied without the use of a nontrivial copy constructor (e.g. ints, pointers, and references). What can be accepted as an initializer? An initializer can be another argument, a value of a type that can be copied without the use of a non-trivial copy constructor, or a constant expression. Note that this definition is recursive in that it allows the use of literals of user defined types as arguments to be used. For example: class Y { complex x, y; literal X(complex a, int b) : x(a), y(complex""a,0"") {} // ... }; const int c = 3; Y""complex""1,2"",c""; This simple definition could be elaborated. For example, should we accept floating point expressions, such as d+1.7 where d is an argument of floating point type? I think not. Even if d is a literal so that the expression to be evaluated is something like 2.3+1.7, I suspect that the complication of requiring floating point arithmetic at compile time is not worth the bother – especially for cross compilers. Syntax for user-defined literals The syntax used to illustrate the idea of a “literal constructor” above has some obvious problems. Consider that last use: const int c = 3; Y""complex""1,2"",c""; That use of quotes (chosen to emphasize the literal nature of the construct) would clearly confuse any traditional lexer (and many human readers). Also, it doesn't exactly extend to string literal arguments. Furthermore, it would not be easy to get used to the idea that elements of the string-like part are separate values and that variable can occur there. I think that a much more natural (i.e. familiar) and readable notation would use parentheses: const int c = 3; Y(complex(1,2),c); After all, parentheses are the way we usually express arguments. However, by doing so, we lost the syntactic distinction of the literal. That is,",,https://www.semanticscholar.org/paper/1bac4d3eea176df7074a527a30c8d03a2ca6540f,
2324,Activation of phospholipase D in permeabilised human neutrophils,,1994-01-12,https://www.semanticscholar.org/paper/6d91e9ba972329e879ec13171d7cff27f9609910,
2549,1 activeNotes : Computer-Assisted Creation of Patient Progress Notes in a Hospital Environment,"We present activeNotes, a note creation prototype for use by physicians in a hospital intensive care unit. The application supports the creation of Critical Care Notes, which document the patient’s progress and prognosis. We integrate automated, context-sensitive patient data retrieval, and user control of automated data updates and alerts through the use of tags, into the note creation process, without significantly altering the interface to which physicians are accustomed. We performed a qualitative study of the prototype with 15 physicians at New York Presbyterian Hospital. Physicians found activeNotes to be valuable and said they would use it to create both formal notes for medical records and informal notes. We were surprised to find that while physicians have rejected template-based systems in the past, they expressed a desire to use activeNotes to create personalized, doctor-specific note templates to be reused with a given patient, or for a",,https://www.semanticscholar.org/paper/c6a0e689d320b7b916d48e671db49ff4f4ef160c,
210,"Evolution and Learning: Used Together, Fused Together. A Response to Watson and Szathmáry.",,2016-12-01,https://www.semanticscholar.org/paper/d7be5f1fef6090298eb9b04d579d852cd744e3f7,Trends in Ecology & Evolution
2556,Representing and Processing Screen Space in Augmented Reality,,,https://www.semanticscholar.org/paper/5a59f74d88d8f412a256f537319eba9065954a44,
3610,Speaking C++ as a native,"C++ supports several styles (“multiple paradigms”) of programming. This allows great flexibility, notational convenience, maintainability, and close-to-optimal performance. Programmers who don’t know the basic native C++ styles and techniques “speak” C++ with a thick accent, limiting themselves to relatively restrictive pidgin dialects. Here, I present language features such as classes, class hierarchies, abstract classes, and templates, together with the fundamental programming styles they support. In particular, I show how to provide generic algorithms, function objects, access objects, and delayed evaluation as needed to build and use flexible and efficient libraries. The aim is to give an idea of what’s possible to provide, and some understanding of the fundamental techniques of modern C++ libraries.",2002-01-29,https://www.semanticscholar.org/paper/02281528c22ad58d8987a6e4d74569def7898c5e,
1115,Search for CP violation in B 0 s ! þ D s X decays in p p collisions at ffiffi s p 1⁄4 1 : 96 TeV,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, M. Ahsan, G.D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G. A. Alves, L. S. Ancu, T. Andeen, M. S. Anzelc, M. Aoki, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, O. Atramentov, C. Avila, J. BackusMayes, F. Badaud, L. Bagby, B. Baldin, D.V. Bandurin, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V.A. Bezzubov, P. C. Bhat, V. Bhatnagar, G. Blazey, S. Blessing, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, E. E. Boos, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, X. B. Bu, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, T. H. Burnett, C. P. Buszello, P. Calfayan, B. Calpas, S. Calvet, J. Cammin, M.A. Carrasco-Lizarraga, E. Carrera, W. Carvalho, B. C. K. Casey, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K.M. Chan, A. Chandra, E. Cheu, D. K. Cho, S. Choi, B. Choudhary, T. Christoudias, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, V. Cuplov, D. Cutts, M. Ćwiok, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, K. DeVaughan, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, T. Dorland, A. Dubey, L. V. Dudko, L. Duflot, D. Duggan, A. Duperrin, S. Dutt, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V. D. Elvira, Y. Enari, S. Eno, P. Ermolov, M. Escalier, H. Evans, A. Evdokimov, V.N. Evdokimov, G. Facini, A. V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, W. Geng, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, B. Gómez, A. Goussiou, P. D. Grannis, S. Greder, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Harder, A. Harel, J.M. Hauptman, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, A. P. Heinson, U. Heintz, C. Hensel, I. Heredia-De La Cruz, K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, T. Hoang, J. D. Hobbs, B. Hoeneisen, M. Hohlfeld, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, N. Huske, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, D. Jamin, C. Jarvis, R. Jesik, K. Johns, C. Johnson, M. Johnson, D. Johnston, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, D. Karmanov, P. A. Kasper, I. Katsanos, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y. N. Kharzheev, D. Khatidze, T. J. Kim, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, J.-P. Konrath, A.V. Kozelov, J. Kraus, T. Kuhl, A. Kumar, A. Kupco, T. Kurča, V. A. Kuzmin, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, W.M. Lee, A. Leflat, J. Lellouch, J. Li, L. Li, Q. Z. Li, S.M. Lietti, J. K. Lim, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna-Garcia,34,xA.L. Lyon, A.K.A. Maciel, D. Mackin, P. Mättig, A. Magerkurth, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, Y. Maravin, B. Martin, R. McCarthy, C. L. McGivern, M.M. Meijer, A. Melnitchouk, L. Mendoza, D. Menezes, P. G. Mercadante, M. Merkin, K.W. Merritt, A. Meyer, J. Meyer, J. Mitrevski, R.K. Mommsen, N.K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, H. A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, G. Obrant, C. Ochando, D. Onoprienko, J. Orduna, N. Oshima, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, M. Padilla, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park, S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma,34,k V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, A.V. Popov, C. Potter, W. L. Prado da Silva, S. Protopopescu, J. Qian, A. Quadt, B. Quinn, A. Rakitine, M. S. Rangel, K. Ranjan, P. N. Ratoff, P. Renkel, P. Rich, M. Rijssenbeek, I. Ripp-Baudot, F. Rizatdinova, S. Robinson, R. F. Rodrigues, M. Rominsky, C. Royon, P. Rubinov, R. Ruchti, G. Safronov, G. Sajot, A. Sánchez-Hernández, M. P. Sanders, B. Sanghi, G. Savage, L. Sawyer, T. Scanlon, D. Schaile, R.D. Schamberger, Y. Scheglov, H. Schellman, T. Schliephake, S. Schlobohm, C. Schwanenberger, R. Schwienhorst, J. Sekaric, H. Severini, PHYSICAL REVIEW D 82, 012003 (2010)",,https://www.semanticscholar.org/paper/26141a41465a4583431511a7ea3863a35c408e14,
1598,The Blessings of Multiple Causes,"Abstract Causal inference from observational data is a vital problem, but it comes with strong assumptions. Most methods assume that we observe all confounders, variables that affect both the causal variables and the outcome variables. This assumption is standard but it is also untestable. In this article, we develop the deconfounder, a way to do causal inference with weaker assumptions than the traditional methods require. The deconfounder is designed for problems of multiple causal inference: scientific studies that involve multiple causes whose effects are simultaneously of interest. Specifically, the deconfounder combines unsupervised machine learning and predictive model checking to use the dependencies among multiple causes as indirect evidence for some of the unobserved confounders. We develop the deconfounder algorithm, prove that it is unbiased, and show that it requires weaker assumptions than traditional causal inference. We analyze its performance in three types of studies: semi-simulated data around smoking and lung cancer, semi-simulated data around genome-wide association studies, and a real dataset about actors and movie revenue. The deconfounder is an effective approach to estimating causal effects in problems of multiple causal inference. Supplementary materials for this article are available online.",2018-05-17,https://www.semanticscholar.org/paper/4e6b198578895bbfe968c92d64dd1e3ef2e977be,Journal of the American Statistical Association
3485,Scheduling in Finite Capacity Networks,"In this paper, we show that a simple distributed algorithm for network scheduling in arbitrary m processor networks with unit capacity links is an O(logm)-approximation algorithm if the optimal schedule length is su ciently large. We will assume that there are m machines or processors labeled p1; p2; : : : ; pm, such that processor pi has ji jobs and P i ji = n. Let d be the maximum degree in the network and let L be the length of the optimal schedule. We also assume that each processor knows the current number of jobs on its neighboring processors. In one step of the algorithm, which we will refer to as Eager-scheduler, a processor with ji jobs will pass one job to each of its neighbors with less than ji 2d jobs. A precise statement of Eager-scheduler appears in Figure 1. This algorithm was analyzed for the load balancing problem by Aiello et al. [1] and Ghosh and Muthukrishnan [2]. The di erence between the load balancing problem and network scheduling is that in the load balancing problem there is no overlap of communication and computation. The objective is to balance (either perfectly or approximately, depending on the variation of the problem) the number of jobs on each machine. The bounds of [1, 2] are not in terms of an actual lower bound but instead an existential lower bound. They can prove that their algorithm balances the number of jobs on each processor so that no two neighbors are more than d apart. Let be the average number of jobs in a network with edge expansion . Their algorithm will perform this approximate balancing in O( = ) steps where = maxi(ji ) and is referred to as the imbalance in the network. Further, they show that there exists a network with imbalance and edge expansion that requires O( = ) steps to balance. Thus, their algorithm is not an approximation algorithm by the usual de nition since the lower bound is not necessarily for the instance at hand but instead an existential lower bound. While their algorithms may produce a short schedule by load balancing, our algorithm gives a guarantee that the schedule produced is no more than an O(logm) factor longer than the shortest possible schedule for the instance given.",,https://www.semanticscholar.org/paper/7e9132232d644261158bf6ec8aba7fb4fc0cc75d,
598,On the Complexity of Designing Distributed Protocols,,1982-06-01,https://www.semanticscholar.org/paper/f3d16c209190ff23ed79dd763c761b6f4094074a,Information and Control
3556,"A Principled, Complete, and Efficient Representation of C++",,2011-12-07,https://www.semanticscholar.org/paper/5b4802e07945dd6b370a8408f4f607b8168038f5,Mathematics and Computer Science
1343,First measurement of $\sigma$ ($p \bar p \to Z^ ) $ . Br ($Z \to \tau \tau^ ) $ at $\sqrt s $ 1.96- TeV,,,https://www.semanticscholar.org/paper/60cf669d600c43f46ef4f2ba16b7eabce02dd148,
47,Towards a query optimizer for text-centric tasks,"Text is ubiquitous and, not surprisingly, many important applications rely on textual data for a variety of tasks. As a notable example, information extraction applications derive structured relations from unstructured text; as another example, focused crawlers explore the Web to locate pages about specific topics. Execution plans for text-centric tasks follow two general paradigms for processing a text database: either we can scan, or “crawl,” the text database or, alternatively, we can exploit search engine indexes and retrieve the documents of interest via carefully crafted queries constructed in task-specific ways. The choice between crawl- and query-based execution plans can have a substantial impact on both execution time and output “completeness” (e.g., in terms of recall). Nevertheless, this choice is typically ad hoc and based on heuristics or plain intuition. In this article, we present fundamental building blocks to make the choice of execution plans for text-centric tasks in an informed, cost-based way. Towards this goal, we show how to analyze query- and crawl-based plans in terms of both execution time and output completeness. We adapt results from random-graph theory and statistics to develop a rigorous cost model for the execution plans. Our cost model reflects the fact that the performance of the plans depends on fundamental task-specific properties of the underlying text databases. We identify these properties and present efficient techniques for estimating the associated parameters of the cost model. We also present two optimization approaches for text-centric tasks that rely on the cost-model parameters and select efficient execution plans. Overall, our optimization approaches help build efficient execution plans for a task, resulting in significant efficiency and output completeness benefits. We complement our results with a large-scale experimental evaluation for three important text-centric tasks and over multiple real-life data sets.",2007-11-01,https://www.semanticscholar.org/paper/a968bb1dea8969d062e4f68059ce94ad7ce734f9,TODS
1276,Measurement of the ratios of the Z / γ ∗ + n jet production cross sections to the total inclusive Z / γ ∗ cross section in pp collisions at √ s = 1 . 96 TeV,"We present a study of events with Z bosons and associated jets produced at the Fermilab Tevatron collider in pp̄ collisions at a center of mass energy of 1.96 TeV. The data sample consists of nearly 14 000 Z/γ ∗ → e+e− candidates corresponding to an integrated luminosity of 0.4 fb−1 collected with the DØ detector. Ratios of the Z/γ ∗+ n jet cross sections to the total inclusive Z/γ ∗ cross section have been measured for n = 1–4 jets, and found to be in good agreement with a next-to-leading order QCD calculation and with a tree-level QCD prediction with parton shower simulation and hadronization. Published by Elsevier B.V. PACS: 13.38.Dg; 14.70.Hp; 13.87.-a; 12.38.Aw; 12.38.Qk; 13.85.-t Open access under CC BY license. Leptonic decays of electroweak gauge bosons, W± and Z, produced in association with jets are prominent signatures at present and future hadron colliders. Measurements of W (or Z) + n jet cross sections are important for understanding perturbative quantum chromodynamics (QCD) calculations and for developing Monte Carlo (MC) simulation programs capable of handling partons in the final state at leading order (LO), or, in some cases, next-to-leading order (NLO). Furthermore, the production of W or Z bosons with associated jets represents a * Corresponding author. E-mail address: buehler@fnal.gov (M. Buehler). 1 Visitor from Lewis University, Romeoville, IL, USA. 2 On leave from IEP SAS Kosice, Slovakia. 3 Visitor from Helsinki Institute of Physics, Helsinki, Finland. significant background to Higgs boson searches, as well as to other Standard Model processes of interest, such as top quark production, and many searches for new phenomena at the Fermilab Tevatron collider and at the CERN large hadron collider. Measurements of Z+ n jet cross sections with lower integrated luminosity and at lower center of mass energy were performed previously by the CDF Collaboration [1]. In this Letter, we present the first measurement of the ratios of the Z/γ ∗+ n jet production cross sections to the total inclusive Z/γ ∗ cross section for jet multiplicities n = 1–4 in pp̄ collisions at √ s = 1.96 TeV. Cross section measurements based on inclusive jet multiplicities provide theoretically sound observables, and can be compared to a variety of predictions. Our results are based on a data sample corresponding to an integrated luminosity of 0.4 fb−1 accumulated with the DØ detector. 116 DØ Collaboration / Physics Letters B 658 (2008) 112–119 The elements of the DØ detector [2] of primary importance to this analysis are the uranium/liquid-argon sampling calorimeter and the tracking system. The DØ calorimeter has a granularity of η × φ = 0.1 × 0.1, forming projective towers, where η is the pseudorapidity (η = − ln[tan(θ/2)], θ is the polar angle relative to the proton beam), and φ is the azimuthal angle. The calorimeter has a central section covering pseudorapidities up to ≈ 1.1, and two end calorimeters that extend the coverage to |η| ≈ 4.2. The tracking system consists of a silicon micro-strip tracker and a central fiber tracker, both located within a 2 T superconducting solenoidal magnet, with designs optimized for tracking and vertexing at pseudorapidities of |η| < 3 and |η| < 2.5, respectively. The data sample for this analysis [3] was collected between April 2002 and June 2004. Events from Z/γ ∗ → e+e− decays were selected with a combination of single-electron triggers, based on energy deposited in calorimeter towers ( η × φ = 0.2 × 0.2). Final event selection was based on detector performance, event properties, and electron and jet identification criteria. Events were required to have a reconstructed primary vertex with a position along the beam direction within 60 cm of the detector center. Electrons were reconstructed from electromagnetic (EM) clusters in the calorimeter using a simple cone algorithm. The two electron candidates in the event with the highest transverse momentum components relative to the beam direction (pT ), and both with pT > 25 GeV, were used to reconstruct the Z boson candidate. The two electrons were required to be in the central region of the calorimeter |ηdet| < 1.1 (pseudorapidity ηdet is calculated relative to the center of the detector), and at least one required to fire the trigger(s) for the event. The electron pair also had to have an invariant mass consistent with the Z boson mass of 75 GeV < Mee < 105 GeV. To reduce background (mainly from jets misidentified as electrons), the EM clusters were required to pass three quality criteria based on the shower profile: (i) the electron had to deposit at least 90% of its energy in the 21-radiation-length EM calorimeter, (ii) the lateral and longitudinal shape of the energy cluster had to be consistent with those of an electron, and (iii) the electron had to be isolated from other energy deposits in the calorimeter, with an isolation fraction fiso < 0.15. (The isolation fraction is defined as fiso = [E(0.4) − EEM(0.2)]/EEM(0.2), where E(Rcone) and EEM(Rcone) are respectively the total and EM energies within a cone of radius Rcone = √ ( η)2 + ( φ)2 centered around the direction of the electron.) Additionally, at least one of the electrons was required to have a spatially matched track associated with the reconstructed calorimeter cluster, and the track momentum had to be consistent with the energy of the EM cluster. A total of 13 893 events passed the selection criteria. Jets were reconstructed using the “Run II cone algorithm” [4] that combines particles within a cone of radius Rcone = 0.5. Spurious jets from isolated noisy calorimeter cells were eliminated through selections on patterns of jet energy deposition. Jets were required to be consistent with energy depositions measured at the trigger stage. This requirement was introduced to address precision readout noise problems: the jet energy at the level 1 trigger tower level was compared to the jet energy derived from the jet cone algorithm, which was based on calorimeter cell precision readout. The transverse momentum of each jet was corrected for multiple pp̄ interactions, calorimeter noise, out-of-cone showering effects, and energy response of the calorimeter as determined from the missing transverse energy balance of photon-jet events [5]. Jets were required to have pT > 20 GeV and |η| < 2.5, and were eliminated if they overlapped with electrons from Z boson decay within R = ( η)2 + ( φ)2 = 0.4. Small losses of jets resulting from this separation criterion for electrons from Z boson decays were estimated as a function of the number of associated jets using a PYTHIA [6] MC sample. The jet energy resolutions were derived from a measurement in photon + jet data for low jet energies and dijet data for higher jet energy values. Fits to the transverse energy asymmetry [pT (1) − pT (2)]/[pT (1) + pT (2)] between the transverse momenta of the back-to-back jets and/or photon (pT (1) and pT (2)) were then used to obtain the jet energy resolution as a function of jet rapidity and transverse energy. The largest contribution to the jet energy resolution uncertainty was due to limited statistics in the samples used. The electron efficiencies for trigger, track matching, reconstruction, and identification were determined from data, based on a “tag-and-probe” method. Z candidates were selected with one electron (the tag) satisfying a tighter track-matching requirement to further reduce background contamination, and another electron (the probe) with all other criteria applied, except the one under study. The fraction of events with probe electrons passing the requirement under study determined the efficiency of a given criterion. The overall trigger efficiency for Z candidates that survived the analysis selections was found to be greater than 99%. The electron reconstruction and identification efficiencies were measured as a function of azimuthal angle and pT , and the average efficiency was found to be about 89%. The combined spatial and energy track-matching efficiency was measured to be about 77%. The electron reconstruction, selection, trigger, and track-matching efficiencies were examined as a function of jet multiplicity. No significant variations of the efficiencies were observed, except for the track-matching efficiency, for which the multiplicity dependence was taken into account in correcting the data. The kinematic and geometric acceptance for electrons from Z/γ ∗ decays in the mass region of 75 GeV < Mee < 105 GeV, for a primary vertex within 60 cm of the detector center, was determined as a function of jet multiplicity. An inclusive PYTHIA sample was used to calculate the acceptance for the inclusive Z/γ ∗ sample. The PYTHIA events were weighted so that the pT distribution of the Z boson in the MC agreed with data. The jet multiplicity dependence of the acceptance was calculated using a Z/γ ∗ +n parton leading-order generator [7], with the evolution of partons into hadrons carried out in PYTHIA. All the samples were processed through full DØ detector simulation using GEANT [8] and the DØ reconstruction software. The overall dielectron acceptance for the Z/γ ∗+ 4 jet sample was found to be about 30% higher than the acceptance for the Z/γ ∗ inclusive sample, because events with jets tend to reDØ Collaboration / Physics Letters B 658 (2008) 112–119 117 Table 1 Cross-section ratios (Rn) with statistical and systematic uncertainties (all ×10−3) for different inclusive jet multiplicities Multiplicity (Z/γ ∗+ n jets) n 1 n 2 n 3 n 4 Rn 120.1 18.6 2.8 0.90 Total statistical uncertainty ±3.3 ±1.4 ±0.56 ±0.44 Total systematic uncertainty −17.1,+15.6 −5.0,+6.2 −1.06,+1.43 −0.40,+0.48 Jet energy calibration ±11.7 ±3.3 ±0.74 ±0.23 Jet reconstruction/identification −7.0,+2.2 −2.9,+4.3 −0.64,+0.82 −0.30,+0.40 Unsmearing procedure −3.6,+2.2 −1.6,+2.4 −0.24,+0.85 −0.08,+0.09 Jet energy resolution −2.7,+3.4 −0.04,+0.13 −0.17,+0.15 −0.03,+0.04 Acceptance ±1.8 ±0.7 ±0.10 ±0.003 Efficiencies (trigger, EM, track)",,https://www.semanticscholar.org/paper/4d9ab8296d404dc1cb0796ef17c45e42665821f5,
2429,Designing AR Visualizations to Facilitate Stair Navigation for People with Low Vision,"Navigating stairs is a dangerous mobility challenge for people with low vision, who have a visual impairment that falls short of blindness. Prior research contributed systems for stair navigation that provide audio or tactile feedback, but people with low vision have usable vision and don't typically use nonvisual aids. We conducted the first exploration of augmented reality (AR) visualizations to facilitate stair navigation for people with low vision. We designed visualizations for a projection-based AR platform and smartglasses, considering the different characteristics of these platforms. For projection-based AR, we designed visual highlights that are projected directly on the stairs. In contrast, for smartglasses that have a limited vertical field of view, we designed visualizations that indicate the user's position on the stairs, without directly augmenting the stairs themselves. We evaluated our visualizations on each platform with 12 people with low vision, finding that the visualizations for projection-based AR increased participants' walking speed. Our designs on both platforms largely increased participants' self-reported psychological security.",2019-10-17,https://www.semanticscholar.org/paper/c5e254fe8571ae1cc251ac30db8fcad7eab1c753,ACM Symposium on User Interface Software and Technology
2410,Exploring the Educational Value and Impact of Vision-Impairment Simulations on Sympathy and Empathy with XREye,"To create a truly accessible and inclusive society, we need to take the more than 2.2 billion people with vision impairments worldwide into account when we design our cities, buildings, and everyday objects. This requires sympathy and empathy, as well as a certain level of understanding of the impact of vision impairments on perception. In this study, we explore the potential of an extended version of our vision-impairment simulation system XREye to increase sympathy and empathy and evaluate its educational value in an expert study with 56 educators and education students. We include data from a previous study in related work on sympathy and empathy as a baseline for comparison with our data. Our results show increased sympathy and empathy after experiencing XREye and positive feedback regarding its educational value. Hence, we believe that vision-impairment simulations, such as XREye, have merit to be used for educational purposes in order to increase awareness for the challenges people with vision impairments face in their everyday lives.",2023-07-06,https://www.semanticscholar.org/paper/a52407068e37bbac2703f8ceb1eb70ea84141505,Multimodal Technologies and Interaction
300,Internet and Network Economics,,,https://www.semanticscholar.org/paper/f61d66e52c4b9ed705110127e36aee6c735005bf,Lecture Notes in Computer Science
1529,Heterogeneous Supervised Topic Models,"Abstract Researchers in the social sciences are often interested in the relationship between text and an outcome of interest, where the goal is to both uncover latent patterns in the text and predict outcomes for unseen texts. To this end, this paper develops the heterogeneous supervised topic model (HSTM), a probabilistic approach to text analysis and prediction. HSTMs posit a joint model of text and outcomes to find heterogeneous patterns that help with both text analysis and prediction. The main benefit of HSTMs is that they capture heterogeneity in the relationship between text and the outcome across latent topics. To fit HSTMs, we develop a variational inference algorithm based on the auto-encoding variational Bayes framework. We study the performance of HSTMs on eight datasets and find that they consistently outperform related methods, including fine-tuned black-box models. Finally, we apply HSTMs to analyze news articles labeled with pro- or anti-tone. We find evidence of differing language used to signal a pro- and anti-tone.",2022-06-01,https://www.semanticscholar.org/paper/bfbd8f1cec08f842e65354c0d6598d42b906f74d,Transactions of the Association for Computational Linguistics
1029,Experimental Gait Analysis of Waveboard Locomotion,"Through modeling and experimentation, we analyze common gaits on a waveboard, an underactuated mechanical system whose motion is governed by both nonholonomic constraints and momentum conservation. We take advantage of the system's symmetries to derive a reduced system model that differentiates between kinematic and dynamic components of motion. We evaluate this model using marker trajectory data gathered through an optical tracking system for various types of gaits. By extracting relevant trajectory parameters via state reconstruction and fitting our joint variables to an ellipse, we determine the kinematic components of gaits commonly used by human riders. In particular, we demonstrate that traditional forward motion is purely dynamic, while sustained turning motion contains kinematic components. In order to validate our model, we compare experimentally obtained trajectories with reconstructed displacements based on the model. Finally, we suggest an approach for further analysis of the dynamic components of these gaits. INTRODUCTION The waveboard, also known as the essboard, caster board, vigor board, and ripstik, is a skateboard variant in which two platforms, each resting upon a caster wheel, are constrained to rotate about the same axis and coupled with a torsional spring. It is a mixed mechanical system whose motion is governed by both nonholonomic velocity constraints and momentum conservation. It is modeled similarly to the variable inertia snakeboard examined by Shammas et al. [1], who used geometric mechanics to differentiate between kinematic and dynamic components of motion. Relative to traditional two-wheel drive systems, the waveboard possesses greater maneuverability and potentially higher efficiency at the expense of stability. Modeling insight could be used by designers to optimize kinematic parameters of waveboards in light of ergonomic considerations. More generally, analysis of the locomotive capabilities of this system informs control and planning of highly dynamic mobile robots. Although the waveboard itself has not appeared often in geometric mechanics literature, the snakeboard is a similar system that has received considerable attention in the context of underactuated systems and controllability of nonholonomic mechanical systems. The snakeboard was first analyzed as a nonholonomic mechanical system by Ostrowski et al. [2]. Shammas et al. [1] analyzed and generated gaits for mixed mechanical systems using height functions to analyze geometric phase shift, as well as a novel scaled momentum and gamma functions to evaluate dynamic phase shift. In [1, 3], Shammas et al. classified gaits into three different categories: purely kinematic, purely dynamic, and kino-dynamic. More recently, Shammas and de Oliveira provided an analytical solution to snakeboard motion planning [4]. Dear et al. [5] built upon their work using body coordinates and local trajectory information to address trajectory generation. Dear et al. [6] also incorporated dissipative friction in the traveling direction and skidding in the snakeboard model, investigating these effects on trajectory planning. Asnafi and Mahzoon [7] generated some flower-like gaits for the snakeboard. Similar geometric approaches can be applied to the waveboard in order to analyze its locomotive capabilities. This paper addresses the challenge of modeling and characterizing motions of the waveboard. In the next section, we present a model for the waveboard and derive its reconstruction equation. Subsequent sections describe experimental methodology and analysis of common types of gaits in the framework of geometric mechanics. Correlations between configurational variations and trajectory parameters are investigated, and numerically reconstructed forward motion displacements are compared with experimental data.",2016-10-12,https://www.semanticscholar.org/paper/391e4c3fd6911f7e7a76c08f9e8f2e78e36a0475,
3606,Abstraction and the C++ Machine Model,,2004-12-09,https://www.semanticscholar.org/paper/dcb38a10f1a634dc82b535527c58791dbae94429,International Conference on Embedded Software and Systems
2080,組合決策於顧客關係管理之應用－歌手發行精選專輯之歌曲組合為實證; A Portfolio Decision Study for Customer Relationship Management: An Empirical Study on the Selection of Songs for Selected Album,,,https://www.semanticscholar.org/paper/936806c988ab639bc2fa66e0e1c0ca7cb0b639aa,
3087,Multimedia on Multiprocessors: Where’s the OS When You Really Need It?,"Due to the limitations of current operating systems in supporting multimedia applications, much work has been done to provide resource management mechanisms to address this problem. As processor cycles are often the most oversubscribed and critical resource, most of this work has focused on uniprocessor scheduling. However, hardware platforms are moving to multiprocessor systems, and little work has been done to address the problem of supporting multimedia applications in a multiprocessor context. This paper proposes a new multiprocessor scheduler designed to meet the requirements of multimedia applications. We present an overview of the scheduling algorithm, describe its implementation in a commercial operating system, and discuss directions for future work.",,https://www.semanticscholar.org/paper/49262e1e7c0b40d588505a6a6ceb87ace81d0772,
126,"Storage-Efficient, Deadlock-Free Packet Routing Algorithms for Torus Networks","We present two new packet routing algorithms for parallel computers with torus interconnection networks of arbitrary size and dimension. Both algorithms use only minimal length paths, are fully adaptive in the sense that all minimal length paths may be used to avoid congestion, and are free of deadlock, livelock and starvation. Algorithm 1 requires only three central queues per routing node. It is the first known minimal length packet routing algorithm for torus networks which requires a constant number of queues per node, regardless of the size and dimension of the torus. In fact, the requirement of three queues per node is optimal, as no such algorithm is possible when all nodes have two or fewer queues. Algorithm 2 requires only that each node have two input buffers per edge. It is the first known minimal-fully-adaptive packet routing algorithm for torus networks which does not require central queues and which does not require any node to have more than two input or two output buffers per edge. Both algorithms are simple and appear to be well-suited to VLSI implementation. They can be used with either store-and-forward or virtual cut-through routing. >",1994-12-01,https://www.semanticscholar.org/paper/8beea0917ac99f0dcd98f9d5cc56a76c1809df22,IEEE Trans. Computers
2706,Introduction to Computer Graphics Macintosh Version Software of SRGP and SPHIGS Software,,1994-06-01,https://www.semanticscholar.org/paper/3bc3e7c17355e7bb5a40cb070ba34568d0a3621d,
2794,Galectin-3 Plays an Important Role in Innate Immunity to Gastric Infection by Helicobacter pylori,"ABSTRACT We studied the role of galectin-3 (Gal3) in gastric infection by Helicobacter pylori. We first demonstrated that Gal3 was selectively expressed by gastric surface epithelial cells and abundantly secreted into the surface mucus layer. We next inoculated H. pylori Sydney strain 1 into wild-type (WT) and Gal3-deficient mice using a stomach tube. At 2 weeks postinoculation, the bacterial cells were mostly trapped within the surface mucus layer in WT mice. In sharp contrast, they infiltrated deep into the gastric glands in Gal3-deficient mice. Bacterial loads in the gastric tissues were also much higher in Gal3-deficient mice than in WT mice. At 6 months postinoculation, H. pylori had successfully colonized within the gastric glands of both WT and Gal3-deficient mice, although the bacterial loads were still higher in the latter. Furthermore, large lymphoid clusters mostly consisting of B cells were frequently observed in the gastric submucosa of Gal3-deficient mice. In vitro, peritoneal macrophages from Gal3-deficient mice were inefficient in killing engulfed H. pylori. Furthermore, recombinant Gal3 not only induced rapid aggregation of H. pylori but also exerted a potent bactericidal effect on H. pylori as revealed by propidium iodide uptake and a morphological shift from spiral to coccoid form. However, a minor fraction of bacterial cells, probably transient phase variants of Gal3-binding sugar moieties, escaped killing by Gal3. Collectively, our data demonstrate that Gal3 plays an important role in innate immunity to infection and colonization of H. pylori.",2016-02-08,https://www.semanticscholar.org/paper/764f8cc3498427c13e94133888ed5bd8a8209e07,Infection and Immunity
268,A New Look at Selfish Routing,"We revisit price of anarchy in network routing, in a new model in which routing decisions are made by self-interested components of the network, as opposed to by the flows as in (12). This significant departure from previous work on the problem seeks to model Internet routing more accurately. We propose two models: the latency model in which the network edges seek to minimize the average latency of the flow through them on the basis of knowledge of latency conditions in the whole network, and the pricing model in which network edges advertise pricing schemes to their neighbors and seek to maximize their profit. We show two rather surprising results: the price of stability in the latency model is unbounded — Ω(n 1 60 ) — even with linear latencies (as compared with 4 in (12) for the case in which routing decisions are made by the flows themselves). However, in the pricing model in which edges advertise pricing schemes — how the price varies as a function of the total amount of flow — we show that, under a condition ruling out monopolistic situations, all Nash equilibria have optimal flows; that is, the price of anarchy in this model is one ,i n the case of linear latencies with no constant term.",,https://www.semanticscholar.org/paper/6a21e10ba5221820c801826f964a5fe0d7234b93,International Conference on Supercomputing
2067,Real option analysis for capacity investment planning for semiconductor manufacturing,"This study aims to propose a real option analysis to evaluate capital investment decisions for capacity expansion under demand uncertainty. Comparing to conventional analysis, this approach can provide a decision framework to incorporate management flexibility and thus provide a better measurement of optional value of capacity investment from potential benefits to avoid capacity shortage and losing growth opportunity. In particular, a binomial model with risk neutral method was employed to illustrate the expansion of the uncertainty event tree and the assessment of option value for supporting top managers' decision flexibility in light of dynamic decision contexts.",2007-10-01,https://www.semanticscholar.org/paper/7b4b8aa6515c87f098a44334cadfe7d9eb2519a9,International Symposium on Semiconductor Manufacturing
3021,HeterogeneousMulti-Mobile Computing,"As smartphones and tablets proliferate, there is a growing demand for multi-mobile computing, the ability to combine multiple mobile systems into more capable ones. We present M2, a system for multimobile computing that enables existing unmodified mobile apps to share and combine multiple devices, including cameras, displays, speakers, microphones, sensors, GPS, and input. M2 introduces a new data-centric approach that leverages higher-level device abstractions and hardware acceleration to efficiently share device data, not API calls. To support heterogeneous devices, M2 introduces device transformation, a new technique to mix and match different types of devices. Example transformations include combining multiple displays into a single larger display for better viewing, or substituting accelerometer for touchscreen input to provide a Nintendo Wii-like experience with existing mobile gaming apps. We have implemented M2 and show that it (1) operates across heterogeneous systems, including multiple versions of Android and iOS, (2) can enable unmodified Android apps to use multiple mobile devices in new and powerful ways, including supporting users with disabilities and better audio conferencing, and (3) can run apps across mobile systems with modest overhead and qualitative performance indistinguishable from using local device hardware.",,https://www.semanticscholar.org/paper/794f11bac9a77b553ed6ed1aac68857bafbcb7d4,
2953,Stochastic gradient variational Bayes for gamma approximating distributions,"While stochastic variational inference is relatively well known for scaling inference in Bayesian probabilistic models, related methods also offer ways to circumnavigate the approximation of analytically intractable expectations. The key challenge in either setting is controlling the variance of gradient estimates: recent work has shown that for continuous latent variables, particularly multivariate Gaussians, this can be achieved by using the gradient of the log posterior. In this paper we apply the same idea to gamma distributed latent variables given gamma variational distributions, enabling straightforward ""black box"" variational inference in models where sparsity and non-negativity are appropriate. We demonstrate the method on a recently proposed gamma process model for network data, as well as a novel sparse factor analysis. We outperform generic sampling algorithms and the approach of using Gaussian variational distributions on transformed variables.",2015-09-04,https://www.semanticscholar.org/paper/087db3a5982b7b6a0d22e5bfa8692534446946fa,
845,The Approximation of Maximum Subgraph Problems,,1993-07-05,https://www.semanticscholar.org/paper/fc79e62fdb1f31f04b2590fad5391eed3cd7cd97,"International Colloquium on Automata, Languages and Programming"
169,Biologically Plausible Neural Networks via Evolutionary Dynamics and Dopaminergic Plasticity,"Artificial neural networks (ANNs) lack in biological plausibility, chiefly because backpropagation requires a variant of plasticity (precise changes of the synaptic weights informed by neural events that occur downstream in the neural circuit) that is profoundly incompatible with the current understanding of the animal brain. Here we propose that backpropagation can happen in evolutionary time, instead of lifetime, in what we call neural net evolution (NNE). In NNE the weights of the links of the neural net are sparse linear functions of the animal’s genes, where each gene has two alleles, 0 and 1. In each generation, a population is generated at random based on current allele frequencies, and it is tested in the learning task through minibatches. The relative performance of the two alleles of each gene is determined, and the allele frequencies are updated via the standard population genetics equations for the weak selection regime. We prove that, under assumptions, NNE succeeds in learning simple labeling functions with high probability, and with polynomially many generations and individuals per generation. NNE is also tested on MNIST with encouraging results. Finally, we explore a further version of biologically plausible ANNs (replacing backprop) inspired by the recent discovery of dopaminergic plasticity.",2019-09-11,https://www.semanticscholar.org/paper/24279ee1fe3c133dc39f10fbf027f36b4b69728d,
1348,Measurement of the λ0b lifetime in the decay λ0b → J/ψλ0 with the D0 detector,,,https://www.semanticscholar.org/paper/88e1c5f010583622c3d4d2db9d7471901f223000,
2805,Deletion of galectin-3 exacerbates microglial activation and accelerates disease progression and demise in a SOD1G93A mouse model of amyotrophic lateral sclerosis,"Galectins are pleiotropic carbohydrate‐binding lectins involved in inflammation, growth/differentiation, and tissue remodeling. The functional role of galectins in amyotrophic lateral sclerosis (ALS) is unknown. Expression studies revealed increases in galectin‐1 mRNA and protein in spinal cords from SOD1 G93A mice, and in galectin‐3 and ‐9 mRNAs and proteins in spinal cords of both SOD1 G93A mice and sporadic ALS patients. As the increase in galectin‐3 appeared in early presymptomatic stages and increased progressively through to end stage of disease in the mouse, it was selected for additional study, where it was found to be mainly expressed by microglia. Galectin‐3 antagonists are not selective and do not readily cross the blood–brain barrier; therefore, we generated SOD1 G93A/Gal‐3 −/− transgenic mice to evaluate galectin‐3 deletion in a widely used mouse model of ALS. Disease progression, neurological symptoms, survival, and inflammation were assessed to determine the effect of galectin‐3 deletion on the SOD1 G93A disease phenotype. Galectin‐3 deletion did not change disease onset, but resulted in more rapid progression through functionally defined disease stages, more severely impaired neurological symptoms at all stages of disease, and expiration, on average, 25 days earlier than SOD1 G93A/Gal‐3 +/+ cohorts. In addition, microglial staining, as well as TNF‐α, and oxidative injury were increased in SOD1 G93A/Gal‐3 −/− mice compared with SOD1 G93A/Gal‐3 +/+ cohorts. These data support an important functional role for microglial galectin‐3 in neuroinflammation during chronic neurodegenerative disease. We suggest that elevations in galectin‐3 by microglia as disease progresses may represent a protective, anti‐inflammatory innate immune response to chronic motor neuron degeneration.",2012-07-23,https://www.semanticscholar.org/paper/5c9d734398875d223ff9b904cb5fd3a388df5fd1,Brain and Behavior
3274,Networks of terrestrial ungulates: linking form and function,,2014-12-18,https://www.semanticscholar.org/paper/dac5ac8433b0de57b9d34e26aef29bb6da77f136,
2831,Galectin-3 regulates peritoneal B1-cell differentiation into plasma cells.,"Extracellular galectin-3 participates in the control of B2 lymphocyte migration and adhesion and of their differentiation into plasma cells. Here, we analyzed the role of galectin-3 in B1-cell physiology and the balance between B1a and B1b lymphocytes in the peritoneal cavity. In galectin-3(-/-) mice, the total number of B1a lymphocytes was lower, while B1b lymphocyte number was higher as compared to wild-type mice. The differentiation of B1a cells into plasma cells was associated with their abnormal adhesion and location on the mesentery. The B220 and CD43, constitutively expressed by B1 lymphocytes, were respectively up- and downregulated in galectin-3(-/-) mice. Mononuclear cells were strongly adhered to the mesenteric membranes of both CD43(-/-) and galectin-3(-/-) mice, but in contrast to CD43(-/-) mice, the accumulation of B1 cells in peritoneal membranes in galectin-3(-/-) mice was accompanied by their functional differentiation into plasma cells. We have shown that in the absence of galectin-3, B1-cell differentiation into plasma cells is favored and the dynamic equilibrium of B1-cell populations in the peritoneum is maintained through a compensatory increase in B1b lymphocytes.",2009-11-01,https://www.semanticscholar.org/paper/60abdb9e9c04497e05eb948944ed8ad47efccd8e,Glycobiology
321,Computing pure nash equilibria in graphical games via markov random fields,"We present a reduction from graphical games to Markov random fields so that pure Nash equilibria in the former can be found by statistical inference on the latter. Our result, when combined with the junction tree algorithm for statistical inference, yields a unified proof of all previously known tractable cases of the NP-complete problem of finding pure Nash equilibria in graphical games, but also implies efficient algorithms for new classes, such as the games with O(log n) treewidth. Furthermore, this important problem becomes susceptible to a wealth of sophisticated and empirically successful techniques from Machine Learning.",2006-06-11,https://www.semanticscholar.org/paper/96516223d950939f19a0536c34d962cf33b0abb6,ACM Conference on Economics and Computation
1321,Measurement of beta (t -> Wb)/beta(t -> Wq) at root s=1.96 TeV,,2006-08-01,https://www.semanticscholar.org/paper/82776adaf3ab8b4c9584d4f32ce0e1c480caa177,
1589,The Deconfounded Recommender: A Causal Inference Approach to Recommendation,"The goal of a recommender system is to show its users items that they will like. In forming its prediction, the recommender system tries to answer: ""what would the rating be if we 'forced' the user to watch the movie?"" This is a question about an intervention in the world, a causal question, and so traditional recommender systems are doing causal inference from observational data. This paper develops a causal inference approach to recommendation. Traditional recommenders are likely biased by unobserved confounders, variables that affect both the ""treatment assignments"" (which movies the users watch) and the ""outcomes"" (how they rate them). We develop the deconfounded recommender, a strategy to leverage classical recommendation models for causal predictions. The deconfounded recommender uses Poisson factorization on which movies users watched to infer latent confounders in the data; it then augments common recommendation models to correct for potential confounding bias. The deconfounded recommender improves recommendation and it enjoys stable performance against interventions on test sets.",2018-08-20,https://www.semanticscholar.org/paper/0e2cce2843780cd03a4108829728833dbfa23632,arXiv.org
3321,The Effect of Space‐Use Patterns of Reintroduced Asiatic Wild Ass on Effective Population Size,"Abstract: Empirical data on behavior, such as space‐use patterns, are important to the success of animal reintroductions. We studied space‐use patterns in a growing population of Asiatic wild ass (   Equus hemionus) reintroduced into the Ramon erosion cirque in the Negev desert, Israel. Between 1988 and 1995 we used direct observation to determine the location and association of males and females. All adult females and dominant males were individually recognized. Home ranges of dominant males overlapped little, suggesting that in this population males are territorial. After the first release of males and females into the wild, only one territory was established, and it covered most of the 20,000 ha of the cirque. After 6 years the number of male territories increased as the number of males in the population increased, and average territory size decreased. Male territories were near permanent and ephemeral water sources, but the water sources were at the peripheries of the territories and were not centers of activity. When there was only one territorial male, female home ranges were almost entirely within the territory. As male territory size decreased, so did the spatial association of females with a single male. During the breeding season, males spent more time in close association with female groups, adopting what may temporarily appear to be a harem breeding strategy. Although demographic and environmental factors pose a greater threat to small populations, our data support the hypothesis that in small, reintroduced populations of territorial, polygynous species, effective population size (  Ne  ) may be dangerously small. Our data suggest that this situation may last for several years until new males are recruited into the population. Thereafter, rapid male turnover and female use of several male territories may ameliorate this problem. We found no relationship between male turnover rate and female reproductive success. The establishment of more male territories is key to increasing Ne and should be the basis for planning reserves for territorial, polygynous species.",2000-12-01,https://www.semanticscholar.org/paper/09f45b6c3b170b4c959c157c6e0b6078f5468db7,Conservation Biology
2648,Surface Region Optimization,"A regional optimization of automatically generated machining toolpath for computer based freeform mechanical models is considered in the framework of multi-axis (three to ve) machining operations. Consider a trichotomy of an arbitrary freeform shaped surface into convex, concave and saddle-like regions. Saddle-like and concave regions can be milled using a ball end tool, in a 3or a 5-axis mode. A subset of the convex regions can be machined faster and with a smaller scallop, using a at end tool that is aligned with the normal of the surface, in 5-axis mode. A method to robustly detect and eliminate local gouging of the milling tool into the object is developed and demonstrated on an actual part.",,https://www.semanticscholar.org/paper/cfb8212fa120b2c41e71228ebe6623d797e438b3,
3473,"Introduction to Algorithms, 2nd edition.",,,https://www.semanticscholar.org/paper/01e4fb65c450930c02208663644b1f7a62b0f0b6,
760,Efficient Qualitative Analysis of Classes of Recursive Markov Decision Processes and Simple Stochastic Games,,2006-02-23,https://www.semanticscholar.org/paper/0395bc208169356de77e58684246c34f90fd3119,Symposium on Theoretical Aspects of Computer Science
371,On the complexity of equilibria,"We prove complexity, approximability, and inapproximability results for the problem of finding an exchange equilibrium in markets with indivisible (integer) goods, most notably a polynomial-time algorithm that approximates the market equilibrium arbitrarily closely when the number of goods is bounded and the utilities are linear. We also show a communication complexity lower bound, implying that the ideal informational economy of a market with unique individual optima is unattainable in general.",2002-05-19,https://www.semanticscholar.org/paper/6ae7db97f3ca25fa05af292503cc7b5dc0ea5f5f,Symposium on the Theory of Computing
21,Selecting Quality Twitter Content for Events,"
 
 Social media sites such as Twitter contain large amounts of user contributed messages for a wide variety of real-world events. While some of these ""event messages"" might contain interesting and useful information (e.g., event time, location, participants, opinions), others might provide little value (e.g., using heavy slang, incomprehensible language) to people interested in learning about an event. Techniques for effective selection of quality event content may therefore help improve applications such as event browsing and search.In this paper, we explore approaches for finding representative messages among a set of Twitter messages that correspond to the same event, with the goal of identifying high quality, relevant messages that provide useful event information. We evaluate our approaches using a large-scale dataset of Twitter messages, and show that we can automatically select event messages that are both relevant and useful.
 
",2011-07-05,https://www.semanticscholar.org/paper/24dab89bcd046a9cbe4a7a2e8eb9e9478d9a7c56,International Conference on Web and Social Media
1758,Stick-Breaking Beta Processes and the Poisson Process,"We show that the stick-breaking construction of the beta process due to Paisley et al. (2010) can be obtained from the characterization of the beta process as a Poisson process. Specifically, we show that the mean measure of the underlying Poisson process is equal to that of the beta process. We use this underlying representation to derive error bounds on truncated beta processes that are tighter than those in the literature. We also develop a new MCMC inference algorithm for beta processes, based in part on our new Poisson process construction.",2012-03-21,https://www.semanticscholar.org/paper/c95af7ce5d123e48191d5ea256029a1542558095,International Conference on Artificial Intelligence and Statistics
3407,Scheduling (Dagstuhl Seminar 16081),"This report documents the program and the outcomes of Dagstuhl Seminar 16081 ""Scheduling"". The seminar was centered around recent new developments, discussion of open problems and exploring future research directions within the broader scheduling community.",,https://www.semanticscholar.org/paper/689cef1db9ee33df5394813b16f7d1fda45117f9,Dagstuhl Reports
3121,Session details: Optimizing encoding,,2004-05-17,https://www.semanticscholar.org/paper/4fec3da202175274700f119b453d8174cd987df9,Proceedings of the 13th international conference on World Wide Web
3237,Ecological Aspects of Social Evolution,,,https://www.semanticscholar.org/paper/442da4d3699e4b3bbd84e5125fa2b3308ccc0d98,
125,The effectiveness of GIOSS for the text database discovery problem,"The popularity of on-line document databases has led to a new problem: finding which text databases (out of many candidate choices) are the most relevant to a user. Identifying the relevant databases for a given query is the text database discovery problem. The first part of this paper presents a practical solution based on estimating the result size of a query and a database. The method is termed GlOSS—Glossary of Servers Server. The second part of this paper evaluates the effectiveness of GlOSS based on a trace of real user queries. In addition, we analyze the storage cost of our approach.",1994-05-24,https://www.semanticscholar.org/paper/70ad64e3ee1191c858e27756c80487ea8b69d2ac,ACM SIGMOD Conference
1112,pp̄ collisions at √ s = 1 . 96 TeV,"V.M. Abazov, B. Abbott, B.S. Acharya, M. Adams, T. Adams, G.D. Alexeev, G. Alkhazov, A. Alton, G. Alverson, M. Aoki, A. Askew, S. Atkins, K. Augsten, C. Avila, F. Badaud, L. Bagby, B. Baldin, D.V. Bandurin, S. Banerjee, E. Barberis, P. Baringer, J. Barreto, J.F. Bartlett, U. Bassler, V. Bazterra, A. Bean, M. Begalli, L. Bellantoni, S.B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V.A. Bezzubov, P.C. Bhat, S. Bhatia, V. Bhatnagar, G. Blazey, S. Blessing, K. Bloom, A. Boehnlein, D. Boline, E.E. Boos, G. Borissov, T. Bose, A. Brandt, O. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, J. Brown, X.B. Bu, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, C.P. Buszello, E. Camacho-Pérez, B.C.K. Casey, H. Castilla-Valdez, S. Caughron, S. Chakrabarti, D. Chakraborty, K.M. Chan, A. Chandra, E. Chapon, G. Chen, S. Chevalier-Théry, D.K. Cho, S.W. Cho, S. Choi, B. Choudhary, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W.E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, A. Croc, D. Cutts, A. Das, G. Davies, S.J. de Jong, 31 E. De La Cruz-Burelo, F. Déliot, R. Demina, D. Denisov, S.P. Denisov, S. Desai, C. Deterre, K. DeVaughan, H.T. Diehl, M. Diesburg, P.F. Ding, A. Dominguez, A. Dubey, L.V. Dudko, D. Duggan, A. Duperrin, S. Dutt, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V.D. Elvira, Y. Enari, H. Evans, A. Evdokimov, V.N. Evdokimov, G. Facini, L. Feng, T. Ferbel, F. Fiedler, F. Filthaut, 31 W. Fisher, H.E. Fisk, M. Fortner, H. Fox, S. Fuess, A. Garcia-Bellido, J.A. Garćıa-González, G.A. Garćıa-Guerra, V. Gavrilov, P. Gay, W. Geng, 59 D. Gerbaudo, C.E. Gerber, Y. Gershtein, G. Ginther, 66 G. Golovanov, A. Goussiou, P.D. Grannis, S. Greder, H. Greenlee, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, T. Guillemin, G. Gutierrez, P. Gutierrez, A. Haas, S. Hagopian, J. Haley, L. Han, K. Harder, A. Harel, J.M. Hauptman, J. Hays, T. Head, T. Hebbeker, D. Hedin, H. Hegab, A.P. Heinson, U. Heintz, C. Hensel, I. Heredia-De La Cruz, K. Herner, G. Hesketh , M.D. Hildreth, R. Hirosky, T. Hoang, J.D. Hobbs, B. Hoeneisen, M. Hohlfeld, I. Howley, Z. Hubacek, 15 V. Hynek, I. Iashvili, Y. Ilchenko, R. Illingworth, A.S. Ito, S. Jabeen, M. Jaffré, A. Jayasinghe, R. Jesik, K. Johns, E. Johnson, M. Johnson, A. Jonckheere, P. Jonsson, J. Joshi, A.W. Jung, A. Juste, K. Kaadze, E. Kajfasz, D. Karmanov, P.A. Kasper, I. Katsanos, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y.N. Kharzheev, I. Kiselevich, J.M. Kohli, A.V. Kozelov, J. Kraus, S. Kulikov, A. Kumar, A. Kupco, T. Kurča, V.A. Kuzmin, S. Lammers, G. Landsberg, P. Lebrun, H.S. Lee, S.W. Lee, W.M. Lee, J. Lellouch, H. Li, L. Li, Q.Z. Li, J.K. Lim, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, H. Liu, Y. Liu, A. Lobodenko, M. Lokajicek, R. Lopes de Sa, H.J. Lubatti, R. Luna-Garcia, A.L. Lyon, A.K.A. Maciel, R. Madar, R. Magaña-Villalba, S. Malik, V.L. Malyshev, Y. Maravin, J. Mart́ınez-Ortega, R. McCarthy, C.L. McGivern, M.M. Meijer, 31 A. Melnitchouk, D. Menezes, P.G. Mercadante, M. Merkin, A. Meyer, J. Meyer, F. Miconi, N.K. Mondal, M. Mulhearn, E. Nagy, M. Naimuddin, M. Narain, R. Nayyar, H.A. Neal, J.P. Negret, P. Neustroev, T. Nunnemann, G. Obrant, J. Orduna, N. Osman, J. Osta, M. Padilla, A. Pal, N. Parashar, V. Parihar, S.K. Park, R. Partridge, N. Parua, A. Patwa, B. Penning, M. Perfilov, Y. Peters, K. Petridis, G. Petrillo, P. Pétroff, M.-A. Pleier, P.L.M. Podesta-Lerma, V.M. Podstavkov, A.V. Popov, M. Prewitt, D. Price, N. Prokopenko, J. Qian, A. Quadt, B. Quinn, M.S. Rangel, K. Ranjan, P.N. Ratoff, I. Razumov, P. Renkel, I. Ripp-Baudot, F. Rizatdinova, M. Rominsky, A. Ross, C. Royon, P. Rubinov, R. Ruchti, G. Sajot, P. Salcido, A. Sánchez-Hernández, M.P. Sanders, B. Sanghi, A.S. Santos, G. Savage, L. Sawyer, T. Scanlon, R.D. Schamberger, Y. Scheglov, H. Schellman, S. Schlobohm, C. Schwanenberger, R. Schwienhorst, J. Sekaric, H. Severini, E. Shabalina, V. Shary, S. Shaw, A.A. Shchukin, R.K. Shivpuri, V. Simak, P. Skubic, P. Slattery, D. Smirnov, K.J. Smith, G.R. Snow, J. Snow, S. Snyder, S. Söldner-Rembold, L. Sonnenschein, K. Soustruznik, J. Stark, D.A. Stoyanova, M. Strauss, L. Stutte, L. Suter, P. Svoisky, M. Takahashi, M. Titov, V.V. Tokmenin, Y.-T. Tsai, K. Tschann-Grimm, D. Tsybychev, B. Tuchming, C. Tully,",,https://www.semanticscholar.org/paper/346cd8bdb6b0477106870738f07fbe706efb0316,
3679,Tracking Through Containers and Occluders in the Wild,"Tracking objects with persistence in cluttered and dynamic environments remains a difficult challenge for computer vision systems. In this paper, we introduce TCOW, a new benchmark and model for visual tracking through heavy occlusion and containment. We set up a task where the goal is to, given a video sequence, segment both the projected extent of the target object, as well as the surrounding container or occluder whenever one exists. To study this task, we create a mixture of synthetic and annotated real datasets to support both supervised learning and structured evaluation of model performance under various forms of task variation, such as moving or nested containment. We evaluate two recent transformer-based video models and find that while they can be surprisingly capable of tracking targets under certain settings of task variation, there remains a considerable performance gap before we can claim a tracking model to have acquired a true notion of object permanence.",2023-05-04,https://www.semanticscholar.org/paper/1a96f901dad704fafa88fa7525174b15c720bcf1,Computer Vision and Pattern Recognition
1200,Search for charged Higgs bosons decaying to top and bottom quarks in $p \bar p $ collisions,"We describe a search for production of a charged Higgs boson, qq ′→H+, reconstructed in the tb final state in the mass range 180≤MH+≤300 GeV. The search was undertaken at the Fermilab Tevatron collider with a center-of-mass energy √s=1.96 TeV and uses 0.9 fb-1 of data collected with the D0 detector. We find no evidence for charged Higgs boson production and set upper limits on the production cross section in the types I, II, and III two-Higgs-doublet models (2HDMs). An excluded region in the (MH+, tan⁡β) plane for type I 2HDM is presented.",2008-07-05,https://www.semanticscholar.org/paper/0db42856f3c886f53a14945e24f21ce0ad34b7e1,
2075,Overall Wafer Effectiveness (OWE): A Novel Industry Standard for Wafer Productivity,"Overall equipment efficiency (OEE) is an index that is widely used to measure equipment performance for semiconductor manufacturing. However, little research has been done to address productivity from the perspective of wafer exposure performance. This study aims to propose a novel standard, overall wafer effectiveness (OWE), to evaluate the effectiveness of wafer exposure rather than only considering tool productivity. Furthermore, the proposed OWE can be easily extended to incorporate additional attributes such as throughput, yield, and price. In particular, a weighted OWE that integrates mask field utilization and OWE is illustrated with numerical example to show the practical viability of OWE as a semiconductor industry standard to drive collaborative efforts among IC designers, equipment vendors, and manufacturers for enhancing total wafer effectiveness.",2006-09-01,https://www.semanticscholar.org/paper/14c4c5b34aef3d2edada63e27334aecb6328123c,2006 IEEE International Symposium on Semiconductor Manufacturing
2938,Landscape of stimulation-responsive chromatin across diverse human immune cells,,2018-09-05,https://www.semanticscholar.org/paper/28e2a40e8863ccd08bc8336a91df11a892d4ea02,Nature Genetics
2817,Lack of Galectin-3 Disturbs Mesenteric Lymph Node Homeostasis and B Cell Niches in the Course of Schistosoma mansoni Infection,"Galectin-3 is a β-galactoside-binding protein that has been shown to regulate pathophysiological processes, including cellular activation, differentiation and apoptosis. Recently, we showed that galectin-3 acts as a potent inhibitor of B cell differentiation into plasma cells. Here, we have investigated whether galectin-3 interferes with the lymphoid organization of B cell compartments in mesenteric lymph nodes (MLNs) during chronic schistosomiasis, using WT and galectin-3-/- mice. Schistosoma mansoni synthesizes GalNAcβ1-4(Fucα1-3)GlcNAc(Lac-DiNAc) structures (N-acetylgalactosamine β1-4 N-acetylglucosamine), which are known to interact with galectin-3 and elicit an intense humoral response. Antigens derived from the eggs and adult worms are continuously drained to MLNs and induce a polyclonal B cell activation. In the present work, we observed that chronically-infected galectin-3-/- mice exhibited a significant reduced amount of macrophages and B lymphocytes followed by drastic histological changes in B lymphocyte and plasma cell niches in the MLNs. The lack of galectin-3 favored an increase in the lymphoid follicle number, but made follicular cells more susceptible to apoptotic stimuli. There were an excessive quantity of apoptotic bodies, higher number of annexin V+/PI- cells, and reduced clearance of follicular apoptotic cells in the course of schistosomiasis. Here, we observed that galectin-3 was expressed in non-lymphoid follicular cells and its absence was associated with severe damage to tissue architecture. Thus, we convey new information on the role of galectin-3 in regulation of histological events associated with B lymphocyte and plasma cell niches, apoptosis, phagocytosis and cell cycle properties in the MLNs of mice challenged with S.mansoni.",2011-05-06,https://www.semanticscholar.org/paper/134b8458734b3c96ebdf116f85f499222bced7b7,PLoS ONE
3304,"Habitat choice of Grevy’s zebras (Equus grevyi) in Laikipia, Kenya","Characterizing habitat choice is essential for endangered species conservation. For the endangered Grevy’s zebra (Equus grevyi), as with many widely ranging vertebrates, human activities may be an important factor affecting space use. Grevy’s zebras are grazing ungulates inhabiting the savannahs of central-northern Kenya and Ethiopia. Past research on their social organization indicates that reproductive status shapes associations and movements. Here, we examine how habitat use varies across four reproductive classes: lactating and nonlactating females, bachelors and territorial males. We also test whether Grevy’s zebra avoid locations close to active livestock corrals, or bomas. We find that forage quality, forage quantity and habitat openness of locations used by Grevy’s zebra vary significantly depending on individual reproductive state. Lactating females and bachelors use areas with green, short grass and mediumdense bush more frequently than nonlactating females or territorial males. We hypothesize that lactating females trade off forage quantity and safety to access nutrients in growing grass. Across reproductive classes, Grevy’s zebra choose locations further from active bomas than if they used the area randomly. Our results suggest that Grevy’s zebra may require a range of vegetation characteristics for different reproductive classes. Further, they may need areas free from competition or disturbance by",2008-09-01,https://www.semanticscholar.org/paper/daa111d00818919f8e0d944075f0a1584344a4ea,
1727,PUTOP: Turning Predominant Senses into a Topic Model for Word Sense Disambiguation,"We extend on McCarthy et al.’s predominant sense method to create an unsupervised method of word sense disambiguation that uses automatically derived topics using Latent Dirichlet allocation. Using topicspecific synset similarity measures, we create predictions for each word in each document using only word frequency information. It is hoped that this procedure can improve upon the method for larger numbers of topics by providing more relevant training corpora for the individual topics. This method is evaluated on SemEval-2007 Task 1 and Task 17. 1 Generative Model of WSD Word Sense Disambiguation (WSD) is the problem of labeling text with the appropriate semantic labels automatically. Although WSD is claimed to be an essential step in information retrieval and machine translation, it has not seen effective practical application because the dearth of labeled data has prevented the use of established supervised statistical methods that have been successfully applied to other natural language problems. Unsupervised methods have been developed for WSD, but despite modest success have not always been well understood statistically (Abney, 2004). Unsupervised methods are particularly appealing because they do not require expensive senseannotated data and can use the ever-increasing amount of raw text freely available. This paper expands on an effective unsupervised method for WSD and embeds it into a topic model, thus allowing an algorithm trained on a single, monolithic corpora to instead hand-pick relevant documents in choosing a disambiguation. After developing this generative statistical model, we present its performance on a number of tasks. 1.1 The Intersection of Syntactic and Semantic Similarity McCarthy et al. (2004) outlined a method for learning a word’s most-used sense given an untagged corpus that ranks each sense wsi using a distributional syntactic similarity γ and a WORDNET-derived semantic similarity α. This process for a word w uses its distributional neighbors Nw, the possible senses of not only the word in question, Sw, and also those of the distributionally similar words, Snj . Thus, P (wsi) =",,https://www.semanticscholar.org/paper/fc72472b075215b633d0f52f97789ba05097ed6c,
3536,Improving performance and maintainability through refactoring in C++11,J. Daniel Garcia's work was partially supported by Fundacion CajaMadrid through their grant programme for Madrid University Professors. Bjarne Stroustrup's work was partially supported by NSF grant #0833199,2015-08-27,https://www.semanticscholar.org/paper/1a84826ad4968082761952b7ef0f5f6bc65f39e7,
2072,Made in Taiwan: Shifting Paradigms in High-tech Industries,,,https://www.semanticscholar.org/paper/c6b65cab9cb232ae6631b3dc1c6082e5db128ba1,
2814,Galectin-3 modulates phagocytosis-induced stellate cell activation and liver fibrosis in vivo.,"Hepatic stellate cells (HSC), the key fibrogenic cells of the liver, transdifferentiate into myofibroblasts upon phagocytosis of apoptotic hepatocytes. Galectin-3, a β-galactoside-binding lectin, is a regulator of the phagocytic process. In this study, our aim was to study the mechanism by which extracellular galectin-3 modulates HSC phagocytosis and activation. The role of galectin-3 in engulfment was evaluated by phagocytosis and integrin binding assays in primary HSC. Galectin-3 expression was studied by real-time PCR and enzyme-linked immunosorbent assay, and in vivo studies were done in wild-type and galectin-3(-/-) mice. We found that HSC from galectin-3(-/-) mice displayed decreased phagocytic activity, expression of transforming growth factor-β1, and procollagen α1(I). Recombinant galectin-3 reversed this defect, suggesting that extracellular galectin-3 is required for HSC activation. Galectin-3 facilitated the α(v)β(3) heterodimer-dependent binding, indicating that galectin-3 modulates HSC phagocytosis via cross-linking this integrin and enhancing the tethering of apoptotic cells. Blocking integrin α(v)β(3) resulted in decreased phagocytosis. Galectin-3 expression and release were induced in active HSC engulfing apoptotic cells, and this was mediated by the nuclear factor-κB signaling. The upregulation of galectin-3 in active HSC was further confirmed in vivo in bile duct-ligated (BDL) rats. Galectin-3(-/-) mice displayed significantly decreased fibrosis, with reduced expression of α-smooth muscle actin and procollagen α1(I) following BDL. In summary, extracellular galectin-3 plays a key role in liver fibrosis by mediating HSC phagocytosis, activation, and subsequent autocrine and paracrine signaling by a feedforward mechanism.",2012-02-01,https://www.semanticscholar.org/paper/de1efea3358c809837042dbd0e373993a28be845,American Journal of Physiology - Gastrointestinal and Liver Physiology
514,ON GRAPH-THEORETIC LEMMATA AND COMPLEXITY CLASSES (Extended Abstract ),"We define several new complexity classes of search problems, ""between"" the classes FP and FNP. These classes are contained (along with factoring, and (JPY)'s class PLS) in the class TFNP of search problems that always have a solu- tion. A problem in each of these new classes is de- fined in terms of an implicitly given, exponentially large graph, very much like PLS. The existence of the solution sought is established via a simple graph- theoretic lemma with an inefficiently constructive proof; for example, PLS can be thought of as cor- responding to the lemma ""every dag has a sink."" The new classes are based on lemmata such as ""ev- ery graph has an even number of odd-degree nodes."" We show several class containments and collapses, resulting in the two new classes PDLF C PLF; the relation of either class to PLS is open. PLF contains several important problems for which no polynom'al time algorithm is presently known, including the lin- ear complementarity problem for P-matrices, finding a mixed equilibrium in a non-zero sum game, find- ing a second Hamilton circuit in a Hamiltonian cubic graph, finding a second Hamiltonian decomposition in a quartic graph, and the computational versions of Sperner's Lemma and Brouwer's Fixpoint Theo- rem. In fact, the latter two problems are shown to be PDLF-complete.",,https://www.semanticscholar.org/paper/86d60cb8f1bf79de6593bc5f53a6a0feedd85dd9,IEEE Annual Symposium on Foundations of Computer Science
789,Perfect Packing Theorems and the Average-Case Behavior of Optimal and Online Bin Packing,"A process for producing alkoxy ketones of formula I wherein R1 represents an alkyl group having 1 to 8 carbon atoms, R2 represents hydrogen or an alkyl group having 1 to 4 carbon atoms, and n represents 1 or 2, by dehydrogenation of a corresponding alkoxyalkanol on a copper-containing catalyst which has been activated by treatment with hydrogen at 120 DEG to 450 DEG C., in which process the activated catalyst is firstly brought into contact at 230 DEG to 350 DEG C. with the vapor of the alkoxyalkanol to be dehydrogenated; hydrogen is subsequently passed over the catalyst at 250 DEG to 450 DEG C.; and then the dehydrogenation is performed at 150 DEG to 450 DEG C. on the catalyst pretreated in this manner, is disclosed.",,https://www.semanticscholar.org/paper/ed92c20debeca111fdea9b2c2bf864d8753735d6,SIAM Review
1463,Evidence of soft and collinear gluon emission ine+e− hadronic events,,1989-09-01,https://www.semanticscholar.org/paper/9da7da70bf409a7af708566d57aa58fc4755a527,
1530,Probabilistic Conformal Prediction Using Conditional Random Samples,"This paper proposes probabilistic conformal prediction (PCP), a predictive inference algorithm that estimates a target variable by a discontinuous predictive set. Given inputs, PCP construct the predictive set based on random samples from an estimated generative model. It is efficient and compatible with either explicit or implicit conditional generative models. Theoretically, we show that PCP guarantees correct marginal coverage with finite samples. Empirically, we study PCP on a variety of simulated and real datasets. Compared to existing methods for conformal inference, PCP provides sharper predictive sets.",2022-06-14,https://www.semanticscholar.org/paper/caf9b1c5458ee90a6351f6438c3a705e4f2086df,International Conference on Artificial Intelligence and Statistics
283,Linked decompositions of networks and the power of choice in Polya urns,"A linked decomposition of a graph with n nodes is a set of subgraphs covering the n nodes such that all pairs of subgraphs intersect; we seek linked decompositions such that all subgraphs have about √n vertices, logarithmic diameter, and each vertex of the graph belongs to either one or two subgraphs. A linked decomposition enables many control and management functions to be implemented locally, such as resource sharing, maintenance of distributed directory structures, deadlock-free routing, failure recovery and load balancing, without requiring any node to maintain information about the state of the network outside the subgraphs to which it belongs. Linked decompositions also enable efficient routing, schemes with small routing tables, which we describe in Section 5. Our main contribution is to show that ""Internet-like graphs"" (e.g. the preferential attachment model proposed by Barabasi et al. [10] and other similar models) have linked decompositions with the parameters described above with high probability; moreover, our experiments show that the Internet topology itself can be so decomposed. Our proof proceeds by analyzing a novel process, which we call Polya urns with the power of choice, which may be of great independent interest. In this new process, we start with n nonempty bins containing O(n) balls total, and each arriving ball is placed in the least loaded of m bins, drawn independently at random with probability proportional to load. Our analysis shows that in our new process, with high probability the bin loads become roughly balanced some time before O(n2+ε) further balls have arrived and stay roughly balanced, regardless of how the initial O(n) balls were distributed, where ε > 0 can be arbitrarily small, provided m is large enough.",2008-01-20,https://www.semanticscholar.org/paper/16e70181c78909e744c132566279b012b1285f8b,ACM-SIAM Symposium on Discrete Algorithms
1391,Exclusion Limits on the WIMP Nucleon Cross-Section from the Cryogenic Dark Matter Search,"The Cryogenic Dark Matter Search (CDMS) employs low-temperature Ge and Si detectors to search for weakly interacting massive particles (WIMPs) via their elastic-scattering interactions with nuclei while discriminating against interactions of background particles. For recoil energies above 10 keV, events due to background photons are rejected with >99.9% efficiency, and surface events are rejected with >95% efficiency. The estimate of the background due to neutrons is based primarily on the observation of multiple-scatter events that should all be neutrons. Data selection is determined primarily by examining calibration data and vetoed events. Resulting efficiencies should be accurate to ∼10%. Results of CDMS data from 1998 and 1999 with a relaxed fiducial-volume cut (resulting in 15.8 kg days exposure on Ge) are consistent with an earlier analysis with a more restrictive fiducial-volume cut. Twenty-three WIMP candidate events are observed, but these events are consistent with a background from neutrons in all ways tested. Resulting limits on the spin-independent WIMP-nucleon elastic-scattering cross section exclude unexplored parameter space for WIMPs with masses between 10–70 GeV/c2. These limits border, but do not exclude, parameter space allowed by supersymmetry models and accelerator constraints. Results are compatible with some regions reported as allowed at 3σ by the annual-modulation measurement of the DAMA Collaboration. However, under the assumptions of standard WIMP interactions and a standard halo, the results are incompatible with the DAMA most likely value at >99.9% confidence level (C.L.), and are incompatible with the model-independent annual-modulation signal of DAMA at 99.99% C.L. in the asymptotic limit.",2002-12-20,https://www.semanticscholar.org/paper/03a9449ef91ac2b31b7bd20595b38b2fbd519272,
2596,"Digitally modeling, visualizing and preserving archaeological sites","Preserving cultural heritage and historic sites is an important problem. These sites are subject to erosion and vandalism, and, as long-lived artifacts, they have gone through many phases of construction, damage and repair. We believe that it is important to use 3D model building technology to create an accurate record of these sites, so preservationists can track changes and foresee structural problems. From a digital libraries perspective, 3D models also allow a much wider audience to ""virtually"" see and tour these sites. We have developed a suite of new methods that can reduce the time to build a model through automation. Our methods utilize range image segmentation and feature extraction algorithms. Once the 3D model is constructed, it is necessary to texture map it with imagery to create a geometrically and photometrically correct model. We are developing a 3D visualization environment to aid archaeologists in their post-excavation interpretation and analysis.",2004-06-07,https://www.semanticscholar.org/paper/36a37ccab70a12901e557193b61c91a5a753aa69,"Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries, 2004."
2800,Galectin-3 promotes HIV-1 budding via association with Alix and Gag p6.,"Galectin-3 has been reported to regulate the functions of a number of immune cell types. We previously reported that galectin-3 is translocated to immunological synapses in T cells upon T-cell receptor engagement, where it associates with ALG-2-interacting protein X (Alix). Alix is known to coordinate with the endosomal sorting complex required for transport (ESCRT) to promote human immunodeficiency virus (HIV)-1 virion release. We hypothesized that galectin-3 plays a role in HIV-1 viral budding. Cotransfection of cells of the Jurkat T line with galectin-3 and HIV-1 plasmids resulted in increased HIV-1 budding, and suppression of galectin-3 expression by RNAi in Hut78 and primary CD4+ T cells led to reduced HIV-1 budding. We used immunofluorescence microscopy to observe the partial colocalization of galectin-3, Alix and Gag in HIV-1-infected cells. Results from co-immunoprecipitation experiments indicate that galectin-3 expression promotes Alix-Gag p6 association, whereas the results of Alix knockdown suggest that galectin-3 promotes HIV-1 budding through Alix. HIV-1 particles released from galectin-3-expressing cells acquire the galectin-3 protein in an Alix-dependent manner, with proteins primarily residing inside the virions. We also found that the galectin-3 N-terminal domain interacts with the proline-rich region of Alix. Collectively, these results suggest that endogenous galectin-3 facilitates HIV-1 budding by promoting the Alix-Gag p6 association.",2014-11-01,https://www.semanticscholar.org/paper/7f8c1a8f85cce48d532c1573262911d5f07074c5,Glycobiology
3115,THINC: a virtual display architecture for thin-client computing,"Rapid improvements in network bandwidth, cost, and ubiquity combined with the security hazards and high total cost of ownership of personal computers have created a growing market for thin-client computing. We introduce THINC, a virtual display architecture for high-performance thin-client computing in both LAN and WAN environments. THINC virtualizes the display at the device driver interface to transparently intercept application display commands and translate them into a few simple low-level commands that can be easily supported by widely used client hardware. THINC's translation mechanism efficiently leverages display semantic information through novel optimizations such as offscreen drawing awareness, native video support, and server-side screen scaling. This is integrated with an update delivery architecture that uses shortest command first scheduling and non-blocking operation. THINC leverages existing display system functionality and works seamlessly with unmodified applications, window systems, and operating systems.We have implemented THINC in an X/Linux environment and compared its performance against widely used commercial approaches, including Citrix MetaFrame, Microsoft RDP, GoToMyPC, X, NX, VNC, and Sun Ray. Our experimental results on web and audio/video applications demonstrate that THINC can provide up to 4.8 times faster web browsing performance and two orders of magnitude better audio/video performance. THINC is the only thin client capable of transparently playing full-screen video and audio at full frame rate in both LAN and WAN environments. Our results also show for the first time that thin clients can even provide good performance using remote clients located in other countries around the world.",2005-10-23,https://www.semanticscholar.org/paper/fb7a756e451eb24ef74fba423bffb9b606fc44f8,Symposium on Operating Systems Principles
1397,Search for the scalar top quark in pp collisions at square root[s] = 1.8 TeV.,"We have performed a search for scalar top quark (stop) pair production in the inclusive electron-muon-missing transverse energy final state, using a sample of pp events corresponding to 108.3 pb(-1) of data collected with the D0 detector at Fermilab. The search is done in the framework of the minimal supersymmetric standard model assuming that the sneutrino is the lightest supersymmetric particle. For the dominant decays of the lightest stop, t-->b chi+1 and t-->blnu, no evidence for signal is found. We derive cross-section limits as a function of stop ( t ), chargino ( chi+1), and sneutrino ( nu) masses.",,https://www.semanticscholar.org/paper/a475f22b553f6df9599a9e84684bfaabebbcb731,Physical Review Letters
535,The parallel complexity of simple chain queries,"They are written m a notation called DATALOG, that IS, PROLOG without function symbols and other lmpurities (an orthogonal way of vlewmg DATALOG 1s as Relatlonal Calculus with the additional power of recurslon) For more on DATALOG see, for example, [UV] Both queries above define a view S m terms of the database relations a and b We are Interested m the parallel complexJtyof these and similar queries, that is, the degree to which such queries are amenable to rapid parallel evaluation by the cooperation of many processors Recently, m view of the projected avallablhty of multlprocessmg systems with a very large number of processors, there has been much Interest m such a classlficatlon of computational problems In particular, it has been proposed that a problem be considered satlsfactorlly solved m parallel if there IS an algorithm for it which can be rendered as a circuit with a polynomial number of gates, andpoiyiogarlthmlc depth (that IS, of depth O(logk n), where n IS the length of the input) The class of all problems thus solvable 1s called NC [Co] Obviously, NC 1s a subset of P, the class of all problems solvable m polynomial sequentd time (It IS perhaps amusing that, m response to a sequence of lmpresslve breakthroughs m computmg technology,",1987-06-01,https://www.semanticscholar.org/paper/052106387e31bc2996721a168027ad86b8b0ac00,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
1486,Experimental limit on the decay tau ---> nu tau K-K0.,,1987-08-01,https://www.semanticscholar.org/paper/c872f94a6f1b4cd6ac6b688b56a9460434012d05,Physical Review Letters
1785,The IBP Compound Dirichlet Process and its Application to Focused Topic Modeling,"The hierarchical Dirichlet process (HDP) is a Bayesian nonparametric mixed membership model—each data point is modeled with a collection of components of different proportions. Though powerful, the HDP makes an assumption that the probability of a component being exhibited by a data point is positively correlated with its proportion within that data point. This might be an undesirable assumption. For example, in topic modeling, a topic (component) might be rare throughout the corpus but dominant within those documents (data points) where it occurs. We develop the IBP compound Dirichlet process (ICD), a Bayesian nonparametric prior that decouples across-data prevalence and within-data proportion in a mixed membership model. The ICD combines properties from the HDP and the Indian buffet process (IBP), a Bayesian nonparametric prior on binary matrices. The ICD assigns a subset of the shared mixture components to each data point. This subset, the data point's ""focus"", is determined independently from the amount that each of its components contribute. We develop an ICD mixture model for text, the focused topic model (FTM), and show superior performance over the HDP-based topic model.",2010-06-21,https://www.semanticscholar.org/paper/a0bcdf26fcd382dd54ac38be07e6b33179bd52f4,International Conference on Machine Learning
1926,Analysing semiconductor manufacturing big data for root cause detection of excursion for yield enhancement,"With the shrinking feature size of integrated circuits driven by continuous technology migrations for wafer fabrication, the control of tightening critical dimensions is critical for yield enhancement, while physical failure analysis is increasingly difficult. In particular, the yield ramp up stage for implementing new technology node involves new production processes, unstable machine configurations, big data with multiple co-linearity and high dimensionality that can hardly rely on previous experience for detecting root causes. This research aims to propose a novel data-driven approach for Analysing semiconductor manufacturing big data for low yield (namely, excursions) diagnosis to detect process root causes for yield enhancement. The proposed approach has shown practical viability to efficiently detect possible root causes of excursion to reduce the trouble shooting time and improve the production yield effectively.",2017-09-02,https://www.semanticscholar.org/paper/da60cf9577d3d52575f38fe3879bab63d066267d,International Journal of Production Research
1755,Scalable Inference of Overlapping Communities,"We develop a scalable algorithm for posterior inference of overlapping communities in large networks. Our algorithm is based on stochastic variational inference in the mixed-membership stochastic blockmodel (MMSB). It naturally interleaves subsampling the network with estimating its community structure. We apply our algorithm on ten large, real-world networks with up to 60,000 nodes. It converges several orders of magnitude faster than the state-of-the-art algorithm for MMSB, finds hundreds of communities in large real-world networks, and detects the true communities in 280 benchmark networks with equal or better accuracy compared to other scalable algorithms.",2012-12-03,https://www.semanticscholar.org/paper/9a5eb8fa8df5d3311b27b895ea1af67b5e35f7ff,Neural Information Processing Systems
3124,MobiDesk: mobile virtual desktop computing,"We present MobiDesk, a mobile virtual desktop computing hosting infrastructure that leverages continued improvements in network speed, cost, and ubiquity to address the complexity, cost, and mobility limitations of today's personal computing infrastructure. MobiDesk transparently virtualizes a user's computing session by abstracting underlying system resources in three key areas: display, operating system, and network. It provides a thin virtualization layer that decouples a user's computing session from any particular end-user device, and moves all application logic to hosting providers. The virtualization layer decouples a user's computing session from the underlying operating system and server instance, enabling high-availability service by transparently migrating sessions from one server to another during server maintenance or upgrades. We have implemented a prototype in Linux that works with existing unmodified applications and operating system kernels. Our experimental results demonstrate that MobiDesk has very low virtualization overhead, can provide a full featured desktop experience including full-motion video support, and is able to migrate users' sessions efficiently and reliably for high-availability, while maintaining existing network connections.",2004-09-26,https://www.semanticscholar.org/paper/6e1f042567fe5fc13a99d55e280838a186261a52,ACM/IEEE International Conference on Mobile Computing and Networking
2303,Regulation of neutrophil apoptosis by diadenosine pentaphosphate and GM-CSF.,,1996-08-01,https://www.semanticscholar.org/paper/33a647aa953546ed5633576c5f4faa6cf328cbbf,Biochemical Society Transactions
701,Planar Graphs that Need Four Pages,,2020-05-28,https://www.semanticscholar.org/paper/8a87f3b42b21b3f3518f35f8ecbd1b914fe115bf,Journal of combinatorial theory. Series B (Print)
3708,UnweaveNet: Unweaving Activity Stories,"Our lives can be seen as a complex weaving of activities; we switch from one activity to another, to maximise our achievements or in reaction to demands placed upon us. Observing a video of unscripted daily activities, we parse the video into its constituent activity threads through a process we call unweaving. To accomplish this, we introduce a video representation explicitly capturing activity threads called a thread bank, along with a neural controller capable of detecting goal changes and resuming of past activities, together forming UnweaveNet. We train and evaluate UnweaveNet on sequences from the unscripted egocentric dataset EPIC-KITCHENS. We propose and showcase the efficacy of pretraining UnweaveNet in a self-supervised manner.",2021-12-19,https://www.semanticscholar.org/paper/0fb956fe2bc1272ed53fecb47060c0c3dcff739c,Computer Vision and Pattern Recognition
303,Improved Tradeoff-based Models of the Internet,"This paper introduces and evaluates several new models of the Internet graph, inspired by the model proposed by Fabrikant, Koutsoupias, and Papadimitriou (FKP), in which connections are chosen based on a tradeoff between a geometric objective and a topology objective. For each new node, the proposed models add at least two edges which optimize in addition to the original tradeoff, secondary criteria such as path independence, and then proceed to add, with some small probability, a new edge from the receiving node. In another version of the model, new edges can be added only to certain nodes, which are designated as fertile, an attribute that changes dynamically. These models are evaluated by comparing them to the real Internet AS graph (or network, interchangeably) with respect to a suite of many test parameters (such as power law exponent and local clustering rank) proposed in the literature.",,https://www.semanticscholar.org/paper/2957defeef10e8e3f8d1d28cb6bd6b72966d2f6f,
3215,"Updated geographic range maps for giraffe,
 Giraffa
 spp., throughout sub‐Saharan Africa, and implications of changing distributions for conservation","1 . Giraffe populations have declined in abundance by almost 40% over the last three decades, and the geographic ranges of the species (previously believed to be one, now defined as four species) have been significantly reduced or altered. With substantial changes in land uses, loss of habitat, declining abundance, translocations, and data gaps, the existing geographic range maps for giraffe need to be updated. 2 . We performed a review of existing giraffe range data, including aerial and ground observations of giraffe, existing geographic range maps, and available literature. The information we collected was discussed with and validated by subject-matter experts. Our updates may serve to correct inaccuracies or omissions in the baseline map, or may reflect actual changes in the distribution of giraffe. 3 . Relative to the 2016 List Assessment range map, the updated geographic range maps show a 5.6% decline in the range area of all giraffe taxa combined. The ranges of Giraffa camelopardalis (northern giraffe) and Giraffa tippelskirchi (Masai giraffe) de-creased in area by 37% (122432 km 2 ) and 4.7% (20816 km 2 ) respectively, whereas 14% (41696 km 2 ) of the range of Giraffa reticulata (reticulated giraffe) had not been included in the original geographic range map and has now been added. The range of Giraffa giraffa (southern giraffe) showed little overall change; it increased by 0.1% (419 km 2 ).",2019-08-06,https://www.semanticscholar.org/paper/1da4ca74e3921f527e67352d5df5b41a233e51bd,Mammal Review
3438,Competitive queuing policies for packet scheduling,"In the Internet, all information is aggregated into packets. The computers connected to the Internet communicate with each other by means of exchanging packets. All packets travel through communication links and network switches. If a burst of packets arrives at the same time, a network switch cannot transmit all of them on the fly. Inside a network switch, there are some output buffer(s). Arriving packets are queued in the output buffer(s), waiting to be delivered. 
Most current Internet switches adopt the First-In-First-Out (FIFO) buffering policy. Using the FIFO buffering policy, network switches send packets in the same order as they arrive. FIFO buffering policy cannot provide assured data transmission for time-critical applications or mission-critical applications due to unpredictable packet loss, end-to-end delay, out-of-order delivery, and jitter. 
In the past ten years, there is rapid growth of network traffic and time-critical applications. The diversity of applications results in unpredictable packet flows and heterogeneous network traffic, and motivates us to study buffer management at the switch levels for providing better Quality of Service (QoS). The difficulty of achieving better QoS in the existing Internet infrastructure without sacrificing high resource utilization remains open. 
In this thesis, we study a model in the Differentiated Services (DiffServ) QoS infrastructure, which is called the ""bounded-delay model"". We characterize packets by their deadlines by which they should be sent, and their payoffs when they are delivered on time. Our goal is to maximize the total value of packets sent by their deadlines. We design deterministic online packet scheduling algorithms for QoS queuing policies. We also develop novel and effective analysis techniques. Our algorithms perform better over existing solutions in terms of competitive ratio, which provides a worst-case performance guarantee for all traffic patterns. The ideas and approaches developed in this thesis explore the insights in similar online models with deadline constraints, and can be generalized and applied to other online scheduling problems.",,https://www.semanticscholar.org/paper/e8d429ff7e07525e2cbd8a59ee272f4e2878601f,
3713,Visual behavior modelling for robotic theory of mind,,2021-01-11,https://www.semanticscholar.org/paper/868381eea54ec0b8a96fb525e22836cd756a08b7,Scientific Reports
2059,Data mining to improve personnel selection and enhance human capital: A case study in high-technology industry,,,https://www.semanticscholar.org/paper/e427b25e719e2d165e4d53f078c1d2b791e09729,Expert systems with applications
2422,Scene Editing as Teleoperation: A Case Study in 6DoF Kit Assembly,"Studies in robot teleoperation have been centered around action specifications-from continuous joint control to discrete end-effector pose control. However, these “robot-centric” interfaces often require skilled operators with extensive robotics expertise. To make teleoperation accessible to nonexpert users, we propose the framework “Scene Editing as Teleoperation” (SEaT), where the key idea is to transform the traditional “robot-centric” interface into a “scene-centric” interface-instead of controlling the robot, users focus on specifying the task's goal by manipulating digital twins of the real-world objects. As a result, a user can perform teleoperation without any expert knowledge of the robot hardware. To achieve this goal, we utilize a category-agnostic scene-completion algorithm that translates the real-world workspace (with unknown objects) into a manipulable virtual scene representation and an action-snapping algorithm that refines the user input before generating the robot's action plan. To train the algorithms, we procedurely generated a large-scale, diverse kit-assembly dataset that contains object-kit pairs that mimic real-world object-kitting tasks. Our experiments in simulation and on a real-world system demonstrate that our framework improves both the efficiency and success rate for 6DoF kit-assembly tasks. A user study demonstrates that SEaT framework participants achieve a higher task success rate and report a lower subjective workload compared to an alternative robot-centric interface.",2021-10-09,https://www.semanticscholar.org/paper/ac93430356cf7656a0cd9134904c63e20cca3b77,IEEE/RJS International Conference on Intelligent RObots and Systems
177,Random Projection in the Brain and Computation with Assemblies of Neurons,"9 It has been recently shown via simulations [7] that random projection followed by a cap operation 10 (setting to one the k largest elements of a vector and everything else to zero), a map believed 11 to be an important part of the insect olfactory system, has strong locality sensitivity properties. 12 We calculate the asymptotic law whereby the overlap in the input vectors is conserved, verify13 ing mathematically this empirical finding. We then focus on the far more complex homologous 14 operation in the mammalian brain, the creation through successive projections and caps of an 15 assembly (roughly, a set of excitatory neurons representing a memory or concept) in the presence 16 of recurrent synapses and plasticity. After providing a careful definition of assemblies, we prove 17 that the operation of assembly projection converges with high probability, over the randomness 18 of synaptic connectivity, even if plasticity is relatively small (previous proofs relied on high plas19 ticity). We also show that assembly projection has itself some locality preservation properties. 20 Finally, we propose a large repertoire of assembly operations, including associate, merge, recip21 rocal project, and append, each of them both biologically plausible and consistent with what we 22 know from experiments, and show that this computational system is capable of simulating, again 23 with high probability, arbitrary computation in a quite natural way. We hope that this novel way 24 of looking at brain computation, open-ended and based on reasonably mainstream ideas in neu25 roscience, may prove an attractive entry point for computer scientists to work on understanding 26 the brain. 27 2012 ACM Subject Classification Dummy classification 28",,https://www.semanticscholar.org/paper/fc9ade6f7ebe9afb9884ca4830b4d6cbc79145fc,Information Technology Convergence and Services
2304,"Neutrophil apoptosis is delayed by the diadenosine polyphosphates, Ap5A and Ap6A: synergism with granulocyte‐macrophage colony‐stimulating factor","In addition to ATP, platelets and other cell types can secrete high quantities of diadenosine polyphosphates Ap3A, Ap4A, Ap5A and Ap6A. There is increasing evidence to show that these molecules can function as novel modulators of cell function. For this report we have measured the effects of the diadenosine polyphosphates Ap5A and Ap6A on neutrophil apoptosis. These molecules can themselves delay neutrophil apoptosis (as assessed by morphology, function, CD16 expression and chromatin integrity), and are as effective on a molar basis as ATP, Ap3A and Ap4A. Moreover, these dinucleotides act synergistically with granulocyte‐macrophage colony‐stimulating factor (GM‐CSF) to delay neutrophil apoptosis. Thus, diadenosine polyphosphates may act, in concert with cytokines, as novel modulators of neutrophil function and survival in certain types of inflammatory conditions.",1996-12-01,https://www.semanticscholar.org/paper/3f42dafdab68b3ef914e6474235d2d89635a37d3,British Journal of Haematology
3646,What is ''Object-Oriented Programming''? (1991 revised version),"‘‘Object-Oriented Programming’’ and ‘‘Data Abstraction’’ have become very common terms. Unfortunately, few people agree on what they mean. I will offer informal definitions that appear to make sense in the context of languages like Ada, C + +, Modula2, Simula, and Smalltalk. The general idea is to equate ‘‘support for data abstraction’’ with the ability to define and use new types and equate ‘‘support for object-oriented programming’’ with the ability to express type hierarchies. Features necessary to support these programming styles in a general purpose programming language will be discussed. The presentation centers around C + + but is not limited to facilities provided by that language.",,https://www.semanticscholar.org/paper/f2038b61b571111877d267c52000b4762dd42f9a,
1862,Variational inference in a truncated Dirichlet process,"The N -component truncated Dirichlet process (DPN ) is defined in Ishwaran and James [2001] and converges almost surely to a true Dirichlet process (DP∞). Like a full Dirichlet process, this distribution can be used as a nonparametric Bayesian prior in a mixture model. Ishwaran and James show that this approximation allows a blocking strategy in the corresponding Gibbs sampler which can be faster than the classical Gibbs samplers developed for the DP∞ prior [Escobar and West, 1995]. In this paper, we develop a variational inference algorithm to approximate the posterior in a Bayesian mixture model with a DPN prior. An exponential family mixture model with DPN prior on the natural parameter of the mixture component is illustrated in Figure 2. The random variables are distributed as follows:",,https://www.semanticscholar.org/paper/dbcb94bc47d0570cb00fc9d48b948377f588d647,
794,Realizability and Veriication of Msc Graphs,"Scenario-based speciications such as message sequence charts (MSC) ooer an intuitive and visual way of describing design requirements. MSC-graphs allow convenient expression of multiple scenarios, and can be viewed as an early model of the system that can be subjected to a variety of analyses. Problems such as LTL model checking are known to be decidable for the class of bounded MSC-graphs. Our rst set of results concerns checking realizability of bounded MSC-graphs. An MSC-graph is realizable if there is a distributed implementation that generates precisely the behaviors in the graph. There are two notions of realizability, weak and safe, depending on whether or not we require the implementation to be deadlock-free. It is known that for a set of MSCs, weak realizability is coNP-complete while safe realizability has a polynomial-time solution. We establish that for bounded MSC-graphs, weak realizability is, surprisingly, undecidable, while safe is in Expspace. Our second set of results concerns veriication of MSC-graphs. While checking properties of a graph G, besides verifying all the scenarios in the set L(G) of MSCs speciied by G, it is desirable to verify all the scenarios in the set L w (G)|the closure of G, that contains the implied scenarios that any distributed implementation of G must include. For checking whether a given MSC M is a possible behavior, checking M 2 L(G) is NP-complete, but checking M 2 L w (G) has a quadratic solution. For temporal logic speciications, considering the closure makes the veriication problem harder: while checking LTL properties of L(G) is Pspace-complete and checking local properties has polynomial-time solutions, even for boolean combinations of local properties of L w (G), verifying acyclic graphs is coNP-complete and verifying bounded graphs is undecidable.",,https://www.semanticscholar.org/paper/eca947f97b8b771de7b81999ed46317884f36cc9,
1030,Optimal control for geometric motion planning of a robot diver,"Inertial reorientation of airborne articulated bodies has been an active area of research in the robotics community, as this behavior can help guide dynamic robots to a safe landing with minimal damage. The main objective of this work is emulating the aggressive and large angle correction maneuvers, like somersaults, that are performed by human divers. To this end, a planar three link robot, called DiverBot, is proposed. By considering a gravity-free scenario, a local connection is obtained between joint angles and the body orientation, resulting in a reduction in the system dynamics. An optimal control policy applied on this reduced configuration space yielded diving maneuvers that are dynamically feasible. Numerical results show that the DiverBot can execute one somersault without drift and multiple somersaults with minimal drift.",2016-10-01,https://www.semanticscholar.org/paper/4e8a39940432895a0123b79c09b6cd879649dca8,IEEE/RJS International Conference on Intelligent RObots and Systems
3314,"Cross-sectional survey of gastro-intestinal parasites of Grevy’s zebras in southern Samburu, Kenya","Cross-sectional survey of gastro-intestinal parasites of Grevy’s zebras in southern Samburu, Kenya Paul K. Muoria*, Philip Muruthi, Daniel Rubenstein, Nicholas O. Oguge and Elephas Munene Institute of Primate Research, National Museums of Kenya, PO Box 24481, 00502, Karen, Kenya, African Wildlife Foundation, Britak Center, Mara Road, PO Box 48177, 00100, Nairobi, Kenya, Department of Ecology and Evolutionary Biology, Princeton University, Guyot 401, Princeton, NJ, 08544-1003, U.S.A. and Earthwatch Institute, PO Box 10717, 00100, Nairobi, Kenya",2005-12-01,https://www.semanticscholar.org/paper/ba234414d310b18dd196e5aceab7d8a223778574,
1593,Estimating Heterogeneous Consumer Preferences for Restaurants and Travel Time Using Mobile Location Data,"This paper analyzes consumer choices over lunchtime restaurants using data from a sample of several thousand anonymous mobile phone users in the San Francisco Bay Area. The data is used to identify users' approximate typical morning location, as well as their choices of lunchtime restaurants. We build a model where restaurants have latent characteristics (whose distribution may depend on restaurant observables, such as star ratings, food category, and price range), each user has preferences for these latent characteristics, and these preferences are heterogeneous across users. Similarly, each item has latent characteristics that describe users' willingness to travel to the restaurant, and each user has individual-specific preferences for those latent characteristics. Thus, both users' willingness to travel and their base utility for each restaurant vary across user-restaurant pairs. We use a Bayesian approach to estimation. To make the estimation computationally feasible, we rely on variational inference to approximate the posterior distribution, as well as stochastic gradient descent as a computational approach. Our model performs better than more standard competing models such as multinomial logit and nested logit models, in part due to the personalization of the estimates. We analyze how consumers re-allocate their demand after a restaurant closes to nearby restaurants versus more distant restaurants with similar characteristics, and we compare our predictions to actual outcomes. Finally, we show how the model can be used to analyze counterfactual questions such as what type of restaurant would attract the most consumers in a given location.",2018-01-22,https://www.semanticscholar.org/paper/394929d51af693e42063f6e033add1db35096553,arXiv.org
748,Finite S,"With advanced computer technology, systems are getting larger to fulfill more complicated tasks: however, they are also becoming less reliable. Consequently, testing is an indispensable part of system design and implementation; yet it has proved to be a formidable task for complex systems. This motivates the study of testing jinite state machines to ensure the correct functioning of systems and to discover aspects of their behavior. A Jinite state machine contains a jinite number of states and produces outputs on state transitions after receiving inputs. Finite state machines are widely used to model systems in diverse areas, including sequential circuits, certain types of programs, and, more recently, communication protocols. In a testing problem we have a machine about which we lack some information; we would like to deduce this information by providing a sequence of inputs to the machine and observing the outputs produced. Because of its practical importance and theoretical interest, the problem of testing finite state machines has been studied in different areas and at various times. The earliest published literature on this topic dates back to the 1950’s. Activities in the 1960’s and early 1970’s were motivated mainly by automata theory and sequential circuit testing. The area seemed to have mostly died down until a few years ago when the testing problem was resurrected and is now being studied anew due to its applications to conformance testing of communication protocols. While some old problems which had been open for decades were resolved recently, new concepts and more intriguing problems from new applications to ensure their correct functioning and to discover aspects of their behavior. There are two types of finite state machines: Mealy machines and Moore machines. The theory is very similar for the two types. We consider Mealy machines here because they model finite state systems more properly and are more general than Moore machines. A Mealy machine has a finite number of states and produces outputs on state transitions after receiving inputs. We discuss the following two types of testing problems. In the first type of problems, we have the transition diagram of a finite state machine but we do not know in which state it is. We apply an input sequence to the machine so that from its inputloutput (UO) behavior we can deduce desired information about its state. Specifically, in the state identification problem we wish to identify the initial state of the machine; a test sequence that solves this problem is called a distinguishing sequence. In the state verification problem we wish to verify that the machine is in a specified state; a test sequence that solves this problem is called a unique input/output (UIO) sequence. A different type of problem is conformance testing. Given a specification finite state machine, for which we have its transition diagram, and an imp1ementation, Or box” for which we can only observe its behavior, we want to test whether the implementation conforms to the specification. This is called the conformance testing or fault detection problem and a test sequence that solves this problem is called a checking sequence. Testing hardware and software contains very wide fields with an extensive literature which we cannot hope to cover. Here we will focus on the basic problems of testing finite state machines and present the general principles and methods. We shall not discuss testing combinational circuits which are essentially not finite state systems [50], [75], [l]. We shall not consider functional testing either where we want to verify the equivalence of two known machines or circuits which are not “black boxes” [l], [34], [69]. Numerical software testing is outside the scope of this article where there is an infinite number (in most cases emerge. We review the fundamental problems in testing jinite state machines and techniques for solving these problems, tracing progress in the area from its inception to the present and the state of the art. In addition, we discuss extensions offinite state machines and some other topics related to testing.",,https://www.semanticscholar.org/paper/dbeeb4e45c0e03fa86ecded549ef777f7833c80f,
2813,Galectins in immune and inflammatory diseases: Insights from experiments with galectin deficient mice,,2012-12-18,https://www.semanticscholar.org/paper/d9275342aa1d656da7e192244716dcfa8945f2e2,
1957,Determining the operator-machine assignment for machine interference problem and an empirical study in semiconductor test facility,,2013-05-03,https://www.semanticscholar.org/paper/479b8cb285064c8aabf9e2efd6fb1142c7307b13,Journal of Intelligent Manufacturing
3711,Real-Time Neural Voice Camouflage,"Automatic speech recognition systems have created exciting possibilities for applications, however they also enable opportunities for systematic eavesdropping. We propose a method to camouflage a person's voice over-the-air from these systems without inconveniencing the conversation between people in the room. Standard adversarial attacks are not effective in real-time streaming situations because the characteristics of the signal will have changed by the time the attack is executed. We introduce predictive attacks, which achieve real-time performance by forecasting the attack that will be the most effective in the future. Under real-time constraints, our method jams the established speech recognition system DeepSpeech 3.9x more than baselines as measured through word error rate, and 6.6x more as measured through character error rate. We furthermore demonstrate our approach is practically effective in realistic environments over physical distances.",2021-12-14,https://www.semanticscholar.org/paper/4e2dfe2b54bcd5d5c8178aca868959568298f0c8,International Conference on Learning Representations
3136,The Design and Implementation of Elastic Quotas: A System for Flexible File System Management,"We introduce elastic quotas, a disk space management technique that makes disk space an elastic resource like CPU and memory. Elastic quotas allow all users to use unlimited amounts of available disk space while still providing system administrators the ability to control how the disk space is allocated among users. Elastic quotas maintain existing persistent file semantics while supporting user-controlled policies for removing files when the file system becomes too full. We have implemented an elastic quota system in Solaris and measured its performance. The system is simple to implement, requires no kernel modifications, and is compatible with existing disk space management methods. Our results show that elastic quotas are an effective, low-overhead solution for flexible file system management.",,https://www.semanticscholar.org/paper/2144c76d3e93a5824c26912751984c19d598af19,
476,Incremental Recompilation of Knowledge,"Approximating a general formula from above and below by Horn formulas (its Horn envelope and Horn core, respectively) was proposed in [SK] as a form of ""knowledge compilation,"" supporting rapid approximate reasoning; on the negative side, this scheme is static in that it supports no updates, and has certain complexity drawbacks pointed out in [KPS]. On the other hand, the many frameworks and schemes proposed in the literature for theory update and revision are plagued by serious complexity-theoretic impediments, even in the Horn case, as was pointed out in [EG2] and the present paper. More fundamentally, these schemes are not inductive, in that they lose in a single update any positive properties of the represented sets of formulas (small size, Horn, etc.). In this paper we propose a new scheme, incremental recompilation, combining Horn approximation and model-based updates; this scheme is inductive and very efficient, free of the problems facing its constituents. A set of formulas is represented by an upper and lower Horn approximation. To update, we replace the upper Horn formula by the Horn envelope of its minimum-change update, and similarly the lower one by the Horn core of its update; the key fact is that Horn envelopes and cores are easy to compute when the underlying formula is the result of a minimum-change update of a Horn formula by a clause. We conjecture that efficient algorithms are possible for more complex updates.",1994-10-05,https://www.semanticscholar.org/paper/d6f31aa49b0c5ecfd9bc77b46e37f619c22a5592,AAAI Conference on Artificial Intelligence
1843,"Variational inference and learning for a unified model of syntax, semantics and morphology","There have been recent a t t empts to produce trainable (unsupervised) models of human-language syntax and semantics, as well as morphology. To our knowledge, there has not been an a t t empt to produce a generative model tha t encorporates semantic, syntactic, and morphological elements. Some immediate applications of this tool axe stemming, word clustering by root, and disambiguation (at the syntactic, semantic, and morphological levels). In this work, we propose a hierarchical topics-syntax-morphology model. We provide the variational inference and upda te rules for this model (exact inference is intractable) . We show some preliminary results on segmentation tasks. * Current address: Computer Science Depar tment , Pr inceton University, Princeton, NJ 08540 Research supported in part by NSF grants IIS-0312814 and IIS0427206 and by the DARPA CALO project. University Libraries Carnegie Mellon University Pittsburgh, PA 152 i 3-3890 1. b a t t e r a. [ b a t t e r ] — liquidy dough b . [ b a t ] [ e r ] — one who bats (in baseball) 2. r u n g a. [ rung] — a horizontal bar in a ladder b . [ r i n g ] [PP] — past participle of ' r ing' 3. d i c e a. [ d i c e ] [PRES] to chop finely b . [ d i e ] [PLU] the plural form of 'die ' 4. r e a r r a n g e a. [ r e ] [ a r r a n g e ] [PRES] — to arrange anew b . [ r e a r ] [ r a n g e ] the range of the rear 5. r e s e n t a. [ r e s e n t ] [PRES] to dislike b . [ r e ] [ send] [PAST] — past tense of 'resend' to send again Figure 1: Morphological ambiguity: analysis",,https://www.semanticscholar.org/paper/78de77e1332ff56275f85f4c0de239c55269f93f,
2294,In vitro effects of GM-CSF on mature peripheral blood neutrophils.,"GM-CSF can play a crucial role in regulating the neutrophil-mediated inflammatory response. This growth factor is a proliferative stimulus for bone marrow neutrophil stem cell precursors and has at least 3 important roles in regulating neutrophil-mediated immunity: a) a direct effect on the proliferation and development of neutrophil progenitors; b) synergistic activity with other haemopoietic growth factors; c) stimulation of the functional activity of mature neutrophils. The production of GM-CSF may be triggered directly by exogenous factors such as antigens and endotoxins, or indirectly through the release of cytokines by a variety of cells including lymphocytes, activated macrophages and endothelial cells exposed to products of mononuclear phagocytes. Such production of GM-CSF may serve to quickly release mature neutrophils from the bone marrow in response to infections. Moreover, enhancement of the function of mature neutrophils may also augment their ability to migrate to infective sites and then phagocytose and kill pathogens. Increased expression of CD11b/CD18 may play a fundamental part in this mechanism because this receptor is essential for the adhesion of neutrophils to the endothelium. Both phagocytosis and oxidative burst activity increase as a result of the action of GM-CSF and the increased expression of complement- and Fc-receptors can augment opsono-phagocytosis. A further level of neutrophil up-regulation occurs by increasing the functional life span of neutrophils by GM-CSF. Thus, by delaying neutrophil apoptosis, GM-CSF greatly extends the time over which neutrophils may function at inflammatory sites. GM-CSF can thus exert a variety of important regulatory controls of neutrophil function during bacterial infections. Both the number and the functional status of neutrophils is highly regulated by GM-CSF. It is also possible that GM-CSF produced within localised sites of acute inflammation or infection may attract, trap and then activate neutrophils within this site.",1998-06-01,https://www.semanticscholar.org/paper/fd8abd62208bc0cdcee3ab2ec72717aad5fe36b9,International Journal of Molecular Medicine
2432,Collaborative exploration of urban data in virtual and augmented reality,"From emergency planning to real estate, many domains can benefit from collaborative exploration of urban environments in VR and AR. We have created an interactive experience that allows multiple users to explore live datasets in context of an immersive scale model of the urban environment with which they are related.",2018-08-12,https://www.semanticscholar.org/paper/24ade600e1a8edd247639d64f0ba4e81628af28a,"ACM SIGGRAPH 2018 Virtual, Augmented, and Mixed Reality"
355,On certain connectivity properties of the Internet topology,"We show that random graphs in the preferential connectivity model have constant conductance, and hence have worst-case routing congestion that scales logarithmically with the number of nodes. Another immediate implication is constant spectral gap between the first and second eigenvalues of the random walk matrix associated with these graphs. We also show that the expected frugality (overpayment in the Vickrey-Clarke-Groves mechanism for shortest paths) of a random graph is bounded by a small constant.",2003-10-11,https://www.semanticscholar.org/paper/451c97adbbb68ec1a51b9041d7c06d076642df90,"44th Annual IEEE Symposium on Foundations of Computer Science, 2003. Proceedings."
972,Position of Central Vascular Trunk and Shape of Optic Nerve Head in Newborns.,"Purpose
To investigate the baseline position of the central vascular trunk (CVT) and the characteristics of the optic nerve head (ONH) in newborns.


Methods
CVT position was evaluated based on fundus images obtained from newborns who had undergone eye-screening examinations. It was then graded according to the optic disc area as follows: grade 1, within central 4%; grade 2, within central 9%; grade 3, within central 16%; grade 4, within central 25%; grade 5, outside central 25% of optic disc area. The direction of the CVT position was determined in cases of grade 2 or more as superior, inferior, nasal, and temporal, relative to the optic disc center. The ovality index and the vertical cup-to-disc ratio were determined as well.


Results
In 1000 fundus images from 1000 newborns, 87.1% showed grade 1 (95% confidence interval 84.7-88.8), and 10.7% showed grade 2. The most common CVT direction was central (87.1%, grade 1), followed by nasal (11.0%) and inferior (1.2%). The ovality index was 1.28 ± 0.09 (range, 1.01-1.61). The ONH shape was vertically oval and highly uniform. The average vertical cup-to-disc ratio was 0.29 ± 0.13 (range, 0.00-0.67).


Conclusions
The CVT of newborns was located in the central area of the ONH in most cases. The shape of the optic disc was vertically oval, and very similar among the newborns. Considering the high variability of ONH morphology and the diverse location of the CVT in adults, our result suggests that the shape of the ONH and the CVT position might change during eyeball growth.",2019-08-01,https://www.semanticscholar.org/paper/68009394da5c0c9bdea392e6e4225a3d9ed497fd,Investigative Ophthalmology and Visual Science
2000,Manufacturing intelligence for early warning of key equipment excursion for advanced equipment control in semiconductor manufacturing,"As feature sizes of integrated circuits are continuously shrinking in nanotechnologies, mining potentially useful information to extract manufacturing intelligence from big data automatically collected in the wafer fabrication facilities to assist in real time decisions for yield enhancement has become practically crucial to maintain competitive advantages and support intelligent manufacturing for operational excellence. Motivated by real needs, this study aims to develop an effective approach to extract manufacturing intelligence for early detection of key equipment excursion for advanced equipment control to enhance yield and reduce potential loss. For validation, an empirical study was conducted in a leading semiconductor manufacturing company to validate the proposed approach in the developed “early warning system” of newly released equipment to reduce tool excursion and abnormal yield loss. The results have demonstrated practical viability of the proposed approach. Indeed, the developed solution has been implemented in this company.",2012-07-01,https://www.semanticscholar.org/paper/6babcab39987808c179d32f86346067b2caa0a3a,
87,Approximate String Joins in a Database (Almost) for Free,"String data is ubiquitous, and its management has taken on particular importance in the past few years. Approximate queries are very important on string data especially for more complex queries involving joins. This is due, for example, to the prevalence of typographical errors in data, and multiple conventions for recording attributes such as name and address. Commercial databases do not support approximate string joins directly, and it is a challenge to implement this functionality efficiently with user-defined functions (UDFs). In this paper, we develop a technique for building approximate string join capabilities on top of commercial databases by exploiting facilities already available in them. At the core, our technique relies on matching short substrings of length , called -grams, and taking into account both positions of individual matches and the total number of such matches. Our approach applies to both approximate full string matching and approximate substring matching, with a variety of possible edit distance functions. The approximate string match predicate, with a suitable edit distance threshold, can be mapped into a vanilla relational expression and optimized by conventional relational optimizers. We demonstrate experimentally the benefits of our technique over the direct use of UDFs, using commercial database systems and real data. To study the I/O and CPU behavior of approximate string join algorithms with variations in edit distance and -gram length, we also describe detailed experiments based on a prototype implementation.",2001-09-11,https://www.semanticscholar.org/paper/5737a1f6fd8d928b88726ada916d7874afdfe0d7,Very Large Data Bases Conference
1087,Projected Sensitivity of the SuperCDMS SNOLAB experiment,"SuperCDMS SNOLAB will be a next-generation experiment aimed at directly detecting low-mass particles (with masses ≤ 10 GeV/c^2) that may constitute dark matter by using cryogenic detectors of two types (HV and iZIP) and two target materials (germanium and silicon). The experiment is being designed with an initial sensitivity to nuclear recoil cross sections ∼ 1×10^(−43) cm^2 for a dark matter particle mass of 1 GeV/c^2, and with capacity to continue exploration to both smaller masses and better sensitivities. The phonon sensitivity of the HV detectors will be sufficient to detect nuclear recoils from sub-GeV dark matter. A detailed calibration of the detector response to low-energy recoils will be needed to optimize running conditions of the HV detectors and to interpret their data for dark matter searches. Low-activity shielding, and the depth of SNOLAB, will reduce most backgrounds, but cosmogenically produced ^3H and naturally occurring ^(32)Si will be present in the detectors at some level. Even if these backgrounds are 10 times higher than expected, the science reach of the HV detectors would be over 3 orders of magnitude beyond current results for a dark matter mass of 1 GeV/c^2. The iZIP detectors are relatively insensitive to variations in detector response and backgrounds, and will provide better sensitivity for dark matter particles with masses ≳ 5 GeV/c^2. The mix of detector types (HV and iZIP), and targets (germanium and silicon), planned for the experiment, as well as flexibility in how the detectors are operated, will allow us to maximize the low-mass reach, and understand the backgrounds that the experiment will encounter. Upgrades to the experiment, perhaps with a variety of ultra-low-background cryogenic detectors, will extend dark matter sensitivity down to the “neutrino floor,” where coherent scatters of solar neutrinos become a limiting background.",2016-09-30,https://www.semanticscholar.org/paper/3403215d8b76208fab144051e76beb33979a124b,
1801,Focused Topic Models,"We present the focused topic model (FTM), a family of nonparametric Bayesian models for learning sparse topic mixture patterns. The FTM integrates desirable features from both the hierarchical Dirichlet process (HDP) and the Indian buffet process (IBP) – allowing an unbounded number of topics for the entire corpus, while each document maintains a sparse distribution over these topics. We observe that the HDP assumes correlation between the global and within-documant prevalences of a topic, and note that such a relationship may be undesirable. By using an IBP to select which topics contribute to a document, and an unnormalized Dirichlet Process to determine how much of the document is generated by that topic, the FTM decouples these probabilities, allowing for more flexible modeling. Experimental results on three text corpora demonstrate superior performance over the hierarchical Dirichlet process topic model.",,https://www.semanticscholar.org/paper/49d942620f925305b583cf4153f1aec88639fbe0,
964,Short foveo-disc distance in situs inversus of optic disc,,2020-10-20,https://www.semanticscholar.org/paper/365f1430ee08c48ef7dd65b634e6c8b8de72bf56,Scientific Reports
507,On path lengths modulo three,"We show that between any two nodes of a cubic, planar, three-connected graph there are three paths whose lengths are 0, 1, and 2 modulo 3, respectively. The proof is by a rather extensive case analysis. Counterexamples show that all three hypotheses (i.e., planarity, degree-three, and three-connectivity) are necessary.",1991-07-01,https://www.semanticscholar.org/paper/e225f9f2c43fe25773454faac16b68f361c94383,Journal of Graph Theory
1663,Exponential Family Embeddings,"Word embeddings are a powerful approach for capturing semantic similarity among terms in a vocabulary. In this paper, we develop exponential family embeddings, a class of methods that extends the idea of word embeddings to other types of high-dimensional data. As examples, we studied neural data with real-valued observations, count data from a market basket analysis, and ratings data from a movie recommendation system. The main idea is to model each observation conditioned on a set of other observations. This set is called the context, and the way the context is defined is a modeling choice that depends on the problem. In language the context is the surrounding words; in neuroscience the context is close-by neurons; in market basket data the context is other items in the shopping cart. Each type of embedding model defines the context, the exponential family of conditional distributions, and how the latent embedding vectors are shared across data. We infer the embeddings with a scalable algorithm based on stochastic gradient descent. On all three applications—neural activity of zebrafish, users' shopping behavior, and movie ratings—we found exponential family embedding models to be more effective than other types of dimension reduction. They better reconstruct held-out data and find interesting qualitative structure.",2016-08-02,https://www.semanticscholar.org/paper/cec8412a03aa42778ef0f4daf61c5c8c81ac9cb1,Neural Information Processing Systems
884,"Pfaffian Orientations, 0/1 Permanents, and Even Cycles in Directed Graphs",,1988-07-11,https://www.semanticscholar.org/paper/7429f8b8bae646762acfa64257162035998ffcf5,"International Colloquium on Automata, Languages and Programming"
2480,Evaluating subtle cueing in head-worn displays,"Goal-oriented visual search in Augmented Reality (AR) can be facilitated by using visual cues to call attention to the target. However, traditional use of explicit cues may degrade visual search performance. In contrast, Subtle Cueing has been previously proposed as an alternative to explicit cueing, but little is known about how well it performs in head-tracked head worn displays (HWDs).
 Using visual search research methods in simulated augmented reality environments, our user study found that Subtle Cueing improves visual search performance in HWDs, and revealed a phenomenon whereby subjects were not able to see the target, even though subjects were primed and the target was well within view.",2014-04-26,https://www.semanticscholar.org/paper/9fdceb03ad6a9579a20b207fde866566311a9792,Chinese CHI '14
3475,Scheduling Multi-task Agents,,2001-12-02,https://www.semanticscholar.org/paper/25d78fba4f9f4b5543f3ff1298ed10e4a0baf9af,Mobile Agents
777,"Testing, optimization, and games",,2004-07-12,https://www.semanticscholar.org/paper/9ebc48c4e82d1a3576cc8ee64e6f6333440e7519,"Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004."
1919,An empirical study of bio manufacturing for the scheduling of hepatitis in vitro diagnostic device with constrained process time window,,2017-12-01,https://www.semanticscholar.org/paper/4287c819ec539cf27a3dcfab6d1c3b1565055d32,Computers & industrial engineering
158,Algorithmic Game Theory and the Internet (Dagstuhl Seminar 03291),,,https://www.semanticscholar.org/paper/67ecddee4ab4f2df18bf02c431c76347eac192b2,
3573,Final Report for DE-FG 02-04 ER 25623 Operating / Runtime Systems for Extreme Scale Scientific Computation Program Notice 04-13 August 2009 SmartApps : Middleware for Adaptive Applications on Reconfigurable Platforms,,,https://www.semanticscholar.org/paper/6a48bee8b7d43c240626b332371d8021bd451448,
1927,Big data analytic for multivariate fault detection and classification in semiconductor manufacturing,"Nowadays, there are more attentions on cost control and yield enhancement in the semiconductor industry. Many manufacturers have the ability to collect the physical data called Status Variables Identification (SVID) by sensors embedded in the advanced machines during the manufacturing process. To maintain the competitive advantages, process monitoring and quick response to yield problem are pivotal in detecting the cause of the faults with the help of the sensor data. To state the physical nature of certain SVID, we usually transform SVID into Fault Detection and Classification parameters (FDC parameters) using statistical indicators. The data containing FDC parameters is called FDC data. This study aims to develop a multivariate analysis model to find out the crucial factors which may lead to process excursion among a large amount of FDC data. We proposed a 2-phase multivariate analysis framework: (1) the Least Absolute Shrinkage and Selection Operator (LASSO) is applied for key operation screening. (2) And Random Forest (RF) is used to rank the FDC parameters based on the key operations. Based on the results, domain engineers can quickly take actions responding to low yield problems.",2017-08-01,https://www.semanticscholar.org/paper/fd43561839625a9fda3e77201547a05adf6e5188,CASE
2743,Automated generation of intent-based 3D Illustrations,"This paper describes an automated intent-based approach to illustration. An illustrution is a picture that is designed to fulfill a communicative intent such as showing the location of an object or showing how an object is manipulated. An illustration is generated by implementing a set of stylistic decisions, ranging from determining the way in which an individual object is lit, to deciding the general composition of the illustration. The design of an illustration is treated as a goal-driven process within a system of constraints. The goal is to achieve communicative intent; the constraints are the illustrative techniques an illustrator can apply.We have developed IBIS (Intent-Based Illustration System), a system that puts these ideas into practice. IBIS designs illustrations using a generate-and-test approach, relying upon a rule-based system of methods and evaluators. Methods are rules that specify how to accomplish visual effects, while evaluators are rules that specify how to determine how well a visual effect is accomplished in an illustration. Examples of illustrations designed by IBIS are included.",1991-07-01,https://www.semanticscholar.org/paper/f29476094033d28e15891c7bfa0ba5e05e12d540,International Conference on Computer Graphics and Interactive Techniques
2199,Mucocutaneous manifestations in juvenile-onset systemic lupus erythematosus: a review of literature,,2015-01-05,https://www.semanticscholar.org/paper/958ec48f86a4515de982a824a33b6ebb7beb307d,Pediatric Rheumatology Online Journal
1004,Low Limit for Effective Signal Strength in the Stratus OCT in Imperative Low Signal Strength Cases,"Purpose To determine the lowest limit of signal strength that is still effective for accurate analysis of optic coherence tomography (OCT) values, we investigated the reproducibility of OCT scans by signal strength (SS). Methods A total of 668 subjects were scanned for measurements of retinal nerve fiber layer (RNFL) thickness using the Stratus OCT twice on the same day. The variability of overall RNFL thickness parameters obtained at different SS was analyzed and compared by repeated-measures of ANOVA and Spearman's correlation coefficient. Values of the intraclass correlation coefficient (ICC) and variability (standard deviation) of RNFL thickness were obtained. The false positive ratio was analyzed. Results When SS was 3, the variability of RNFL thickness was significantly different (low ICC, high variability) in comparison to when SS was 4 or greater. Significant negative correlations were observed between variability in RNFL thickness and signal strength. The difference of variability of average RNFL thickness between SS 4 (4.94 µm) and SS 6 (4.41 µm) was 0.53 µm. Conclusions Clinically, the difference of variability of average RNFL thickness between SS 4 and SS 6 was quite small. High SS is important, however, when signal strength is low due to uncorrectable factors in patients in need of OCT for glaucoma and retinal disease. Our results suggest that SS 4 is the lowest acceptable limit of signal strength for obtaining reproducible scanning images.",2012-05-22,https://www.semanticscholar.org/paper/4e85363a86af1d5b41804faa2ed4693790c68d3b,Korean Journal of Ophthalmology
226,On Simplex Pivoting Rules and Complexity Theory,,2014-04-12,https://www.semanticscholar.org/paper/34d71cd53c7c615454b6cf46ac3d5eb58b330453,Conference on Integer Programming and Combinatorial Optimization
318,The Connectivity of Boolean Satisfiability: Computational and Structural Dichotomies,"Given a Boolean formula, do its solutions form a connected subgraph of the hypercube? This and other related connectivity considerations underlie recent work on random Boolean satisfiability. We study connectivity properties of the space of solutions of Boolean formulas, and establish computational and structural dichotomies. Specifically, we first establish a dichotomy theorem for the complexity of the st-connectivity problem for Boolean formulas in Schaefer's framework. Our result asserts that the tractable side is more generous than the tractable side in Schaefer's dichotomy theorem for satisfiability, while the intractable side is PSPACE-complete. For the connectivity problem, we establish a dichotomy along the same boundary between membership in coNP and PSPACE-completeness. Furthermore, we establish a structural dichotomy theorem for the diameter of the connected components of the solution space: for the PSPACE-complete cases, the diameter can be exponential, but in all other cases it is linear. Thus, small diameter and tractability of the st-connectivity problem are remarkably aligned.",2006-07-10,https://www.semanticscholar.org/paper/57530a32d50c3b890507f7017ffbc1668aaf8478,SIAM journal on computing (Print)
2816,The roles of Galectin-3 in autoimmunity and tumor progression,,2012-03-15,https://www.semanticscholar.org/paper/ff94ac157ce9be6d382c1142d0a7d025baf85266,Immunologic research
1672,Continuous-Time Limit of Stochastic Gradient Descent Revisited,"Stochastic Gradient Descent (SGD) is an important algorithm in machine learning. With constant learning rates, it is a stochastic process that reaches a stationary distribution. We revisit an analysis of SGD in terms of stochastic differential equations in the limit of small constant gradient steps. This limit, which we feel is not appreciated in the machine learning community, allows us to approximate SGD in terms of a multivariate Ornstein-Uhlenbeck process, and hence to compute stationary distributions in closed form. This formalism has interesting new implications for machine learning. We consider the case where the objective has the interpretation of a log-posterior. Traditional theory suggests choosing the learning rate such that the stationary distribution approximates a point mass at the optimum, but this can lead to wasted effort and overfitting. When the goal is instead to approximate the posterior as well as possible, we can derive criteria for optimal minibatch sizes, learning rates, and preconditioning matrices.",,https://www.semanticscholar.org/paper/344882b08c412076b22ba9e98885e8dd397ec38f,
3442,Non-Preemptive Min-Sum Scheduling with Resource Augmentation,"We give the first O(l)-speed O(l) approximation polynomial-time algorithms for several nonpreemptive min-sum scheduling problems where jobs arrive over time and must be processed on one machine. More precisely, we give the first O(l)-speed O(l)-approximations for the non-preemptive scheduling problems; l|r<sub>j</sub>| Sigmaw<sub>j</sub>F<sub>j</sub> (weighted flow time), l |r<sub>j</sub>| SigmaT<sub>j</sub> (total tardiness), the broadcast version of 1 |r<sub>j</sub>| Sigmaw<sub>j</sub>F<sub>j</sub> , an O(I)-speed, 1-approximation for l |r<sub>j</sub>| Sigma U macr<sub>j</sub> (throughput maximization), and an O(l)-machine, O(l)-speed O(1)-approximation for l |r<sub>j</sub>| Sigmaw<sub>j</sub>T<sub>j</sub> (weighted tardiness). Our main contribution is an integer programming formulation whose relaxation is sufficiently close to the integer optimum, and which can be transformed to a schedule on a faster machine.",2007-10-21,https://www.semanticscholar.org/paper/85e70fb59afa4e9ba693ab0f83959a8419264c5d,IEEE Annual Symposium on Foundations of Computer Science
1375,Search for Wbb and WH production in pp collisions at square root [s]=1.96 TeV.,"We present a search for Wbb production in pp collisions at sqrt[s]=1.96 TeV in events containing one electron, an imbalance in transverse momentum, and two b-tagged jets. Using 174 pb(-1) of integrated luminosity accumulated by the D0 experiment at the Fermilab Tevatron collider, and the standard-model description of such events, we set a 95% C.L. upper limit on Wbb production of 6.6 pb for b quarks with transverse momenta p(b)(T)>20 GeV and bb separation in pseudorapidity-azimuth space DeltaR(bb)>0.75. Restricting the search to optimized bb mass intervals provides upper limits on WH production of 9.0-12.2 pb for Higgs-boson masses of 105-135 GeV.",2004-10-21,https://www.semanticscholar.org/paper/af9848c6cd86bef3a460e96c74ee810734605736,Physical Review Letters
907,Cutting and Partitioning a Graph aifter a Fixed Pattern (Extended Abstract),,1983-07-18,https://www.semanticscholar.org/paper/a5010453d836642967c95cbb1e710f5c95fd651d,"International Colloquium on Automata, Languages and Programming"
3363,SEXUAL SELECTION IN TOADS: THE ROLES OF FEMALE CHOICE AND MALE BODY SIZE,"Darwin (1871, p. 568) wrote ""sexual selection depends on the advantage which certain individuals have over others of the same sex and species solely in respect to reproduction."" This selection may act in several ways. Two extremes are either the individuals of one sex, usually males (but see Trivers, 1972), compete amongst themselves, with the winners acquiring the most mates; or the members of one sex, usually females, discriminate among members of the other sex choosing to mate with the most ""attractive"" individuals. The first extreme of sexual selection, competition among males, has been documented by field studies on baboons (De Vore, 1965), dungflies (Parker, 1970), elephant seals (Le Boeuff, 1974), lizards (Trivers, 1972, 1976), prairie chickens (Robel, 1966), and sage grouse (Scott, 1942). For example, Le Boeuff (1974) found that less than one third of the males in a breeding aggregation accounted for all of the matings and that copulation frequency was correlated with social rank. Competition among males may be incited in turn by the behavior of females (Cox and Le Boeuff, 1977). The second extreme of sexual selection, female choice among alternate mates, has not been studied as vigorously, and some biologists (Huxley, 1938; Lack, 1968) have doubted its importance to evolution. However, Trivers (1972) has theoretically shown the adaptive advantage that a female can gain by choosing the best of alternative mates and O'Donald (1972, 1973) with computer simulations has dem-",1978-06-01,https://www.semanticscholar.org/paper/3a84a580356b48a465465518b2decfdcb53f579c,Evolution; international journal of organic evolution
1884,Digital transformation to empower smart production for Industry 3.5 and an empirical study for textile dyeing,,2020-04-01,https://www.semanticscholar.org/paper/6105a49a9fe97438f6a86f977993c0a10ec090db,Computers & industrial engineering
1072,First Dark Matter Constraints from a SuperCDMS Single-Charge Sensitive Detector.,"We present the first limits on inelastic electron-scattering dark matter and dark photon absorption using a prototype SuperCDMS detector having a charge resolution of 0.1 electron-hole pairs (CDMS HVeV, a 0.93 g CDMS high-voltage device). These electron-recoil limits significantly improve experimental constraints on dark matter particles with masses as low as 1  MeV/c^{2}. We demonstrate a sensitivity to dark photons competitive with other leading approaches but using substantially less exposure (0.49 g d). These results demonstrate the scientific potential of phonon-mediated semiconductor detectors that are sensitive to single electronic excitations.",2018-04-27,https://www.semanticscholar.org/paper/7cf7ab28d8c0c2256f2cf7b617e99d69e5443549,Physical Review Letters
3474,Simultaneously optimizing two scheduling objectives,"Scheduling algorithms are designed to optimize many optimality criteria in a wide variety of scheduling models. To do so is well-motivated and justified, as an algorithm that works well for one scheduling problem/objective may perform poorly on a different scheduling problem/objective. In this abstract, we give very general results about the existence of schedules which simultaneously minimize two criteria. Our results are general in that they apply to almost any scheduling environment, and that they apply to all pairs of metrics in which the first metric is one of maximum flow time, makespan, or maximum lateness and the second metric is one of average flow time, average completion time, average lateness, number of on-time jobs. We will show that for almost all such pairs of metrics there exist schedules which are simultaneously close to optimal for both metrics.",2001-04-23,https://www.semanticscholar.org/paper/13f92c2b45ec0b30451a2f482d169d389037b81d,"Proceedings, International Parallel and Distributed Processing Symposium (IPDPS)"
3481,Clustering Data without Prior Knowledge,,2000-09-05,https://www.semanticscholar.org/paper/c47a285efa5ff60f5957e029412f3d9ba2db57a4,Workshop on Algorithm Engineering
2330,Cytokine expression by inflammatory neutrophils.,"Bloodstream neutrophils do not express mRNA for interleukin-1 beta (IL-1 beta), but transcripts for this cytokine are rapidly induced following exposure to recombinant granulocyte-macrophage colony-stimulating factor (rGM-CSF) in vitro. Levels of IL-1 beta mRNA reach maximal values 1 h after exposure to rGM-CSF and then decline to near basal levels by 4 h. Similarly, rGM-CSF treatment of blood neutrophils in vitro induced increases in levels of mRNA for IL-6 and tumour necrosis factor-alpha (TNF-alpha). RNA extracted from neutrophils isolated from the synovial fluid of patients with rheumatoid arthritis expressed low, but significant levels of IL-1 beta mRNA that were between 0.5 and 3% of the levels that could be maximally induced by rGM-CSF treatment of blood neutrophils. However, transcripts for TNF-alpha and IL-6 were not detected in these synovial fluid neutrophils. mRNA for transforming growth factor-beta (TGF-beta) was constitutively expressed in blood and synovial fluid neutrophils and transcripts for this cytokine were not altered by rGM-CSF exposure. Because of the transient nature of IL-1 beta expression by activated neutrophils, we propose that the low levels of expression of mRNA for this cytokine in the synovial fluid neutrophils represents expression by a small, perhaps newly-recruited and activated, sub-population of cells. IL-1 beta expression by this sub-population may thus contribute to the pathogenesis of rheumatoid disease.",1994-03-01,https://www.semanticscholar.org/paper/a784bda910605f9818bc6788b821ed7118d19d67,FEMS Immunology & Medical Microbiology
637,The NP-Completeness of the bandwidth minimization problem,,1976-09-01,https://www.semanticscholar.org/paper/913fea849518f26443477fbedb2a00146f78a159,Computing
1701,Hierarchical topographic factor analysis,"Recent work has revealed that cognitive processes are often reflected in patterns of functional connectivity throughout the brain (for review see [16]). However, examining functional connectivity patterns using traditional methods carries a substantial computational burden (of computing time and memory). Here we present a technique, termed Hierarchical topographic factor analysis, for efficiently discovering brain networks in large multi-subject neuroimaging datasets.",2014-06-04,https://www.semanticscholar.org/paper/78db7ecd2c2b56db9f2e8a27a36cc7178bdbe34e,International Workshop on Pattern Recognition in NeuroImaging
510,On graph-theoretic lemmata and complexity classes,"Several new complexity classes of search problems that lie between the classes FP and FNP are defined. These classes are contained in the class TFNP of search problems that always have a solution. A problem in each of these new classes is defined in terms of an implicitly given, exponentially large graph, very much like PLS (polynomial local search). The existence of the solution sought is established by means of a simple graph-theoretic lemma with an inefficiently constructive proof. Several class containments and collapses, resulting in the two new classes PDLF contained in PLF are shown; the relation of either class of PLS is open. PLF contains several important problems for which no polynomial-time algorithm is presently known.<<ETX>>",1990-10-22,https://www.semanticscholar.org/paper/14a35370622c069bc62f6f3d1a9ab72562e4b950,Proceedings [1990] 31st Annual Symposium on Foundations of Computer Science
2167,Isolation of Microvesicles from Human Circulating Neutrophils.,"Neutrophil-derived microvesicles (NDMVs) are liberated by neutrophils upon cell activation by molecules. Once activated, neutrophils are primarily involved in acute inflammation; however, the microvesicles they produce are largely anti-inflammatory. NDMVs have been shown to protect cartilage during inflammatory arthritis. They exert these effects by inhibiting or affecting the function of target cells, including macrophages. NDMVs have the potential to act as disease-modifying agents, especially for inflammatory diseases. This protocol describes a method using differential centrifugation to separate neutrophils from whole human blood. Subsequently, neutrophils are identified by cytospin and Wright's staining, and then the NDMVs are isolated using differential centrifugation.",2021-10-05,https://www.semanticscholar.org/paper/a9919a713fabfb2b2bce09d76cb30d10eacbb258,Bio-protocol
168,Game dynamics as the meaning of a game,"Learning dynamics have traditionally taken a secondary role to Nash equilibria in game theory. We propose a new approach that places the understanding of game dynamics over mixed strategy profiles as the central object of inquiry. We focus on the stable recurrent points of the dynamics, i.e. states which are likely to be revisited infinitely often; obviously, pure Nash equilibria are a special case of such behavior. We propose a new solution concept, the Markov-Conley Chain (MCC), which has several favorable properties: It is a simple randomized generalization of the pure Nash equilibrium, just like the mixed Nash equilibrium; every game has at least one MCC; an MCC is invariant under additive constants and positive multipliers of the players' utilities; there is a polynomial number of MCCs in any game, and they can be all computed in polynomial time; the MCCs can be shown to be, in a well defined sense, surrogates or traces of an important but elusive topological object called the sink chain component of the dynamics; finally, it can be shown that a natural game dynamics surely ends up at one of the MCCs of the game.",2019-05-07,https://www.semanticscholar.org/paper/2151cc3fcf890ee6b04dd529f0d5a6bcb1237294,SeCO Workshops
2535,Interaction and presentation techniques for shake menus in tangible augmented reality,"Menus play an important role in both information presentation and system control. We explore the design space of shake menus, which are intended for use in tangible augmented reality. Shake menus are radial menus displayed centered on a physical object and activated by shaking that object. One important aspect of their design space is the coordinate system used to present menu options. We conducted a within-subjects user study to compare the speed and efficacy of several alternative methods for presenting shake menus in augmented reality (world-referenced, display-referenced, and object-referenced), along with a baseline technique (a linear menu on a clipboard). Our findings suggest tradeoffs amongst speed, efficacy, and flexibility of interaction, and point towards the possible advantages of hybrid approaches that compose together transformations in different coordinate systems. We close by describing qualitative feedback from use and present several illustrative applications of the technique.",2009-10-19,https://www.semanticscholar.org/paper/82ee6442f78cdeeb15410df4ed1ebfe7da8379c8,2009 8th IEEE International Symposium on Mixed and Augmented Reality
591,Hamilton Paths in Grid Graphs,"A grid graph is a node-induced finite subgraph of the infinite grid. It is rectangular if its set of nodes is the product of two intervals. Given a rectangular grid graph and two of its nodes, we give necessary and sufficient conditions for the graph to have a Hamilton path between these two nodes. In contrast, the Hamilton path (and circuit) problem for general grid graphs is shown to be NP-complete. This provides a new, relatively simple, proof of the result that the Euclidean traveling salesman problem is NP-complete.",1982-11-01,https://www.semanticscholar.org/paper/4d2abfc483c9ffa4187d43269a53ec37e64e1c5d,SIAM journal on computing (Print)
3144,The Performance of Remote Display Mechanisms for Thin-Client Computing,"The growing popularity of thin-client systems makes it important to determine the factors that govern the performance of these thin-client architectures. To assess the viability of the thin-client computing model, we measured the performance of six popular thin-client platforms—Citrix MetaFrame, Microsoft Terminal Services, Sun Ray, Tarantella, VNC, and X—running over a wide range of network access bandwidths. We find that thinclient systems can perform well on web and multimedia applications in LAN environments, but the efficiency of the thin-client protocols varies widely. We analyze the differences in the various approaches and explain the impact of the underlying remote display protocols on overall performance. Our results quantify the impact of different approaches in display encoding primitives, display update policies, and display caching and compression techniques across a broad range of thin-client systems.",2002-06-10,https://www.semanticscholar.org/paper/e60a892427b03bfbcbbcfb058ef310708006276c,"USENIX Annual Technical Conference, General Track"
1490,Development of the cerenkov ring imaging detector for the SLD,"Results of recent beam tests of a physics prototype cerenkov Ring Imaging Detector (CRID) for the SLD are reported. The system includes both liquid (C6F14) and gas (isobutane) radiators and an 80 cm quartz TPC with a gaseous TMAE photocathode and proportional wire readout. Measurements of the quality factor (N0) and cerenkov angles of both radiators at various TMAE concentrations and beam momenta are presented. Other system characteristics, including electron lifetimes, spatial resolution, ""photon feedback"" and preliminary results from third coordinate charge division readout are discussed.",1986-02-01,https://www.semanticscholar.org/paper/dc0e3fa947631ca98cff8c211d52162930c090a7,IEEE Transactions on Nuclear Science
2407,Continuous-flow Cell Cycle Fractionation of Eukaryotic Micro-organisms,"Previous methods of cell cycle fractionation have been based on sedimentation of organisms through density gradients in tubes or zonal centrifuge rotors (Warmsley & Pasternak, 1970). Both rate-sedimentation and equilibrium density methods have been used, for example for Saccharomyces cerevisiae and for Schizosaccharomyces pombe (Sebastian, Carter & Halvorson, 1971; Poole & Lloyd, 1973; Poole, Lloyd & Chance, 1974; Edwards & Lloyd, 1977). However, these methods suffer from a major drawback. Organisms must be harvested from their growth media, resuspended, loaded on to the gradient, then separated and recovered. Such procedures may take up to I h during which time the organisms are exposed to conditions of nutrient and oxygen deprivation, suboptimal growth temperatures and, in some cases, unfavourable osmotic environments. Continuous-flow cell cycle fractionation in a Sharples Supercentrifuge is completed in less than 15 min (for a 10 1 culture), and thus obviates the unfavourable conditions inherent in gradient methods ; size selection is just as efficient.",1977-03-01,https://www.semanticscholar.org/paper/650ec1f02b595bb0209f40fdb214d884ff53a4f5,
3669,Adding classes to the C language: An exercise in language evolution,"The C language is a fine tool for writing compact and efficient programs. It is relatively easy to produce good compilers for, and the number of tools available for supporting program‐ ming in C is large, especially in its ‘home environment’, the UNM system. However, C'S facilities for structuring programs were, until recently, rather limited. To remedy this situation, a data abstraction facility, called classes, was added. The class concept described here has benefitted from the experience gained through a year's use. It is now in use at close to a hundred installations.",1983-02-01,https://www.semanticscholar.org/paper/97a4c9ff0f1c01e1d17141af984773ef9522f1ff,"Software, Practice & Experience"
2474,ParaFrustum: visualization techniques for guiding a user to a constrained set of viewing positions and orientations,"Many tasks in real or virtual environments require users to view a target object or location from one of a set of strategic viewpoints to see it in context, avoid occlusions, or view it at an appropriate angle or distance. We introduce ParaFrustum, a geometric construct that represents this set of strategic viewpoints and viewing directions. ParaFrustum is inspired by the look-from and look-at points of a computer graphics camera specification, which precisely delineate a location for the camera and a direction in which it looks. We generalize this approach by defining a ParaFrustum in terms of a look-from volume and a look-at volume, which establish constraints on a range of acceptable locations for the user's eyes and a range of acceptable angles in which the user's head can be oriented. Providing tolerance in the allowable viewing positions and directions avoids burdening the user with the need to assume a tightly constrained 6DoF pose when it is not required by the task. We describe two visualization techniques for virtual or augmented reality that guide a user to assume one of the poses defined by a ParaFrustum, and present the results of a user study measuring the performance of these techniques. The study shows that the constraints of a tightly constrained ParaFrustum (e.g., approximating a conventional camera frustum) require significantly more time to satisfy than those of a loosely constrained one. The study also reveals interesting differences in participant trajectories in response to the two techniques.",2014-10-05,https://www.semanticscholar.org/paper/5bc9cd5b54d9781f3f388673a7102e579b5a176c,ACM Symposium on User Interface Software and Technology
1998,A HYBRID EVOLUTIONARY ALGORITHM FOR FMS OPTIMIZATION WITH AGV DISPATCHING,"Scheduling is one of the most significant fields in manufacturing system. In this paper, we also consider how to handle materials during searching the optimal solutions of scheduling problem, because its impact in practical flexible manufacturing system (FMS) cannot be ignored. So we used the state-of-art automated guided vehicle (AGV) as a material-handling system in the FMS. We focus on the combination of an operation scheduling, which means to obtain the optimization of manufacturing scheduling, and the routing of AGVs, which is to transport materials of different operations between different machines in FMS. We use network structure to model FMS with AGV system as a material handling system. System constraints and decision variables about FMS especially related to AGVs dispatching can be presented on the network. That is to say that network modeling describes both operation scheduling information and AGV routing path information on a directed network model. We propose a random key-based particle swarm optimization (PSO) algorithm with crossover and mutation operation to avoid premature convergence and to maintain diversity of the swarm. Numerical analyses for case study show the effectiveness of proposed approach comparing with Genetic Algorithm (GA).",2012-06-26,https://www.semanticscholar.org/paper/50440746897861bf850989d0ed9f12a47236fdd6,
1187,Measurement of Dijet Angular Distributions at ffiffi s p 1⁄4 1 : 96 TeV and Searches for Quark Compositeness and Extra Spatial Dimensions,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, M. Ahsan, G.D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G. A. Alves, L. S. Ancu, T. Andeen, M. S. Anzelc, M. Aoki, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, O. Atramentov, C. Avila, J. BackusMayes, F. Badaud, L. Bagby, B. Baldin, D.V. Bandurin, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V.A. Bezzubov, P. C. Bhat, V. Bhatnagar, G. Blazey, S. Blessing, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, E. E. Boos, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, X. B. Bu, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, T. H. Burnett, C. P. Buszello, P. Calfayan, B. Calpas, S. Calvet, J. Cammin, M.A. Carrasco-Lizarraga, E. Carrera, W. Carvalho, B. C. K. Casey, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K.M. Chan, A. Chandra, E. Cheu, D. K. Cho, S. Choi, B. Choudhary, T. Christoudias, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, D. Cutts, M. Ćwiok, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, K. DeVaughan, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, T. Dorland, A. Dubey, L. V. Dudko, L. Duflot, D. Duggan, A. Duperrin, S. Dutt, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V. D. Elvira, Y. Enari, S. Eno, M. Escalier, H. Evans, A. Evdokimov, V.N. Evdokimov, G. Facini, A. V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, W. Geng, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, B. Gómez, A. Goussiou, P. D. Grannis, S. Greder, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Harder, A. Harel, J.M. Hauptman, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, A. P. Heinson, U. Heintz, C. Hensel, I. Heredia-De La Cruz, K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, T. Hoang, J. D. Hobbs, B. Hoeneisen, M. Hohlfeld, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, N. Huske, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, D. Jamin, R. Jesik, K. Johns, C. Johnson, M. Johnson, D. Johnston, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, D. Karmanov, P. A. Kasper, I. Katsanos, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y. N. Kharzheev, D. Khatidze, T. J. Kim, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, J.-P. Konrath, A.V. Kozelov, J. Kraus, T. Kuhl, A. Kumar, A. Kupco, T. Kurča, V. A. Kuzmin, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, W.M. Lee, A. Leflat, J. Lellouch, J. Li, L. Li, Q. Z. Li, S.M. Lietti, J. K. Lim, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna-Garcia,34,x A.L. Lyon, A.K.A. Maciel, D. Mackin, P. Mättig, R. Magaña-Villalba, A. Magerkurth, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, Y. Maravin, B. Martin, R. McCarthy, C. L. McGivern, M.M. Meijer, A. Melnitchouk, L. Mendoza, D. Menezes, P. G. Mercadante, M. Merkin, K.W. Merritt, A. Meyer, J. Meyer, J. Mitrevski, N.K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, H.A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, G. Obrant, C. Ochando, D. Onoprienko, J. Orduna, N. Oshima, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, M. Padilla, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park, S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma,34,k V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, A. V. Popov, W. L. Prado da Silva, S. Protopopescu, J. Qian, A. Quadt, B. Quinn, A. Rakitine, M. S. Rangel, K. Ranjan, P. N. Ratoff, P. Renkel, P. Rich, M. Rijssenbeek, I. Ripp-Baudot, F. Rizatdinova, S. Robinson, M. Rominsky, C. Royon, P. Rubinov, R. Ruchti, G. Safronov, G. Sajot, A. Sánchez-Hernández, M. P. Sanders, B. Sanghi, G. Savage, L. Sawyer, T. Scanlon, D. Schaile, R.D. Schamberger, Y. Scheglov, PRL 103, 191803 (2009) P HY S I CA L R EV I EW LE T T E R S week ending 6 NOVEMBER 2009",,https://www.semanticscholar.org/paper/ddbf48ad869dc2eeeb6b842b8d39bb0ffeadc1c0,
3533,Reflection on Attributes,"Current reflection proposals do not propose to reflect on attributes. However we think it is a powerful feature to have as attributes combined with reflection can enable important use cases, as filtering and augmenting entities with additional information. Unfortunately, attributes are only identified by their names, and if they accept parameters, the parameters form a balanced token sequence, which makes it impossible for individual parameters to be extracted from within a program. We introduce the notion of user-defined attributes and a typesafe mechanism to reflect on these attributes and their parameters at compile time.",,https://www.semanticscholar.org/paper/64dac1f22dc8a0d857b812e715e50077ce48cea0,
2904,Multiset correlation and factor analysis enables exploration of multi-omic data,"Multi-omics datasets are becoming more common, necessitating better integration methods to realize their revolutionary potential. Here, we introduce Multi-set Correlation and Factor Analysis, an unsupervised integration method that enables fast inference of shared and private factors in multi-modal data. Applied to 614 ancestry-diverse participant samples across five ‘omics types, MCFA infers a shared space that captures clinically relevant molecular processes.",2022-07-20,https://www.semanticscholar.org/paper/5873787a7ebfd28080a58df29e9921086a910d2b,bioRxiv
2226,Reply to Kahn,,2012-02-15,https://www.semanticscholar.org/paper/ee5db282d5c93806edb673a9194fdcc07c318c50,
728,The Complexity of Optimal Multidimensional Pricing,"We resolve the complexity of revenue-optimal deterministic auctions in the unit-demand single-buyer Bayesian setting, i.e., the optimal item pricing problem, when the buyer's values for the items are independent. We show that the problem of computing a revenue-optimal pricing can be solved in polynomial time for distributions of support size 2 and its decision version is NP-complete for distributions of support size 3. We also show that the problem remains NP-complete for the case of identical distributions.",2013-11-08,https://www.semanticscholar.org/paper/2faada3bca28233d0c9ef1b39edff258bef5a279,ACM-SIAM Symposium on Discrete Algorithms
1440,"Physics of high-energy gamma gamma, e gamma, and e- e- collisions",,,https://www.semanticscholar.org/paper/926623f72f787b2606677c187955e9b563b39c5f,
977,Positional Change of Optic Nerve Head Vasculature during Axial Elongation as Evidence of Lamina Cribrosa Shifting: Boramae Myopia Cohort Study Report 2.,,2018-03-12,https://www.semanticscholar.org/paper/2f1d12a4d30b73cede31891c8de6697386351445,"Ophthalmology (Rochester, Minn.)"
1765,A Tutorial on Bayesian Nonparametric Models,,2011-06-14,https://www.semanticscholar.org/paper/57df462188c1b97bd3898f54161ba85f474116b6,
770,Algorithmic Verification of Recursive Probabilistic State Machines,,2005-04-04,https://www.semanticscholar.org/paper/8ca0e8be0f48826f8eb3ce31a9681d3cf52d4952,International Conference on Tools and Algorithms for Construction and Analysis of Systems
3119,THINC: A Remote Display Architecture for Thin-Client Computing,"Rapid improvements in network bandwidth, cost, and ubiquity combined with the security hazards and high total cost of ownership of personal computers have created a growing market for thin-client computing. We introduce THINC, a remote display system architecture for high-performance thin-client computing in both LAN and WAN environments. THINC transparently maps high-level application display calls to a few simple low-level commands which can be implemented easily and efficiently. THINC introduces a number of novel latency-sensitive optimization techniques, including offscreen drawing awareness, command buffering and scheduling, nonblocking display operation, native video support, and serverside screen scaling. We have implemented THINC in an XFree86/Linux environment and compared its performance with other popular approaches, including Citrix MetaFrame, Microsoft Terminal Services, SunRay, VNC, and X. Our experimental results on web and video applications demonstrate that THINC can be as much as five times faster than traditional thin-client systems in high latency network environments and is capable of playing full-screen video at full frame rate.",,https://www.semanticscholar.org/paper/1ececfd1b84eb9ec52b350a84a959dec164d1372,
2835,Targeted disruption of the galectin-3 gene results in decreased susceptibility to multiple low dose streptozotocin-induced diabetes in mice.,,,https://www.semanticscholar.org/paper/d5217be83393dd66542e94042354a6cc7bdb476d,Clinical Immunology
1477,"Measurement of the photon structure function F/sub 2//sup gamma/(x,Q/sup 2/) between 10 less than or equal to Q/sup 2/ less than or equal to 60 GeV/sup 2/","We present a measurement of the photon structure function F/sub 2//sup ..gamma../ in the reaction ee..-->..eeX for Q/sup 2/ in the range 10 < Q/sup 2/ < 60 GeV/sup 2/, using 285 multihadron events obtained with the TPC/Two-Gamma detector at PEP. The data have been corrected for detector effects using a regularized unfolding procedure. Using our previous low Q/sup 2/ measurements to estimate the hadronic component, we perform a QCD analysis at high Q/sup 2/ within the context of the regularisation scheme of Antoniadis and Grunberg. We obtain rather safe bounds on the value of the QCD scale parameter of 119 +- 34 < ..lambda../sub M-bar S-bar/ < 215 +- 55 MeV.",,https://www.semanticscholar.org/paper/559ec75fd1baa96b5f44666efb44288192709da9,
1487,"Measurement of the photon structure functionF2γ(x, Q2) in the region 0.2",,1987-03-01,https://www.semanticscholar.org/paper/f5c234620769ff884ecdffe19e100eb352516086,
602,A Fast Algorithm for Testing for Safety and Detecting Deadlocks in Locked Transaction Systems,,1981-09-01,https://www.semanticscholar.org/paper/63601adf49f75d97e1b0360cf90ac83d422cf5df,J. Algorithms
2323,Biochemistry and Physiology of the Neutrophil: The cytoskeleton: The molecular framework regulating cell shape and the traffic of intracellular components,,,https://www.semanticscholar.org/paper/67fd5a01b7929f265e6327f2a6745ad20ecd67b9,
633,Some Examples of Difficult Traveling Salesman Problems,"We construct instances of the symmetric traveling salesman problem with n = 8k cities that have the following property: There is exactly one optimal tour with cost n, and there are 2k-1k-1! tours that are next-best, have arbitrarily large cost, and cannot be improved by changing fewer than 3k edges. Thus, there are many local optima with arbitrarily high cost. It appears that local search algorithms are ineffective when applied to these problems. Even more catastrophic examples are available in the non-symmetric case.",1978-06-01,https://www.semanticscholar.org/paper/7487ea033b1729fb7695841673ece0e4782fdb88,Operational Research
1000,Additive diagnostic role of imaging in glaucoma: optical coherence tomography and retinal nerve fiber layer photography.,"PURPOSE
To investigate the additive diagnostic role of spectral-domain optical coherence tomography (SD-OCT) and red-free retinal nerve fiber layer photography (RNFLP) in making clinical glaucoma diagnosis.


METHODS
Four diagnostic combination sets, including the most recent image from each measurement of 196 glaucoma eyes (including the 44 preperimetric glaucoma eyes) and 101 healthy eyes, were prepared: (1) stereo disc photography and Humphrey visual field (SH), (2) SH and SD-OCT (SHO), (3) SH and RNFLP (SHR), and (4) SHR and SD-OCT (SHRO). Each randomly sorted set was serially presented at 1-month intervals to five glaucoma specialists who were asked to evaluate them in a subjective and independent manner. The specialists' glaucoma-diagnostic performances based on the sets were then compared.


RESULTS
For each specialist, adding SD-OCT to SH or SHR increased the glaucoma-diagnostic sensitivity but not to a level of statistical significance. For one specialist, adding RNFLP to SH significantly increased the sensitivity. Each specialist showed a high level of specificity regardless of the diagnostic set. The overall sensitivity of all specialists' assessments was significantly increased by adding RNFLP or the combination of SD-OCT and RNFLP to SH (P < 0.001); however, adding SD-OCT to SH or SHR did not significantly increase the sensitivity. A similar relationship was noted also for the preperimetric glaucoma subgroup.


CONCLUSIONS
In contrast to RNFLP, SD-OCT did not significantly enhance the diagnostic accuracy of detecting glaucoma or even of preperimetric glaucoma. Our results suggest that, at least for glaucoma specialists, the additive diagnostic role of OCT is limited.",2014-12-01,https://www.semanticscholar.org/paper/cae54ce995df4b392c36aceee13aa06842d42392,Investigative Ophthalmology and Visual Science
2994,High temperature mechanical properities and creep crack initiation of DS CM186LC for nozzle guide vane,,1998-09-01,https://www.semanticscholar.org/paper/28de5c6730f3f5ce3e0a5516ea16927d940cbb28,
553,The Complexity of Recognizing Polyhedral Scenes (Extended Abstract),"Given a dr,awi ngof straight lines on the plane, we wish to decide whether it is the projection of the visible part of a set of opaque polyhedra. Although there is an extensive literature and reports on e~iri~11y succesful algorithms for this problem, there has been no definite result concerning its complex; ty. In thi s paper we show that, ratfle~ . surprisingly, this problem is NP-complete. TfllS 1S true even in the relatively simple case of trihedral scenes (no four planes share a point) without shadows or crack.s. Desp . jte this negative result, weoresent a fast algorlthm for the 1mportant spec1a~ case.of·orthohedral scenes (all planes are perpendicular to'one of the three axes) with a fixed number of ""possible"" objects.",,https://www.semanticscholar.org/paper/030d419e03cb2bcb0b37074c70ae59da36f98443,IEEE Annual Symposium on Foundations of Computer Science
917,The complexity of facets (and some facets of complexity),"Many important combinatorial optimization problems, including the traveling salesman problem (TSP), the clique problem and many others, call for the optimization of a linear functional over some discrete set of vectors.",1982-05-05,https://www.semanticscholar.org/paper/d01d8269be394b9fa5f3916dc82deae147a2dff2,Symposium on the Theory of Computing
953,Development of a novel hyaluronic acid membrane for the treatment of ocular surface diseases,,2021-01-27,https://www.semanticscholar.org/paper/7844a97100a5b2f43cf803d1a927c2020a4ff381,Scientific Reports
2818,Absence of galectin-3 does not affect the development of experimental tongue carcinomas in mice.,,2011-04-01,https://www.semanticscholar.org/paper/4b0e1bfdc885514f973dfb7394c7833d95eebece,Experimental and molecular pathology (Print)
1844,Panel Discussion,,,https://www.semanticscholar.org/paper/793a76d1025eed16abf92a22300ec6964227aa9a,SNA@ICML
720,Doubly Balanced Connected Graph Partitioning,"We introduce and study the doubly balanced connected graph partitioning problem: Let G=(V, E) be a connected graph with a weight (supply/demand) function p : V → {−1, +1} satisfying p(V)=∑ j&isin V p(j) = 0. The objective is to partition G into (V1,V2) such that G[V1] and G[V2] are connected, ∣p(V1)∣,∣p(V2)∣≤ cp, and max{ ∣V1 / V2∣,∣V2 / V1∣} ≤ cs, for some constants cp and cs. When G is 2-connected, we show that a solution with cp=1 and cs=2 always exists and can be found in randomized polynomial time. Moreover, when G is 3-connected, we show that there is always a “perfect” solution (a partition with p(V1)=p(V2)=0 and ∣V1∣=∣V2∣, if ∣V∣≡ 0 (mod 4)), and it can be found in randomized polynomial time. Our techniques can be extended, with similar results, to the case in which the weights are arbitrary (not necessarily ±1), and to the case that p(V)≠ 0 and the excess supply/demand should be split evenly. They also apply to the problem of partitioning a graph with two types of nodes into two large connected subgraphs that preserve approximately the proportion of the two types.",2016-07-21,https://www.semanticscholar.org/paper/44987e5805b918f8b6e3791b35be85d4828b93b6,ACM-SIAM Symposium on Discrete Algorithms
1131,Search for Higgs boson production in dilepton and missing energy final states with 5.4 fb-1 of pp- collisions at Sqrt s=1.96 TeV,"A search for the standard model Higgs boson is presented using events with two charged leptons and large missing transverse energy selected from 5 : 4 fb (cid:1) 1 of integrated luminosity in p (cid:1) p collisions at ﬃﬃﬃ s p ¼ 1 : 96 TeV collected with the D0 detector at the Fermilab Tevatron collider. No signiﬁcant excess of events above background predictions is found, and observed (expected) upper limits at 95% conﬁdence level on the rate of Higgs boson production are derived that are a factor of 1.55 (1.36) above the predicted standard model cross section at m H ¼ 165 GeV .",,https://www.semanticscholar.org/paper/7b3b044d0812de197c45a6ef2c7719a1c01a102a,
1536,Identifiable Deep Generative Models via Sparse Decoding,"We develop the sparse VAE for unsupervised representation learning on high-dimensional data. The sparse VAE learns a set of latent factors (representations) which summarize the associations in the observed data features. The underlying model is sparse in that each observed feature (i.e. each dimension of the data) depends on a small subset of the latent factors. As examples, in ratings data each movie is only described by a few genres; in text data each word is only applicable to a few topics; in genomics, each gene is active in only a few biological processes. We prove such sparse deep generative models are identifiable: with infinite data, the true model parameters can be learned. (In contrast, most deep generative models are not identifiable.) We empirically study the sparse VAE with both simulated and real data. We find that it recovers meaningful latent factors and has smaller heldout reconstruction error than related methods.",2021-10-20,https://www.semanticscholar.org/paper/0bf88192d02c08661b9185b2b16399306694c4a4,Trans. Mach. Learn. Res.
230,"Algorithms, complexity, and the sciences","Significance The theory of algorithms and complexity, of which the basic concepts and results are being reviewed here, is an important and consequential domain of mathematical investigation that is unfamiliar to most PNAS readers. Furthermore, in the second half of the article we focus on recent and current research, applying these concepts and results to help elucidate certain central theoretical problems in the social and life sciences, including market equilibria and the theory of evolution. Algorithms, perhaps together with Moore’s law, compose the engine of the information technology revolution, whereas complexity—the antithesis of algorithms—is one of the deepest realms of mathematical investigation. After introducing the basic concepts of algorithms and complexity, and the fundamental complexity classes P (polynomial time) and NP (nondeterministic polynomial time, or search problems), we discuss briefly the P vs. NP problem. We then focus on certain classes between P and NP which capture important phenomena in the social and life sciences, namely the Nash equlibrium and other equilibria in economics and game theory, and certain processes in population genetics and evolution. Finally, an algorithm known as multiplicative weights update (MWU) provides an algorithmic interpretation of the evolution of allele frequencies in a population under sex and weak selection. All three of these equivalences are rife with domain-specific implications: The concept of Nash equilibrium may be less universal—and therefore less compelling—than has been presumed; selection on gene interactions may entail the maintenance of genetic variation for longer periods than selection on single alleles predicts; whereas MWU can be shown to maximize, for each gene, a convex combination of the gene’s cumulative fitness in the population and the entropy of the allele distribution, an insight that may be pertinent to the maintenance of variation in evolution.",2014-10-27,https://www.semanticscholar.org/paper/7081b6498e21d92e0574bddde2ef453e912de7ee,Proceedings of the National Academy of Sciences of the United States of America
3,Cross-Lingual Text Classification with Minimal Resources by Transferring a Sparse Teacher,"Cross-lingual text classification alleviates the need for manually labeled documents in a target language by leveraging labeled documents from other languages. Existing approaches for transferring supervision across languages require expensive cross-lingual resources, such as parallel corpora, while less expensive cross-lingual representation learning approaches train classifiers without target labeled documents. In this work, we propose a cross-lingual teacher-student method, CLTS, that generates “weak” supervision in the target language using minimal cross-lingual resources, in the form of a small number of word translations. Given a limited translation budget, CLTS extracts and transfers only the most important task-specific seed words across languages and initializes a teacher classifier based on the translated seed words. Then, CLTS iteratively trains a more powerful student that also exploits the context of the seed words in unlabeled target documents and outperforms the teacher. CLTS is simple and surprisingly effective in 18 diverse languages: by transferring just 20 seed words, even a bag-of-words logistic regression student outperforms state-of-the-art cross-lingual methods (e.g., based on multilingual BERT). Moreover, CLTS can accommodate any type of student classifier: leveraging a monolingual BERT student leads to further improvements and outperforms even more expensive approaches by up to 12% in accuracy. Finally, CLTS addresses emerging tasks in low-resource languages using just a small number of word translations.",2020-10-06,https://www.semanticscholar.org/paper/2c6161e57952eca8dabf25c1a48de1f40e2c9b5e,Findings
1923,Modeling collinear WATs for parametric yield enhancement in semiconductor manufacturing,"Yield enhancement is one of the major objectives for semiconductor manufacturing. In addition to the usual functional yield that needs to achieve a much higher ratio of good dies in a wafer, parametric yield requires other important factors that can improve the quality and capability of the wafer. Owing to the much more complexity for the processes of wafers in today's semiconductor technology, it is difficult to find the root causes that may affect the parameter yield. Based on the selected important factors that may affect the parametric yield, this study aims to provide an efficient analytic framework for modeling the factors with high correlations. A modified PLS approach (mPLS) is applied in this study for model building that can simultaneously handle collinear problems and provide reasonable explanations with physical meaning.",2017-08-01,https://www.semanticscholar.org/paper/bc5a968d9bec1f69db8d1a579fdb7a242abadce4,CASE
185,Long Term Memory and the Densest K-Subgraph Problem,"In a recent experiment, a cell in the human medial temporal lobe (MTL) encoding one sensory stimulus starts to also respond to a second stimulus following a combined experience associating the two. We develop a theoretical model predicting that an assembly of cells with exceptionally high synaptic intraconnectivity can emerge, in response to a particular sensory experience, to encode and abstract that experience. We also show that two such assemblies are modified to increase their intersection after a sensory event that associates the two corresponding stimuli. The main technical tools employed are random graph theory, and Bernoulli approximations. Assembly creation must overcome a computational challenge akin to the Densest K-Subgraph problem, namely selecting, from a large population of randomly and sparsely interconnected cells, a subset with exceptionally high density of interconnections. We identify three mechanisms that help achieve this feat in our model: (1) a simple two-stage randomized algorithm, and (2) the ""triangle completion bias"" in synaptic connectivity and a ""birthday paradox"", while (3) the strength of these connections is enhanced through Hebbian plasticity.",,https://www.semanticscholar.org/paper/d4d28f5e9907b531d5b3046dceb88b6025424700,Information Technology Convergence and Services
1382,Present status of the Cryogenic Dark Matter Search (CDMS II) experiment,,2003-05-01,https://www.semanticscholar.org/paper/0c9f210ca91513646de10a92fd275510549697af,
2442,Hybrid UIs for Music Exploration in AR and VR,"We present hybrid user interfaces that facilitate interaction with music content in 3D, using a combination of 2D and 3D input and display devices. Participants will explore an online music library, some wearing AR or VR head-worn displays used alone or in conjunction with touch screens, and others using only touch screens. They will select genres, artists, albums, and songs, interacting through a combination of 3D hand-tracking and 2D multi-touch technologies.",2018-10-01,https://www.semanticscholar.org/paper/e069b87075ef3615af616dc74cee28872db21b96,2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)
44,Efficient Keyword Search Across Heterogeneous Relational Databases,"Keyword search is a familiar and potentially effective way to find information of interest that is ""locked"" inside relational databases. Current work has generally assumed that answers for a keyword query reside within a single database. Many practical settings, however, require that we combine tuples from multiple databases to obtain the desired answers. Such databases are often autonomous and heterogeneous in their schemas and data. This paper describes Kite, a solution to the keyword-search problem over heterogeneous relational databases. Kite combines schema matching and structure discovery techniques to find approximate foreign-key joins across heterogeneous databases. Such joins are critical for producing query results that span multiple databases and relations. Kite then exploits the joins - discovered automatically across the databases - to enable fast and effective querying over the distributed data. Our extensive experiments over real-world data sets show that (1) our query processing algorithms are efficient and (2) our approach manages to produce high-quality query results spanning multiple heterogeneous databases, with no need for human reconciliation of the different databases.",2007-04-15,https://www.semanticscholar.org/paper/430d8e89c6466987f637d9a2f3642679de3844ba,IEEE International Conference on Data Engineering
3253,Juvenile social relationships reflect adult patterns of behavior in wild geladas,"Unlike many mammals, primates spend much of their lives as reproductively‐immature juveniles. During the juvenile period, they develop social relationships and physical skills that both facilitate survival to adulthood and impact adult fitness. In this study, we use 2 years of observational data to examine the development of these skills across the juvenile period in a wild cercopithecine primate, the gelada (Theropithecus gelada). As adults, male and female geladas require different skills to be successful; we therefore expected sex differences in social behavior and partner choice during the juvenile period to already reflect these sex‐specific trajectories. For example, males, who disperse at puberty and ultimately must challenge other adult males for access to mates, should invest in high‐energy play‐fighting with other males to develop fighting and rival assessment skills. In contrast, philopatric females, who remain with their close kin throughout their lives, should invest more in forming less‐physical and more‐social bonds with other females within their group. As predicted, sex differences that foreshadowed sex‐specific adult roles were apparent in play rates, the average number of play partners per individual, grooming partner types and social partner preferences. Males played more and had more play partners than same‐age females. Males also groomed more often with individuals from outside their natal group than females, although no sex difference was observed in either grooming rates or number of grooming partners per individual. Females stopped playing earlier than males, and instead invested in grooming relationships with close relatives. Additionally, we found that individual play and grooming rates were temporally consistent for both males and females (i.e., from one year to the next year), suggesting that individuals exhibit stable behavioral phenotypes. We conclude by discussing how early life in geladas may shape adult behavior and reproductive strategies. Am. J. Primatol. 77:1086–1096, 2015. © 2015 Wiley Periodicals, Inc.",2015-10-01,https://www.semanticscholar.org/paper/2c33b007df5430fe0a38a3ec4108ffeea14fcff5,American Journal of Primatology
624,SERIALIZABILITY OF CONCURRENT DATA BASE UPDATES,"A sequence of interleaved user transactions in a data base system may not be serializable, i.e., equivalent to some sequential execution of the individual transactions. Using a simple transaction model we show that recognizing the transaction histories which are serializable is an NP-complete problem. We therefore introduce several efficiently recognizable subclasses of the class of serializable histories; most of these subclasses correspond to serializability principles existing in the literature and used in practice. We also propose two new principles which subsume all previously known ones. We give necessary and sufficient conditions for a class of histories to be the output of an efficient history scheduler, these conditions imply that there can be no efficient scheduler that outputs all of serializable histories studies above have an efficient scheduler. Finally, we show how our results can be extended to far more general transaction models, to transactions with partly interpreted functions, and to distributed data base systems.",1979-03-01,https://www.semanticscholar.org/paper/89a5523c9c6b6ac4efa180a8e7189c9c072744fe,
3483,Better Rounding Algorithms for a Geometric Embedding Relaxation of Minimum Multiway Cut,,,https://www.semanticscholar.org/paper/2b492fc0343e07af3b7cc22fa705f3fc9eeac531,Symposium on the Theory of Computing
638,The complexity of combinatorial optimization problems.,,,https://www.semanticscholar.org/paper/95cbd64642a0013c3e63a97b9868eacaaeff6592,
2276,Control of neutrophil apoptosis in rheumatoid arthritis: Expression of Bax and Mcl-1,,,https://www.semanticscholar.org/paper/1779ab93eec67574ac19fcadce078de425289600,
247,Efficiency-Revenue Trade-Offs in Auctions,,2012-05-14,https://www.semanticscholar.org/paper/dbf88d2b5aea256ca93d697c0ef762d4605c6d89,"International Colloquium on Automata, Languages and Programming"
1889,Pathways and barriers to circularity in food systems,,2019-04-01,https://www.semanticscholar.org/paper/0c4a6610a5f68f2d582cf9367ff5c3ba5c4f8386,"Resources, Conservation and Recycling"
2449,Interactive tools for inpatient medication tracking: a multi-phase study with cardiothoracic surgery patients,"OBJECTIVE
Prior studies of computing applications that support patients' medication knowledge and self-management offer valuable insights into effective application design, but do not address inpatient settings. This study is the first to explore the design and usefulness of patient-facing tools supporting inpatient medication management and tracking.


MATERIALS AND METHODS
We designed myNYP Inpatient, a custom personal health record application, through an iterative, user-centered approach. Medication-tracking tools in myNYP Inpatient include interactive views of home and hospital medication data and features for commenting on these data. In a two-phase pilot study, patients used the tools during cardiothoracic postoperative care at Columbia University Medical Center. In Phase One, we provided 20 patients with the application for 24-48 h and conducted a closing interview after this period. In Phase Two, we conducted semi-structured interviews with 12 patients and 5 clinical pharmacists who evaluated refinements to the tools based on the feedback received during Phase One.


RESULTS
Patients reported that the medication-tracking tools were useful. During Phase One, 14 of the 20 participants used the tools actively, to review medication lists and log comments and questions about their medications. Patients' interview responses and audit logs revealed that they made frequent use of the hospital medications feature and found electronic reporting of questions and comments useful. We also uncovered important considerations for subsequent design of such tools. In Phase Two, the patients and pharmacists participating in the study confirmed the usability and usefulness of the refined tools.


CONCLUSIONS
Inpatient medication-tracking tools, when designed to meet patients' needs, can play an important role in fostering patient participation in their own care and patient-provider communication during a hospital stay.",,https://www.semanticscholar.org/paper/03a7424bf9c971a447120a8edb96040518d76c9d,J. Am. Medical Informatics Assoc.
2475,Patient engagement in the inpatient setting: a systematic review,"OBJECTIVE
To systematically review existing literature regarding patient engagement technologies used in the inpatient setting.


METHODS
PubMed, Association for Computing Machinery (ACM) Digital Library, Institute of Electrical and Electronics Engineers (IEEE) Xplore, and Cochrane databases were searched for studies that discussed patient engagement ('self-efficacy', 'patient empowerment', 'patient activation', or 'patient engagement'), (2) involved health information technology ('technology', 'games', 'electronic health record', 'electronic medical record', or 'personal health record'), and (3) took place in the inpatient setting ('inpatient' or 'hospital'). Only English language studies were reviewed.


RESULTS
17 articles were identified describing the topic of inpatient patient engagement. A few articles identified design requirements for inpatient engagement technology. The remainder described interventions, which we grouped into five categories: entertainment, generic health information delivery, patient-specific information delivery, advanced communication tools, and personalized decision support.


CONCLUSIONS
Examination of the current literature shows there are considerable gaps in knowledge regarding patient engagement in the hospital setting and inconsistent use of terminology regarding patient engagement overall. Research on inpatient engagement technologies has been limited, especially concerning the impact on health outcomes and cost-effectiveness.",2014-07-01,https://www.semanticscholar.org/paper/5dc94597a5bbcfd7773c94aa9d41136b92a75673,J. Am. Medical Informatics Assoc.
2902,Integrative transcriptomic analysis of the amyotrophic lateral sclerosis spinal cord implicates glial activation and suggests new risk genes,,2022-12-08,https://www.semanticscholar.org/paper/4c6a2fd88342a9083a19044f5c9fb7e77ab545e0,Nature Neuroscience
3502,Approximating Disjoint-Path Problems Using Greedy Algorithms and Packing Integer Programs,,1997-10-01,https://www.semanticscholar.org/paper/f5978f6136255ba7d0d91c30c69c54140ac2c776,Conference on Integer Programming and Combinatorial Optimization
86,Learning search engine specific query transformations for question answering,"We introduce a method for learning query transformations that improves the ability to retrieve answers to questions from an information retrieval system. During the training stage the method involves automatically learning phrase features for classifying questions into different types, automatically generating candidate query transformations from a training set of question/answer pairs, and automatically evaluating the candidate transforms on target information retrieval systems such as real-world general purpose search engines. At run time, questions are transformed into a set of queries, and re-ranking is performed on the documents retrieved. We present a prototype search engine, Tritus, that applies the method to web search engines. Blind evaluation on a set of real queries from a web search engine log shows that the method significantly outperforms the underlying web search engines as well as a commercial search engine specializing in question answering.",2001-05-01,https://www.semanticscholar.org/paper/54cbc1e24f5a480c668ef8b1f55ba50e3f350434,The Web Conference
812,On the complexity of protein folding (abstract),". Proceedings of the 29th Annual ACM Sym- posium on the Theory of Computing, 1997, pp.21-29. [13] R Unger, J. Moult. Finding the lowest free energy con- formation of a protein is an NP-hard problem: proof and implications. Bulletin of Mathematical Biology 55 (1993), pp. 1163-119s.",1998-03-01,https://www.semanticscholar.org/paper/ef1ce9addc245bbb0591961586d6f5c300a60c87,Annual International Conference on Research in Computational Molecular Biology
518,The Optimum Execution Order of Queries in Linear Storage,,1990-11-01,https://www.semanticscholar.org/paper/e893038c3d2435b18cc2fd60294fc561abd53aed,Information Processing Letters
2168,Role of antimicrobial peptides in atopic dermatitis,"Host defense peptides (HDPs) or antimicrobial peptides (AMPs) are short cationic amphipathic peptides of divergent sequences, which are part of the innate immune system and produced by various types of cells and tissues. The predominant role of HDPs is to respond to and protect humans against infection and inflammation. Common human HDPs include defensins, cathelicidin, psoriasin, dermcidin, and ribonucleases, but these peptides may be dysregulated in the skin of patients with atopic dermatitis (AD). Current evidence suggests that the antimicrobial properties and immunomodulatory effects of HDPs are involved in AD pathogenesis, making HDPs research a promising area for predicting disease severity and developing novel treatments for AD. In this review, we describe a potential role for human HDPs in the development, exacerbation, and progression of AD and propose their potential therapeutic benefits.",2021-08-25,https://www.semanticscholar.org/paper/d5727a13c5cd7f38b9f5a7573a117c87d88a6d6d,International Journal of Dermatology
1366,Measurement of Dijet Azimuthal Decorrelations at Central Rapidities in p̄p Collisions at √ s = 1 . 96 TeV,"We present a preliminary measurement of azimuthal decorrelations between the two leading jets in multi-jet events acquired with the DØ detector during 2002 and 2003 studying p̄p collisions at a center-of-mass energy √ s = 1.96TeV. Such decorrelations provide a sensitive tool for examining the impact of QCD radiation on jet production. The analysis is based on an inclusive dijet event sample in the central region of rapidity of |yjet| < 0.5. Jets are reconstructed using an iterative cone algorithm with radius Rcone = 0.7. The data sample corresponds to an integrated luminosity of L = 150pb−1. We observe an increased dijet azimuthal decorrelation at smaller transverse jet momenta. Perturbative QCD at lowest order of the strong coupling constant αs, does not provide a good description of the data. However, Monte Carlo event generators using parton showers can be tuned to produce the observed decorrelations.",,https://www.semanticscholar.org/paper/3e7f0c05d4081307567bf04b8a32555b610ca933,
3226,An Animal Detection Pipeline for Identification,"This paper proposes a 5-component detection pipeline for use in a computer vision-based animal recognition system. The end result of our proposed pipeline is a collection of novel annotations of interest (AoI) with species and view-point labels. These AoIs, for example, could be fed as the focused input data into an appearance-based animal identification system. The goal of our method is to increase the reliability and automation of animal censusing studies and to provide better ecological information to conservationists. Our method is able to achieve a localization mAP of 81.67%, a species and viewpoint annotation classification accuracy of 94.28% and 87.11%, respectively, and an AoI accuracy of 72.75% across 6 animal species of interest. We also introduce the Wildlife Image and Localization Dataset (WILD), which contains 5,784 images and 12,007 labeled annotations across 28 classification species and a variety of challenging, real-world detection scenarios.",2018-05-03,https://www.semanticscholar.org/paper/6f3b9616e883b67debf4748473c58161b43cd667,IEEE Workshop/Winter Conference on Applications of Computer Vision
3212,The behavioural challenge of the COVID-19 pandemic: Indirect measurements and personalized attitude changing treatments (IMPACT): The behavioral challenge of COVID-19,,2020-08-01,https://www.semanticscholar.org/paper/febd8a33b905bef50f8550caaf0be4fad6738d16,
604,The Complexity of Searching a Graph (Preliminary Version),"T. Parsons proposed and partially analyzed the following pursuit-evasion problem on graphs: A team of searchers traverse the edges of a graph G in pursuit of a fugitive, who moves along the edges of the graph with complete knowledge of the locations of the pursuers. What is the smallest number s(G) of searchers that will suffice for guaranteeing capture of the fugitive? We show that determining whether s(G) ≤ K, for a given integer K, is NP-hard for general graphs but can be solved in linear time for trees. We also provide a structural characterization of those graphs with s(G) ≤ K for K = 1,2,3.",1981-10-28,https://www.semanticscholar.org/paper/79d7ce3bdaa83d3cf3293ecaac91216edecdf8f4,IEEE Annual Symposium on Foundations of Computer Science
1286,Measurement of the Lambda b lifetime in the exclusive decay Lambda b --> J/psi Lambda.,"We have measured the Lambda b lifetime using the exclusive decay Lambda b --> J/psi Lambda, based on 1.2 fb(-1) of data collected with the D0 detector during 2002-2006. From 171 reconstructed Lambda b decays, where the J/psi and Lambda are identified via the decays J/psi --> mu+ mu- and Lambda --> ppi, we measured the Lambda b lifetime to be tau(Lambda b)=1.218 (+0.130)/(-0.115) (stat) +/- 0.042(syst) ps. We also measured the B0 lifetime in the decay B0 --> J/psi(mu+ mu-)K(0)/(S)(pi+ pi-) to be tau(B0)=1.501 (+0.078)/(-0.074) (stat) +/- 0.050(syst) ps, yielding a lifetime ratio of tau(Lambda b)/tau(B0)=0.811 (+0.096)/(-0.087) (stat) +/- 0.034(syst).",2007-04-01,https://www.semanticscholar.org/paper/a88bb01caff9738506076c1f40a886394ea4a01a,Physical Review Letters
3208,Linking Multiscalar Fisheries Using Metacoupling Models,"Marine fisheries are social-ecological systems important for human health and livelihoods. However, research approaches that consider human–nature interactions within as well as between adjacent and distant fisheries are scarce. As such, we measured and modeled marine fisheries catches at local and regional scales over 65 years (1950–2014), assessed cross-scalar interactions among fishing types (artisanal, subsistence, industrial, recreational), and predicted future catches using the metacoupling framework, a new approach for evaluating human-nature interactions within and across adjacent and distant fisheries (metacouplings). Across taxa examined (mahi-mahi [Coryphaena hippurus], Atlantic bluefin tuna [Thunnus thynnus], cods [Gadidae]), 75% of catches (8.5 million metric tons [MMT]) were made by nations in their own exclusive economic zones (EEZs; Type 1 fishing). However, catches in adjacent EEZs (Type 2 fishing, 1.0 MMT) and distant EEZs and the high seas (Type 3 fishing, 1.9 MMT) increased substantially for all taxa at certain times, becoming consistently important for tuna and cods after 1980. Moreover, Types 1–3 fishing interacted in ways that affect humans differentially across fisheries. For instance, tuna artisanal and subsistence catches (Type 1) decreased with increasing Type 2 and Type 3 industrial fishing, respectively. Cod subsistence catches declined with increasing Type 2/3 industrial fishing and Type 1 artisanal fishing, whereas fishing-type interactions were largely positive for mahi-mahi, causing catches to increase across sectors. Overall, metacouplings affect humans in positive and negative ways that vary across scales and fisheries systems, galvanizing the need for metacoupling-informed fisheries research, policy, and management programs.",2020-07-28,https://www.semanticscholar.org/paper/afddf32a0ea3e3107206dd3d0ae9c1ac43447052,Frontiers in Marine Science
752,Recursive Stochastic Games with Positive Rewards,,2008-07-07,https://www.semanticscholar.org/paper/53b764aaadae945a515fc1676433ad4021769ab6,"International Colloquium on Automata, Languages and Programming"
647,Troponin I in the assessment of myocardial damage during percutaneous transluminal coronary angioplasty with stenting,,2000-12-01,https://www.semanticscholar.org/paper/faffacebf8c6fa1c8f7f112e05309ceaf4ec34d8,
2453,"A framework to facilitate reusable, modular widget design for real-time interactive systems","Game engines have become popular development platforms for real-time interactive systems. Contemporary game engines, such as Unity and Unreal, feature component-based architectures, in which an object's appearance and behavior is determined by a collection of component scripts added to that object. This design pattern allows common functionality to be contained within component scripts and shared among different types of objects. In this paper, we describe a flexible framework that enables programmers to design modular, reusable widgets for real-time interactive systems using a collection of component scripts. We provide a reference implementation written in C# for the Unity game engine. Making an object, or a group of objects, part of our managed widget framework can be accomplished with just a few drag-and-drop operations in the Unity Editor. While our framework provides hooks and default implementations for common widget behavior (e.g., initialization, refresh, and toggling visibility), programmers can also define custom behavior for a particular widget or combine simple widgets into a hierarchy and build arbitrarily rich ones. Finally, we provide an overview of an accompanying library of scripts that support functionality for testing and networking.",2016-03-20,https://www.semanticscholar.org/paper/2496b98e3d275b6d1d6c689ced55c144fe2a4123,Workshop on Software Engineering and Architectures for Realtime Interactive Systems
1944,Epistar and the Global LED Market,,2015-06-08,https://www.semanticscholar.org/paper/2d0bf9f05b314eab8d21a8f979a6af2d2a20f7c8,
2262,Secretion of oncostatin M by neutrophils in rheumatoid arthritis.,"OBJECTIVE
Neutrophils are known to express and release a large number of proinflammatory cytokines when they are stimulated by inflammatory stimuli. The objective of this study was to determine whether neutrophils express oncostatin M (OSM), a member of the interleukin-6 family of cytokines that has been implicated in the pathogenesis of inflammatory joint disease.


METHODS
Neutrophils were isolated from the blood of healthy volunteer donors and from the blood and synovial fluid of patients with rheumatoid arthritis (RA). OSM levels were measured in cell extracts and in culture supernatants by Western blotting. Total RNA was isolated from control and granulocyte-macrophage colony-stimulating factor (GM-CSF)-treated neutrophils, and OSM messenger RNA levels were quantified by hybridization of a radiolabeled probe.


RESULTS
GM-CSF stimulated a rapid and transient expression and release of OSM from blood neutrophils, which was more rapid than the expression and release from blood monocytes. A 28-kd protein was identified in cell extracts, but an additional 25-kd isoform was detected in culture supernatants. Synovial fluid neutrophils could not be stimulated to express OSM, but this cytokine was detected in cell-free supernatants at various levels.


CONCLUSION
Blood neutrophils can be stimulated to express and rapidly release large quantities of OSM. We propose that this important cytokine is released from neutrophils as they infiltrate rheumatoid joints and, thus, contribute to the complex cytokine network that characterizes RA.",2004-05-01,https://www.semanticscholar.org/paper/26f4e061fcdb98a2a24a652778a583b1215e0826,Arthritis & Rheumatism
282,Combinatorial Auctions : VC v . VCG,"The existence of incentive-compatible, computationally-efficient protocols for combinatorial auctions with decent approximation ratios is one of the most central and well studied open questions in mechanism design. The only universal technique known for the design of truthful mechanisms is the celebrated Vickrey-Clarke-Groves (VCG) scheme, which is "" maximal in range "" , i.e., it always exactly optimizes over a subset of the possible outcomes. We present a first-of-its-kind technique for proving computational-complexity inapproximability results for maximal-in-range mechanism for combinatorial auctions (under the complexity assumption that NP has no polynomial circuits). We show that in some interesting cases the lower bounds obtained using this technique can be extended to hold for all truthful mechanisms. Our lower-bounding method is based on a generalization of the VC-dimension to k-tuples of disjoint sets. We illustrate our technique via the case of two-bidder combinatorial auctions. We believe that this technique is of independent interest, and has great promise for making progress on the general problem.",,https://www.semanticscholar.org/paper/16834ddce3e20bf35ed68a14f2cd5e439b933c6d,
1421,Exclusion limits on the WIMP-nucleon scattering cross-section from the Cryogenic Dark Matter Search,,2000-04-07,https://www.semanticscholar.org/paper/60201ace92e99e1e2c00ea4405bc0a58ff41b321,
1353,Measurement of theB 0 Lifetime in the Exclusive Decay ChannelB 0 !J=,,,https://www.semanticscholar.org/paper/9edebedfe86330cc26bf965174015f700216180e,
1694,Variational Tempering,"Variational inference (VI) combined with data subsampling enables approximate posterior inference over large data sets, but suffers from poor local optima. We first formulate a deterministic annealing approach for the generic class of conditionally conjugate exponential family models. This approach uses a decreasing temperature parameter which deterministically deforms the objective during the course of the optimization. A well-known drawback to this annealing approach is the choice of the cooling schedule. We therefore introduce variational tempering, a variational algorithm that introduces a temperature latent variable to the model. In contrast to related work in the Markov chain Monte Carlo literature, this algorithm results in adaptive annealing schedules. Lastly, we develop local variational tempering, which assigns a latent temperature to each data point; this allows for dynamic annealing that varies across data. Compared to the traditional VI, all proposed approaches find improved predictive likelihoods on held-out data.",2014-11-07,https://www.semanticscholar.org/paper/209e1d36f36b8e7db3147b0e424874e54df9012e,International Conference on Artificial Intelligence and Statistics
2002,ENERGY-CONSTRAINT OPERATION STRATEGY FOR HIGH-SPEED RAILWAY,"With given trip time on each section, conventional train energy-efficient op- eration problem optimizes the reference speed prole such that the energy consumption for tracking the prole is minimized. Alternatively, this study aims to solve its anti-problem that minimizes the trip time under certain energy constraint, namely the train energy- constraint operation problem. In particular, this study focused on high-speed railway, for which the resistance mainly comes from the air friction. Firstly, we apply the Pontrya- gin maximum principle to prove that the optimal speed prole consists of four phases including acceleration, cruising, coasting and braking. Furthermore, we prove that the switching strategy among different phases is uniquely determined by the cruising speed, and then we solve the optimal cruising speed with an analytical approach. Finally, we prove some theorems on the energy-constrain",,https://www.semanticscholar.org/paper/8da8536ec964e53d682e1a68dc81ac51f5c35543,
2964,A reversible infinite HMM using normalised random measures,"We present a nonparametric prior over reversible Markov chains. We use completely random measures, specifically gamma processes, to construct a countably infinite graph with weighted edges. By enforcing symmetry to make the edges undirected we define a prior over random walks on graphs that results in a reversible Markov chain. The resulting prior over infinite transition matrices is closely related to the hierarchical Dirichlet process but enforces reversibility. A reinforcement scheme has recently been proposed with similar properties, but the de Finetti measure is not well characterised. We take the alternative approach of explicitly constructing the mixing measure, which allows more straightforward and efficient inference at the cost of no longer having a closed form predictive distribution. We use our process to construct a reversible infinite HMM which we apply to two real datasets, one from epigenomics and one ion channel recording.",2014-03-17,https://www.semanticscholar.org/paper/7cdcc054fa7abbb06e5f5d18faebbce90df95fc0,International Conference on Machine Learning
3529,Implementation of a Combinatorial Multicommodity Flow Algorithm,"The multicommodityow probleminvolves simultaneouslyship-ping multiplecommoditiesthrough a single network so that the total amount of ow on each edge is no more than the capacity of the edge. This problem can be expressed as a large linear program, and most known algorithms for it, both theoretical and practical, are linear programming algorithms designed to take advantage of the structure of multicommodity ow problems. The size of the linear programs, however, makes it prohibitively diicult to solve large multicommodity ow problems. In this paper, we describe and examine a multicommodity ow implementation based on the recent combinatorial approximation algorithm of Leighton et al. 13]. The theory predicts that the running time of the algorithm increases linearly with the number of commodities. Our experiments verify this behavior. The theory also predicts that the running time increases as the square of the desired precision. Our experiments show that the running time increases at most this fast, and often slower. We also compare our combinatorial implementation against two diierent linear programming-based codes. First we compare our code to that of of Kennington 10], which is a network simplex code known to perform well on multicommodity ow problems. For many problems, our combinatorial algorithm outperforms this simplex-based linear programming algorithm. More precisely, as the number of commodities increases, the running time of our algorithm grows much more slowly than that of Kennington's linear programming-based algorithm. Second, we compared our code to an interior point code of Karmarkar and Ramakrishnan. Here too, we achieved similar, but less dramatic results. Our results suggest that our algorithm may be able to solve larger multicommodity ow problems than have been solved in the past.",,https://www.semanticscholar.org/paper/cd51f99b4c8018cef18b3a1b779a94da08b4d7b7,Network Flows And Matching
149,Topological mobile robot localization using fast vision techniques,"We present a system for topologically localizing a mobile robot using color histogram matching of omnidirectional images. The system is intended for use as a navigational tool for the autonomous vehicle for exploration and navigation of urban environments (AVENUE) mobile robot. Our method makes use of omnidirectional images which are acquired from the robot's on-board camera. The method is fast and rotation invariant. Our tests have indicated that normalized color histograms are best for an outdoor environment while normalization is not required for indoor work. The system quickly narrows down the robot's location to one or two regions within the much larger test environment. Using this regional localization information, other vision systems that we have developed can further localize the robot.",2002-08-07,https://www.semanticscholar.org/paper/06e7faf4adc8be14a7259616141b867f6a2482b8,Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292)
1305,Limits on spin-independent interactions of weakly interacting massive particles with nucleons from the two-tower run of the cryogenic dark matter search.,"We report new results from the Cryogenic Dark Matter Search (CDMS II) at the Soudan Underground Laboratory. Two towers, each consisting of six detectors, were operated for 74.5 live days, giving spectrum-weighted exposures of 34 (12) kg d for the Ge (Si) targets after cuts, averaged over recoil energies 10-100 keV for a weakly interacting massive particle (WIMP) mass of 60 GeV/c2. A blind analysis was conducted, incorporating improved techniques for rejecting surface events. No WIMP signal exceeding expected backgrounds was observed. When combined with our previous results from Soudan, the 90% C.L. upper limit on the spin-independent WIMP-nucleon cross section is 1.6 x 10(-43) cm2 from Ge and 3 x 10(-42) cm2 from Si, for a WIMP mass of 60 GeV/c2. The combined limit from Ge (Si) is a factor of 2.5 (10) lower than our previous results and constrains predictions of supersymmetric models.",2006-01-13,https://www.semanticscholar.org/paper/256ce0f0a9c0f3ef0176fa8a7f3e435f2a344ead,Physical Review Letters
3120,Remote display performance for wireless healthcare computing.,"Organizations are beginning to recognize that health care providers are highly mobile and optimal care requires providing access to a large and dynamic body of information wherever the provider and patient are. Remote display protocols (RDP) are one way that organizations are using to deliver healthcare applications to mobile users. While many organizations have begun to use RDPs to deliver real-time access to health care information to clinicians, little formal work has been done to evaluate the performance or the effectiveness of thin-client computing with health care applications. This study examines the performance of wireless thin-client tablets with two web-based clinical applications, a text-centric, graphics-poor EMR and a graphic-rich image analysis program. The study compares the performance of two popular RDP implementations, Citrix and Microsoft Remote Desktop, with the performance of a traditional web browser in a wireless environment. For both applications, the RDPs demonstrated both higher speed and reduced bandwidth requirements than the web browser.",,https://www.semanticscholar.org/paper/4c9b80f671743318448e3f17af57a43bb81b7ecb,
1940,Extended priority-based hybrid genetic algorithm for the less-than-container loading problem,,2016-06-01,https://www.semanticscholar.org/paper/dbba17786159666850e2c3539b12d2c342601a12,Computers & industrial engineering
556,The complexity of recognizing polyhedral scenes,,1985-10-21,https://www.semanticscholar.org/paper/5ab528cf8712117494715e57c5f4c7626aaf4a3a,26th Annual Symposium on Foundations of Computer Science (sfcs 1985)
3744,Actor-Centric Relation Network,,2018-07-28,https://www.semanticscholar.org/paper/6b325af08a63bc8f94c39ae1c12509dce23d755c,European Conference on Computer Vision
2528,Physician Attitudes about Patient-Facing Information Displays at an Urban Emergency Department.,"Hospital information systems have primarily been designed to support physicians and administrators, though recent research has explored the value of patient-facing information displays. Electronic systems can be designed to provide tailored information to patients on their health, their care teams, the status of their hospital stays, and their expected care plans. However, this direct delivery of information from database to patient represents a fundamental change to the traditional flow of clinical information. We therefore explore physician attitudes toward a proposed patient-facing display of information abstracted from a hospital EHR, in the context of an urban emergency department. We find that physicians generally support direct delivery of electronic information to patients, and uncover important concerns to consider in the design of patient-facing information systems.",2010-11-13,https://www.semanticscholar.org/paper/f598f2a5b9bf1ea037a32dc0a4c76ecf14f6a816,AMIA ... Annual Symposium proceedings. AMIA Symposium
3683,Affective Faces for Goal-Driven Dyadic Communication,"We introduce a video framework for modeling the association between verbal and non-verbal communication during dyadic conversation. Given the input speech of a speaker, our approach retrieves a video of a listener, who has facial expressions that would be socially appropriate given the context. Our approach further allows the listener to be conditioned on their own goals, personalities, or backgrounds. Our approach models conversations through a composition of large language models and vision-language models, creating internal representations that are interpretable and controllable. To study multimodal communication, we propose a new video dataset of unscripted conversations covering diverse topics and demographics. Experiments and visualizations show our approach is able to output listeners that are significantly more socially appropriate than baselines. However, many challenges remain, and we release our dataset publicly to spur further progress. See our website for video results, data, and code: https://realtalk.cs.columbia.edu.",2023-01-26,https://www.semanticscholar.org/paper/35f5483fa6c1816739b604a5bb57719fadd79249,arXiv.org
2005,Manufacturing intelligence to forecast and reduce semiconductor cycle time,,2012-12-01,https://www.semanticscholar.org/paper/d3977c6e31ccb8a4775772731ace05d09872cabb,Journal of Intelligent Manufacturing
344,The complexity of pure Nash equilibria,"We investigate from the computational viewpoint multi-player games that are guaranteed to have pure Nash equilibria. We focus on congestion games, and show that a pure Nash equilibrium can be computed in polynomial time in the symmetric network case, while the problem is PLS-complete in general. We discuss implications to non-atomic congestion games, and we explore the scope of the potential function method for proving existence of pure Nash equilibria.",2004-06-13,https://www.semanticscholar.org/paper/71573900a6f2b934c5fd5eaf0e57958dc53527f6,Symposium on the Theory of Computing
1267,Measurement of the lifetime of the Bc+/- meson in the semileptonic decay channel.,"Using approximately 1.3 fb(-1) of data collected by the D0 detector between 2002 and 2006, we measure the lifetime of the Bc+/- meson in the Bc-/+-->J/psimicro+/-+X final state. A simultaneous unbinned likelihood fit to the J/psi+micro invariant mass and lifetime distributions yields a signal of 881+/-80(stat) candidates and a lifetime measurement of tau(Bc+/-)=0.448(-0.036)(+0.038)(stat)+/-0.032(syst) ps.",2008-05-16,https://www.semanticscholar.org/paper/ef62b32f10832870d6b65c9e92ae9d8bd4e0c72a,Physical Review Letters
2568,Visualizing and navigating complex situated hypermedia in augmented and virtual reality,"We present a set of techniques that enable mobile users to visualize and navigate complex hypermedia structures embedded in the real world, through augmented reality or virtual reality. Situating hypermedia in the 3D physical environment makes it possible to represent information about users' surroundings in context. However, it requires addressing a new set of problems beyond those of visualizing hypermedia on a 2D display: Nodes and links can potentially be distributed across large distances, and may be occluded by other objects, both real and virtual. Our techniques address these issues by enabling mobile users to select and manipulate portions of the hypermedia structure by tilting, lifting and shifting them, to view more clearly links and nodes that would otherwise be occluded or ambiguously connected.",2006-10-22,https://www.semanticscholar.org/paper/36ed21db5484ff40cd64597a9909cb234789f023,2006 IEEE/ACM International Symposium on Mixed and Augmented Reality
3638,The Design and Evolution of C,PART I. 1. The Prehistory of C++ . 2. C with Classes. 3. The Birth of C++. 4. C++ Language Design Rules. 5. Chronology 1985-1993. 6. Standardization. 7. Interest and Use. 8. Libraries. 9. Looking Ahead. PART II. 1. Memory Management. 2. Overloading. 3. Multiple Inheritance. 4. Class Concept Refinements. 5. Casting. 6. Templates. 7. Exception Handling. 8. Namespaces. 9. The C Preprocessor. Index. 0201543303T04062001,,https://www.semanticscholar.org/paper/617845029af8e8adba855ca7261cb1ff0f1ef40e,
3622,Generalizing Overloading for C + + 2000,"This paper outlines the proposal for generalizing the overloading rules for Standard C++ that is expected to become part of the next revision of the standard. The focus is on general ideas rather than technical details (which can be found in AT&T Labs Technical Report no. 42, April 1,1998).",,https://www.semanticscholar.org/paper/424f1905989ff2d3549640df3a439b7e2106704e,
1680,Objective Variables for Probabilistic Revenue Maximization in Second-Price Auctions with Reserve,"Many online companies sell advertisement space in second-price auctions with reserve. In this paper, we develop a probabilistic method to learn a profitable strategy to set the reserve price. We use historical auction data with features to fit a predictor of the best reserve price. This problem is delicate - the structure of the auction is such that a reserve price set too high is much worse than a reserve price set too low. To address this we develop objective variables, an approach for combining probabilistic modeling with optimal decision-making. Objective variables are ""hallucinated observations"" that transform the revenue maximization task into a regularized maximum likelihood estimation problem, which we solve with the EM algorithm. This framework enables a variety of prediction mechanisms to set the reserve price. As examples, we study objective variable methods with regression, kernelized regression, and neural networks on simulated and real data. Our methods outperform previous approaches both in terms of scalability and profit.",2015-06-24,https://www.semanticscholar.org/paper/59c8ca723801e441840fdde577f8e33b995d45a4,The Web Conference
750,"Automata, Probability, and Recursion",,2008-07-21,https://www.semanticscholar.org/paper/13140970ded9750d41733996dea1a879e8b55210,International Conference on Implementation and Application of Automata
504,Designing secure communication protocols from trust specifications,,1991-12-17,https://www.semanticscholar.org/paper/c881650846db3dd471ac8f01290812c8b4dc591f,Algorithmica
639,Some complexity results for the Traveling Salesman Problem,"It is shown that, unless P&equil;NP, local search algorithms for the Traveling Salesman Problem having polynomial time complexity per iteration will generate solutions arbitrarily far from the optimal. The Traveling Salesman Problem is also shown to be NP-Complete even if its instances are restricted to be realizable by a set of points on the Euclidean plane.",1976-05-03,https://www.semanticscholar.org/paper/b71714a5a99290fb9f9b1f9406c60be6cc32de8a,Symposium on the Theory of Computing
717,A Polynomial Time Algorithm for Computing Extinction Probabilities of Multitype Branching Processes,We show that one can approximate the least fixed point solution for a multivariate system of monotone probabilistic polynomial equations in time polynomial in both the encoding size of the system o...,2017-09-26,https://www.semanticscholar.org/paper/b6fa400f80969db103d60af72f7f4c3955474e98,SIAM journal on computing (Print)
292,On the Hardness of Being Truthful,"The central problem in computational mechanism design is the tension between incentive compatibility and computational efficiency. We establish the first significant approximability gap between algorithms that are both truthful and computationally-efficient, and algorithms that only achieve one of these two desiderata. This is shown in the context of a novel mechanism design problem which we call the combinatorial public project problem (cppp). cpppis an abstraction of many common mechanism design situations, ranging from elections of kibbutz committees to network design.Our result is actually made up of two complementary results -- one in the communication-complexity model and one in the computational-complexity model. Both these hardness results heavily rely on a combinatorial characterization of truthful algorithms for our problem. Our computational-complexity result is one of the first impossibility results connecting mechanism design to complexity theory; its novel proof technique involves an application of the Sauer-Shelah Lemma and may be of wider applicability, both within and without mechanism design.",2008-10-25,https://www.semanticscholar.org/paper/8c573c11f35f33bc31a00fea5331f6e04329935e,2008 49th Annual IEEE Symposium on Foundations of Computer Science
513,On the predictability of coupled automata: an allegory about chaos,The authors show a sharp dichotomy between systems of identical automata with symmetric global control whose behavior is easy to predict and those whose behavior is hard to predict. The division pertains to whether the global control rule is invariant with respect to permutations of the states of the automaton. It is also shown that testing whether the global control rule has this invariance property is an undecidable problem. It is argued that there is a natural analog between complexity in the present model and chaos in dynamical systems.<<ETX>>,1990-10-22,https://www.semanticscholar.org/paper/78723b772ec90a57f66fc47e55fd7b8cee3737b9,Proceedings [1990] 31st Annual Symposium on Foundations of Computer Science
887,The Maximum k-Colorable Subgraph Problem for Chordal Graphs,,1987-01-30,https://www.semanticscholar.org/paper/174747140fbd56a777161f37131f8a120d355da1,Information Processing Letters
298,Complexity of game dynamics,"What happens when independent agents interact based on their selfish interests? Game theory's earliest and most natural simple model of such interaction is the best-response Nash dynamics, the process of agents making unilateral moves that are their best response to the actions of others. Pure Nash equilibria, when they do exist, arise naturally as the steady states of this process. When they don't exist, behavioral predictions can be made from ""sink equilibria"", a universal (guaranteed to exist) generalization of Nash equilibria to ""steady clusters of states."" 
We now know that it is vital for a model of naturally-occuring behavior to be computationally tractable, not only for simulations, but also to check how realistic the model is, since we expect that nature (aside maybe from quantum physics) cannot produce systems with fundamentally more computational power than computers as we know them. 
In this dissertation, I show several results about the tractability of analyzing a game's best-response dynamics. If the game payoff tables are given explicitly (in normal form), searching for pure Nash or sink equilibria is trivial. However, most interesting games are represented more succinctly. For pure Nash equilibria, I show that in potential games, a well-studied class of succinct games guaranteed to have pure equilibria, finding pure Nash equilibria is PLS-complete, and the best-response dynamics takes an exponentially long time to converge in the worst case, even when the games are restricted to network routing games, or to symmetric games. For sink equilbria, I prove that it is PSPACE-complete to analyze them in graphical games. 
On the practical side, I resolve a decade-old well-known open problem in networking by establishing that it is PSPACE-complete to predict whether Internet inter-domain routing may be destabilized by large-scale oscillations; that is, whether a system of path preferences in the BGP protocol may lead to flapping. This turns out to be a question about the best-response dynamics in a special kind of game. 
Lastly, I propose several enhanced equilibrium concepts inspired by game dynamics that allow for higher rationality by the players while mostly retaining the tractability and universality of sink equilibria in normal-form games.",,https://www.semanticscholar.org/paper/de61d8f3008a649951f82fd2c9a99cdbd27155de,
2263,Oscillations in NF-kappaB signaling control the dynamics of gene expression.,"Signaling by the transcription factor nuclear factor kappa B (NF-kappaB) involves its release from inhibitor kappa B (IkappaB) in the cytosol, followed by translocation into the nucleus. NF-kappaB regulation of IkappaBalpha transcription represents a delayed negative feedback loop that drives oscillations in NF-kappaB translocation. Single-cell time-lapse imaging and computational modeling of NF-kappaB (RelA) localization showed asynchronous oscillations following cell stimulation that decreased in frequency with increased IkappaBalpha transcription. Transcription of target genes depended on oscillation persistence, involving cycles of RelA phosphorylation and dephosphorylation. The functional consequences of NF-kappaB signaling may thus depend on number, period, and amplitude of oscillations.",,https://www.semanticscholar.org/paper/7973a9988e4a3cc3381a0d56b53adaa74b5952d4,Science
2958,Using contextual information to classify nuclei in histology images,"Nucleus classification is a central task in digital pathology. Given a tissue image, our goal is to classify detected nuclei into different types, for example nuclei of tumor cells, stroma cells, or immune cells. State-of-the-art methods achieve this by extracting different types of features such as morphology, image intensities, and texture features in the nucleus regions. Such features are input to training and classification, e.g. using a support vector machine. In this paper, we introduce additional contextual information obtained from neighboring nuclei or texture in the surrounding tissue regions to improve nucleus classification. Three different methods are presented. These methods use conditional random fields (CRF), texture features computed in image patches centered at each nucleus, and a novel method based on the bag-of-word (BoW) model. The methods are evaluated on images of tumor-burdened tissue from H&E-stained and Ki-67-stained breast samples. The experimental results show that contextual information systematically improves classification accuracy. The proposed BoW-based method performs better than the CRF-based method, and requires less computation than the texture-feature-based method.",2015-04-16,https://www.semanticscholar.org/paper/65b025e06f2fb416ff3d16122e48328c8369db86,IEEE International Symposium on Biomedical Imaging
1350,Search for Randall-Sundrum gravitons in dilepton and diphoton final states.,"We report the first direct search for the Kaluza-Klein (KK) modes of Randall-Sundrum gravitons using dielectron, dimuon, and diphoton events observed with the D0 detector operating at the Fermilab Tevatron pp(-) Collider at sqrt[s]=1.96 TeV. No evidence for resonant production of gravitons has been found in the data corresponding to an integrated luminosity of approximately equal to 260 pb(-1). Lower limits on the mass of the first KK mode at the 95% C.L. have been set between 250 and 785 GeV, depending on its coupling to standard model particles.",2005-05-09,https://www.semanticscholar.org/paper/916132cd350319dc961af05e3fbbeb8b4c802fa6,Physical Review Letters
1495,Measurement of Nucleon Structure Function in Muon Scattering at High $q^{2}$,"The nucleon structure function, F/sub 2/, has been measured up to q/sup 2/ = 120 (GeV/c)/sup 2/ and for 40 < W/sup 2/ < 300 GeV/sup 2/. The data exhibit a significant pattern of scaling violation. Compared to lower-energy data, F/sub 2/ shows an observable increase of approx. 15% at high q/sup 2/ for x < 0.4. The pattern of the increase may accommodate a threshold in W or new theoretical parametrizations.",1979-04-02,https://www.semanticscholar.org/paper/10941d4f9f274fa585f470ab7c955df5c8007092,
1826,A Computational Approach to Style in American Poetry,"We develop a quantitative method to assess the style of American poems and to visualize a collection of poems in relation to one another. Qualitative poetry criticism helped guide our development of metrics that analyze various orthographic, syntactic, and phonemic features. These features are used to discover comprehensive stylistic information from a poem's multi-layered latent structure, and to compute distances between poems in this space. Visualizations provide ready access to the analytical components. We demonstrate our method on several collections of poetry, showing that it better delineates poetry style than the traditional word-occurrence features that are used in typical text analysis algorithms. Our method has potential applications to academic research of texts, to research of the intuitive personal response to poetry, and to making recommendations to readers based on their favorite poems.",2007-10-28,https://www.semanticscholar.org/paper/9c514afc65342e71adc84ed9b46fda3a54a3d127,Industrial Conference on Data Mining
1987,Overall Wafer Effectiveness (OWE): A novel industry standard for semiconductor ecosystem as a whole,,2013-05-01,https://www.semanticscholar.org/paper/e0f724525c5b3d0bc00038f2e60f3570ecb7280f,Computers & industrial engineering
2781,Indispensable role of Galectin-3 in promoting quiescence of hematopoietic stem cells,,2021-04-09,https://www.semanticscholar.org/paper/6358b1fa6aebe48ada3db075aa2a8343df9fee26,Nature Communications
69,Categorizing web queries according to geographical locality,"Web pages (and resources, in general) can be characterized according to their geographical locality. For example, a web page with general information about wildflowers could be considered a global page, likely to be of interest to a geographically broad audience. In contrast, a web page with listings on houses for sale in a specific city could be regarded as a local page, likely to be of interest only to an audience in a relatively narrow region. Similarly, some search engine queries (implicitly) target global pages, while other queries are after local pages. For example, the best results for query [wildflowers] are probably global pages about wildflowers such as the one discussed above. However, local pages that are relevant to, say, San Francisco are likely to be good matches for a query [houses for sale] that was issued by a San Francisco resident or by somebody moving to that city. Unfortunately, search engines do not analyze the geographical locality of queries and users, and hence often produce sub-optimal results. Thus query [wildflowers] might return pages that discuss wildflowers in specific U.S. states (and not general information about wildflowers), while query [houses for sale] might return pages with real estate listings for locations other than that of interest to the person who issued the query. Deciding whether an unseen query should produce mostly local or global pages---without placing this burden on the search engine users---is an important and challenging problem, because queries are often ambiguous or underspecify the information they are after. In this paper, we address this problem by first defining how to categorize queries according to their (often implicit) geographical locality. We then introduce several alternatives for automatically and efficiently categorizing queries in our scheme, using a variety of state-of-the-art machine learning tools. We report a thorough evaluation of our classifiers using a large sample of queries from a real web search engine, and conclude by discussing how our query categorization approach can help improve query result quality.",2003-11-03,https://www.semanticscholar.org/paper/8e5f1448c34cfd78b85ef2601ddc2fda84fde101,International Conference on Information and Knowledge Management
1523,A Bayesian Causal Inference Approach for Assessing Fairness in Clinical Decision-Making,"Fairness in clinical decision-making is a critical element of health equity, but assessing fairness of clinical decisions from observational data is challenging. Recently, many fairness notions have been proposed to quantify fairness in decision-making, among which causality-based fairness notions have gained increasing attention due to its potential in adjusting for confounding and reasoning about bias. However, causal fairness notions remain under-explored in the context of clinical decision-making with large-scale healthcare data. In this work, we propose a Bayesian causal inference approach for assessing a causal fairness notion called principal fairness in clinical settings. We demonstrate our approach using both simulated data and electronic health records (EHR) data.",2022-11-21,https://www.semanticscholar.org/paper/60c6c0fbae81caee615f328cbc46c4a9a6f0cd22,arXiv.org
2887,"The adhesive specificity of the soluble human lectin, IgE-binding protein, toward lipid-linked oligosaccharides. Presence of the blood group A, B, B-like, and H monosaccharides confers a binding activity to tetrasaccharide (lacto-N-tetraose and lacto-N-neotetraose) backbones.","The immunoglobulin E-binding protein, epsilon BP (also known as CBP35, Mac-2, L-34, and L-29), is a beta-galactoside-binding protein of approximately 30 kDa and a member of the animal lectin family termed S-type or S-Lac. Multiple biological activities have been attributed to this lectin such as mediation of IgE binding to the surface of Langerhans cells and activation of mast cells through binding to the high affinity IgE receptor. In order to better understand the cell-binding activity and the proposed role for epsilon BP as a biological response modifier, we have studied the specificity of binding of the radioiodinated epsilon BP to a series of lipid-linked, structurally defined oligosaccharide sequences of the lacto/neolacto family. The results show that the minimum lipid-linked oligosaccharides that can support epsilon BP binding are pentasaccharides of the lacto/neolacto series and that the lectin binds more strongly to oligosaccharides of this family that bear the blood group A, B, or B-like determinants than to those bearing blood group H. This preferential binding of epsilon BP is also manifest with whole cells, as erythrocytes of blood groups A and B are more strongly bound by epsilon BP than those of blood group O. Blood group Le(a) and Le(x) sequences are not bound by the lectin.(ABSTRACT TRUNCATED AT 250 WORDS)",1994-05-24,https://www.semanticscholar.org/paper/8c3c64c610ad1c22efd231d294c792d6a9caa467,Biochemistry
2077,Yield improvement planning for the recycle processes of test wafers,,2006-02-01,https://www.semanticscholar.org/paper/76f6bb02446c6deae2fee62a5a239fed70b8d551,
3746,A Large Scale Video Dataset for Event Recognition,,2018-09-01,https://www.semanticscholar.org/paper/b263ccf4c5bb19a578165ed731ca24f9ea3653cf,Journal of Vision
3469,Algorithm Engineering and Experiments,,,https://www.semanticscholar.org/paper/ce8a91f2506b87ecfb40abe9fc78c4d65302cf7d,Lecture Notes in Computer Science
2925,Molecular Choreography of Acute Exercise,"Exercise testing is routinely used in clinical practice to assess fitness - a strong predictor of survival - as well as causes of exercise limitations. While these studies often focus on cardiopulmonary response and selected molecular pathways, the dynamic system-wide molecular response to exercise has not been fully characterized. We performed a longitudinal multi-omic profiling of plasma and peripheral blood mononuclear cells including transcriptome, immunome, proteome, metabolome and lipidome in 36 well-characterized volunteers before and after a controlled bout of acute exercise (2, 15, 30 min and 1 hour in recovery). Integrative analysis revealed an orchestrated choreography of biological processes across key tissues. Most of these processes were dampened in insulin resistant participants. Finally, we discovered biological pathways involved in exercise capacity and developed prediction models revealing potential resting blood-based biomarkers of fitness.",2020-01-14,https://www.semanticscholar.org/paper/177d5b1da1097f0f91368610b486eb98a2da337f,Cell
3324,Shoal choice behaviour in fish : The relationship between assessment time and assessment quality,"In this study, we investigated the role of assessment time in group size discrimination and in particular the trade-off between the time cost involved in gathering information and the potential benefits derived from the acquired information. In a first experiment, we presented individual chub, Semotilus atromaculatus, with a choice between 4 vs 4 and 8 vs 8 conspecific stimulus fish. After release we recorded the time taken by test fish to make a choice between the two stimulus shoals in the presence and absence of a fright stimulus. Test fish significantly reduced their response time in the presence of a fright stimulus and larger shoals (8 vs 8) were more quickly approached than smaller ones (4 vs 4). In a control experiment, chub were given a choice between an empty cylinder and a shoal (of 4 or 8 fish). By subtracting the response time in the control treatment from that in the choice treatment, we estimated the time test fish spent choosing between stimulus shoals to be 24-55% of the overall response time. These results indicate that choosing between different groups is associated with a significant time cost. In a second experiment, we presented test fish with stimulus shoals that differed in size: 4 vs 5, 4 vs 6, 4 vs 7 and 4 vs 8, to investigate how the response time of fish and their ability to distinguish between shoals of different size were affected by the magnitude of the shoal size difference and the presence and absence of a fright stimulus. The ability to discriminate between shoals of different size increased with increasing shoal size difference whereas response time decreased. Both response time and discrimination ability were significantly reduced in the presence of a fright stimulus. The latter suggests that the benefits derived from group size discrimination were increasingly outweighed by the time costs of making group size assessments in the presence of potential danger; i.e. making fast assessments became relatively more important than making correct ones.",,https://www.semanticscholar.org/paper/23391b0a5fcf103bbbf79e855e75d43294295299,
327,Computing equilibria in multi-player games,"We initiate the systematic study of algorithmic issues involved in finding equilibria (Nash and correlated) in games with a large number of players; such games, in order to be computationally meaningful, must be presented in some succinct, game-specific way. We develop a general framework for obtaining polynomial-time algorithms for optimizing over correlated equilibria in such settings, and show how it can be applied successfully to symmetric games (for which we actually find an exact polytopal characterization), graphical games, and congestion games, among others. We also present complexity results implying that such algorithms are not possible in certain other such games. Finally, we present a polynomial-time algorithm, based on quantifier elimination, for finding a Nash equilibrium in symmetric games when the number of strategies is relatively small.",2005-01-23,https://www.semanticscholar.org/paper/1cede7f04cbc628802990b1bcf6463259c65ac6b,ACM-SIAM Symposium on Discrete Algorithms
649,Angiographic follow-up and clinical experience with the flexible Tantalum Cordis stent.,"The Cordis stent is a flexible, highly radioopaque intracoronary stent engineered from a single Tantalum filament folded into a sinusoidal helical coil. It is premounted on a semicompliant balloon expandable stent delivery system. From September 1995-March 1996, 147 Cordis stents were deployed in 105 patients (aged 58+/-12 yr, 71% male). Clinical indications for stenting were unstable angina in 59 (55%), stable angina in 41 (38%), and acute myocardial infarction in 7 (7%). The target vessel was the right coronary artery in 45%, the left anterior descending in 31%, and the circumflex artery in 22%. One stent was deployed in a vein graft, and one stent was deployed in a left internal mammary artery graft. Stent deployment was achieved in all but one patient. Acute in-stent thrombosis occurred in 3 patients (2.9%). Two of these patients required urgent coronary artery bypass surgery. Subacute stent thrombosis occurred in 2 patients (1.9%). Minimum lumen diameter increased from 0.70+/-0.41 mm to 3.50+/-0.60 mm following stent placement. All patients received aspirin. Eighty-one patients (77%) received ticlopidine, and 4 patients (4%) received warfarin therapy. The mean hospital stay was 3.4+/-2.3 days. Six-month follow-up angiography was performed on 50 out of 55 eligible patients at one of the two institutions involved in this study. Computer-assisted quantitative coronary angiography defined a restenosis rate of 26%. Repeat revascularization was required in 8 patients (14.5%) at 6-mo follow-up. The Tantalum Cordis intracoronary stent is an effective and safe means of treating coronary lesions, even in patients with unstable ischemic syndromes. Acute and subacute rates of in-stent thrombosis were acceptable, and the long-term angiographic restenosis rates and need for repeat revascularization were favorable.",1998-02-01,https://www.semanticscholar.org/paper/3614865f3590afa28337d2cd304f74c37359a3aa,Catheterization and Cardiovascular Diagnosis
1255,A Search for WIMPs with the First Five-Tower Data from CDMS,"We report ﬁrst results from the Cryogenic Dark Matter Search (CDMS II) experiment running with its full complement of 30 cryogenic particle detectors at the Soudan Underground Laboratory. This report is based on the analysis of data acquired between October 2006 and July 2007 from 15 Ge detectors (3.75 kg), giving an eﬀective exposure of 121.3 kg-d (averaged over recoil energies 10– 100 keV, weighted for a weakly interacting massive particle (WIMP) mass of 60 GeV/c 2 ). A blind analysis, incorporating improved techniques for event reconstruction and data quality monitoring, resulted in zero observed events. This analysis sets an upper limit on the WIMP-nucleon spin-independent cross section of 6.6 × 10 − 44 cm 2 (4.6 × 10 − 44 cm 2 when combined with previous CDMS Soudan data) at the 90% conﬁdence level for a WIMP mass of 60 GeV/c 2 . By providing the best sensitivity for dark matter WIMPs with masses above 42 GeV/c 2 , this work signiﬁcantly restricts the parameter space for some of the favored supersymmetric models.",,https://www.semanticscholar.org/paper/d1d1ef112962710db959347ae9fded21362d25fb,
1756,Variational Bayesian Inference with Stochastic Search,"Mean-field variational inference is a method for approximate Bayesian posterior inference. It approximates a full posterior distribution with a factorized set of distributions by maximizing a lower bound on the marginal likelihood. This requires the ability to integrate a sum of terms in the log joint likelihood using this factorized distribution. Often not all integrals are in closed form, which is typically handled by using a lower bound. We present an alternative algorithm based on stochastic optimization that allows for direct optimization of the variational lower bound. This method uses control variates to reduce the variance of the stochastic search gradient, in which existing lower bounds can play an important role. We demonstrate the approach on two non-conjugate models: logistic regression and an approximation to the HDP.",2012-06-26,https://www.semanticscholar.org/paper/9ceb1dea15ac3df3d610fd0b3cc52b9a4e9141a3,International Conference on Machine Learning
2162,Phenotypic and functional changes of T cell subsets after CoronaVac vaccination,,2022-10-01,https://www.semanticscholar.org/paper/09df568859721ea62b3098174bcb0a6d1b8be6e3,Vaccine
1615,The Holdout Randomization Test for Feature Selection in Black Box Models,"Abstract We propose the holdout randomization test (HRT), an approach to feature selection using black box predictive models. The HRT is a specialized version of the conditional randomization test (CRT) that uses data splitting for feasible computation. The HRT works with any predictive model and produces a valid p-value for each feature. To make the HRT more practical, we propose a set of extensions to maximize power and speed up computation. In simulations, these extensions lead to greater power than a competing knockoffs-based approach, without sacrificing control of the error rate. We apply the HRT to two case studies from the scientific literature where heuristics were originally used to select important features for predictive models. The results illustrate how such heuristics can be misleading relative to principled methods like the HRT. Code is available at https://github.com/tansey/hrt. Supplementary materials for this article are available online.",2018-11-01,https://www.semanticscholar.org/paper/f7725abd17be6bf40f286de54be6aeeee61e0bcf,Journal of Computational And Graphical Statistics
945,Equivalence among Relational Expressions with the Union and Difference Operation,"A generalization of tableaux as a method for representing queries in relational databases, called sets of tableaux, is proposed. Every relational expression with the operators select, project, join and union can be represented by a set of tableaux. This paper studies the equivalence problem for sets of tableaux. It is shown that the theory of tableaux is easily extended to sets of tableaux, but the equivalence problem for sets of tableaux (as well as the containment problem for single tableaux) is NP-complete even in very restricted cases. Polynomial time algorithms for testing equivalence of sets of tableaux (and containment of tableaux) in three special cases are presented. Sets of tableaux are further generalized to sets of elementary differences in order to include also the difference operator. The equivalence problem for sets of elementary differences is investigated.",1978-09-13,https://www.semanticscholar.org/paper/2d77349cfe804f4709d0d71e8438067d4f57c3d2,Very Large Data Bases Conference
2985,Gaussian Process Regression Networks,"We introduce a new regression framework, Gaussian process regression networks (GPRN), which combines the structural properties of Bayesian neural networks with the nonparametric exibility of Gaussian processes. GPRN accommodates input (predictor) dependent signal and noise correlations between multiple output (response) variables, input dependent length-scales and amplitudes, and heavy-tailed predictive distributions. We derive both elliptical slice sampling and variational Bayes inference procedures for GPRN. We apply GPRN as a multiple output regression and multivariate volatility model, demonstrating substantially improved performance over eight popular multiple output (multi-task) Gaussian process models and three multivariate volatility models on real datasets, including a 1000 dimensional gene expression dataset.",2011-10-19,https://www.semanticscholar.org/paper/ebdd2ac920461d6ed9b5ba0cc3fd74d844494690,International Conference on Machine Learning
3579,IAP Distinguished Lecture,"This Saturday (September 20), the new ISO C++ standard, C++0x, will be voted out for public review. That means that the committee consider the standard feature complete and ready for nit picking. A good programming language is far more than a simple collection of features. My ideal is to provide a set of facilities that smoothly work together to support design and programming styles of a generality beyond my imagination. Here, I briefly outline rules of thumb (guidelines, principles), with examples, that are being applied in the design of C++0x. Then, I give two large examples of new language features: concepts and generalized initialization. Since there are far more proposals than could be presented in an hour, I'll take questions.",,https://www.semanticscholar.org/paper/30396838bf4c4c47ce714960021d7a21964b7ea0,
218,The Web Graph as an Equilibrium,,2015-09-28,https://www.semanticscholar.org/paper/7bc7d622b6a5ebd210ecfb00fd726598656fc867,Algorithmic Game Theory
1037,Dissipation-Induced Self-Recovery in Systems on Principal Bundles,"The “self-recovery” phenomenon is a seemingly curious property of certain underactuated dissipative systems in which dissipative forces always push the system to a pre-determined equilibrium state dependent on the initial conditions. The systems for which this has been studied are Abelian, with all system velocity interactions due entirely to inertial effects. In this paper we also consider Abelian systems, but in the context of principal bundles, and introduce drag in addition to inertial interactions, allowing us to show that the same conservation that induces self-recovery now depends on the trajectories of the system inputs in addition to initial conditions. We conclude by demonstrating an example illustrating the conditions derived from our proof, along with an observation that the present analysis is insufficient for self-recovery in non-Abelian systems.Copyright © 2014 by ASME",2014-10-22,https://www.semanticscholar.org/paper/03641011175ea13793f2bfd6357a086c418bbabd,
691,Reducing Tarski to Unique Tarski (in the Black-box Model),We study the problem of finding a Tarski fixed point over the k -dimensional grid [ n ] k . We give a black-box reduction from the Tarski problem to the same problem with an additional promise that the input function has a unique fixed point. It implies that the Tarski problem and the unique Tarski problem have exactly the same query complexity. Our reduction is based on a novel notion of partial-information functions which we use to fool algorithms for the unique Tarski problem as if they were working on a monotone function with a unique fixed point,,https://www.semanticscholar.org/paper/48f4375253789920bfea64a3d3abaf86d6e30b42,Electron. Colloquium Comput. Complex.
696,Technical Perspective: Structure and Complexity of Bag Consistency,"The paper Structure and Complexity of Bag Consistency by Albert Atserias and Phokion Kolaitis [1] studies fundamental structural and algorithmic questions on the global consistency of databases in the context of bag semantics. A collection D of relations is called globally consistent if there is a (so-called “universal”) relation over all the attributes that appear in all the relations of D whose projections yield the relations in D . The basic algorithmic problem for consistency is: given a database D , determine whether D is globally consistent. An obvious necessary condition for global consistency is local (or pairwise ) consistency : every pair of relations in D must be consistent. This condition is not suf-ﬁcient however: It is possible that every pair is consistent, but there is no single global relation over all the attributes whose projections yield the relations in D . A natural structural question is: Which database schemas have the property that every locally consistent database over the schema is also globally consistent? which local global The paper by Atserias and (multisets).",,https://www.semanticscholar.org/paper/ac14592372f6804cfa21713089ccfc847599b6e7,
83,"Probe, count, and classify: categorizing hidden web databases","The contents of many valuable web-accessible databases are only accessible through search interfaces and are hence invisible to traditional web “crawlers.” Recent studies have estimated the size of this “hidden web” to be 500 billion pages, while the size of the “crawlable” web is only an estimated two billion pages. Recently, commercial web sites have started to manually organize web-accessible databases into Yahoo!-like hierarchical classification schemes. In this paper, we introduce a method for automating this classification process by using a small number of query probes. To classify a database, our algorithm does not retrieve or inspect any documents or pages from the database, but rather just exploits the number of matches that each query probe generates at the database in question. We have conducted an extensive experimental evaluation of our technique over collections of real documents, including over one hundred web-accessible databases. Our experiments show that our system has low overhead and achieves high classification accuracy across a variety of databases.",2001-05-01,https://www.semanticscholar.org/paper/1e2355cea9da54478de58efdec1e4f8e995cf231,ACM SIGMOD Conference
1821,"Statistical Network Analysis: Models, Issues, and New Directions - ICML 2006 Workshop on Statistical Network Analysis, Pittsburgh, PA, USA, June 29, 2006, Revised Selected Papers",,,https://www.semanticscholar.org/paper/46c825c9c5c6ce278671419ce76ea9c71d4dcbc7,SNA@ICML
3297,Reproductive status influences group size and persistence of bonds in male plains zebra (Equus burchelli),,2009-04-02,https://www.semanticscholar.org/paper/46402a7ecb8ebfdef6553ff07082a82a6f637259,Behavioral Ecology and Sociobiology
2259,Neutrophil gene expression in rheumatoid arthritis.,,2005-10-01,https://www.semanticscholar.org/paper/ed017863c971daff319ee566f776ab7e1052f398,Pathophysiology
1019,"Swim: A General-Purpose, High-Performing, and Efficient Activation Function for Locomotion Control Tasks","Activation functions play a significant role in the performance of deep learning algorithms. In particular, the Swish activation function tends to outperform ReLU on deeper models, including deep reinforcement learning models, across challenging tasks. Despite this progress, ReLU is the preferred function partly because it is more efficient than Swish. Furthermore, in contrast to the fields of computer vision and natural language processing, the deep reinforcement learning and robotics domains have seen less inclination to adopt new activation functions, such as Swish, and instead continue to use more traditional functions, like ReLU. To tackle those issues, we propose Swim, a general-purpose, efficient, and high-performing alternative to Swish, and then provide an analysis of its properties as well as an explanation for its high-performance relative to Swish, in terms of both reward-achievement and efficiency. We focus on testing Swim on MuJoCo's locomotion continuous control tasks since they exhibit more complex dynamics and would therefore benefit most from a high-performing and efficient activation function. We also use the TD3 algorithm in conjunction with Swim and explain this choice in the context of the robot locomotion domain. We then conclude that Swim is a state-of-the-art activation function for continuous control locomotion tasks and recommend using it with TD3 as a working framework.",2023-03-05,https://www.semanticscholar.org/paper/e7b503d48f4f5864fafb9e3fe6c1391a1f32328d,arXiv.org
3188,Staying Alive: Long-Term Success of Bottlenose Dolphin Interventions in Southwest Florida,"Small cetaceans face persistent threats from fisheries interactions, making effective mitigation a priority for conservation. In southwest Florida, interactions come primarily from small-scale recreational hook and line and trap/pot fisheries, with regional stranding network partners working with federal agency managers to assess and intervene as possible in cases of live animal entanglement. Evaluating success of intervention cases is difficult due to financial and logistical constraints which may preclude detailed follow-up monitoring. Survival over the initial 6 weeks post-release has been used as a marker of short-term success for small-cetacean rescue and/or rehabilitation cases. Early intervention prior to stranding, especially via remote disentanglement or rescue and immediate re-release onsite, can save entangled free-ranging dolphins facing life-threatening anthropogenic injuries. However, given the costs associated with interventions, it is important to understand the benefits of these endeavors not only to save individuals, but also to establish if and how saved individuals contribute to social functioning, survival and reproduction within small, resident populations facing multiple concurrent threats. Here we provide evidence from 27 well-documented common bottlenose dolphin (Tursiops truncatus) intervention cases during 1985–2019 where follow-up monitoring over multiple years sheds light on the longer-term success of these efforts and potential benefits to local populations. Nearly all rescued individuals (92%) survived longer than 6 weeks post-release (mean minimum survival period = 5 years, range 0–35 years), with 13 still observed frequently within their prior resident communities, in good physical health, and engaging in normal behavior. Survivorship rates did not decline substantially between 1 and 5 years post-rescue, meaning survival beyond 1 year may be a useful benchmark of long-term success. Rescued females that reached reproductive maturity (n = 4) have produced 12 post-intervention offspring to date. Social network analysis and demographic modeling applied to cases from the long-term resident community in Sarasota Bay confirmed that animals maintain social connections post-intervention and that interventions result in higher population growth rates. While not every intervention succeeds, this study demonstrates the conservation value of pre-stranding interventions which allow individuals that otherwise would be lost to remain viable and productive members of local populations when prevention of anthropogenic injury is not possible.",2021-01-18,https://www.semanticscholar.org/paper/0905b9d270f3ad470556b4fdbbde43edde7a9741,Frontiers in Marine Science
3352,Reproductive Value and Behavioral Strategies: Coming of Age in Monkeys and Horses,,,https://www.semanticscholar.org/paper/0cad3e8028ae2b70649a43702f94f3f2cd9c288b,
3658,A Set of C++ Classes,,,https://www.semanticscholar.org/paper/4102972639ba54dd75ccfcd626bcb9cfcaa68d14,C++ Workshop
3759,Visualizing Object Detection Features,,2016-03-01,https://www.semanticscholar.org/paper/d274a0c1c383bc2440f9d90cab61df4ff934efdb,International Journal of Computer Vision
738,Temporal Synthesis for Bounded Systems and Environments,"Temporal synthesis is the automated construction of a system from its temporal specification. It is by now realized that requiring the synthesized system to satisfy the specifications against all possible environments may be too demanding, and, dually, allowing all systems may be not demanding enough. In this work we study bounded temporal synthesis, in which bounds on the sizes of the state space of the system and the environment are additional parameters to the synthesis problem. This study is motivated by the fact that such bounds may indeed change the answer to the synthesis problem, as well as the theoretical and computational aspects of the synthesis problem. In particular, a finer analysis of synthesis, which takes system and environment sizes into account, yields deeper insight into the quantificational structure of the synthesis problem and the relationship between strong synthesis -- there exists a system such that for all environments, the specification holds, and weak synthesis -- for all environments there exists a system such that the specification holds. 
 
We first show that unlike the unbounded setting, where determinacy of regular games implies that strong and weak synthesis coincide, these notions do not coincide in the bounded setting. We then turn to study the complexity of deciding strong and weak synthesis. We show that bounding the size of the system or both the system and the environment, turns the synthesis problem into a search problem, and one cannot expect to do better than brute-force search. In particular, the synthesis problem for bounded systems and environment is Sigma^P_2-complete (in terms of the bounds, for a specification given by a deterministic automaton). We also show that while bounding the environment may lead to the synthesis of specifications that are otherwise unrealizable, such relaxation of the problem comes at a high price from a complexity-theoretic point of view.",,https://www.semanticscholar.org/paper/5456e12fbacb18180f052bfc5d5c64db1b92dc8e,Symposium on Theoretical Aspects of Computer Science
1387,Search for narrow tt resonances in pp collisions at square root of (s)=1.8 TeV.,"A search for narrow resonances that decay into tt pairs has been performed using 130 pb(-1) of data in the lepton + jets channel collected by the Dphi detector in pp collisions at square root of (s)=1.8 TeV. There is no significant deviation observed from the standard-model predictions at a top-quark mass of 175 GeV/c2. We therefore present upper limits at the 95% confidence level on the product of the production cross section and branching fraction to tt for narrow resonances as a function of the resonance mass MX. These limits are used to exclude the existence of a leptophobic top-color particle with mass MX<560 GeV/c2, using a theoretical cross section for a width GammaX=0.012MX.",2003-07-29,https://www.semanticscholar.org/paper/85e0932f4bc6ba2fbde8f3b454ffd137d712e98e,Physical Review Letters
1418,Exclusion limits on the WIMP-nucleon cross section from the cryogenic dark matter search.,"The Cryogenic Dark Matter Search (CDMS) employs Ge and Si detectors to search for weakly interacting massive particles (WIMPs) via their elastic-scattering interactions with nuclei while discriminating against interactions of background particles. CDMS data, accounting for the neutron background, give limits on the spin-independent WIMP-nucleon elastic-scattering cross section that exclude unexplored parameter space above 10 GeV/c2 WIMP mass and, at >75% C.L., the entire 3sigma allowed region for the WIMP signal reported by the DAMA experiment.",2000-06-19,https://www.semanticscholar.org/paper/0030c4844265dfeb1a3c04540dbb58c039993639,Physical Review Letters
3319,Status and Action Plan for the Plains Zebra (Equus burchellii),"IUCN Red List Category (E. burchellii, E.b. antiquorum, and E.b. boehmi were assessed using version 3.1; all others with version 2.3): Equus burchellii LC Least Concern E. b. boehmi LR Lower Risk E. b. zambesiansis DD Data Deficient (? extinct in wild) E. b. crawshayi DD Data Deficient (? endangered) E. b. chapmani DD Data Deficient E. b. antiquorum LR Lower Risk E. b. burchellii EX Extinct (1930)",,https://www.semanticscholar.org/paper/a96afac8e2934d975a05183bf6069f8fcdadc532,
2150,On Lower Bounds for the Capacity of Deletion Channels,"This correspondence considers binary deletion channels, where bits are deleted independently with probability d; it improves upon the framework used to analyze the capacity of binary deletion channels established by Diggavi and Grossglauser, improving on their lower bounds. Diggavi and Grossglauser considered codebooks with codewords generated by a first-order Markov chain. They only consider typical outputs, where an output is typical if an N bit input gives an N(1-d)(1-epsi) bit output. The improvements in this correspondence arise from two considerations. First, a stronger notion of a typical output from the channel is used, which yields better bounds even for the codebooks studied by Diggavi and Grossglauser. Second, codewords generated by more general processes than first-order Markov chains are considered",2006-10-01,https://www.semanticscholar.org/paper/9845e84f4f9785ee898343b96204d0a255eb1762,IEEE Transactions on Information Theory
3366,The Concept Privacy and Its Biological Basis,Privacy is viewed as a regulatory process that serves to selectively control access of external stimulation to one's self or the flow of information to others. It may be manifested by a physical separation or withdrawal from conspecifics. Privacy may also be manifested by actions that mislead potential competitors as to the motivational status or strength of the individual in question. The degree to which this occurs is often related to simple economic (cost/benefit) principles. But in each species the variables that define the cost/benefit equation may vary. Generalizations about privacy are thus unlikely to prove useful.,1977-07-01,https://www.semanticscholar.org/paper/1bc558ec29f08a9b7f1c2a5a27daf37ec29b1e78,
3644,"The C++ Programming Language, Second Edition",,,https://www.semanticscholar.org/paper/7ef33dadf79f475db560be5d5ae62042b0d29fe1,
494,On the Optimal Bisection of a Polygon,"We show that bisecting a polygon into two equal (possibly disconnected) parts with the smallest possible total perimeter is NP-complete, and it is in fact NP-hard to approximate within any ratio. In contrast, we give a dynamic programming algorithm which finds a subdivision into two parts with total perimeter at most that of the optimum bisection, such that the two parts have areas within e of each other; the time is polynomial in the number of sides of the polygon, and 1/e. When the polygon is convex, or if the parts are required to be connected, then the exact problem can be solved in quadratic time. INFORMS Journal on Computing, ISSN 1091-9856, was published as ORSA Journal on Computing from 1989 to 1995 under ISSN 0899-1499.",1992-11-01,https://www.semanticscholar.org/paper/dcdf8f62ad3f9b7861c288ce0a12d4f9307cee27,INFORMS journal on computing
1152,Measurement of þ b þ X and þ c þ X Production Cross Sections in p p Collisions at ffiffi s p 1⁄4 1 : 96 TeV,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, M. Ahsan, G. D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G.A. Alves, M. Anastasoaie, L. S. Ancu, T. Andeen, B. Andrieu, M. S. Anzelc, M. Aoki, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, A. C. S. Assis Jesus, O. Atramentov, C. Avila, J. BackusMayes, F. Badaud, L. Bagby, B. Baldin, D. V. Bandurin, P. Banerjee, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, G. Blazey, F. Blekman, S. Blessing, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, E. E. Boos, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, X. B. Bu, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, T. H. Burnett, C. P. Buszello, P. Calfayan, B. Calpas, S. Calvet, J. Cammin, M.A. Carrasco-Lizarraga, E. Carrera, W. Carvalho, B. C. K. Casey, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K.M. Chan, A. Chandra, E. Cheu, D. K. Cho, S. Choi, B. Choudhary, L. Christofek, T. Christoudias, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, V. Cuplov, D. Cutts, M. Ćwiok, H. da Motta, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, K. DeVaughan, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, T. Dorland, A. Dubey, L. V. Dudko, L. Duflot, S. R. Dugad, D. Duggan, A. Duperrin, S. Dutt, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V. D. Elvira, Y. Enari, S. Eno, P. Ermolov,38,xx M. Escalier, H. Evans, A. Evdokimov, V.N. Evdokimov, A.V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, C. Garcia, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, W. Geng, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, B. Gómez, A. Goussiou, P. D. Grannis, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Harder, A. Harel, J.M. Hauptman, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, A. P. Heinson, U. Heintz, C. Hensel,22,x K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, T. Hoang, J. D. Hobbs, B. Hoeneisen, M. Hohlfeld, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, N. Huske, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, C. Jarvis, R. Jesik, K. Johns, C. Johnson, M. Johnson, D. Johnston, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, D. Karmanov, P. A. Kasper, I. Katsanos, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y. N. Kharzheev, D. Khatidze, T. J. Kim, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, J.-P. Konrath, A. V. Kozelov, J. Kraus, T. Kuhl, A. Kumar, A. Kupco, T. Kurča, V. A. Kuzmin, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, W.M. Lee, A. Leflat, J. Lellouch, J. Li,78,xx L. Li, Q. Z. Li, S.M. Lietti, J. K. Lim, J. G. R. Lima, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna-Garcia,33,k A.L. Lyon, A.K.A. Maciel, D. Mackin, R. J. Madaras, P. Mättig, A. Magerkurth, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, Y. Maravin, B. Martin, R. McCarthy, M.M. Meijer, A. Melnitchouk, L. Mendoza, P. G. Mercadante, M. Merkin, K.W. Merritt, A. Meyer, J. Meyer,22,x J. Mitrevski, R.K. Mommsen, N. K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, H. A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, D. C. O’Neil, G. Obrant, C. Ochando, D. Onoprienko, N. Oshima, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, M. Padilla, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park,22,x S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, M. Petteni, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma,33,{ V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, B.G. Pope, A.V. Popov, C. Potter, W. L. Prado da Silva, H. B. Prosper, S. Protopopescu, J. Qian, A. Quadt,22,x B. Quinn, A. Rakitine, M. S. Rangel, K. Ranjan, P. N. Ratoff, P. Renkel, P. Rich, PRL 102, 192002 (2009) P HY S I CA L R EV I EW LE T T E R S week ending 15 MAY 2009",,https://www.semanticscholar.org/paper/4c08d73e1e4e60e4602fe2e5e8e6357af4c1cbf1,
3546,"The C++ Programming Language, 4th Edition","From the Publisher: 
This is a complete rewrite of the most widely read and most trusted book on C++. Based on the ANSI/ISO C++ final draft, this book covers the C++ language, its standard library, and key design techniques as an integrated whole. The C++ Programming Language provides comprehensive coverage of C++ language features and standard library components. With this third edition, Stroustrup makes C++ even more accessible to those new to the language while adding information and techniques that even expert C++ programmers will find invaluable.",2013-05-19,https://www.semanticscholar.org/paper/dc2f57bfcd9d2d66f5ac865e70c46a5f0a25c973,
23,Hip and trendy: Characterizing emerging trends on Twitter,"Twitter, Facebook, and other related systems that we call social awareness streams are rapidly changing the information and communication dynamics of our society. These systems, where hundreds of millions of users share short messages in real time, expose the aggregate interests and attention of global and local communities. In particular, emerging temporal trends in these systems, especially those related to a single geographic area, are a significant and revealing source of information for, and about, a local community. This study makes two essential contributions for interpreting emerging temporal trends in these information systems. First, based on a large dataset of Twitter messages from one geographic area, we develop a taxonomy of the trends present in the data. Second, we identify important dimensions according to which trends can be categorized, as well as the key distinguishing features of trends that can be derived from their associated messages. We quantitatively examine the computed features for different categories of trends, and establish that significant differences can be detected across categories. Our study advances the understanding of trends on Twitter and other social awareness streams, which will enable powerful applications and activities, including user-driven real-time information services for local communities. © 2011 Wiley Periodicals, Inc.",2011-05-01,https://www.semanticscholar.org/paper/aedca557e79d36d4c3f81f76a247a98f1cfffcc4,J. Assoc. Inf. Sci. Technol.
178,From Battlefields to Elections: Winning Strategies of Blotto and Auditing Games,"Mixed strategies are often evaluated based on the expected payoff that they guarantee. This is not always desirable. In this paper, we consider games for which maximizing the expected payoff deviates from the actual goal of the players. To address this issue, we introduce the notion of a (u, p)-maxmin strategy which ensures receiving a minimum utility of u with probability at least p. We then give approximation algorithms for the problem of finding a (u, p)-maxmin strategy for these games. The first game that we consider is Colonel Blotto, a well-studied game that was introduced in 1921. In the Colonel Blotto game, two colonels divide their troops among a set of battlefields. Each battlefield is won by the colonel that puts more troops in it. The payoff of each colonel is the weighted number of battlefields that she wins. We show that maximizing the expected payoff of a player does not necessarily maximize her winning probability for certain applications of Colonel Blotto. For example, in presidential elections, the players' goal is to maximize the probability of winning more than half of the votes, rather than maximizing the expected number of votes that they get. We give an exact algorithm for a natural variant of continuous version of this game. More generally, we provide constant and logarithmic approximation algorithms for finding (u, p)-maxmin strategies. We also introduce a security game version of Colonel Blotto which we call auditing game. It is played between two players, a defender and an attacker. The goal of the defender is to prevent the attacker from changing the outcome of an instance of Colonel Blotto. Again, maximizing the expected payoff of the defender is not necessarily optimal. Therefore we give a constant approximation for (u, p)-maxmin strategies.",2018-01-07,https://www.semanticscholar.org/paper/0dab34a0bb73b2b966a7edfddfce414646fe6986,ACM-SIAM Symposium on Discrete Algorithms
2136,Sound source above a rough absorbent plane,"The scattering of sound from a steady simple source above a rough absorbent plane is treated in the context of the theory of geometrical acoustics. The roughness of the plane is described by a scalar parameter which defines the fraction of the reflected sound energy which is scattered randomly (Lambert’s Law), the remainder being reflected specularly (Snell’s Law). An image principle is derived; the specular image source is nondirectional and the random image source is directional.",1980-03-01,https://www.semanticscholar.org/paper/6317d69419b140d97a11e652ff66b084a543f782,
2180,Human neutrophils activated via TLR8 promote Th17 polarization through IL‐23,"Human neutrophils contribute to the regulation of inflammation via the generation of a range of cytokines that affect all elements of the immune system. Here, we investigated their ability to express some of the members of the IL‐12 family after incubation with TLR8 agonists. Highly pure human neutrophils were thus incubated for up to 48 h with or without R848, or other TLR8 agonists, to then measure the expression levels of transcripts and proteins for IL‐12 family member subunits by RNA‐seq, reverse transcription quantitative PCR, and ELISA. We show a TLR8‐mediated inducible expression of IL‐12B and IL‐23A, but not IL‐12A, mRNA, which occurs via chromatin remodeling (as assessed by ChIP‐seq), and subsequent production of IL‐23 and IL‐12B, but no IL‐12, proteins. Induction of IL‐23 requires endogenous TNF‐α, as both mRNA and protein levels were blocked in TLR8‐activated neutrophils via a TNF‐α‐neutralizing Ab. We also show that supernatants from TLR8‐activated neutrophils, but not autologous monocytes, induce the differentiation of Th17 cells from naïve T cells in an IL‐23‐dependent fashion. This study unequivocally demonstrates that highly pure human neutrophils express and produce IL‐23, further supporting the key roles played by these cells in the important IL‐17/IL‐23 network and Th17 responses.",2019-06-01,https://www.semanticscholar.org/paper/7112dd22a835bf5efcfd79a514e42c7cea409764,Journal of Leukocyte Biology
1065,Search for excited electrons in pp collisions at √s = 1.96 TeV,,,https://www.semanticscholar.org/paper/e48d10db73997de3d2a877b7ec968597f38089cf,
2096,CONSTRUCTING WEB-BASED HOSPITAL EXECUTIVE INFORMATION SYSTEM AND AN EMPIRICAL STUDY,"ABSTRACT With the development of information technology, the decision makers have to deal with massive information and obtain the useful information in time for supporting their decisions and maintaining the competitive advantages of their organizations. Therefore, developing Executive Information System (EIS) has become an important issue for both research and practical needs. However, few studies have been done to apply EIS in the hospital management. This study proposes a framework for constructing a Hospital Executive Information System (HEIS) based on the methodologies including system engineering, EIS, decision analysis, and key performance indexes. Furthermore, using a hospital as an empirical study, we construct a web-based HEIS with three functional modules including: i) an information preparation and visualization module; ii) an information retrieval and decision support module; and iii) a knowledge management module. The results of the empirical study show that HEIS can help managers to grasp important information before making decisions and thus improve the quality of their decisions.",2004-01-01,https://www.semanticscholar.org/paper/8862415d182e737807dea01d4959078ef3f95df6,
2332,Biochemistry and Physiology of the Neutrophil,1. Neutrophils and host defence: the fight against infection 2. The development and structure of neutrophils 3. The generation and recognition of neutrophil-activating factors: structure and function of neutrophil receptors 4. The cytoskeleton: the molecular framework regulating cell shape and the traffic of intracellular components 5. The respiratory burst: the generation of reactive oxygen metabolites and their role in microbial killing 6. Neutrophil activation: the production of intracellular signalling molecules 7. Neutrophil priming: regulation of neutrophil function during inflammatory activation 8. Disorders of neutrophil function Index.,1994-03-01,https://www.semanticscholar.org/paper/b730235f3bb58aa1e0dfc064625b3b76a298c7cc,
857,On the value of information in distributed decision-making (extended abstract),The treatment of rice polish by drying into a specific moisture content so that the rice polish is stabilized and resists deterioration for long periods of time even when stored without refrigeration. The moisture content ranges from 5.8 to 8.0 grams of moisture/100 grams of fat free solids which corresponds to a single molecular layer of water (a mono layer film) on each rice polish particle. This minimizes both fatty acid development and oxidative rancidity.,1991-07-01,https://www.semanticscholar.org/paper/40b860d3ce4357660192ee43e27094e350bce50f,ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing
846,Online minimization of transition systems (extended abstract),"We are given a transition system implicitly through a compact representation and wish to perform simultaneously reachability analysis and minimization without constructing first the whole system graph. We present an algorithm for this problem that applies to general systems, provided we have appropriate primitive operations for manipulating blocks of states and we can determine termination; the number of operations needed to construct the minimal reachable graph is quadratic in the size of this graph. We specialize the method to obtain efficient algorithms for extended finite state machines that apply separable affine transformations on the variables.",1992-07-01,https://www.semanticscholar.org/paper/0383138611eb997fe52ba8a3b96d727580a627e6,Symposium on the Theory of Computing
700,The Platform Design Problem,,2020-09-13,https://www.semanticscholar.org/paper/5f392561552741d9e6aba1951bc7663e3698d417,Workshop on Internet and Network Economics
237,Sparse covers for sums of indicators,,2013-06-05,https://www.semanticscholar.org/paper/04e8bf2e697790906bce721301fe22eebd5c3f24,arXiv.org
2543,IBM Research Report activeNotes: Computer-Assisted Creation of Patient Progress Notes in a Hospital Environment,,,https://www.semanticscholar.org/paper/4330574d5dd55db0ce83cda05435aef307be0b7d,
2996,Effective Performance Issue Diagnosis with Value-Assisted Cost Profiling,"Diagnosing performance issues is often difficult, especially when they occur only during some program executions. Profilers can help with performance debugging, but are ineffective when the most costly functions are not the root causes of performance issues. To address this problem, we introduce a new profiling methodology, value-assisted cost profiling, and a tool vProf. Our insight is that capturing the values of variables can greatly help diagnose performance issues. vProf continuously records values while profiling normal and buggy program executions. It identifies anomalies in the values and the functions where they occur to pinpoint the real root causes of performance issues. Using a set of 15 real-world performance bugs in four widely used applications, we show that vProf is effective at diagnosing all of the issues while other state-of-the-art tools diagnose only a few of them. We further use vProf to diagnose longstanding performance issues in these applications that have been unresolved for over four years.",2023-05-08,https://www.semanticscholar.org/paper/4831c52655050e37dd61c98b2c984b1060eafe9c,European Conference on Computer Systems
1298,Measurement of the Ab lifetime in the exclusive decay Ab → J/ψA,"We have measured the Λ b lifetime using the exclusive decay Λ b → J/ψΛ, based on 1.2 fb -1 of data collected with the DO detector during 2002-2006. From 171 reconstructed Λ b decays, where the J/ψ and A are identified via the decays J/ψ → μ + μ - and Λ→ pπ, we measured the Λ b lifetime to be τ(Λ b ) = 1.218 +0.130 -0.115 (stat) ± 0.042(syst) ps. We also measured the B° lifetime in the decay B° → J/ψ(μ + μ - )K 0 S (π + π - ) to be τ(B 0 ) = 1.501 +0.078 -0.074 (stat) ± 0.050(syst) ps, yielding a lifetime ratio of τ(Λ b )/τ(B 0 ) = 0.811 +0.096 -0.087 (stat) ± 0.034(syst).",,https://www.semanticscholar.org/paper/f2e44e0cac8054e049ab6617a5e399f228651581,
2317,Biochemistry and Physiology of the Neutrophil: The generation and recognition of neutrophil-activating factors: Structure and function of neutrophil receptors,,,https://www.semanticscholar.org/paper/0afdbb5420f8a5f9d046134af8a71223c6c4b22e,
3422,Energy Aware Scheduling for Weighted Completion Time and Weighted Tardiness,,2011-10-04,https://www.semanticscholar.org/paper/c9df0bccf3132346c2bf97bfc19b3e4fe3f75da5,arXiv.org
233,Unsupervised Learning through Prediction in a Model of Cortex,"We propose a primitive called PJOIN, for ""predictive join,"" which combines and extends the operations JOIN and LINK, which Valiant proposed as the basis of a computational theory of cortex. We show that PJOIN can be implemented in Valiant's model. We also show that, using PJOIN, certain reasonably complex learning and pattern matching tasks can be performed, in a way that involves phenomena which have been observed in cognition and the brain, namely memory-based prediction and downward traffic in the cortical hierarchy.",2014-12-26,https://www.semanticscholar.org/paper/b4f00525d7fca5c1cfe2e698683e38de42c56925,arXiv.org
1968,Data Mining for Optimizing IC Feature Designs to Enhance Overall Wafer Effectiveness,"As global competition continues to strengthen in semiconductor industry, semiconductor companies have to continuously advance manufacturing technology and improve productivity to maintain competitive advantages. Die cost is significantly influenced by wafer productivity that is determined by yield rate and the number of gross dies per wafer. However, little research has been done on design for manufacturing and productivity enhancement through increasing the gross die number per wafer and decreasing the required shot number for exposure. This paper aims to propose a novel approach to improve overall wafer effectiveness via data mining to generate the optimal IC feature designs that can bridge the gap between integrated circuit (IC) design and wafer fabrication by providing chip designer with the optimal IC feature size in the design phase to increase gross dies and reduce the required shots. An empirical study was conducted in a leading semiconductor company for validation. The results have shown that the proposed approach can effectively enhance wafer productivity. Indeed, the developed solution has been implemented in the company to provide desired IC features to IC designers to enhance overall wafer effectiveness.",2014-02-01,https://www.semanticscholar.org/paper/a54202cfaec90b2e02855d8c67954399a235b8ed,IEEE transactions on semiconductor manufacturing
2159,Neutrophil function following treatment of psoriatic arthritis patients with secukinumab: altered cytokine signalling but no impairment of host defence.,"OBJECTIVE
Identifying that dysfunction of the IL-23/17 axis underlies psoriatic arthritis (PsA) has led to the development of effective targeted therapies, such as the IL-17A inhibitor, secukinumab. As IL-17A stimulates the secretion of neutrophil chemoattractants, such as CXCL8 (IL-8), we examined the effect of secukinumab on neutrophil function in PsA.


METHODS
Nineteen patients with active PsA were treated with secukinumab. Clinical response (PsARC and PASI) and peripheral blood neutrophil function (apoptosis, receptor expression, phagocytosis/killing, chemotaxis and RNA expression) were measured at 12 week intervals for 48 weeks and compared with age- and sex-matched healthy controls.


RESULTS
At 12 weeks 12/16 (75%) had a PsARC response (100% at 36 weeks) and 10/14 (71%) achieved a PASI90. At baseline, there were no differences in PsA neutrophil ROS generation, constitutive or cytokine-delayed apoptosis, chemotaxis or phagocytosis of opsonised Staphylococcus aureus, compared to healthy controls. Similarly, there were no differences in these functions from baseline to 12-weeks of therapy. However, surface levels of CD11b/CD18 and CD63 increased and expression of CD16 decreased during therapy. In addition, in a sub-group of early (12 week) responders to secukinumab, RNA-seq revealed transcriptome changes predicting down-regulation of cytokine signalling and chemotaxis pathways and up-regulation of de novo gene expression pathways, including translation initiation, mRNA catabolism and translation.


CONCLUSION
Complex changes in the properties of circulating neutrophils occur with secukinumab treatment in PsA that may indicate altered responsiveness to changes in both local and systemic levels of pro-inflammatory cytokines. However, host defence processes of neutrophils were unaltered.",2023-01-06,https://www.semanticscholar.org/paper/bbf61d62abfa4ab9e38cdc954fbc9af095e667e4,Rheumatology
1430,Results of the Cryogenic Dark Matter Search (CDMS) Obtained with Thermistor-Instrumented Germanium Calorimeters,"WIMP scattering in a semiconductor target would produce less ionization per unit deposited energy than gamma rays do. Therefore, discrimination against background gamma rays can be achieved by simultaneously measuring the ioniza-tion and heat produced by scattering events. The Cryogenic Dark Matter Search CDMS experiment uses germanium and silicon detectors cooled to 20 mK to attempt to detect weakly interacting dark matter. We discuss recent results obtained with NTD thermistor-instrumented germanium detectors. Currently, the background rejection capability of these devices is compromised by poor charge collection at the detector surfaces. Nevertheless, the limits on WIMP interaction rates derived from our measurements are close to the best achieved by other methods, with exciting prospects for improvement in the near future.",,https://www.semanticscholar.org/paper/9ee4253e6197006cd9eed1528169a3ebfd9b4446,
3106,Experiences teaching operating systems using virtual platforms and linux,"Operating system courses teach students much more when they provide hands-on kernel-level project experience with a real operating system. However, enabling a large class of students to do kernel development can be difficult. To address this problem, we created a virtual kernel development environment in which operating systems can be developed, debugged, and rebooted in a shared computer facility without affecting other users. Using virtual machines and remote display technology, our virtual kernel development laboratory enables even distance learning students at remote locations to participate in kernel development projects with on-campus students. We have successfully deployed and used our virtual kernel development environment together with the open-source Linux kernel to provide kernel-level project experiences for over nine hundred students in the introductory operating system course at Columbia University.",,https://www.semanticscholar.org/paper/369699cb9e83032b6de03deb02a1029dee4ae030,Technical Symposium on Computer Science Education
1728,Scalable Recommendation with Poisson Factorization,"We develop a Bayesian Poisson matrix factorization model for forming recommendations from sparse user behavior data. These data are large user/item matrices where each user has provided feedback on only a small subset of items, either explicitly (e.g., through star ratings) or implicitly (e.g., through views or purchases). In contrast to traditional matrix factorization approaches, Poisson factorization implicitly models each user's limited attention to consume items. Moreover, because of the mathematical form of the Poisson likelihood, the model needs only to explicitly consider the observed entries in the matrix, leading to both scalable computation and good predictive performance. We develop a variational inference algorithm for approximate posterior inference that scales up to massive data sets. This is an efficient algorithm that iterates over the observed entries and adjusts an approximate posterior over the user/item representations. We apply our method to large real-world user data containing users rating movies, users listening to songs, and users reading scientific papers. In all these settings, Bayesian Poisson factorization outperforms state-of-the-art matrix factorization methods.",2013-11-07,https://www.semanticscholar.org/paper/1b145525d29300f47330d2486f2cf3509fe2308a,arXiv.org
2056,Modeling strategic semiconductor assembly outsourcing decisions based on empirical settings,,2008-01-12,https://www.semanticscholar.org/paper/b561da237a72782cc38c534a6a6fa699bf3cc1ac,OR Spectr.
1179,"Search for next-to-minimal supersymmetric higgs bosons in the h→aa→μμμμ, μμττ channels using pp̄ collisions at s=1.96TeV","We report on a first search for production of the lightest neutral CP-even Higgs boson (h) in the next-to-minimal supersymmetric standard model, where h decays to a pair of neutral pseudoscalar Higgs bosons (α), using 4.2 fb -1 of data recorded with the DO detector at Fermilab. The α bosons are required to either both decay to μ + μ - or one to μ + μ - and the other to τ + τ - . No significant signal is observed, and we set limits on its production as functions of M a and M h .",2009-08-03,https://www.semanticscholar.org/paper/bc7e1ff98b16ab1630bbcebeb0ae2ed9dce6d7ed,
2600,Seeing into the past: creating a 3D modeling pipeline for archaeological visualization,"Archaeology is a destructive process in which accurate and detailed recording of a site is imperative. As a site is exposed, documentation is required in order to recreate and understand the site in context. We have developed a 3D modeling pipeline that can assist archaeologists in the documentation effort by building rich, geometrically and photometrically accurate 3D models of the site. The modeling effort begins with data acquisition (images, range scans, GIS data, and video) and ends with the use of a sophisticated visualization tool that can be used by researchers to explore and understand the site. The pipeline includes new methods for shadow-based registration of 2D images and temporal change detection. Our multimodal augmented reality system allows users wearing head-tracked, see-through, head-worn displays to visualize the site model and associated archaeological artifacts, and to interact with them using speech and gesture.",2004-09-06,https://www.semanticscholar.org/paper/52a7435d23345c156be50bc15a450f14c3b5605a,"Proceedings. 2nd International Symposium on 3D Data Processing, Visualization and Transmission, 2004. 3DPVT 2004."
2548,"Session details: Scratching, tapping, rubbing and rolling",,2008-10-19,https://www.semanticscholar.org/paper/b74d9c5d49fd55405c6f391b9f880bd090112a2e,Proceedings of the 21st annual ACM symposium on User interface software and technology
666,Solving Linear Algebra by Program Synthesis,"We solve MIT's Linear Algebra 18.06 course and Columbia University's Computational Linear Algebra COMS3251 courses with perfect accuracy by interactive program synthesis. This surprisingly strong result is achieved by turning the course questions into programming tasks and then running the programs to produce the correct answers. We use OpenAI Codex with zero-shot learning, without providing any examples in the prompts, to synthesize code from questions. We quantify the difference between the original question text and the transformed question text that yields a correct answer. Since all COMS3251 questions are not available online the model is not overfitting. We go beyond just generating code for questions with numerical answers by interactively generating code that also results visually pleasing plots as output. Finally, we automatically generate new questions given a few sample questions which may be used as new course content. This work is a significant step forward in solving quantitative math problems and opens the door for solving many university level STEM courses by machine.",2021-11-16,https://www.semanticscholar.org/paper/4e40595d6ecba027cebb4f2e3b43ae44bcf51daf,arXiv.org
1456,First results from SLD with polarized electron beam at SLC,"The SLAC Linear Collider (SLC) has been modified to collide a longitudinally polarized electron beam with the unpolarized positron beam. We review the beginning of polarized beam running at the SLC, and report on the measurement of the left-right cross section asymmetry (A{sub LR}) made with a sample of 10,224 Z decays collected over the course of the 1992 run. The average beam polarization for this set of Z decays was 22.4 {plus_minus} 0.6%(syst.). A{sub LR} was measured to be 0.100 {plus_minus} 0.044(stat.) {plus_minus} 0.004(syst.). From this measurement, the weak mixing angle defined at the Z boson pole is determined to be sin{sup 2}{theta}{sup eff}{sub W} = 0.2378 {plus_minus} 0.0056 {plus_minus} 0.0005.",1992-12-01,https://www.semanticscholar.org/paper/129615341cc672596188b71bebb854de2b22f8b4,
109,The Stanford InfoBus and Its Service Layers: Augmenting the Internet with High-Level Information Management Protocols,,,https://www.semanticscholar.org/paper/4e54e204e30f8143b48e62a3822607df87ca53e9,The MeDoc Approach
1259,Measurement of the electron charge asymmetry in pp[over ]-->W+X-->enu+X events at sqrt[s]=1.96 TeV.,"We present a measurement of the electron charge asymmetry in pp[over ]-->W+X-->enu+X events at a center of mass energy of 1.96 TeV using 0.75 fb(-1) of data collected with the D0 detector at the Fermilab Tevatron Collider. The asymmetry is measured as a function of the electron transverse momentum and pseudorapidity in the interval (-3.2, 3.2) and is compared with expectations from next-to-leading order calculations in perturbative quantum chromodynamics. These measurements will allow more accurate determinations of the proton parton distribution functions.",,https://www.semanticscholar.org/paper/dc29a175b073c6efb2265886d1bc3a7121c1c2c9,Physical Review Letters
1634,Proximity Variational Inference,"Variational inference is a powerful approach for approximate posterior inference. However, it is sensitive to initialization and can be subject to poor local optima. In this paper, we develop proximity variational inference (PVI). PVI is a new method for optimizing the variational objective that constrains subsequent iterates of the variational parameters to robustify the optimization path. Consequently, PVI is less sensitive to initialization and optimization quirks and finds better local optima. We demonstrate our method on three proximity statistics. We study PVI on a Bernoulli factor model and sigmoid belief network with both real and synthetic data and compare to deterministic annealing (Katahira et al., 2008). We highlight the flexibility of PVI by designing a proximity statistic for Bayesian deep learning models such as the variational autoencoder (Kingma and Welling, 2014; Rezende et al., 2014). Empirically, we show that PVI consistently finds better local optima and gives better predictive performance.",2017-05-24,https://www.semanticscholar.org/paper/b5c504b1383170939a1b122e400a906332fe0423,International Conference on Artificial Intelligence and Statistics
1044,Projected sensitivities of the LUX-ZEPLIN experiment to new physics via low-energy electron recoils,"LUX-ZEPLIN (LZ) is a dark matter detector expected to obtain world-leading sensitivity to weakly interacting massive particles (WIMPs) interacting via nuclear recoils with a ~7-tonne xenon target mass. This manuscript presents sensitivity projections to several low-energy signals of the complementary electron recoil signal type: 1) an effective neutrino magnetic moment and 2) an effective neutrino millicharge, both for pp-chain solar neutrinos, 3) an axion flux generated by the Sun, 4) axion-like particles forming the galactic dark matter, 5) hidden photons, 6) mirror dark matter, and 7) leptophilic dark matter. World-leading sensitivities are expected in each case, a result of the large 5.6t 1000d exposure and low expected rate of electron recoil backgrounds in the $<$100keV energy regime. A consistent signal generation, background model and profile-likelihood analysis framework is used throughout.",2021-02-23,https://www.semanticscholar.org/paper/16174d4ab330427e8100d1b551359c46121c875d,Physical Review D
1137,"Search for single top quarks in the tau + jets channel using 4.8 fb-1 of p over(p, ̄) collision data",,2010-06-07,https://www.semanticscholar.org/paper/f1eee28b22565edbbb0affe8206b6d086449a63e,
3553,Software Development for Infrastructure,"Infrastructure software needs more stringent correctness, reliability, efficiency, and maintainability requirements than non- essential applications. This implies greater emphasis on up-front design, static structure enforced by a type system, compact data structures, simplified code structure, and improved tool support. Education for infrastructure and application developers should differ to reflect that emphasis. This Web extra video features Bjarne Stroustrup of Texas A&M University discussing how C++ can help improve the reliability, maintainability, and performance of infrastructure software. He also describes features that are part of the latest versions of the C++ language.",,https://www.semanticscholar.org/paper/eb24f14677fab1ae65c3f558c899c2c256c147ae,Computer
458,An approximation scheme for planar graph TSP,We consider the special case of the traveling salesman problem (TSP) in which the distance metric is the shortest-path metric of a planar unweighted graph. We present a polynomial-time approximation scheme (PTAS) for this problem.,1995-10-23,https://www.semanticscholar.org/paper/ddf784c8e12525143feb73a2fcecf8ef309db1eb,Proceedings of IEEE 36th Annual Foundations of Computer Science
1839,Statistical modeling of biomedical corpora: mining the Caenorhabditis Genetic Center Bibliography for genes related to life span,,,https://www.semanticscholar.org/paper/2205bc21bf3fb324bb96fad5c32c3e2cfd7304ee,BMC Bioinformatics
1390,[Formula Presented] production cross section in [Formula Presented] collisions at [Formula Presented],,,https://www.semanticscholar.org/paper/c5244c1f39ad5fafb2aa4c9a9b3dae68e460116b,
921,Worst-Case Ratios for Planar Graphs and the Method of Induction on Faces (Extended Abstract),,,https://www.semanticscholar.org/paper/411a2cf2ef4f61cc05c72170d671d4cba1d056cc,IEEE Annual Symposium on Foundations of Computer Science
2641,View management for virtual and augmented reality,"We describe a view-management component for interactive 3D user interfaces. By view management, we mean maintaining visual constraints on the projections of objects on the view plane, such as locating related objects near each other, or preventing objects from occluding each other. Our view-management component accomplishes this by modifying selected object properties, including position, size, and transparency, which are tagged to indicate their constraints. For example, some objects may have geometric properties that are determined entirely by a physical simulation and which cannot be modified, while other objects may be annotations whose position and size are flexible.We introduce algorithms that use upright rectangular extents to represent on the view plane a dynamic and efficient approximation of the occupied space containing the projections of visible portions of 3D objects, as well as the unoccupied space in which objects can be placed to avoid occlusion. Layout decisions from previous frames are taken into account to reduce visual discontinuities. We present augmented reality and virtual reality examples to which we have applied our approach, including a dynamically labeled and annotated environment.",2001-11-11,https://www.semanticscholar.org/paper/11035becfa4b6d71dac0d647abf78d201bf05417,ACM Symposium on User Interface Software and Technology
1404,D0 Run IIB upgrade technical design report,,,https://www.semanticscholar.org/paper/fef992930569b87bbd369f01ec105d761115ec19,
3175,Zebras of all stripes repel biting flies at close range,,2022-11-03,https://www.semanticscholar.org/paper/44331c7df0d282182757b593179155c999c1e364,Scientific Reports
2822,LPS-Induced Galectin-3 Oligomerization Results in Enhancement of Neutrophil Activation,"Galectin-3 (Gal 3) is a glycan-binding protein that can be secreted by activated macrophages and mast cells at inflammation sites and plays an important role in inflammatory diseases caused by Bacteria and their products, such as lipopolysaccharides (LPS). Although it is well established that Gal 3 can interact with LPS, the pathophysiological importance of LPS/Gal 3 interactions is not fully understood. Data presented herein demonstrate for the first time that the interaction of Gal 3, either via its carbohydrate binding C-terminal domain or via its N-terminal part, with LPS from different bacterial strains, enhances the LPS-mediated neutrophil activation in vitro. Gal 3 allowed low LPS concentrations (1 µg/mL without serum, 1 ng/mL with serum) to upregulate CD11b expression and reactive oxygen species (ROS) generation on human neutrophils in vitro and drastically enhanced the binding efficiency of LPS to the neutrophil surface. These effects required LPS preincubation with Gal 3, before neutrophil stimulation and involved specific Gal 3/LPS interaction. A C-terminal Gal-3 fragment, which retains the lectin domain but lacks the N-terminal part, was still able to bind both to Escherichia coli LPS and to neutrophils, but had lost the ability to enhance neutrophil response to LPS. This result emphasizes the importance of an N-terminus-mediated Gal 3 oligomerization induced by its interaction with LPS. Finally we demonstrated that Balb/C mice were more susceptible to LPS-mediated shock when LPS was pretreated with Gal 3. Altogether, these results suggest that multimeric interactions between Gal 3 oligomers and LPS potentiate its pro-inflammatory effects on neutrophils.",2011-10-21,https://www.semanticscholar.org/paper/882a9d9af87852f7a281c14101107d5bf9f28322,PLoS ONE
1848,Statistical modeling of biomedical corpora: mining the Caenorhabditis Genetic Center Bibliography for genes related to life span,,2006-05-08,https://www.semanticscholar.org/paper/afd354506626d4b9ee30de86239a82d586f5800c,BMC Bioinformatics
703,Computational Complexity of the Hylland-Zeckhauser Scheme for One-Sided Matching Markets,"In 1979, Hylland and Zeckhauser \cite{hylland} gave a simple and general scheme for implementing a one-sided matching market using the power of a pricing mechanism. Their method has nice properties -- it is incentive compatible in the large and produces an allocation that is Pareto optimal -- and hence it provides an attractive, off-the-shelf method for running an application involving such a market. With matching markets becoming ever more prevalant and impactful, it is imperative to finally settle the computational complexity of this scheme. We present the following partial resolution: 1. A combinatorial, strongly polynomial time algorithm for the special case of $0/1$ utilities. 2. An example that has only irrational equilibria, hence proving that this problem is not in PPAD. Furthermore, its equilibria are disconnected, hence showing that the problem does not admit a convex programming formulation. 3. A proof of membership of the problem in the class FIXP. We leave open the (difficult) question of determining if the problem is FIXP-hard. Settling the status of the special case when utilities are in the set $\{0, {\frac 1 2}, 1 \}$ appears to be even more difficult.",2020-04-03,https://www.semanticscholar.org/paper/cb3815c6c806b8672ea3d64c395a3e8b6bddc0a6,Information Technology Convergence and Services
3163,The Standard Map Machine,Abstract : The Standard Map Machine (SMM) is designed as an answer to the intensive computational requirements involved in the study of chaotic behavior in nonlinear systems. The high-speed and high-precision performance of this computer is due to its simple architecture specialized to the numerical computations required of nonlinear systems. This report will discuss the design and implementation of this special-purpose machine. (JHD),1989-09-01,https://www.semanticscholar.org/paper/51f453967d852cd1c0247e7ce61bd64bc739e95e,
2786,Intracranial alternating current stimulation facilitates neurogenesis in a mouse model of Alzheimer’s disease,,2020-07-23,https://www.semanticscholar.org/paper/9f8d2b8f28a17c052b8f1bc7c407261c917ac429,Alzheimer's Research & Therapy
711,Reachability for Branching Concurrent Stochastic Games,"We give polynomial time algorithms for deciding almost-sure and limit-sure reachability in Branching Concurrent Stochastic Games (BCSGs). These are a class of infinite-state imperfect-information stochastic games that generalize both finite-state concurrent stochastic reachability games, as well as branching simple stochastic reachability games.",2018-06-01,https://www.semanticscholar.org/paper/738aa8b51fc76c3a2ae9048e37e38fcc4bc3e511,"International Colloquium on Automata, Languages and Programming"
2833,Endogenous galectin-3 is localized in membrane lipid rafts and regulates migration of dendritic cells.,,2009-03-01,https://www.semanticscholar.org/paper/a6afe20d538480398bc3b077885eb312fc5d6573,Journal of Investigative Dermatology
2983,"Performance Measures as a Function of Trial Type and Time on Task , Separately Averaged for Each of the Six Consecutive Time Bins","This section expands on the analysis of Section 3 in the original manuscript regarding the relation of the SHGP to Hierarchical Gamma (HGP) and Hierarchical Dirichlet processes (HDP) as seen in Table 1. The SHGP is a prior over the weight matrix J as opposed to the HDP which is a prior over the transition matrix P . This difference is crucial, since it allows for direct manipulation of the weights, enabling us to enforce symmetry and thereby make the Markov chain reversible. The SHGP can be viewed as a HGP where symmetry is imposed on the produced weight matrix J . However, there are subtle differences in the construction of the weight matrix. Looking at the Table 1, both processes, the HGP and SHGP, use the Gamma process in a hierarchical way. The HGP constructs each row j in the weight matrix by sampling from the same Gamma process ΓP (α̃, G0),∀j, as opposed to the SHGP where each row is sampled by a Gamma process with a different shape parameter dependent on the corresponding base weight wj . This is a modelling choice and by choosing the base measure μ of the weight matrix to be the G0 rather than the product G0 × G0 the SHGP (with no symmetrization imposed) becomes identical to the HGP.",,https://www.semanticscholar.org/paper/bfe505504d15bc9004b5242929fd675182a3bf15,
302,ErgasÐa-Episkìphsh dhmosÐeushc : Computing Equilibria in Multi-player Games,"Sthn paroÔsa ergasÐa ja knoume mia episkìphsh thc dhmosÐeushc: Computing Equilibria in Multi-Player Games twn Papadimitriou kai Roughgarden [Ch.05] (ìpwc faÐnetai ki apì ton tÐtlo!). H dhmosÐeush afor kurÐwc correlated equilibria, mia pio 'genik ' morf issoropÐac apì ta Nash equilibria, pou krÔbei mèsa thc èna eÐdoc sunergasÐac metaxÔ twn paikt ̧n (an kai den eÐnai akrib ̧c ètsi, oi paÐktec exakoloujoÔn kai skèftontai atomik). Ja perigryoume autoÔ tou eÐdouc tic isorropÐec, kai ja doÔme ti neì prosèfere h dhmosÐeush sth melèth tou probl matoc kaj ̧c kai th genik idèa pÐsw apì ta apotelèsmata pou parousizontai.",,https://www.semanticscholar.org/paper/156480cfc2476afef7397ea856a11c9393150e2c,
322,On The Approximability Of The Traveling Salesman Problem,,2006-02-01,https://www.semanticscholar.org/paper/c62bd5870663dc332993690e2cf638318539f396,Comb.
756,Computing with Continuous-Time Liapunov Systems,"Powered by TCPDF (www.tcpdf.org) This material is protected by copyright and other intellectual property rights, and duplication or sale of all or part of any of the repository collections is not permitted, except that material may be duplicated by you for your research use or educational purposes in electronic or print form. You must obtain permission for any other use. Electronic or print copies may not be offered, whether for sale or otherwise to anyone who is not an authorised user. Síma, Jirí; Orponen, Pekka",,https://www.semanticscholar.org/paper/20e64c4453ce2197d5deb437ab2735f43cdbb02f,
1873,UNISON decision framework for hybrid optimization of wastewater treatment and recycle for Industry 3.5 and cleaner semiconductor manufacturing,,,https://www.semanticscholar.org/paper/18e16a5158e9c8eedb7c611a41a79496ef976040,"Resources, Conservation and Recycling"
564,The Complexity of Cubical Graphs,,1985-07-01,https://www.semanticscholar.org/paper/e09d85193f17a9810a40840444611f12f690821d,Information and Control
2415,A Testbed for Exploring Multi-Level Precueing in Augmented Reality,"Precueing information about upcoming subtasks prior to performing them has the potential to make an entire task faster and easier to accomplish than cueing only the current subtask. Most AR and VR research on precueing has addressed path-following tasks requiring simple actions at a series of locations, such as pushing a button or just visiting that location. We present a testbed for exploring multi-level precueing in a richer task that requires the user to move their hand between specified locations, transporting an object between some of them, and rotating it to a designated orientation.",2022-03-01,https://www.semanticscholar.org/paper/b86aa99029b3d7ac9833d464ddf9994d12e1928f,2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)
1192,Measurement of gamma+b+X and gamma+c+X Production Cross Sections in pp[over ] Collisions at sqrt[s]=1.96 TeV.,"First measurements of the differential cross sections d;{3}sigma/(dp_{T};{gamma}dy;{gamma}dy;{jet}) for the inclusive production of a photon in association with a heavy quark (b, c) jet are presented, covering photon transverse momenta 30<p_{T};{gamma}<150 GeV, photon rapidities |y;{gamma}|<1.0, jet rapidities |y;{jet}|<0.8, and jet transverse momenta p_{T};{jet}>15 GeV. The results are based on an integrated luminosity of 1 fb;{-1} in pp[over ] collisions at sqrt[s]=1.96 TeV recorded with the D0 detector at the Fermilab Tevatron Collider. The results are compared with next-to-leading order perturbative QCD predictions.",,https://www.semanticscholar.org/paper/f9fc95db5c46fbe1329f4687d50d116ef8cfdbc7,Physical Review Letters
2467,[POSTER] Interactive Visualizations for Monoscopic Eyewear to Assist in Manually Orienting Objects in 3D,"Assembly or repair tasks often require objects to be held in specific orientations to view or fit together. Research has addressed the use of AR to assist in these tasks, delivered as registered overlaid graphics on stereoscopic head-worn displays. In contrast, we are interested in using monoscopic head-worn displays, such as Google Glass. To accommodate their small monoscopic field of view, off center from the user's line of sight, we are exploring alternatives to registered overlays. We describe four interactive rotation guidance visualizations for tracked objects intended for these displays.",2015-09-29,https://www.semanticscholar.org/paper/469c16953e13f4d4c7b947782de491331c2fd54a,2015 IEEE International Symposium on Mixed and Augmented Reality
709,Fixed Point Computation Problems and Facets of Complexity (Invited Talk),"Many problems from a wide variety of areas can be formulated mathematically as the problem of computing a fixed point of a suitable given multivariate function. Examples include a variety of problems from game theory, economics, optimization, stochastic analysis, verification, and others. In some problems there is a unique fixed point (for example if the function is a contraction); in others there may be multiple fixed points and any one of them is an acceptable solution; while in other cases the desired object is a specific fixed point (for example the least fixed point or greatest fixed point of a monotone function). In this talk we will discuss several types of fixed point computation problems, their complexity, and some of the common themes that have emerged: classes of problems for which there are efficient algorithms, and other classes for which there seem to be serious obstacles. 2012 ACM Subject Classification Theory of computation → Complexity theory and logic",,https://www.semanticscholar.org/paper/feb7d5c39ce504385b820b9739f0905e9a929e02,"International Colloquium on Automata, Languages and Programming"
791,Approximation of Multiobjective Optimization Problems,,2001-08-08,https://www.semanticscholar.org/paper/7293420513488a517a33da2e8f1ccba18cabc9e9,Workshop on Algorithms and Data Structures
201,A Model for Structured Information Representation in Neural Networks of the Brain,"Abstract Humans can reason at an abstract level and structure information into abstract categories, but the underlying neural processes have remained unknown. Recent experimental data provide the hint that this is likely to involve specific subareas of the brain from which structural information can be decoded. Based on this data, we introduce the concept of assembly projections, a general principle for attaching structural information to content in generic networks of spiking neurons. According to the assembly projections principle, structure-encoding assemblies emerge and are dynamically attached to content representations through Hebbian plasticity mechanisms. This model provides the basis for explaining a number of experimental data and provides a basis for modeling abstract computational operations of the brain.",2016-11-11,https://www.semanticscholar.org/paper/6d4e8da48fca855edb6381cccf81e2ff3dc25dd8,eNeuro
3317,Dynamics of fish shoals: identifying key decision rules,"Social aggregations of fish are extremely common in nature. Pitcher (1983) defines a social aggregation of fish as a shoal, with a highly polarized shoal constituting a school. The ultimate causes of fish shoaling have been extensively studied and are well established, with the main causes being protection from predators and enhanced foraging ability. The proximate mechanisms by which groups are maintained are less well understood. Several models exist that examine these decision rules. A common theme to these models is the existence of a region at large nearest-neighbour distances (NND), where an individual will move towards its nearest neighbour, and a region of repulsion at small NND, where the individual will move away from its nearest neighbour. Recent models (Gueron et al., 1996; Couzin and Krause, 2003) suggest that shoaling decisions may not be instantaneous, instead being hierarchical as fish assess the presence or absence of one or more neighbours in zones of attraction, repulsion and neutrality. Here a mixed shoal of creek chubs (Semotilus atromaculatus) and blacknose dace (Rhinichthys atratulus) was examined in the field through video recording and digitization of images. Shoal dynamics were examined both under normal, undisturbed conditions, and in the presence of a simulated predator. By tracking the movements of individual fish over time, we find evidence for both attraction and repulsion zones. But three other novel features emerge as well. First, between regions where focal fish are attracted to, or are repulsed by, neighbours, there appears to be a ‘neutral zone’, where no consistent response occurs. Second, changes in NND at far distances, more so than at close distances, are affected not only by the position of nearest neighbours, but by the orientation of their velocity vectors as well. Third, the effect of increased fear level of fish induced by the appearance of simulated predators is a decrease in both the average NND and the sizes of the stress, attraction and neutral behavioural zones.",,https://www.semanticscholar.org/paper/c34f66db21cefb3d7d2f761f6223707f01372ee3,
2756,Expert systems and hypertext,"The relationships between expert systems and hypertext are many and varied. Expert systems have been proposed as authoring environments and navigational aids for hypertext systems and hypertext systems have been proposed as knowledge representation vehicles and rule editors for expert systems. These interrelationships should come as no surprise given the similarity of intellectual challenges confronting investigators in the two respective disciplines. In each, issues of knowledge representation, control of inference, and computational complexity are central. This panel will attempt to explore some of these overlapping issues from the perspective of both basic research and commercial applications. Although some primary data will be presented, the session will be more one of making links between other Hypertext 89 Proceedings presentations and a larger body of work. Audience participation will be strongly encouraged.",1989-11-01,https://www.semanticscholar.org/paper/989cce99996943f66eb0aa2ce390974fe591ff6b,UK Conference on Hypertext
3193,"Land use influence on distribution and abundance of herbivores in Samburu-Laikipia, Kenya","The distribution and abundance of different wildlife herbivores was studied in Samburu-Laikipia landscape. The study sites included; Mpala and Oljogi, both commercial ranches in Laikipia district; Oldonyiro and Kipsing community areas in Isiolo district; West Gate Conservancy, Ngaroni Community area, Kalama Community area and Sessia-Barsalinga Community area in Samburu district; and Buffalo Spring National Reserve and Samburu National Reserve both protected areas in the landscape. The objectives of the study were: 1) Determine the influence of different land use on seasonal abundances and distribution wildlife species and 2) Examine the influence of livestock, human settlements and water on wildlife species in Samburu-Laikipia landscape. Distance sampling was used to estimate wildlife, livestock and bomas densities. Distance to nearest water was projected from GPS coordinates for both wildlife and livestock sighting using ARCGIS. Our analysis showed non-uniform distributions of wildlife groups across the Samburu-Laikipia ecosystem largely driven by seasonal rainfall patterns and land use types. Like predicted, most wildlife groups occurred in higher abundances on protected areas, Laikipia commercial ranches and community conservancies unlike in community grazing areas in both dry and wet season. However, large grazers increased substantially in community grazing areas over the wet season when livestock grazing was heavy, stimulating growth of short annuals plants of high-quality nutrients. Human activities had negative influences on all wildlife groups. Our findings indicate that the type of land -use influenced herbivore distribution and abundance in Samburu-Laikipia landscape. This suggests that human activities, including pastoralism, in conjunction with season rainfall patterns and land-use shape herbivore distribution and abundance in the area. Conservation strategies for successfully increasing survival of wildlife therefore, requires maintenance of a mixture of land-use types with well controlled and sustainable development.",2021-07-12,https://www.semanticscholar.org/paper/5cea8da9d9c2cdf4ecbcbd9d38b031c1778781b8,"Journal of sustainability, environment and peace"
1508,Search for Large Extra Dimensions via Single Photon plus Missing Energy Final States at √ S = 1.96 Tev,In this note we investigate Kaluza-Klein graviton production with a photon and missing energy in the final state and set limits on the fundamental Planck scale MD for a set of data with a total integrated luminosity of 2.7 fb −1. At 95% C.L. we set limits on the fundamental mass scale MD from 970 GeV to 816 GeV for two to eight extra dimensions.,,https://www.semanticscholar.org/paper/d2905474b9fd3debc18a5e6e7c496bdbd1767364,
3612,C and C++: Siblings,"This article presents a view of the relationship between K&R C’s most prominent descendants: ISO C and ISO C++. It briefly discusses some implications of these incompatibilities, reflects on the ‘‘Spirit of C’’ notion, and gives examples of how incompatibilities can be handled. This article is the first of three, providing a ‘‘philosophical’’ view of the C/C ++ relationship. The second article will present arguments to the effect that a merger of C and C ++ is the best direction for the C/C++ community [Stroustrup,2002b], and the third article will present some examples of how language incompatibilities might be reconciled [Stroustrup,2002c].",,https://www.semanticscholar.org/paper/496dab7fc6ca12fafa139e455b75ab0fcaa60a1d,
1243,Status of the Cryogenic Dark Matter Search Experiment,,2008-01-24,https://www.semanticscholar.org/paper/9dd8b03aff2331e5d01c8e7cf156e2430dc9127b,
2564,On Beyond GUI,,2007-01-30,https://www.semanticscholar.org/paper/fdaead0fed23072980ed13eca3fa80dd2649c391,Australasian User Interface Conference
1384,Results from the 1998–1999 runs of the cryogenic dark matter search,,2003-07-01,https://www.semanticscholar.org/paper/62d02958ce3096363cfad4ede05fc0ae352ad637,
2888,Expression and function of an IgE-binding animal lectin (epsilon BP) in mast cells.,"epsilon BP (IgE-binding protein) is a 31,000 M(r) protein originally identified in rat basophilic leukemia (RBL) cells. The protein is composed of two domains with the amino-terminal domain containing a highly conserved repetitive sequence and the carboxyl-terminal domain containing consensus sequences shared by other beta-galactoside-binding soluble lectins. The protein has wide tissue distribution, is found on cell surfaces and in extracellular milieu. By combined efforts from several research groups including ours a multifunctional nature of this lectin began to emerge. This review emphasizes the following characteristics of epsilon BP: (i) epsilon BP is secreted by cells such as macrophages; (ii) like many other lectins, epsilon BP functions at least bivalently; (iii) epsilon BP has specificity for distinct oligosaccharide structures that have a terminal galactose not masked by sialic acids; and (iv) in addition to binding IgE, epsilon BP binds to surfaces of various cell types via lectin-carbohydrate interaction. Importantly, epsilon BP binds to the IgE receptor on mast cells. We propose that epsilon BP can function as a modulatory protein on various cells by cross-linking critical cell surface glycoproteins. The proposed action of epsilon BP on mast cells is presented as a model.",,https://www.semanticscholar.org/paper/cf735c1c2f5c501edfc3525f982c8039ebf709b7,Immunopharmacology
1398,Direct search for charged Higgs bosons in decays of top quarks,"We present a search for charged Higgs bosons in decays of pair-produced top quarks in pp̄ collisions at √ s = 1.8 TeV using 62.2 pb−1 of data recorded by the DØ detector at the Fermilab Tevatron collider. No evidence is found for signal, and we exclude at 95% confidence most regions of the (MH±, tanβ) parameter space where the decay t → Hb has a branching fraction greater than 0.36 and B(H± → τντ ) is large.",,https://www.semanticscholar.org/paper/abdf5159d08be697615ed9fe4612fcba18380f51,
2073,Hybrid data mining approach for pattern extraction from wafer bin map to improve yield in semiconductor manufacturing,,2007-05-01,https://www.semanticscholar.org/paper/d3e035961e87bc6bf923f6f04ad3aacd4c33f9f4,International Journal of Production Economics
2130,A hardware-software co-simulator for embedded system design and debugging,"One of the interesting problems in hardware-software co-design is that of debugging embedded software in conjunction with hardware. Currently, most software designers wait until a working hardware prototype is available before debugging software. Bugs discovered in hardware during the software debugging phase require re-design and re-fabrication, thereby not only delaying the project but also increasing cost. It also puts software debugging on hold until a new hardware prototype is available. In this paper we describe a hardware-software co-simulator that can be used in the design, debugging and verification of embedded systems. This tool contains simulators for different parts of the system and a backplane which is used to integrate the simulators. This enables us to simulate hardware, software and their interaction efficiently. We also address the problem of simulation speed. Currently, the more accurate (in terms of timing) the models used, the longer it takes to simulate a system. Our main contribution is a set of techniques to speed up simulation of processors and peripherals without significant loss in timing accuracy. Finally, we describe applications used to test the co-simulator and our experience in using it.",1995-08-01,https://www.semanticscholar.org/paper/038ca383073178be26c238a5218a627e5dc20bd9,Proceedings of ASP-DAC'95/CHDL'95/VLSI'95 with EDA Technofair
2417,Adaptive Visual Cues for Guiding a Bimanual Unordered Task in Virtual Reality,"Work on cueing performance in AR and VR has focused on sequential tasks in which each step must be completed in order before the user can proceed to the next. However, for unordered tasks such as putting books back on a library shelf, the user may be able to perform multiple steps concurrently without needing to follow a specific order. In such situations, giving the user multiple cues for potentially concurrent steps may improve performance time. To investigate this, we built a bimanual VR testbed in which the user needs to move objects to designated destinations, guided by different numbers of cues. The user can decide the order to perform the cued steps and, in some conditions, can affect which cues are shown.In a formal user study, we found that in most conditions, participants perform fastest with three cues. Dynamically updating the set of displayed cues based on hand proximity improves performance, and updating the set based on eye gaze improves performance even more. Finally, for both the hand-proximity and eye-gaze mechanisms, performance can be further improved by locking the cues for objects predicted to be moved next based on hand distance.",2022-10-01,https://www.semanticscholar.org/paper/efee354668c112d0d8cabb9c58a78110ca9423fd,International Symposium on Mixed and Augmented Reality
3369,The Socially Constructive Aspects of Outside Agents in Community Decision-Making in a Rural Area,,1975-07-01,https://www.semanticscholar.org/paper/2cbb9391b9b157ecb835ece6634aab5fa2f2f9f7,The Journal of Sociology &amp; Social Welfare
3583,Practical and Verifiable C++ Dynamic Cast for Hard Real-Time Systems,"The dynamic cast operation allows flexibility in the design and use of data management facilities in object-oriented programs. Dynamic cast has an important role in the implementation of the Data Management Services (DMS) of the Mission Data System Project (MDS), the Jet Propulsion Laboratory’s experimental work for providing a state-based and goal-oriented unified architecture for testing and development of mission software. DMS is responsible for the storage and transport of control and scientific data in a remote autonomous spacecraft. Like similar operators in other languages, the C++ dynamic cast operator does not provide the timing guarantees needed for hard real-time embedded systems. In a recent study, Gibbs and Stroustrup (G&S) devised a dynamic cast implementation strategy that guarantees fast constant-time performance. This paper presents the definition and application of a cosimulation framework to formally verify and evaluate the G&S fast dynamic casting scheme and its applicability in the Mission Data System DMS application. We describe the systematic process of model-based simulation and analysis that has led to performance improvement of the G&S algorithm’s heuristics by about a factor of 2. In this work we introduce and apply a library for extracting semantic information from C++ source code that helps us deliver a practical and verifiable implementation of the fast dynamic casting algorithm.",2008-12-31,https://www.semanticscholar.org/paper/86e1515db53dcca67d1d9f62f26b8d5449ab0d60,Journal of Computing Science and Engineering
2351,Receptor expression and oxidase activity in human neutrophils: Regulation by granulocyte-macrophage colony-stimulating factor and dependence upon protein biosynthesis,,1990-08-01,https://www.semanticscholar.org/paper/6d353860c0f44e12c6c7c74d9164ad9989defdb6,Bioscience Reports
2476,Attributes of Subtle Cues for Facilitating Visual Search in Augmented Reality,"Goal-oriented visual search is performed when a person intentionally seeks a target in the visual environment. In augmented reality (AR) environments, visual search can be facilitated by augmenting virtual cues in the person's field of view. Traditional use of explicit AR cues can potentially degrade visual search performance due to the creation of distortions in the scene. An alternative to explicit cueing, known as subtle cueing, has been proposed as a clutter-neutral method to enhance visual search in video-see-through AR. However, the effects of subtle cueing are still not well understood, and more research is required to determine the optimal methods of applying subtle cueing in AR. We performed two experiments to investigate the variables of scene clutter, subtle cue opacity, size, and shape on visual search performance. We introduce a novel method of experimentally manipulating the scene clutter variable in a natural scene while controlling for other variables. The findings provide supporting evidence for the subtlety of the cue, and show that the clutter conditions of the scene can be used both as a global classifier, as well as a local performance measure.",2014-03-01,https://www.semanticscholar.org/paper/63a3da01b70ccae417cbad77a7c1b29326b026e4,IEEE Transactions on Visualization and Computer Graphics
3689,Understanding Zero-Shot Adversarial Robustness for Large-Scale Models,"Pretrained large-scale vision-language models like CLIP have exhibited strong generalization over unseen tasks. Yet imperceptible adversarial perturbations can significantly reduce CLIP's performance on new tasks. In this work, we identify and explore the problem of \emph{adapting large-scale models for zero-shot adversarial robustness}. We first identify two key factors during model adaption -- training losses and adaptation methods -- that affect the model's zero-shot adversarial robustness. We then propose a text-guided contrastive adversarial training loss, which aligns the text embeddings and the adversarial visual features with contrastive learning on a small set of training data. We apply this training loss to two adaption methods, model finetuning and visual prompt tuning. We find that visual prompt tuning is more effective in the absence of texts, while finetuning wins in the existence of text guidance. Overall, our approach significantly improves the zero-shot adversarial robustness over CLIP, seeing an average improvement of over 31 points over ImageNet and 15 zero-shot datasets. We hope this work can shed light on understanding the zero-shot adversarial robustness of large-scale models.",2022-12-14,https://www.semanticscholar.org/paper/16596dd03fa40ba278f9533ea9986982dcc81fb6,International Conference on Learning Representations
3707,RESIN: A Dockerized Schema-Guided Cross-document Cross-lingual Cross-media Information Extraction and Event Tracking System,"We present a new information extraction system that can automatically construct temporal event graphs from a collection of news documents from multiple sources, multiple languages (English and Spanish for our experiment), and multiple data modalities (speech, text, image and video). The system advances state-of-the-art from two aspects: (1) extending from sentence-level event extraction to cross-document cross-lingual cross-media event extraction, coreference resolution and temporal event tracking; (2) using human curated event schema library to match and enhance the extraction output. We have made the dockerlized system publicly available for research purpose at GitHub, with a demo video.",,https://www.semanticscholar.org/paper/039ce73659332c12168de439e3f79e7039b636af,North American Chapter of the Association for Computational Linguistics
822,Searching a Fixed Graph,,1996-07-08,https://www.semanticscholar.org/paper/dfdb3be95b742a6a44fcae89b5f771441d12349f,"International Colloquium on Automata, Languages and Programming"
1720,Structured Stochastic Variational Inference,"Stochastic variational inference makes it possible to approximate posterior distributions induced by large datasets quickly using stochastic optimization. The algorithm relies on the use of fully factorized variational distributions. However, this ""mean-field"" independence approximation limits the fidelity of the posterior approximation, and introduces local optima. We show how to relax the mean-field approximation to allow arbitrary dependencies between global parameters and local hidden variables, producing better parameter estimates by reducing bias, sensitivity to local optima, and sensitivity to hyperparameters.",2014-04-15,https://www.semanticscholar.org/paper/e84a29252dabbd2680fb9ebe65bc79bc3f52a73c,
2912,Deep mendelian randomization: Investigating the causal knowledge of genomic deep learning models,"Multi-task deep learning (DL) models can accurately predict diverse genomic marks from sequence, but whether these models learn the causal relationships between genomic marks is unknown. Here, we describe Deep Mendelian Randomization (DeepMR), a method for estimating causal relationships between genomic marks learned by genomic DL models. By combining Mendelian Randomization with in silico mutagenesis, DeepMR obtains local (locus specific) and global estimates of (an assumed) linear causal relationship between marks. In a simulation designed to test recovery of pairwise causal relations between transcription factors (TFs), DeepMR gives accurate and unbiased estimates of the ‘true’ global causal effect, but its coverage decays in the presence of sequence-dependent confounding. We then apply DeepMR to examine the global relationships learned by a state-of-the-art DL model, BPNet [Avsec et al., 2020], between TFs involved in reprogramming. DeepMR’s causal effect estimates validate previously hypothesized relationships between TFs and suggest new relationships for future investigation.",2022-02-02,https://www.semanticscholar.org/paper/c2818374b762b0d8176d71ef7bc754d0aa9c51a3,bioRxiv
3625,C++ : programovací jazyk : The C++ programming language (Orig.),,,https://www.semanticscholar.org/paper/905b9da5fc7d090e8b96814507d84c4167b4f29c,
3528,Improved approximation algorithms for shop scheduling problems,"In the job shop scheduling problem, there are $m$ machines and $n$ jobs. A job consists of a sequence of operations, each of which must be processed on a specified machine, and the aim is to complete all jobs as quickly as possible. This problem is strongly ${\cal NP}$-hard even for very restrictive special cases. The authors give the first randomized and deterministic polynomial-time algorithms that yield polylogarithmic approximations to the optimal length schedule. These algorithms also extend to the more general case where a job is given not by a linear ordering of the machines on which it must be processed but by an arbitrary partial order. Comparable bounds can also be obtained when there are $m'$ types of machines, a specified number of machines of each type, and each operation must be processed on one of the machines of a specified type, as well as for the problem of scheduling unrelated parallel machines subject to chain precedence constraints.",1991-03-01,https://www.semanticscholar.org/paper/5e8f017cf9d6fdf1c3031d4af0b35e7266cf55a9,ACM-SIAM Symposium on Discrete Algorithms
2401,Electron transport pathways alternative to the main phosphorylating respiratory chain,,,https://www.semanticscholar.org/paper/39b9e61b68045bb980938ddd33ba5fe291498cd3,
331,Afterword: From the Newsgroup,"Our hero is Turing, an interactive tutoring program and namesake (or virtual emanation?) of Alan Turing, World War II code breaker and father of computer science. In this unusual novel, Turing's idiosyncratic version of intellectual history from a computational point of view unfolds in tandem with the story of a love affair involving Ethel, a successful computer executive, Alexandros, a melancholy archaeologist, and Ian, a charismatic hacker. After Ethel (who shares her first name with Alan Turing's mother) abandons Alexandros following a sundrenched idyll on Corfu, Turing appears on Alexandros's computer screen to unfurl a tutorial on the history of ideas. He begins with the philosopher-mathematicians of ancient Greece -- ""discourse, dialogue, argument, proof... can only thrive in an egalitarian society"" -- and the Arab scholar in ninth-century Baghdad who invented algorithms; he moves on to many other topics, including cryptography and artificial intelligence, even economics and developmental biology. (These lessons are later critiqued amusingly and developed further in postings by a fictional newsgroup in the book's afterword.) As Turing's lectures progress, the lives of Alexandros, Ethel, and Ian converge in dramatic fashion, and the story takes us from Corfu to Hong Kong, from Athens to San Francisco -- and of course to the Internet, the disruptive technological and social force that emerges as the main locale and protagonist of the novel.Alternately pedagogical and romantic, Turing (A Novel about Computation) should appeal both to students and professionals who want a clear and entertaining account of the development of computation and to the general reader who enjoys novels of ideas.",,https://www.semanticscholar.org/paper/4c696680b5517f351cbd377d057ba3f2029ed346,
2609,Turning VR inside out: thoughts about where we are heading,"Our field and the world have changed greatly in the ten years since the first VRST was held in Singapore in 1994. Computers have grown smaller, faster, and cheaper, while polygon counts, frame rates, and display resolutions have increased impressively, true to the promise of Moore's Law. But, what comes next?This talk will sketch some of the directions in which I feel virtual reality is (or should be) heading. I will discuss the potential for taking virtual reality outside, through wearable and mobile computing; for bring the outside in, by capturing the real world; and for accommodating large numbers of displays, users, and tasks, by embedding them in a fluid and collaborative augmented environment.",2004-11-10,https://www.semanticscholar.org/paper/da81db575f5a46de1d08cc50714a7cdb90a9f51c,Virtual Reality Software and Technology
560,An Algorithm for Shortest-Path Motion in Three Dimensions,,1985-06-12,https://www.semanticscholar.org/paper/867bb6f7ab1728d76eeb6d9974d6d2f3a96466e9,Information Processing Letters
1962,A data mining approach for analyzing semiconductor MES and FDC data to enhance overall usage effectiveness (OUE),"AbstractWafer fabrication is a complex and lengthy process that involves hundreds of process steps with monitoring numerous process parameters at the same time for yield enhancement. Big data is automatically collected during manufacturing processes in modern wafer fabrication facility. Thus, potential useful information can be extracted from big data to enhance decision quality and enhance operational effectiveness. This study aims to develop a data mining framework that integrates FDC and MES data to enhance the overall usage effectiveness (OUE) for cost reduction. We validated this approach with an empirical study in a semiconductor company in Taiwan. The results demonstrated the practical viability of this approach. The extracted information and knowledge is helpful to engineers for identifying the major tools factors affecting indirect material usage effectiveness and identify specific periods of time when a functional tool has abnormal usage of material.",2014-07-22,https://www.semanticscholar.org/paper/761fbdba4182210cba43c5a1d6e9d354a87de2ea,International Journal of Computational Intelligence Systems
2085,利用資料挖礦提升半導體廠製造技術員人力資源管理品質; Using Data Mining to Improve the quality of Human Resource Management of Operators in Semiconductor Manufactures,,,https://www.semanticscholar.org/paper/29357c47175ba4f462480673efc00c02f3ee10ed,
2952,Pitman Yor Diffusion Trees for Bayesian Hierarchical Clustering,"In this paper we introduce the Pitman Yor Diffusion Tree (PYDT), a Bayesian non-parametric prior over tree structures which generalises the Dirichlet Diffusion Tree [30] and removes the restriction to binary branching structure. The generative process is described and shown to result in an exchangeable distribution over data points. We prove some theoretical properties of the model including showing its construction as the continuum limit of a nested Chinese restaurant process model. We then present two alternative MCMC samplers which allow us to model uncertainty over tree structures, and a computationally efficient greedy Bayesian EM search algorithm. Both algorithms use message passing on the tree structure. The utility of the model and algorithms is demonstrated on synthetic and real world data, both continuous and binary.",2015-02-01,https://www.semanticscholar.org/paper/04981e6b2063168038c1c1aa3cc4f009892a8829,IEEE Transactions on Pattern Analysis and Machine Intelligence
1704,A probabilistic approach to full-brain functional connectivity analyses,"Recent work suggests that our brains’ sub-structures change how they communicate with one another depending on the particular functions or computations that our ongoing cognitive processes demand (for review see [1]). The standard approach to estimating these so called functional connectivity patterns in functional magnetic resonance imaging (fMRI) data is to compute the correlation between the time series of (pairs of) voxel activations during a particular experimental condition. However, this voxel-based approach carries a substantial computational burden (of computing time and memory), which has led most researchers to focus their connectivity analyses on a small number of pre-selected regions of interest (ROIs). Here we present a technique, termed Hierarchical Topographic Factor Analysis (HTFA), for efficiently discovering full-brain networks (without pre-selecting ROIs) in large multi-subject neuroimaging datasets. HTFA approximates each subject’s full-brain functional connectivity network through a smaller number of network nodes. The number of nodes, along with their locations, sizes, and activations (over time) are determined in an unsupervised manner from the dataset. Because the number of nodes is typically substantially smaller than the number of voxels in an fMRI dataset, HTFA can be orders of magnitude more efficient than voxel-based functional connectivity approaches. Among other benefits, this enables researchers to apply polynomial time algorithms (which includes many pattern classification algorithms) to full-brain functional connectivity networks without paying the typical huge increase in computational time and memory that voxel-based methods demand. We show that HTFA recovers the connectivity patterns underlying a synthetic dataset, and provide a case study illustrating how HTFA may be used to discover full-brain connectivity patterns in real fMRI data.",,https://www.semanticscholar.org/paper/7bcfc73c4fbcedf8f290882ddb3d15c70b1eefcb,
1675,Probabilistic Topic Models and User Behavior,"David Blei is a Professor of Statistics and Computer Science at Columbia University. His research is in statistical machine learning, involving probabilistic topic models, Bayesian nonparametric methods, and approximate posterior inference. He works on a variety of applications, including text, images, music, social networks, user behavior, and scientific data. 
 
David earned his Bachelor's degree in Computer Science and Mathematics from Brown University (1997) and his PhD in Computer Science from the University of California, Berkeley (2004). Before arriving to Columbia, he was an Associate Professor of Computer Science at Princeton University. He has received several awards for his research, including a Sloan Fellowship (2010), Office of Naval Research Young Investigator Award (2011), Presidential Early Career Award for Scientists and Engineers (2011), Blavatnik Faculty Award (2013), and ACM-Infosys Foundation Award (2013).",2015-10-16,https://www.semanticscholar.org/paper/3bb64c846759e52ce8c9a417fbae32c3b80bd31e,
721,On Complexity as Bounded Rationality1,,,https://www.semanticscholar.org/paper/cbaeb3cf17ad447b368fcdf9d1fbec6a321b23fc,Symposium on the Theory of Computing
421,"Elements of the theory of computation / Harry R. Lewis, Christos H. Papadimitriou",,,https://www.semanticscholar.org/paper/566ca83a740fc6247651395f2ccf25eeb06a8641,
3182,Towards Individual Grevy's Zebra Identification via Deep 3D Fitting and Metric Learning,"This paper combines deep learning techniques for species detection, 3D model fitting, and metric learning in one pipeline to perform individual animal identification from photographs by exploiting unique coat patterns. This is the first work to attempt this and, compared to traditional 2D bounding box or segmentation based CNN identification pipelines, the approach provides effective and explicit view-point normalisation and allows for a straight forward visualisation of the learned biometric population space. Note that due to the use of metric learning the pipeline is also readily applicable to open set and zero shot re-identification scenarios. We apply the proposed approach to individual Grevy's zebra (Equus grevyi) identification and show in a small study on the SMALST dataset that the use of 3D model fitting can indeed benefit performance. In particular, back-projected textures from 3D fitted models improve identification accuracy from 48.0% to 56.8% compared to 2D bounding box approaches for the dataset. Whilst the study is far too small accurately to estimate the full performance potential achievable in larger-scale real-world application settings and in comparisons against polished tools, our work lays the conceptual and practical foundations for a next step in animal biometrics towards deep metric learning driven, fully 3D-aware animal identification in open population settings. We publish network weights and relevant facilitating source code with this paper for full reproducibility and as inspiration for further research.",2022-06-05,https://www.semanticscholar.org/paper/a6b0984cdca0fb6612cd19a4bd4b34717c52249e,arXiv.org
2642,Steps Toward Accommodating Variable Position Tracking Accuracy in a Mobile Augmented Reality System,"The position-tracking accuracy of a location-aware mobile system can change dynamically as a function of the user’s location and other variables specific to the tracker technology used. This is especially problematic for mobile augmented reality systems, which ideally require extremely precise position tracking for the user’s head, but which may not always be able to achieve the necessary level of accuracy. While it is possible to ignore variable positional accuracy in an augmented reality user interface, this can make for a confusing system; for example, when accuracy is low, virtual objects that are nominally registered with real ones may be too far off to be of use. To address this problem, we describe the early stages of an experimental mobile augmented reality system that adapts its user interface automatically to accommodate changes in tracking accuracy. Our system employs different technologies for tracking a user’s position, resulting in a wide variation in positional accuracy: an indoor ultrasonic tracker and an outdoor real-time kinematic GPS system. For areas outside the range of both, we introduce a dead-reckoning approach that combines a pedometer and orientation tracker with environmental knowledge expressed in spatial maps and accessibility graphs. We present preliminary results from this approach in the context of a navigational guidance system that helps users to orient themselves in an unfamiliar environment. Our system uses inferencing and path planning to guide users toward targets that they choose.",,https://www.semanticscholar.org/paper/35425d60f458c97f9599e2eed5a4fc53390d5b13,
1904,A hybrid genetic algorithm with 2D encoding for the scheduling of rehabilitation patients,,2018-11-01,https://www.semanticscholar.org/paper/627c9e0beefc1c5e21b686cccecd3862a206ddde,Computers & industrial engineering
3543,Simplifying the analysis of c++ programs,"Based on our experience of working with different C++ front ends, this thesis identifies numerous problems that complicate the analysis of C++ programs along the entire spectrum of analysis applications. We utilize library, language, and tool extensions to address these problems and offer solutions to many of them. In particular, we present efficient, expressive and non-intrusive means of dealing with abstract syntax trees of a program, which together render the visitor design pattern obsolete. We further extend C++ with open multi-methods to deal with the broader expression problem. Finally, we offer two techniques, one based on refining the type system of a language and the other on abstract interpretation, both of which allow developers to statically ensure or verify various run-time properties of their programs without having to deal with the full language semantics or even the abstract syntax tree of a program. Together, the solutions presented in this thesis make ensuring properties of interest about C++ programs available to average language users.",,https://www.semanticscholar.org/paper/6e1b971eab8db0efbd9e91c744821d251c224b58,
3139,Optimal linear interpolation coding for server-based computing,"Due to its reduced administrative costs and better resource utilization, server-based computing (SBC) is becoming a popular approach for delivering computational services across a network. In SBC, all application processing is done on servers while only screen updates are sent to clients. While many SBC encoding techniques have been explored for transmitting screen updates efficiently, existing approaches do not effectively support multimedia applications. To address this problem, we propose optimal linear interpolation (OLI), a new pixel-based SBC screen update coding algorithm. With OLI, the server selects and transmits only a small sample of pixels to represent a screen update. The client recovers the complete screen update from these samples using piecewise linear interpolation to achieve the best visual quality. OLI can be used to provide lossless or lossy compression for an adaptive trade-off between network bandwidth and processing time requirements. We further propose and evaluate 2D lossless linear interpolation (2DLI), which is based on OLI but additionally provides lower encoding complexity for lossless compression. Our experimental results show that when compared with other compression methods, 2DLI provides good data compression ratio with modest computational overhead, for both servers and clients.",2002-08-07,https://www.semanticscholar.org/paper/450fff5448f51244a5a95c854036d486afd28e20,2002 IEEE International Conference on Communications. Conference Proceedings. ICC 2002 (Cat. No.02CH37333)
795,From Rule-based to Automata-based Testing,,2000-10-10,https://www.semanticscholar.org/paper/6dcd45fe755d4a8d295e83c4b5a31ba79c54de35,Formal Techniques for (Networked and) Distributed Systems
3781,Efficiently Scaling Up Video Annotation with Crowdsourced Marketplaces,,2010-09-05,https://www.semanticscholar.org/paper/09dd01e19b247a33162d71f07491781bdf4bfd00,European Conference on Computer Vision
413,On the complexity of single-rule datalog queries,,1999-09-06,https://www.semanticscholar.org/paper/cd0b508cc8a127cffab0d010b0bafdb360fa77c8,Information and Computation
1997,Hybrid Sampling Strategy-based Multiobjective Evolutionary Algorithm,,,https://www.semanticscholar.org/paper/49abeffaa2087d90ac12bd77434888bced102cb3,Complex Adaptive Systems
1920,Embedding ant system in genetic algorithm for re-entrant hybrid flow shop scheduling problems with time window constraints,,2017-12-01,https://www.semanticscholar.org/paper/9cd191446b5c3ab80d0a636450d7ddadf7b3db86,Journal of Intelligent Manufacturing
194,"Front Matter, Table of Contents, Preface, Conference Organization",,,https://www.semanticscholar.org/paper/fbd51e3e9fc4ea6dffd17f692425fb1b14831b1e,Information Technology Convergence and Services
1346,Measurement of the WW production cross section in pp collisions at square root[s]=1.96 TeV.,"We present a measurement of the W boson pair-production cross section in pp collisions at a center-of-mass energy of sqrt[s]=1.96 TeV. The data, collected with the Run II D0 detector at Fermilab, correspond to an integrated luminosity of 224-252 pb(-1) depending on the final state (ee, emu, or mumu). We observe 25 candidates with a background expectation of 8.1+/-0.6(stat)+/-0.6(syst)+/-0.5(lum) events. The probability for an upward fluctuation of the background to produce the observed signal is 2.3x10(-7), equivalent to 5.2 standard deviations. The measurement yields a cross section of 13.8(+4.3)(-3.8)(stat)+1.2-0.9(syst)+/-0.9(lum) pb, in agreement with predictions from the standard model.",,https://www.semanticscholar.org/paper/84444e25cc8f3e71deef5630a09099fd4760abe3,Physical Review Letters
181,Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of Neurons,"We analyze linear independence of rank one tensors produced by tensor powers of randomly perturbed vectors. This enables efficient decomposition of sums of high-order tensors. Our analysis builds upon [BCMV14] but allows for a wider range of perturbation models, including discrete ones. We give an application to recovering assemblies of neurons. 
Assemblies are large sets of neurons representing specific memories or concepts. The size of the intersection of two assemblies has been shown in experiments to represent the extent to which these memories co-occur or these concepts are related; the phenomenon is called association of assemblies. This suggests that an animal's memory is a complex web of associations, and poses the problem of recovering this representation from cognitive data. Motivated by this problem, we study the following more general question: Can we reconstruct the Venn diagram of a family of sets, given the sizes of their $\ell$-wise intersections? We show that as long as the family of sets is randomly perturbed, it is enough for the number of measurements to be polynomially larger than the number of nonempty regions of the Venn diagram to fully reconstruct the diagram.",2018-10-28,https://www.semanticscholar.org/paper/6e4fab41d34251a186496d86926e2a0871e42a7e,Neural Information Processing Systems
1857,Hierarchical Topic Models and the Nested Chinese Restaurant Process,"We address the problem of learning topic hierarchies from data. The model selection problem in this domain is daunting—which of the large collection of possible trees to use? We take a Bayesian approach, generating an appropriate prior via a distribution on partitions that we refer to as the nested Chinese restaurant process. This nonparametric prior allows arbitrarily large branching factors and readily accommodates growing data collections. We build a hierarchical topic model by combining this prior with a likelihood that is based on a hierarchical variant of latent Dirichlet allocation. We illustrate our approach on simulated data and with an application to the modeling of NIPS abstracts.",2003-12-09,https://www.semanticscholar.org/paper/28e245ce0e06f398dd26a9d6ab6bb04ef4c016e6,Neural Information Processing Systems
2187,Opisthorchiasis-Induced Cholangiocarcinoma: How Innate Immunity May Cause Cancer.,,,https://www.semanticscholar.org/paper/a6b5f26f1dfde47449921fd3d9ac16343288ffc0,Advances in Parasitology
1527,Estimating Social Influence from Observational Data,"We consider the problem of estimating social influence, the effect that a person's behavior has on the future behavior of their peers. The key challenge is that shared behavior between friends could be equally explained by influence or by two other confounding factors: 1) latent traits that caused people to both become friends and engage in the behavior, and 2) latent preferences for the behavior. This paper addresses the challenges of estimating social influence with three contributions. First, we formalize social influence as a causal effect, one which requires inferences about hypothetical interventions. Second, we develop Poisson Influence Factorization (PIF), a method for estimating social influence from observational data. PIF fits probabilistic factor models to networks and behavior data to infer variables that serve as substitutes for the confounding latent traits. Third, we develop assumptions under which PIF recovers estimates of social influence. We empirically study PIF with semi-synthetic and real data from Last.fm, and conduct a sensitivity analysis. We find that PIF estimates social influence most accurately compared to related methods and remains robust under some violations of its assumptions.",2022-03-24,https://www.semanticscholar.org/paper/aef22855ca3475e324d92768cbc0d1d84110b786,CLEaR
849,The complexity of multiway cuts (extended abstract),"In the Multiway Cut problem we are given an edge-weighted graph and a subset of the vertices called terminals, and asked for a minimum weight set of edges that separates each terminal from all the others. When the number <italic>k</italic> of terminals is two, this is simply the min-cut, max-flow problem, and can be solved in polynomial time. We show that the problem becomes NP-hard as soon as <italic>k</italic> = 3, but can be solved in polynomial time for planar graphs for any fixed <italic>k</italic>. The planar problem is NP-hard, however, if <italic>k</italic> is not fixed. We also describe a simple approximation algorithm for arbitrary graphs that is guaranteed to come within a factor of 2–2/<italic>k</italic> of the optimal cut weight.",1992-07-01,https://www.semanticscholar.org/paper/523b9604863d9dd9282723d927b6efb7bad1bcb0,Symposium on the Theory of Computing
1118,The CDMS II Data Acquisition System,,2011-05-11,https://www.semanticscholar.org/paper/b0121b2d470e800b584dc6e9b898676f3fc8382e,
2868,Galectin-12 Is Required for Adipogenic Signaling and Adipocyte Differentiation*,"Galectin-12 is a member of the galectin family consisting of β-galactoside-binding proteins with conserved carbohydrate recognition domains. This protein is preferentially expressed in peripheral blood leukocytes and adipocytes. We previously showed that galectin-12 is induced by cell cycle block at the G1 phase and causes G1 arrest when overexpressed (Yang, R.-Y., Hsu, D. K., Yu, L., Ni, J., and Liu, F.-T. (2001) J. Biol. Chem. 276, 20252-20260). Here, we show that the galectin-12 gene is expressed in mouse preadipocytes and is up-regulated when preadipocytes undergo cell cycle arrest, concomitant with acquisition of the competence to undergo differentiation in response to adipogenic hormone stimulation. Following a brief down-regulation 1 day after adipogenic treatment, its expression was once again markedly elevated when cells underwent terminal differentiation. Down-regulation of endogenous galectin-12 expression by RNA interference greatly reduced the expression of the adipogenic transcription factors CCAAT/enhancer-binding protein-β and -α and peroxisome proliferator-activated receptor-γ and severely suppressed adipocyte differentiation as a result of defective adipogenic signaling. We conclude that galectin-12 is required for signal transduction that conveys hormone stimulation to the induction of adipogenic factors essential for adipocyte differentiation. The findings suggest that galectin-12 is a major regulator of adipose tissue development.",2004-07-09,https://www.semanticscholar.org/paper/fd6e8ef17fd96067c98c26ccfea9cbb81b0d667d,Journal of Biological Chemistry
2307,Gene expression by inflammatory neutrophils: stimulation of interleukin-1 beta production by rheumatoid synovial fluid.,"The neutrophl has been thought of as a terminally differentiated cell with little or no capacity or requirement for de novo protein synthesis. It has recently been demonstrated that neutrophils are biosynthetically active and that the biosynthesis of some cellular components is essential to maintain the neutrophil in an active state [I]. It has also been shown that neutrophls can synthesise and secrete a range of cytokines in v i m including Interleukin (1L)-I p, IL-6, IL-8 and tumour necrosis factor-a (TNFa), all of which are present in the synovial fluid of rheumatoid joints [2,3]. L I P has been implicated as a mediator of tissueand bone-damage in rheumatoid arthritis and among its many effects it has been shown to stimulate osteoclasts and chondrocytes to resorb bone 131. As neutrophils can comprise 80% of the cell population in a rheumatoid joint, their production of IL-IP in the joint could be an important contributing factor in the perpetuation of the disease. This production in the joint could have many effects including the stimulation of production of further IL1 P by forming a positive feedback loop. IL-1p has also been shown to enhance adhesion molecule expression on vascular endothelium thereby promoting the accumulation of further neutrophils and other leukocytes [4]. Here we show the synthesis of IL-lp by neutrophils in response to rheumatoid synovial fluid. Neutrophils were isolated from fresh buffy coats as described previously [5] and suspended in RPMI 1640 medium. Suspensions (2x10’ celldml) were re-incubated at 37°C with gentle agitation in the presence of [’ S]-methionine for 15 min. Following this, either granulocyte macrophage-colony stimulating factor (GM-CSF) (14 ng/ml), lipopolysaccharide (LPS) (5 pg/ml), TNFa (25 nglml), synthetic soluble or insoluble immune complexes (10 %, v/v) or cell free synovial fluid (5 %, v/v) were added. Incubation was continued at 37°C with gentle agitation for time periods of up to 24 h. After incubation, cells were pelleted and any IL-Ip present in the cells or culture medium was immunoprecipitated as described previously [6]. The immuno-precipitated samples were then analysed by SDS-PAGE and fluorography. P",1996-08-01,https://www.semanticscholar.org/paper/b286d561e52dfd5d018a0a0f16fbcb5c3887e4ef,Biochemical Society Transactions
1047,"Projected sensitivity of the LUX-ZEPLIN experiment to the two-neutrino and neutrinoless double 
β
 decays of 
Xe134","The projected sensitivity of the LUX-ZEPLIN (LZ) experiment to two-neutrino and neutrinoless double β decay of 134 Xe is presented. LZ is a 10-tonne xenon time-projection chamber optimized for the detection of dark matter particles and is expected to start operating in 2021 at Sanford Underground Research Facility, USA. Its large mass of natural xenon provides an exceptional opportunity to search for the double β decay of 134 Xe, for which xenon detectors enriched in 136 Xe are less effective. For the two-neutrino decay mode, LZ is predicted to exclude values of the half-life up to 1 . 7 × 10 24 years at 90% conﬁdence level (CL) and has a three-sigma observation potential of 8 . 7 × 10 23 years, approaching the predictions of nuclear models. For the neutrinoless decay mode LZ, is projected to exclude values of the half-life up to 7 . 3 × 10 24 years at 90% CL.",2021-04-26,https://www.semanticscholar.org/paper/907a9b8dcdb2d487c548cbb9d2fec854bf2ed109,Physical Review C
2939,A Birth-Death Process for Feature Allocation,"Konstantina's research leading to these results has received funding from the
European Research Council under the European Union's Seventh Framework
Programme (FP7/2007-2013) ERC grant agreement no. 617411.
EPSRC Grant EP/N014162/1
ATI Grant EP/N510129/1


Institutions involved:
Oxford University, 
Cambridge University,
Stanford University",2017-07-17,https://www.semanticscholar.org/paper/311dbdf39b17668efdcb03457f824fd6c0e716ca,International Conference on Machine Learning
844,On the hardness of approximating minimization problems,"We prove results indicating that it is hard to compute efficiently good approximate solutions to the Graph Coloring, Set Covering and other related minimization problems. Specifically, there is an c >0 such that Graph Coloring cannot be approximated with ratio n’ unless P=NP. Set Covering cannot be approximated with ratio clog n for any c < 1/4 unless NP is contained in DTIME[nPOIY log ~ ]. Similar results follow for related problems such as Clique Cover, Fractional Chromatic Number, Dominating Set and others.",1993-06-01,https://www.semanticscholar.org/paper/f2be999f55fae0c8d189565b29a975d71df7bf67,Symposium on the Theory of Computing
2580,Combined research and curriculum development of nontraditional manufacturing,"Nontraditional manufacturing (NTM) is becoming increasingly important in modern engineering. Therefore, it is important to develop up-to-date pedagogic materials for the area. This paper reports collaborative efforts among three universities in such a development sponsored by National Science Foundation of USA. The features of the development include systematic introduction, recent research results, and web implementation with interactive capabilities. This paper is based on an extensive web based course with animations, including Java applets, Shockwave animations, VRML animations, and QuickTime movies. The development is aimed at upper level undergraduate and introductory graduate students. Areas of focus include Laser Material Processing, Electrical Discharge Machining, Electro-Chemical Machining, and Abrasive Water Jet Machining. Cross process innovation are also presented. Needs for further pedagogic developments are discussed.",2005-09-01,https://www.semanticscholar.org/paper/2efdbd7d0264f4e122fc2ffafdc32fc4970fd14d,
3432,FairTorrent: bringing fairness to peer-to-peer systems,"Peer-to-Peer file-sharing applications suffer from a fundamental problem of unfairness. Free-riders cause slower download times for others by contributing little or no upload bandwidth while consuming much download bandwidth. Previous attempts to address this fair bandwidth allocation problem suffer from slow peer discovery, inaccurate predictions of neighboring peers' bandwidth allocations, underutilization of bandwidth, and complex parameter tuning. We present FairTorrent, a new deficit-based distributed algorithm that accurately rewards peers in accordance with their contribution. A FairTorrent peer simply uploads the next data block to a peer to whom it owes the most data as measured by a deficit counter. FairTorrent is resilient to exploitation by free-riders and strategic peers, is simple to implement, requires no bandwidth over-allocation, no prediction of peers' rates, no centralized control, and no parameter tuning. We implemented FairTorrent in a BitTorrent client without modifications to the BitTorrent protocol, and evaluated its performance against other widely-used BitTorrent clients. Our results show that FairTorrent provides up to two orders of magnitude better fairness, up to five times better download times for contributing peers, and 60% to 100% better performance on average in live BitTorrent swarms.",2009-12-01,https://www.semanticscholar.org/paper/691fd792034ffa74a93738eebf8bbe5d1d7c416c,Conference on Emerging Network Experiment and Technology
2399,The effect of inhibitors on the oxygen kinetics of terminal oxidases of Acanthamoeba castellanii.,"1. Respiration of growing cultures of Acanthamoeba castellanii is inhibited less than 60% by azide (35 mM); the respiration of early-exponential-phase cultures differs from that of late-exponential-phase cultures in being stimulated by up to 120% by low concentrations (less than 1 mM) of this inhibitor. Azide (0.5 mM) plus 1 mM-salicylhydroxamic acid gives 80% inhibition of respiration in early- or late-exponential-phase cultures. 2. Lineweaver-Burk plots of 1/v against 1/[O2] for growing and stationary-phase cultures give values of less than 1 muM for the apparent Km for oxygen. 3. These values are not significantly altered when determined in the presence of 1 mM-salicylhydroxamic acid. 4. Higher values (greater than 7 muM) for apparent Km values for oxygen were obtained in the presence of azide, which gives non-linear Lineweaver-Burk plots. 5. Competitive inhibition of respiration by CO occurs with Ki 2.4 muM. 6. The results are discussed in terms of the presence of three terminal oxidases in this organism, namely two oxidases with high affinities for oxygen (cytochrome c oxidase of the main phosphorylating electron-transport chain and the salicylhydroxamic acid-sensitive oxidase) and a third oxidase with a low affinity for oxygen, sensitive to inhibition by cyanide but not by azide or salicylhydroxamic acid. The relative contributions to oxygen utilization by these oxidases change during the growth of a batch culture.",1979-07-15,https://www.semanticscholar.org/paper/e768a21bea0cac9381e81f960403c471d5b72158,Biochemical Journal
3336,The Gr se Meet and Biological Diversity,"of rainforest destruction on the species that inhabit tropical areas is now receiving increased attention in the media. In contrast, the slow but inexorable changes in climate that are a by-product of rainforest de- struction have only recently entered the limelight. The accumulation of gases in the atmosphere due to the burning of fossil fuels and the re- duced photosynthetic potential of a deforested Earth produce climatic effects that are likely to be profound. In two papers that are destined to become citation classicsl,2, Robert Peters of the World Wildlife Fund made the logical connection be- tween the current trends towards a warmer climate and the fact that the present sites of many nature re- serves may soon no longer enjoy the meteorological conditions necessary for the well-being of the species they were established to support. A con- ference convened by the World Wildlife Fund, held in Washington in October 1988, brought together speakers from a variety of different disciplines to discuss the potential consequences for biodiversity of the currently available predictions for climate change. This article comple- ments two other recent reports of the conference3e4. Predictions for climate change The main cause of global warming is a build-up of carbon dioxide",,https://www.semanticscholar.org/paper/683261d2ead9b60e8490a951c115b99d070f36b6,
122,Generalizing GlOSS to Vector-Space Databases and Broker Hierarchies,"As large numbers of text databases have become available on the Internet, it is getting harder to locate the right sources for given queries. In this paper we present gGlOSS, a generalized Glossary-Of-Servers Server, that keeps statistics on the available databases to estimate which databases are the potentially most useful for a given query. gGlOSS extends our previous work, which focused on databases using the boolean model of document retrieval, to cover databases using the more sophisticated vector-space retrieval model. We evaluate our new techniques using real-user queries and 53 databases. Finally, we further generalize our approach by showing how to build a hierarchy of gGlOSS brokers. The top level of the hierarchy is so small it could be widely replicated, even at end-user workstations.",1995-09-11,https://www.semanticscholar.org/paper/8897aed85e8da828c8331ceca2a1b98e4cd7e763,Very Large Data Bases Conference
3255,How the zebra got its stripes: a problem with too many solutions,"The adaptive significance of zebra stripes has thus far eluded understanding. Many explanations have been suggested, including social cohesion, thermoregulation, predation evasion and avoidance of biting flies. Identifying the associations between phenotypic and environmental factors is essential for testing these hypotheses and substantiating existing experimental evidence. Plains zebra striping pattern varies regionally, from heavy black and white striping over the entire body in some areas to reduced stripe coverage with thinner and lighter stripes in others. We examined how well 29 environmental variables predict the variation in stripe characteristics of plains zebra across their range in Africa. In contrast to recent findings, we found no evidence that striping may have evolved to escape predators or avoid biting flies. Instead, we found that temperature successfully predicts a substantial amount of the stripe pattern variation observed in plains zebra. As this association between striping and temperature may be indicative of multiple biological processes, we suggest that the selective agents driving zebra striping are probably multifarious and complex.",2015-01-01,https://www.semanticscholar.org/paper/4a943a8ed14bab479b97136cf501f26eea23b92a,Royal Society Open Science
305,Computing Equilibria in Anonymous Games,"We present efficient approximation algorithms for finding Nash equilibria in anonymous games, that is, games in which the players utilities, though different, do not differentiate between other players. Our results pertain to such games with many players but few strategies. We show that any such game has an approximate pure Nash equilibrium, computable in polynomial time, with approximation O(s2lambda), where s is the number of strategies and lambda is the Lipschitz constant of the utilities. Finally, we show that there is a PTAS for finding an isin-approximate Nash equilibrium when the number of strategies is two.",2007-10-21,https://www.semanticscholar.org/paper/40da8359c2000f9feafc79b418ff1cfd0216f47f,IEEE Annual Symposium on Foundations of Computer Science
1621,Structured Embedding Models for Grouped Data,"Word embeddings are a powerful approach for analyzing language, and exponential family embeddings (EFE) extend them to other types of data. Here we develop structured exponential family embeddings (S-EFE), a method for discovering embeddings that vary across related groups of data. We study how the word usage of U.S. Congressional speeches varies across states and party affiliation, how words are used differently across sections of the ArXiv, and how the co-purchase patterns of groceries can vary across seasons. Key to the success of our method is that the groups share statistical information. We develop two sharing strategies: hierarchical modeling and amortization. We demonstrate the benefits of this approach in empirical studies of speeches, abstracts, and shopping baskets. We show how S-EFE enables group-specific interpretation of word usage, and outperforms EFE in predicting held-out data.",2017-09-28,https://www.semanticscholar.org/paper/22f3c0a727bc7f07e7d5073b6d6bb4f73102ba74,Neural Information Processing Systems
1847,Computational Analysis and Visualized Comparison of Style in American Poetry,"This thesis describes the creation of software to quantitatively compute the style of American poems and accordingly visualize a collection of poems in relation to one another. While certain components have been and are being researched, a comparable comprehensive system had not previously been attempted. Such a system has potential applications in academic research of texts and of the intuitive personal response to poetry, in making recommendations to readers based on their favorite poems, and more. Sample applications were developed and run to better assess the accuracy and usefulness of the software.",,https://www.semanticscholar.org/paper/a465c9b65f3f99ec6ee9cb1bea0da9b5c46bd94a,
3221,Moving beyond structure to function,,2018-02-01,https://www.semanticscholar.org/paper/2e94ab0313867b358b1e411eddedc99aa1c74a48,Animal Behaviour
725,On the Complexity of Optimal Lottery Pricing and Randomized Mechanisms,"We study the optimal lottery problem and the optimal mechanism design problem in the setting of a single unit-demand buyer with item values drawn from independent distributions. Optimal solutions to both problems are characterized by a linear program with exponentially many variables. For the menu size complexity of the optimal lottery problem, we present an explicit, simple instance with distributions of support size 2, and show that exponentially many lotteries are required to achieve the optimal revenue. We also show that, when distributions have support size 2 and share the same high value, the simpler scheme of item pricing can achieve the same revenue as the optimal menu of lotteries. The same holds for the case of two items with support size 2 (but not necessarily the same high value). For the computational complexity of the optimal mechanism design problem, we show that unless the polynomial-time hierarchy collapses (more exactly, PNP = P#P), there is no universal efficient randomized algorithm to implement an optimal mechanism even when distributions have support size 3.",2015-10-17,https://www.semanticscholar.org/paper/bca2b5cccf4379e1924571b4f0c379402b13352d,IEEE Annual Symposium on Foundations of Computer Science
1877,Solid waste management in emerging economies: opportunities and challenges for reuse and recycling,,2021-09-01,https://www.semanticscholar.org/paper/1c7bd4528f3942e32c8007e9b1ac2654b0540477,"Resources, Conservation and Recycling"
2109,Design of a sampling strategy for measuring and compensating for overlay errors in semiconductor manufacturing,"To enhance the resolution and alignment accuracy in semiconductor manufacturing, it is important to measure overlay errors and control them into the tolerances by removing assignable causes. A number of related studies have been done to examine the factors causing the overlay errors, to propose mathematical models and to develop overlay error control methods. However, the involved sampling strategies received little attention. This study aimed to propose specific designs of sampling patterns effectively to measure and compensate for overlay errors within the limited number of samples in practice. To verify the validity of the proposed approach, the sampling strategies were compared using empirical data from a wafer fabrication facility. The proposed sampling patterns had a higher goodness of fit for the overlay model and lower residuals after compensation. This paper concludes with our findings and discussions on further research.",2003-01-01,https://www.semanticscholar.org/paper/ff7fee60e3c4842ae0310b6e5e6385a53c96160d,
3565,Programming and Validation Techniques for Reliable Goal-driven Autonomic Software,,,https://www.semanticscholar.org/paper/c21a4e332b7db0494d70810744da97fff4c7bb94,Autonomic Communication
740,How good is the Chord algorithm?,"The Chord algorithm is a popular, simple method for the succinct approximation of curves, which is widely used, under different names, in a variety of areas, such as, multiobjective and parametric optimization, computational geometry, and graphics. We analyze the performance of the chord algorithm, as compared to the optimal approximation that achieves a desired accuracy with the minimum number of points. We prove sharp upper and lower bounds, both in the worst case and average case setting.",2010-01-17,https://www.semanticscholar.org/paper/02feacac034ce8109deaeb6625704e070a1a4caf,ACM-SIAM Symposium on Discrete Algorithms
996,The Effect of Silica Nanoparticles on Human Corneal Epithelial Cells,,2016-10-01,https://www.semanticscholar.org/paper/ece35efa751d3f4bc972dd7c3b0ed9499639d9e4,Scientific Reports
2729,Automated Generation of Three-Dimensional Virtual Worlds for Task Explanation,"Abstract : During the second quarter of our contract, we did further work on the software infrastructure needed to support our research, expanding on the testbed for knowledge-based augmented reality that we had begun to build in September 1991. We concentrated on low-level graphics systems programming needed to improve our support for multiple 3D trackers and to increase the functionality of the 3D graphics package we are using with our head-mounted display, two of the areas detailed in our previous report. In addition, we learned that the paper on this research that we had submitted to Graphics Interface 92 was accepted.",1992-02-29,https://www.semanticscholar.org/paper/b892e3d5ebdc6beece53e5dff0a4e631bc236df9,
3049,Structured linux kernel projects for teaching operating systems concepts,"Linux has emerged as a widely-used platform for enabling hands-on kernel programming experience to learn about operating system concepts. However, developing pedagogically-effective programming projects in the context of a complex, production operating system can be a challenge. We present a structured series of five Linux kernel programming projects suitable for a one semester introductory operating systems course to address this issue. Each assignment introduces students to a core topic and major component of an operating system while implicitly teaching them about various aspects of a real-world operating system. Projects are of modest coding complexity, but require students to understand and leverage core components of the Linux operating system. The learning benefits for students from this approach include learning from real-world operating system code examples by expert kernel designers and gaining software engineering experience managing production code complexity. We have successfully used these structured Linux kernel projects to teach over a thousand students in the introductory operating systems course at Columbia University.",2011-03-09,https://www.semanticscholar.org/paper/3be9c5fa026b3fa887a8652a752d100b84e57451,Technical Symposium on Computer Science Education
3575,What is C++0x?,"This paper illustrates the power of C++ through some simple examples of C++0x code presented in the context of their role in C++. My aim is to give an idea of the breath of the facilities and an understanding of the aims of C++, rather than offering an in-depth understanding of any individual feature. The list of language features and standard library facilities described is too long mention here, but a major theme is the role of features as building blocks for elegant and efficient software, especially software infrastructure components. The emphasis is on C++’s facilities for building lightweight abstractions.",,https://www.semanticscholar.org/paper/c5919ead7fe787bceaad4414567fbaf9b542ead8,
393,Latent Semantic Indexing: A Probabilistic Analysis,"Latent semantic indexing (LSI) is an information retrieval technique based on the spectral analysis of the term-document matrix, whose empirical success had heretofore been without rigorous prediction and explanation. We prove that, under certain conditions, LSI does succeed in capturing the underlying semantics of the corpus and achieves improved retrieval performance. We propose the technique of random projection as a way of speeding up LSI. We complement our theorems with encouraging experimental results. We also argue that our results may be viewed in a more general framework, as a theoretical basis for the use of spectral methods in a wider class of applications such as collaborative filtering.",2000-10-01,https://www.semanticscholar.org/paper/408f9a6585db6f34f9c724b0f5c3600f0e9dab24,Journal of computer and system sciences (Print)
1739,Modeling Overlapping Communities with Node Popularities,"We develop a probabilistic approach for accurate network modeling using node popularities within the framework of the mixed-membership stochastic block-model (MMSB). Our model integrates two basic properties of nodes in social networks: homophily and preferential connection to popular nodes. We develop a scalable algorithm for posterior inference, based on a novel nonconjugate variant of stochastic variational inference. We evaluate the link prediction accuracy of our algorithm on nine real-world networks with up to 60,000 nodes, and on simulated networks with degree distributions that follow a power law. We demonstrate that the AMP predicts significantly better than the MMSB.",2013-12-05,https://www.semanticscholar.org/paper/e2df74941a0a3f11f6126b009e4c154f97600d13,Neural Information Processing Systems
2126,An iterative cutting procedure for determining the optimal wafer exposure pattern,"Conventionally, people focus on defect reduction to improve yield rate. Little research has been done to deal with the problem of optimizing wafer exposure patterns. This paper develops a computer-based procedure to maximize the number of dies possibly produced from a wafer. A program has been developed and implemented in a 6-in wafer fabrication factory in Taiwan. The results validate the practical viability of the proposed procedure.",1999-08-01,https://www.semanticscholar.org/paper/ff49a7d1c5c1621bf293e2d86e0785b67ddaf7e2,
3526,Approximation algorithms for multicommodity flow and shop scheduling problems,"Abstract : In this thesis, we give efficient approximation algorithms for two classical combinatorial optimization problems: multicommodity flow problems and shop scheduling problem. The algorithms we develop for these problems yield solutions that are not necessarily optimal, but come with a provable performance guarantee; that is, we can guarantee that the solution found is within a certain percentage of the optimal solution. This type of algorithm is known as an approximation algorithm. Our results show that by allowing a small error in the solution of a problem, it is often possible to gain a significant reduction in the running time of an algorithm for that problem. In Chapter 2, we study the multicommodity flow problem. The multicommodity flow problem involves simultaneously shipping several different commodities from their respective sources to their sinks in a single network so that the total amount of flow going through each edge is no more than its capacity. Associated with each commodity is a demand, which is the amount of that commodity that we wish to ship. Given a multicommodity flow problem, one often wants to know if there is a feasible flow, i.e., if it is possible to find a flow that satisfies the demands and obeys the capacity constraints. More generally, we might wish to know the maximum percentage z such that at least z percent of each demand can be shipped without violating the capacity constraints. The latter problem is known as the concurrent flow problem. multicommodity flow, scheduling, combinatorial optimization, network algorithms, approximation algorithms, randomized algorithms.",,https://www.semanticscholar.org/paper/a12d31cbdead4a4b737dadf50adf338522633f94,
2034,Cluster analysis of genome-wide expression data for feature extraction,,2009-03-01,https://www.semanticscholar.org/paper/a6ffd8b1c5ed2a65614f0e95ed0b6473f8d7f712,Expert systems with applications
1399,Deployment of the first CDMS II ZIP Detectors at the Stanford Underground Facility,,2002-07-01,https://www.semanticscholar.org/paper/bdd41d5a0e609672caa0ac1763b449c55aeadf75,
1524,Variational Inference for Infinitely Deep Neural Networks,"We introduce the unbounded depth neural network (UDN), an infinitely deep probabilistic model that adapts its complexity to the training data. The UDN contains an infinite sequence of hidden layers and places an unbounded prior on a truncation L, the layer from which it produces its data. Given a dataset of observations, the posterior UDN provides a conditional distribution of both the parameters of the infinite neural network and its truncation. We develop a novel variational inference algorithm to approximate this posterior, optimizing a distribution of the neural network weights and of the truncation depth L, and without any upper limit on L. To this end, the variational family has a special structure: it models neural network weights of arbitrary depth, and it dynamically creates or removes free variational parameters as its distribution of the truncation is optimized. (Unlike heuristic approaches to model search, it is solely through gradient-based optimization that this algorithm explores the space of truncations.) We study the UDN on real and synthetic data. We find that the UDN adapts its posterior depth to the dataset complexity; it outperforms standard neural networks of similar computational complexity; and it outperforms other approaches to infinite-depth neural networks.",2022-09-21,https://www.semanticscholar.org/paper/6eac963198c68e8e54d3f95c7dc87dedd4c34ea0,International Conference on Machine Learning
1559,Posterio Collapse and Latent Variable Non-identiﬁability,"Variational autoencoders model high-dimensional data by positing low-dimensional latent variables that are mapped through a ﬂexible distribution parametrized by a neural network. Unfortunately, variational autoencoders often suﬀer from posterior collapse: the posterior of the latent variables is equal to its prior, rendering the variational autoencoder useless as a means to produce meaningful representations. Existing approaches to posterior collapse often attribute it to the use of neural networks or optimization issues due to variational approximation. In this paper, we show that posterior collapse is a problem of latent variable non-identiﬁability. We prove that the posterior collapses if and only if the latent variables are non-identiﬁable in the generative model. This fact implies that posterior collapse is not a phenomenon speciﬁc to the use of ﬂexible distributions or approximate inference. Rather, it can occur in classical probabilistic models even with exact inference, which we also demon-strate. Based on these results, we propose a class of identiﬁable variational autoencoders, deep generative models which enforce identiﬁability without sacriﬁcing ﬂexibility. This model class resolves the problem of latent variable non-identiﬁability by leveraging bijective Bre-nier maps and parameterizing them with input convex neural networks, without special variational inference objectives or optimization tricks. Across synthetic and real datasets, identiﬁable variational autoencoders outperform existing methods in mitigating posterior collapse and providing meaningful representations of the data.",,https://www.semanticscholar.org/paper/6cdddd82ace8c0970bca736565c9607c45a13874,
1993,Cooperative Estimation of Distribution Algorithm: A Novel Approach for semiconductor final test scheduling,"During the past several years, there have been a significant number of researches conducted in the area of semiconductor final test scheduling problems (SFTSP). As specific example of simultaneous multiple resources scheduling problem (SMRSP), intelligent manufacturing planning and scheduling based on meta-heuristic methods, such as Genetic Algorithm (GA), Simulated Annealing (SA), and Particle Swarm Optimization (PSO), have become the common tools for finding satisfactory solutions within reasonable computational times in real settings. However, limited researches were aiming at analyze the effects of interdependent relations during group decision-making activities. Moreover for complex and large problems, local constraints and objectives from each managerial entity, and their contributions towards the global objectives cannot be effectively represented in a single model. In this paper, we propose a novel Cooperative Estimation of Distribution Algorithm (CEDA) to overcome the challenges mentioned before. The CEDA is established based on divide-and-conquer strategy and a co-evolutionary framework. Considerable experiments have been conducted and the results confirmed that CEDA outperforms recent research results for scheduling problems in FMS (Flexible Manufacturing Systems).",,https://www.semanticscholar.org/paper/154a181f3ef91acb31f101291e304a37011de5aa,
2438,Leveraging Patient-Reported Outcomes Using Data Visualization,"Abstract Background Health care organizations increasingly use patient-reported outcomes (PROs) to capture patients' health status. Although federal policy mandates PRO collection, the challenge remains to better engage patients in PRO surveys, and ensure patients comprehend the surveys and their results. Objective This article identifies the design requirements for an interface that assists patients with PRO survey completion and interpretation, and then builds and evaluates the interface. Methods We employed a user-centered design process that consisted of three stages. First, we conducted qualitative interviews and surveys with 13 patients and 11 health care providers to understand their perceptions of the value and challenges associated with the use of PRO measures. Second, we used the results to identify design requirements for an interface that collects PROs, and designed the interface. Third, we conducted usability testing with 12 additional patients in a hospital setting. Results In interviews, patients and providers reported that PRO surveys help patients to reflect on their symptoms, potentially identifying new opportunities for improved care. However, 6 out of 13 patients reported significant difficultly in understanding PRO survey questions, answer choices and results. Therefore, we identified aiding comprehension as a key design requirement, and incorporated visualizations into our interface design to aid comprehension. In usability testing, patients found the interface highly usable. Conclusion Future interfaces designed to collect PROs may benefit from employing strategies such as visualization to aid comprehension and engage patients with surveys.",2018-07-01,https://www.semanticscholar.org/paper/954011ab14b181af811c2112c59977e03486ec56,Applied Clinical Informatics
2806,The roles of Galectin-3 in autoimmunity and tumor progression,,2012-03-15,https://www.semanticscholar.org/paper/6b5941ff590d02abd6ca8d90e1bfd6c67f9852a1,Immunologic research
3447,"Grouped distributed queues: distributed queue, proportional share multiprocessor scheduling","We present Grouped Distributed Queues (GDQ), the first proportional share scheduler for multiprocessor systems that scales well with a large number of processors and processes. GDQ uses a distributed queue architecture, and achieves accurate proportional fairness scheduling with only O(1) scheduling overhead. GDQ takes a novel approach to distributed queuing: instead of creating per-processor queues that need to be constantly balanced to achieve any measure of proportional sharing fairness, GDQ uses a simple grouping strategy to organize processes into groups based on similar processor time allocation rights, and then assigns processors to groups based on aggregate group shares. Group membership of processes is static, and fairness is achieved by dynamically migrating processors among groups. The set of processors working on a group use simple, low-overhead round-robin queues, while processor reallocation among groups is achieved using a new multiprocessor adaptation of Weighted Fair Queuing. By commoditizing processors and decoupling their allocation from process scheduling, GDQ provides, with only constant scheduling overhead, fairness within a constant of the ideal generalized processor sharing model for process weights with a fixed upper bound. We have implemented GDQ in Linux and measured its performance. Our experimental results show that GDQ has low overhead and scales well with the number of processors and processes.",2006-07-23,https://www.semanticscholar.org/paper/0e3f0e1278b314a2f5e23ef06c71c0e295e32b48,ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing
1018,Guided Deep Reinforcement Learning for Articulated Swimming Robots,"Deep reinforcement learning has recently been applied to a variety of robotics applications, but learning locomotion for robots with unconventional configurations is still limited. Prior work has shown that, despite the simple modeling of articulated swimmer robots, such systems struggle to find effective gaits using reinforcement learning due to the heterogeneity of the search space. In this work, we leverage insight from geometric models of these robots in order to focus on promising regions of the space and guide the learning process. We demonstrate that our augmented learning technique is able to produce gaits for different learning goals for swimmer robots in both low and high Reynolds number fluids.",2023-01-30,https://www.semanticscholar.org/paper/798c599b3ff4ac4392189ec162574400733f32af,arXiv.org
2060,Using genetic algorithms (GA) and a coloured timed Petri net (CTPN) for modelling the optimization-based schedule generator of a generic production scheduling system,"The semiconductor manufacturing industry is one of the most complicated manufacturing systems in the world. Considering its complex problem nature, such as the unrelated parallel machine environment, dynamic job arrival, non-pre-emption, inseparable sequence-dependent set-up time, multiple-resource requirements, general precedence constraint, and job recirculation, this study proposed the optimization-based schedule generator (OptSG) for solving the generalized scheduling problems arising from the semiconductor manufacturing environment. The separation of the problem structure and problem configuration in OptSG contributes to the structural independence, making OptSG robust and convenient in analysis and problem-solving in real settings with changing properties. Meanwhile, an MILP model was proposed as a benchmark to estimate the validity of OptSG. Inseparable sequence-dependent set-up time and multiple-resource requirements that have not been addressed simultaneously in the literature were considered in this model. By using different evaluation criteria, including makespan, total completion time and maximum tardiness, experiments were conducted to compare the solutions of the MILP model, OptSG and dispatching rule-based heuristics (DRBH). The results validated the solution quality of OptSG.",2007-03-09,https://www.semanticscholar.org/paper/1c2682fc1743442f18164f2bbca810f0f06f4598,
2161,Anti-Inflammatory Effects and Decreased Formation of Neutrophil Extracellular Traps by Enoxaparin in COVID-19 Patients,"Neutrophil Extracellular Traps (NETs) are a contributing factor of vascular thrombosis and alveolar damage in COVID-19 patients. As enoxaparin is currently used to inhibit vascular thrombosis, this study aimed to investigate whether enoxaparin also reduced inflammation and NETs in COVID-19 patients. Patients with COVID-19 infection were classified into three groups: mild, moderate, and severe (n = 10 for all groups). Plasma was collected from patients and healthy donors (n = 10). Neutrophils isolated from healthy controls were incubated with COVID-19 or healthy plasma, and with or without enoxaparin pretreatment in vitro. Neutrophils and plasma isolated from patients treated with enoxaparin were also investigated. The levels of inflammatory cytokines and NET products such as dsDNA, NE, MPO–DNA and Histone–DNA complexes in plasma and supernatants were measured using immunofluorescence staining and ELISA kits. The expression of inflammatory signaling genes by neutrophils (RELA, SYK, ERK and PKC) was measured using real-time qPCR. The levels of NET products were elevated in the plasma of COVID-19 patients, particularly in the severe group (p < 0.01). Moreover, plasma from the severe group enhanced NET formation (p < 0.01) from neutrophils in vitro. Enoxaparin pretreatment in vitro decreased plasma-induced NETs in a dose-dependent manner and down-regulated the expression of inflammatory genes (p < 0.05). Patients treated with prophylactic enoxaparin showed lower inflammatory cytokine levels and expression of inflammatory genes (p < 0.05). Increased NETs were associated with the severity of COVID-19 infection, particularly in patients with severe pneumonia, and could be used as biomarkers to assess disease severity. Enoxaparin pretreatment inhibited NETs and reduced the expression of inflammatory cytokines, and these effects mostly persisted in patients treated with prophylactic enoxaparin.",2022-04-27,https://www.semanticscholar.org/paper/03e2abef3d2b1e5b236ad7c3cd86bade4910e85b,International Journal of Molecular Sciences
2552,Visual Hints for Tangible Gestures in Augmented Reality,"Tangible augmented reality (AR) systems imbue physical objects with the ability to act and respond in new ways. In particular, physical objects and gestures made with them gain meaning that does not exist outside the tangible AR environment. The existence of this new set of possible actions and outcomes is not always apparent, making it necessary to learn new movements or gestures. Addressing this opportunity, we present visual hints, which are graphical representations in AR of potential actions and their consequences in the augmented physical world. Visual hints enable discovery, learning, and completion of gestures and manipulation in tangible AR. Here, we discuss our investigation of a variety of representations of visual hints and methods for activating them. We then describe a specific implementation that supports gestures developed for a tangible AR user interface to an electronic field guide for botanists, and present results from a pilot study.",2007-11-13,https://www.semanticscholar.org/paper/0ff3f23b5ce9630b25e5066c159c7154919b6464,2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality
1565,Adapting Text Embeddings for Causal Inference,"Does adding a theorem to a paper affect its chance of acceptance? Does labeling a post with the author's gender affect the post popularity? This paper develops a method to estimate such causal effects from observational text data, adjusting for confounding features of the text such as the subject or writing quality. We assume that the text suffices for causal adjustment but that, in practice, it is prohibitively high-dimensional. To address this challenge, we develop causally sufficient embeddings, low-dimensional document representations that preserve sufficient information for causal identification and allow for efficient estimation of causal effects. Causally sufficient embeddings combine two ideas. The first is supervised dimensionality reduction: causal adjustment requires only the aspects of text that are predictive of both the treatment and outcome. The second is efficient language modeling: representations of text are designed to dispose of linguistically irrelevant information, and this information is also causally irrelevant. Our method adapts language models (specifically, word embeddings and topic models) to learn document embeddings that are able to predict both treatment and outcome. We study causally sufficient embeddings with semi-synthetic datasets and find that they improve causal estimation over related embedding methods. We illustrate the methods by answering the two motivating questions---the effect of a theorem on paper acceptance and the effect of a gender label on post popularity. Code and data available at this https URL}{this http URL",2019-05-29,https://www.semanticscholar.org/paper/09428af106c378616d7767a37c4f4070a2664e5a,Conference on Uncertainty in Artificial Intelligence
164,Brain computation by assemblies of neurons,"Significance Our expanding understanding of the brain at the level of neurons and synapses, and the level of cognitive phenomena such as language, leaves a formidable gap between these two scales. Here we introduce a computational system which promises to bridge this gap: the Assembly Calculus. It encompasses operations on assemblies of neurons, such as project, associate, and merge, which appear to be implicated in cognitive phenomena, and can be shown, analytically as well as through simulations, to be plausibly realizable at the level of neurons and synapses. We demonstrate the reach of this system by proposing a brain architecture for syntactic processing in the production of language, compatible with recent experimental results. Assemblies are large populations of neurons believed to imprint memories, concepts, words, and other cognitive information. We identify a repertoire of operations on assemblies. These operations correspond to properties of assemblies observed in experiments, and can be shown, analytically and through simulations, to be realizable by generic, randomly connected populations of neurons with Hebbian plasticity and inhibition. Assemblies and their operations constitute a computational model of the brain which we call the Assembly Calculus, occupying a level of detail intermediate between the level of spiking neurons and synapses and that of the whole brain. The resulting computational system can be shown, under assumptions, to be, in principle, capable of carrying out arbitrary computations. We hypothesize that something like it may underlie higher human cognitive functions such as reasoning, planning, and language. In particular, we propose a plausible brain architecture based on assemblies for implementing the syntactic processing of language in cortex, which is consistent with recent experimental results.",2019-12-08,https://www.semanticscholar.org/paper/022210ae703b93ed29ce6aec8ffcfad6cbc084f8,Proceedings of the National Academy of Sciences of the United States of America
1760,A Bayesian Boosting Model,"We offer a novel view of AdaBoost in a statistical setting. We propose a Bayesian model for binary classification in which label noise is modeled hierarchically. Using variational inference to optimize a dynamic evidence lower bound, we derive a new boosting-like algorithm called VIBoost. We show its close connections to AdaBoost and give experimental results from four datasets.",2012-09-10,https://www.semanticscholar.org/paper/cff80c31103745ae319bbd62a8d226343d3e4daf,
581,Concurrency Control by Locking,"We present a geometric method for studying concurrency control by locking. When there are only two transactions, our method yields an exact characterization of safe locking policies and also of deadlock-free locking policies. Our results can be extended to more than two transactions, but in that case the problem becomes NP-complete.",1983-05-01,https://www.semanticscholar.org/paper/62310dd997c8e71acbea6e4cc4907ad974d26fa1,SIAM journal on computing (Print)
206,Sex as an algorithm,Looking at the mysteries of evolution from a computer science point of view yields some unexpected insights.,2016-10-28,https://www.semanticscholar.org/paper/8f1501d68983e86ed0ad77ee1b052a981ebd4781,Communications of the ACM
3400,Advance Service Reservations with Heterogeneous Customers,"We study a fundamental model of resource allocation in which a finite number of resources must be assigned in an online manner to a heterogeneous stream of customers. The customers arrive randomly over time according to known stochastic processes. Each customer requires a specific amount of capacity and has a specific preference for each of the resources with some resources being feasible for the customer and some not. The system must find a feasible assignment of each customer to a resource or must reject the customer. The aim is to maximize the total expected capacity utilization of the resources over the horizon. This model has application in services, freight transportation, and online advertising. We present online algorithms with bounded competitive ratios relative to an optimal off-line algorithm that knows all stochastic information. Our algorithms perform extremely well compared with common heuristics as demonstrated on a real data set from a large hospital system in New York City. This paper was accepted by Yinyu Ye, optimization.",2018-05-15,https://www.semanticscholar.org/paper/e24400ee3147ebcb16729a87863543de1ebf7044,Management Sciences
3441,Better online buffer management,"As the Internet becomes more mature, there is a realization that improving the performance of routers has the potential to substantially improve Internet performance in general. Currently, most routers forward packets in a First-In-First-Out (FIFO) order. However, the diversity of applications supported by modern IP-based networks has resulted in unpredictable packet flows, and heterogeneous network traffic. Thus, it is becoming more reasonable to consider differentiating between different types of packets, and perhaps to consider allowing packets to specify a deadline by which it must be processed. These issues have made buffer management at routers a critical issue in providing effective quality of service to the various applications that use the network.
 In this paper, we study an online problem in which each packet is described by its discrete arrival time, non-negative weight and discrete deadline; arriving packets are buffered for delivery and all packets have the same processing time. The packets arrive online, and our objective is to maximize the sum of weights of those packets that are sent by their deadlines. We describe an online deterministic algorithm with a competitive ratio of 1.854, improving the best previous known competitive ratio of 1.939 (Bartal et al. STACS 2004).
 The algorithmic framework we use has several interesting features. First, we do not use a potential function. Instead, after each step we modify the adversary's buffer. Second, we introduce ""dummy packets"" to facilitate the decision making.",2007-01-07,https://www.semanticscholar.org/paper/7ad72f9647513a4693fb30c6aaf0528db999b5a7,ACM-SIAM Symposium on Discrete Algorithms
3101,An Application Streaming Service for Mobile Handheld Devices,"Mobile handheld devices such as PDAs and smartphones are increasingly being used by service providers to deliver application functionality similar to that found in traditional desktop computing environments. However, these handheld applications can be quite slow and often lack important functionality compared to their desktop counterparts. We have developed PASSPORT, (PDA application streaming service portal) a thin-client solution that leverages more powerful servers to run full-function desktop applications and then simply stream screen updates to the PDA for display. PASSPORT uses server-side screen scaling to provide high-fidelity display and seamless mobility across a broad range of different clients and screen sizes, including both portrait and landscape viewing modes. PASSPORT also leverages existing PDA control buttons to improve system usability and maximize available screen resolution for application display. We have implemented PASSPORT on Windows PDAs and demonstrate that it can provide superior application performance and functionality compared to the traditional approach of running applications directly on handheld devices",2006-09-18,https://www.semanticscholar.org/paper/beae55a7523354a298c84f3aeac1c99affa8156e,IEEE International Conference on Services Computing
1834,Correction: A correlated topic model of Science,Correction to Annals of Applied Statistics 1 (2007) 17--35 [doi:10.1214/07-AOAS114],2007-12-01,https://www.semanticscholar.org/paper/e18a0e2f03807c998c92a3b4c68bf031bbb4cec7,
1429,Measurement of the Lambdab0 lifetime using semileptonic decays.,"We report a measurement of the Lambda(b)(0) lifetime using a sample corresponding to 1.3 fb(-1) of data collected by the D0 experiment in 2002-2006 during run II of the Fermilab Tevatron collider. The Lambda(b)(0) baryon is reconstructed via the decay Lambda(b)(0)-->micronuLambda(c)(+)X. Using 4437+/-329 signal candidates, we measure the Lambda(b)(0) lifetime to be tau(Lambda(b)(0))=1.290(-0.110)(+0.119)(stat)(-0.091)(+0.087)(syst) ps, which is among the most precise measurements in semileptonic Lambda(b)(0) decays. This result is in good agreement with the world average value.",1999-02-01,https://www.semanticscholar.org/paper/36b79f7545730310e054ab0cc97ae5049610e76a,Physical Review Letters
2044,Analysing inspection frequency for wafer bumping process and an empirical study of UNISON decision framework,"This study aims to develop a UNISON decision framework for analysing the inspection frequency decisions for the advanced wafer bumping process. Since the accumulated values of the wafers fabricated in wafer fabs are high, process excursion and defects in bumping will cause serious loss. Thus, it is critical to determine the inspection frequency to fulfil the requirement of mass production while ensuring the yield. For validation, an empirical study was conducted in a bumping company and the results showed practical viability of the proposed approach.",2008-03-13,https://www.semanticscholar.org/paper/35f644564bf1da938be2800a9fd6f4de1b99998a,International Journal of Manufacturing Technology and Management (IJMTM)
370,Special Issue on PODS 1999 - Guest Editors' Foreword,,,https://www.semanticscholar.org/paper/5c29b127932fc3d6ed0ebafda5490444149bb293,Journal of computer and system sciences (Print)
3666,Operator Overloading in C,"Operator overloading is giving new functionality to an existing operator. It means the behavior of operators when applied to objects of a class can be redefined. It is similar to overloading functions except the function name is replaced by the keyword operator followed by the operator's symbol. There are 5 operators that are forbidden to overload. In the following code fragment, we will overload binary + operator for Complex number class object.",,https://www.semanticscholar.org/paper/2a392967a4edeee3934287fc3352b5feb4d7e427,
1867,v 3 COMS E 6998-002 : Probabilistic Modeling for Discrete Data Lecture 3 : Word Embeddings III Instructor,"If I missed any of your comments from class below or misattributed an existing comment, it was not intentional, and I'll fix it. The following scribed notes are provided in a stream of consciousness style. If anything is missing or confusing, please let me know and I will update the notes. 0 Logistics • If you are using GitHub, please switch to BitBucket. • Please update your project log every time you work on your project. Be more like Tom. At the end of the previous class, we asked: Why do likelihood ratios give us analogies? Maybe this isn't the right approach. We should start from the modeling assumption that the probability of a word appearing in the context of another word is a log linear model, as follows:",,https://www.semanticscholar.org/paper/0b21071aeb96b73aabdf8e6b4c7d961158da4765,
296,Market equilibrium via a primal--dual algorithm for a convex program,We give the first polynomial time algorithm for exactly computing an equilibrium for the linear utilities case of the market model defined by Fisher. Our algorithm uses the primal--dual paradigm in the enhanced setting of KKT conditions and convex programs. We pinpoint the added difficulty raised by this setting and the manner in which our algorithm circumvents it.,2008-10-01,https://www.semanticscholar.org/paper/ceb12d7358557d362101960501d1cc96b96de786,JACM
1342,and Limits on Anomalous WWZCouplings,,,https://www.semanticscholar.org/paper/52b0aec3c085bcdb95a78d199504d3610494da14,
2268,Regulation of neutrophil apoptosis via death receptors,,2003-11-01,https://www.semanticscholar.org/paper/344163612e1068024cd17faa361d8d0b261b6d83,Cellular and Molecular Life Sciences (CMLS)
1197,Measurement of the polarization of the upsilon(1S) and upsilon(2S) states in pp collisions at square root[s]=1.96 TeV.,"We present a study of the polarization of the Upsilon(1S) and Upsilon(2S) states using a 1.3 fb;{-1} data sample collected by the D0 experiment in 2002-2006 during run II of the Fermilab Tevatron Collider. We measure the polarization parameter alpha=(sigma_{T}-2sigma_{L})/(sigma_{T}+2sigma_{L}), where sigma_{T} and sigma_{L} are the transversely and longitudinally polarized components of the production cross section, as a function of the transverse momentum (p_{T};{Upsilon}) for the Upsilon(1S) and Upsilon(2S). Significant p_{T};{Upsilon}-dependent longitudinal polarization is observed for the Upsilon(1S). A comparison with theoretical models is presented.",2008-04-01,https://www.semanticscholar.org/paper/07ee235b5776fc14e47a861001b27c47e10a8ea4,Physical Review Letters
1028,A physical parameter-based skidding model for the snakeboard,"The physical violation of a nonholonomic system's idealized constraints in the form of skidding has recently elucidated interest in new models in order to directly incorporate the phenomenon into the system dynamics. However, such models either are too simple to capture physical attributes or have otherwise been tested only on systems with simple behaviors, such as the rolling disk. In this work, we present a novel skidding model, based on physical parameters, for a snakeboard system, which is simultaneously rich in behavior but simple in design. This model extends the system's configuration space and associates traction forces to a skidding angle using an experimentally verified observation from the literature. We validate our model in simulation and discuss its advantages over the Rayleigh dissipation function skidding model. We also show that the model accurately predicts a physical system's behavior in experimentation with tuned parameters and standard controllers.",2016-12-01,https://www.semanticscholar.org/paper/12f79d003d4dd6b2db848ce71b233d9d8ff943cd,IEEE Conference on Decision and Control
589,Symmetric Space-Bounded Computation,,1982-08-01,https://www.semanticscholar.org/paper/3739fc0150b4dcd7d826d2eef807f1a5693e5a34,Theoretical Computer Science
1633,Zero-Inflated Exponential Family Embeddings,"Word embeddings are a widely-used tool to analyze language, and exponential family embeddings (Rudolph et al., 2016) generalize the technique to other types of data. One challenge to fitting embedding methods is sparse data, such as a document/term matrix that contains many zeros. To address this issue, practitioners typically downweight or subsample the zeros, thus focusing learning on the non-zero entries. In this paper, we develop zero-inflated embeddings, a new embedding method that is designed to learn from sparse observations. In a zero-inflated embedding (ZIE), a zero in the data can come from an interaction to other data (i.e., an embedding) or from a separate process by which many observations are equal to zero (i.e. a probability mass at zero). Fitting a ZIE naturally downweights the zeros and dampens their influence on the model. Across many types of data— language, movie ratings, shopping histories, and bird watching logs—we found that zero-inflated embeddings provide improved predictive performance over standard approaches and find better vector representation of items.",2017-07-17,https://www.semanticscholar.org/paper/b0f7e146bff2f5be42c4d84eac2f7309310c54b7,International Conference on Machine Learning
1883,Dynamic coordinated scheduling for supply chain under uncertain production time to empower smart production for Industry 3.5,,2020-04-01,https://www.semanticscholar.org/paper/44249e25f5050cfd39280d4bdd964f12c810c903,Computers & industrial engineering
1901,AI and Big Data Analytics for Wafer Fab Energy Saving and Chiller Optimization to Empower Intelligent Manufacturing,"The chiller machine is one of the most electricity-consuming parts of factory facilities in high-tech industries such as semiconductor and TFT-LCD manufacturing. To reduce variability and optimize the chiller allocation, researchers have come up with various solutions, but few of them can indeed be widely adopted due to differences of factory layout, machine types, data collections, etc. This study proposes a solution that integrates big data analytics and machine learning techniques to automatically provide recommendations of chiller optimization for energy saving. The optimal chiller adjustment is defined as the condition that the required cooling load for a wafer fab is satisfied while and the electricity consumption is minimized. In the meantime, those adjustment alternatives considering chiller healthy status to obviate inappropriate combinations. Hence, engineers only need to judge the rationality of these recommendations to adjust chillers so that can guarantee operation effectiveness and efficiency as well as empower intelligent manufacturing. An empirical study was conducted in a leading semiconductor company in Taiwan to demonstrate the validity of the proposed approach.",2018-09-01,https://www.semanticscholar.org/paper/3ef3ba2ae62f0c834ec2f63d555d96fcae9d4768,2018 e-Manufacturing & Design Collaboration Symposium (eMDC)
988,Spectral-domain optical coherence tomography in glaucoma: its additive role in structural diagnosis,,2016-09-26,https://www.semanticscholar.org/paper/12ee57a2225016a2751a7249234392fc2652cbf5,
3391,A General Framework for Handling Commitment in Online Admission Control,,,https://www.semanticscholar.org/paper/5169bc1b772cffc5351cc6b0fbeafe5914074636,
2357,Role of myeloperoxidase in the killing of Staphylococcus aureus by human neutrophils: studies with the myeloperoxidase inhibitor salicylhydroxamic acid.,"We have used salicylhydroxamic acid (SHAM) to inhibit intraphagosomal myeloperoxidase activity in order to evaluate the role of this enzyme in the killing of Staphylococcus aureus by human neutrophils. 50 microM-SHAM reduced the luminol-dependent chemiluminescence response stimulated during phagocytosis of unopsonized latex beads and opsonized S. aureus by over 80% and 60%, respectively. When opsonized S. aureus were incubated with neutrophils, 45% were killed within 15 min incubation and 60% by 1 h. However, in neutrophil suspensions incubated with 50 microM-SHAM, only 13% were killed by 15 min whilst 71% still remained viable after 1 h. This inhibitor had no effect upon the number of bacteria phagocytosed or upon degranulation. In a cell-free system, 2.5 microM-H2O2 alone killed 55% of the bacteria, whereas in the presence of myeloperoxidase (i.e. 10 mU myeloperoxidase and 2.5 microM-H2O2) virtually all of the bacteria were killed: the addition of 50 microM-SHAM abolished this myeloperoxidase-enhanced killing but did not affect the H2O2-dependent killing. We therefore conclude that in normal neutrophils whilst H2O2 is required for killing of this pathogen, both myeloperoxidase-dependent and -independent pathways exist.",1989-05-01,https://www.semanticscholar.org/paper/63ec0a0fa9d7c7b85b53004e8043be7d8f4e3df9,Journal of General Microbiology
2312,Neutrophils from preterm neonates and adults show similar cell surface receptor expression: analysis using a whole blood assay.,"Previous work has shown that Fc gamma RIII expression in isolated neonate neutrophils is defective. We have re-examined this phenomenon in view of the facts that (1) the receptor is present on mobilisable subcellular stores and (2) commonly used isolation procedures can affect receptor expression in suspensions of isolated neutrophils. Receptor expression was measured by fluorescence-activated cell sorter analysis of neutrophils in unfractionated whole blood. Examination of receptor expression in preterm, term and adult neutrophils indicated small but significantly decreased expression of CR1 and CR3 in preterm neutrophils compared with term neutrophils (p < 0.01). A small decrease in expression was found for Fc gamma RI and Fc gamma RIII (p < 0.05). No significant difference in expression of Fc gamma RII was observed in all groups analysed. These data suggest that isolated preterm neonate neutrophils have greatly decreased expression of Fc gamma RIII because of impaired composition or mobilisation of the subcellular stores of this receptor and/or increased lability of the surface receptor which leads to its shedding during purification.",,https://www.semanticscholar.org/paper/641d6dabbecfbcffe0cbc2a48fa6b22d8390cfa3,Biology of the Neonate
3531,Leighton-Rao might be practical: faster approximation algorithms for concurrent flow with uniform capacities,"In this paper, we describe new algorithms for approximately solving the concurrent multicommodity flow problem with uniform capacities. Our algorithms are much faster than previously known algorithms. Besides being an important problem in its own right, the concurrent flow problem has many interesting applications. Leighton and Rao used concurrent flow to find an approximately ""sparsest cut"" in a graph, and thereby approximately solve a wide variety of graph problems, including minimum feedback arc set, minimum cut linear arrangement, and minimum area layout. We show that their method might be practical by giving an O(m~logm) expected-time randomized algorithm for their concurrent flow problem on an m-edge graph. l~aghavan and Thompson used concurrent flow to approximately solve a channel width minimization problem in VLSI. We give an O(k3/2(m+n log n)) expectedtime randomized algorithm and an O(k min{n, k}(m + n log n) log k) deterministic algorithm for this problem when the channel width is O(logn), where k denotes the number of wires to be routed in an n-node, m-edge network, *Research partially suppor ted by ONR grant N00014-88-K0243 and DARPA grant N00039-88-C0113 at Harvard University tSuppor t provided by Air Force Contract AFOSI:t-86-0078, and by an NSF PYI awarded to David Shmoya, with matching funds from IBM, Sun Microsysterns, and UPS. t Research partially supported by NSF grant DMS87-06133. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 1 I n t r o d u c t i o n The multicommodity flow problem involves shipping several different commodities from their respective sources to their sinks in a single network with the total amount of flow going through an edge limited by its capacity. Here we consider the concurrent flow problem with uniform capacities, which is the problem of finding a multicommodity flow that minimizes the maximum total flow on any edge (the congestion). An important special case of the problem, called the unit-demand unit-capacity concurrent flow problem, arises when the amount of flow that needs to be shipped is the same for each commodity. For both versions of the problem we give algorithms that, for any positive e, find a solution whose congestion is no more than (1 + e) times the minimum congestion. Our algorithms significantly improve the time required for finding such approximately optimal solutions. We shall use n, m and k to denote the number of nodes, edges and commodities. Leighton and Rao [7] showed how to use the solution to a unit-capacity unit-demand concurrent fiow problem to find an approximate ""sparsest cut"" of a graph. As a consequence, they gave the first polylog-timesoptimal approximation algorithms for a wide variety of graph problems. The computational bottleneck of their method is solving a unit-capacity unit-demand concurrent flow problem with O(n) commodities. They appealed to linear programming techniques to show that the problem can be solved in polynomial time. The new approximation algorithm greatly improves the resulting running time. T h e o r e m 1.1 For any fixed 0 < e < 1, a (1 + e)-factor approximation to the unit-capacity unit-demand concurrent flow problem can be found by a randomized algorithm in O((k + m)mlogm) time, where the constant depends",1990-04-01,https://www.semanticscholar.org/paper/f9aea0cac404108bbbc71eb1f91afdc89a4a4980,Symposium on the Theory of Computing
1875,Integrated circuit probe card troubleshooting based on rough set theory for advanced quality control and an empirical study,,2022-11-03,https://www.semanticscholar.org/paper/e13a880180ba424f00796f8c388d162f3df9cb11,Journal of Intelligent Manufacturing
3630,Proposal to Acknowledge That Garbage Collection for C++ Is Possible X3j16/96-0114 Wg21/n0932,"The ARM, ""The C++ Programming Language (2nd edition)"", and ""The Design and Evolution of C++"" all mention that automatic garbage collection of C++ is possible, but that an implementation is not required to provide a garbage collector. This is a proposal to make this explicit in the standard and to specify a couple of details of what it means to collect garbage. The proposal is for clarification rather than significant normative changes.",,https://www.semanticscholar.org/paper/8ff7802cd9f7e89887f1dfae9c251307794c617d,
2846,"Expression and Function of Galectin-3, a f-Galactoside-Binding Lectin, in Human Monocytes and Macrophages","A family of flgalactoside-binding animal lectins has recently been designated as galectins. One member of this family, galectin-3, has been known as cBPfor its IgE-binding activity and as Mac-2, a macrophage surface antigen, CBP35, CBP30, L-29, and L-34. Although much information has accumulated on the expression of this lectin in murine macrophages and human monocytic cell lines, little is known about the expression and function of this protein in normal human monocytes/macrophages. We now report that galectin-3 is expressed in normal human peripheral blood monocytes and its level increases dramaticaly as human monocytes differentiate into macrophages upon culturing in vitro Immunoblot analysis showed that there was a 5-fold increase in the level of galectin-3 after I day of culture and greater than a 12-fold increase after 5 days. Immunocytochemical analysis confirmed this progressive increase of galectin-3 expression in cultured monocytes. Immunogold cytochemistry/electron microscopy galectin-3 was the surface of human the of",,https://www.semanticscholar.org/paper/0ddcb178dd5511441c4d4df2348ffc3dedb0ee30,
3287,"Aggression, grooming and group‐level cooperation in white‐faced capuchins (Cebus capucinus): insights from social networks","The form of animal social systems depends on the nature of agonistic and affiliative interactions. Social network theory provides tools for characterizing social structure that go beyond simple dyadic interactions and consider the group as a whole. We show three groups of capuchin monkeys from Barro Colorado Island, Panama, where there are strong connections between key aspects of aggression, grooming, and proximity networks, and, at least among females, those who incur risk to defend their group have particular “social personalities.” Although there is no significant correlation for any of the network measures between giving and receiving aggression, suggesting that dominance relationships do not follow a simple hierarchy, strong correlations emerge for many measures between the aggression and grooming networks. At the local, but not global, scale, receiving aggression and giving grooming are strongly linked in all groups. Proximity shows no correlation with aggression at either the local or the global scale, suggesting that individuals neither seek out nor avoid aggressors. Yet, grooming has a global but not local connection to proximity. Extensive groomers who tend to direct their efforts at other extensive groomers also spend time in close proximity to many other individuals. These results indicate the important role that prosociality plays in shaping female social relationships. We also show that females who receive the least aggression, and thus pay low costs for group living, are most likely to participate in group defense. No consistent “social personality” traits characterize the males who invest in group defense. Am. J. Primatol. 73:821–833, 2011. © 2011 Wiley‐Liss, Inc.",2011-08-01,https://www.semanticscholar.org/paper/823dd2e8f486ecb7dac716a994f49071fa7f8706,American Journal of Primatology
1468,F1 (1285) formation in photon photon fusion reactions,,1988-07-28,https://www.semanticscholar.org/paper/dfaf3e1f2053ed2738b50ccba6e5c53d1781b7e5,
2137,Decay of reverberant sound in a spherical enclosure,"The assumption of diffuse reflection (Lambert’s Law) leads to integral equations for the wall intensity in a reverberant sound field in the steady state and during decay. The latter equation, in the special case of a spherical enclosure with uniformly absorbent walls and uniform wall intensity, allows exponential decay with a decay time which agrees closely with the Norris–Eyring prediction. The sound‐intensity and sound‐energy density in the medium, during decay, are also calculated.",1977-12-01,https://www.semanticscholar.org/paper/d18608419275729db12d293532d52827c5004458,
1465,Charged hadron production in e/sup +/e/sup -/ annihilation at. sqrt. s = 29 GeV,"We have used data from the Time Projection Chamber at the SLAC storage ring PEP to study the inclusive production of charged hadrons in e/sup /+//e/sup /-// annihilation at a center of mass energy of 29 GeV. Charged particles were identified by simultaneous dEdx and momentum measurements. We present cross sections and particle fractions for ..pi../sup/plus minus//, k/sup + -/, and p(/ovr/p//) as a function of energy, momentum, rapidity, and transverse momentum. We compare the predictions of various hadronization models to the data and note discrepancies at high momentum.",1988-03-01,https://www.semanticscholar.org/paper/39dbc1b69194846bbdb6f5b052311335c2f530d0,
995,Spectral-domain Optical Coherence Tomography in Manifest Glaucoma: Its Additive Role in Structural Diagnosis.,,2016-11-01,https://www.semanticscholar.org/paper/d582b775b4321e97bf6bbafae69beb5709acea42,American journal of ophthalmology-glaucoma
1436,Preliminary limits on the WIMP-nucleon cross section from the cryogenic dark matter search (CDMS),,1997-12-30,https://www.semanticscholar.org/paper/c365eafcce1dd3806f9cb178d277f5ad9109c0a1,
773,Realizability and verification of MSC graphs,,2005-02-15,https://www.semanticscholar.org/paper/bff6c72f7826ad4831c0b65e6ed322165ee5504d,Theoretical Computer Science
1198,A Search for W IM Ps w ith the First Five-Tower D ata from C D M S,,,https://www.semanticscholar.org/paper/0ad1625017f339f714152f7fc5762c7286a6767c,
2646,Mobile augmented reality: a complex human-centered system,,,https://www.semanticscholar.org/paper/bc5c818a93d77d2790f2e2aaccba4595242d117e,
182,From Nash Equilibria to Chain Recurrent Sets: An Algorithmic Solution Concept for Game Theory,"In 1950, Nash proposed a natural equilibrium solution concept for games hence called Nash equilibrium, and proved that all finite games have at least one. The proof is through a simple yet ingenious application of Brouwer’s (or, in another version Kakutani’s) fixed point theorem, the most sophisticated result in his era’s topology—in fact, recent algorithmic work has established that Nash equilibria are computationally equivalent to fixed points. In this paper, we propose a new class of universal non-equilibrium solution concepts arising from an important theorem in the topology of dynamical systems that was unavailable to Nash. This approach starts with both a game and a learning dynamics, defined over mixed strategies. The Nash equilibria are fixpoints of the dynamics, but the system behavior is captured by an object far more general than the Nash equilibrium that is known in dynamical systems theory as chain recurrent set. Informally, once we focus on this solution concept—this notion of “the outcome of the game”—every game behaves like a potential game with the dynamics converging to these states. In other words, unlike Nash equilibria, this solution concept is algorithmic in the sense that it has a constructive proof of existence. We characterize this solution for simple benchmark games under replicator dynamics, arguably the best known evolutionary dynamics in game theory. For (weighted) potential games, the new concept coincides with the fixpoints/equilibria of the dynamics. However, in (variants of) zero-sum games with fully mixed (i.e., interior) Nash equilibria, it covers the whole state space, as the dynamics satisfy specific information theoretic constants of motion. We discuss numerous novel computational, as well as structural, combinatorial questions raised by this chain recurrence conception of games.",2018-10-01,https://www.semanticscholar.org/paper/91b1271aa1f675d8ab6a51b581d722a7e7b69382,Entropy
3760,Generating Videos with Scene Dynamics,"We capitalize on large amounts of unlabeled video in order to learn a model of scene dynamics for both video recognition tasks (e.g. action classification) and video generation tasks (e.g. future prediction). We propose a generative adversarial network for video with a spatio-temporal convolutional architecture that untangles the scene's foreground from the background. Experiments suggest this model can generate tiny videos up to a second at full frame rate better than simple baselines, and we show its utility at predicting plausible futures of static images. Moreover, experiments and visualizations show the model internally learns useful features for recognizing actions with minimal supervision, suggesting scene dynamics are a promising signal for representation learning. We believe generative video models can impact many applications in video understanding and simulation.",2016-09-08,https://www.semanticscholar.org/paper/ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1,Neural Information Processing Systems
1452,Letter of Intent for the Study of CP Violation and Heavy Flavor Physics at PEP-II,,1994-06-01,https://www.semanticscholar.org/paper/a299331fd8aecf22a01ab3550b5cbc281696b1cb,
2310,Modulation of neutrophil apoptosis by pharmacological agents.,"The human neutrophil is known to have a short half-life in circulation, estimated to be between 8 and 16 h. This lifespan is so short because circulating neutrophils constituitively undergo apoptosis. As neutrophils become apoptotic the chromatin becomes condensed and fragmented, expression of the low affinity receptor for IgG (CD16) on the cell surface falls and functional activities such as the ability to produce superoxide are diminished [ 11. Apoptotic circulating neutrophils are quickly cleared from the circulation by phagwytic cells, which recognise markers of apoptosis on the cell surface [2]. As the mature neutrophil has such a short lifespan, the production of neutrophils from the bone marrow must be maintained at -5 x 10"" every day to keep numbers of circulating neutrophils at levels that are able to protect against infections. If this production of neutrophils is disrupted, neutropaenia quickly develops, resulting in a decreased ability to fight off bacterial or fungal infections. Patients undergoing chemoor radio-therapy for the treatment of certain leukaemia's and solid tumours are known to suffer from neutropaenia during the periods of treatment due to damage to the bone marrow. The period and severity of the neutropeania vary greatly, but in all cases there is an increased risk of infection in these patients. This often results in a suspension of therapy and increased hospitalisation times. This therapyinduced neutropaenia may be managed by the use of colony stimulating factors such as Granulocyte-Colony Stimulating Factor (GM-CSF) to increase the production of neutrophils from the bone marrow. These treatments show a reduction in the period and severity of the neutropeania but side-effects such as increased adhesion of neutrophils to capillary walls and pulmonary accumulation, due to up-regulation of certain surface proteins, may be seen. These side-effects are a consequence of neutrophil priming. As an alternative to the use of colony stimulating factors to increase neutrophil production we have been studying the effects of three pharmacological agents (5azacytidine, hexarnethylene-bis-acetamide [HMBA] and sodium butyrate) on neutrophil apoptosis, with the aim of increasing the functional lifespan of the circulating neutrophil. Each of these drugs have previously been shown not to prime neutrophils [3] and so should not elicit the side effects that result from CSFinduced increases in adhesion. Neutrophils were isolated from venous blood of healthy volunteers to >98% purity, and suspended in RPMI 1640 medium supplemented with 0.25% (v/v) foetal calf serum and 2 mM L-glutamine as in [4]. Suspensions of 5 x lo6 celldml were incubated with no additions (controls), or were supplemented with 50 U/ml GM-CSF, 50 ph4 5-azacytidine, 1 mM hexamethylene-bis-acetamide, 0.4 mM sodium butyrate or a combination of GM-CSF with each of the other drugs. After incubation at 37 ""C for 22 h neutrophil aliquots were used for morphological assessment of apoptosis, ability to produce superoxide, and measurement of DNA fragmentation. Cytospins were prepared from 10' cells and stained with May-Griinwald solution; at least 500 cells were assessed per slide [4]. Superoxide production was measured from 5 x Id cells with 10 @I luminol using either 1 @I f-Met-Leu-Phe or 100 ng/d PMA [5]. DNA fragmentation was measured by separating fragmented and non-fragmented DNA by cenbifugation and determining DNA content colorimetrically using diphenylamine reagent [4]. Table 1. shows that sodium butyrate protects neutrophils from apoptosis more effectively than GM-CSF, confirming our previous results, and that this effect is enhanced when these two agents are used together. Sodium butyrate [6], 5-azacyt1dine [7] and HMBA [8] have all been shown to increase gene transcription in other cell types, and to stimulate protein biosynthesis in human neutrophils [3]. However neither HMBA or 5-azacyt1dine gave significant protection from apoptosis Table 1. &",1996-08-01,https://www.semanticscholar.org/paper/c81af580f7bc891821d337b322377800b9b7cf04,Biochemical Society Transactions
2256,The mitochondrial adenosine triphosphatase ofAcanthamoeba castellanii,"1. The mitochondrial ATPase of Acanthamoeba castellanii accumulated discontinuously in synchronous cultures prepared by a minimally perturbing size-selection technique. 2. Enzyme activity per ml of culture doubled overall during one cell cycle time of 8h, but oscillated to give seven maxima during this period. Similar oscillations were observed in the specific activities of ATPase and of the naturally occurring inhibitor protein. 3. These variations in enzyme activity reflected changes in amount of enzyme protein as assayed by an immunological technique. 4. Large variations in 150 values (pg of inhibitor/mg of protein necessary for 50% inhibition of inhibitor-sensitive activity) for inhibition of ATPase activity by seven different inhibitors of energy conservation were observed. Activity was more sensitive to inhibition by oligomycin, efrapeptin, citreoviridin and quercetin when values were highest. 5. The results are discussed in relation to the phased organization of biosynthesis and degradation of cellular components known to occur during the cell cycle of this organism.",,https://www.semanticscholar.org/paper/45e694c8a21e6571a3e1b111a108bb024866e208,
2223,"Mavrilimumab, a human monoclonal GM-CSF receptor-α antibody for the management of rheumatoid arthritis: a novel approach to therapy","Introduction: Mavrilimumab, formerly known as CAM-3001, a GM-CSF receptor-α antibody, is the first human monoclonal antibody to be used in Phase II studies (2011) to modulate the innate immunity pathway targeting GM-CSF signaling in moderate rheumatoid arthritis (RA). Areas covered: Analysis of available clinical trial data on GM-CSF receptor-α antibody and medical literature search using MEDLINE for molecular mechanisms of pathogenesis of RA and its treatment forms the basis of this expert opinion review. The mavrilimumab Phase II double blind, randomized, placebo-controlled ascending dose trial demonstrated statistically significant achievement of primary and secondary end points in patients with moderate RA. The trial demonstrated significant clinical benefit in the 100 mg mavrilimumab cohort compared to the placebo group. Expert opinion: The novel molecular targeting mechanism of mavrilimumab together with its demonstrated clinical efficacy, tolerability and safety profile in Phase II clinical trials in moderate RA, suggests significant potential utility for this drug to induce clinical remission, reduce flares and improve morbidity and mortality in patients with RA.",2012-11-10,https://www.semanticscholar.org/paper/53059edc8379f7ba6573b4da84f726fba07f6760,Expert Opinion on Biological Therapy
1119,"Publisher’s Note: Search forCPviolation inBs0→μ+Ds−Xdecays inpp¯collisions ats=1.96TeV[Phys. Rev. D82, 012003 (2010)]",,2011-06-03,https://www.semanticscholar.org/paper/ff15a3e6f7fbdec8e2c5f894601b837c7ba650fd,
1638,Variational Sequential Monte Carlo,"Many recent advances in large scale probabilistic inference rely on variational methods. The success of variational approaches depends on (i) formulating a flexible parametric family of distributions, and (ii) optimizing the parameters to find the member of this family that most closely approximates the exact posterior. In this paper we present a new approximating family of distributions, the variational sequential Monte Carlo (VSMC) family, and show how to optimize it in variational inference. VSMC melds variational inference (VI) and sequential Monte Carlo (SMC), providing practitioners with flexible, accurate, and powerful Bayesian inference. The VSMC family is a variational family that can approximate the posterior arbitrarily well, while still allowing for efficient optimization of its parameters. We demonstrate its utility on state space models, stochastic volatility models for financial data, and deep Markov models of brain neural circuits.",2017-05-31,https://www.semanticscholar.org/paper/fbb8aaac1b6bc7326fad06c4bb8ef10c61c8f1d2,International Conference on Artificial Intelligence and Statistics
727,"Upper Bounds for Newton’s Method on Monotone Polynomial Systems, and P-Time Model Checking of Probabilistic One-Counter Automata","A central computational problem for analyzing and model checking various classes of infinite-state recursive probabilistic systems (including quasi-birth-death processes, multitype branching processes, stochastic context-free grammars, probabilistic pushdown automata and recursive Markov chains) is the computation of termination probabilities, and computing these probabilities in turn boils down to computing the least fixed point (LFP) solution of a corresponding monotone polynomial system (MPS) of equations, denoted x=P(x). It was shown in Etessami and Yannakakis [2009] that a decomposed variant of Newton’s method converges monotonically to the LFP solution for any MPS that has a nonnegative solution. Subsequently, Esparza et al. [2010] obtained upper bounds on the convergence rate of Newton’s method for certain classes of MPSs. More recently, better upper bounds have been obtained for special classes of MPSs [Etessami et al. 2010, 2012]. However, prior to this article, for arbitrary (not necessarily strongly connected) MPSs, no upper bounds at all were known on the convergence rate of Newton’s method as a function of the encoding size |P| of the input MPS, x=P(x). In this article, we provide worst-case upper bounds, as a function of both the input encoding size |P|, and ε > 0, on the number of iterations required for decomposed Newton’s method (even with rounding) to converge to within additive error ε > 0 of q*, for an arbitrary MPS with LFP solution q*. Our upper bounds are essentially optimal in terms of several important parameters of the problem. Using our upper bounds, and building on prior work, we obtain the first P-time algorithm (in the standard Turing model of computation) for quantitative model checking, to within arbitrary desired precision, of discrete-time QBDs and (equivalently) probabilistic 1-counter automata, with respect to any (fixed) ω-regular or LTL property.",2013-02-15,https://www.semanticscholar.org/paper/12ee4fe3cd8ea4cd84e80828832a28bb4f93e17b,Journal of the ACM
1020,The Geometric Structure of Externally Actuated Planar Locomoting Systems in Ambient Media,"Robots often interact with the world via attached parts such as wheels, joints, or appendages. In many systems, these interactions, and the manner in which they lead to locomotion, can be understood using the machinery of geometric mechanics, explaining how inputs in the shape space of a robot affect motion in its configuration space and the configuration space of its environment. In this paper we consider an opposite type of locomotion, wherein robots are influenced actively by interactions with an externally forced ambient medium. We investigate two examples of externally actuated systems; one for which locomotion is governed by a principal connection, and is usually considered to possess no drift dynamics, and another for which no such connection exists, with drift inherent in its locomotion. For the driftless system, we develop geometric tools based on previously understood internally actuated versions of the system and demonstrate their use for motion planning under external actuation. For the system possessing drift, we employ nonholonomic reduction to obtain a reduced representation of the system dynamics, illustrate geometric features conducive to studying locomotion, and derive strategies for external actuation.",2021-08-14,https://www.semanticscholar.org/paper/e38c13e5e83b34494c27a4d73477b1bc1e9baf0f,arXiv.org
919,The Clique Problem for Planar Graphs,,,https://www.semanticscholar.org/paper/1af1c38925c2df2d192203a6f19c124b0b5814b6,Information Processing Letters
2560,IEEE Symposium on 3D User Interfaces 2007,The following topics are dealt with: virtual reality; 3D movement; sequences & gestures; devices; mixed & augmented reality; 3D selection; forces; and 3D navigation & entertainment,,https://www.semanticscholar.org/paper/a997d172358730c82ef89283e4d42007066a7055,IEEE Symposium on 3D User Interfaces
3075,WARP: Enabling fast CPU scheduler development and evaluation,"Developing CPU scheduling algorithms and understanding their impact in practice can be difficult and time consuming due to the need to modify and test operating system kernel code and measure the resulting performance on a consistent workload of real applications. To address this problem, we have developed WARP, a trace-driven virtualized scheduler execution environment that can dramatically simplify and speed the development of CPU schedulers. WARP is easy to use as it can run unmodified kernel scheduling code and can be used with standard user-space debugging and performance monitoring tools. It accomplishes this by virtualizing operating system and hardware events to decouple kernel scheduling code from its native operating system and hardware environment. A simple kernel tracing toolkit can be used with WARP to capture traces of all CPU scheduling related events from a real system. WARP can then replay these traces in its virtualized environment with the same timing characteristics as in the real system. Traces can be used with different schedulers to provide accurate comparisons of scheduling performance for a given application workload. We have implemented a WARP Linux prototype. Our results show that WARP can use application traces captured from its toolkit to accurately reflect the scheduling behavior of the real Linux operating system. Furthermore, testing scheduler behavior using WARP with application traces can be two orders of magnitude faster than running the applications using Linux.",2009-04-26,https://www.semanticscholar.org/paper/b5d5921662913507e9085291efa1e306b11a542e,IEEE International Symposium on Performance Analysis of Systems and Software
1224,Search for Higgs bosons decaying to tau pairs in pp over collisions with the D0 detector.,"We present a search for the production of neutral Higgs bosons varphi decaying into tau+tau - final states in pp over collisions at a center-of-mass energy of 1.96 TeV. The data, corresponding to an integrated luminosity of approximately 1 fb(-1), were collected by the D0 experiment at the Fermilab Tevatron Collider. Limits on the production cross section times branching ratio are set. The results are interpreted in the minimal supersymmetric standard model yielding limits that are the most stringent to date at hadron colliders.",2008-05-16,https://www.semanticscholar.org/paper/611313076a36d38b6f0c9f6c25dd199dca383d92,Physical Review Letters
213,Assembly projections support the assignment of thematic roles to concepts in networks of spiking neurons,"Currently existing neural network models lack an important computational capability of networks of neurons in the brain: the capability to reason on an abstract level, and to structure information according to abstract categories. While hardly anything is known about the processes underlying these capabilities in the human brain, experimental evidence for the organization of an important prerequisite for abstract reasoning has recently been found: for assigning words to thematic roles, such as subject or object. Such data from fMRI recordings indicate that assemblies in subregions of temporal cortex which encode thematic roles are shaped by concepts that are assigned to that role. We propose a model for the assignment of thematic content to variables that is consistent with these data and provides new functions to neural network computations. We provide a proof of principle that this model can be implemented even in networks of spiking neurons. It enables structured information retrieval and copying of information without routing, and provides a basis for the emulation of more demanding cognitive computations in networks of spiking neurons.",2016-11-11,https://www.semanticscholar.org/paper/f1a97a6f976829b3d47a75417f216fc4c6ed7e26,
3191,Moving through the mosaic: identifying critical linkage zones for large herbivores across a multiple‐use African landscape,,2021-03-14,https://www.semanticscholar.org/paper/4a6a1676680c2aa84c55b811a09a68c907325b23,Landscape Ecology
3169,"A Framework for Fast, Large-scale, Semi-Automatic Inference of Animal Behavior from Monocular Videos","An automatic, quick, accurate, and scalable method for animal behavior inference using only videos of animals offers unprecedented opportunities to understand complex biological phenomena and answer challenging ecological questions. The advent of sophisticated machine learning techniques now allows the development and implementation of such a method. However, apart from developing a network model that infers animal behavior from video inputs, the key challenge is to obtain sufficient labeled (annotated) data to successfully train that network - a laborious task that needs to be repeated for every species and/or animal system. Here, we propose solutions for both problems, i) a novel methodology for rapidly generating large amounts of annotated data of animals from videos and ii) using it to reliably train deep neural network models to infer the different behavioral states of every animal in each frame of the video. Our method’s workflow is bootstrapped with a relatively small amount of manually-labeled video frames. We develop and implement this novel method by building upon the open-source tool Smarter-LabelMe, leveraging deep convolutional visual detection and tracking in combination with our behavior inference model to quickly produce large amounts of reliable training data. We demonstrate the effectiveness of our method on aerial videos of plains and Grévy’s Zebras (Equus quagga and Equus grevyi). We fully open-source the code1 of our method as well as provide large amounts of accurately-annotated video datasets2 of zebra behavior using our method. A video abstract of this paper is available here3.",2023-08-02,https://www.semanticscholar.org/paper/98e3b68ea3e6d9df7bb9f4ae3b5aa4b92f547024,bioRxiv
1459,First QCD results from SLD,"k .. The first Z” data were recorded by the SLD experiment at SLAC during an engineering run in 1991’. From the sample of a few hundred hadronic events collected, the strong coupling cr,(Mz) has been measured from jet rates and energy-energy correlations -(EEC). These (p re iminary) 1 results are presented here. From jet rates a second order perturbative QCD fit yields: a,(Mz) = 0.117 f 0.009 (stat.) f 0.006 (exp. syst.) ‘8*$; (theory). Large systematic differences between cyb values derived from fits to the EEC distribution are observed for various second order QCD calculations, in addition-to a significant dependence on the QCD renormalisation scale ~1~. For the Kunszt-Nason calculations at p2 = 0.1, ty#(Mz) = 0.123 f 0.004 (stat.) ~$~~ (exp. syst.) ‘i:$i (theory) is obtained. For both measurements the theoretical error is dominated by the uncertainty involved in choosing the scale p2. . Presented at the XXVII Rencontre de Moriond: &CD and High Energy Hadronic Interactions . Les Arcs, Prance, March 22-28, 1992 * Work supported by Department of Energy contracts DE-AC03-76SF00515 (SLAC), and DE-AC02-76ER03069 (MIT).",,https://www.semanticscholar.org/paper/eb109802f998bfa457b1f2651e1d5b056f2ac6bb,
19,Identifying content for planned events across social media sites,"User-contributed Web data contains rich and diverse information about a variety of events in the physical world, such as shows, festivals, conferences and more. This information ranges from known event features (e.g., title, time, location) posted on event aggregation platforms (e.g., Last.fm events, EventBrite, Facebook events) to discussions and reactions related to events shared on different social media sites (e.g., Twitter, YouTube, Flickr). In this paper, we focus on the challenge of automatically identifying user-contributed content for events that are planned and, therefore, known in advance, across different social media sites. We mine event aggregation platforms to extract event features, which are often noisy or missing. We use these features to develop query formulation strategies for retrieving content associated with an event on different social media sites. Further, we explore ways in which event content identified on one social media site can be used to retrieve additional relevant event content on other social media sites. We apply our strategies to a large set of user-contributed events, and analyze their effectiveness in retrieving relevant event content from Twitter, YouTube, and Flickr.",2012-02-08,https://www.semanticscholar.org/paper/4d76072a133a39144b5fe4b16611b603b641d487,Web Search and Data Mining
1183,Measurement of the angular and lifetime parameters of the decays Bd0-->J/psiK*0 and Bs0-->J/psiphi.,We present measurements of the linear polarization amplitudes and the strong relative phases that describe the flavor-untagged decays Bd0-->J/psiK*0 and Bs0-->J/psiphi in the transversity basis. We also measure the mean lifetime taus of the Bs0 mass eigenstates and the lifetime ratio taus/taud. The analyses are based on approximately 2.8 fb(-1) of data recorded with the D0 detector. From our measurements of the angular parameters we conclude that there is no evidence for a deviation from flavor SU(3) symmetry for these decays and that the factorization assumption is not valid for the Bd0-->J/psiK*0 decay.,,https://www.semanticscholar.org/paper/c77dde68f72af9d8f20a073aef6d69977ae4d62e,Physical Review Letters
192,Cycles in adversarial regularized learning,"Regularized learning is a fundamental technique in online optimization, machine learning and many other fields of computer science. A natural question that arises in these settings is how regularized learning algorithms behave when faced against each other. We study a natural formulation of this problem by coupling regularized learning dynamics in zero-sum games. We show that the system's behavior is Poincare recurrent, implying that almost every trajectory revisits any (arbitrarily small) neighborhood of its starting point infinitely often. This cycling behavior is robust to the agents' choice of regularization mechanism (each agent could be using a different regularizer), to positive-affine transformations of the agents' utilities, and it also persists in the case of networked competition, i.e., for zero-sum polymatrix games.",2017-09-08,https://www.semanticscholar.org/paper/dd3eefc22d78467971b28f0b0f9b5b09e838fd56,ACM-SIAM Symposium on Discrete Algorithms
2320,Biochemistry and Physiology of the Neutrophil: Neutrophils and host defence: The fight against infection,,,https://www.semanticscholar.org/paper/33969b664fd80f9540e508939950cea4e3cb114f,
3158,Integrated Processors Scheduling for Multimedia,,1995-04-19,https://www.semanticscholar.org/paper/cc1f69155d69260ea1b09874fdb8933d6e41da70,International Workshop on Network and Operating System Support for Digital Audio and Video
3397,Scheduling (Dagstuhl Seminar 18101),,,https://www.semanticscholar.org/paper/4504e38b4efbf9b53ec48242ae67a3a4e04377fa,Dagstuhl Reports
3748,The Sound of Pixels,,2018-04-09,https://www.semanticscholar.org/paper/fe018f22600d07cbd0452a070e03708886470015,European Conference on Computer Vision
942,l\tlodeling COlnlnunications Protocols by Autolnata,,,https://www.semanticscholar.org/paper/da7966d472fa3da9c864783ceeaceb5497727982,
3423,Online Stochastic Packing Applied to Display Ad Allocation,,2010-01-27,https://www.semanticscholar.org/paper/7859ed93b7d0c2a2a83d382866dbc22170faf25d,Embedded Systems and Applications
1154,Evidence of WW and WZ Production with lepton + jets Final States in p p Collisions at √s = 1.96 Te V,"We present first evidence for WW + WZ production in lepton + jets final states at a hadron collider. The data correspond to 1.07 fb -1 of integrated luminosity collected with the D0 detector at the Fermilab Tevatron in p p collisions at √s = 1.96 TeV. The observed cross section for WW + WZ production is 20.2 ± 4.5 pb, consistent with the standard model and more precise than previous measurements in fully leptonic final states. The probability that background fluctuations alone produce this excess is <5.4 × 10- 6 , which corresponds to a significance of 4.4 standard deviations.",,https://www.semanticscholar.org/paper/5b9f74bae16511e06d998cddcebc183259c93c01,
1823,Admixtures of latent blocks with application to protein interaction networks,"In this paper, we consider the statistical analysis of a protein interaction network. We propose a Bayesian model that uses a hierarchy of probabilistic assumptions about the way proteins interact with one another in order to: (i) identify the number of non-observable functional modules; (ii) estimate the degree of membership of proteins to modules; and (iii) estimate typical interaction patterns among the functional modules themselves. Our model describes large amount of (relational) data using a relatively small set of parameters that we can reliably estimate with an efficient inference algorithm. We apply our methodology to data on protein-to-protein interactions in saccharomyces cerevisiae to reveal proteins’ diverse functional roles. The case study provides the basis for an overview of which scientific questions can be addressed using our methods, and for a discussion of technical issues.",2007-06-03,https://www.semanticscholar.org/paper/59fc7efc9cfe92c90704ef32017162a7fc23ff06,
2532,Spatially aware handhelds for high-precision tangible interaction with large displays,"While touch-screen displays are becoming increasingly popular, many factors affect user experience and performance. Surface quality, parallax, input resolution, and robustness, for instance, can vary with sensing technology, hardware configurations, and environmental conditions.
 We have developed a framework for exploring how we could overcome some of these dependencies, by leveraging the higher visual and input resolution of small, coarsely tracked mobile devices for direct, precise, and rapid interaction on large digital displays.
 The results from a formal user study show no significant differences in performance when comparing four techniques we developed for a tracked mobile device, where two existing touch-screen techniques served as baselines. The mobile techniques, however, had more consistent performance and smaller variations among participants, and an overall higher user preference in our setup. Our results show the potential of spatially aware handhelds as an interesting complement or substitute for direct touch-interaction on large displays.",2009-02-16,https://www.semanticscholar.org/paper/4512a28cdebe66c2cc2e19e0a086409d71008be4,"International Conference on Tangible, Embedded, and Embodied Interaction"
2828,Lack of galectin-3 alleviates trypanosomiasis-associated anemia of inflammation.,,2010-09-01,https://www.semanticscholar.org/paper/89e04f8a4851ef9c52e9d15f4a5905c1abcace45,Immunobiology
3456,Approximation Algorithms for Semidefinite Packing Problems with Applications to Maxcut and Graph Coloring,,2005-06-08,https://www.semanticscholar.org/paper/86e52ce64ec6e929573c5a2c252cc54bcfde51da,Conference on Integer Programming and Combinatorial Optimization
2655,Information filtering for mobile augmented reality,"Augmented reality is a potentially powerful paradigm for annotating the (real) environment with computer-generated material. These benefits will be even greater when augmented reality systems become mobile and wearable. However, to minimize the problem of clutter and to maximize the effectiveness of the display, algorithms must be developed to select only the most important information for the user. In this paper, we describe a region-based information filtering algorithm. The algorithm takes account of the state of the user (location and intent) and the state of individual objects about which information can be presented. It can dynamically respond to changes in the environment and the user's state. We also describe how simple temporal, distance and angle cues can be used to refine the transitions between different information sets.",2000-10-05,https://www.semanticscholar.org/paper/b3c4c934ecd427e9fff563fba229dbc8b527a34e,Proceedings IEEE and ACM International Symposium on Augmented Reality (ISAR 2000)
2967,Beta Diffusion Trees,"We define the beta diffusion tree, a random tree structure with a set of leaves that defines a collection of overlapping subsets of objects, known as a feature allocation. The generative process for the tree is defined in terms of particles (representing the objects) diffusing in some continuous space, analogously to the Dirichlet and Pitman-Yor diffusion trees (Neal, 2003b; Knowles & Ghahramani, 2011), both of which define tree structures over clusters of the particles. With the beta diffusion tree, however, multiple copies of a particle may exist and diffuse to multiple locations in the continuous space, resulting in (a random number of) possibly overlapping clusters of the objects. We demonstrate how to build a hierarchically-clustered factor analysis model with the beta diffusion tree and how to perform inference over the random tree structures with a Markov chain Monte Carlo algorithm. We conclude with several numerical experiments on missing data problems with data sets of gene expression arrays, international development statistics, and intranational socioeconomic measurements.",2014-06-21,https://www.semanticscholar.org/paper/b1637dbe60de0193d5680811506fb210507fcb02,International Conference on Machine Learning
1207,Search for Pair Production of Doubly Charged Higgs Bosons in the H þþ H ! þ þ Final State,,,https://www.semanticscholar.org/paper/3f2ade0ea227950b3ae7c54134db0b39cbdb27b8,
1222,Search for the StandardModel Higgs Boson in theMissing Energy and Acoplanar b-Jet Topology at ffiffi s p 1⁄4 1 : 96 TeV,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, M. Ahsan, G. D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G.A. Alves, M. Anastasoaie, L. S. Ancu, T. Andeen, B. Andrieu, M. S. Anzelc, M. Aoki, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, A. C. S. Assis Jesus, O. Atramentov, C. Avila, F. Badaud, L. Bagby, B. Baldin, D. V. Bandurin, P. Banerjee, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, C. Biscarat, G. Blazey, F. Blekman, S. Blessing, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, E. E. Boos, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, X. B. Bu, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, T. H. Burnett, C. P. Buszello, J.M. Butler, P. Calfayan, S. Calvet, J. Cammin, E. Carrera, W. Carvalho, B. C. K. Casey, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K.M. Chan, A. Chandra, E. Cheu, F. Chevallier, D. K. Cho, S. Choi, B. Choudhary, L. Christofek, T. Christoudias, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, V. Cuplov, D. Cutts, M. Ćwiok, H. da Motta, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, K. DeVaughan, J. D. Degenhardt, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, H. Dong, T. Dorland, A. Dubey, L. V. Dudko, L. Duflot, S. R. Dugad, D. Duggan, A. Duperrin, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V.D. Elvira, Y. Enari, S. Eno, P. Ermolov, H. Evans, A. Evdokimov, V.N. Evdokimov, A.V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, C. Garcia, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, W. Geng, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, N. Gollub, B. Gómez, A. Goussiou, P. D. Grannis, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Harder, A. Harel, J.M. Hauptman, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, A. P. Heinson, U. Heintz, C. Hensel,22,x K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, J. D. Hobbs, B. Hoeneisen, H. Hoeth, M. Hohlfeld, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, C. Jarvis, R. Jesik, K. Johns, C. Johnson, M. Johnson, D. Johnston, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, J.M. Kalk, D. Karmanov, P. A. Kasper, I. Katsanos, D. Kau, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y.M. Kharzheev, D. Khatidze, T. J. Kim, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, J.-P. Konrath, A. V. Kozelov, J. Kraus, T. Kuhl, A. Kumar, A. Kupco, T. Kurča, V. A. Kuzmin, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, W.M. Lee, A. Leflat, J. Lellouch, J. Li, L. Li, Q. Z. Li, S.M. Lietti, J. K. Lim, J. G. R. Lima, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna, A. L. Lyon, A. K.A. Maciel, D. Mackin, R. J. Madaras, P. Mättig, C. Magass, A. Magerkurth, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, Y. Maravin, B. Martin, R. McCarthy, A. Melnitchouk, L. Mendoza, P. G. Mercadante, M. Merkin, K.W. Merritt, A. Meyer, J. Meyer,22,x J. Mitrevski, R.K. Mommsen, N.K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, N.A. Naumann, H.A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, V. O’Dell, D. C. O’Neil, G. Obrant, C. Ochando, D. Onoprienko, N. Oshima, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park,22,x S.K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, M. Petteni, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma, V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, B.G. Pope, A.V. Popov, C. Potter, W. L. Prado da Silva, H. B. Prosper, S. Protopopescu, J. Qian, A. Quadt,22,x B. Quinn, A. Rakitine, M. S. Rangel, K. Ranjan, P. N. Ratoff, P. Renkel, P. Rich, PRL 101, 251802 (2008) P HY S I CA L R EV I EW LE T T E R S week ending 19 DECEMBER 2008",,https://www.semanticscholar.org/paper/5ab887ac1e077d6621eea7ba993ee256faa6d02f,
2244,Differential cytokine/chemokine concentrations in synovial fluid regulate differential effects on neutrophil function,,,https://www.semanticscholar.org/paper/eee68492bdf0c7692762da64de3048dcf0097e88,
170,Optimal Strategies of Blotto Games: Beyond Convexity,"The Colonel Blotto game, first introduced by Borel in 1921, is a well-studied game theory classic. Two colonels each have a pool of troops that they divide simultaneously among a set of battlefields. The winner of each battlefield is the colonel who puts more troops in it and the overall utility of each colonel is the sum of weights of the battlefields that s/he wins. Over the past century, the Colonel Blotto game has found applications in many different forms of competition from advertisements to politics to sports. Two main objectives have been proposed for this game in the literature: (i) maximizing the guaranteed expected payoff, and (ii) maximizing the probability of obtaining a minimum payoff u. The former corresponds to the conventional utility maximization and the latter concerns scenarios such as elections where the candidates' goal is to maximize the probability of getting at least half of the votes (rather than the expected number of votes). In this paper, we consider both of these objectives and show how it is possible to obtain (almost) optimal solutions that have few strategies in their support. One of the main technical challenges in obtaining bounded support strategies for the Colonel Blotto game is that the solution space becomes non-convex. This prevents us from using convex programming techniques in finding optimal strategies which are essentially the main tools that are used in the literature. However, we show through a set of structural results that the solution space can, interestingly, be partitioned into polynomially many disjoint convex polytopes that can be considered independently. Coupled with a number of other combinatorial observations, this leads to polynomial time approximation schemes for both of the aforementioned objectives. We also provide the first complexity result for finding the maximin of Blotto-like games: we show that computing the maximin of a generalization of the Colonel Blotto game that we call General Colonel Blotto is exponential time-complete.",2019-01-14,https://www.semanticscholar.org/paper/2a8393c972ad75e77f34367240d890ecd14a4424,ACM Conference on Economics and Computation
3301,"Grevy's zebra conservation: overcoming threats of isolation, genetic hybridization and demographic instability","1 Centre for Conservation Ecology and Environmental Change, School of Conservation Sciences, Bournemouth University, Dorset, UK 2 Department of Ecology and Evolutionary Biology, Princeton University, Princeton, NJ, USA 3 Department of Conservation Biology, Denver Zoological Foundation, Denver CO, USA 4 Mpala Research Centre, Nanyuki, Kenya 5 Department of Ecology and Evolutionary Biology, University of California, Los Angeles, CA, USA 6 Department of Biology, The Pennsylvania State University, University Park, PA, USA",2009-12-01,https://www.semanticscholar.org/paper/c4370ce33e7f70735e7ac43872698df024cce2d9,
1687,Scalable Recommendation with Hierarchical Poisson Factorization,"We develop hierarchical Poisson matrix factorization (HPF), a novel method for providing users with high quality recommendations based on implicit feedback, such as views, clicks, or purchases. In contrast to existing recommendation models, HPF has a number of desirable properties. First, we show that HPF more accurately captures the long-tailed user activity found in most consumption data by explicitly considering the fact that users have finite attention budgets. This leads to better estimates of users' latent preferences, and therefore superior recommendations, compared to competing methods. Second, HPF learns these latent factors by only explicitly considering positive examples, eliminating the often costly step of generating artificial negative examples when fitting to implicit data. Third, HPF is more than just one method— it is the simplest in a class of probabilistic models with these properties, and can easily be extended to include more complex structure and assumptions. We develop a variational algorithm for approximate posterior inference for HPF that scales up to large data sets, and we demonstrate its performance on a wide variety of real-world recommendation problems—users rating movies, listening to songs, reading scientific papers, and reading news articles.",2015-07-12,https://www.semanticscholar.org/paper/b2a35b6693c74abe7d42ba13e8b90c1545b569f7,Conference on Uncertainty in Artificial Intelligence
2280,Life and death of multiple myeloma cells,"Multiple myeloma (MM) is a B-cell malignancy in which plasma cells have decreased proliferative ability and an extended lifespan. Zhang and colleagues (page [1885][1]) set out to identify the molecular processes responsible for this extended survival (or delayed apoptosis) in MM cells.

First they",2002-03-15,https://www.semanticscholar.org/paper/c319438722b126970db40acdec2ca0b0cd1951c0,
766,Succinct Approximation of Trade-Off Curves,,2006-12-15,https://www.semanticscholar.org/paper/f652907235d5865e840d29b7c868a87c713af6cc,Workshop on Internet and Network Economics
3157,The Design of SMART: A Scheduler for Multimedia Applications,"We have created SMART, a Scheduler for Multimedia And Real-Time applications. SMART supports both real-time and conventional computations and provides flexible and accurate control over the sharing of processor time. SMART is able to satisfy real-time constraints in an optimal manner and provide proportional sharing across all real-time and conventional tasks. Furthermore, when not all real-time constraints can be met, SMART satisfies each real-time task''s proportional share of deadlines, and adjusts its execution rate dynamically. This technique is especially important for multimedia applications that can operate at different rates depending on the loading condition. This paper presents the design of SMART and provides measured performance results of its effectiveness based on a prototype implementation in the Solaris operating system.",1996-06-01,https://www.semanticscholar.org/paper/4051754e54a513b3b73f5b12ad5840ce538a6ae9,
145,A Hybrid Approach to Topological Mobile Robot Localization,"We present a hybrid method for localizing a mobile robot in a complex environment. The method combines the use of multiresolution histograms with a signal strength analysis of existing wireless networks. We tested this localization procedure on the campus of Columbia University with our mobile robot, the Autonomous Vehicle for Exploration and Navigation of Urban Environments. Our results indicate that localization accuracy is significantly improved when five levels of resolution are used instead of one in color histogramming. We also find that incorporating wireless signal strengths into the method further improves reliability and helps to resolve ambiguities which arise when different regions have similar visual appearances.",,https://www.semanticscholar.org/paper/1a012a7ad0cf23a24ddb5aa1ff778a89d2314468,
1603,Black Box FDR,"Analyzing large-scale, multi-experiment studies requires scientists to test each experimental outcome for statistical significance and then assess the results as a whole. We present Black Box FDR (BB-FDR), an empirical-Bayes method for analyzing multi-experiment studies when many covariates are gathered per experiment. BB-FDR learns a series of black box predictive models to boost power and control the false discovery rate (FDR) at two stages of study analysis. In Stage 1, it uses a deep neural network prior to report which experiments yielded significant outcomes. In Stage 2, a separate black box model of each covariate is used to select features that have significant predictive power across all experiments. In benchmarks, BB-FDR outperforms competing state-of-the-art methods in both stages of analysis. We apply BB-FDR to two real studies on cancer drug efficacy. For both studies, BB-FDR increases the proportion of significant outcomes discovered and selects variables that reveal key genomic drivers of drug sensitivity and resistance in cancer.",2018-06-08,https://www.semanticscholar.org/paper/852bcc3cc41df93e079582a2ef3c40689ff8411a,International Conference on Machine Learning
400,Optimization problems in congestion control,"One of the crucial elements in the Internet's success is its ability to adequately control congestion. The paper defines and solves several optimization problems related to Internet congestion control, as a step toward understanding the virtues of the TCP congestion control algorithm currently used and comparing it with alternative algorithms. We focus on regulating the rate of a single unicast flow when the bandwidth available to it is unknown and may change over time. We determine near-optimal policies when the available bandwidth is unchanging, and near-optimal competitive policies when the available bandwidth is changing in a restricted manner under the control of an adversary.",2000-11-12,https://www.semanticscholar.org/paper/c0b9f1f946f92e3cfd6fd63f88b11d810c06866f,Proceedings 41st Annual Symposium on Foundations of Computer Science
63,"Proceedings of the 2004 ACM CIKM International Conference on Information and Knowledge Management, Washington, DC, USA, November 8-13, 2004",,,https://www.semanticscholar.org/paper/eea35842b6621527b5ea0f2f4f02f449a42741d5,International Conference on Information and Knowledge Management
2836,Galectin-3 negatively regulates TCR-mediated CD4+ T-cell activation at the immunological synapse,"We have investigated the function of endogenous galectin-3 in T cells. Galectin-3-deficient (gal3−/−) CD4+ T cells secreted more IFN-γ and IL-4 than gal3+/+CD4+ T cells after T-cell receptor (TCR) engagement. Galectin-3 was recruited to the cytoplasmic side of the immunological synapse (IS) in activated T cells. In T cells stimulated on supported lipid bilayers, galectin-3 was primarily located at the peripheral supramolecular activation cluster (pSMAC). Gal3+/+ T cells formed central SMAC on lipid bilayers less effectively and adhered to antigen-presenting cells less firmly than gal3−/− T cells, suggesting that galectin-3 destabilizes the IS. Galectin-3 expression was associated with lower levels of early signaling events and phosphotyrosine signals at the pSMAC. Additional data suggest that galectin-3 potentiates down-regulation of TCR in T cells. By yeast two-hybrid screening, we identified as a galectin-3-binding partner, Alix, which is known to be involved in protein transport and regulation of cell surface expression of certain receptors. Co-immunoprecipitation confirmed galectin-3-Alix association and immunofluorescence analysis demonstrated the translocation of Alix to the IS in activated T cells. We conclude that galectin-3 is an inhibitory regulator of T-cell activation and functions intracellularly by promoting TCR down-regulation, possibly through modulating Alix's function at the IS.",2009-08-25,https://www.semanticscholar.org/paper/da04fdf9d5956f3db2049f95497af94227e1f1b6,Proceedings of the National Academy of Sciences of the United States of America
1963,Re-entrant flow shop scheduling problem with time windows using hybrid genetic algorithm based on auto-tuning strategy,"The re-entrant flow shop scheduling problem considering time windows constraint is one of the most important problems in hard-disc drive (HDD) manufacturing systems. In order to maximise the system throughput, the problem of minimising the makespan with zero loss is considered. In this paper, evolutionary techniques are proposed to solve the complex re-entrant scheduling problem with time windows constraint in manufacturing HDD devices with lot size. This problem can be formulated as a deterministic Fm | fmls, rcrc, temp | Cmax problem. A hybrid genetic algorithm was used for constructing chromosomes by checking and repairing time window constraints, and improving chromosomes by a left-shift heuristic as a local search algorithm. An adaptive hybrid genetic algorithm was eventually developed to solve this problem by using fuzzy logic control in order to enhance the search ability of the genetic algorithm. Finally, numerical experiments were carried out to demonstrate the efficiency of the developed approaches.",2014-03-14,https://www.semanticscholar.org/paper/7d7e8d604b6bf438ca19341b04acdca2294350c5,
1329,"Limits on anomalous trilinear gauge couplings from WW→e+e-, WW→e±e, and WW→μ+μ- events from pp̄ collisions at s=1.96TeV","Limits are set on anomalous WWγ and WWZ trilinear gauge couplings using W + W - →e + ν e e-ν‾ e , W + W - →e ± ν e μ±ν
 μ , and W + W - →μ + νμ
 - ν‾ μ events. The data set was collected by the Run II D0 detector at the Fermilab Tevatron Collider and corresponds to approximately 250 pb -1 of integrated luminosity at √s=1.96 TeV. Under the assumption that the WWγ couplings are equal to the WWZ couplings and using a form factor scale of Λ=2.0 TeV, the combined 95% C.L. one-dimensional coupling limits from all three channels are -0.32<Δ k <0.45 and -0.29<λ<0.30.",2006-09-08,https://www.semanticscholar.org/paper/d975c2bb4277742b08f1a0be07637f53c7ed9b9a,
3715,Visual behavior modelling for robotic theory of mind,,2021-01-11,https://www.semanticscholar.org/paper/9fab147d338fe2b7fa3ffb6ecefed75bed7cf824,Scientific Reports
2922,Evaluation of fracture toughness and residual stress in AISI 316L electron beam welds,"Weld residual stress and fracture behaviour of 316L electron beam weldments, which are of particular interest in power generation industry, were investigated in this work. Two butt-weld joints were manufactured in stainless steel 316L plates of 6 mm and 25.4 mm thicknesses. Three complementary methods were used to measure the three orthogonal components of the residual stress in the weld coupons and fracture tests were conducted on single edge notched bending specimens extracted from different regions of the welds and parent metals. The residual stress measurements showed a maximum value of 450 MPa in longitudinal direction, while it was less than 150 MPa in the other two orthogonal directions, revealing that in our material, and with the chosen weld parameters, the residual stresses were biaxial. The fracture resistance of the weldment and parent material was similar, with material microstructure differences being more significant than the measured residual stresses. The study suggests that 316L electron beam weldments are not susceptible to fracture failure due to their high ductility and ability to relieve residual stresses through gross plasticity. Electron beam welding may therefore be suggested as a reliable manufacturing technology for safety critical 316L components.",2021-04-12,https://www.semanticscholar.org/paper/fe8d5a709bb55881ad0ce67040658ef133daa59a,Fatigue & Fracture of Engineering Materials & Structures
1349,Measurement of inclusive differential cross sections for pp collisions at (square root)s = 1.96 TeV.,"We present measurements of the inclusive production cross sections of the Gamma(1S) bottomonium state in pp collisions at (square root)s = 1.96 TeV. Using the Gamma(1S) --> mu(+)mu(-) decay mode for a data sample of 159 +/- 10 pb(-1) collected by the D0 detector at the Fermilab Tevatron collider, we determine the differential cross sections as a function of the Gamma(1S) transverse momentum for three ranges of the Gamma(1S) rapidity: 0 < y(Gamma) < or = 0.6, 0.6 < y(Gamma) < or = 1.2, and 1.2 < y(Gamma) < or = 1.8.",2005-06-13,https://www.semanticscholar.org/paper/8a1441071ccbe569e43e01b120832a41a3e8fd54,Physical Review Letters
2470,Virtual Replicas for Remote Assistance in Virtual and Augmented Reality,"In many complex tasks, a remote subject-matter expert may need to assist a local user to guide actions on objects in the local user's environment. However, effective spatial referencing and action demonstration in a remote physical environment can be challenging. We introduce two approaches that use Virtual Reality (VR) or Augmented Reality (AR) for the remote expert, and AR for the local user, each wearing a stereo head-worn display. Both approaches allow the expert to create and manipulate virtual replicas of physical objects in the local environment to refer to parts of those physical objects and to indicate actions on them. This can be especially useful for parts that are occluded or difficult to access. In one approach, the expert points in 3D to portions of virtual replicas to annotate them. In another approach, the expert demonstrates actions in 3D by manipulating virtual replicas, supported by constraints and annotations. We performed a user study of a 6DOF alignment task, a key operation in many physical task domains, comparing both approaches to an approach in which the expert uses a 2D tablet-based drawing system similar to ones developed for prior work on remote assistance. The study showed the 3D demonstration approach to be faster than the others. In addition, the 3D pointing approach was faster than the 2D tablet in the case of a highly trained expert.",2015-11-05,https://www.semanticscholar.org/paper/90a67bc508e86c6cf20b14955820d6fa0be5614b,ACM Symposium on User Interface Software and Technology
1480,Lorentz angle studies for the SLD endcap Cherenkov Ring Imaging detector,,1987-11-01,https://www.semanticscholar.org/paper/620c54e09bf97d191370789437b9283b5ef10e57,
864,Testing finite state machines,"We present simple randomized algorithms for the fault detection problem: Given a specification in the form of a deterministic finite state machine A and an implementation machine B, determine whether B is equal to A. If A has n states and p inputs, then in randomized polynomial time we can construct with high probability a checking sequence of length O(pn4 log n), i.e., a sequence that detects all faulty machines with at most n states. Better bounds can be obtained in certain cases. The techniques generalize to partially specified finite state machines.",1991-01-03,https://www.semanticscholar.org/paper/9d60a1796e9feeeb0c6ecf8e5ed7ce79c31809b4,Symposium on the Theory of Computing
2509,Creating hybrid user interfaces with a 2D multi-touch tabletop and a 3D see-through head-worn display,"How can multiple different display and interaction devices be used together to create an effective augmented reality environment? We explore the design of several prototype hybrid user interfaces that combine a 2D multi-touch tabletop display with a 3D head-tracked video-see-through display. We describe a simple modeling application and an urban visualization tool in which the information presented on the head-worn display supplements the information displayed on the tabletop, using a variety of approaches to track the head-worn display relative to the tabletop. In all cases, our goal is to allow users who can see only the tabletop to interact effectively with users wearing head-worn displays.",2011-10-26,https://www.semanticscholar.org/paper/a765f6b0bbaf57832023d69c7272642db7ec4e02,2011 10th IEEE International Symposium on Mixed and Augmented Reality
209,Assembly pointers for variable binding in networks of spiking neurons,"We propose a model for binding of variables such as the thematic role of a word in a sentence or episode (e.g., agent or patient), to concrete fillers (e.g., a word or concept). Our model is based on recent experimental data about corresponding processes in the human brain. One source of information are electrode recordings from the human brain, which suggest that concepts are represented in the medial temporal lobe (MTL) through sparse sets of neurons (assemblies). Another source of information are fMRI recordings from the human brain, which suggest that subregions of the temporal cortex are dedicated to the representation of specific roles (e.g., subject or object) of concepts in a sentence or visually presented episode. We propose that quickly recruited assemblies of neurons in these subregions act as pointers to previously created assemblies that represent concepts. We provide a proof of principle that the resulting model for binding through assembly pointers can be implemented in networks of spiking neurons, and supports basic operations of brain computations, such as structured information retrieval and copying of information. We also show that salient features of fMRI data on neural activity during structured information retrieval can be reproduced by the proposed model.",2016-11-11,https://www.semanticscholar.org/paper/cda4f6c146fe4f5ef337948a92bb995e27addad1,
85,SDLIP + STARTS = SDARTS a protocol and toolkit for metasearching,"In this paper we describe how we combined SDLIP and STARTS, two comple mentary protocols for searching over distributed document collections. The resulting protocol, which we call SDARTS, is simple yet expressible enough to enable building sophisticated metasearch engines. SDARTS can be viewed as an instantiation of SDLIP with metasearch-specific elements from STARTS. We also report on our experience building three SDARTS-compliant wrappers: for locally available plain-text document collections, for locally available XML document collections, and for external web-accessible collections. These wrappers were developed to be easily customizable for new collections. Our work was developed as part of Columbia University's Digital Libraries Initiative--Phase 2 (DLI2) project, which involves the departments of Computer Science, Medical Informatics, and Electrical Engineering, the Columbia University libraries, and a large number of industrial partners. The main goal of the project is to provide personalized access to a distributed patient-care digital library.",,https://www.semanticscholar.org/paper/46a2ceb19aae1cef1e2bb2432d09cac08aeaf8ce,ACM/IEEE Joint Conference on Digital Libraries
3421,FairTorrent: A Deficit-Based Distributed Algorithm to Ensure Fairness in Peer-to-Peer Systems,"Peer-to-peer file-sharing applications suffer from a fundamental problem of unfairness. Free-riders cause slower download times for others by contributing little or no upload bandwidth while consuming much download bandwidth. Previous attempts to address this fair bandwidth allocation problem suffer from slow peer discovery, inaccurate predictions of neighboring peers' bandwidth allocations, underutilization of bandwidth, and complex parameter tuning. We present FairTorrent, a new deficit-based distributed algorithm that accurately rewards peers in accordance with their contribution. A FairTorrent peer simply uploads the next data block to a peer to whom it owes the most data as measured by a deficit counter. FairTorrent is resilient to exploitation by free-riders and strategic peers, is simple to implement, requires no bandwidth overallocation, no prediction of peers' rates, no centralized control, and no parameter tuning. We implemented FairTorrent in a BitTorrent client without modifications to the BitTorrent protocol and evaluated its performance against other widely used BitTorrent clients. Our results show that FairTorrent provides up to two orders of magnitude better fairness, up to five times better download times for contributing peers, and 60%-100% better performance on average in live BitTorrent swarms.",2012-10-01,https://www.semanticscholar.org/paper/b7f32327cef986b3572a3b1bc625ec6c1dfd9390,IEEE/ACM Transactions on Networking
675,Lecture 8 – t-Distributed Stochastic Neighbor Embedding,"Year Method Author Summary 1901 PCA Karl Pearson First dimensionality reduction technique 2000 Isomap Tenenbaum, de Silva, and Langford First non-linear dimensionality reduction technique 2002 SNE Hinton and Roweis Original SNE algorithm 2008 tSNE Maaten and Hinton Addressed the crowding issue of SNE, O(N2) 2014 BHt-SNE Maaten Using BarnesHut approximation to achieve O(N log(N)) 2017 Linderman and Steinerberger First step towards theoretical guarantee for t-SNE 2017 Fit-SNE Linderman et al. Acceleration to O(N) 2018 Arora et al. Theoretical guarantee for tSNE 2018 Verma et al. Generalization of t-SNE to manifold",,https://www.semanticscholar.org/paper/bd1bab3535fb8f66e54a8a8d94f063f95dbe221b,
1208,Search forandProduction inCollisions atand Limits on AnomalousandCouplings,,2008-04-02,https://www.semanticscholar.org/paper/3f51fda8e71f10b9f993f6195d119b30420c4249,
2236,"Distinct cytokine/chemokine profiles in inflammatory synovial fluid based on diagnosis, therapy and response",,,https://www.semanticscholar.org/paper/19856acb6d4c22cf02fb2d6aec06ac6b074ce81f,
2253,Sodium Salicylate Promotes Neutrophil Apoptosis by Stimulating Caspase-Dependent Turnover of Mcl-11,"Mcl-1 is an antiapoptotic member of the Bcl-2 family of proteins that plays a central role in cell survival of neutrophils and other cells. The protein is unusual among family members in that it has a very short half-life of 2–3 h. In this report, we show that sodium salicylate (at 10 mM) greatly enhances the rate at which neutrophils undergo apoptosis and, in parallel, greatly accelerates the turnover rate of Mcl-1, decreasing its half-life to only 90 min. Whereas constitutive and GM-CSF-modified Mcl-1 turnover is regulated by the proteasome, the accelerated sodium salicylate-induced Mcl-1 turnover is mediated largely via caspases. Sodium salicylate resulted in rapid activation of caspase-3, -8, -9, and -10, and salicylate-accelerated Mcl-1 turnover was partly blocked by caspase inhibitors. Sodium salicylate also induced dramatic changes in the activities of members of the MAPK family implicated in Mcl-1 turnover and apoptosis. For example, sodium salicylate blocked GM-CSF-stimulated Erk and Akt activation, but resulted in rapid and sustained activation of p38-MAPK, an event mimicked by okadaic acid that also accelerates Mcl-1 turnover and neutrophil apoptosis. These data thus shed important new insights into the dynamic and highly regulated control of neutrophil apoptosis that is effected by modification in the rate of Mcl-1 turnover.",2006-01-15,https://www.semanticscholar.org/paper/88f20cf9bb6e965aae3eaa093ba75b5930c869af,Journal of Immunology
3007,Formal Verification of a Multiprocessor Hypervisor on Arm Relaxed Memory Hardware,"Concurrent systems software is widely-used, complex, and error-prone, posing a significant security risk. We introduce VRM, a new framework that makes it possible for the first time to verify concurrent systems software, such as operating systems and hypervisors, on Arm relaxed memory hardware. VRM defines a set of synchronization and memory access conditions such that a program that satisfies these conditions can be mostly verified on a sequentially consistent hardware model and the proofs will automatically hold on relaxed memory hardware. VRM can be used to verify concurrent kernel code that is not data race free, including code responsible for managing shared page tables in the presence of relaxed MMU hardware. Using VRM, we verify the security guarantees of a retrofitted implementation of the Linux KVM hypervisor on Arm. For multiple versions of KVM, we prove KVM's security properties on a sequentially consistent model, then prove that KVM satisfies VRM's required program conditions such that its security proofs hold on Arm relaxed memory hardware. Our experimental results show that the retrofit and VRM conditions do not adversely affect the scalability of verified KVM, as it performs similar to unmodified KVM when concurrently running many multiprocessor virtual machines with real application workloads on Arm multiprocessor server hardware. Our work is the first machine-checked proof for concurrent systems software on Arm relaxed memory hardware.",2021-10-26,https://www.semanticscholar.org/paper/59c83a2ced9816343098d85cdc7c12d806838fce,Symposium on Operating Systems Principles
3654,Type-Safe Linkage for C++,This paper describes the problems involved in generating names for overloaded functions in C++ and in linking to C programs. It also discusses how these problems relate to library building. It presents a solution that provides a degree of type-safe linkage. This eliminates several classes of errors from C++ and allows libraries to be composed more freely than has hitherto been possible. Finally the current encoding scheme for C++ names is presented.,,https://www.semanticscholar.org/paper/4ab04a6cf34213abb4bccaa51c8692d9318ce1a0,Computing Systems
3050,Record and transplay: partial checkpointing for replay debugging across heterogeneous systems,"Software bugs that occur in production are often difficult to reproduce in the lab due to subtle differences in the application environment and nondeterminism. To address this problem, we present Transplay, a system that captures production software bugs into small per-bug recordings which are used to reproduce the bugs on a completely different operating system without access to any of the original software used in the production environment. Transplay introduces partial checkpointing, a new mechanism that efficiently captures the partial state necessary to reexecute just the last few moments of the application before it encountered a failure. The recorded state, which typically consists of a few megabytes of data, is used to replay the application without requiring the specific application binaries, libraries, support data, or the original execution environment. Transplay integrates with existing debuggers to provide standard debugging facilities to allow the user to examine the contents of variables and other program state at each source line of the application's replayed execution. We have implemented a Transplay prototype that can record unmodified Linux applications and replay them on different versions of Linux as well as Windows. Experiments with several applications including Apache and MySQL show that Transplay can reproduce real bugs and be used in production with modest recording overhead.",2011-06-07,https://www.semanticscholar.org/paper/4bec0240809c506f45411a43e16c901c131c481d,Measurement and Modeling of Computer Systems
2423,COVIZ: Visualization of Effects of COVID-19 on New York City Through Socially Impactful Virtual Reality,"This work is the product of a collaboration between students studying computer science and social work to visualize the impacts and effects of COVID-19 in New York City in a virtual environment (VE). As a proof of concept, the team chose two datasets from NYC Open Data; COVID-19 infection cases and rates per zip code and vehicular traffic rates within the five boroughs of New York City. To foster unexplored insights into the relationship between these data, we developed a virtual reality application that provides a stronger sense of embodiment and ownership of urban visualization analysis when manipulating 3D virtual maps for comparison in a VE.",2021-03-01,https://www.semanticscholar.org/paper/d4161ffacb19f86e87b46a75cee56cd4490e589e,2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)
957,Moxifloxacin releasing intraocular implant based on a cross-linked hyaluronic acid membrane,,2021-12-01,https://www.semanticscholar.org/paper/b7db2b4410451d42a1628b4cf29b2da4559f9d65,Scientific Reports
1077,Evidence for the Decay Bs0 âƒTM Ds(*)Ds(*) and a Measurement of ÎflÎfisCP/Îfis,,,https://www.semanticscholar.org/paper/1ab336926721d47d9b6cbc537179c8bf9ff1726c,
187,Stathis Zachos at 70!,,2017-05-24,https://www.semanticscholar.org/paper/034e89b491fabac25b233a7d19109cb7f1672a2a,International/Italian Conference on Algorithms and Complexity
659,What are the predictors of acute complications following coronary artery stenting? Single institutional experience,,1991-02-01,https://www.semanticscholar.org/paper/7a98c9c1a6042fd1d3f86deb028c5873a770ee58,
1791,Nonparametric Density Estimation for Stochastic Optimization with an Observable State Variable,"In this paper we study convex stochastic optimization problems where a noisy objective function value is observed after a decision is made. There are many stochastic optimization problems whose behavior depends on an exogenous state variable which affects the shape of the objective function. Currently, there is no general purpose algorithm to solve this class of problems. We use nonparametric density estimation to take observations from the joint state-outcome distribution and use them to infer the optimal decision for a given query state s. We propose two solution methods that depend on the problem characteristics: function-based and gradient-based optimization. We examine two weighting schemes, kernel based weights and Dirichlet process based weights, for use with the solution methods. The weights and solution methods are tested on a synthetic multi-product newsvendor problem and the hour ahead wind commitment problem. Our results show that in some cases Dirichlet process weights offer substantial benefits over kernel based weights and more generally that nonparametric estimation methods provide good solutions to otherwise intractable problems.",2010-12-06,https://www.semanticscholar.org/paper/e700bd326cd50ac0154f6e58f2adab9fa51b3128,Neural Information Processing Systems
354,On a network creation game,"We introduce a novel game that models the creation of Internet-like networks by selfish node-agents without central design or coordination. Nodes pay for the links that they establish, and benefit from short paths to all destinations. We study the Nash equilibria of this game, and prove results suggesting that the ""price of anarchy"" [4] in this context (the relative cost of the lack of coordination) may be modest. Several interesting: extensions are suggested.",2003-07-13,https://www.semanticscholar.org/paper/2cf44c2edd3e0da932ca3e94cbe385998fdecbeb,ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing
2656,Wearable 3D Graphics for Augmented Reality: A Case Study of Two Experimental Backpack Computers,"Graphical mobile augmented reality applications will only be effective if the wearable computers on which they run are capable of high-performance 3D graphics. However, no current commercial wearable system provides the graphical performance of even a typical modern desktop computer. In this paper, we describe two different experimental wearable graphics computers designed for prototyping augmented reality applications requiring fast 3D graphics. We explain the system requirements and design decisions that resulted in these architectures.",,https://www.semanticscholar.org/paper/e097604afdc02ac0cf4bf414b3925f39ce95805e,
920,On the Complexity of Testing Implications of Functional and Join Dependencies,"It iS shown that testing whether a dependency o is unpiled by a set ~ of functional and join dependencies is NP-hard if o is a join dependency, but it reqmres only O(l u Ill ~ II) time ff o Is either a funcuonal or a multivalued dependency ( j U [ is the number of elements in the set of all the attributes U, and II ~ II as the space required to write down ~). The fact that inferring join dependencies is NP-hard follows from the followmg stronger result. It is proved that if ~ is a set of one jom dependency and several funcuonal dependencies, then testing whether Z implies a join dependency o is NP-complete By combming this result with a recent result of Beeri and Var& ~t can be proved that if 2 is a set of one join dependency and several multivalued dependencies, then testing whether ~ unphes a join dependency o Is NP-hard It is also shown that the problem of deciding whether a JD-rule can be applied to a tableau T and the problem of testing whether a relation r does not obey a join dependency are NP-complete. The first problem is NP-complete even if T can be obtamed from a tableau corresponding to a join dependency by applying some FD-rules. As a result, It follows that deciding whether the join of several relations obtained by projecUon from a umversal instance is not equal to the universal instance is NP-complete. Finally, it is proved that there is no umversal constant n such that for every set of multlvalued dependencies ~ and a join dependency o that is not unpiled by ~, there is a relation with no more than n tuples in which holds but o fails.",1981-10-01,https://www.semanticscholar.org/paper/304528d94097dee67455ddf23b70d80d22ac932a,JACM
3461,On the Capacity of Secure Network Coding,"We consider the problem of using a multicast network code to transmit information securely in the presence of a “wire-tap” adversary who can eavesdrop on a bounded number of network edges. Cai & Yeung (ISIT, 2002) gave a method to alter any given linear network code into a new code that is secure. However, their construction is in general inefficient, and requires a very large field size; in many cases this is much greater than the field size required by standard network code construction algorithms to achieve the min-cut capacity (without a security guarantee). In this paper we generalize and simplify the method of Cai & Yeung, and show that the problem of making a linear network code secure is equivalent to the problem of finding a linear code with certain generalized distance properties. We show that if we give up a small amount of overall capacity, then a random code achieves these properties using a much smaller field size — in some cases a field of constant size suffices — than the construction of Cai & Yeung. We add further support to this approach by showing that if we are not willing to give up any capacity, then a large field size may sometimes be required to achieve security.",,https://www.semanticscholar.org/paper/04452aaaf039e489c1ec6cc96f4cf1726cdb8504,
906,On the Desirability of Acyclic Database Schemes,"A class of database schemes, called acychc, was recently introduced. It is shown that this class has a number of desirable properties. In particular, several desirable properties that have been studied by other researchers m very different terms are all shown to be eqmvalent to acydicity. In addition, several equivalent charactenzauons of the class m terms of graphs and hypergraphs are given, and a smaple algorithm for determining acychclty is presented. Also given are several eqmvalent characterizations of those sets M of multivalued dependencies such that M is the set of muRlvalued dependencies that are the consequences of a given join dependency. Several characterizations for a conflict-free (in the sense of Lien) set of muluvalued dependencies are provided.",1983-07-01,https://www.semanticscholar.org/paper/666dfa8258914bf17970b20d2f7247c7c1468307,JACM
771,Recursive Markov Decision Processes and Recursive Stochastic Games,"We introduce Recursive Markov Decision Processes (RMDPs) and Recursive Simple Stochastic Games (RSSGs), which are classes of (finitely presented) countable-state MDPs and zero-sum turn-based (perfect information) stochastic games. They extend standard finite-state MDPs and stochastic games with a recursion feature. We study the decidability and computational complexity of these games under termination objectives for the two players: one player's goal is to maximize the probability of termination at a given exit, while the other player's goal is to minimize this probability. In the quantitative termination problems, given an RMDP (or RSSG) and probability p, we wish to decide whether the value of such a termination game is at least p (or at most p); in the qualitative termination problem we wish to decide whether the value is 1. The important 1-exit subclasses of these models, 1-RMDPs and 1-RSSGs, correspond in a precise sense to controlled and game versions of classic stochastic models, including multitype Branching Processes and Stochastic Context-Free Grammars, where the objective of the players is to maximize or minimize the probability of termination (extinction). We provide a number of upper and lower bounds for qualitative and quantitative termination problems for RMDPs and RSSGs. We show both problems are undecidable for multi-exit RMDPs, but are decidable for 1-RMDPs and 1-RSSGs. Specifically, the quantitative termination problem is decidable in PSPACE for both 1-RMDPs and 1-RSSGs, and is at least as hard as the square root sum problem, a well-known open problem in numerical computation. We show that the qualitative termination problem for 1-RMDPs (i.e., a controlled version of branching processes) can be solved in polynomial time both for maximizing and minimizing 1-RMDPs. The qualitative problem for 1-RSSGs is in NP ∩ coNP, and is at least as hard as the quantitative termination problem for Condon's finite-state simple stochastic games, whose complexity remains a well known open problem. Finally, we show that even for 1-RMDPs, more general (qualitative and quantitative) model-checking problems with respect to linear-time temporal properties are undecidable even for a fixed property.",2005-07-11,https://www.semanticscholar.org/paper/8e08c0fa120d02db8516ae669c4583d0ad93de49,"International Colloquium on Automata, Languages and Programming"
1322,Experimental discrimination between charge 2e/3 top quark and charge 4e/3 exotic quark production scenarios.,"We present the first experimental discrimination between the 2e/3 and 4e/3 top quark electric charge scenarios, using top quark pairs (tt) produced in pp collisions at (square root) s = 1.96 TeV by the Fermilab Tevatron Collider. We use 370 pb;{-1} of data collected by the D0 experiment and select events with at least one high transverse momentum electron or muon, high transverse energy imbalance, and four or more jets. We discriminate between b- and b-quark jets by using the charge and momenta of tracks within the jet cones. The data are consistent with the expected electric charge, |q|=2e/3. We exclude, at the 92% C.L., that the sample is solely due to the production of exotic quark pairs QQ with |q|=4e/3. We place an upper limit on the fraction of QQ pairs rho<0.80 at the 90% C.L.",2006-08-16,https://www.semanticscholar.org/paper/92249b39b5413e18cf0d0ccfa05b95f83a692b53,Physical Review Letters
3320,Energy-efficient computing for wildlife tracking: design tradeoffs and early experiences with ZebraNet,"Over the past decade, mobile computing and wireless communication have become increasingly important drivers of many new computing applications. The field of wireless sensor networks particularly focuses on applications involving autonomous use of compute, sensing, and wireless communication devices for both scientific and commercial purposes. This paper examines the research decisions and design tradeoffs that arise when applying wireless peer-to-peer networking techniques in a mobile sensor network designed to support wildlife tracking for biology research.The ZebraNet system includes custom tracking collars (nodes) carried by animals under study across a large, wild area; the collars operate as a peer-to-peer network to deliver logged data back to researchers. The collars include global positioning system (GPS), Flash memory, wireless transceivers, and a small CPU; essentially each node is a small, wireless computing device. Since there is no cellular service or broadcast communication covering the region where animals are studied, ad hoc, peer-to-peer routing is needed. Although numerous ad hoc protocols exist, additional challenges arise because the researchers themselves are mobile and thus there is no fixed base station towards which to aim data. Overall, our goal is to use the least energy, storage, and other resources necessary to maintain a reliable system with a very high `data homing' success rate. We plan to deploy a 30-node ZebraNet system at the Mpala Research Centre in central Kenya. More broadly, we believe that the domain-centric protocols and energy tradeoffs presented here for ZebraNet will have general applicability in other wireless and sensor applications.",2002-10-01,https://www.semanticscholar.org/paper/d342c54cbba28cf4fdc1f97df7ab72f96d965d23,ASPLOS X
1838,Proceedings of the 2006 conference on Statistical network analysis,,2006-06-29,https://www.semanticscholar.org/paper/0c5eb26a1cf9e6ca8a7580a8a4bfbd743cbb7ed6,
2719,Graphical editing by example,"Constructing illustrations by computer can be both tedious and difficult. This thesis introduces five example-based techniques to facilitate the process. These techniques are independently useful, but also interrelate in interesting ways: (1) Graphical Search and Replace, the analogue to textual search and replace in text editors, is useful for making repetitive changes throughout graphical documents. (2) Constraint-Based Search and Replace, an extension to graphical search and replace, allows users to define their own illustration beautification rules and constraint inferencing rules by demonstration. (3) Constraint Inferencing from Multiple Snapshots facilitates constraint specification by automatically computing constraints that hold in multiple configurations of an illustration. (4) Editable Graphical Histories, a visual representation of commands in a graphical user interface, are useful for reviewing, undoing, and redoing sets of operations. (5) Graphical Macros By Example, based on this history representation, allow users to scroll through previously executed commands and encapsulate useful sequences into macros. These macros can be generalized into procedures, with arguments and flow of control using graphical and constraint-based search and replace. 
Individually and in combination, these techniques reduce repetition in graphical editing tasks, visually and by example, using the application's own interface. These techniques have been implemented in Chimera, an editor built to serve as a testbed for this research.",1993-01-02,https://www.semanticscholar.org/paper/967d23e4b26d8b347c13b0cb8cdc95c90dc31783,
392,On certain rigorous approaches to data mining (invited talk) (abstract only),,2000-08-01,https://www.semanticscholar.org/paper/34272981642265777a78e5b0160e15dbc9358974,Knowledge Discovery and Data Mining
2582,Editorial,,,https://www.semanticscholar.org/paper/3f4917c8eb81acd225e6ee80052ae7807407d490,Virtual Reality
1431,Results and status of the Cryogenic Dark Matter Search (CDMS),,1998-12-01,https://www.semanticscholar.org/paper/06cd233d4faadb3c44de753ac01613cc184e3172,
1597,Measuring discursive influence across scholarship,"Significance Scientific and scholarly influence is multifaceted, shifts over time, and varies across disciplines. We present a dynamic topic model to credit documents with influence that shapes future discourse based on their content and contextual features. We trace discursive innovation in scholarship and identify the influence of particular articles along with their authors, affiliations, and journals. In collections of science, social science, and humanities research spanning over a century, our measure helps predict citations and reveals signals that recognize authors who make diverse contributions and whose contributions take longer to be appreciated, allowing us to compensate for bias in citation behavior. Assessing scholarly influence is critical for understanding the collective system of scholarship and the history of academic inquiry. Influence is multifaceted, and citations reveal only part of it. Citation counts exhibit preferential attachment and follow a rigid “news cycle” that can miss sustained and indirect forms of influence. Building on dynamic topic models that track distributional shifts in discourse over time, we introduce a variant that incorporates features, such as authorship, affiliation, and publication venue, to assess how these contexts interact with content to shape future scholarship. We perform in-depth analyses on collections of physics research (500,000 abstracts; 102 years) and scholarship generally (JSTOR repository: 2 million full-text articles; 130 years). Our measure of document influence helps predict citations and shows how outcomes, such as winning a Nobel Prize or affiliation with a highly ranked institution, boost influence. Analysis of citations alongside discursive influence reveals that citations tend to credit authors who persist in their fields over time and discount credit for works that are influential over many topics or are “ahead of their time.” In this way, our measures provide a way to acknowledge diverse contributions that take longer and travel farther to achieve scholarly appreciation, enabling us to correct citation biases and enhance sensitivity to the full spectrum of scholarly impact.",2018-03-12,https://www.semanticscholar.org/paper/4ae9c97b65ef9c816f2f88e73ecf5416863a17ad,Proceedings of the National Academy of Sciences of the United States of America
3544,Concepts Lite: Constraining Templates with Predicates,"In this paper, we introduce template constraints (a.k.a., “concepts lite”), an extension of C++ that allows the use of predicates to constrain template arguments. The proposed feature is minimal, principled, and uncomplicated. Template constraints are applied to enforce the correctness of template use, not the correctness of template definitions. The design of these features is intended to support easy and incremental adoption by users. More precisely, constraints:",,https://www.semanticscholar.org/paper/86393d134b504c19170964381be6288c0b02919e,
1887,Deep reinforcement learning for selecting demand forecast models to empower Industry 3.5 and an empirical study for a semiconductor component distributor,"A semiconductor distributor that plays a third-party role in the supply chain will buy diverse components from different suppliers, warehouse and resell them to a number of electronics manufacturers with vendor-managed inventories, while suffering both risks of oversupply and shortage due to demand uncertainty. However, demand fluctuation and supply chain complexity are increasing due to shortening product life cycle in the consumer electronics era and long lead time for capacity expansion for high-tech manufacturing. Focusing realistic needs of a leading distributor for semiconductor components and modules, this study aims to construct a UNISON framework based on deep reinforcement learning (RL) for dynamically selecting the optimal demand forecast model for each of the products with the corresponding demand patterns to empower smart production for Industry 3.5. Deep RL that integrates deep learning architecture and RL algorithm can learn successful policies from the dynamic and complex real world. The reward function mechanism of deep RL can reduce negative impact of demand uncertainty. An empirical study was conducted for validation showing practical viability of the proposed approach. Indeed, the developed solution has been in real settings.",2020-03-03,https://www.semanticscholar.org/paper/b745b89e1412516e6e6799367214b8c8bdcaae8d,International Journal of Production Research
2574,Prototyping retractable string-based interaction techniques for dual-display mobile devices,"Accessing information on mobile and wearable devices often requires the user's visual attention, and the precise operation of virtual or physical widgets. However, these interactions may sometimes be too time-consuming and socially inappropriate. To address this, we introduce a novel input/output device that is based on the manipulation of a retractable string in a polar coordinate frame. Depending on how the user pulls the string from its enclosure--to a particular length, at a particular angle--various system features may be directly accessed. Furthermore, we present our concept for a 1D pixel array, embedded in the string that may be used as a secondary 1D display. Since it is possible to unwind the display itself and trigger functionality with a single pull, information may be accessed and presented quickly, and perceived at a glance. We present scenarios for how the string input/output device may be used in conjunc-tion with the mobile device's primary 2D display and describe our augmented reality proof-of-concept prototype.",2006-04-22,https://www.semanticscholar.org/paper/895131b2e558ba3a2824ca422dc0afa20dd37ea9,International Conference on Human Factors in Computing Systems
3001,Design and Veriﬁcation of the Arm Conﬁdential Compute Architecture,"The increasing use of sensitive private data in computing is matched by a growing concern regarding data privacy. System software such as hypervisors and operating systems are supposed to protect and isolate applications and their private data, but their large codebases contain many vulnerabilities that can risk data conﬁdentiality and integrity. We introduce Realms, a new abstraction for conﬁdential computing to protect the data conﬁdentiality and integrity of virtual machines. Hardware creates and enforces Realm world, a new physical address space for Realms. Firmware controls the hardware to secure Realms and handles requests from untrusted system software to manage Realms, including creating and running them. Untrusted system software retains control of the dynamic allocation of memory to Realms, but cannot access Realm memory contents, even if run at a higher privileged level. To guarantee the security of Realms, we veriﬁed the ﬁrmware, introducing novel veriﬁcation techniques that enable us to prove, for the ﬁrst time, the security and correctness of concurrent software with hand-over-hand locking and dynamically allocated shared page tables, data races in kernel code running on relaxed memory hardware, integrated C and Arm assembly code calling one another, and untrusted software being in full control of allocating system resources. Realms are included in the Arm Conﬁdential Compute Architecture.",,https://www.semanticscholar.org/paper/59af677f81ded821b3c24f70b26808a4b12e207b,
1219,Measurement of the inclusive jet cross section in pp[over] collisions at square root [s]=1.96 TeV.,"We report on a measurement of the inclusive jet cross section in pp[over ] collisions at a center-of-mass energy sqrt[s]=1.96 TeV using data collected by the D0 experiment at the Fermilab Tevatron Collider corresponding to an integrated luminosity of 0.70 fb;{-1}. The data cover jet transverse momenta from 50 to 600 GeV and jet rapidities in the range -2.4 to 2.4. Detailed studies of correlations between systematic uncertainties in transverse momentum and rapidity are presented, and the cross section measurements are found to be in good agreement with next-to-leading order QCD calculations.",2008-02-17,https://www.semanticscholar.org/paper/4e695ffc959bed9ff6b98df95d3588adb178ac49,Physical Review Letters
2350,"Inhibition of neutrophil superoxide secretion by the preservative, methylhydroxybenzoate: effects mediated by perturbation of intracellular Ca2+?","The preservative, methylhydroxybenzoate inhibited O2- secretion from human neutrophils activated by both the chemotactic peptide fMet-Leu-Phe and phorbol myristate acetate (PMA): the low level of oxidant secretion activated by the ionophore A23187 was similarly reduced in preservative-treated suspensions. Oxidant secretion was similarly reduced in fMet-Leu-Phe and A23187 treated suspensions in which intracellular Ca2+ was buffered by loading with Quin-2, indicating that methylhydroxybenzoate may exert its effects by perturbation of intracellular Ca2(+)-dependent processes. Methylhydroxybenzoate could mimic EGTA in preventing the Ca2+ dependent enhancement of trypsin activity and could also bind this cation in experiments using a Ca2+ electrode, although the preservative bound Ca2+ more slowly and had a lower affinity than EGTA. These data indicate that methylhydroxybenzoate may exert its effects on neutrophils by perturbation of Ca2(+)-dependent activation pathways and this phenomenon may also explain its other known pharmacological effects. Furthermore, these observations provide an insight into the mechanisms by which intracellular Ca2+ may regulate oxidant secretion.",,https://www.semanticscholar.org/paper/351a75130a19904360fde89a3114a8edffc98204,Free Radical Research Communications
1435,Looking for WIMPs: The Cryogenic Dark Matter Search,,,https://www.semanticscholar.org/paper/1d07f1629311e6bac5662ea83433b32a52f7f136,
2213,DcR3 Mutations in Patients with Juvenile-onset Systemic Lupus Erythematosus Lead to Enhanced Lymphocyte Proliferation,"Objective. Previous studies suggested a role for the death decoy receptor 3 (DcR3) in the pathogenesis of adult systemic lupus erythematosus (SLE). We investigated the role of DcR3 in juvenile-onset SLE, to identify polymorphisms that might alter the function of this protein. Methods. DcR3 was measured in the serum of 61 patients with juvenile SLE. The coding region of the DcR3 gene was sequenced in 100 juvenile and 103 adult patients with SLE, together with 500 healthy controls. Results. DcR3 was elevated in the serum of juvenile patients with active SLE disease (440.8 ± 169.1 pg/ml), compared to patients with inactive disease (122.6 ± 28.05 pg/ml; p = 0.0014) and controls (69.27 ± 20.23 pg/ml; p = 0.0009). DNA sequencing identified 2 novel missense mutations: c.C167T (p.T56I) in an adult SLE patient and c.C364T (p.H122Y) in a juvenile patient. Recombinant proteins containing these mutations exhibited altered binding kinetics to FasL and they significantly increased lymphocyte proliferation, compared to the wild-type protein (p < 0.05). The adult patient with SLE carrying the p.T56I mutation had significantly increased lymphocyte proliferation compared to 3 SLE controls matched for age, sex, and disease severity. Conclusion. DcR3 may play an etiologic role in SLE through either elevated serum levels of wild-type DcR3 or normal levels of gain-of-function DcR3 proteins that increase lymphocyte proliferation.",2013-08-01,https://www.semanticscholar.org/paper/1c20f7846314b2e131ec26dc62364f9d6f177c86,Journal of Rheumatology
3466,Partitioning planar graphs with costs and weights,"A graph separator is a set of vertices or edges whose removal divides an input graph into components of bounded size. This paper describes new algorithms for computing separators in planar graphs as well as techniques that can be used to speed up their implementation and improve the partition quality. In particular, we consider planar graphs with costs and weights on the vertices, where weights are used to estimate the sizes of the components and costs are used to estimate the size of the separator. We show that one can find a small separator that divides the graph into components of bounded size. We describe implementations of the partitioning algorithms and discuss results of our experiments.",,https://www.semanticscholar.org/paper/29d172dcecd0178d565918f2e4eaa76e14414889,
2607,BRIDGING THE GAPS: HYBRID TRACKING FOR ADAPTIVE MOBILE AUGMENTED REALITY,"Tracking accuracy in a location-aware mobile system can change dynamically as a function of the user's location and other variables specific to the tracking technologies used. This is especially problematic for mobile augmented reality systems, which ideally require extremely precise position tracking for the user's head, but which may not always be able to achieve that level of accuracy. While it is possible to ignore variable positional accuracy in an augmented reality user interface, this can make for a confusing system; for example, when accuracy is low, virtual objects that are nominally registered with real ones may be too far off to be of use. To address this problem, we describe an experimental mobile augmented reality system that: (1) employs multiple position-tracking technologies, including ones that apply heuristics based on environmental knowledge; (2) coordinates these concurrently monitored tracking systems; and (3) automatically adapts the user interface to varying degrees of confidence in tracking accuracy. We share our experiences with managing these multiple tracking technologies, employing various techniques to facilitate smooth and reasonable “hand-offs” between the cooperating systems. We present these results in the context of an intelligent navigational guidance system that helps users to orient themselves in an unfamiliar environment, using path planning to guide them toward destinations they choose, and sometimes towards ones the system infers as equally relevant.",2004-07-01,https://www.semanticscholar.org/paper/b3d6b80c4c3b6f95b8bf56c1450154439a3820ff,Applied Artificial Intelligence
1738,NON-PARAMETRIC BAYESIAN ANALYSIS OF HETEROGENEOUS DATA,"Abstract : Under this grant, my research focused on fusing heterogenous sources of data with Bayesian nonparametric models. We published many papers in the service of this goal. I would like to highlight the following papers about furthering Bayesian nonparametrics and examining the fusion of heterogenous data types in a diversity of settings. This is an extension of last year s report. It is my final report.",2013-03-01,https://www.semanticscholar.org/paper/adc53e88c061a6f871c0a6aa653de443fdee21e2,
648,Stenting of the right internal mammary artery graft and right coronary artery via a femoral approach.,"We describe a case of balloon angioplasty and stenting of the right internal mammary artery (RIMA) graft anastomosis and the native right coronary artery through an in situ RIMA graft using two Bard XT stents (USCI Division of C.R. Bard, Inc., Billerica, Massachusetts). This case illustrates the feasibility of transluminal angioplasty and stenting of RIMA grafts and the native coronary artery using a femoral artery approach.",1999-06-01,https://www.semanticscholar.org/paper/197c957c26b22dea2d4da77b485cb6cae3fdf43d,The Journal of invasive cardiology
2354,Effect of azacytidine upon protein synthesis in human neutrophils,,1989-08-01,https://www.semanticscholar.org/paper/562e70f3e663c6b2ba58054e77f5543e8a1d2afc,
1725,Topic Model,,,https://www.semanticscholar.org/paper/f47af707941a43fae8b58066eab91ee12ea7a72a,Encyclopedia of Social Network Analysis and Mining
891,Four pages are necessary and sufficient for planar graphs,,1986-11-01,https://www.semanticscholar.org/paper/a1ae48e8c24cf15c64fe7bbc47c63a64d55efea5,Symposium on the Theory of Computing
3754,Stream 2 D convolutions Foreground Stream 3 D convolutions Noise 100 dim Mask Foreground Background,"We capitalize on large amounts of unlabeled video in order to learn a model of scene dynamics for both video recognition tasks (e.g. action classification) and video generation tasks (e.g. future prediction). We propose a generative adversarial network for video with a spatio-temporal convolutional architecture that untangles the scene’s foreground from the background. Experiments suggest this model can generate tiny videos up to a second at full frame rate better than simple baselines, and we show its utility at predicting plausible futures of static images. Moreover, experiments and visualizations show the model internally learns useful features for recognizing actions with minimal supervision, suggesting scene dynamics are a promising signal for representation learning. We believe generative video models can impact many applications in video understanding and simulation.",,https://www.semanticscholar.org/paper/2e68190ebda2db8fb690e378fa213319ca915cf8,
3063,Teaching operating systems using virtual appliances and distributed version control,"Students learn more through hands-on project experience for computer science courses such as operating systems, but providing the infrastructure support for a large class to learn by doing can be hard. To address this issue, we introduce a new approach to managing and grading operating system homework assignments based on virtual appliances, a distributed version control system, and live demonstrations. Our solution is easy to deploy and use with students' personal computers, and obviates the need to provide a computer laboratory for teaching purposes. It supports the most demanding course projects, such as those that involve operating system kernel development, and can be used by both on-campus and remote distance learning students even with intermittent network connectivity. Our experiences deploying and using this solution to teach operating systems at Columbia University show that it is easier to use, more flexible, and more pedagogically effective than other approaches.",2010-03-10,https://www.semanticscholar.org/paper/8e63c7f5e88d1bd1cc7facd44611b1b2d6901469,Technical Symposium on Computer Science Education
3288,Biometric animal databases from field photographs: identification of individual zebra in the wild,"We describe an algorithmic and experimental approach to a fundamental problem in field ecology: computer-assisted individual animal identification. We use a database of noisy photographs taken in the wild to build a biometric database of individual animals differentiated by their coat markings. A new image of an unknown animal can then be queried by its coat markings against the database to determine if the animal has been observed and identified before. Our algorithm, called StripeCodes, efficiently extracts simple image features and uses a dynamic programming algorithm to compare images. We test its accuracy against two different classes of methods: Eigenface, which is based on algebraic techniques, and matching multi-scale histograms of differential image features, an approach from signal processing. StripeCodes performs better than all competing methods for our dataset, and scales well with database size.",2011-04-18,https://www.semanticscholar.org/paper/c1886c3dd3c12afb079efa2d0f14efa5324fb721,International Conference on Multimedia Retrieval
588,Inclusion dependencies and their interaction with functional dependencies,"Inclusion dependencies, or INDs (which can say, for example, that every manager is an employee) are studied, including their interaction with functional dependencies, or FDs. A simple complete axiomatization for INDs is presented, and the decision problem for INDs is shown to be PSPACE-complete. (The decision problem for INDs is the problem of determining whether or not Σ logically implies σ, given a set Σ of INDs and a single IND σ). It is shown that finite implication (implication over databases with a finite number of tuples) is the same as unrestricted implications for INDs, although finite implication and unrestricted implication are distinct for FDs and INDs taken together. It is shown that, although there are simple complete axiomatizations for FDs alone and for INDs alone, there is no complete axiomatization for FDs and INDs taken together, in which every rule is k-ary for some fixed k (and in particular, there is no finite complete axiomatization.) This is true whether we consider finite implication or unrestricted implication, and is true even if no relation scheme has more than three attributes. The nonexistence of a k-ary complete axiomatization for FDs and INDs taken together is proven by giving a condition which is necessary and sufficient in general for the existence of a k-ary complete axiomatization.",1982-03-29,https://www.semanticscholar.org/paper/1eac7a953a57dda2112cb759423c80ec723e429c,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
784,Closed Partition Lattice and Machine Decomposition,"Finite-state machines are widely used to model systems in diverse areas. Often, the modeling machines can be decomposed into smaller component machines and this decomposition can facilitate the system design, implementation and analysis. J. Hartmanis and R.E. Stearns (1966) developed an elegant algebraic theory for machine decomposition that is based on the closed-partition lattice of a machine. In this paper, we study the computation of the closed-partition lattice of finite-state machines for the application to their decomposition. We present efficient algorithms for constructing the closed-partition lattice and for machine decomposition.",2002-02-01,https://www.semanticscholar.org/paper/1ba76d961bda5cc5db8ae2b9142135f24c576da7,IEEE Trans. Computers
1409,Search for leptoquark pairs decaying to $\nu\nu$ + jets in $p\bar p$ collisions at $\sqrt s$ = 1.8 TeV,"We present the results of a search for leptoquark (LQ) pairs in (85.2 +- 3.7) pb^{-1} of p anti-p collider data collected by the D0 experiment at the Fermilab Tevatron. We observe no evidence for leptoquark production and set a limit on sigma(p anti-p -> LQ anti-LQ -> neutrino neutrino + jets) as a function of the mass of the leptoquark (m_{LQ}). Assuming the decay LQ -> neutrino q, we exclude scalar leptoquarks for m_{LQ} < 98 GeV/c^2, and vector leptoquarks for m_{LQ} < 200 GeV/c^2 and coupling which produces the minimum cross section, at a 95% confidence level.",,https://www.semanticscholar.org/paper/4be98300c9f82ced0a549215ca08d8c95c04ae49,
3338,"Sperm competition in the water strider, Gerris remigis
",,1989-10-01,https://www.semanticscholar.org/paper/b41ca951dce8725edc7daf0ad12ae82fe97b884e,Animal Behaviour
1335,Helicity of the W boson in lepton + jets tt̄ events,,2005-06-23,https://www.semanticscholar.org/paper/1f8c596e3f34b16753e860b28b41cfdc0bd05bb1,
2772,[38] O. Sudarsky and C. Gotsman. Output-sensitive Rendering and Communication in Dynamic A. Funkhouser. Ring: a Client-server System for Multi-user Virtual Environments. in Bibliography Summary and Conclusions,"[30] B. F. Naylor. Partitioning tree image representation and generation from 3D geometric models. [37] O. Sudarsky and C. Gotsman. Output-sensitive visibility algorithms for dynamic scenes with applications to virtual reality. [18] T. A. Funkhouser. Database management for interactive display of large architectural models. Kinetic binary space partitions for intersecting segments and disjoint triangles. BSP tree projection. Different culling algorithms can be used in a similar way. Minor adjustments may be required for some algorithms. For example, if Teller and Funkhouser's cell intervisibility precalculation is used [19, 41], then occlusions of dynamic objects by static scenery can easily be utilized, but occlusions by dynamic objects are harder to detect. Other occlusion culling techniques may be even harder to adapt to dynamic scenes. For example, in a static scene, the set of objects seen from each region of viewpoints in space can simply be found by brute force at preprocessing, and stored for use at runtime; however, the generalization of this method to dynamic scenes is not simple, and might even be less efficient than rendering the whole model without any occlusion culling. The TBVs used in this research are "" flat, "" in the sense that each is related to a single object (usually composed of numerous primitives). An alternative that can be explored is to employ hierarchical TBVs, i.e. temporal bounding volumes that contain, in turn, other volumes, thus relating to more than one object. This may have some advantages in certain cases, e.g. when the dynamic objects tend to stay in clusters rather than being evenly spread through space. As mentioned above, one of the main advantages of dynamic scene occlusion culling is that it saves unneeded updates of unseen dynamic objects. It thus harnesses the power of occlusion culling to reduce the number of object update messages, which can potetially be very time-consuming in distributed environments. Another possible direction of future research is the combination this message reduction method with other techniques, such as dead reckoning. The same general idea may also be applied to level-of-detail control: update messages for distant objects with small screen projections can be sent less frequently than for apparently large objects. In conclusion, the rich body of work on 3D graphics optimization includes a lot of techniques that were originally developed with static scenes in mind. The generalization of these techniques to dynamic scenes is not always simple, but it is definitely …",,https://www.semanticscholar.org/paper/1b55c33cf31e1a9bd1a5e3687d255d06a6268773,
1770,Distance Dependent Infinite Latent Feature Models,"Latent feature models are widely used to decompose data into a small number of components. Bayesian nonparametric variants of these models, which use the Indian buffet process (IBP) as a prior over latent features, allow the number of features to be determined from the data. We present a generalization of the IBP, the distance dependent Indian buffet process (dd-IBP), for modeling non-exchangeable data. It relies on distances defined between data points, biasing nearby data to share more features. The choice of distance measure allows for many kinds of dependencies, including temporal and spatial. Further, the original IBP is a special case of the dd-IBP. We develop the dd-IBP and theoretically characterize its feature-sharing properties. We derive a Markov chain Monte Carlo sampler for a linear Gaussian model with a dd-IBP prior and study its performance on real-world non-exchangeable data.",2011-10-25,https://www.semanticscholar.org/paper/7d9184edefd59b8692f9f41c038446afacea931f,IEEE Transactions on Pattern Analysis and Machine Intelligence
2900,Prediction of on-target and off-target activity of CRISPR-Cas13d guide RNAs using deep learning.,,2023-07-03,https://www.semanticscholar.org/paper/f4b1a3cf74e8128f5d9c3b7f64666135ffe3e2fd,Nature Biotechnology
3300,A rare fight in female plains zebra,,,https://www.semanticscholar.org/paper/96d278fe951923abec07e5d02da3219d1919672d,Journal of ethology
1139,Search for Associatedand Higgs Boson Production inCollisions at,,2009-02-04,https://www.semanticscholar.org/paper/026b67a478bdf78c5000caf513f071e225238147,
1799,Syntactic Topic Models Supplement,"1. Choose global topic weights β ∼ GEM(α) 2. For each topic index k = {1, . . . }: (a) Choose topic transition distribution πk ∼ DP(αT , β). (b) Choose topic τk ∼ Dir(σ) 3. For each document d = {1, . . . M}: (a) Choose topic weights θd ∼ DP(αD, β). (b) For each sentence in the document: i. Choose topic assignment z0 ∝ θdπstart ii. Choose root word w0 ∼ mult(1, τz0) iii. For each additional word wn and parent pn, n ∈ {1, . . . dn} • Choose topic assignment zn ∝ θdπzp(n) • Choose word wn ∼ mult(1, τz0)",,https://www.semanticscholar.org/paper/470555cbaa483af32fd1a5cd7ca314554e91a61a,
2876,Human Galectin-3 Is a Novel Chemoattractant for Monocytes and Macrophages1,"Galectin-3 is a β-galactoside-binding protein implicated in diverse biological processes. We found that galectin-3 induced human monocyte migration in vitro in a dose-dependent manner, and it was chemotactic at high concentrations (1.0 μM) but chemokinetic at low concentrations (10–100 nM). Galectin-3-induced monocyte migration was inhibited by its specific mAb and was blocked by lactose and a C-terminal domain fragment of the protein, indicating that both the N-terminal and C-terminal domains of galectin-3 are involved in this activity. Pertussis toxin (PTX) almost completely blocked monocyte migration induced by high concentrations of galectin-3. Galectin-3 caused a Ca2+ influx in monocytes at high, but not low, concentrations, and both lactose and PTX inhibited this response. There was no cross-desensitization between galectin-3 and any of the monocyte-reactive chemokines examined, including monocyte chemotactic protein-1, macrophage inflammatory protein-1α, and stromal cell-derived factor-1α. Cultured human macrophages and alveolar macrophages also migrated toward galectin-3, but not monocyte chemotactic protein-1. Finally, galectin-3 was found to cause monocyte accumulation in vivo in mouse air pouches. These results indicate that galectin-3 is a novel chemoattractant for monocytes and macrophages and suggest that the effect is mediated at least in part through a PTX-sensitive (G protein-coupled) pathway.",2000-08-15,https://www.semanticscholar.org/paper/6b839c691c98fda8340cac159e81e9b90aff40d6,Journal of Immunology
107,Exploiting Geographical Location Information of Web Pages,"Many information resources on the web are relevant primarily to limited geographical communities. For instance, web sites containing information on restaurants, theaters, and apartment rentals are relevant primarily to web users in geographical proximity to these locations. In contrast, other information resources are relevant to a broader geographical community. For instance, an on-line newspaper may be relevant to users across the United States. Unfortunately, the geographical scope of web resources is largely ignored by web search engines. We make the case for identifying and exploiting the geographical location information of web sites so that web search engines can rank resources in a geographically sensitive fashion, in addition to using more traditional information-retrieval strategies. In this paper, we first consider how to compute the geographical location of web pages. Subsequently, we consider how to exploit such information in one specific ""proof-of-concept"" application we implemented in JAVA, and discuss other examples as well.",1999-06-03,https://www.semanticscholar.org/paper/fa27189fb9955538b0590d16b525af1dc3ad5a8b,International Workshop on the Web and Databases
1143,Search for dark photons from supersymmetric hidden valleys.,"We search for a new light gauge boson, a dark photon, with the D0 experiment. In the model we consider, supersymmetric partners are pair produced and cascade to the lightest neutralinos that can decay into the hidden sector state plus either a photon or a dark photon. The dark photon decays through its mixing with a photon into fermion pairs. We therefore investigate a previously unexplored final state that contains a photon, two spatially close leptons, and large missing transverse energy. We do not observe any evidence for dark photons and set a limit on their production.",2009-05-11,https://www.semanticscholar.org/paper/15055385a0615ead20447ab729a331fe9e6990b4,Physical Review Letters
1231,"Erratum to Measurement of $\sigma (p \bar p \to Z) \cdot Br(Z \to \tau\tau)$ at $\bm{\sqrt{s}=}$1.96 TeV, published in Phys. Rev. D {71}, 072004 (2005)",A change in estimated integrated luminosity (from 226 pb$^{-1} to 257 pb$^{-1}$ leads to a corrected value for ${\sigma (p \bar p \to Z) \cdot}$Br${(Z \to \tau \tau)}$ of $209\pm13(stat.)\pm16(syst.)\pm13(lum) pb.,,https://www.semanticscholar.org/paper/7edd07bc59853e2db299e7361153b50d4d1f4dd1,
2189,238. ROLE OF EXOGENOUS AND ENDOGENOUS TUMOUR NECROSIS FACTOR ALPHA IN THE REGULATION OF AN INTERFERON GENE EXPRESSION SIGNATURE IN RHEUMATOID ARTHRITIS NEUTROPHILS,,2017-04-01,https://www.semanticscholar.org/paper/348e8dcabfc817ee02d5d18e7a118ad0f60e1f1b,
1493,Strange-quark suppression in 225-GeV/c. pi. /sup -/Be interactions,"We report here on a new measurement of the strange-quark suppression factor lambda, using data on ..omega..(783) and phi(1020) mesons observed via the decay to ..mu../sup +/..mu../sup -/. We find lambda = 0.31 +- 0.05, compared to a world average of about 0.29.",1983-10-01,https://www.semanticscholar.org/paper/8d04cc3b5bdb0b2b7026a5d6ba3252e4fab0f9a9,
2696,Research in 3D user interface design at Columbia University,The Computer Graphics and User Interfaces Laboratory at Columbia University is pursuing research in the design and development of new user interface metaphors. This overview provides a high-level description of our work and surveys projects that reflect our two key research directions: 3D user interfaces (including virtual environments and augmented reality) and knowledge-based user interfaces.,1996-04-18,https://www.semanticscholar.org/paper/c45c68b8cea5e61b41a692dc1229ffd1af897ab5,CHI Conference Companion
1079,Results from the Super Cryogenic Dark Matter Search Experiment at Soudan.,"We report the result of a blinded search for weakly interacting massive particles (WIMPs) using the majority of the SuperCDMS Soudan data set. With an exposure of 1690 kg d, a single candidate event is observed, consistent with expected backgrounds. This analysis (combined with previous Ge results) sets an upper limit on the spin-independent WIMP-nucleon cross section of 1.4×10^{-44} (1.0×10^{-44})  cm^{2} at 46  GeV/c^{2}. These results set the strongest limits for WIMP-germanium-nucleus interactions for masses >12  GeV/c^{2}.",2017-08-29,https://www.semanticscholar.org/paper/39b32d5869b417f23b7cdd250ac3207ce413c579,Physical Review Letters
551,The performance of a precedence-based queuing discipline,"A queuing system with infinitely many servers, and with the following queuing discipline is considered: For any two jobs <italic>i</italic> and <italic>j</italic> in the system, such that <italic>i</italic> arrived later than <italic>j</italic>, there is a fixed probability <italic>p</italic> that <italic>i</italic> will have to wait for <italic>j</italic>'s execution to terminate before <italic>i</italic> starts executing. This queuing system is a very simple model for database concurrency control via “static” locking, as well as of parallel execution of programs consisting of several interdependent processes. The problem of determining the maximum arrival rate (as a function of <italic>p</italic>) that can be sustained before this system becomes unstable is studied. It is shown that this rate is inversely proportional to <italic>p</italic>, and close upper and lower bounds on the constant for the case of deterministic departures are found. The result suggests that the degree of multiprogramming of multiuser databases, or the level of parallelism of concurrent programs, is inversely proportional to the probability of conflict, and that the constant is small and known within a factor of 2. The technique used involves the computation of certain asymptotic parameters of a random infinite directed acyclic graph (dag) that seem of interest by themselves.",1986-05-01,https://www.semanticscholar.org/paper/9cf7fa4c11f0c5c2606c464c04b9c05e785162e9,JACM
1473,Study of eta-prime formation in photon-photon collisions,"Disclaimer/Complaints regulations If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. In case of a legitimate complaint, the Library will make the material inaccessible and/or remove it from the website. Please Ask the Library: http://uba.uva.nl/en/contact, or a letter to: Library of the University of Amsterdam, Secretariat, Singel 425, 1012 WP Amsterdam, The Netherlands. You will be contacted as soon as possible.",,https://www.semanticscholar.org/paper/3dd15edd311dfd07480d39d74e36dac4403e1a4b,
304,Algorithmic Game Theory: The Complexity of Finding Nash Equilibria,,,https://www.semanticscholar.org/paper/3b82210417e454106a3c753b044b28ff8df5d246,
2388,Elevation of AMP Levels During Phagocytosis in Acanthamoeba castellanii,"SUMMARY: Addition of particles to growing cultures of the amoeba, Acanthamoeba castellanii resulted in the production of large amounts of AMP, much of which was found extracellularly. At the time of maximal AMP production (13 h growth) adenylate energy charge values in conditioned and fresh medium were 0·58 and 0·1, respectively. Removal of particles from growth medium by filtration lowered the AMP level to 22% of the control value at the time of maximal AMP production; addition of particles to conditioned medium raised the level of AMP 3·6-fold.
Uptake of killed yeast was accompanied by relatively small changes in levels of ATP and ADP, but large (5·7-fold) changes in AMP levels. Successive cycles of phagocytosis were paralleled by cyclic changes in AMP levels.",1982-12-01,https://www.semanticscholar.org/paper/7219680337922609983c3c958eed756ad322231c,
1516,Nonparametric Identifiability of Causal Representations from Unknown Interventions,"We study causal representation learning, the task of inferring latent causal variables and their causal relations from high-dimensional functions (""mixtures"") of the variables. Prior work relies on weak supervision, in the form of counterfactual pre- and post-intervention views or temporal structure; places restrictive assumptions, such as linearity, on the mixing function or latent causal model; or requires partial knowledge of the generative process, such as the causal graph or the intervention targets. We instead consider the general setting in which both the causal model and the mixing function are nonparametric. The learning signal takes the form of multiple datasets, or environments, arising from unknown interventions in the underlying causal model. Our goal is to identify both the ground truth latents and their causal graph up to a set of ambiguities which we show to be irresolvable from interventional data. We study the fundamental setting of two causal variables and prove that the observational distribution and one perfect intervention per node suffice for identifiability, subject to a genericity condition. This condition rules out spurious solutions that involve fine-tuning of the intervened and observational distributions, mirroring similar conditions for nonlinear cause-effect inference. For an arbitrary number of variables, we show that two distinct paired perfect interventions per node guarantee identifiability. Further, we demonstrate that the strengths of causal influences among the latent variables are preserved by all equivalent solutions, rendering the inferred representation appropriate for drawing causal conclusions from new data. Our study provides the first identifiability results for the general nonparametric setting with unknown interventions, and elucidates what is possible and impossible for causal representation learning without more direct supervision.",2023-06-01,https://www.semanticscholar.org/paper/58c4a25181c962df905bbf32f23a047d57549163,arXiv.org
3000,BlackBox: A Container Security Monitor for Protecting Containers on Untrusted Operating Systems,"Containers are widely deployed to package, isolate, and multiplex applications on shared computing infrastructure, but rely on the operating system to enforce their security guarantees. This poses a signiﬁcant security risk as large operating system codebases contain many vulnerabilities. We have created BlackBox, a new container architecture that provides ﬁne-grain protection of application data conﬁdentiality and integrity without trusting the operating system. BlackBox introduces a container security monitor, a small trusted computing base that creates protected physical address spaces (PPASes) for each container such that there is no direct information ﬂow from container to operating system or other container PPASes. Indirect information ﬂow can only happen through the monitor, which only copies data between container PPASes and the operating system as system call arguments, encrypting data as needed to protect interprocess communication through the operating system. Containerized applications do not need to be modiﬁed, can still make use of operating system services via system calls, yet their CPU and memory state are isolated and protected from other containers and the operating system. We have implemented BlackBox by leveraging Arm hardware virtualization support, using nested paging to enforce PPASes. The trusted computing base is a few thousand lines of code, many orders of magnitude less than Linux, yet supports widely-used Linux containers with only modest modiﬁcations to the Linux kernel. We show that BlackBox provides superior security guarantees over traditional hypervisor and container architectures with only modest performance overhead on real application workloads.",,https://www.semanticscholar.org/paper/3af13b96191578ccb41388b3017829246859ea00,USENIX Symposium on Operating Systems Design and Implementation
2241,Reduction in membrane TNF expression in neutrophils from rheumatoid arthritis patients following anti-TNF therapy,,,https://www.semanticscholar.org/paper/46773f3c8a29f06453ae54a28338918c585101e8,
1244,Measurement of Bs0 mixing parameters from the flavor-tagged decay Bs0-->J/psiphi.,"From an analysis of the flavor-tagged decay Bs0-->J/psiphi we obtain the width difference between the Bs0 light and heavy mass eigenstates, DeltaGammas = 0.19+/-0.07(stat)(-0.01)+0.02(syst) ps(-1), and the CP-violating phase, phi s= -0.57(-0.30)+0.24(stat)(-0.02)+0.08(syst). The allowed 90% CL intervals of DeltaGammas and phi s are 0.06 < DeltaGammas < 0.30 ps(-1) and -1.20 < phi s < 0.06, respectively. The data sample corresponds to an integrated luminosity of 2.8 fb(-1) accumulated with the D0 detector at the Fermilab Tevatron collider.",2008-12-08,https://www.semanticscholar.org/paper/a25538a1bed116f6995a49d0b7b402493a3e9aae,Physical Review Letters
3464,Approximating disjoint-path problems using packing integer programs,,,https://www.semanticscholar.org/paper/e63fb6dfb7b2b1903e1c64ac75eadb12b037f216,Mathematical programming
2662,Exploratory programming of distributed augmented environments,"Augmented reality is a form of virtual reality that uses see-through displays to enhance the world with computer-generated material. When combined with more traditional displays, a powerful augmented environment emerges in which two and three dimensional information can be presented to a user simultaneously on a combination of displays. Prototyping these environments is challenging both because they are highly distributed, interactive systems, and because of the exploratory nature of building systems for new interaction paradigms. 
We have developed a testbed for exploratory programming of distributed augmented environments, called Coterie. A single programming model is used for both single and multiprocess programs by building applications as groups of threads communicating via shared objects. The distributed programming model is distributed object memory (DOM), an object-based approach to distributed shared memory. Coterie's DOM presents the programmer with both client-server and replicated distributed objects. 
Both interpreted (Repo) and compiled (Modula-3) languages present the application programmer with similar DOM programming models. Modula-3's replicated objects are implemented using Shared Objects, an object replication package that is tightly integrated with the Modula-3 object system and designed to be flexible and easy-to-use. Repo is implemented using the Shared Object package, and presents the programmer with an interpreted language that supports both client-server and replicated objects uniformly across its entire type system. The final important component of Coterie is Repo-3D, a high-level, distributed graphics library, built using the Shared Objects package and tightly integrated with Repo. By making all graphical objects extensible and transparently distributable, programmers can use Repo-3D scene graphs as the basis for their application data structures, allowing complex distributed graphical applications to be created in a straight-forward manner. 
Numerous stand-alone and distributed augmented environment systems have been developed using Coterie, and demonstrate its usefulness. These include an architectural anatomy system for viewing the support structures inside the walls of a building, a construction assistant for space frame buildings, a maintenance and repair task for telephone crossboxes, an augmented reality tour guide, and a number of interface concepts for the National Tele-Immersion Initiative.",,https://www.semanticscholar.org/paper/75109e5d9c33e18f5ebc0d4048b8f959963f3555,
1841,Nonparametric empirical Bayes for the Dirichlet process mixture model,,2006-03-01,https://www.semanticscholar.org/paper/31cbc51a4a441d2ca6668e0e0614f5abfcb88194,Statistics and computing
3346,Tail size and female choice in the guppy (Poecilia reticulata),,1985-08-01,https://www.semanticscholar.org/paper/e25f72e9c1ab59de8c6a063449e3030ad913d3e7,Behavioral Ecology and Sociobiology
729,"Stochastic Context-Free Grammars, Regular Languages, and Newton's Method",,2013-02-26,https://www.semanticscholar.org/paper/749bdc64263934e431592875f2e6f5565ffab121,"International Colloquium on Automata, Languages and Programming"
423,Approximation Algorithms for SegmentationProblems,"We introduce and study a novel genre of optimization problems, which we call segmentation problems, motivated in part by certain aspects of clustering and data mining. For any classical optimization problem, the corresponding segmentation problem seeks to partition a set of cost vectors into several segments, so that the overall cost is optimized. We focus on two natural and interesting (but MAXSNP-complete) problems in this class, the hypercube segmentation problem and the catalog segmentation problem, and present approximation algorithms for them. We also present a general greedy scheme, which can be specialized to approximate any segmentation problem.",,https://www.semanticscholar.org/paper/7518ef9313bb0e16961ed37c264f55ec2089123c,
128,The Efficacy of GlOSS for the Text Database Retrieval Problem,,,https://www.semanticscholar.org/paper/ba92ba07cb9eafe18f6435e4ccadddb358195468,
2960,Allele-specific expression reveals interactions between genetic variation and environment,,2015-09-13,https://www.semanticscholar.org/paper/de683687eec3674612e8db66723629cfe20e583e,Nature Methods
259,Modeling Social Networks through User Background and Behavior,,2011-05-27,https://www.semanticscholar.org/paper/d41417d03bc623c50f5c2bd7887eb4377ea9622a,Workshop on Algorithms and Models for the Web-Graph
1102,Snowmass CF1 Summary: WIMP Dark Matter Direct Detection,"Author(s): Cushman, P; Galbiati, C; McKinsey, DN; Robertson, H; Tait, TMP; Bauer, D; Borgland, A; Cabrera, B; Calaprice, F; Cooley, J; Empl, T; Essig, R; Figueroa-Feliciano, E; Gaitskell, R; Golwala, S; Hall, J; Hill, R; Hime, A; Hoppe, E; Hsu, L; Hungerford, E; Jacobsen, R; Kelsey, M; Lang, RF; Lippincott, WH; Loer, B; Luitz, S; Mandic, V; Mardon, J; Maricic, J; Maruyama, R; Mahapatra, R; Nelson, H; Orrell, J; Palladino, K; Pantic, E; Partridge, R; Ryd, A; Saab, T; Sadoulet, B; Schnee, R; Shepherd, W; Sonnenschein, A; Sorensen, P; Szydagis, M; Volansky, T; Witherell, M; Wright, D; Zurek, K | Abstract: As part of the Snowmass process, the Cosmic Frontier WIMP Direct Detection subgroup (CF1) has drawn on input from the Cosmic Frontier and the broader Particle Physics community to produce this document. The charge to CF1 was (a) to summarize the current status and projected sensitivity of WIMP direct detection experiments worldwide, (b) motivate WIMP dark matter searches over a broad parameter space by examining a spectrum of WIMP models, (c) establish a community consensus on the type of experimental program required to explore that parameter space, and (d) identify the common infrastructure required to practically meet those goals.",2013-10-30,https://www.semanticscholar.org/paper/2ab5584a05b674a0120cc033219948e2287c3909,
1380,Measurement of the ratio of inclusive cross sections sigma(pp --> Z + b jet)/sigma(pp --> Z + jet) at square root(s) = 1.96 TeV.,"Using the data collected with the D0 detector at square root(s) = 1.96 TeV, for integrated luminosities of about 180 pb(-1), we have measured the ratio of inclusive cross sections for pp --> Z + b jet to pp --> Z + jet production. The inclusive Z + b-jet reaction is an important background to searches for the Higgs boson in associated ZH production at the Fermilab Tevatron collider. Our measurement is the first of its kind, and relies on the Z --> e+ e- and Z --> mu+ mu- modes. The combined measurement of the ratio yields 0.021+/-0.005 for hadronic jets with transverse momenta pT > 20 GeV/c and pseudorapidities absolute value(eta) < 2.5, consistent with next-to-leading-order predictions of the standard model.",2004-10-26,https://www.semanticscholar.org/paper/eed6b53f0466bd84d68be086012707c6e125d865,Physical Review Letters
2366,"The relationship between superoxide generation, cytochrome β and oxygen in activated neutrophils",,,https://www.semanticscholar.org/paper/f4e1f5bb54916856ac3d34f66ca8fc3caf8788a0,FEBS Letters
3250,Social networks predict selective observation and information spread in ravens,"Animals are predicted to selectively observe and learn from the conspecifics with whom they share social connections. Yet, hardly anything is known about the role of different connections in observation and learning. To address the relationships between social connections, observation and learning, we investigated transmission of information in two raven (Corvus corax) groups. First, we quantified social connections in each group by constructing networks on affiliative interactions, aggressive interactions and proximity. We then seeded novel information by training one group member on a novel task and allowing others to observe. In each group, an observation network based on who observed whose task-solving behaviour was strongly correlated with networks based on affiliative interactions and proximity. Ravens with high social centrality (strength, eigenvector, information centrality) in the affiliative interaction network were also central in the observation network, possibly as a result of solving the task sooner. Network-based diffusion analysis revealed that the order that ravens first solved the task was best predicted by connections in the affiliative interaction network in a group of subadult ravens, and by social rank and kinship (which influenced affiliative interactions) in a group of juvenile ravens. Our results demonstrate that not all social connections are equally effective at predicting the patterns of selective observation and information transmission.",2016-07-01,https://www.semanticscholar.org/paper/e1ea08992af39011570b4fec3c6a95e13239dfb5,Royal Society Open Science
1311,Search for resonant second generation slepton production at the Fermilab Tevatron.,"We present a search for supersymmetry in the R-parity violating resonant production and decay of smuons and muon sneutrinos in the channels mu-->chi(1)(0)mu, mu-->chi(2,3,4)(0)mu, and nu(mu)-->chi(1,2)(+/-)mu. We analyzed 0.38 fb(-1) of integrated luminosity collected between April 2002 and August 2004 with the D0 detector at the Fermilab Tevatron Collider. The observed number of events is in agreement with the standard model expectation, and we calculate 95% C.L. limits on the slepton production cross section times branching fraction to gaugino plus muon, as a function of slepton and gaugino masses. In the framework of minimal supergravity, we set limits on the coupling parameter lambda(211)('), extending significantly previous results obtained in Run I of the Tevatron and at the CERN LEP collider.",2006-05-03,https://www.semanticscholar.org/paper/3ddae2c1269439d3ad98ec88c08e23c1abd95cae,Physical Review Letters
2527,Designing for Adoption: A Living Laboratory for Health IT,"We describe how an interdisciplinary collaboration has created a “living laboratory” in which researchers maintain a direct and ongoing l oop between innovation and production and study true adoption of technology in real world settings. The collaborators include the Department of Biomedical Informat ics and the Department of Computer Science at Columbia University, industrial partners developing commerci al health IT applications, and New York-Presbyterian Hospital’s Columbia University Medical Center. In this paper we discuss our current projects, and mention some of the unique benefits and challenges of building a living laboratory for health information technology.",,https://www.semanticscholar.org/paper/eab964d1670580b0a3fca937d3d0b9b6bdafc8fe,
3554,"Syllabus Types and Declarations, Pointers, Arrays, and Structures, Expressions and Statements, Functions, Namespaces and Exceptions, Source Files and Programs. Classes, Operator Overloading, Derived Classes, Templates, Exception Handling, Class Hierarchies. Library Organization and Container, Standa",,,https://www.semanticscholar.org/paper/ff0992f71886ff3483e7f7a32b4013121938c838,
2966,Differential methylation of the TRPA1 promoter in pain sensitivity,,2014-02-04,https://www.semanticscholar.org/paper/a9a9ad920b21d3399a7784d4b7283a313aff5eea,Nature Communications
975,Longitudinal Changes of Optic Nerve Head and Peripapillary Structure during Childhood Myopia Progression on OCT: Boramae Myopia Cohort Study Report 1.,,2018-03-14,https://www.semanticscholar.org/paper/15ec49356dff8471394993ff05671fd630ff72d0,"Ophthalmology (Rochester, Minn.)"
2866,Galectin–3 mediates advanced glycation endproduct (AGE)–induced breakdown of the blood–retinal barrier,,2004-05-01,https://www.semanticscholar.org/paper/b07b0626ee36fb6bf52556f56a9ca51c8ce485cc,
1130,Search for the standard model higgs Boson in the ZH-->nunubb channel in 5.2 fb{-1} of pp collisions at sqrt[s]=1.96 TeV.,"A search is performed for the standard model Higgs boson in 5.2 fb{-1} of pp collisions at sqrt[s]=1.96 TeV, collected with the D0 detector at the Fermilab Tevatron Collider. The final state considered is a pair of b jets and large missing transverse energy, as expected from pp-->ZH-->nunubb production. The search is also sensitive to the WH-->lnubb channel when the charged lepton is not identified. For a Higgs boson mass of 115 GeV, a limit is set at the 95% C.L. on the cross section multiplied by branching fraction for [pp-->(Z/W)H](H-->bb) that is a factor of 3.7 larger than the standard model value, consistent with the factor of 4.6 expected.",,https://www.semanticscholar.org/paper/627f7c637843a66a4fdad133cbdd5287b6be1e64,Physical Review Letters
3006,DistAI: Data-Driven Automated Invariant Learning for Distributed Protocols,"Distributed systems are notoriously hard to implement correctly due to non-determinism. Finding the inductive invariant of the distributed protocol is a critical step in verifying the correctness of distributed systems, but takes a long time to do even for simple protocols. We present DistAI, a data-driven automated system for learning inductive invariants for distributed protocols. DistAI generates data by simulating the distributed protocol at different instance sizes and recording states as samples. Based on the observation that invariants are often concise in practice, DistAI starts with small invariant formulas and enumerates all strongest possible invariants that hold for all samples. It then feeds those invariants and the desired safety properties to an SMT solver to check if the conjunction of the invariants and the safety properties is inductive. Starting with small invariant formulas and strongest possible invariants avoids large SMT queries, improving SMT solver performance. Because DistAI starts with the strongest possible invariants, if the SMT solver fails, DistAI does not need to discard failed invariants, but knows to monotonically weaken them and try again with the solver, repeating the process until it eventually succeeds. We prove that DistAI is guaranteed to find the ∃-free inductive invariant that proves the desired safety properties in finite time, if one exists. Our evaluation shows that DistAI successfully verifies 13 common distributed protocols automatically and outperforms alternative methods both in the number of protocols it verifies and the speed at which it does so, in some cases by more than two orders of magnitude.",,https://www.semanticscholar.org/paper/1d71a942f457f6b324c42256eed829a8806b77dd,USENIX Symposium on Operating Systems Design and Implementation
2141,Teaching geometry effectively with dynamic software Report,"This workshop examined issues related to the effective teaching of geometry with dynamic geometry software. The discussions mainly focused on the development and use of curriculum-related sketches that are either partially constructed, or pre-constructed. Examples of web-based and program-based sketches created with Geometer's Sketchpad and Cinderella were presented and discussed in light of research results and the experience of participants. An important theme throughout the discussions was how to address the needs of teachers – to develop greater geometric knowledge, to access welldesigned materials, and to acquire technological skills. In light of the theme of critical thinking we began by examining how pre-constructed dynamic geometry sketches can help students think about and analyse mathematical ideas. In our definition of pre-constructed sketches we included both web-based and program-based dynamic geometry sketches, whether prepared by teachers, by researchers, or by professional applet designers. Some of these could more properly be named “partially-constructed”, since students are able to alter any program-based sketch and some web-based sketches. Sinclair presented some results from a study that involved grade 12 students using preconstructed web-based sketches. Her research showed that to benefit from using dynamic pre-constructed sketches, students must learn: a) to notice (i.e., to notice detail in static images, to notice change in dynamic images and to apply mathematical knowledge to make sense of the information); b) to pose (their own) questions; and c) to explore. The development of these skills depends both on pedagogical interventions and on the creation of appropriate learning objects. With regard to pedagogy, teachers who want to use dynamic software activities face new challenges. For example, there is a great deal of talk about “investigations” in mathematics classes; however, unlike investigators who continually re-evaluate their progress, and determine how to proceed, students often rely on the teacher to suggest the next step or ask the question that will guide further exploration. Sinclair found that students working in pairs in a lab environment are often unable to engage in fruitful ongoing investigation if they cannot pose their own questions. We discussed the importance of helping inservice and preservice teachers learn how to make effective use of dynamic software tasks. Good design decisions (i.e., what colours to use; whether to display tick marks or measurements; whether to animate) are intimately related to knowledge of what helps us",,https://www.semanticscholar.org/paper/e9ffa3f89ce9d42a03e4195128f476bf0fbc5dd8,
1067,Measurement of the Angular and Lifetime Parameters of the Decays Bd0 âƒTM J/Ï‹K*0 and Bs0 âƒTM J/ÏƒÏ‹,,,https://www.semanticscholar.org/paper/f561636031946a057212a921307697e5ae40e258,
3194,Increased vigilance of plains zebras (Equus quagga) in response to more bush coverage in a Kenyan savanna,,2021-02-22,https://www.semanticscholar.org/paper/6e79bc7a884ff76b701f3c364a1f502e6731424a,Climate Change Ecology
3756,SoundNet: Learning Sound Representations from Unlabeled Video,"We learn rich natural sound representations by capitalizing on large amounts of unlabeled sound data collected in the wild. We leverage the natural synchronization between vision and sound to learn an acoustic representation using two-million unlabeled videos. Unlabeled video has the advantage that it can be economically acquired at massive scales, yet contains useful signals about natural sound. We propose a student-teacher training procedure which transfers discriminative visual knowledge from well established visual recognition models into the sound modality using unlabeled video as a bridge. Our sound representation yields significant performance improvements over the state-of-the-art results on standard benchmarks for acoustic scene/object classification. Visualizations suggest some high-level semantics automatically emerge in the sound network, even though it is trained without ground truth labels.",2016-10-27,https://www.semanticscholar.org/paper/7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9,Neural Information Processing Systems
3151,Measuring the Multimedia Performance of Server-Based Computing,"The server-based computing (SBC) model is becoming an increasingly popular approach for delivering computational services with reduced administrative costs and better resource utilization. In this paper, we examine how effectively SBC architectures support multimedia applications. We focus on the effectiveness of the remote display protocol used in three popular SBC platforms for supporting video applications, Citrix Metaframe, Windows Terminal Server, and AT&T VNC. Our results show that SBC can be a viable approach for delivering VCR-quality video in LAN environments, but that existing solutions are inadequate at network access bandwidths found in broadband environments. Our results also show that SBC can deliver video with comparable network efficiency as streaming media solutions. We show that there is wide variation in the performance of the remote display technologies and discuss the factors that influence their performance.",,https://www.semanticscholar.org/paper/350fd78f0e8432f00d1d18e0c8c003c52a4b57d1,
1991,Coordinating strategic outsourcing decisions for semiconductor assembly using a bi-objective genetic algorithm,"Increasing global competition has forced high-tech companies to focus on their core competences and outsource other activities to maintain their competitive advantages in the supply chains. While most companies rely on domain experts to coordinate strategic outsourcing decisions among a number of qualified vendors with different capabilities, the present problem can be formulated into a complex nonlinear, multi-dimensional, multi-objective combinatorial optimisation problem. Focused on real settings, this study aims to fill the gap via developing a bi-objective genetic algorithm (boGA) for determining the outsourcing order allocation with nonlinear cost structure, while minimising both the total alignment gap and the total allocation cost. The proposed boGA incorporates specific random key representation to facilitate encoding and decoding. This study also develops a bi-objective Pareto solution generation algorithm to enable efficient searching of Pareto solutions in multiple ranks and designs a composite Pareto ranking selection with uniform sum rank weighting for effective selection. To estimate its validity, the proposed boGA was validated with realistic cases from a leading semiconductor company in Hsinchu Science Park in Taiwan. The optimal boGA parameters were tested using a set of experiments. Scenario analyses were conducted to evaluate the performance of the proposed algorithm under different demand conditions using the metrics in the literature. The results have shown the practical viability of the proposed algorithm to solve the present problem of monthly outsourcing decisions for the case company in practicable computation time. This algorithm can determine the near-optimal Pareto front for decision makers to further incorporate with their preferences. This study concludes with discussion of future research directions.",2012-01-01,https://www.semanticscholar.org/paper/0e7d5fb1f990c02d39eba0f4f9c8994fd006d223,
859,Modularity of cycles and paths in graphs,"Certain problems related to the length of cycles and paths modulo a given integer are studied. Linear-time algorithms are presented that determine whether all cycles in an undirected graph are of length <italic>P</italic> mod <italic>Q</italic> and whether all paths between two specified nodes are of length <italic>P</italic> mod <italic>Q</italic>, for fixed integers <italic>P</italic>.<italic>Q</italic>. These results are compared to those for directed graphs.",1991-04-01,https://www.semanticscholar.org/paper/5d348bdba7f33d23d539b7f9463e26f7e41eda8f,JACM
2477,"2014 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design, ISMAR-MASH'D 2014, Munich, Germany, September 10-12, 2014",,,https://www.semanticscholar.org/paper/745546473038ea67b12a45997fc2d6d0116f3ddc,ISMAR-MASH'D
2559,Augmented Reality for Maintenance and Repair (ARMAR),"Abstract : The purpose of this research, Augmented Reality for Maintenance and Repair (ARMAR), was to research the design and development of experimental augmented reality systems for maintenance job aiding. The goal was to explore and evaluate the feasibility of developing prototype adaptive augmented reality systems that can be used to investigate how real time computer graphics, overlaid on and registered with the actual equipment being maintained, can significantly increase the productivity of maintenance personnel, both during training and in the field.",2007-08-01,https://www.semanticscholar.org/paper/a4828a8524cb61ad6765b2de1110979c65078c77,
1419,Inclusive jet production in pp(macro) collisions.,"We report a new measurement of the pseudorapidity (eta) and transverse-energy ( E(T)) dependence of the inclusive jet production cross section in pp(macro) collisions at square root of s = 1.8 TeV using 95 pb(-1) of data collected with the D0 detector at the Fermilab Tevatron. The differential cross section d(2)sigma/(dE(T)d eta) is presented up to eta = 3, significantly extending previous measurements. The results are in good overall agreement with next-to-leading order predictions from QCD and indicate a preference for certain parton distribution functions.",2000-11-10,https://www.semanticscholar.org/paper/097590d373bb9d5ff794dc837f04431c57a916a8,Physical Review Letters
1121,Measurement of Z/γ∗+jet+X angular distributions in collisions at,,2010-01-04,https://www.semanticscholar.org/paper/1bb70319977b0e052e1cad6aeb9b1c494f4d7e1b,
1946,Multi-objective multi-population biased random-key genetic algorithm for the 3-D container loading problem,,2015-11-01,https://www.semanticscholar.org/paper/8bfafe5ede5bf4758bb9fabfecd943b85a5f5663,Computers & industrial engineering
1954,An effective Markov network based EDA for flexible job shop scheduling problems under uncertainty,"This paper presents a min-max regret version programming model for the stochastic flexible job shop scheduling problem (S-FJSP) with the uncertainty of processing time. An effective Markov network based estimation of distribution algorithm (EDA) is proposed to solve S-FJSP to minimize its maximum regret. The proposal employs Markov network modeling machine assignment where the effects between decision variables are represented as an undirected graph model. Furthermore, min-max regret metric based assessing algorithm is used to measure the robustness, where a critical path-based local search method is adopted to achieve better performance. We present an empirical validation for the proposal by applying it to solve various benchmark flexible job shop problems.",2014-10-30,https://www.semanticscholar.org/paper/29580ab60eecf85a53f2137490ce0523e03a313e,2014 IEEE International Conference on Automation Science and Engineering (CASE)
25,Beyond Trending Topics: Real-World Event Identification on Twitter,"
 
 User-contributed messages on social media sites such as Twitter have emerged aspowerful, real-time means of information sharing on the Web. These short messages tend to reflect a variety of events in real time, making Twitter particularly well suited as a source of real-time event content. In this paper, we explore approaches for analyzing the stream of Twitter messages to distinguish between messages about real-world events andnon-event messages. Our approach relies on a rich family of aggregatestatistics of topically similar message clusters. Large-scale experiments over millions of Twitter messages show the effectiveness of our approach for surfacing real-world event content on Twitter.
 
",2011-07-05,https://www.semanticscholar.org/paper/bb7965a9dbeab34cec56e19aae949690f2463f20,International Conference on Web and Social Media
2386,Terminal Oxidase of Crithidia fasciculata. Reactions with Carbon Monoxide and Oxygen at Subzero Temperatures and Photochemical Action Spectra,"SUMMARY: Room temperature CO-difference spectra of whole cells of Crithidia fasciculata show two CO-reacting haemoproteins. The reaction of cytochrome a/a
3 with CO is complete within 1 min of bubbling with CO; that of cytochrome b takes longer than 40 min. A non-photodissociable O2-containing compound of cytochrome a/a
3 was formed in whole cell suspensions at — 112 °C after photolysis of CO in the presence of 200 μm-O2. No O2-cytochrome b compound was observed under these conditions. Photochemical action spectra for the relief of CO-inhibited respiration, obtained at different O2 tensions, indicate cytochrome a/a
3 to be the major haemoprotein terminal oxidase; no evidence for a b-type cytochrome oxidase has been found.",1983-07-01,https://www.semanticscholar.org/paper/bbeb714e363843d4b7d0b525a199d7bfd6554e15,
1290,Search for Stopped Gluinos fromCollisions at,,2007-09-24,https://www.semanticscholar.org/paper/b83e516960c38bfbdd35ff1b9e5510017c1d330e,
3183,Evaluating expert‐based habitat suitability information of terrestrial mammals with GPS‐tracking data,"Abstract Aim Macroecological studies that require habitat suitability data for many species often derive this information from expert opinion. However, expert‐based information is inherently subjective and thus prone to errors. The increasing availability of GPS tracking data offers opportunities to evaluate and supplement expert‐based information with detailed empirical evidence. Here, we compared expert‐based habitat suitability information from the International Union for Conservation of Nature (IUCN) with habitat suitability information derived from GPS‐tracking data of 1,498 individuals from 49 mammal species. Location Worldwide. Time period 1998–2021. Major taxa studied Forty‐nine terrestrial mammal species. Methods Using GPS data, we estimated two measures of habitat suitability for each individual animal: proportional habitat use (proportion of GPS locations within a habitat type), and selection ratio (habitat use relative to its availability). For each individual we then evaluated whether the GPS‐based habitat suitability measures were in agreement with the IUCN data. To that end, we calculated the probability that the ranking of empirical habitat suitability measures was in agreement with IUCN's classification into suitable, marginal and unsuitable habitat types. Results IUCN habitat suitability data were in accordance with the GPS data (> 95% probability of agreement) for 33 out of 49 species based on proportional habitat use estimates and for 25 out of 49 species based on selection ratios. In addition, 37 and 34 species had a > 50% probability of agreement based on proportional habitat use and selection ratios, respectively. Main conclusions We show how GPS‐tracking data can be used to evaluate IUCN habitat suitability data. Our findings indicate that for the majority of species included in this study, it is appropriate to use IUCN habitat suitability data in macroecological studies. Furthermore, we show that GPS‐tracking data can be used to identify and prioritize species and habitat types for re‐evaluation of IUCN habitat suitability data.",2022-05-09,https://www.semanticscholar.org/paper/b22f1f9b93a5550a80c5120401918b65e504821a,Global Ecology and Biogeography
431,Incremental Recompilation of Knowledge,"Approximating a general formula from above and below by Horn formulas (its Horn envelope and Horn core, respectively) was proposed by Selman and Kautz (1991, 1996) as a form of ""knowledge compilation,"" supporting rapid approximate reasoning; on the negative side, this scheme is static in that it supports no updates, and has certain complexity drawbacks pointed out by Kavvadias, Papadimitriou and Sideri (1993). On the other hand, the many frameworks and schemes proposed in the literature for theory update and revision are plagued by serious complexity-theoretic impediments, even in the Horn case, as was pointed out by Eiter and Gottlob (1992), and is further demonstrated in the present paper. More fundamentally, these schemes are not inductive, in that they may lose in a single update any positive properties of the represented sets of formulas (small size, Horn structure, etc.). In this paper we propose a new scheme, incremental recompilation, which combines Horn approximation and model-based updates; this scheme is inductive and very efficient, free of the problems facing its constituents. A set of formulas is represented by an upper and lower Horn approximation. To update, we replace the upper Horn formula by the Horn envelope of its minimum-change update, and similarly the lower one by the Horn core of its update; the key fact which enables this scheme is that Horn envelopes and cores are easy to compute when the underlying formula is the result of a minimum-change update of a Horn formula by a clause. We conjecture that efficient algorithms are possible for more complex updates.",1997-12-31,https://www.semanticscholar.org/paper/3a12e22b1ca1fe84c475b4c2f8e52ce8582f2f21,Journal of Artificial Intelligence Research
3263,Sociality increases juvenile survival after a catastrophic event in the feral horse (Equus caballus),"In several social species, adult associations have been linked to individual fitness. Less is known about offspring associations and the mechanisms by which they may influence fitness. We investigate the effects of sociality on juvenile survival in feral horses (Equus caballus). We use foal degree (number of associates) and foal weight (number of interactions) to assess sociality’s importance to foal survival of a catastrophic event, the gathering and removal of 40% of the horse population. We found that 1) foal degree was a better predictor of foal survival than was foal weight; 2) following the gather, foals with access to at least one parent and some members of their natal groups were more likely to survive than were foals left with no such access; 3) foals with a higher degree both pre- and postgather were more likely to survive; 4) the influence of pregather degree appeared to be more pronounced among foals without access to parent(s) and natal group members; and 5) the influence of foal degree postgather was important to the survival of all foals, regardless of parental and natal group access. These results add to our understanding of the benefits afforded by juvenile social networks. Moreover, our study is unique in that foals were separated from parental support at a crucial point in development. We were therefore able to separate the effects of parental behavior on juvenile response, allowing us to more directly ask the question: do the behaviors exhibited by young mammals confer immediate and/or future benefits?",,https://www.semanticscholar.org/paper/ec499feacb4b41cb30c79763652f3aa7c59fd393,
594,A theorem in database concurrency control,"Consider two straight-line programs a and b, and let h be a set of sequences of steps of a and b, possibly interleaved, but each containing all steps of a and b in the right order. A necessary and sufficient condition is given for h to be realisable as the set of all sequences of steps which are legal under some insertion of lock-unlock steps between the steps of a and b. 13 references.",1982-10-01,https://www.semanticscholar.org/paper/8a76ccc9eb307722bf4dc977be450ed0016d4818,JACM
1548,Assessing the Effects of Friend-to-Friend Texting on Turnout in the 2020 U.S. Presidential Election,"Political campaigns in recent elections have started to embrace friend-to-friend organizing, in which volunteers organize and encourage their own close contacts to cast a ballot on Election Day. Unlike traditional “get out the vote” (GOTV) campaigns, which often rely on texts, calls, or visits from strangers, friend-to-friend organizing is premised on the notion that GOTV encouragements are especially effective when delivered by trusted messengers, like friends or family members.",,https://www.semanticscholar.org/paper/ba4d377d62e614d8a243b8113ce507501cab2e80,
3127,USENIX Association Proceedings of the First Symposium on Networked Systems Design and Implementation,"We have developed SWAP, a system that automatically detects process dependencies and accounts for such dependencies in scheduling. SWAP uses system call history to determine possible resource dependencies among processes in an automatic and fully transparent fashion. Because some dependencies cannot be precisely determined, SWAP associates confidence levels with dependency information that are dynamically adjusted using feedback from process blocking behavior. SWAP can schedule processes using this imprecise dependency information in a manner that is compatible with existing scheduling mechanisms and ensures that actual scheduling behavior corresponds to the desired scheduling policy in the presence of process dependencies. We have implemented SWAP in Linux and measured its effectiveness on microbenchmarks and real applications. Our results show that SWAP has low overhead, effectively solves the priority inversion problem and can provide substantial improvements in system performance in scheduling processes with dependencies.",,https://www.semanticscholar.org/paper/ef4123d33009283697b7043f88ae30af1942e901,
1709,A Mixed Membership Approach to the Assessment of Political Ideology from Survey Responses,"We employ mixed-membership (or grade-of-membership) techniques—of growing popularity in medical diagnostics, psychology, genetics, and machine learning—in order to identify prototypical profiles of survey respondents based on their answers to questions aimed at uncovering their basic orientations or ideological predispositions. In contrast with factor analytic techniques and IRT approaches, we treat both manifest and latent variables as categorical. A mixed membership model may be thought of as a generalization of latent class modeling, in which individuals act as members of more than one class. This notion is well-aligned with earlier theoretical work of Zaller, Feldman, Stimson, and others, who at times envision respondents to be internally complex, answering survey questions probabilistically according to what Zaller calls varying “considerations.” Reanalyzing data in this way, we develop new insights into the sorts of constraints that may structure mass belief systems.",2014-11-06,https://www.semanticscholar.org/paper/9f6c0954bd4fa5c8e81924e503d3a652249a3c20,
1291,Study of the Decay B0s→ D(*)sD(*)s,"We report a study of the decay B 0 s → D (*) s D (*) s using a data sample corresponding to 1.3 fb -1 of integrated luminosity collected by the DO experiment in 2002-2006 during run II of the Fermilab Tevatron collider. One D (*) s meson was partially reconstructed in the decay D s →Φμν, and the other D (*) s meson was identified using the decay D s → (Φπ where no attempt was made to distinguish D s and D* s ; states. For the branching fraction Br(B 0 s → D (*) s D (*) s ) we obtain a 90% C.L. range [0.002, 0.080] and central value 0. 039+ 0.019 -0.017 (stat) +0.016 0.015 (syst). This was subsequently used to make the most precise estimate of the width difference ΔΓ CP s in the B 0 s -B 0 s system: ΔΓ CP s /Γ s = 0.079+ 0.038 -0.035 (stat)+ 0.031 -0.030 (syst).",,https://www.semanticscholar.org/paper/b876905c32844860781c7fed08078ee8e4a8ab29,
2451,Eyewear Computing for Skill Augmentation and Task Guidance,,,https://www.semanticscholar.org/paper/1ee06bcd522766089a9110fc55fd5ce549767588,
2934,Clinically-relevant cell type cross-talk identified from a human lung tumor microenvironment interactome,"Tumors comprise a complex microenvironment of interacting malignant and stromal cell types. Much of our understanding of the tumor microenvironment comes from in vitro studies isolating the interactions between malignant cells and a single stromal cell type, often along a single pathway. To develop a deeper understanding of the interactions between cells within human lung tumors we performed RNA-seq profiling of flow-sorted malignant cells, endothelial cells, immune cells, fibroblasts, and bulk cells from freshly resected human primary non-small-cell lung tumors. We mapped the cell-specific differential expression of prognostically-associated secreted factors and cell surface genes, and computationally reconstructed cross-talk between these cell types to generate a novel resource we call the Lung Tumor Microenvironment Interactome (LTMI). Using this resource, we identified and validated a prognostically unfavorable influence of Gremlin-1 production by fibroblasts on proliferation of malignant lung adenocarcinoma cells. We also found a prognostically favorable association between infiltration of mast cells and less aggressive tumor cell behavior. These results illustrate the utility of the LTMI as a resource for generating hypotheses concerning tumor-microenvironment interactions that may have prognostic and therapeutic relevance. Summary RNA-seq profiling of sorted populations from primary lung cancer samples identifies prognostically relevant cross-talk between cell types in the tumor microenvironment.",2019-05-30,https://www.semanticscholar.org/paper/5d03bd170267fc0623335423822701667f8ad853,bioRxiv
1475,Charged hadron production at high X in E+ E- annihilation at S**(1/2) = 29-GEV,,,https://www.semanticscholar.org/paper/425c94cdfb55a10442cb1583ec415f8e3b35b1fe,
2815,Galectin-3 promotes HIV-1 budding through association with Alix and Gag-p6 (170.25),"
 Galectin-3 (Gal3), a β-galactoside-binding lectin, has been reported to regulate the functions of a number of immune cell types. We demonstrated that Gal3 is translocated to the immunological synapse in T cells upon T cell receptors engagement and associated with ALG-2-interacting protein X (Alix). Alix is known to coordinate with endosomal sorting complex required for transport (ESCRT) to promote HIV-1 virion release through binding to the HIV-1 Gag-P6 protein. We hypothesized that Gal3 plays a role in HIV-1 viral budding. Co-transfection of Gal3 and HIV-1 plasmids in HEK293T cells indicate that endogenous Gal3 facilitates HIV-1 budding. This effect was inhibited by knocking down Gal3 expression by shRNA. Immunoblotting of trypsin-treated virions and immuno-electron microscopy indicate that Gal3 is mainly located inside the HIV-1 virions. Immunofluorescent staining and coimmunoprecipitation (Co-IP) suggest that Gal3, Alix, and Gag-p6 are colocalized in HIV-1-infected cells. Notably, Gal3 expression was found to promote the association between Alix and Gag-p6 as demonstrated by Co-IP. Co-transfection of Gal3 and HIV-1 plasmids in Alix knocked-down cells indicate that promotion of HIV-1 budding by Gal3 is mediated through Alix. Finally, knocking down Gal3 expression in primary CD4+ T cells resulted in a significant decrease of HIV-1 titer. Our results indicate that endogenous Gal3 facilitates the HIV-1 virus budding through stabilizing the association between Alix and Gag-p6.",2012-05-01,https://www.semanticscholar.org/paper/f75e32bf6a91fac67b3e4f4f016006c69df579c2,Journal of Immunology
1892,MODELLING AND DECISION SUPPORT SYSTEM FOR INTELLIGENT MANUFACTURING: AN EMPIRICAL STUDY FOR FEEDFORWARD-FEEDBACK LEARNING-BASED RUN-TO-RUN CONTROLLER FOR SEMICONDUCTOR DRY-ETCHING PROCESS,"This study aims to address the formation of various decision models based on modeling, analytics, and optimization techniques for intelligent manufacturing and smart production. Indeed, smart manufacturing deals with flexible decisions for addressing the dynamic, competitive, and global supply chains and production networks by employing advanced information technology, intelligent computerized control, digital decision technologies, and high levels of adaptability. While research in the broad area of smart manufacturing and its challenges in decision making encompasses a wide range of topics and methodologies, this study provides a good snapshot of current quantitative modeling approaches, issues, and trends. The validity of the proposed framework is estimated with a number of illustrations. This study concludes with discussion of future research directions.",2019-01-08,https://www.semanticscholar.org/paper/361aa30292f096bd027bb7e32d455d26742dab50,
1190,"Erratum to: ""Search for particles decaying into a Z boson and a photon in p over(p, ̄) collisions at sqrt(s) = 1.96 TeV"" [Phys. Lett. B 641 (2006) 415] (DOI:10.1016/j.physletb.2006.08.079)",,2009-01-05,https://www.semanticscholar.org/paper/e8a35cbee4e47c77aba5fafa2cd000e048feb721,
2209,Effects of IL-6 and IL-6 blockade on neutrophil function in vitro and in vivo.,"OBJECTIVES
Reports on the regulation of neutrophil function by IL-6 are often conflicting. Therapeutic inhibition of IL-6 in RA is associated with occasional neutropenia, but the mechanisms underlying this observation are poorly understood. This study investigated interactions between IL-6, the anti-IL-6 receptor agent tocilizumab (TCZ) and neutrophils in vitro and in vivo.


METHODS
Neutrophils were isolated from healthy controls and incubated in vitro with pharmacologically relevant concentrations of IL-6 or TCZ. Neutrophils were also isolated from RA patients, including a cohort following TCZ therapy. Apoptosis was measured by annexin V/propidium iodide (PI) flow cytometry; phagocytosis was measured by incubating apoptotic neutrophils with THP-1-derived macrophages; chemotaxis was measured using cell migration through hanging-cell inserts towards IL-8 and cell surface proteins, including adhesion molecules CD11b (αMβ2 integrin) and CD62L (L-selectin) were measured by flow cytometry.


RESULTS
IL-6 (10-100 ng/ml) did not affect the rate of neutrophil apoptosis, priming of the respiratory burst or adhesion molecule expression nor act as a neutrophil chemoattractant. However, IL-6 enhanced signal transducer and activator of transcription 3 (STAT3) activation and neutrophil migration towards IL-8. TCZ in vitro did not induce apoptosis or phagocytosis of neutrophils, nor did it have a significant effect upon apoptosis or cell surface molecule expression. Neutrophil functions in ex vivo neutrophils from RA patients receiving TCZ treatment were unaffected.


CONCLUSION
Therapeutic blockade of IL-6, while inducing a transient neutropenia, does not directly affect neutrophil functions associated with host defence. TCZ-associated neutropenia cannot be explained by direct induction of apoptosis by TCZ, induction of apoptosis following depletion of IL-6, nor increased phagocytosis of neutrophils.",2014-07-01,https://www.semanticscholar.org/paper/84e3e1d49b6ff5a2137763a28c65406149db5709,Rheumatology
3507,Improved Length Bounds for the Shortest Superstring Problem (Extended Abstract),,1995-08-16,https://www.semanticscholar.org/paper/08471e3f0bb3ac33269388440ccde34af6171c69,Workshop on Algorithms and Data Structures
1501,Search for pair produ ction o f first-generation leptoquarks in p p collisions at ^ / s = 1 . 96 TeV,,,https://www.semanticscholar.org/paper/623e334c7a70c48729fbd3a0966715618a150849,
1364,A Search for Anomalous Heavy-Flavor Quark Production in Association with W Bosons,"We present a search for anomalous production of heavy-flavor quark jets in association with a W boson at the Fermilab Tevatron ppbar Collider. This search is conducted through an examination of the exclusive jet spectrum of W+jets final states in which the heavy-flavor quark content has been enhanced by requiring at least one tagged jet in an event. Jets are tagged by the combined use of two algorithms, one based on semileptonic decays of b/c hadrons, and the other on their lifetimes. We compare data in e+jets (164 pb-1) and mu+jets (145 pb-1) channels, collected with the D0 detector at sqrt{s}=1.96 TeV, to expectations from the standard model, and set upper limits on anomalous production of such events.",2004-11-28,https://www.semanticscholar.org/paper/31b8c836d2e230be6508694dc624a21f3d3b07ad,
1469,Observation of scaling of the photon structure function F2 gamma at low Q2.,"Disclaimer/Complaints regulations If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. In case of a legitimate complaint, the Library will make the material inaccessible and/or remove it from the website. Please Ask the Library: http://uba.uva.nl/en/contact, or a letter to: Library of the University of Amsterdam, Secretariat, Singel 425, 1012 WP Amsterdam, The Netherlands. You will be contacted as soon as possible.",1987-01-12,https://www.semanticscholar.org/paper/00bd99b98bb2656feda7e462c31cb7b6eeb9de3b,Physical Review Letters
470,Default Theories that Always Have Extensions,,1994-09-01,https://www.semanticscholar.org/paper/7fc9e8ffe34853602bf53fe8db81fb39cbec32da,Artificial Intelligence
1169,Search for the standard model Higgs boson in tau final states.,"We present a search for the standard model Higgs boson using hadronically decaying tau leptons, in 1 fb(-1) of data collected with the D0 detector at the Fermilab Tevatron pp collider. We select two final states: tau+/- plus missing transverse energy and b jets, and tau+ tau- plus jets. These final states are sensitive to a combination of associated W/Z boson plus Higgs boson, vector boson fusion, and gluon-gluon fusion production processes. The observed ratio of the combined limit on the Higgs production cross section at the 95% C.L. to the standard model expectation is 29 for a Higgs boson mass of 115 GeV.",2009-03-27,https://www.semanticscholar.org/paper/924f20f4176a4dd1946950a1d410f842e747e754,Physical Review Letters
3426,Online Stochastic Ad Allocation: Efficiency and Fairness,,2010-01-29,https://www.semanticscholar.org/paper/ec3c72bf4bd5d690cf3015b92b27faeaa55bbfd9,arXiv.org
276,A Note on Strictly Competitive Games,,2009-12-09,https://www.semanticscholar.org/paper/840f716e5b5de23dd14f5a1c1ee8914dec36500d,Workshop on Internet and Network Economics
105,GlOSS: text-source discovery over the Internet,"The dramatic growth of the Internet has created a new problem for users: location of the relevant sources of documents. This article presents a framework for (and experimentally analyzes a solution to) this problem, which we call the text-source discovery problem. Our approach consists of two phases. First, each text source exports its contents to a centralized service. Second, users present queries to the service, which returns an ordered list of promising text sources. This article describes GlOSS, Glossary of Servers Server, with two versions: bGlOSS, which provides a Boolean query retrieval model, and vGlOSS, which provides a vector-space retrieval model. We also present hGlOSS, which provides a decentralized version of the system. We extensively describe the methodology for measuring the retrieval effectiveness of these systems and provide experimental evidence, based on actual data, that all three systems are highly effective in determining promising text sources for a given query.",1999-06-01,https://www.semanticscholar.org/paper/8cd0e93f0c4a79a6a4cd6af1e89d3ffa6123d30c,TODS
495,Decision-Making with Incomplete Information,,1991-12-16,https://www.semanticscholar.org/paper/2897cedb05bf8b768d9a0ba03ac5486323145a11,International Symposium on Algorithms
672,Meta-Learning to Cluster,"Clustering is one of the most fundamental and wide-spread techniques in exploratory data analysis. Yet, the basic approach to clustering has not really changed: a practitioner hand-picks a task-specific clustering loss to optimize and fit the given data to reveal the underlying cluster structure. Some types of losses---such as k-means, or its non-linear version: kernelized k-means (centroid based), and DBSCAN (density based)---are popular choices due to their good empirical performance on a range of applications. Although every so often the clustering output using these standard losses fails to reveal the underlying structure, and the practitioner has to custom-design their own variation. In this work we take an intrinsically different approach to clustering: rather than fitting a dataset to a specific clustering loss, we train a recurrent model that learns how to cluster. The model uses as training pairs examples of datasets (as input) and its corresponding cluster identities (as output). By providing multiple types of training datasets as inputs, our model has the ability to generalize well on unseen datasets (new clustering tasks). Our experiments reveal that by training on simple synthetically generated datasets or on existing real datasets, we can achieve better clustering performance on unseen real-world datasets when compared with standard benchmark clustering techniques. Our meta clustering model works well even for small datasets where the usual deep learning models tend to perform worse.",2019-10-30,https://www.semanticscholar.org/paper/77868d73295d92fa21d64b424ff4359efa0e68ba,arXiv.org
1859,Modeling annotated data,"We consider the problem of modeling annotated data---data with multiple types where the instance of one type (such as a caption) serves as a description of the other type (such as an image). We describe three hierarchical probabilistic mixture models which aim to describe such data, culminating in correspondence latent Dirichlet allocation, a latent variable model that is effective at modeling the joint distribution of both types and the conditional distribution of the annotation given the primary type. We conduct experiments on the Corel database of images and captions, assessing performance in terms of held-out likelihood, automatic annotation, and text-based image retrieval.",2003-07-28,https://www.semanticscholar.org/paper/473f4b7f8ae2b03dda2593f54b316ff7d55db26b,Annual International ACM SIGIR Conference on Research and Development in Information Retrieval
3616,Wrapping C++ Member Function Calls,"This paper presents a simple, general, and efficient solution to the old problem of ‘‘wrapping’’ calls to an object in pairs of prefix and suffix code. The solution is also non-intrusive, applies to existing classes, allows the use of several prefix/suffix pairs, and can be implemented in 15 simple lines of Standard C++. A robust version of the wrapper is also presented. The claim of efficiency is backed by measurement. The paper is organized around a series of examples evolving the basic idea into a final robust template class.",,https://www.semanticscholar.org/paper/5b7e2b8fd75fabaae99d554a5f99a729399be4b1,
3312,Social Networks in Wild Asses: Comparing Patterns and Processes among Populations,"Asiatic wild asses inhabit some of the most arid environments in the world. All live in fissionfusion societies, but demography varies and the deserts in which they live often differ in subtle ways. Characterizing details of social structure of wild ass populations has been a challenge and has made it difficult to determine causes and consequences of any differences that might exist. We use network theory to compare the social structures of two populations of Asiatic asses/onagers inhabiting the Negev desert, Israel and khur of the Little Rann of Kuch, India and show that populations differ in important structural ways that represent adaptive responses to variations in ecological demographic and phenotypic circumstances. Our analyses show that onagers inhabiting more variable environments then khur also live in larger, more cohesive groups than khur. Presumably networks with this structure facilitate the spread of information and foster cooperation. We also show that demography matters since social fragmentation increases as populations grow. Increases in the number of components in populations, reductions in the number of associates and diminished cliquishness within components, appear to be adaptive responses to integrating increasing numbers of individuals into social networks. We also find some support for the idea that social connectedness varies with phenotype. In our larger populations, non-lactating females who are most challenged in finding sparse feeding sites, are more selective than lactating females in their choice of strong associates. Presumably networks with this structure enhance foraging success by increasing information flow among like-minded individuals. As our study demonstrates, network analysis facilitates testing predictions about the cause of social structure and its impact on transmission processes.",,https://www.semanticscholar.org/paper/ef54cd3e1d4b2d9c103e082fb8e0f2b9552db5b5,
223,The Complexity of Computing Equilibria,,,https://www.semanticscholar.org/paper/f5e3536c2b66a27be839e551ece78f4910fbf18b,
749,"Quasi-Birth-Death Processes, Tree-Like QBDs, Probabilistic 1-Counter Automata, and Pushdown Systems","We begin by observing that (discrete-time) Quasi-Birth-Death Processes (QBDs) are equivalent, in a precise sense, to (discrete-time) probabilistic 1-Counter Automata (p1CAs), and both Tree-Like QBDs (TL-QBDs) and Tree-Structured QBDs (TS-QBDs) are equivalent to both probabilistic Pushdown Systems (pPDSs) and Recursive Markov Chains (RMCs). We then proceed to exploit these connections to obtain a number of new algorithmic upper and lower bounds for central computational problems about these models. Our main result is this: for an arbitrary QBD (even a null-recurrent one), we can approximate its termination probabilities (i.e., its G matrix) to within i bits of precision (i.e., within additive error 1/2i), in time polynomial in both the encoding size of the QBD and in i, in the unit-cost rational arithmetic RAM model of computation. Specifically, we show that a decomposed Newton's method can be used to achieve this. We emphasize that this bound is very different from the well-known ""linear/quadratic convergence"" of numerical analysis, known for QBDs and TL-QBDs, which typically gives no constructive bound in terms of the encoding size of the system being solved. In fact, we observe (based on recent results for pPDSs) that for the more general TL-QBDs this bound fails badly. Specifically, in the worst case Newton's method ""converges linearly"" to the termination probabilities for TL-QBDs, but requires exponentially many iterations in the encoding size of the TL-QBD to approximate these probabilities within any non-trivial constant error c < 1. Our upper bound proof for QBDs combines several ingredients: a detailed analysis of the structure of 1-counter automata, an iterative application of a classic condition number bound for errors in linear systems,and a very recent constructive bound on the performance of Newton's method for monotone systems of polynomial equations.",2008-09-14,https://www.semanticscholar.org/paper/039d956bd8b95138cece5dc0d4d1f84a9f1336bf,2008 Fifth International Conference on Quantitative Evaluation of Systems
619,On linear characterizations of combinatorial optimization problems,We show that there can be no computationally tractable description by linear inequalities of the polyhedron associated with any NP-complete combinatorial optimization problem unless NP = co-NP -- a very unlikely event. We also apply the ellipsoid method for linear programming to show that a combinatorial optimization problem is solvable in polynomial time if and only if it admits a small generator of violated inequalities.,1980-10-13,https://www.semanticscholar.org/paper/da27773e409b3a42676019ac33696342778744a5,21st Annual Symposium on Foundations of Computer Science (sfcs 1980)
511,The Geometry of Grasping,"A form closure (or complete restraint) of a solid object is a finite set of wrenches (force-moment combinations) applied on the object, with the property that any other wrench acting on the object can be balanced by a positive combination of the original ones. Intuitively, form closure is a way of defining the notion of a ""firm grip"" of the object (when friction is not taken into account). It has been pointed out by Reuleaux (1875) and Somoff (1897), and more recently by Lakshmin arayana (1978), that the form closure of a two-dimensional object requires at least four wrenches, and that form closure of a three-dimensional object requires at least seven wrenches. It was also conjectured that these numbers can be achieved by wrenches realizable as forces normal to the surface of the object (such wrenches are called fingers). In this paper we prove this conjecture. In particular we show that form closure of any two-dimensional bounded object with piecewise smooth boundary (except a circle) can be achieved by four fingers. For three dimensions, we prove that form closure of any bounded object with piecewise smooth boundary can be achieved with 12 fingers if and only if the object does not have a rotational symmetry (in which case, of course, form closure is not achievable, since no moment along the axis of symmetry can be opposed). We also show that, under very general conditions, form closure of three-dimensional objects without rotational symmetries can be achieved with seven fingers. Finally, we show that when Coulomb friction is taken into account, under the most relaxed assumptions three fingers are necessary and sufficient in two dimensions, and four fingers in three dimensions.",1990-01-02,https://www.semanticscholar.org/paper/3a1815d82f04c211f997b05890d18b7482f1432d,Int. J. Robotics Res.
3057,Apiary: Easy-to-Use Desktop Application Fault Containment on Commodity Operating Systems,"Desktop computers are often compromised by the interaction of untrusted data and buggy software. To address this problem, we present Apiary, a system that transparently contains application faults while retaining the usage metaphors of a traditional desktop environment. Apiary accomplishes this with three key mechanisms. It isolates applications in containers that integrate in a controlled manner at the display and file system. It introduces ephemeral containers that are quickly instantiated for single application execution, to prevent any exploit that occurs from persisting and to protect user privacy. It introduces the Virtual Layered File System to make instantiating containers fast and space efficient, and to make managing many containers no more complex than a single traditional desktop. We have implemented Apiary on Linux without any application or operating system kernel changes. Our results with real applications, known exploits, and a 24-person user study show that Apiary has modest performance overhead, is effective in limiting the damage from real vulnerabilities, and is as easy for users to use as a traditional desktop.",2010-06-23,https://www.semanticscholar.org/paper/5d39ee861cfdb90a61cc4d1d0890ff7043bca39f,USENIX Annual Technical Conference
2037,Foreword,,,https://www.semanticscholar.org/paper/da89180216e106fc747718a9792c7396306185b1,Computers & industrial engineering
1433,The BaBar Physics Book: Physics at an Asymmetric B Factory,"Results of a year-long workshop devoted to a review of the physics opportunities of the BABAR experiment at the PEP-II B Factory, at the Stanford Linear Accelerator Center laboratory are presented.",1998-10-01,https://www.semanticscholar.org/paper/9afb8b80f7c06ec280eba26c35c214a52defa7ee,
2301,The diadenosine polyphosphates Ap3A and Ap4A and adenosine triphosphate interact with granulocyte-macrophage colony-stimulating factor to delay neutrophil apoptosis: implications for neutrophil: platelet interactions during inflammation.,"Incubation of neutrophils with cytokines such as granulocyte macrophage colony-stimulating factor (GM-CSF) delays their loss of function and changes in cellular morphology that are characteristic of apoptosis. Adenosine triphosphate (ATP) and the diadenosine polyphosphates Ap4A and AP3A were almost as effective as GM-CSF in delaying neutrophil apoptosis. The nucleotides could thus preserve cellular morphology, protect against chromatin fragmentation, and preserve functions such as NADPH oxidase activity and expression of CD16. Moreover, addition of ATP, AP3A and AP4A together with GM-CSF resulted in more pronounced protection from apoptosis than was observed during incubation with either the cytokine or the nucleotides alone. Because ATP, Ap3A, and AP4A may be secreted from activated platelets, these observations suggest that platelet-derived products, perhaps acting in combination with endothelial-derived or immune cell-derived cytokines, can regulate neutrophil function during certain types of inflammation.",1996-04-15,https://www.semanticscholar.org/paper/1c8c9e9966a94daf09743551405d8bed90a53315,Blood
3042,Session details: Invited talk,,2012-03-03,https://www.semanticscholar.org/paper/a588a9ff9d7c43049dcfb9dd90a42ac3ab8a510d,Proceedings of the 8th ACM SIGPLAN/SIGOPS conference on Virtual Execution Environments
612,Book Collection 1981 : Elements of the theory of computation / Harry R.,,,https://www.semanticscholar.org/paper/dcde6561f61edb5dda7dcfb2eb02806baf68cbd9,
261,"The Complexity of the Homotopy Method, Equilibrium Selection, and Lemke-Howson Solutions","We show that the widely used homotopy method for solving fix point problems, as well as the Harsanyi-Selten equilibrium selection process for games, are PSPACE-complete to implement. Extending our result for the Harsanyi-Selten process, we show that several other homotopy-based algorithms for finding equilibria of games are also PSPACE-complete to implement. A further application of our techniques yields the result that it is PSPACE-complete to compute any of the equilibria that could be found via the classical Lemke-How son algorithm, a complexity-theoretic strengthening of the result in [24]. These results show that our techniques can be widely applied and suggest that the PSPACE-completeness of implementing homotopy methods is a general principle.",2010-06-28,https://www.semanticscholar.org/paper/057664d4849ad4483d3c1c18d72a7e783fe437a3,IEEE Annual Symposium on Foundations of Computer Science
1296,Measurement of theproduction cross section incollisions atusing kinematic characteristics ofevents,,2007-11-27,https://www.semanticscholar.org/paper/e05088697aa2ab5f6348ffaf8f3c2ff3330cc47d,
492,Competitive distributed decision-making,,1992-09-07,https://www.semanticscholar.org/paper/9929c0ed18de4670216ab3743341f36e7fe85b01,Algorithmica
2720,Supporting interactivity in automated 3D illustrations,"An interactive intent-based illustration is a picture designed to satisfy an input communicative intent, and which can be interactively redesigned as it is viewed. We describe how the architecture of IBIS (Intent-Based Illustration System) automates the design of 3D interactive intent-based illustrations. The types of interaction that IBIS supports include changes in the world, as objects move and otherwise change state; changes in the communicative intent, as modified by the user or other programs; queries, in which the user can request additional information; and selfeva.luation, in which other programs can request IBIS to analyze various properties of the illustration, such as how well an illustration’s communicative intent is satisfied or which graphical techniques it uses. We show how IBIS’s design process and rule base make possible these forms of interaction.",1993-02-01,https://www.semanticscholar.org/paper/ae76c05e80e2b5f7bdbfdce369bd6ec58150b1d8,International Conference on Intelligent User Interfaces
1768,Predicting Legislative Roll Calls from Text,"We develop several predictive models linking legislative sentiment to legislative text. Our models, which draw on ideas from ideal point estimation and topic models, predict voting patterns based on the contents of bills and infer the political leanings of legislators. With supervised topics, we provide an exploratory window into how the language of the law is correlated with political support. We also derive approximate posterior inference algorithms based on variational methods. Across 12 years of legislative data, we predict specific voting patterns with high accuracy.",2011-06-28,https://www.semanticscholar.org/paper/62e14dec73970514a5e3f81b059d63b34e9ad37c,International Conference on Machine Learning
3758,Cross-Modal Scene Networks,"People can recognize scenes across many different modalities beyond natural images. In this paper, we investigate how to learn cross-modal scene representations that transfer across modalities. To study this problem, we introduce a new cross-modal scene dataset. While convolutional neural networks can categorize scenes well, they also learn an intermediate representation not aligned across modalities, which is undesirable for cross-modal transfer applications. We present methods to regularize cross-modal convolutional neural networks so that they have a shared representation that is agnostic of the modality. Our experiments suggest that our scene representation can help transfer representations across modalities for retrieval. Moreover, our visualizations suggest that units emerge in the shared representation that tend to activate on consistent concepts independently of the modality.",2016-10-27,https://www.semanticscholar.org/paper/a4162e328aacba376ea95a7654378423e504ca3d,IEEE Transactions on Pattern Analysis and Machine Intelligence
2329,Biochemistry and Physiology of the Neutrophil: Preface,,,https://www.semanticscholar.org/paper/9b3ff4b85e43f3d099ecdde2e13b7dddad5063b8,
2083,Magnetic resonance microsystems for life science applications,"Nuclear magnetic (MR) resonance spectroscopy and imaging technique are powerful methods available for determining molecular structures and non-invasive 3D imaging. In the effort of developing a nanoMRI microsystem, the authors have designed, fabricated, assembled and did preliminary characterization of the nanoMRI probe. A multilayer high aspect ratio metal process has been developed for this project. NanoMRI probes are designed through multi-physics finite element 3D analysis, integrated using the high aspect ratio process, assembled, and the RF coils are matched and tuned to a 500MHz system. Due to the large magnetic field gradients and fast switching gradient coils, the high mass-sensitivity and additional orthogonal RF signal channels, special MR pulse sequencies (Lauterbur et al., 1992) can be developed for imaging and molecular structural analysis.",2005-06-05,https://www.semanticscholar.org/paper/168c40ac4697ed55820d1047a27ca8f1478d72e7,"The 13th International Conference on Solid-State Sensors, Actuators and Microsystems, 2005. Digest of Technical Papers. TRANSDUCERS '05."
74,Navigation- vs. index-based XML multi-query processing,"XML path queries form the basis of complex filtering of XML data. Most current XML path query processing techniques can be divided in two groups. Navigation-based algorithms compute results by analyzing an input document one tag at a time. In contrast, index-based algorithms take advantage of precomputed numbering schemes over the input XML document. We introduce a new index-based technique, index-filter, to answer multiple XML path queries. Index-filter uses indexes built over the document tags to avoid processing large portions of the input document that are guaranteed not to be part of any match. We analyze index-filter and compare it against Y-filter, a state-of-the-art navigation-based technique. We show that both techniques have their advantages, and we discuss the scenarios under which each technique is superior to the other one. In particular, we show that while most XML path query processing techniques work off SAX events, in some cases it pays off to preprocess the input document, augmenting it with auxiliary information that can be used to evaluate the queries faster. We present experimental results over real and synthetic XML documents that validate our claims.",2003-03-05,https://www.semanticscholar.org/paper/f9df398e5e8e173111a27a12da5ee72f1722ad11,Proceedings / International Conference on Data Engineering
3111,"FlowPuter: A Cluster Architecture Unifying Switch, Server and Storage Processing","We present a novel cluster architecture that unifies switch, server and storage processing to achieve a level of price-performance and simplicity of application development not achievable with current architectures. Our architecture takes advantage of the increasing disparity between storage capacity, network switching on the one hand, and processing power of modern processors and architectures on the other. We propose the use of Network Processors (NPUs), which can apply simple classify/act/forward operations on data packets at wire speeds, to split processing of operations such as complex database queries across a network. We quantify the theoretical benefits of such an architecture over traditional server-cluster approaches using warehouse database queries as a motivating application. We also discuss the challenges such an architecture presents to programming language design and implementation, performance analysis, and security.",,https://www.semanticscholar.org/paper/c9791a4fa39452810f67e84fed3727f7ac3cd13f,
1120,Search for the Standard Model Higgs Boson in the ZH ! b b Channel in 5 : 2 fb 1 of p p Collisions at ffiffi s p 1⁄4 1 : 96 TeV,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, G.D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G.A. Alves, L. S. Ancu, M. Aoki, Y. Arnoud, M. Arov, A. Askew, B. Åsman, O. Atramentov, C. Avila, J. BackusMayes, F. Badaud, L. Bagby, B. Baldin, D.V. Bandurin, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, G. Blazey, S. Blessing, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, E. E. Boos, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, X. B. Bu, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, T. H. Burnett, C. P. Buszello, P. Calfayan, B. Calpas, S. Calvet, E. Camacho-Pérez, J. Cammin, M.A. Carrasco-Lizarraga, E. Carrera, B. C. K. Casey, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K.M. Chan, A. Chandra, E. Cheu, S. Chevalier-Théry, D. K. Cho, S.W. Cho, S. Choi, B. Choudhary, T. Christoudias, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, D. Cutts, M. Ćwiok, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, K. DeVaughan, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, T. Dorland, A. Dubey, L. V. Dudko, L. Duflot, D. Duggan, A. Duperrin, S. Dutt, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V.D. Elvira, Y. Enari, S. Eno, H. Evans, A. Evdokimov, V.N. Evdokimov, G. Facini, A.V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, S. Fuess, T. Gadfort, C. F. Galea, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, W. Geng, D. Gerbaudo, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, G. Golovanov, B. Gómez, A. Goussiou, P. D. Grannis, S. Greder, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, P. Haefner, S. Hagopian, J. Haley, I. Hall, L. Han, K. Harder, A. Harel, J.M. Hauptman, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, A. P. Heinson, U. Heintz, C. Hensel, I. Heredia-De La Cruz, K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, T. Hoang, J. D. Hobbs, B. Hoeneisen, M. Hohlfeld, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, N. Huske, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, D. Jamin, R. Jesik, K. Johns, C. Johnson, M. Johnson, D. Johnston, A. Jonckheere, P. Jonsson, A. Juste,49,x E. Kajfasz, D. Karmanov, P. A. Kasper, I. Katsanos, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y. N. Kharzheev, D. Khatidze, M.H. Kirby, M. Kirsch, J.M. Kohli, A.V. Kozelov, J. Kraus, A. Kumar, A. Kupco, T. Kurča, V.A. Kuzmin, J. Kvita, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, H. S. Lee, W.M. Lee, A. Leflat, J. Lellouch, L. Li, Q. Z. Li, S.M. Lietti, J. K. Lim, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna-Garcia,34,k A.L. Lyon, A.K. A. Maciel, D. Mackin, P. Mättig, R. Magaña-Villalba, P. K. Mal, S. Malik, V. L. Malyshev, Y. Maravin, J. Martı́nez-Ortega, R. McCarthy, C. L. McGivern, M.M. Meijer, A. Melnitchouk, L. Mendoza, D. Menezes, P. G. Mercadante, M. Merkin, A. Meyer, J. Meyer, R. K. Mommsen, N.K. Mondal, T. Moulik, G. S. Muanza, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, R. Nayyar, H. A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, G. Obrant, C. Ochando, D. Onoprienko, J. Orduna, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, M. Padilla, P. Padley, M. Pangilinan, N. Parashar, V. Parihar, S.-J. Park, S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma,34,{ V.M. Podstavkov, M.-E. Pol, P. Polozov, A.V. Popov, M. Prewitt, D. Price, S. Protopopescu, J. Qian, A. Quadt, B. Quinn, M. S. Rangel, K. Ranjan, P. N. Ratoff, I. Razumov, P. Renkel, P. Rich, M. Rijssenbeek, I. Ripp-Baudot, F. Rizatdinova, S. Robinson, M. Rominsky, C. Royon, P. Rubinov, R. Ruchti, G. Safronov, G. Sajot, A. Sánchez-Hernández, M. P. Sanders, B. Sanghi, G. Savage, L. Sawyer, T. Scanlon, D. Schaile, R.D. Schamberger, Y. Scheglov, H. Schellman, T. Schliephake, S. Schlobohm, C. Schwanenberger, R. Schwienhorst, J. Sekaric, H. Severini, E. Shabalina, V. Shary, A. A. Shchukin, R.K. Shivpuri, V. Simak, V. Sirotenko, P. Skubic, P. Slattery, PRL 104, 071801 (2010) P HY S I CA L R EV I EW LE T T E R S week ending 19 FEBRUARY 2010",,https://www.semanticscholar.org/paper/0c2721974b51a1a4938ba451742860065b9305b1,
1779,"Context, learning, and extinction.","A. Redish et al. (2007) proposed a reinforcement learning model of context-dependent learning and extinction in conditioning experiments, using the idea of ""state classification"" to categorize new observations into states. In the current article, the authors propose an interpretation of this idea in terms of normative statistical inference. They focus on renewal and latent inhibition, 2 conditioning paradigms in which contextual manipulations have been studied extensively, and show that online Bayesian inference within a model that assumes an unbounded number of latent causes can characterize a diverse set of behavioral results from such manipulations, some of which pose problems for the model of Redish et al. Moreover, in both paradigms, context dependence is absent in younger animals, or if hippocampal lesions are made prior to training. The authors suggest an explanation in terms of a restricted capacity to infer new causes.",,https://www.semanticscholar.org/paper/097ade72f43a979e652ed5a6aa801f5e8dfb9066,Psychology Review
2337,Receptor expression insynovial fluid neutrophils frompatients withrheumatoid arthritis,"Objectives-The aimofthisstudywasto determine ifneutrophils isolated fromthe bloodandsynovial fluid ofpatients with rheumatoid arthritis had patternsof receptor expression resembling thoseof bloodneutrophils fromcontrols which hadbeenactivated andprimedinvitro. Methods-Fluorescence activated cell sorting was usedtomeasurereceptor expression inpaired bloodandsynovial fluidneutrophils frompatients andin control neutrophils exposedtophorbol myristateacetateand granulocytemacrophage colony stimulating factor. Results-There was no significant difference inthepatterns ofreceptor expression in bloodneutrophils from patients and healthycontrols, but neutrophils inthesynovial fluid hadbeen primedandactivated withinthejoint. About50%ofrheumatoid synovial fluid neutrophil samplesexpressed FcyRI,a highaffinity receptor formonomericIgG, whichisonlyexpressed inneutrophils exposed tocytokines. Conclusions-Synovial fluidneutrophils are activated and primedwithinthe inflamed joint andhencetheirability to respondto activating factors suchas immunecomplexes will bemodulated. As theexpression ofFcyRIrequires active biosynthesis, thiswork indicates that selective geneactivation occurswhen neutrophils arerecruited intorheumatoid joints.",,https://www.semanticscholar.org/paper/ae4ae56889a5ad05fb639cba34c9f876aa107085,
522,On the Convergence of Query Evaluation,,1989-04-01,https://www.semanticscholar.org/paper/04ca8ad0b0fdc81bc11c9fea2c6d9247ed1b6c21,Journal of computer and system sciences (Print)
960,A Case Report of Hemodialysis Graft-induced Increased Intraocular Pressure.,"Dear Editor, Hemodialysis is performed in the patients with end-stage renal disease, and arteriovenous fistula (AVF) is regarded as the best type of hemodialysis access [1]. However, various complications, such as thrombosis, stenosis and infection have been reported [2]. In the field of ophthalmology, rare cases of increased intraocular pressure (IIOP) related to hemodialytic condition have been reported [2]. In this study, we report the case of a patient who presented with IIOP, severe headache, and prolonged choroidal detachment due to abnormal venous drainage. A 50-year-old Korean man, with end-stage renal disease and in a hemodialysis program for 8 years, presented with IIOP in his left eye. His right eye was blinded due to a history of surgery for retinal detachment, and he was undergoing treatment for chronic open-angle glaucoma in his left eye. Visual acuity was 20 / 25, IOP was 18 mmHg, and spherical equivalent was -0.375 diopter. Ocular examination revealed regular pseudophakia, axial length of 23.13 mm and central corneal thickness of 507 μm. Fundus exam showed a pale optic disc and a diffuse superior thinning of the retinal nerve fiber layer. He underwent trabeculectomy due to IIOP even with the maximum tolerated medical therapy. After surgery, the IOP decreased to 9 mmHg, but choroidal detachment was developed. Nine days after surgery, he presented with severe headache and ocular pain. The IOP increased to 25 mmHg, and functional filtration bleb formed by trabeculectomy was not well elevated. In addition, although the IOP was elevated, no significant improvement in choroidal detachment was observed (Fig. 1A, 1B). Afterwards, the status of choroidal detachment tended to wax and wane, although the IOP was maintained relatively high. He underwent brain work-up, and result showed f low signs on left internal jugular vein (IJV) with a significant dilatation in the arterial phase (Fig. 1C). Due to the suspicion that the IIOP may be related to an abnormality in the hemodialytic vessels, he underwent fistulography to check the arteriovenous f low. Surprisingly, fistulography confirmed that the venous flow of the cephalic vein in the AVF circuit was directly joined to the IJV, and not to the subclavian vein, inducing venous reflux to the brain (Fig. 1D). He underwent a left cephalic vein ligation and new AVF formation in the right side. After surgery, the IOP decreased to 16 mmHg on the first day and 6 mmHg on the second day, and the patient’s subjective symptoms also improved. After two weeks, IOP was stable and the visual acuity was improved to 20 / 40. In addition, a remarkable improvement of choroidal detachment over time was observed, which completely resolved after two months. He was disKorean J Ophthalmol 2021;35(4):328-329 https://doi.org/10.3341/kjo.2021.0031",2021-06-21,https://www.semanticscholar.org/paper/fd870011a2a488fb3c6563e5031d3b09d7bcf7ef,Korean Journal of Ophthalmology
642,"Dynamic Programming 6.1 Shortest Paths in Dags, Revisited","In the preceding chapters we have seen some elegant design principles—such as divide-and-conquer, graph exploration, and greedy choice—that yield definitive algorithms for a variety of important computational tasks. The drawback of these tools is that they can only be used on very specific types of problems. We now turn to the two sledgehammers of the algorithms craft, dynamic programming and linear programming, techniques of very broad applicability that can be invoked when more specialized methods fail. Predictably, this generality often comes with a cost in efficiency. At the conclusion of our study of shortest paths (Chapter 4), we observed that the problem is especially easy in directed acyclic graphs (dags). Let's recapitulate this case, because it lies at the heart of dynamic programming. The special distinguishing feature of a dag is that its nodes can be linearized; that is, they can be arranged on a line so that all edges go from left to right (Figure 6.1). To see why this helps with shortest paths, suppose we want to figure out distances from node S to the other nodes. For concreteness, let's focus on node D. The only way to get to it is through its Figure 6.1 A dag and its linearization (topological ordering). B D C A S E 1 2 4 1 6 3 1 2 S C A B D E 4 6 3 1 2 1 1 2 169",,https://www.semanticscholar.org/paper/1a7431ed46769beee30002c13ae4d44c25978a5b,
984,Effect of Nitric Oxide on Human Corneal Epithelial Cell Viability and Corneal Wound Healing,,2017-08-14,https://www.semanticscholar.org/paper/25d2fcc9c45916e6a3c6eae7d56f3b33f3099307,Scientific Reports
1766,The Discrete Infinite Logistic Normal Distribution for Mixed-Membership Modeling,"We present the discrete innite logistic normal distribution (DILN), a Bayesian nonparametric prior for mixed membership models. DILN generalizes the hierarchical Dirichlet process (HDP) to model correlation structure between the weights of the atoms at the group level. We derive a representation of DILN as a normalized collection of gamma-distributed random variables and study its statistical properties. We derive a variational inference algorithm for approximate posterior inference. We apply DILN to topic modeling of documents and study its empirical performance on four corpora, comparing performance with the HDP and the correlated topic model (CTM). To compute with large-scale data, we develop a stochastic variational inference algorithm for DILN and compare with similar algorithms for HDP and latent Dirichlet allocation (LDA) on a collection of 350; 000 articles from Nature.",2011-03-24,https://www.semanticscholar.org/paper/593cb435702d2e6e7ed8c84dec1c3154bcc11df9,International Conference on Artificial Intelligence and Statistics
2179,Relationships between blood leukocyte mitochondrial DNA copy number and inflammatory cytokines in knee osteoarthritis,"Osteoarthritis (OA) is a degenerative articular disorder manifested by cartilage destruction, subchondral sclerosis, osteophytes, and synovitis, resulting in chronic joint pain and physical disability in the elderly. The purpose of this study was to investigate mitochondrial DNA copy number (mtDNACN) and inflammatory cytokines in primary knee OA patients and healthy volunteers. A total of 204 knee OA patients and 169 age-matched healthy volunteers were recruited. Their relative blood leukocyte mtDNACN was assessed by quantitative real-time polymerase chain reaction (qRT-PCR), and ten inflammatory cytokines in their plasma were detected by multiplex immunoassay. Blood leukocyte mtDNACN in the OA group was significantly lower than that in the control group. Leukocyte mtDNACN in the control group was negatively correlated with their age (r=−0.380, P<0.0001), whereas mtDNACN in the OA group was positively correlated with their age (r=0.198, P<0.001). Plasma interleukin-4 (IL-4) and IL-6 were significantly higher in the knee OA group than in the control group. The plasma IL-6 level was positively correlated with blood leukocyte mtDNACN in the OA group (r=0.547, P=0.0014). IL-5 showed as a major factor (coefficient 0.69) in the second dimension of principle components analysis (PCA)-transformed data and was significantly higher in the OA group (P<0.001) as well as negatively correlated with mtDNACN (r=−0.577, P<0.001). These findings suggest that elevation of plasma IL-4 and IL-6 and a relative reduction in mtDNACN might be effective biomarkers for knee OA. IL-5 is a plausible factor responsible for decreasing blood leukocyte mtDNACN in knee OA patients.",2019-12-21,https://www.semanticscholar.org/paper/3e66b05f0cd7e4a7fecf6413d91fa005e609b2cd,Journal of Zhejiang University SCIENCE B
3738,Moments in Time Dataset: One Million Videos for Event Understanding,"We present the Moments in Time Dataset, a large-scale human-annotated collection of one million short videos corresponding to dynamic events unfolding within three seconds. Modeling the spatial-audio-temporal dynamics even for actions occurring in 3 second videos poses many challenges: meaningful events do not include only people, but also objects, animals, and natural phenomena; visual and auditory events can be symmetrical in time (“opening” is “closing” in reverse), and either transient or sustained. We describe the annotation process of our dataset (each video is tagged with one action or activity label among 339 different classes), analyze its scale and diversity in comparison to other large-scale video datasets for action recognition, and report results of several baseline models addressing separately, and jointly, three modalities: spatial, temporal and auditory. The Moments in Time dataset, designed to have a large coverage and diversity of events in both visual and auditory modalities, can serve as a new challenge to develop models that scale to the level of complexity and abstract reasoning that a human processes on a daily basis.",2018-01-09,https://www.semanticscholar.org/paper/07174c2f209f15cacf9ad3422b48652df286be69,IEEE Transactions on Pattern Analysis and Machine Intelligence
416,Reflective Relational Machines,"Abstract We propose a model of database programming with reflection (dynamic generation of queries within the host programming language), called the reflective relational machine , and characterize the power of this machine in terms of known complexity classes. In particular, the polynomial time restriction of the reflective relational machine is shown to express PSPACE, and to correspond precisely to uniform circuits of polynomial depth and exponential size. This provides an alternative, logic based formulation of the uniform circuit model, which may be more convenient for problems naturally formulated in logic terms, and establishes that reflection allows for more “intense” parallelism, which is not attainable otherwise (unless P=PSPACE). We also explore the power of the reflective relational machine subject to restrictions on the number of variables used, emphasizing the case of sublinear bounds.",1998-06-15,https://www.semanticscholar.org/paper/073ebc60d29fbdcf16223593d47f545ffea4be40,Information and Computation
2563,Cursorless interaction techniques for wearable and mobile computing,"In the past two decades, interaction for desktop computing systems has been dominated by graphical user interfaces (GUIs) that use a keyboard for text entry and a pointing device controlling an on-screen cursor for the majority of other tasks. These human-computer interfaces rely on the visual display system for two purposes: to provide data output, and to provide visual feedback. In this thesis we shall discuss why these interfaces are not the most appropriate on wearable computing systems, where the user's visual attention may be heavily loaded and input devices and display devices need to be compact and portable. 
This dissertation presents a set of interaction techniques for touch-sensor-based input devices that address these issues. Our user interface systems are cursorless. Therefore, they do not rely on the manipulation and activation of on-screen visual widgets with the use of an on-screen pointer. Consequently, they minimize the amount of visual feedback that is needed during their operation. 
We explore alternative input channels—in addition to position—that the human hand can manipulate and output channels that the finger can sense: multi-finger use, applied pressure, and passive haptics provided by tangible physical features. Here, the focus is on minimizing visual feedback requirements by transferring the versatility of GUIs that use on-screen widgets to the input device itself. A further goal is to offer expert users the possibility of eyes-free data entry and system control by exploiting the passive tactile physical features of the input device. We present the results of quantitative and qualitative user studies designed to evaluate our input techniques. 
In addition to describing these input systems and their prototype implementations, we discuss sample applications developed to illustrate the use of these input techniques. We also discuss the applicability of these contributions to other fields of computer science: mobile augmented reality, immersive virtual reality, and interaction with public displays.",,https://www.semanticscholar.org/paper/ed51b7d4959bcf0962892eed9c7c603111e21b5f,
732,Polynomial Time Algorithms for Branching Markov Decision Processes and Probabilistic Min(Max) Polynomial Bellman Equations,,2012-02-21,https://www.semanticscholar.org/paper/452dbc46ce40de491066df9abc142637b0190481,"International Colloquium on Automata, Languages and Programming"
786,Testing and Checking of Finite State Systems,,2002-04-03,https://www.semanticscholar.org/paper/4ca49b0258077b8317a2ede39ca899112ab2510b,Latin American Symposium on Theoretical Informatics
2143,Broadcasting with real-time delay,,,https://www.semanticscholar.org/paper/e7b1ce1eb146e686476de77c69b58a76983f2c8d,
1269,Search for flavor-changing-neutral-current D meson decays,We study the flavor-changing-neutral-current process c to u mu+ mu- using 1.3 fb^-1 of p p bar collisions at sqrt(s) = 1.96 TeV recorded by the D0 detector operating at the Fermilab Tevatron Collider. We see clear indications of the Ds+ and D+ to phi pi+ to mu+ mu- pi+ final states with significance greater than four standard deviations above background for the D+ state. We search for the continuum decay of D+ to pi+mu+mu- in the dimuon invariant mass spectrum away from the phi resonance. We see no evidence of signal above background and set a limit of B(D+ to pi+mu+mu-)<3.9 x 10^-6 at the 90% C.L. This limit places the most stringent constraint on new phenomena in the c to u mu+ mu- transition.,2007-08-15,https://www.semanticscholar.org/paper/03e68aaa2fd85790e79dff5c3a259e86e16eb4ad,
1622,Variational Inference via χ Upper Bound Minimization,"Variational inference (VI) is widely used as an efficient alternative to Markov chain Monte Carlo. It posits a family of approximating distributions q and finds the closest member to the exact posterior p. Closeness is usually measured via a divergence D(q||p) from q to p. While successful, this approach also has problems. Notably, it typically leads to underestimation of the posterior variance. In this paper we propose CHIVI, a black-box variational inference algorithm that minimizes Dχ(p||q), the χ-divergence from p to q. CHIVI minimizes an upper bound of the model evidence, which we term the χ upper bound (CUBO). Minimizing the CUBO leads to improved posterior uncertainty, and it can also be used with the classical VI lower bound (ELBO) to provide a sandwich estimate of the model evidence. We study CHIVI on three models: probit regression, Gaussian process classification, and a Cox process model of basketball plays. When compared to expectation propagation and classical VI, CHIVI produces better error rates and more accurate estimates of posterior variance.",,https://www.semanticscholar.org/paper/24865152648081fa29bf5e3c6c77027e1d2b0205,
2361,Interactions between bacterial surfaces and phagocyte plasma membranes.,,1989-06-01,https://www.semanticscholar.org/paper/fe275f0ac1308bef223562d0edae549888d2082b,Biochemical Society Transactions
2171,"Type I Interferon regulates cytokine-delayed neutrophil apoptosis, reactive oxygen species production and chemokine expression via activation of p38 MAPK","Interferons (IFNs) are key regulators of a number of inflammatory conditions in which neutrophils play an important role in pathology, such as rheumatoid arthritis (RA) and systemic lupus erythematosus (SLE), where Type I IFNs are implicated in disease pathology. However, IFNs are usually generated in vivo together with other cytokines that also have immunoregulatory functions but such interactions are poorly-defined experimentally. We measured the effects of Type-I IFN (IFNα), elevated in both RA and SLE, on the functions of healthy neutrophils incubated in vitro in the absence and presence of pro-inflammatory cytokines typically elevated in inflammatory diseases (TNFα, GM-CSF). IFNα alone had no effect on neutrophil apoptosis, however it did abrogate the anti-apoptotic effect of GM-CSF (18h, p< 0.01). The enhanced stabilty of the anti-apoptotic protein Mcl-1 and delayed activation of caspase activation normally regulated by GM-CSF were blocked by IFNα: this effect was mediated, in part, by activation of p38 MAPK, increased turnover of the anti-apoptotic protein Mcl-1 and cleavage of caspases. IFNα alone also primed ROS production alone and maintained the transient priming effect of TNF for up to 4h: it also down-regulated GM-CSF and TNFα-activated expression of CXCL1, CXCL2, CXCL3, CXCL8, CCL3 and CCL4, but in contrast increased the expression of CXCL10. These novel data identify complex regulatory signalling networks in which Type I IFNs profoundly alter the response of neutrophils to inflammatory cytokines. This is likely to have important consequences in vivo and may explain the complexity and heterogeneity of inflammatory diseases such as RA, in which multiple cytokine cascades have been activated.",2020-07-01,https://www.semanticscholar.org/paper/57cb689cfbde6994af023f0d9a89abafb661504e,bioRxiv
616,A Worst-Case Analysis of Nearest Neighbor Searching by Projection,,1980-07-14,https://www.semanticscholar.org/paper/9f896738b9d622dd694777ef0ef4d3aea0b500cb,"International Colloquium on Automata, Languages and Programming"
2271,Oligomannan suppresses neutrophil and monocyte respiratory burst: A possible mechanism for granulomatous inflammation in Crohn's disease,,2003-04-01,https://www.semanticscholar.org/paper/7b4d56cb9f9f5aa8b79e551f9a72044e1aad5bcb,
3489,Improved Bounds on Relaxations of a Parallel Machine Scheduling Problem,,1998-12-01,https://www.semanticscholar.org/paper/695837342d3b39aa1db775e5988c16488fc3d45d,Journal of combinatorial optimization
1434,A Search for dark matter using cryogenic detectors (CDMS),"The Cryogenic Dark Matter Search experiment uses germanium and silicon detectors cooled to cryogenic temperatures in a direct search for weakly-interacting massive particles in our Galaxy. The novel detectors allow a high degree of background rejection by discriminating between electron and nuclear recoils through the simultaneous measurement of the energy deposited in phonons (heat) and ionization. Exposures of a few kilogram-days from initial runs of our experiment yield (preliminary) upper limits on the WIMP-nucleon cross section that are comparable to much longer runs of other experiments. Current and future data promise significant improvement, primarily due to improved detectors and reduced backgrounds from surface radioactivity.",,https://www.semanticscholar.org/paper/c16069fe6020009354cea6e297d0a0de09cbd51c,
1500,Search for Long-lived Charged Massive Particles with the D0 Detector,,,https://www.semanticscholar.org/paper/572ac04d94fb11b144f36fc823544530f3f3c027,
3062,RSIO: automatic user interaction detection and scheduling,"We present RSIO, a processor scheduling framework for improving the response time of latency-sensitive applications by monitoring accesses to I/O channels and inferring when user interactions occur. RSIO automatically identifies processes involved in a user interaction and boosts their priorities at the time the interaction occurs to improve system response time. RSIO also detects processes indirectly involved in processing an interaction, automatically accounting for dependencies and boosting their priorities accordingly. RSIO works with existing schedulers and requires no application modifications to identify periods of latency-sensitive application activity. We have implemented RSIO in Linux and measured its effectiveness on microbenchmarks and real applications. Our results show that RSIO is easy to use and can provide substantial improvements in system performance for latency-sensitive applications.",2010-06-12,https://www.semanticscholar.org/paper/80bd596d8090bd33ab7f3e6df84a6282e886eea3,Measurement and Modeling of Computer Systems
2008,Manufacturing Intelligence and Feedback Control for Semiconductor Yield Enhancement,,2011-06-01,https://www.semanticscholar.org/paper/072a0656a4aecddf4f60158485225ab2b7e8b27f,
1439,Physics and technology of the next linear collider,,1996-06-01,https://www.semanticscholar.org/paper/7bc204b18ad2f176aba39eb5746383f0653b03d5,
352,Mythematics: storytelling in the teaching of computer science and mathematics,"• Illustrating a key concept: there are many ways to introduce and illustrate exponential growth -other than the dry mathematical expression with n up high, or the graph that pierces its upper right margin. Perhaps in terms of the physical world, via chain reactions and the initial growth of bacteria and embrya; or by recalling the Malthusian argument about populations and resources; or by discussing Moore's Law and the way it has been driving the world. Or, even better, by recounting the tale of the wise man who asked the grateful khaliph to simply place for him one grain of rice at the first square of the chessboard, two at the second, four at the third, and so forth.",2003-09-01,https://www.semanticscholar.org/paper/1ce11b93a9f9be555c27b050a3c5356a44be6048,Annual Conference on Innovation and Technology in Computer Science Education
196,Zero-Sum Polymatrix Games: A Generalization of Minmax,"We show that in zero-sum polymatrix games, a multiplayer generalization of two-person zero-sum games, Nash equilibria can be found efficiently with linear programming. We also show that the set of coarse correlated equilibria collapses to the set of Nash equilibria. In contrast, other important properties of two-person zero-sum games are not preserved: Nash equilibrium payoffs need not be unique, and Nash equilibrium strategies need not be exchangeable or max-min.",2016-01-27,https://www.semanticscholar.org/paper/45edb86a7ee18a0e7063bf24a3524501d72541cb,Mathematics of Operations Research
3387,Log Diameter Rounds Algorithms for 2-Vertex and 2-Edge Connectivity,"Many modern parallel systems, such as MapReduce, Hadoop and Spark, can be modeled well by the MPC model. The MPC model captures well coarse-grained computation on large data --- data is distributed to processors, each of which has a sublinear (in the input data) amount of memory and we alternate between rounds of computation and rounds of communication, where each machine can communicate an amount of data as large as the size of its memory. This model is stronger than the classical PRAM model, and it is an intriguing question to design algorithms whose running time is smaller than in the PRAM model. 
In this paper, we study two fundamental problems, $2$-edge connectivity and $2$-vertex connectivity (biconnectivity). PRAM algorithms which run in $O(\log n)$ time have been known for many years. We give algorithms using roughly log diameter rounds in the MPC model. Our main results are, for an $n$-vertex, $m$-edge graph of diameter $D$ and bi-diameter $D'$, 1) a $O(\log D\log\log_{m/n} n)$ parallel time $2$-edge connectivity algorithm, 2) a $O(\log D\log^2\log_{m/n}n+\log D'\log\log_{m/n}n)$ parallel time biconnectivity algorithm, where the bi-diameter $D'$ is the largest cycle length over all the vertex pairs in the same biconnected component. Our results are fully scalable, meaning that the memory per processor can be $O(n^{\delta})$ for arbitrary constant $\delta>0$, and the total memory used is linear in the problem size. Our $2$-edge connectivity algorithm achieves the same parallel time as the connectivity algorithm of Andoni et al. (FOCS 2018). We also show an $\Omega(\log D')$ conditional lower bound for the biconnectivity problem.",2019-05-02,https://www.semanticscholar.org/paper/09adeb7e2464f6960782352ccaeb1d0bd8ad6982,"International Colloquium on Automata, Languages and Programming"
1357,Study of Zgamma events and limits on anomalous ZZgamma and Zgammagamma couplings in pp collisions at square root s = 1.96 TeV.,"We present a measurement of the Zgamma production cross section and limits on anomalous ZZgamma and Zgammagamma couplings for form-factor scales of lambda = 750 and 1000 GeV. The measurement is based on 138 (152) candidates in the eegamma (mumugamma) final state using 320(290) pb(-1) of pp(-1) collisions at square root of s = 1.96 TeV. The 95% C.L. limits on real and imaginary parts of individual anomalous couplings are /h(10,30)Z/ < 0.23, /h(20,40)Z/ < 0.020, /h(10,30)gamma/ < 0.23, and /h(20,40)gamma/ < 0.019 for lambda = 1000 GeV.",,https://www.semanticscholar.org/paper/c4f1b25de53082c78062c51a523a191f6b216a5c,Physical Review Letters
985,The Antibiofilm efficacy of nitric oxide on soft contact lenses,,2017-11-21,https://www.semanticscholar.org/paper/30bbef03693997a5c817c65f5f5a2b1f2efd5306,BMC Ophthalmology
1899,Compensating Misalignment Using Dynamic Random-Effect Control System: A Case of High-Mixed Wafer Fabrication,"It is vital to have an exclusive modification in semiconductor production process because of meeting differentiated customer demands in dynamic and competitive global minuscule semiconductor technology market and the highly complex fabrication process. In this paper, we propose a control system based on the dynamic mixed-effect least-square support vector regression (LS-SVR) control system for overlay error compensation with stochastic metrology delay to minimize the misalignment of the patterning process. Moreover, for the stability of the control system in the presence of metrology delay and to deal with nonlinearity among the overlay factors, the novel Lyapunov-based kernel function is merged with the LS-SVR controller. The proposed controller’s operation has been validated and implemented by a major semiconductor manufacturer in Taiwan. The experiments are verified that mixed-effect LS-SVR controller has the higher validity and higher efficiency in comparison with the exponentially weighted moving average (EWMA) and threaded EWMA controllers which had been previously implemented at the company or applied in similar studies. Note to Practitioners—Due to high production complexity in semiconductor manufacturing process, a meticulous and intelligent process control is needed to achieve higher throughput and customer satisfaction. Monitoring a complex system is challenging because the process components and variables operate autonomously and interoperate with other manufacturing segments. This paper proposes a novel run-to-run (R2R) control system to compensate the overlay error during the photolithography process that efficiently deals with the high-mixed manufacturing environment and metrology delay.",2019-02-19,https://www.semanticscholar.org/paper/d8389627324cdfcb66e650eb7ef8685f531fdcef,IEEE Transactions on Automation Science and Engineering
2360,Granulocyte‐macrophage colony‐stimulating factor (GM‐CSF) primes the respiratory burst and stimulates protein biosynthesis in human neutrophils,,1989-10-09,https://www.semanticscholar.org/paper/e2cf681775445883e3df1d9595f28a43732e5c62,FEBS Letters
2663,Augmented Reality Exploring MARS: developing indoor and outdoor user interfaces to a mobile augmented reality system,"We describe an experimental mobile augmented reality system (MARS) testbed that employs di!erent user interfaces to allow outdoor and indoor users to access and manage information that is spatially registered with the real world. Outdoor users can experience spatialized multimedia presentations that are presented on a head-tracked, see-through, head-worn display used in conjunction with a hand-held pen-based computer. Indoor users can get an overview of the outdoor scene and communicate with outdoor users through a desktop user interface or a head- and hand-tracked immersive augmented reality user interface. ( 1999 Elsevier Science Limited. All rights reserved.",,https://www.semanticscholar.org/paper/83413d90cc51e6275275f59edf313b839a2a3135,
1969,Call for papers,,,https://www.semanticscholar.org/paper/a9e4d25fa612624fe66304c765b848be05054ad8,
1066,Search for the Flavor-Changing Neutral Current Decay Bs0 âƒTM Î1⁄4+Î1⁄4- in ppÌ– Collisions at â‹ıs = 1.96 TeV with the D0 Detector,,,https://www.semanticscholar.org/paper/e601796811683b603ef79671744fe81f04825886,
2342,Inhibition of neutrophil oxidant secretion by D-penicillamine: scavenging of H2O2 and HOCl.,"D-Penicillamine inhibited oxidant secretion from human neutrophils after activation by the chemotactic peptide N-formyl-methionyl-leucyl-phenylalanine (fMet-Leu-Phe), as assessed by luminol dependent chemiluminescence. In contrast, this drug had little effect on either intracellular oxidant production or lucigenin dependent chemiluminescence activated by the same agonist. The drug was shown to scavenge both H2O2 and HOCl in a cell free luminol chemiluminescence system, though its ability to scavenge HOCl was greater than that for H2O2. Both these oxidants could oxidise the drug, but again HOCl was more potent than H2O2. When D-penicillamine was oxidised by exposure to H2O2 it could no longer serve as a scavenger of secreted oxidants from neutrophils. These data suggest that in vivo the preferential scavenging of HOCl may be important under pathological conditions where secreted myeloperoxidase may be functional.",1992-03-01,https://www.semanticscholar.org/paper/e4ef55269d60c75538951cf5ae2d5ae5afdbb26c,Annals of the Rheumatic Diseases
3468,Approximation Algorithms for Single-Source Unsplittable Flow,"In the single-source unsplittable flow problem, we are given a network G, a source vertex s, and k commodities with sinks ti and real-valued demands $\rho_i,$ $1\leq i \leq k.$ We seek to route the demand $\rho_i$ of each commodity i along a single s-ti flow path so that the total flow routed across any edge e is bounded by the edge capacity ue. The conceptual difficulty of this NP-hard problem arises from combining packing constraints due to the existence of capacities with path selection in a graph of arbitrary topology. In this paper we give a generic framework, which yields approximation algorithms that are simpler than those previously known and achieve significant improvements upon the approximation ratios. Our framework, with appropriate subroutines, applies to all optimization versions previously considered and, unlike previous work, treats in a unified manner directed and undirected graphs. We provide extensions of our algorithms which yield the best possible approximation guarantees for restricted sets of demand values and an associated scheduling problem.",2002-03-01,https://www.semanticscholar.org/paper/4bff0aba150b151b329915f028ce66e1f7b831ef,SIAM journal on computing (Print)
1854,Integrating Topics and Syntax,"Statistical approaches to language learning typically focus on either short-range syntactic dependencies or long-range semantic dependencies between words. We present a generative model that uses both kinds of dependencies, and can be used to simultaneously find syntactic classes and semantic topics despite having no representation of syntax or semantics beyond statistical dependency. This model is competitive on tasks like part-of-speech tagging and document classification with models that exclusively use short- and long-range dependencies respectively.",2004-12-01,https://www.semanticscholar.org/paper/0ecc5ffeae38689dd2fe6ed4c32a6745744d7641,Neural Information Processing Systems
1193,Analysis of the low-energy electron-recoil spectrum of the CDMS experiment,"We report on the analysis of the low-energy electron-recoil spectrum from the CDMS II experiment using data with an exposure of 443.2 kg-days. The analysis provides details on the observed counting rate and possible background sources in the energy range of 2–8.5 keV. We find no significant excess of a peaked contribution to the total counting rate above the background model, and compare this observation to the recent DAMA results. In the framework of a conversion of a dark matter particle into electromagnetic energy, our 90% confidence level upper limit of 0.246  events/kg/day at 3.15 keV is lower than the total rate above background observed by DAMA. In absence of any specific particle physics model to provide the scaling in cross section between NaI and Ge, we assume a Z2 scaling. With this assumption the observed rate in DAMA remains higher than the upper limit in CDMS. Under the conservative assumption that the modulation amplitude is 6% of the total rate we obtain upper limits on the modulation amplitude a factor of ~2 lower than observed by DAMA, constraining some possible interpretations of this modulation.",2009-07-09,https://www.semanticscholar.org/paper/ffe7a12a9ce695ee5b36664da29539aae2d6bb5a,
519,A linear programming approach to reasoning about probabilities,,1990-09-01,https://www.semanticscholar.org/paper/ed253d8aa572b36ee25ea2e6a9c034a8ac14231e,Annals of Mathematics and Artificial Intelligence
2212,RNA-Seq Reveals Activation of Both Common and Cytokine-Specific Pathways following Neutrophil Priming,"Neutrophils are central to the pathology of inflammatory diseases, where they can damage host tissue through release of reactive oxygen metabolites and proteases, and drive inflammation via secretion of cytokines and chemokines. Many cytokines, such as those generated during inflammation, can induce a similar “primed” phenotype in neutrophils, but it is unknown if different cytokines utilise common or cytokine-specific pathways to induce these functional changes. Here, we describe the transcriptomic changes induced in control human neutrophils during priming in vitro with pro-inflammatory cytokines (TNF-α and GM-CSF) using RNA-seq. Priming led to the rapid expression of a common set of transcripts for cytokines, chemokines and cell surface receptors (CXCL1, CXCL2, IL1A, IL1B, IL1RA, ICAM1). However, 580 genes were differentially regulated by TNF-α and GM-CSF treatment, and of these 58 were directly implicated in the control of apoptosis. While these two cytokines both delayed apoptosis, they induced changes in expression of different pro- and anti-apoptotic genes. Bioinformatics analysis predicted that these genes were regulated via differential activation of transcription factors by TNF-α and GM-CSF and these predictions were confirmed using functional assays: inhibition of NF-κB signalling abrogated the protective effect of TNF-α (but not that of GM-CSF) on neutrophil apoptosis, whereas inhibition of JAK/STAT signalling abrogated the anti-apoptotic effect of GM-CSF, but not that of TNF-α (p<0.05). These data provide the first characterisation of the human neutrophil transcriptome following GM-CSF and TNF-α priming, and demonstrate the utility of this approach to define functional changes in neutrophils following cytokine exposure. This may provide an important, new approach to define the molecular properties of neutrophils after in vivo activation during inflammation.",2013-03-06,https://www.semanticscholar.org/paper/0289216b0961ad16d91f448e12840dfce8de1f63,PLoS ONE
1853,Correlated Topic Models,"Topic models, such as latent Dirichlet allocation (LDA), can be useful tools for the statistical analysis of document collections and other discrete data. The LDA model assumes that the words of each document arise from a mixture of topics, each of which is a distribution over the vocabulary. A limitation of LDA is the inability to model topic correlation even though, for example, a document about genetics is more likely to also be about disease than x-ray astronomy. This limitation stems from the use of the Dirichlet distribution to model the variability among the topic proportions. In this paper we develop the correlated topic model (CTM), where the topic proportions exhibit correlation via the logistic normal distribution [1]. We derive a mean-field variational inference algorithm for approximate posterior inference in this model, which is complicated by the fact that the logistic normal is not conjugate to the multinomial. The CTM gives a better fit than LDA on a collection of OCRed articles from the journal Science. Furthermore, the CTM provides a natural way of visualizing and exploring this and other unstructured data sets.",2005-12-05,https://www.semanticscholar.org/paper/e49da956b23ed295541c80939d4a1261d0a1022f,Neural Information Processing Systems
2392,Oscillatory accumulation of total cellular protein in synchronous cultures of Candida utilis,,1981-11-01,https://www.semanticscholar.org/paper/38c3c1aaccad97193578bdc435584f7ebfb9aac6,
2869,Critical role of galectin-3 in phagocytosis by macrophages.,"Galectin-3 is a member of a large family of animal lectins. This protein is expressed abundantly by macrophages, but its function in this cell type is not well understood. We have studied the effect of galectin-3 gene targeting on phagocytosis, a major function of macrophages. Compared with wild-type macrophages, galectin-3-deficient (gal3-/-) cells exhibited reduced phagocytosis of IgG-opsonized erythrocytes and apoptotic thymocytes in vitro. In addition, gal3-/- mice showed attenuated phagocytic clearance of apoptotic thymocytes by peritoneal macrophages in vivo. These mice also exhibited reduced IgG-mediated phagocytosis of erythrocytes by Kupffer cells in a murine model of autoimmune hemolytic anemia. Additional experiments indicate that extracellular galectin-3 does not contribute appreciably to the phagocytosis-promoting function of this protein. Confocal microscopic analysis of macrophages containing phagocytosed erythrocytes revealed localization of galectin-3 in phagocytic cups and phagosomes. Furthermore, gal3-/- macrophages exhibited a lower degree of actin rearrangement upon Fcgamma receptor crosslinkage. These results indicate that galectin-3 contributes to macrophage phagocytosis through an intracellular mechanism. Thus, galectin-3 may play an important role in both innate and adaptive immunity by contributing to phagocytic clearance of microorganisms and apoptotic cells.",2003-08-01,https://www.semanticscholar.org/paper/f5b1a2f3d2fa0dc01004d9f35721b85df1c1d1d5,Journal of Clinical Investigation
2854,Role of galectin-3 in mast cell functions: galectin-3-deficient mast cells exhibit impaired mediator release and defective JNK expression.,"Galectin-3 is a member of the beta-galactoside-binding animal lectin family expressed in various cell types, including mast cells. To determine the role of galectin-3 in the function of mast cells, we studied bone marrow-derived mast cells (BMMC) from wild-type (gal3(+/+)) and galectin-3-deficient (gal3(-/-)) mice. Cells from the two genotypes showed comparable expression of IgE receptor and c-Kit. However, upon activation by FcepsilonRI cross-linkage, gal3(-/-) BMMC secreted a significantly lower amount of histamine as well as the cytokine IL-4, compared with gal3(+/+) BMMC. In addition, we found significantly reduced passive cutaneous anaphylaxis reactions in gal3(-/-) mice compared with gal3(+/+) mice. These results indicate that there is a defect in the response of mast cells in gal3(-/-) mice. Unexpectedly, we found that gal3(-/-) BMMC contained a dramatically lower basal level of JNK1 protein compared with gal3(+/+) BMMC, which is probably responsible for the lower IL-4 production. The decreased JNK1 level in gal3(-/-) BMMC is accompanied by a lower JNK1 mRNA level, suggesting that galectin-3 regulates the transcription of the JNK gene or processing of its RNA. All together, these results point to an important role of galectin-3 in mast cell biology.",2006-10-15,https://www.semanticscholar.org/paper/06bf8f3000d07d272c7612104216f9fa1b173919,Journal of Immunology
681,CitiSense: improving geospatial environmental assessment of air quality using a wireless personal exposure monitoring system,"Environmental exposures are a critical component in the development of chronic conditions such as asthma and cancer. Yet, medical and public health practitioners typically must depend on sparse regional measurements of the environment that provide macro-scale summaries. Recent projects have begun to measure an individual's exposure to these factors, often utilizing body-worn sensors and mobile phones to visualize the data. Such data, collected from many individuals and analyzed across an entire geographic region, holds the potential to revolutionize the practice of public health.
 We present CitiSense, a participatory air quality sensing system that bridges the gap between personal sensing and regional measurement to provide micro-level detail at a regional scale. In a user study of 16 commuters using CitiSense, measurements were found to vary significantly from those provided by official regional pollution monitoring stations. Moreover, applying geostatistical kriging techniques to our data allows CitiSense to infer a regional map that contains considerably greater detail than official regional summaries. These results suggest that the cumulative impact of many individuals using personal sensing devices may have an important role to play in the future of environmental measurement for public health.",2012-10-23,https://www.semanticscholar.org/paper/75eb613a3cbaa25d5fb2f7afd084d07d20af103e,Wireless Health
1609,Equation Embeddings,"We present an unsupervised approach for discovering semantic representations of mathematical equations. Equations are challenging to analyze because each is unique, or nearly unique. Our method, which we call equation embeddings, finds good representations of equations by using the representations of their surrounding words. We used equation embeddings to analyze four collections of scientific articles from the arXiv, covering four computer science domains (NLP, IR, AI, and ML) and $\sim$98.5k equations. Quantitatively, we found that equation embeddings provide better models when compared to existing word embedding approaches. Qualitatively, we found that equation embeddings provide coherent semantic representations of equations and can capture semantic similarity to other equations and to words.",2018-03-24,https://www.semanticscholar.org/paper/b495ea6d5bcabdb757371a7cb4ce6bfda4df93c6,arXiv.org
2433,SpaceTokens: Interactive Map Widgets for Location-centric Interactions,"Map users often need to interact repetitively with multiple important locations. For example, a traveler may frequently check her hotel or a train station on a map, use them to localize an unknown location, or investigate routes involving them. Ironically, these location-centric tasks cannot be performed using locations directly; users must instead pan and zoom the map or use a menu to access locations. We propose SpaceTokens, interactive widgets that act as clones of locations, and which users can create and place on map edges like virtual whiteboard magnets. SpaceTokens make location a first-class citizen of map interaction. They empower users to rapidly perform location-centric tasks directly using locations: users can select combinations of on-screen locations and SpaceTokens to control the map window, or connect them to create routes. Participants in a study overwhelmingly preferred a SpaceTokens prototype over Google Maps on identical smartphones for the majority of tasks.",2018-04-21,https://www.semanticscholar.org/paper/376a65003a650c8c09199a7561a16e49bdfea63e,International Conference on Human Factors in Computing Systems
406,Novel Computational Approaches to Information Retrieval and Data Mining (Abstract),,1999-01-10,https://www.semanticscholar.org/paper/5d051d08e56b18c0a88d630f7cdaa5f60c72043e,International Conference on Database Theory
420,Planar map graphs,"We introduce and study a modi ed notion of planarity, in which two regions of a map are considered adjacent when they share any point of their boundaries (not an edge, as standard planarity requires). We seek to characterize the abstract graphs realized by such map adjacencies. We prove some preliminary properties of such graphs, and give a polynomial time algorithm for the following restricted problem: given an abstract graph, decide whether it is realized by a map in which at most four regions meet at any point. The general recognition problem remains open.",1998-05-23,https://www.semanticscholar.org/paper/53ba3ac19073a87241506b2202f98ad439a33c84,Symposium on the Theory of Computing
1354,Search for Wb b and WH Production in p p Collisions at s p 1 : 96 TeV,"V. M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, M. Agelou, J.-L. Agram, S. H. Ahn, M. Ahsan, G. D. Alexeev, G. Alkhazov, A. Alton, G. Alverson, G. A. Alves, M. Anastasoaie, S. Anderson, B. Andrieu, Y. Arnoud, A. Askew, B. Åsman, O. Atramentov, C. Autermann, C. Avila, F. Badaud, A. Baden, B. Baldin, P. W. Balm, S. Banerjee, E. Barberis, P. Bargassa, P. Baringer, C. Barnes, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, A. Bean, S. Beauceron, M. Begel, A. Bellavance, S. B. Beri, G. Bernardi, R. Bernhard,* I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, M. Binder, K. M. Black, I. Blackler, G. Blazey, F. Blekman, S. Blessing, D. Bloch, U. Blumenschein, A. Boehnlein, O. Boeriu, T. A. Bolton, F. Borcherding, G. Borissov, K. Bos, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, S. Burdin, T. H. Burnett, E. Busato, J. M. Butler, J. Bystricky, W. Carvalho, B. C. K. Casey, N. M. Cason, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K. M. Chan, A. Chandra, D. Chapin, F. Charles, E. Cheu, L. Chevalier, D. K. Cho, S. Choi, T. Christiansen, L. Christofek, D. Claes, B. Clément, C. Clément, Y. Coadou, M. Cooke, W. E. Cooper, D. Coppage, M. Corcoran, J. Coss, A. Cothenet, M.-C. Cousinou, S. Crépé-Renaudin, M. Cristetiu, M. A. C. Cummings, D. Cutts, H. da Motta, B. Davies, G. Davies, G. A. Davis, K. De, P. de Jong, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, S. Dean, F. Déliot, P. A. Delsart, M. Demarteau, R. Demina, P. Demine, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, M. Doidge, H. Dong, S. Doulas, L. Duflot, S. R. Dugad, A. Duperrin, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, T. Edwards, J. Ellison, J. Elmsheuser, J. T. Eltzroth, V. D. Elvira, S. Eno, P. Ermolov, O. V. Eroshin, J. Estrada, D. Evans, H. Evans, A. Evdokimov, V. N. Evdokimov, J. Fast, S. N. Fatakia, L. Feligioni, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, W. Freeman, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, E. Gallas, E. Galyaev, C. Garcia, A. Garcia-Bellido, J. Gardner, V. Gavrilov, P. Gay, D. Gelé, R. Gelhaus, K. Genser, C. E. Gerber, Y. Gershtein, G. Ginther, T. Golling, B. Gómez, K. Gounder, A. Goussiou, P. D. Grannis, S. Greder, H. Greenlee, Z. D. Greenwood, E. M. Gregores, Ph. Gris, J.-F. Grivaz, L. Groer, S. Grünendahl, M. W. Grünewald, S. N. Gurzhiev, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, S. Hagopian, I. Hall, R. E. Hall, C. Han, L. Han, K. Hanagaki, K. Harder, R. Harrington, J. M. Hauptman, R. Hauser, J. Hays, T. Hebbeker, D. Hedin, J. M. Heinmiller, A. P. Heinson, U. Heintz, C. Hensel, G. Hesketh, M. D. Hildreth, R. Hirosky, J. D. Hobbs, B. Hoeneisen, M. Hohlfeld, S. J. Hong, R. Hooper, P. Houben, Y. Hu, J. Huang, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, V. Jain, K. Jakobs, A. Jenkins, R. Jesik, K. Johns, M. Johnson, A. Jonckheere, P. Jonsson, H. Jöstlein, A. Juste, M. M. Kado, D. Käfer, W. Kahl, S. Kahn, E. Kajfasz, A. M. Kalinin, J. Kalk, D. Karmanov, J. Kasper, D. Kau, R. Kehoe, S. Kermiche, S. Kesisoglou, A. Khanov, A. Kharchilava, Y. M. Kharzheev, K. H. Kim, B. Klima, M. Klute, J. M. Kohli, M. Kopal, V. M. Korablev, J. Kotcher, B. Kothari, A. Koubarovsky, A. V. Kozelov, J. Kozminski, S. Krzywdzinski, S. Kuleshov, Y. Kulik, S. Kunori, A. Kupco, T. Kurča, S. Lager, N. Lahrichi, G. Landsberg, J. Lazoflores, A.-C. Le Bihan, P. Lebrun, S. W. Lee, W. M. Lee, A. Leflat, F. Lehner,* C. Leonidopoulos, P. Lewis, J. Li, Q. Z. Li, J. G. R. Lima, D. Lincoln, S. L. Linn, J. Linnemann, V. V. Lipaev, R. Lipton, L. Lobo, A. Lobodenko, M. Lokajicek, A. Lounis, H. J. Lubatti, L. Lueking, M. Lynker, A. L. Lyon, A. K. A. Maciel, R. J. Madaras, P. Mättig, A. Magerkurth, A.-M. Magnan, N. Makovec, P. K. Mal, S. Malik, V. L. Malyshev, H. S. Mao, Y. Maravin, M. Martens, S. E. K. Mattingly, A. A. Mayorov, R. McCarthy, R. McCroskey, D. Meder, H. L. Melanson, A. Melnitchouk, M. Merkin, K. W. Merritt, A. Meyer, H. Miettinen, D. Mihalcea, J. Mitrevski, N. Mokhov, J. Molina, N. K. Mondal, H. E. Montgomery, R. W. Moore, G. S. Muanza, M. Mulders, Y. D. Mutaf, E. Nagy, M. Narain, N. A. Naumann, H. A. Neal, J. P. Negret, S. Nelson, P. Neustroev, C. Noeding, A. Nomerotski, S. F. Novaes, T. Nunnemann, E. Nurse, V. O’Dell, D. C. O’Neil, V. Oguri, N. Oliveira, N. Oshima, G. J. Otero y Garzón, P. Padley, N. Parashar, J. Park, S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, P. M. Perea, E. Perez, O. Peters, P. Pétroff, M. Petteni, L. Phaf, R. Piegaia, P. L. M. Podesta-Lerma, V. M. Podstavkov, Y. Pogorelov, B. G. Pope, W. L. Prado da Silva, H. B. Prosper, S. Protopopescu, M. B. Przybycien, J. Qian, A. Quadt, B. Quinn, K. J. Rani, P. A. Rapidis, P. N. Ratoff, N. W. Reay, S. Reucroft, M. Rijssenbeek,",,https://www.semanticscholar.org/paper/a4fddc5b454440ab88b873a8978326f3de76c1d5,
1596,Dynamic Embeddings for Language Evolution,"Word embeddings are a powerful approach for unsupervised analysis of language. Recently, Rudolph et al. developed exponential family embeddings, which cast word embeddings in a probabilistic framework. Here, we develop dynamic embeddings, building on exponential family embeddings to capture how the meanings of words change over time. We use dynamic embeddings to analyze three large collections of historical texts: the U.S. Senate speeches from 1858 to 2009, the history of computer science ACM abstracts from 1951 to 2014, and machine learning papers on the ArXiv from 2007 to 2015. We find dynamic embeddings provide better fits than classical embeddings and capture interesting patterns about how language changes.",2018-04-10,https://www.semanticscholar.org/paper/417acb6b197d8f81368e67b63a9e280288f30599,The Web Conference
3518,A New Approach to the Minumum Cut Problem,,,https://www.semanticscholar.org/paper/ca5e4c19c4f72d722a62e5b79b817992b0623649,
2485,"Spatial Computing ∗ : Accomplishments , Opportunities , and Research Needs","We present a perspective on the societal accomplishments, recent cultural shifts, challenges, and opportunities in spatial computing based on the discussions at the 2012 Computing Community Consortium (CCC) visioning workshop, “From GPS and Virtual Globes to Spatial Computing – 2020,” held at the National Academies’ Keck Center to assess interdisciplinary developments and research challenges in spatial computing. In this article, we first provide detailed examples of transformative accomplishments resulting from spatial computing research. We then discuss the cultural shift resulting from the deep integration of spatial computing technologies into the everyday lives of citizens. This integration has presented a number of short-term opportunities for new developments in spatial computing along with long-term research needs to further transform our society.",,https://www.semanticscholar.org/paper/672c5920aacd1bcdfa79fc0005a8e33d2fe7402d,
1188,Determination of the strong coupling constant from the inclusive jet cross section in p p collisions at ffiffi s p 1⁄4 1 : 96 TeV,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, M. Ahsan, G.D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G. A. Alves, L. S. Ancu, M. Aoki, Y. Arnoud, M. Arov, A. Askew, B. Åsman, O. Atramentov, C. Avila, J. BackusMayes, F. Badaud, L. Bagby, B. Baldin, D.V. Bandurin, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V.A. Bezzubov, P. C. Bhat, V. Bhatnagar, G. Blazey, S. Blessing, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, E. E. Boos, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, X. B. Bu, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, T. H. Burnett, C. P. Buszello, P. Calfayan, B. Calpas, S. Calvet, E. Camacho-Pérez, J. Cammin, M.A. Carrasco-Lizarraga, E. Carrera, W. Carvalho, B. C. K. Casey, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K.M. Chan, A. Chandra, E. Cheu, S. Chevalier-Théry, D. K. Cho, S.W. Cho, S. Choi, B. Choudhary, T. Christoudias, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, D. Cutts, M. Ćwiok, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, K. DeVaughan, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, T. Dorland, A. Dubey, L. V. Dudko, L. Duflot, D. Duggan, A. Duperrin, S. Dutt, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V. D. Elvira, Y. Enari, S. Eno, H. Evans, A. Evdokimov, V.N. Evdokimov, G. Facini, A.V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, S. Fuess, T. Gadfort, C. F. Galea, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, W. Geng, D. Gerbaudo, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, G. Golovanov, B. Gómez, A. Goussiou, P. D. Grannis, S. Greder, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas,70,x P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Harder, A. Harel, J.M. Hauptman, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, A. P. Heinson, U. Heintz, C. Hensel, I. Heredia-De LaCruz, K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, T. Hoang, J. D. Hobbs, B. Hoeneisen, M. Hohlfeld, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, N. Huske, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, D. Jamin, R. Jesik, K. Johns, C. Johnson, M. Johnson, D. Johnston, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, D. Karmanov, P. A. Kasper, I. Katsanos, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y. N. Kharzheev, D. Khatidze, M.H. Kirby, M. Kirsch, J.M. Kohli, A. V. Kozelov, J. Kraus, A. Kumar, A. Kupco, T. Kurča, V. A. Kuzmin, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, H. S. Lee, W.M. Lee, A. Leflat, J. Lellouch, L. Li, Q. Z. Li, S.M. Lietti, J. K. Lim, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna-Garcia,34,kA.L. Lyon, A. K.A. Maciel, D. Mackin, P. Mättig, R. Magaña-Villalba, P. K. Mal, S. Malik, V. L. Malyshev, Y. Maravin, B. Martin, J. Martı́nez-Ortega, R. McCarthy, C. L. McGivern, M.M. Meijer, A. Melnitchouk, L. Mendoza, D. Menezes, P. G. Mercadante, M. Merkin, A. Meyer, J. Meyer, N.K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, R. Nayyar, H.A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, G. Obrant, D. Onoprienko, J. Orduna, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, M. Padilla, P. Padley, M. Pangilinan, N. Parashar, V. Parihar, S.-J. Park, S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma,34,{ V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, A.V. Popov, M. Prewitt, S. Protopopescu, J. Qian, A. Quadt, B. Quinn, M. S. Rangel, K. Ranjan, P. N. Ratoff, I. Razumov, P. Renkel, P. Rich, M. Rijssenbeek, I. Ripp-Baudot, F. Rizatdinova, S. Robinson, M. Rominsky, C. Royon, P. Rubinov, R. Ruchti, G. Safronov, G. Sajot, A. Sánchez-Hernández, M. P. Sanders, B. Sanghi, G. Savage, L. Sawyer, T. Scanlon, D. Schaile, R. D. Schamberger, Y. Scheglov, H. Schellman, T. Schliephake, S. Schlobohm, C. Schwanenberger, R. Schwienhorst, J. Sekaric, H. Severini, E. Shabalina, M. Shamim, V. Shary, A.A. Shchukin, R. K. Shivpuri, V. Simak, V. Sirotenko, P. Skubic, P. Slattery, D. Smirnov, PHYSICAL REVIEW D 80, 111107(R) (2009) RAPID COMMUNICATIONS",,https://www.semanticscholar.org/paper/e44926a9be7db74f1a6777ec8b096b6544c07e7b,
1274,Combined D 0 measurements constraining the CP-violating phase and width difference in the B 0 s system,"V. M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, S. H. Ahn, M. Ahsan, G. D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G. A. Alves, M. Anastasoaie, L. S. Ancu, T. Andeen, S. Anderson, B. Andrieu, M. S. Anzelc, Y. Arnoud, M. Arov, A. Askew, B. Åsman, A. C. S. Assis Jesus, O. Atramentov, C. Autermann, C. Avila, C. Ay, F. Badaud, A. Baden, L. Bagby, B. Baldin, D. V. Bandurin, P. Banerjee, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, C. Barnes, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, L. Berntzon, I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, M. Binder, C. Biscarat, I. Blackler, G. Blazey, F. Blekman, S. Blessing, D. Bloch, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, G. Borissov, K. Bos, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, S. Burdin, S. Burke, T. H. Burnett, E. Busato, C. P. Buszello, J. M. Butler, P. Calfayan, S. Calvet, J. Cammin, S. Caron, W. Carvalho, B. C. K. Casey, N. M. Cason, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K. Chan, K. M. Chan, A. Chandra, F. Charles, E. Cheu, F. Chevallier, D. K. Cho, S. Choi, B. Choudhary, L. Christofek, T. Christoudias, D. Claes, B. Clément, C. Clément, Y. Coadou, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, B. Cox, S. Crépé-Renaudin, D. Cutts, M. Ćwiok, H. da Motta, A. Das, B. Davies, G. Davies, K. De, P. de Jong, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, J. D. Degenhardt, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, M. Doidge, A. Dominguez, H. Dong, L. V. Dudko, L. Duflot, S. R. Dugad, D. Duggan, A. Duperrin, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V. D. Elvira, Y. Enari, S. Eno, P. Ermolov, H. Evans, A. Evdokimov, V. N. Evdokimov, A. V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Ford, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, E. Gallas, E. Galyaev, C. Garcia, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, D. Gelé, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, N. Gollub, B. Gómez, A. Goussiou, P. D. Grannis, H. Greenlee, Z. D. Greenwood, E. M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M. W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Hanagaki, P. Hansson, K. Harder, A. Harel, R. Harrington, J. M. Hauptman, R. Hauser, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, J. M. Heinmiller, A. P. Heinson, U. Heintz, C. Hensel, K. Herner, G. Hesketh, M. D. Hildreth, R. Hirosky, J. D. Hobbs, B. Hoeneisen, H. Hoeth, M. Hohlfeld, S. J. Hong, R. Hooper, P. Houben, Y. Hu, Z. Hubacek, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, C. Jarvis, A. Jenkins, R. Jesik, K. Johns, C. Johnson, M. Johnson, A. Jonckheere, P. Jonsson, A. Juste, D. Käfer, S. Kahn, E. Kajfasz, A. M. Kalinin, J. M. Kalk, J. R. Kalk, S. Kappler, D. Karmanov, J. Kasper, P. Kasper, I. Katsanos, D. Kau, R. Kaur, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y. M. Kharzheev, D. Khatidze, H. Kim, T. J. Kim, M. H. Kirby, B. Klima, J. M. Kohli, J.-P. Konrath, M. Kopal, V. M. Korablev, J. Kotcher, B. Kothari, A. Koubarovsky, A. V. Kozelov, D. Krop, A. Kryemadhi, T. Kuhl, A. Kumar, S. Kunori, A. Kupco, T. Kurča, J. Kvita, D. Lam, S. Lammers, G. Landsberg, J. Lazoflores, P. Lebrun, W. M. Lee, A. Leflat, F. Lehner, V. Lesne, J. Leveque, P. Lewis, J. Li, L. Li, Q. Z. Li, S. M. Lietti, J. G. R. Lima, D. Lincoln, J. Linnemann, V. V. Lipaev, R. Lipton, Z. Liu, L. Lobo, A. Lobodenko, M. Lokajicek, A. Lounis, P. Love, H. J. Lubatti, M. Lynker, A. L. Lyon, A. K. A. Maciel, R. J. Madaras, P. Mättig, C. Magass, A. Magerkurth, N. Makovec, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, H. S. Mao, Y. Maravin, B. Martin, R. McCarthy, A. Melnitchouk, A. Mendes, L. Mendoza, P. G. Mercadante, M. Merkin, K. W. Merritt, A. Meyer, J. Meyer, M. Michaut, H. Miettinen, T. Millet, J. Mitrevski, J. Molina, R. K. Mommsen, N. K. Mondal, J. Monk, R. W. Moore, T. Moulik, G. S. Muanza, M. Mulders, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, N. A. Naumann, H. A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, C. Noeding, A. Nomerotski, S. F. Novaes, T. Nunnemann, V. O’Dell, D. C. O’Neil, G. Obrant, C. Ochando, V. Oguri, N. Oliveira, D. Onoprienko, N. Oshima, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park, S. K. Park, J. Parsons, R. Partridge, N. Parua, PHYSICAL REVIEW D 76, 057101 (2007)",,https://www.semanticscholar.org/paper/412895c738c9ba2da39829c490daf9e2eed45436,
1909,Modelling and analysis of semiconductor supply chains,"Supply chain management (SCM) problems have existed in the semiconductor industry since the early days of the industry, but have become increasingly important in the last decade (Chien et al. 2011)...",2018-04-25,https://www.semanticscholar.org/paper/76a0d6d93823d2bf003e056c11e7c34c004aeab5,International Journal of Production Research
402,Software synthesis of variable-length code decoder using a mixture of programmed logic and table lookups,"Implementation of variable-length code (VLC) decoders can involve a tradeoff between the number of decoding steps and memory usage. In this paper, we proposed a novel scheme for optimizing this tradeoff using a machine model abstracted from general purpose processors with hierarchical memories. We formulate the VLC decode problem as an optimization problem where the objective is to minimize the average decoding time. After showing that the problem is NP-complete, we present a Lagrangian algorithm that finds an approximate solution with bounded error. An implementation is automatically synthesized by a code generator. To demonstrate the efficacy of our approach, we conducted experiments of decoding codebooks for a pruned tree-structured vector quantizer and H.263 motion vector that show a performance gain of our proposed algorithm over single table lookup implementation and logic implementation.",1999-03-29,https://www.semanticscholar.org/paper/174ec7f0600c03b9169af7ae89f00cc268b60569,Proceedings DCC'99 Data Compression Conference (Cat. No. PR00096)
1467,Calibration systems for the CDF central electromagnetic calorimeter,,1988-05-01,https://www.semanticscholar.org/paper/baf5704c3e546bde5ad4b3fa7bc22c73705a15a5,
1471,"Comparison of π±, K± and p, p production in the central rapidity region in hadron-hadron collisions and in e+e− annihilation",,1987-01-22,https://www.semanticscholar.org/paper/2dcbee5d36aa9fc93f62a3627229426a64c2492f,
2362,Impaired microbial killing in two patients with defective degranulation of myeloperoxidase.,,,https://www.semanticscholar.org/paper/838554c47c99673ee9f4eb69d6009de1a1bf0646,Acta paediatrica Hungarica
2605,Directions and frameworks for effective telepresence,"1. PANEL INTRODUCTION Following the great standards set by the panels in the workshops held in the last two years [1,2], we have this year again a distinguished panel to discuss and debate the directions and frameworks for telepresence. Some of the questions brought up in the last two years continue to be on the top of our minds: Why is telepresence not as common as we think it can be today? How much technology is too much in a telepresence system? Is there too much emphasis on creating an immersive telepresence system? Which are the suitable paradigms for telepresence? How much are they dependent on the task and application? Which are the most effective telepresence systems we have today? How do we make telepresence more effective? How do we shift the focus from transmitting multi-modal data to creating effective means of experiencing remote environments and events?",2004-10-15,https://www.semanticscholar.org/paper/aa236d618197d8bc15ccdf47379bb44875a094c0,ACM SIGMM workshop on Experiential Telepresence
1754,How They Vote: Issue-Adjusted Models of Legislative Behavior,"We develop a probabilistic model of legislative data that uses the text of the bills to uncover lawmakers' positions on specific political issues. Our model can be used to explore how a lawmaker's voting patterns deviate from what is expected and how that deviation depends on what is being voted on. We derive approximate posterior inference algorithms based on variational methods. Across 12 years of legislative data, we demonstrate both improvement in heldout predictive performance and the model's utility in interpreting an inherently multi-dimensional space.",2012-12-03,https://www.semanticscholar.org/paper/9805ddd8b0a92764b6df18b0408e8ef78d505e15,Neural Information Processing Systems
3114,WebPod: persistent Web browsing sessions with pocketable storage devices,"We present WebPod, a portable system that enables mobile users to use the same persistent, personalized web browsing session on any Internet-enabled device. No matter what computer is being used, WebPod provides a consistent browsing session, maintaining all of a user's plugins, bookmarks, browser web content, open browser windows, and browser configuration options and preferences. This is achieved by leveraging rapid improvements in capacity, cost, and size of portable storage devices. WebPod provides a virtualization and checkpoint/restart mechanism that decouples the browsing environment from the host, enabling web browsing sessions to be suspended to portable storage, carried around, and resumed from the storage device on another computer. WebPod virtualization also isolates web browsing sessions from the host, protecting the browsing privacy of the user and preventing malicious web content from damaging the host. We have implemented a Linux WebPod prototype and demonstrate its ability to quickly suspend and resume web browsing sessions, enabling a seamless web browsing experience for mobile users as they move among computers.",2005-05-10,https://www.semanticscholar.org/paper/f522222a16bddbe7a9ec0029f93e589e89712597,The Web Conference
823,On Datalog vs. Polynomial Time,"We show that certain monotonic polynomial time queries are not expressible in variants of Datalog. The proof techniques include lower bounds for monotone circuit size and a ""Pumping Lemma"" for Datalog queries.",1995-10-01,https://www.semanticscholar.org/paper/1a089b08363fdc66b90a71d63395ebb4bacd6da6,Journal of computer and system sciences (Print)
913,The Complexity of the Partial Order Dimension Problem,"The dimension of a partial order P is the minimum number of linear orders whose intersection is P. There are efficient algorithms to test if a partial order has dimension 1 or 2. We prove that it is NP-complete to determine if a partial order has dimension 3. As a consequence, several other related dimension-type problems are shown to be NP-complete.",1982-09-01,https://www.semanticscholar.org/paper/4fc2697014fefd77645f2a3575f4a6c0bdbd7b92,
2599,Collaborative mixed reality visualization of an archaeological excavation,"We present VITA (visual interaction tool for archaeology), an experimental collaborative mixed reality system for offsite visualization of an archaeological dig. Our system allows multiple users to visualize the dig site in a mixed reality environment in which tracked, see-through, head-worn displays are combined with a multi-user, multi-touch, projected table surface, a large screen display, and tracked hand-held displays. We focus on augmenting existing archaeological analysis methods with new ways to organize, visualize, and combine the standard 2D information available from an excavation (drawings, pictures, and notes) with textured, laser range-scanned 3D models of objects and the site itself. Users can combine speech, touch, and 3D hand gestures to interact multimodally with the environment. Preliminary user tests were conducted with archaeology researchers and students, and their feedback is presented here.",2004-11-02,https://www.semanticscholar.org/paper/4835ffa05831617be3e0c36d306b0e0fc339f703,Third IEEE and ACM International Symposium on Mixed and Augmented Reality
3103,MOVE: An End-to-End Solution to Network Denial of Service,"We present a solution to the denial of service (DoS) problem that does not rely on network infrastructure support, conforming to the end-to-end (e2e) design principle. Our approach is to combine an overlay network, which allows us to treat authorized traffic preferentially, with a lightweight process-migration environment that allows us to move services easily between different parts of a distributed system. Functionality residing on a part of the system that is subjected to a DoS attack migrates to an unaffected location. The overlay network ensures that traffic from legitimate users, who are authenticated before they are allowed to access the service, is routed to the new location. We demonstrate the feasibility and effectiveness of our approach by measuring the performance of an experimental prototype against a series of attacks using PlanetLab, a distributed experimental testbed. Our preliminary results show that the end-toend latency remains at acceptable levels during regular operation, increasing only by a factor of 2 to 3, even for large overlays. When a process migrates due to a DoS attack, the disruption of service for the end user is in the order of a few seconds, depending on the network proximity of the servers involved in the migration.",,https://www.semanticscholar.org/paper/104c67cd413008b4370d4cca320db096dc426339,Network and Distributed System Security Symposium
1613,Correlated RandomMeasures Rajesh Ranganatha,,,https://www.semanticscholar.org/paper/ee9c54cee156bc1a71a7c2e118b3f7b7703231d5,
3112,Reducing Downtime Due to System Maintenance and Upgrades (Awarded Best Student Paper!),"Patching, upgrading, and maintaining operating system software is a growing management complexity problem that can result in unacceptable system downtime. We introduce AutoPod, a system that enables unscheduled operating system updates while preserving application service availability. AutoPod provides a group of processes and associated users with an isolated machine-independent virtualized environment that is decoupled from the underlying operating system instance. This virtualized environment is integrated with a novel checkpoint-restart mechanism which allows processes to be suspended, resumed, and migrated across operating system kernel versions with different security and maintenance patches. 
 
AutoPod incorporates a system status service to determine when operating system patches need to be applied to the current host, then automatically migrates application services to another host to preserve their availability while the current host is updated and rebooted. We have implemented AutoPod on Linux without requiring any application or operating system kernel changes. Our measurements on real world desktop and server applications demonstrate that AutoPod imposes little overhead and provides sub-second suspend and resume times that can be an order of magnitude faster than starting applications after a system reboot. AutoPod enables systems to autonomically stay updated with relevant maintenance and security patches, while ensuring no loss of data and minimizing service disruption.",2005-12-04,https://www.semanticscholar.org/paper/d4101710a4aa68e904d056147806d4a745867eec,LiSA
582,Topological Bandwidth,,1983-03-09,https://www.semanticscholar.org/paper/9fb6260ab31ec3e25be68aa8a699a9af3ee0b8cc,Colloquium on Trees in Algebra and Programming
205,Power-Law Distributions in a Two-Sided Market and Net Neutrality,,2016-10-16,https://www.semanticscholar.org/paper/8d7c3a53e485617451b5cf5c7bf5dc13fd8b93c5,Workshop on Internet and Network Economics
3104,Group round robin,"We present group round-robin (GRR) scheduling, a hybrid fair packet scheduling framework based on a grouping strategy that narrows down the traditional trade-off between fairness and computational complexity. GRR combines its grouping strategy with a specialized round-robin scheduling algorithm that utilizes the properties of GRR groups to schedule flows within groups in a manner that provides O(1) bounds on fairness with only O(1) time complexity. Under the practical assumption that GRR employs a small constant number of groups, we apply GRR to popular fair queuing scheduling algorithms and show how GRR can be used to achieve constant bounds on fairness and time complexity for these algorithms. We also present and prove new results on the fairness bounds for several of these fair queuing algorithms using a consistent fairness measure. We analyze the behavior of GRR and present experimental results that demonstrate how GRR can be combined with existing scheduling algorithms to provide much lower scheduling overhead and more than an order of magnitude better scheduling accuracy in practice than scheduling algorithms without GRR.",2005-10-01,https://www.semanticscholar.org/paper/13624d2ca68720ac1a5d1ef3df597c352f146fb9,Symposium on Architectures for Networking and Communications Systems
1885,The evolution of Omega-The International Journal of Management Science over the past 40 years: A bibliometric overview,,2020-06-01,https://www.semanticscholar.org/paper/632a9c545e7ae99c4baabc81104b2b569ed5f79d,
217,Cortical Computation,"A computational theory of cortex necessitates a novel paradigm of exquisitely distributed computation. Here we review recent work on a primitive called Predictive Join, or PJoin, which is both plausible and useful in regards to cortical computation, and which enables a spontaneous form of unsupervised learning exhibiting many of the characteristics of brain activity. We also outline several immediate goals of a computational research program on the brain.",2015-07-21,https://www.semanticscholar.org/paper/3047903cb1007e97589a5b8cdbb1af338075f314,ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing
1679,Bayesian Poisson Tensor Factorization for Inferring Multilateral Relations from Sparse Dyadic Event Counts,"We present a Bayesian tensor factorization model for inferring latent group structures from dynamic pairwise interaction patterns. For decades, political scientists have collected and analyzed records of the form ""country i took action a toward country j at time t"" - known as dyadic events - in order to form and test theories of international relations. We represent these event data as a tensor of counts and develop Bayesian Poisson tensor factorization to infer a low-dimensional, interpretable representation of their salient patterns. We demonstrate that our model's predictive performance is better than that of standard non-negative tensor factorization methods. We also provide a comparison of our variational updates to their maximum likelihood counterparts. In doing so, we identify a better way to form point estimates of the latent factors than that typically used in Bayesian Poisson matrix factorization. Finally, we showcase our model as an exploratory analysis tool for political scientists. We show that the inferred latent factor matrices capture interpretable multilateral relations that both conform to and inform our knowledge of international a airs.",2015-06-10,https://www.semanticscholar.org/paper/4ddb48f5e50ecf3595a0ef2517d36d077f968e25,Knowledge Discovery and Data Mining
1947,Flexible Multistage Forward/Reverse Logistics Network Under Uncertain Demands with Hybrid Genetic Algorithm,,,https://www.semanticscholar.org/paper/d3e1b7a47f1fb0718cba5223edb9f5117085739a,
2561,Visual Hints for Tangible Gestures,"Tangible Augmented Reality imbues physical objects with the ability to act and respond in new ways. In particular, physical objects and gestures made with them gain meaning that does not exist outside the tangible augmented reality environment. The existence of this new set of possible actions and outcomes is not always apparent, making it necessary to learn new movements or gestures. Addressing this opportunity, we present visual hints, which are graphical representations in augmented reality of potential actions and their consequences in the augmented physical world. Visual hints enable discovery, learning, and completion of gestures and manipulation in tangible augmented reality. Here, we discuss our investigation of a variety of representations of visual hints and methods for activating them. We then describe a specific implementation that supports gestures developed for a tangible augmented reality user interface to an electronic field guide for botanists, and present results from a pilot study. CR",,https://www.semanticscholar.org/paper/aa8755a9cae570b6f8218cba01be15368b70b814,
2906,New Correlative Microscopy Approaches to Understand the Microstructural Origins of Creep Cavitation in Austenitic Steels,"Creep is an important degradation mechanism in high temperature, high stress environments in industries such as aerospace and nuclear reactors. Metallic components gradually accumulate creep damage over extended periods of time that can eventually build to cracking. Understanding the microstructural mechanisms behind such processes in failed components or using laboratory-based uniaxial creep tests is complicated by the large ductile deformation that occurs in the final period prior to fracture, which can obscure many of the subtler features that caused it. Typically an interrupted test gives better representative data of the early stages of cavitation, but this presents challenges to understand how nanometer-scale cavities are distributed at larger length scales [1]. Often only by combining multiple characterization techniques across different length scales can the full picture of creep damage be fully characterized [2]. In this study we will explore new ways to understand how creep cavitation forms in AISI 316H austenitic stainless steel used for advanced gas-cooled nuclear reactors (AGRs), through both ex-service material from a boiler header and laboratory uniaxial creep test specimens. We present new correlative microscopy approaches to understand the early stage nucleation of creep cavities prior to failure using a combination of scanning electron microscopy (SEM), electron backscatter diffraction (EBSD), focused ion beam (FIB) imaging assisted by xenon difluoride (XeF 2 ) gas and transmission electron microscopy (TEM), together",2022-07-22,https://www.semanticscholar.org/paper/6aa24e3a87cc493d8d6f1e17143fca415c9b667a,Microscopy and Microanalysis
3380,A Competitive Algorithm for Throughout Maximization on Identical Machines,This paper considers the basic problem of scheduling jobs online with preemption to maximize the number of jobs completed by their deadline on $m$ identical machines. The main result is an $O(1)$ competitive deterministic algorithm for any number of machines $m>1$.,2021-11-12,https://www.semanticscholar.org/paper/0336879a1746aa5f2032159c7f6e5d00432acb4f,arXiv.org
3031,ARM Virtualization: Performance and Architectural Implications,"ARM servers are becoming increasingly common, making server technologies such as virtualization for ARM of growing importance. We present the first study of ARM virtualization performance on server hardware, including multi-core measurements of two popular ARM and x86 hypervisors, KVM and Xen. We show how ARM hardware support for virtualization can enable much faster transitions between VMs and the hypervisor, a key hypervisor operation. However, current hypervisor designs, including both Type 1 hypervisors such as Xen and Type 2 hypervisors such as KVM, are not able to leverage this performance benefit for real application workloads. We discuss the reasons why and show that other factors related to hypervisor software design and implementation have a larger role in overall performance. Based on our measurements, we discuss changes to ARM's hardware virtualization support that can potentially bridge the gap to bring its faster VM-to-hypervisor transition mechanism to modern Type 2 hypervisors running real applications. These changes have been incorporated into the latest ARM architecture.",2016-06-18,https://www.semanticscholar.org/paper/ad3058c4e44a2770f4f3ed38693f0787a2ccf2f3,International Symposium on Computer Architecture
3720,Dissecting Image Crops,"The elementary operation of cropping underpins nearly every computer vision system, ranging from data augmentation and translation invariance to computational photography and representation learning. This paper investigates the subtle traces introduced by this operation. For example, despite refinements to camera optics, lenses will leave behind certain clues, notably chromatic aberration and vignetting. Photographers also leave behind other clues relating to image aesthetics and scene composition. We study how to detect these traces, and investigate the impact that cropping has on the image distribution. While our aim is to dissect the fundamental impact of spatial crops, there are also a number of practical implications to our work, such as revealing faulty photojournalism and equipping neural network researchers with a better understanding of shortcut learning. Code is available at https://github.com/basilevh/dissecting-image-crops.",2020-11-24,https://www.semanticscholar.org/paper/5f4cb14efef53e82b116f999b829c108104e8670,IEEE International Conference on Computer Vision
224,On Neural Networks and Paul Spirakis,,,https://www.semanticscholar.org/paper/f65d5b27c5b104781dea6121f3e224088cae1ca1,"Algorithms, Probability, Networks, and Games"
1013,A Case of Green Laser Pointer Injury to the Macula,"Purpose: We report a case of macular injury by accidental exposure to a green laser pointer. Case summary: A 25-year-old man had an acute reduction of visual acuity in his right eye two years ago after accidental exposure to a green laser pointer for a few seconds. The patient’s best corrected visual acuity was counting fingers in his right eye. Fundus examination and optical coherence tomography showed a macular hole and a linear retinal scar in his right eye. Conclusions: Green laser pointers may cause macular damage after exposure of just a few seconds, which can lead to irreversible reduction of visual acuity.",2008-04-01,https://www.semanticscholar.org/paper/e3979857bfbd98ac9e0d3df6a966e41ada1ef06d,
3041,KVM/ARM: Experiences Building the Linux ARM Hypervisor,"As ARM CPUs become increasingly common in mobile devices and servers, there is a growing demand for providing the benefits of virtualization for ARMbased devices. We present our experiences building the Linux ARM hypervisor, KVM/ARM, the first full system ARM virtualization solution that can run unmodified guest operating systems on ARM multicore hardware. KVM/ARM introduces split-mode virtualization, allowing a hypervisor to split its execution across CPU modes to take advantage of CPU mode-specific features. This allows KVM/ARM to leverage Linux kernel services and functionality to simplify hypervisor development and maintainability while utilizing recent ARM hardware virtualization extensions to run application workloads in guest operating systems with comparable performance to native execution. KVM/ARM has been successfully merged into the mainline Linux 3.9 kernel, ensuring that it will gain wide adoption as the virtualization platform of choice for ARM. We provide the first measurements on real hardware of a complete hypervisor using ARM hardware virtualization support. Our results demonstrate that KVM/ARM has modest virtualization performance and power costs, and can achieve lower performance and power costs compared to x86-based Linux virtualization on multicore hardware.",,https://www.semanticscholar.org/paper/6da7c0d50b8f0cfcdc1e4075c5fc496ba0ccf717,
991,"Systemic Comorbidities of Dry Eye Syndrome: The Korean National Health and Nutrition Examination Survey V, 2010 to 2012","Purpose: To identify systemic comorbidities in patients with dry eye syndrome in South Korea. Methods: From 2010 to 2012, 17,364 participants aged 20 or older were randomly included in the nationwide Korean National Health and Nutrition Examination Survey V. The prevalence of dry eye syndrome and demographics of these patients were investigated. We performed conditional logistic regression analyses based on age, sex, residential area, education level, occupation type, and household income level to obtain the odds ratio for each systemic comorbidity among subjects with and without dry eye syndrome. Results: The prevalence of dry eye syndrome in this study was 10.4%. Age [adjusted odds ratio (AOR): 1.02], female gender (AOR: 3.01), and indoor occupation (AOR: 1.30) were associated with a higher prevalence of dry eye syndrome and found to be less prevalent in those residing in rural areas (AOR: 0.73) and with lower education levels (AOR: 0.66–0.99). With regard to systemic comorbidities, dyslipidemia (AOR: 1.63), degenerative arthritis (AOR: 1.56), rheumatoid arthritis (AOR: 1.44), thyroid disease (AOR: 1.79), and renal failure (AOR: 2.56) were associated with a significantly higher prevalence of dry eye syndrome. Conclusions: We found that patients with dry eye syndrome have a higher prevalence of several systemic comorbidities. A more comprehensive therapeutic approach considering the effect of systemic medication may be necessary in these patients.",2016-02-01,https://www.semanticscholar.org/paper/647b5b585d9e7dbf5869b431b226e59638048163,Cornea
3516,Task Scheduling in Networks (Extended Abstract),,1994-07-06,https://www.semanticscholar.org/paper/a4486673a4615971d066b9a3871dd498e9f09921,Scandinavian Workshop on Algorithm Theory
2798,Galectin 3 Regulates HCC cell invasion by RhoA and MLCK activation,,2015-05-22,https://www.semanticscholar.org/paper/e7b9fbf35a24240e9c75f1c248c144722922ba10,Laboratory Investigation
3047,Capture: a desktop display-centric text recorder,"As more and more information is designed for human visual consumption through computer displays, the need to capture and process display-centric content is becoming increasingly important, especially for visually impaired users. We present Capture, a novel display-centric text recorder that facilitates real-time access to onscreen text and its structure and contextual information, including data associated with both foreground and background windows. Capture provides an intelligent caching architecture that integrates with the standard accessibility framework available on modern operating systems to continuously track onscreen text and metadata. This enables fast, semantic information recording without any modifications to applications, window systems, or operating system kernels. The recorded data is useful for a variety of problem domains, including assistive technologies, desktop search, auditing, and predictive graphical user interfaces. We have implemented a Capture prototype on Linux with the GNOME Accessibility Toolkit. Our results on real desktop applications demonstrate that Capture provides low runtime overhead and much more complete recording of onscreen text than modern desktop screen readers used for visually impaired users.",2012-10-22,https://www.semanticscholar.org/paper/fb98da66fab8a3f98294ef69875f6387704552c2,International ACM SIGACCESS Conference on Computers and Accessibility
2932,Sparse discriminative latent characteristics for predicting cancer drug sensitivity from genomic features,"Drug screening studies typically involve assaying the sensitivity of a range of cancer cell lines across an array of anti-cancer therapeutics. Alongside these sensitivity measurements high dimensional molecular characterizations of the cell lines are typically available, including gene expression, copy number variation and genomic mutations. We propose a sparse multitask regression model which learns discriminative latent characteristics that predict drug sensitivity and are associated with specific molecular features. We use ideas from Bayesian nonparametrics to automatically infer the appropriate number of these latent characteristics. The resulting analysis couples high predictive performance with interpretability since each latent characteristic involves a typically small set of drugs, cell lines and genomic features. Our model uncovers a number of drug-gene sensitivity associations missed by single gene analyses. We functionally validate one such novel association: that increased expression of the cell-cycle regulator C/EBPδ decreases sensitivity to the histone deacetylase (HDAC) inhibitor panobinostat.",2019-05-01,https://www.semanticscholar.org/paper/2ac952da5609e2823841d9472afa7d1bea4aa558,PLoS Comput. Biol.
1653,Variational Inference: A Review for Statisticians,"ABSTRACTOne of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this article, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find a member of that family which is close to the target density. Closeness is measured by Kullback–Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data...",2016-01-04,https://www.semanticscholar.org/paper/6f24d7a6e1c88828e18d16c6db20f5329f6a6827,arXiv.org
886,On Generating All Maximal Independent Sets,,1988-03-25,https://www.semanticscholar.org/paper/bf6af5a2d45964c7daf45a22976d6f2ffe205c16,Information Processing Letters
243,The New Faces of Combinatorial Optimization,,2012-04-19,https://www.semanticscholar.org/paper/3627b9251afb693b9d143213ee910b7392f217ea,International Symposium on Combinatorial Optimization
3637,The design of C,,,https://www.semanticscholar.org/paper/11639f4e479b630e66fa27564590cfaca9f45445,
3023,ARM Virtualization,"ARM servers are becoming increasingly common, making server technologies such as virtualization for ARM of growing importance. We present the first study of ARM virtualization performance on server hardware, including multi-core measurements of two popular ARM and x86 hypervisors, KVM and Xen. We show how ARM hardware support for virtualization can enable much faster transitions between VMs and the hypervisor, a key hypervisor operation. However, current hypervisor designs, including both Type 1 hypervisors such as Xen and Type 2 hypervisors such as KVM, are not able to leverage this performance benefit for real application workloads on ARMv8.0. We discuss the reasons why and show that other factors related to hypervisor software design and implementation have a larger role in overall performance. Based on our measurements, we discuss software changes and new hardware features, the Virtualization Host Extensions (VHE), added in ARMv8.1 that bridge the gap and bring ARM's faster VM-to-hypervisor transition mechanism to modern Type 2 hypervisors running real applications.",2018-08-28,https://www.semanticscholar.org/paper/24fe584525c3307d7ffdd726b9849b8bb2aba0cd,OPSR
3116,SWAP: A Scheduler with Automatic Process Dependency Detection,"We have developed SWAP, a system that automatically detects process dependencies and accounts for such dependencies in scheduling. SWAP uses system call history to determine possible resource dependencies among processes in an automatic and fully transparent fashion. Because some dependencies cannot be precisely determined, SWAP associates confidence levels with dependency information that are dynamically adjusted using feedback from process blocking behavior. SWAP can schedule processes using this imprecise dependency information in a manner that is compatible with existing scheduling mechanisms and ensures that actual scheduling behavior corresponds to the desired scheduling policy in the presence of process dependencies. We have implemented SWAP in Linux and measured its effectiveness on microbenchmarks and real applications. Our results show that SWAP has low overhead, effectively solves the priority inversion problem and can provide substantial improvements in system performance in scheduling processes with dependencies.",2004-03-29,https://www.semanticscholar.org/paper/007d530ea71264fd36323ebcadf8ecafe20ac578,Symposium on Networked Systems Design and Implementation
2242,THE EFFECT OF IMMUNO-SUPPRESSANT DRUGS ON INNATE IMMUNITY: 1467,,2008-07-01,https://www.semanticscholar.org/paper/6a609a54d42779e18172e951319f18a52f1e56e8,
3751,"See, Hear, and Read: Deep Aligned Representations","We capitalize on large amounts of readily-available, synchronous data to learn a deep discriminative representations shared across three major natural modalities: vision, sound and language. By leveraging over a year of sound from video and millions of sentences paired with images, we jointly train a deep convolutional network for aligned representation learning. Our experiments suggest that this representation is useful for several tasks, such as cross-modal retrieval or transferring classifiers between modalities. Moreover, although our network is only trained with image+text and image+sound pairs, it can transfer between text and sound as well, a transfer the network never observed during training. Visualizations of our representation reveal many hidden units which automatically emerge to detect concepts, independent of the modality.",2017-06-03,https://www.semanticscholar.org/paper/52ed3b634c302af93ee2e70b7c28e4b2128a5947,arXiv.org
1039,Snakeboard Motion Planning With Local Trajectory Information,"We address trajectory generation for the snakeboard, a system commonly studied in the geometric mechanics community. Our approach derives a solution using body coordinates and local trajectory information, leading to a more intuitive solution compared to prior work. The simple forms of the solution clearly show how they depend on local curvature and desired velocity profile, allowing for a description of some simple motion primitives. We readily propose techniques to navigate paths, including those with sharp corners, by taking advantage of the snakeboard’s singular configuration, as well as discuss some implications of torque limits.",2013-10-21,https://www.semanticscholar.org/paper/6cb9c3aa2f582fc0d66b2bad859419d2394554d8,
3549,The demacrofier,"C++ programs can be rejuvenated by replacing error-prone usage of the C Preprocessor macros with type safe C++11 declarations. We have developed a classification of macros that directly maps to corresponding C++11 expressions, statements, and declarations. We have built a set of tools that replaces macros with equivalent C++ declarations and iteratively introduces the refactorings into the software build.",2012-09-23,https://www.semanticscholar.org/paper/48db89589ab1d387b6522abd6bc21c4cc0704804,International Conference on Smart Multimedia
1858,Hierarchical Bayesian Models for Applications in Information Retrieval,"SUMMARY We present a simple hierarchical Bayesian approach to the modeling collections of texts and other large-scale data collections. For text collections, we posit that a document is generated by choosing a random set of multinomial probabilities for a set of possible “topics,” and then repeatedly generating words by sampling from the topic mixture. This model is intractable for exact probabilistic inference, but approximate posterior probabilities and marginal likelihoods can be obtained via fast variational methods. We also present extensions to coupled models for joint text/image data and multiresolution models for topic hierarchies.",,https://www.semanticscholar.org/paper/401680497e8144dfeef032f5a3393e869180c7b7,
961,Sustained nitric oxide-providing small molecule and precise release behavior study for glaucoma treatment.,"Incidence of glaucoma, a severe disease leading to irreversible loss of vision, is increasing with global aging populations. Lowering intraocular pressure (IOP) is the only proven treatment method for glaucoma. Nitric oxide (NO) is an emerging material targeting the conventional outflow pathway by relaxing the trabecular meshwork (TM). However, there is little understanding on NO level effective to IOP lowering without toxicity. Here we report a novel long-term NO-releasing polydiazeniumdiolate (NOP) that enables lowering IOP via the conventional outflow pathway. NOP is composed of carbon-bound polydiazeniumdiolate, stable NO donor moiety. NO release was monitored with accurate parameters by detection of real-time gas and accumulated form. Based on the NO release information, the selected safe level of NOP exhibited effective TM relaxation and potential an IOP lowering effect in vivo without side effects. This work provides new insights to nitric oxide release behavior that should be considered for glaucoma treatment.",2020-01-08,https://www.semanticscholar.org/paper/0ad730e75df49b5a842938b83897ec88b74974fa,Molecular Pharmaceutics
3631,Standardizing C,,1996-05-01,https://www.semanticscholar.org/paper/90d9b93cebd4517c4fc60dc260a0a7c107646c7c,
536,On Stochastic Scheduling with In-Tree Precedence Constraints,"We consider the problem of optimal scheduling of a set of jobs obeying in-tree precedence constraints, when a number M of processors is available. It is assumed that the service times of different jobs are independent identically distributed random variables. Subject to a minor assumption on the service time distribution, we show that policies of the ""Highest Level First"" type are optimal asymptotically, as the number of jobs tends to infinity.",1987-02-01,https://www.semanticscholar.org/paper/06245c745eb73db6bfa78c90f45a957e4f9be828,SIAM journal on computing (Print)
607,Worst-Case and Probabilistic Analysis of a Geometric Location Problem,"We consider the problem of choosing K “medians” among n points on the Euclidean plane such that the sum of the distances from each of the n points to its closest median is minimized. We show that this problem is NP-complete. We also present two heuristics that produce arbitrarily good solutions with probability going to 1. One is a partition heuristic, and works when K grows linearly—or almost so—with n. The other is the “honeycomb” heuristic, and is applicable to rates of growth of K of the form $K \sim n^\varepsilon $, $0 < \varepsilon < 1$.",1981-08-01,https://www.semanticscholar.org/paper/8f38db0d58fc7f0a694b337a888e3b2ecb9df0a4,SIAM journal on computing (Print)
1640,Context Selection for Embedding Models,"Word embeddings are an effective tool to analyze language. They have been recently extended to model other types of data beyond text, such as items in recommendation systems. Embedding models consider the probability of a target observation (a word or an item) conditioned on the elements in the context (other words or items). In this paper, we show that conditioning on all the elements in the context is not optimal. Instead, we model the probability of the target conditioned on a learned subset of the elements in the context. We use amortized variational inference to automatically choose this subset. Compared to standard embedding models, this method improves predictions and the quality of the embeddings.",,https://www.semanticscholar.org/paper/fea7064e129db2e577f8c3b84a6d11a9f835a8c3,Neural Information Processing Systems
3406,"Simultaneously Load Balancing for Every p-norm, With Reassignments","This paper investigates the task of load balancing where the objective function is to minimize the p-norm of loads, for p\geq 1, in both static and incremental settings. We consider two closely related load balancing problems. In the bipartite matching problem we are given a bipartite graph G=(C\cup S, E) and the goal is to assign each client c\in C to a server s\in S so that the p-norm of assignment loads on S is minimized. 
In the graph orientation problem the goal is to orient (direct) the edges of a given undirected graph while minimizing the p-norm of the out-degrees. The graph orientation problem is a special case of the bipartite matching problem, but less complex, which leads to simpler algorithms. 
 
For the graph orientation problem we show that the celebrated Chiba-Nishizeki peeling algorithm provides a simple linear time load balancing scheme whose output is an orientation that is 2-competitive, in a p-norm sense, for all p\geq 1. For the bipartite matching problem we first provide an offline algorithm that computes an optimal assignment. We then extend this solution to the online bipartite matching problem with reassignments, where vertices from C arrive in an online fashion together with their corresponding edges, and we are allowed to reassign an amortized O(1) vertices from C each time a new vertex arrives. In this online scenario we show how to maintain a single assignment that is 8-competitive, in a p-norm sense, for all p\geq 1.",2017-11-01,https://www.semanticscholar.org/paper/fdda90a3b02a54439a1354676f28d64b6872d9f5,Information Technology Convergence and Services
454,Topological Inference,"Geographical database systems deal with certain basic topological relations such as ""A overlaps B"" and ""B contains C"" between simply connected regions in the plane. It is of great interest to make sound inferences from elementary statements of this form. This problem has been identified extensively in the recent literature, but very limited progress has been made towards addressing the considerable technical difficulties involved. In this paper we study the computational problems involved in developing such an inference system. We point out that the problem has two distinct components that interact in rather complex ways: relational consistency, and planarity. We develop polynomial-time algorithms for several important special cases, and prove almost all the others to be NP-hard.",1995-08-20,https://www.semanticscholar.org/paper/77c8f39a59e6082115fc97898f131a5da4cd4d15,International Joint Conference on Artificial Intelligence
3472,Minimizing Makespan for the Lazy Bureaucrat Problem,,2002-07-03,https://www.semanticscholar.org/paper/fb4369ee8600d2792028bd2a37e7bcf5b813503b,Scandinavian Workshop on Algorithm Theory
3172,Savannas are vital but overlooked carbon sinks,,2022-01-28,https://www.semanticscholar.org/paper/022618327c8a064d0544b2bb7562de2c08f45d30,Science
3365,CHOICE AND MALE BODY SIZE,,,https://www.semanticscholar.org/paper/c59e690fb67f8850b160ab45dc543036c74e87bd,
1249,Measurement of the tt[over] production cross section in pp[over] collisions at sqrt(s)=1.96 TeV.,"We measure the tt[over] production cross section in pp[over] collisions at sqrt(s)=1.96 TeV in the lepton + jets channel. Two complementary methods discriminate between signal and background: b tagging and a kinematic likelihood discriminant. Based on 0.9 fb(-1) of data collected by the D0 detector at the Fermilab Tevatron Collider, we measure sigma(tt[over])=7.62+/-0.85 pb, assuming the current world average m(t)=172.6 GeV. We compare our cross section measurement with theory predictions to determine a value for the top-quark mass of 170+/-7 GeV.",,https://www.semanticscholar.org/paper/b5a4157d9eb86d8f249e46adbcac662096eba2d0,Physical Review Letters
2683,A Touring Hachine: Prototgping 3D Hobite Augmented Reatitg Sgstems for Exptoring the Urban Environment,,,https://www.semanticscholar.org/paper/169f62d2b088451dfc52cf2ca529cd7582a8d9fe,
1729,A Nested HDP for Hierarchical Topic Models,"We develop a nested hierarchical Dirichlet process (nHDP) for hierarchical topic modeling. The nHDP is a generalization of the nested Chinese restaurant process (nCRP) that allows each word to follow its own path to a topic node according to a document-specific distribution on a shared tree. This alleviates the rigid, single-path formulation of the nCRP, allowing a document to more easily express thematic borrowings as a random effect. We demonstrate our algorithm on 1.8 million documents from The New York Times.",2013-01-16,https://www.semanticscholar.org/paper/204711170720d254b19b4141ac994beeaf87f5c6,International Conference on Learning Representations
1618,Tea Leaves : How Humans Interpret Topic Models,"Probabilistic topic models are a popular tool for the unsupervised analysis of text, providing both a predictive model of future text and a latent topic representation of the corpus. Practitioners typically assume that the latent space is semantically meaningful. It is used to check models, summarize the corpus, and guide exploration of its contents. However, whether the latent space is interpretable is in need of quantitative evaluation. In this paper, we present new quantitative methods for measuring semantic meaning in inferred topics. We back these measures with large-scale user studies, showing that they capture aspects of the model that are undetected by previous measures of model quality based on held-out likelihood. Surprisingly, topic models which perform better on held-out likelihood may infer less semantically meaningful topics.",,https://www.semanticscholar.org/paper/160d86a1e8804507444daa74ede04a0821df16b2,
1245,Measurement of the Shape of the Boson-Transverse Momentum Distribution in p p ! Z= ! ee X Events Produced at s,,,https://www.semanticscholar.org/paper/a33226a71aa218d529d3177c061e006aab0dc95d,
2081,Data mining for improving the solder bumping process in the semiconductor packaging industry,"Modern semiconductor manufacturing is very complex and expensive. Maintaining high quality and yield enhancement have been recognized as important factors to build core competences for semiconductor manufacturing companies. Data mining can find potentially useful information from huge databases. This paper proposes a data-mining framework based on decision-tree induction for improving the yield of the solder bumping process in which the various (physical and chemical) input variables that affect the bumping process exhibit highly complex interactions. We conducted an empirical study in a semiconductor fabrication facility in Taiwan to validate this approach. The results show that the proposed approach can effectively derive the causal relationships among controllable input process factors and the target class to enhance the yield. Copyright © 2007 John Wiley & Sons, Ltd.",,https://www.semanticscholar.org/paper/e720dc803b3c37f973bb6d06f167c89742a09e01,Intell. Syst. Account. Finance Manag.
2858,Galectins in apoptosis.,,,https://www.semanticscholar.org/paper/af950daaaf008b4833b9a3bb15aa4bdc32d804a9,Methods in Enzymology
1089,WIMP-Search Results from the Second CDMSlite Run,"R. Agnese, A.J. Anderson, T. Aramaki, M. Asai, W. Baker, D. Balakishiyeva, D. Barker, R. Basu Thakur, 23 D.A. Bauer, J. Billard, A. Borgland, M.A. Bowles, P.L. Brink, R. Bunker, B. Cabrera, D.O. Caldwell, R. Calkins, D.G. Cerdeno, H. Chagani, Y. Chen, J. Cooley, B. Cornell, P. Cushman, M. Daal, P.C.F. Di Stefano, T. Doughty, L. Esteban, S. Fallows, E. Figueroa-Feliciano, M. Ghaith, G.L. Godfrey, S.R. Golwala, J. Hall, H.R. Harris, T. Hofer, D. Holmgren, L. Hsu, M.E. Huber, D. Jardin, A. Jastram, O. Kamaev, B. Kara, M.H. Kelsey, A. Kennedy, A. Leder, B. Loer, E. Lopez Asamar, P. Lukens, R. Mahapatra, V. Mandic, N. Mast, N. Mirabolfathi, R.A. Moffatt, J.D. Morales Mendoza, S.M. Oser, K. Page, W.A. Page, R. Partridge, M. Pepin, ∗ A. Phipps, K. Prasad, M. Pyle, H. Qiu, W. Rau, P. Redl, A. Reisetter, Y. Ricci, A. Roberts, H.E. Rogers, T. Saab, B. Sadoulet, 4 J. Sander, K. Schneck, R.W. Schnee, S. Scorza, B. Serfass, B. Shank, D. Speller, D. Toback, R. Underwood, S. Upadhyayula, A.N. Villano, B. Welliver, J.S. Wilson, D.H. Wright, S. Yellin, J.J. Yen, B.A. Young, and J. Zhang",,https://www.semanticscholar.org/paper/b402a6d06f170cb09abc83accc5b61092b24d936,
189,The EATCS Award 2017 - Laudatio for Eva Tardos,,2017-02-08,https://www.semanticscholar.org/paper/acb69b14902a3872dfd9fa76d2b415c7a6309251,Bull. EATCS
3302,ADAPTIVE ADVANTAGES OF MIXED‐SPECIES FEEDING FLOCKS AMONG SEED‐EATING FINCHES IN COSTA RICA,"Summary 
 
The feeding ecology of three Costa Rican finches occurring in mixed flocks, Tiaris olivacea, Sporophila aurita corvina and Sporophila torquella, was investigated by measuring both behavioural and ecological variables. Observations on foraging height, rate of hopping and pecking rate, as well as the identity, proximity and number of nearest neighbours were recorded. In addition the duration of all feeding and perching episodes were timed. Comparisons were also made between the abundances of food items (grass seeds) consumed and those potentially available for consumption. 
 
 
 
The analysis of variance of the feeding behaviour revealed that the presence or absence of neighbouring birds, whether of the same or different species, influenced the duration of feeding bouts more significantly than did either differences in habitat or species-characteristic behaviour. In addition the dietary comparisons revealed overlap in both species and size of seed consumed. Such similarities suggest that these species are not partitioning fields in the classical sense. 
 
 
 
We propose that the increase in the duration of the feeding bout associated with the presence of mixed species aggregations leads to increased feeding efficiency and is the result of intra- and inter-specific social learning. Certainly flocking is often advantageous, since searching in a group facilitates finding clumped resources; mixed species flocking, by increasing exposure to a diversity of foraging places and patterns, can further augment feeding efficiency.",2008-04-03,https://www.semanticscholar.org/paper/4a49d288a4fd6cfbdf5abf8a7bbb8556903cca2d,
3537,Object-Oriented Programming without Inheritance (Invited Talk),"Object-oriented programming is often characterized as encapsulation plus polymorphism plus inheritance. The original Simula67 demonstrated that we could do without encapsulation and Kristen Nygaard insisted that some OOP could be done without inheritance. I present generic programming as providing encapsulation plus polymorphism. In C++, this view is directly supported by language facilities, such as classes, templates and (only recently) concepts. I show a range of type-and-resource-safe techniques covering a wide range of applications including containers, algebraic concepts, and numerical and non-numerical algorithms.",,https://www.semanticscholar.org/paper/1cd7db9c5b0fa292941a834a8cda55b7a8d82cd2,European Conference on Object-Oriented Programming
1334,Beyond the CDMS-II Dark Matter Search: SuperCDMS,"Presently the CDMS-II collaboration's Weakly Interacting Massive Particle (WIMP) search at the Soudan Underground Laboratory sets the most stringent exclusion limits of any WIMP cold dark matter direct-detection experiment. To extend our reach further, to WIMP-nucleon cross sections in the range $10^{-46} - 10^{-44}$cm$^2$, we propose SuperCDMS, which would take advantage of a very deep site. One promising site is the recently approved SNOLab facility in Canada. In this paper we will present our overall plan, identify primary issues, and set the goals that need to be met prior to embarking upon each phase of SuperCDMS.",2005-03-01,https://www.semanticscholar.org/paper/176d2689e459a6c23d341c129c18430cbbaa2c94,
3552,Rejuvenating C++ programs through demacrofication,"We describe how legacy C++ programs can be rejuvenated using C++11 features such as generalized constant expressions, perfect forwarding, and lambda expressions. In general, this work develops a correspondence between different kinds of macros and the C++ declarations to which they should be transformed. We have created a set of demacrofication tools to assist a developer in the rejuvenation of C++ programs. To evaluate the work, we have applied the rejuvenation tools to a number of C++ libraries to assess the extent to which these libraries might be improved by demacrofication. Results indicate that between 68 and 98% of potentially refactorable macros could be transformed into C++11 declarations. Additional experiments demonstrate why these numbers are not readily achieved using fully automated rejuvenation tools. We also discuss some techniques to further assist in automating rejuvenation process.",2012-09-23,https://www.semanticscholar.org/paper/de91c41c6335f1541d2c56b25711629ce7f8b552,International Conference on Smart Multimedia
340,Three-Player Games Are Hard,"We prove that computing a Nash equilibrium in a 3-player game is PPAD-complete, solving a problem left open in (2).",,https://www.semanticscholar.org/paper/ec72f622b8c5041a9ae7150220b5525283d612d1,Electron. Colloquium Comput. Complex.
2787,"Role of skin and gut microbiota in the pathogenesis of psoriasis, an inflammatory skin disease",,2020-06-01,https://www.semanticscholar.org/paper/a1a55251af8869f143444ab813cada3a2ba56031,Medicine in Microecology
1685,The Population Posterior and Bayesian Inference on Streams,"Many modern data analysis problems involve inferences from streaming data. However, streaming data is not easily amenable to the standard probabilistic modeling approaches, which assume that we condition on finite data. We develop population variational Bayes, a new approach for using Bayesian modeling to analyze streams of data. It approximates a new type of distribution, the population posterior, which combines the notion of a population distribution of the data with Bayesian inference in a probabilistic model. We study our method with latent Dirichlet allocation and Dirichlet process mixtures on several large-scale data sets.",2015-07-19,https://www.semanticscholar.org/paper/9195ed23cc16b9bfd3528ac94c8271b01320b6d3,
3476,Scheduling multi-task multi-agent systems,We present a centralized and a distributed algorithms for scheduling multi-task agents in heterogeneous networks. Our centralized algorithm has an upper bound on the overall completion time and is used as a module in the distributed algorithm. Extensive simulations show promising results.,2001-05-28,https://www.semanticscholar.org/paper/323128767bbf6894e2d57f7ebc65fd998c316bb2,International Conference on Autonomous Agents
3704,Task Bias in Vision-Language Models,"Incidental supervision from language has become a popular approach for learning generic visual representations that can be prompted to perform many recognition tasks in computer vision. We conduct an in-depth exploration of the CLIP model and show that its visual representation is often strongly biased towards solving some tasks more than others. Moreover, which task the representation will be biased towards is unpredictable, with little consistency across images. To resolve this task bias, we show how to learn a visual prompt that guides the representation towards features relevant to their task of interest. Our results show that these visual prompts can be independent of the input image and still effectively provide a conditioning mechanism to steer visual representations towards the desired task.",2022-12-08,https://www.semanticscholar.org/paper/d857fa1e47283da17b72f8e59c377c7aa72bae78,arXiv.org
3457,A parallel algorithm for approximating the minimum cycle cover,,,https://www.semanticscholar.org/paper/929a33c5ec2083432e6348995e0e0115cdc527a4,Algorithmica
2440,Augmented reality task guidance for international space station stowage operations,"Built at NASA Johnson Space Center (JSC) and Columbia University and tested in JSC's full-scale mockup of the International Space Station (ISS), StowageApp is a prototype for the future of conducting cargo operations in space. StowageApp dynamically guides astronauts as they complete stowage tasks, packing and unpacking cargo.",2018-08-12,https://www.semanticscholar.org/paper/a4138c11c6c68ebdaf64b47416196bf1784ff6ab,"ACM SIGGRAPH 2018 Virtual, Augmented, and Mixed Reality"
543,The Discrete Geodesic Problem,"We present an algorithm for determining the shortest path between a source and a destination on an arbitrary (possibly nonconvex) polyhedral surface. The path is constrained to lie on the surface, and distances are measured according to the Euclidean metric. Our algorithm runs in time O(n log n) and requires O(n2) space, where n is the number ofedges ofthe surface. Afterwe run our algorithm, the distance from the source to any other destination may be determined using standard techniques in time O(log n) by locating the destination in the subdivision created by the algorithm. The actual shortest path from the source to a destination can be reported in time O(k+ log n), where k is the number of faces crossed by the path. The algorithm generalizes to the case of multiple source points to build the Voronoi diagram on the surface, where n is now the maximum of the number of vertices and the number of sources.",1987-08-01,https://www.semanticscholar.org/paper/f8902dc723ac2a49ee52efbc58947c21f8d0970b,SIAM journal on computing (Print)
425,Computational complexity in the life sciences (invited talk),,1998-08-28,https://www.semanticscholar.org/paper/79e17780669e0981862ec7e42ec1f7ff40d0b06d,
3273,Linking social environment and stress physiology in feral mares (Equus caballus): group transfers elevate fecal cortisol levels.,,2014-01-15,https://www.semanticscholar.org/paper/8d0de1904552631f2f3a505a1fe9d90935d637c7,General and Comparative Endocrinology
2819,Galectins in regulation of apoptosis.,,2011-12-19,https://www.semanticscholar.org/paper/696005a293433b9ad15993ffe99ba0c165d53829,Advances in Experimental Medicine and Biology
1959,Efficient development of cycle time response surfaces using progressive simulation metamodeling,"In semiconductor manufacturing, hot lots are to provide marketing and engineering with extra flexibility regarding delivery lead times, and in turn enhance its competitive advantages against other companies. On the other hand, hot lots are among major sources of disruption of the smoothness of the manufacturing flow. They can lead to a significant increase of cycle time of normal lots, and in turn result in delayed delivery times and serious service deteriorations. Due to the complex nature of semiconductor manufacturing, evaluating the impact of hot lots on the cycle time of normal lots presents major challenges. In this paper, we propose a methodology, called progressive simulation metamodelling (PSM), that allows for an efficient development of the response surface between the cycle time of normal lots and the percentage of hot lots in semiconductor manufacturing. The response surface generated by the proposed PSM is like an easy-to-use analytical model, but with the fidelity of simulation that takes into account all important manufacturing details. The specially-designed mechanisms, including identifying the critical region and sequentially adding design points in the critical region, further grants PSM computational advantages compared to the traditional response surface method. An empirical study conducted in collaboration with a semiconductor company validates the viability of PSM in real settings.",2014-03-25,https://www.semanticscholar.org/paper/48ac6ca2404b349e7b596f490b8f56d3e672d2c9,
775,Multiway cuts in node weighted graphs,,,https://www.semanticscholar.org/paper/5151d92034ee4da74884be4c6350cbb3928a7eca,J. Algorithms
2575,Content-aware scrolling,"Scrolling is used to navigate large information spaces on small screens, but is often too restrictive or cumbersome to use for particular types of content, such as multi-page, multi-column documents. To address this problem, we introduce content-aware scrolling (CAS), an approach that takes into account various characteristics of document content to determine scrolling direction, speed, and zoom. We also present the CAS widget, which supports scrolling through a content-aware path using traditional scrolling methods, demonstrating the advantages of making a traditional technique content-aware.",2006-10-15,https://www.semanticscholar.org/paper/9c39799b5a4364905fdb66caa6c06b3bb5efee44,ACM Symposium on User Interface Software and Technology
2682,A standard reference model for intelligent multimedia presentation systems,,1997-12-01,https://www.semanticscholar.org/paper/16143a7302880cdd423131b00167ede701dd75a8,Comput. Stand. Interfaces
3504,Improved approximation algorithms for minsum criteria,,,https://www.semanticscholar.org/paper/22e6bfe203d8b4c2f3b7368c4c6ae763ac466e5f,
850,The Proof That N,"is similar to the proof of Theorem 2.4 ((rst direction), together with the second part of Lemma 4.3 that guarantees that D 1 (e) = D 1 (e f) D 1 (e g). Using the last two theorems, we get Let us now brieey discuss the case of computing general relations and not necessarily functions. The equality in Lemma 4.3 part (1), does not hold anymore. However, by FKN91] the two sides cannot be too far. As a result, Theorem 4.4 is changed as well and it claims: Let R and S be two relations. Then Simple lower bound for monotone clique using a communication game"", Information Processing Letters, 41, pp. 221-226 (1992). K71] V. Khrapchenko, \A method of determining lower bounds for the complexity of-schemes"", Now, we can come back to the proof of Theorem 4.1. To analyze the two-round deterministic communication complexity of a relation R, we deene the following hypergraph H 2 R. The vertices are again all the pairs in f0; 1g n f0; 1g n. The hyperedges are all the rectangles of the form A f0; 1g n , where A f0; 1g n. Now, for each such hyperedge e we deene its weight to be D 1 (e), the one-way deterministic communication complexity of computing R on the sub-domain e. in the opposite direction, let us concentrate for a while on the case of computing functions. We need the following lemma.",,https://www.semanticscholar.org/paper/76349b29077d60ce3be9625185a5e2aaaad4c0fc,
693,The Smoothed Complexity of Policy Iteration for Markov Decision Processes,"We show subexponential lower bounds (i.e., 2Ω (nc)) on the smoothed complexity of the classical Howard’s Policy Iteration algorithm for Markov Decision Processes. The bounds hold for the total reward and the average reward criteria. The constructions are robust in the sense that the subexponential bound holds not only on the average for independent random perturbations of the MDP parameters (transition probabilities and rewards), but for all arbitrary perturbations within an inverse polynomial range. We show also an exponential lower bound on the worst-case complexity for the simple reachability objective.",2022-11-30,https://www.semanticscholar.org/paper/183e447b3101ac996c020d5d49cc1589d48fbde3,Symposium on the Theory of Computing
1670,The $χ$-Divergence for Approximate Inference,"Variational inference enables Bayesian analysis for complex probabilistic models with massive data sets. It works by positing a family of distributions and finding the member in the family that is closest to the posterior. While successful, variational methods can run into pathologies; for example, they typically underestimate posterior uncertainty. We propose CHI-VI, a complementary algorithm to traditional variational inference with KL($q$ || $p$) and an alternative algorithm to EP. CHI-VI is a black box algorithm that minimizes the $\chi$-divergence from the posterior to the family of approximating distributions. In EP, only local minimization of the KL($p$ || $q$) objective is possible. In contrast, CHI-VI optimizes a well-defined global objective. It directly minimizes an upper bound to the model evidence that equivalently minimizes the $\chi$-divergence. In experiments, we illustrate the utility of the upper bound for sandwich estimating the model evidence. We also compare several probabilistic models and a Cox process for basketball data. We find CHI-VI often yields better classification error rates and better posterior uncertainty.",2016-11-01,https://www.semanticscholar.org/paper/feb8736dbeb1b6d4049511bd461b2fef37b64a69,arXiv.org
3478,Implementation of a PTAS for Scheduling with Release Dates,,2001-01-05,https://www.semanticscholar.org/paper/b04cce450d832fef98e4d1321dd646434ec7f081,Workshop on Algorithm Engineering and Experimentation
285,The myth of the folk theorem,"A well-known result in game theory known as ""the Folk Theorem"" suggests that finding Nash equilibria in repeated games should be easier than in one-shot games. In contrast, we show that the problem of finding any (approximate) Nash equilibrium for a three-player infinitely-repeated game is computationally intractable (even when all payoffs are in {-1,0,1}), unless all of PPAD can be solved in randomized polynomial time. This is done by showing that finding Nash equilibria of (k+1)-player infinitely-repeated games is as hard as finding Nash equilibria of k-player one-shot games, for which PPAD-hardness is known (Daskalakis, Goldberg and Papadimitriou, 2006; Chen, Deng and Teng, 2006; Chen, Teng and Valiant, 2007). This also explains why no computationally-efficient learning dynamics, such as the ""no regret"" algorithms, can be ""rational"" (in general games with three or more players) in the sense that, when one's opponents use such a strategy, it is not in general a best reply to follow suit.",2008-05-17,https://www.semanticscholar.org/paper/3ef9fdcf15411cb175c966102f637c8e1a2d1b0f,Games Econ. Behav.
2617,SenseShapes: using statistical geometry for object selection in a multimodal augmented reality,"We introduce a set of statistical geometric tools designed to identify the objects being manipulated through speech and gesture in a multimodal augmented reality system. SenseShapes are volumetric regions of interest that can be attached to parts of the user's body to provide valuable information about the user's interaction with objects. To assist in object selection, we generate a rich set of statistical data and dynamically choose which data to consider based on the current situation.",2003-10-07,https://www.semanticscholar.org/paper/5bca94396a4f7739eb682413e57a325d5dbaaf84,"The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings."
2992,Peptidomimetic-based inhibitors of farnesyltransferase,,,https://www.semanticscholar.org/paper/15517a05e7fb1a51a410f12ba0e7591aa58b79fd,
255,Economies with non-convex production and complexity equilibria,"The convexity assumptions required for the Arrow-Debreu theorem are reasonable and realistic for preferences; however, they are highly problematic for production because they rule out economies of scale. We take a complexity-theoretic look at economies with non-convex production. It is known that in such markets equilibrium prices may not exist; we show that it is an intractable problem to achieve Pareto efficiency, the fundamental objective achieved by equilibrium prices. The same is true for core efficiency or any one of an array of concepts of stability, with the degree of intractability ranging from F Δ2P-completeness to PSPACE-hardness. We also identify a novel phenomenon that we call complexity equilibrium in which agents quiesce, not because there is no way for any one of group of them to improve their situation, but because discovering the changes necessary for (individual or group) improvement is intractable. In fact, we exhibit a somewhat natural distribution of economies that has an average-case hard complexity equilibrium.",2011-06-05,https://www.semanticscholar.org/paper/88748063316e36a8443f2415588adde2367dea99,ACM Conference on Economics and Computation
1723,1 Introduction to Mixed Membership Models and Methods,1.1 Historical Developments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.2 A General Formulation for Mixed Membership Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.3 Advantages of Mixed Membership Models in Applied Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1.4 Theoretical Issues with Mixed Membership Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 1.4.1 General Issues Inherent to Mixtures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10,,https://www.semanticscholar.org/paper/f0f1292719f02a59990a7fd4a35b97de85be1c11,
2414,Precueing Object Placement and Orientation for Manual Tasks in Augmented Reality,"When a user is performing a manual task, AR or VR can provide information about the current subtask (cueing) and upcoming subtasks (precueing) that makes them easier and faster to complete. Previous research on cueing and precueing in AR and VR has focused on path-following tasks requiring simple actions at each of a series of locations, such as pushing a button or just visiting. We consider a more complex task, whose subtasks involve moving to and picking up an item, moving that item to a designated place while rotating it to a specific angle, and depositing it. We conducted two user studies to examine how people accomplish this task while wearing an AR headset, guided by different visualizations that cue and precue movement and rotation. Participants performed best when given movement information for two successive subtasks and rotation information for a single subtask. In addition, participants performed best when the rotation visualization was split across the manipulated object and its destination.",2022-09-01,https://www.semanticscholar.org/paper/73e52edbb12665f689ab04807e686d37bb384543,IEEE Transactions on Visualization and Computer Graphics
1502,Measurement of the W boson helicity in top quark decay at D 0,"We present a measurement of the fraction f+ of right-handed W bosons produced in top quark decays, based on a candidate sample of tt̄ events in the `+jets and dilepton decay channels corresponding to an integrated luminosity of 370 pb collected by the DØ detector at the Fermilab Tevatron pp̄ Collider at √ s = 1.96 TeV. We reconstruct the decay angle θ for each lepton. By comparing the cos θ distribution from the data with those for the expected background and signal for various values of f+, we find f+ = 0.056±0.080 (stat)±0.057 (syst). (f+ < 0.23 at 95% C.L.), consistent with the standard model prediction of f+ = 3.6 × 10. PACS numbers: 14.65.Ha, 14.70.Fm, 12.15.Ji, 12.38.Qk, 13.38.Be, 13.88.+e",,https://www.semanticscholar.org/paper/66a1681a191f72486e02db6b252376722d34d4a2,
3501,Experimental study of minimum cut algorithms,"Recently, several new algorithms have been developed for the minimum cut problem that substantially improve worst-case time bounds for the problem. These algorithms are very different from the earlier ones and from each other. We conduct an experimental evaluation of the relative performance of these algorithms. In the process, we develop heuristics and data structures that substantially improve practical performance of the algorithms. We also develop problem families for testing minimum cut algorithms. Our work leads to a better understanding of practical performance of the minimum cut algorithms and produces very efficient codes for the problem.",1997-01-05,https://www.semanticscholar.org/paper/dddf141709c2d07d9ce77c3a2ff79cbe2434b47d,ACM-SIAM Symposium on Discrete Algorithms
2971,"Gene expression changes with age in skin, adipose tissue, blood and brain",,2013-07-26,https://www.semanticscholar.org/paper/cc7224e106d5ebe2ac66444dc14056cacb27acb4,Genome Biology
2154,A Randomized Singular Value Decomposition Algorithm for Image Processing Applications,"The main contribution of this paper is to demonstrate that a new randomized SVD algorithm, proposed by Drineas et. al. in [4], is not only of theoretical interest but also a viable and fast alternative to traditional SVD algorithms in applications (e.g. image processing). This algorithm samples a constant number of rows (or columns) of the matrix, scales them appropriately to form a small matrix, say S, and then computes the SVD of S (which is a good approximation to the SVD of the original matrix). We experimentally evaluate the accuracy and speed of this algorithm for image matrices, using various probability distributions to perform the sampling.",,https://www.semanticscholar.org/paper/e881439705f383468b276415b9d01d0059c1d3e5,
2778,"Intensity-dependent gamma electrical stimulation regulates microglial activation, reduces beta-amyloid load, and facilitates memory in a mouse model of Alzheimer’s disease",,2023-07-28,https://www.semanticscholar.org/paper/5eeba8728650e8a9443e5532e5ed1489ada8e0e4,Cell & Bioscience
2269,"The Mitochondrial Network of Human Neutrophils: Role in Chemotaxis, Phagocytosis, Respiratory Burst Activation, and Commitment to Apoptosis 1","It is commonly assumed that human neutrophils possess few, if any, functional mitochondria and that they do not depend on these organelles for cell function. We have used the fluorescent mitochondrial indicators, JC-1, MitoTracker Red, and dihydrorhodamine 123 to show that live neutrophils possess a complex mitochondrial network that extends through the cytoplasm. The membrane potential of these mitochondria was rapidly (within 2 min) disrupted by the addition of FCCP (IC50 = 20 nM), but not by the Fo-ATPase inhibitor, oligomycin (at up to 7 μg/ml). However, inhibition of mitochondrial function with both agents resulted in cell shape changes. Neither activation of the respiratory burst nor phagocytosis of either latex particles or serum-opsonized Staphylococcus aureus was affected by the addition of FCCP or oligomycin. However, FCCP inhibited chemotaxis at concentrations that paralleled disruption of mitochondrial membrane potential. Furthermore, prolonged (2-h) incubation with oligomycin resulted in an impaired ability to activate a respiratory burst and also inhibited chemotaxis. These observations indicate that intact mitochondrial function is required to sustain some neutrophil functions, but not for the rapid initiation of the respiratory burst or phagocytosis. Loss of mitochondrial membrane potential was a very early marker for commitment of neutrophils into apoptosis and preceded the appearance of phosphatidylserine on the cell surface. However, inhibition of mitochondrial function did not accelerate the rate of neutrophil apoptosis. These data shed important insights into the hitherto unrecognized importance of mitochondria in the function of neutrophils during infection and inflammation.",2003-02-15,https://www.semanticscholar.org/paper/5941a8add4c97d55a0e63af4feac93619f6e3d8b,Journal of Immunology
3691,Representing Spatial Trajectories as Distributions,"We introduce a representation learning framework for spatial trajectories. We represent partial observations of trajectories as probability distributions in a learned latent space, which characterize the uncertainty about unobserved parts of the trajectory. Our framework allows us to obtain samples from a trajectory for any continuous point in time, both interpolating and extrapolating. Our flexible approach supports directly modifying specific attributes of a trajectory, such as its pace, as well as combining different partial observations into single representations. Experiments show our method's advantage over baselines in prediction tasks.",2022-10-04,https://www.semanticscholar.org/paper/1c2a3eec0d09ff66266c4484e19fe279aedba3c0,Neural Information Processing Systems
1134,Search for CP violation in Bs 0 → μ + Ds-X decays in pp̅ collisions at √ s = 1 . 96,"Disclaimer/Complaints regulations If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. In case of a legitimate complaint, the Library will make the material inaccessible and/or remove it from the website. Please Ask the Library: https://uba.uva.nl/en/contact, or a letter to: Library of the University of Amsterdam, Secretariat, Singel 425, 1012 WP Amsterdam, The Netherlands. You will be contacted as soon as possible.",,https://www.semanticscholar.org/paper/bb385db6c0f078088219823cb82c6fef14a2a261,
1772,Collaborative topic modeling for recommending scientific articles,"Researchers have access to large online archives of scientific articles. As a consequence, finding relevant papers has become more difficult. Newly formed online communities of researchers sharing citations provides a new way to solve this problem. In this paper, we develop an algorithm to recommend scientific articles to users of an online community. Our approach combines the merits of traditional collaborative filtering and probabilistic topic modeling. It provides an interpretable latent structure for users and items, and can form recommendations about both existing and newly published articles. We study a large subset of data from CiteULike, a bibliography sharing service, and show that our algorithm provides a more effective recommender system than traditional collaborative filtering.",2011-08-21,https://www.semanticscholar.org/paper/92eb167f30ad59f6949667021760eb41078cf85c,Knowledge Discovery and Data Mining
1800,Dirichlet Process Mixtures of Generalized Linear Models,"We propose Dirichlet Process mixtures of Generalized Linear Models (DP-GLM), a new class of methods for nonparametric regression. Given a data set of input-response pairs, the DP-GLM produces a global model of the joint distribution through a mixture of local generalized linear models. DP-GLMs allow both continuous and categorical inputs, and can model the same class of responses that can be modeled with a generalized linear model. We study the properties of the DP-GLM, and show why it provides better predictions and density estimates than existing Dirichlet process mixture regression models. We give conditions for weak consistency of the joint distribution and pointwise consistency of the regression estimate.",2009-09-28,https://www.semanticscholar.org/paper/49be9a3bd3d59a1ff2399213594af003eec82d45,Journal of machine learning research
954,Development of a novel hyaluronic acid membrane for the treatment of ocular surface diseases,,2021-01-27,https://www.semanticscholar.org/paper/8f649a805d6ebe1249e0d077a4546e96d7e5182e,Scientific Reports
1994,Global Unichip Corporation (A),,2012-10-16,https://www.semanticscholar.org/paper/190fb352a51bc6dd7881f8ca73b779e6b71f3c15,
2020,Manufacturing Intelligence to Exploit the Value of Production and Tool Data to Reduce Cycle Time,"Cycle time reduction is crucial for semiconductor wafer fabrication companies to maintain competitive advantages as the semiconductor industry is becoming more dynamic and changing faster. According to Little's Law, while maintaining the same throughput level, the reduction in Work-in-Process (WIP) will result in cycle time reduction. On one hand, the existing queueing models for predicting the WIP of tool sets in wafer fabrication facilities (fab) have limitations in real settings. On the other hand, little research has been done to predict the WIP of tool sets with tool dedication and waiting time constraint so as to control the corresponding WIP levels of various tool sets to reduce cycle time without affecting throughput. This study aims to fill the gap by proposing a manufacturing intelligence (MI) approach based on neural networks (NNs) to exploit the value of the wealthy production data and tool data for predicting the WIP levels of the tool sets for cycle time reduction. To validate this approach, empirical data were collected and analyzed in a leading semiconductor company. The comparison results have shown practical viability of this approach. Furthermore, the proposed approach can identify and improve the critical input factors for reducing the WIP to reduce cycle time in a fab.",,https://www.semanticscholar.org/paper/e5627f0efb618d7fb2766135c6fed27a7bef3b41,IEEE Transactions on Automation Science and Engineering
1195,Search for ZZ and Zgamma* production in pp[over ] collisions at square root s=1.96 TeV and limits on anomalous ZZZ and ZZgamma* couplings.,"We present a study of micro micro micro micro, eeee, and micro micro ee events using 1 fb(-1) of data collected with the D0 detector at the Fermilab Tevatron pp[over ] Collider at square root s=1.96 TeV. Requiring the lepton pair masses to be greater than 30 GeV, we observe one event, consistent with the expected background of 0.13+/-0.03 events and with the predicted standard model ZZ and Zgamma* production of 1.71+/-0.15 events. We set an upper limit on the ZZ and Zgamma* cross section of 4.4 pb at the 95% C.L. We also derive limits on anomalous neutral trilinear ZZZ and ZZgamma* gauge couplings. The one-parameter 95% C.L. coupling limits with a form-factor scale Lambda=1.2 TeV are -0.28<f(40)(Z)<0.28, -0.31<f(50)(Z)<0.29, -0.26<f(40)(gamma)<0.26, and -0.30<f(50)(gamma)<0.28.",,https://www.semanticscholar.org/paper/02f6d1f23c3552cb23c49da51fb76df3512b005e,Physical Review Letters
459,Reversible Simulation of Space-Bounded Computations,,1995-05-29,https://www.semanticscholar.org/paper/fb334c05d3a3b7d2d8362118acfa8bc9f7ace2e5,Theoretical Computer Science
277,Algorithmic Game Theory: A Snapshot,,2009-07-06,https://www.semanticscholar.org/paper/9339a426c2a437d441a96744e5a9879d0099e22d,"International Colloquium on Automata, Languages and Programming"
320,A note on approximate Nash equilibria,,2006-12-15,https://www.semanticscholar.org/paper/6d2a49d83d28b383eb846f385dccbbde1146bc64,Theoretical Computer Science
3152,Examining VMware,"VMware is a virtual-machine platform that provides an abstraction of x86 PC hardware so that multiple operating systems can run unmodified and at the same time on a standard PC. For developers, this means you can run multiple development environments on your desktop without rebooting or repartitioning. In the process, you can isolate and protect operating environments (and the applications and data that are running in them), as well as interoperate among operating systems for networking, device/file sharing, and cut-andpaste. For users, VMware makes it possible to run Windows applications with Linux. VMware comes in two flavors, depending on the operating system running on the user’s Pentium-based (or compatible) PC -VMware for Linux, and VMware for Windows NT/2000. VMware installs like an application program, requiring no special hardware support.",,https://www.semanticscholar.org/paper/382c83c7d987ca8d71adbd0070172027accd990e,
3692,FLEX: Full-Body Grasping Without Full-Body Grasps,"Synthesizing 3D human avatars interacting realistically with a scene is an important problem with applications in AR/VR, video games, and robotics. Towards this goal, we address the task of generating a virtual human – hands and full body – grasping everyday objects. Existing methods approach this problem by collecting a 3D dataset of humans interacting with objects and training on this data. However, 1) these methods do not generalize to different object positions and orientations or to the presence of furniture in the scene, and 2) the diversity of their generated full-body poses is very limited. In this work, we address all the above challenges to generate realistic, diverse full-body grasps in everyday scenes without requiring any 3D full-body grasping data. Our key insight is to leverage the existence of both full-body pose and hand-grasping priors, composing them using 3D geometrical constraints to obtain full-body grasps. We empirically validate that these constraints can generate a variety of feasible human grasps that are superior to baselines both quantitatively and qualitatively. See our webpage for more details: flex.cs.columbia.edu.",2022-11-22,https://www.semanticscholar.org/paper/1f1fd049a174e521e417596946e64a37290ec251,Computer Vision and Pattern Recognition
220,Cortical Learning via Prediction,"What is the mechanism of learning in the brain? Despite breathtaking advances in neuroscience, and in machine learning, we do not seem close to an answer. Using Valiant’s neuronal model as a foundation, we introduce PJOIN (for “predictive join”), a primitive that combines association and prediction. We show that PJOIN can be implemented naturally in Valiant’s conservative, formal model of cortical computation. Using PJOIN — and almost nothing else — we give a simple algorithm for unsupervised learning of arbitrary ensembles of binary patterns (solving an open problem in Valiant’s work). This algorithm relies crucially on prediction, and entails significant downward traffic (“feedback”) while parsing stimuli. Prediction and feedback are well-known features of neural cognition and, as far as we know, this is the first theoretical prediction of their essential role in learning.",2015-06-26,https://www.semanticscholar.org/paper/da88528713f9be28c923931f38eca36617397b6e,Annual Conference Computational Learning Theory
2131,Method and system for preparing statement,"PURPOSE: To provide a method and a system with which a statement interactive session to be processed by an auxiliary program for performing work setting and statement adjusting work and a statement preparing operation for defining a batch program for preparing a final printing statement are made into subsets and controlled. CONSTITUTION: While using a profile managing mechanism for allocating a system managing profile, including a statement group cycle profile, plural statements are divided into groups according to a cycle for preparation and processing, so that the statement preparation work can be continuously performed in parallel with overlapped statement cycles. A statement interactive session work station and a host are provided, and the selection of the attendants managed by the profile can be made of the statement in the statement cycle requiring the adjusting work of data including image data. COPYRIGHT: (C)1995,JPO",1994-11-22,https://www.semanticscholar.org/paper/5ab29a6ae10a7efe2bf2375832507860d40cf369,
3734,Visual Hide and Seek,"We train embodied agents to play Visual Hide and Seek where a prey must navigate in a simulated environment in order to avoid capture from a predator. We place a variety of obstacles in the environment for the prey to hide behind, and we only give the agents partial observations of their environment using an egocentric perspective. Although we train the model to play this game from scratch, experiments and visualizations suggest that the agent learns to predict its own visibility in the environment. Furthermore, we quantitatively analyze how agent weaknesses, such as slower speed, effect the learned policy. Our results suggest that, although agent weaknesses make the learning problem more challenging, they also cause more useful features to be learned. Our project website is available at: this http URL ~bchen/visualhideseek/.",2019-09-25,https://www.semanticscholar.org/paper/2af4c764352d911641e96c4a52093b2fdeba6a61,IEEE Symposium on Artificial Life
2443,Remote collaboration in AR and VR using virtual replicas,"In many complex tasks, a remote subject-matter expert may need to assist a local user, to guide their actions on objects in the local user's environment. However, effective spatial referencing and action demonstration in a remote physical environment can be challenging. We demonstrate an approach that uses Virtual Reality (VR) or Augmented Reality (AR) for the remote expert, and AR for the local user, each wearing a stereo head-worn display (HWD). Our approach allows the remote expert to create and manipulate virtual replicas of physical objects in the local environment to refer to parts of those physical objects and to indicate actions on them. This can be especially useful for parts that are occluded or difficult to access. The remote expert can demonstrate actions in 3D by manipulating virtual replicas, supported by constraints and annotations, and point in 3D to portions of virtual replicas to annotate them.",2017-07-30,https://www.semanticscholar.org/paper/10f0b32a12d04d48c4eb4b09f135e9465ea145f0,SIGGRAPH VR Village
958,Relationship between Three-Dimensional Magnetic Resonance Imaging Eyeball Shape and Optic Nerve Head Morphology,,2021-04-01,https://www.semanticscholar.org/paper/e2c546a87550b8baa8c156d9c4cfb0389a2b33c1,"Ophthalmology (Rochester, Minn.)"
3627,Making a vector fit for a standard,,1996-05-01,https://www.semanticscholar.org/paper/3ec9d13d788118152063927b6a3f161be232e10a,
3700,Robust Perception through Equivariance,"Deep networks for computer vision are not reliable when they encounter adversarial examples. In this paper, we introduce a framework that uses the dense intrinsic constraints in natural images to robustify inference. By introducing constraints at inference time, we can shift the burden of robustness from training to the inference algorithm, thereby allowing the model to adjust dynamically to each individual image's unique and potentially novel characteristics at inference time. Among different constraints, we find that equivariance-based constraints are most effective, because they allow dense constraints in the feature space without overly constraining the representation at a fine-grained level. Our theoretical results validate the importance of having such dense constraints at inference time. Our empirical experiments show that restoring feature equivariance at inference time defends against worst-case adversarial perturbations. The method obtains improved adversarial robustness on four datasets (ImageNet, Cityscapes, PASCAL VOC, and MS-COCO) on image recognition, semantic segmentation, and instance segmentation tasks. Project page is available at equi4robust.cs.columbia.edu.",2022-12-12,https://www.semanticscholar.org/paper/82d19ceba300875f108a91539ca555dfad142a99,International Conference on Machine Learning
3240,Physiology modulates social flexibility and collective behaviour in equids and other large ungulates,"Though morphologically very similar, equids across the extant species occupy ecological niches that are surprisingly non-overlapping. Occupancy of these distinct niches appears related to subtle physiological and behavioural adaptations which, in turn, correspond to significant differences in the social behaviours and emergent social systems characterizing the different species. Although instances of intraspecific behavioural variation in equids demonstrate that the same body plan can support a range of social structures, each of these morphologically similar species generally shows robust fidelity to its evolved social system. The pattern suggests a subtle relationship between physiological phenotypes and behavioural flexibility. While environmental conditions can vary widely within relatively short temporal or spatial scales, physiological changes and changes to the behaviours that regulate physiological processes, are constrained to longer cycles of adaptation. Physiology is then the limiting variable in the interaction between ecological variation and behavioural and socio-structural flexibility. Behavioural and socio-structural flexibility, in turn, will generate important feedbacks that will govern physiological function, thus creating a coupled web of interactions that can lead to changes in individual and collective behaviour. Longitudinal studies of equid and other large-bodied ungulate populations under environmental stress, such as those discussed here, may offer the best opportunities for researchers to examine, in real time, the interplay between individual behavioural plasticity, socio-structural flexibility, and the physiological and genetic changes that together produce adaptive change. This article is part of the themed issue ‘Physiological determinants of social behaviour in animals’.",2017-08-19,https://www.semanticscholar.org/paper/85340fba23be41562d8ffa24840666a11c901bd2,Philosophical Transactions of the Royal Society B: Biological Sciences
2186,Anti-neutrophil cytoplasmic antibodies and their clinical significance,,2018-03-10,https://www.semanticscholar.org/paper/80f12a848fc47b4fe690ee045d67fc319e900d86,Clinical Rheumatology
1881,Dynamic Support Vector Regression Control System for Overlay Error Compensation With Stochastic Metrology Delay,"This study aims to develop a robust monitoring system for advanced control and compensation of the overlay errors based on <inline-formula> <tex-math notation=""LaTeX"">$\boldsymbol {\epsilon }$ </tex-math></inline-formula>-insensitive support vector regression (SVR), considering metrology delay. The proposed <inline-formula> <tex-math notation=""LaTeX"">$\boldsymbol {\epsilon }$ </tex-math></inline-formula>-insensitive SVR control system has the ability to solve quadratic optimization problems in real settings. To investigate the consistency and reliability of the proposed algorithm, a simulation study based on empirical data was conducted to validate the solution quality enhancement by the proposed approach. The stability of the system under metrology delay was investigated when Lyapunov stability function takes place as the kernel function of the <inline-formula> <tex-math notation=""LaTeX"">$\boldsymbol {\epsilon }$ </tex-math></inline-formula>-insensitive SVR optimization system. For sensitivity analysis, we compared and analyzed the effect of noise and time-varying metrology delay, within an online process with a simulation study based on empirical data. This approach can effectively reduce the misalignment of the overlay errors through the self-tuning process of <inline-formula> <tex-math notation=""LaTeX"">$\boldsymbol {\epsilon }$ </tex-math></inline-formula>-insensitive SVR and provide real-time decision aid for process engineers. <italic>Note to Practitioners</italic>—In practice, there are dynamic metrology delays that have not been adequately addressed. This study developed a robust monitoring system that can consider metrology delay for advanced control and effective compensation of the overlay errors. A study based on empirical data has validated the practical viability of the proposed approach. Indeed, the proposed algorithm can obtain a high degree of reliability for the measurement data in the complicated semiconductor fabrication process. Indeed, the developed solution is implemented in real practice.",2020-01-01,https://www.semanticscholar.org/paper/00318e348c2e51e901c8c404fc5ea51d03332701,IEEE Transactions on Automation Science and Engineering
39,Classification-aware hidden-web text database selection,"Many valuable text databases on the web have noncrawlable contents that are “hidden” behind search interfaces. Metasearchers are helpful tools for searching over multiple such “hidden-web” text databases at once through a unified query interface. An important step in the metasearching process is database selection, or determining which databases are the most relevant for a given user query. The state-of-the-art database selection techniques rely on statistical summaries of the database contents, generally including the database vocabulary and associated word frequencies. Unfortunately, hidden-web text databases typically do not export such summaries, so previous research has developed algorithms for constructing approximate content summaries from document samples extracted from the databases via querying. We present a novel “focused-probing” sampling algorithm that detects the topics covered in a database and adaptively extracts documents that are representative of the topic coverage of the database. Our algorithm is the first to construct content summaries that include the frequencies of the words in the database. Unfortunately, Zipf's law practically guarantees that for any relatively large database, content summaries built from moderately sized document samples will fail to cover many low-frequency words; in turn, incomplete content summaries might negatively affect the database selection process, especially for short queries with infrequent words. To enhance the sparse document samples and improve the database selection decisions, we exploit the fact that topically similar databases tend to have similar vocabularies, so samples extracted from databases with a similar topical focus can complement each other. We have developed two database selection algorithms that exploit this observation. The first algorithm proceeds hierarchically and selects the best categories for a query, and then sends the query to the appropriate databases in the chosen categories. The second algorithm uses “shrinkage,” a statistical technique for improving parameter estimation in the face of sparse data, to enhance the database content summaries with category-specific words. We describe how to modify existing database selection algorithms to adaptively decide (at runtime) whether shrinkage is beneficial for a query. A thorough evaluation over a variety of databases, including 315 real web databases as well as TREC data, suggests that the proposed sampling methods generate high-quality content summaries and that the database selection algorithms produce significantly more relevant database selection decisions and overall search results than existing algorithms.",2008-03-01,https://www.semanticscholar.org/paper/8e568809e0d8b46b9a0ab47de3996633c2035620,TOIS
610,On the complexity of integer programming,A simple proof that integer programming ts in X~ ~s given. The proof also estabhshes that there ~s a pseudopolynomial-tune algorithm for integer programmmg with any (fixed) number of constraints.,1981-10-01,https://www.semanticscholar.org/paper/c0a6a6dca0a5ca42a966595d15d202c8e4450b0d,JACM
3656,A better C,,1988-08-01,https://www.semanticscholar.org/paper/de5bf13554dd9c34757700fa27d171277877aea8,
1545,Variational Combinatorial Sequential Monte Carlo Methods for Bayesian Phylogenetic Inference,"Bayesian phylogenetic inference is often conducted via local or sequential search over topologies and branch lengths using algorithms such as random-walk Markov chain Monte Carlo (MCMC) or Combinatorial Sequential Monte Carlo (CSMC). However, when MCMC is used for evolutionary parameter learning, convergence requires long runs with inefficient exploration of the state space. We introduce Variational Combinatorial Sequential Monte Carlo (VCSMC), a powerful framework that establishes variational sequential search to learn distributions over intricate combinatorial structures. We then develop nested CSMC, an efficient proposal distribution for CSMC and prove that nested CSMC is an exact approximation to the (intractable) locally optimal proposal. We use nested CSMC to define a second objective, VNCSMC which yields tighter lower bounds than VCSMC. We show that VCSMC and VNCSMC are computationally efficient and explore higher probability spaces than existing methods on a range of tasks.",2021-05-31,https://www.semanticscholar.org/paper/89a587b76b2ad28417ec209c205848362df1ef8e,Conference on Uncertainty in Artificial Intelligence
1898,A Data Mining Approach for Optimizing Manufacturing Parameters of Wire Bonding Process in IC Packaging Industry and Empirical Study,"In the wire bonding process, different setting value of manufacturing parameters affect the quality of the solder joints and the speed of wire bonding significantly. And when a new product is introduced, it is difficult to quickly obtain effective parameters simply by relying on the experience of the engineers. The study aims to propose a data mining framework to help the IC packaging factories to increase production capacity by reducing the number of downtimes and speeding up the wire bonding time. The proposed data mining framework employed random forest and XGBoost method to classify the occurrence of defect, MARS algorithm to predict the wire bonding time, and genetic algorithm to search for the manufacturing parameters. By exploring the production data, the proposed framework finally provides a set of recommended manufacturing parameters of the second bonding process. This study cooperates with a leading assembly company in Taiwan to validate the proposed framework. The empirical result reveals that it improves the packaging yield by 0.03%. The domain engineers can also find parameters more systematically and quickly by the proposed framework.",2019-04-01,https://www.semanticscholar.org/paper/c5f806f700c84b052e28228bad9ff8de5ba97412,3D Structure from Multiple Images of Large-Scale Environments
2384,"Mitochondrial cytochromes of Acanthamoeba castellanii: Oscillatory accumulation of haemoproteins, immunological determinants and activity during the cell cycle",,1983-02-01,https://www.semanticscholar.org/paper/936dc187471f45756ffdb3590913be3f0da5233d,
2049,System on a Chip 2008: Global Unichip Corp.,,2008-06-20,https://www.semanticscholar.org/paper/6a3d68fa3670979213f3e34c33743a6c630327e9,
485,On platers with a bounded number of states,,,https://www.semanticscholar.org/paper/0523db2a1147ebb7cf48624fecd5b79ab310ed72,
2472,"Session details: Seeing, walking and being in spatial VEs",,2014-10-04,https://www.semanticscholar.org/paper/1fb64af1bc49106973612872888ce53e27a414d3,
503,Proceedings of the 32nd annual symposium on Foundations of computer science,,1991-09-01,https://www.semanticscholar.org/paper/aeed9466d0695120bf304cac86a42bf65f66a841,
702,Homa: An Efficient Topology and Route Management Approach in SD-WAN Overlays,"This paper presents an efficient topology and route management approach in Software-Defined Wide Area Networks (SD-WAN). Traditional WANs suffer from low utilization and lack of global view of the network. Therefore, during failures, topology/service/traffic changes, or new policy requirements, the system does not always converge to the global optimal state. Using Software Defined Networking architectures in WANs provides the opportunity to design WANs with higher fault tolerance, scalability, and manageability. We exploit the correlation matrix derived from monitoring system between the virtual links to infer the underlying route topology and propose a route update approach that minimizes the total route update cost on all flows. We formulate the problem as an integer linear programming optimization problem and provide a centralized control approach that minimizes the total cost while satisfying the quality of service (QoS) on all flows. Experimental results on real network topologies demonstrate the effectiveness of the proposed approach in terms of disruption cost and average disrupted flows.",2020-07-01,https://www.semanticscholar.org/paper/99194efa76b8afcfec823a3de3ba383bc689bb48,IEEE Conference on Computer Communications
3070,A2M: Access-Assured Mobile Desktop Computing,,2009-09-04,https://www.semanticscholar.org/paper/38a8e32cce656049487137aca0f6248f7339a643,Information Security Conference
1010,Retinal nerve fiber layer defect and cerebral small vessel disease.,"PURPOSE
To determine whether retinal nerve fiber layer defect (RNFLD) is associated with cerebral small vessel diseases (SVDs) and to identify risk factors for RNFLD.


METHODS
A total of 4421 Korean subjects who underwent health checkups including brain magnetic resonance imaging (MRI) and fundus photography between January 2008 and October 2009 were included in this study. Co-morbid systemic diseases including hypertension, diabetes mellitus, and stroke or ocular diseases were evaluated using detailed questionnaires and medical records. Two experienced ophthalmologists assessed RNFLD on fundus photographs, according to the definition that describes the condition as marked thinning or absence of retinal nerve fiber layer bundles.


RESULTS
RNFLD was detected in 238 of 4395 eligible subjects, and the estimated prevalence was 5.4%. Multivariate regression analysis results showed the prevalence of RNFLD to be significantly higher in hypertensive subjects (odds ratio [OR], 1.73; 95% confidence interval [CI], 1.28-2.34), in those with cerebral SVD based on MRI (OR, 1.58; 95% CI, 1.17-2.12), and in male (OR, 1.47; 95% CI, 1.10-1.96) and older subjects (OR, 1.02; 95% CI, 1.00-1.03). Among the cases of cerebral SVD, white matter lesions (WMLs) were associated with RNFLD, whereas lacunar infarctions were not significantly associated with it.


CONCLUSIONS
The results indicate that RNFLD may be related to the presence of cerebral SVD, particularly WMLs. Furthermore, being older and male and having hypertension increase the risk of RNFLD.",2011-08-01,https://www.semanticscholar.org/paper/9525138586f220e04398fc21edadc191949565d9,Investigative Ophthalmology and Visual Science
383,"Algorithms, Games, and the Internet (Extended Abstract)","Over the past fty years, researchers in Theoretical Computer Science have sought and achieved a productive foundational understanding of the von Neumann computer and its software, employing the mathematical tools of Logic and Combinatorics. The next half century appears now much more confusing (halfcenturies tend to look like that in the beginning). What computational artifact will be the object of the next great modeling adventure of our eld? And what mathematical tools will be handy in this endeavor?",,https://www.semanticscholar.org/paper/490e9fa242aa3a3281822dabf2c878b68229fa8c,
433,Decision-making by hierarchies of discordant agents,,1997-12-17,https://www.semanticscholar.org/paper/44e9a124ac393b0396c4f26d34551f90d9f7bba9,Mathematical programming
1921,A Conceptual Framework for “Industry 3.5” to Empower Intelligent Manufacturing and Case Studies,,,https://www.semanticscholar.org/paper/b3d73603b48b2fc6db283d7bfa1edd4d514a5713,
1813,Data-Driven Recomposition using the Hierarchical Dirichlet Process Hidden Markov Model,"Hidden Markov Models (HMMs) have been widely used in various audio analysis tasks such as speech recognition and genre classification. In this paper we show how HMMs can be used to synthesize new audio clips of unlimited length inspired by the temporal structure and perceptual content of a training recording or set of such recordings. We use Markov chain techniques similar to those that have long been used to generate symbolic data such as text and musical scores to instead generate sequences of continuous audio feature data that can then be transformed into audio using feature-based and concatenative synthesis techniques. Additionally, we explore the use of the Hierarchical Dirichlet Process HMM (HDP-HMM) for music, which sidesteps some difficulties with traditional HMMs, and extend the HDP-HMM to allow multiple song models to be trained simultaneously in a way that allows the blending of different models to produce output that is a hybrid of multiple input recordings.",2009-10-01,https://www.semanticscholar.org/paper/e651bf5fbf5aa2ca7fc3c7ce05d7c02f6fed1509,International Conference on Mathematics and Computing
3395,A System And Method For Task Management,"A system and method for task management are disclosed. The system may include an electronic device that allows users to enter a list of tasks as input. The system may further use a scheduling algorithm to schedule the entered tasks. The primary output of the system is a schedule assigning tasks for a predetermined interval days or even hours. The scheduling algorithm may compute an objective function defined by the user and take into account costs for each task. The method then involves minimizing total task costs subject to constraints, while efficiently scheduling the tasks across the time interval. The system is configured to improve via user inputs. The system and method disclosed may help users to schedule work they need to complete each day and in the future. As a result, users may be less overwhelmed by their list of tasks.",,https://www.semanticscholar.org/paper/2c201f3486371714cb8fa2f6fab79108a3947c3c,
3680,Objaverse-XL: A Universe of 10M+ 3D Objects,"Natural language processing and 2D vision models have attained remarkable proficiency on many tasks primarily by escalating the scale of training data. However, 3D vision tasks have not seen the same progress, in part due to the challenges of acquiring high-quality 3D data. In this work, we present Objaverse-XL, a dataset of over 10 million 3D objects. Our dataset comprises deduplicated 3D objects from a diverse set of sources, including manually designed objects, photogrammetry scans of landmarks and everyday items, and professional scans of historic and antique artifacts. Representing the largest scale and diversity in the realm of 3D datasets, Objaverse-XL enables significant new possibilities for 3D vision. Our experiments demonstrate the improvements enabled with the scale provided by Objaverse-XL. We show that by training Zero123 on novel view synthesis, utilizing over 100 million multi-view rendered images, we achieve strong zero-shot generalization abilities. We hope that releasing Objaverse-XL will enable further innovations in the field of 3D vision at scale.",2023-07-11,https://www.semanticscholar.org/paper/1b90e9e9734bed6b379ae87d688cb3b887baf597,arXiv.org
1544,A Proxy Variable View of Shared Confounding,"Causal inference from observational data can be biased by unobserved confounders. Confounders—the variables that affect both the treatments and the outcome—induce spurious non-causal correlations between the two. Without additional conditions, unobserved confounders generally make causal quantities hard to identify. In this paper, we focus on the setting where there are many treatments with shared confounding, and we study under what conditions is causal identification possible. The key observation is that we can view subsets of treatments as proxies of the unobserved confounder and identify the intervention distributions of the rest. Moreover, while existing identification formulas for proxy variables involve solving integral equations, we show that one can circumvent the need for such solutions by directly modeling the data. Finally, we extend these results to an expanded class of causal graphs, those with other confounders and selection variables.",,https://www.semanticscholar.org/paper/87f8173265cfe3b077e53d09fd3598f14f2667e4,International Conference on Machine Learning
3348,"Kinship, Need, and the Distribution of Altruism","The optimal distribution of investment in kin cannot be determined solely on the basis of knowledge of genetic relatedness. The distribution will be affected by the fact that altruists are likely to encounter diminishing returns on their investments in kin. Furthermore, returns to altruism will vary because of phenotypic variation among recipients. Differences in fitness conversion efficiencies may outweigh relatedness considerations so that a distant relative may be more valuable than a close relative. Or else, if all kin are superefficient at converting investment into fitness, an even distribution of investment among kin may be optimal irrespective of differences in relatedness. It is necessary to ascertain whether the principal consequence of investment results in increased fecundity or increased survivorship of recipients because the optimal distribution of investment may differ considerably in each case.",1983-06-01,https://www.semanticscholar.org/paper/4150754cbc0c59da9b34ef158fbb9d3a4bb11e38,American Naturalist
3597,Lambda expressions and closures for C,"This proposal describes a design for direct support for lambda expressions in C++. The design space for lambda expressions is large, and involves many tradeoffs. We include a thorough discussion of the benefits and the drawbacks of our design. In addition, we describe several other viable alternatives that warrant consideration.",,https://www.semanticscholar.org/paper/58183c51a14662095957a0af67b13a83c45bf413,
2776,Surface Region Optimization 12 11] G. Elber. Free Form Surface Analysis Using a Hybrid of Symbolic and Numeric Surface Region Optimization Surface Region Optimization Surface Region Optimization Surface Region Optimization,"11 surface subdivision scheme for regions that can be machined using a at end tool, regions that can be machined using a large ball end tool, and regions that can be machined using a small ball end tool. This extension can be arbitrarily reened to several sizes of ball end tools. In 9], a method to subdivide a surface into regions with diierent curvature bounds is discussed. This subdivision can be directly exploited for further reenements of the algorithm proposed herein, for several levels of diierent sizes of ball end tools, a at end tool, and possibly even concave ball end tools. 10 Figure 7: The toolpath of the nger in Figure 5 is split with the aid of the surface shape dichotomy in Figure 6 into regions that can be machined using a at end tool (full lines) and using a ball end tool (dashed lines). 9 Figure 4: A model of a nger was used to test the proposed algorithm. Figure 5: Toolpath derived for the nger model in Figure 4 using adaptive isoparametric curves. Figure 6: The bicubic surface of the nger in Figure 4 is dichotomized into a convex region (full lines), and a saddle-like region (dashed lines). No concave regions exists in this surface. The parabolic set is also shown in thick lines.",,https://www.semanticscholar.org/paper/bb3de565e2018955625f553cec8bfc95bed563be,
3484,Approximation schemes for minimizing average weighted completion time with release dates,"We consider the problem of scheduling n jobs with release dates on m machines so as to minimize their average weighted completion time. We present the first known polynomial time approximation schemes for several variants of this problem. Our results include PTASs for the case of identical parallel machines and a constant number of unrelated machines with and without preemption allowed. Our schemes are efficient: for all variants the running time for /spl alpha/(1+/spl epsiv/) approximation is of the form f(1//spl epsiv/, m)poly(n).",1999-10-17,https://www.semanticscholar.org/paper/604a45914d6ec955491ccf8b37ad61b1f62ff0cc,40th Annual Symposium on Foundations of Computer Science (Cat. No.99CB37039)
407,On the Floyd-Warshall Algorithm for Logic Programs,,1999-10-01,https://www.semanticscholar.org/paper/727add3d6621891fbb1387777488f2a18ec773dc,The Journal of Logic Programming
1229,Observation of ZZ Production in p p Collisions at ffiffi s p 1⁄4 1 : 96 TeV,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, M. Ahsan, G. D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G.A. Alves, M. Anastasoaie, L. S. Ancu, T. Andeen, B. Andrieu, M. S. Anzelc, M. Aoki, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, A. C. S. Assis Jesus, O. Atramentov, C. Avila, F. Badaud, L. Bagby, B. Baldin, D. V. Bandurin, P. Banerjee, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, C. Biscarat, G. Blazey, F. Blekman, S. Blessing, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, E. E. Boos, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, X. B. Bu, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, T. H. Burnett, C. P. Buszello, J.M. Butler, P. Calfayan, S. Calvet, J. Cammin, E. Carrera, W. Carvalho, B. C.K. Casey, H. Castilla-Valdez, G. Cerminara, S. Chakrabarti, D. Chakraborty, K.M. Chan, A. Chandra, E. Cheu, F. Chevallier, D.K. Cho, S. Choi, B. Choudhary, L. Christofek, T. Christoudias, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, V. Cuplov, D. Cutts, M. Ćwiok, H. da Motta, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, K. DeVaughan, J. D. Degenhardt, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, H. Dong, T. Dorland, A. Dubey, L. V. Dudko, L. Duflot, S. R. Dugad, D. Duggan, A. Duperrin, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V.D. Elvira, Y. Enari, S. Eno, P. Ermolov, H. Evans, A. Evdokimov, V.N. Evdokimov, G. Facini, A.V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, C. Garcia, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, W. Geng, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, N. Gollub, B. Gómez, A. Goussiou, P. D. Grannis, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Harder, A. Harel, J.M. Hauptman, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, A. P. Heinson, U. Heintz, C. Hensel,22,x K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, J. D. Hobbs, B. Hoeneisen, H. Hoeth, M. Hohlfeld, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, C. Jarvis, R. Jesik, K. Johns, C. Johnson, M. Johnson, D. Johnston, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, J.M. Kalk, D. Karmanov, P. A. Kasper, I. Katsanos, D. Kau, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y.M. Kharzheev, D. Khatidze, T. J. Kim, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, J.-P. Konrath, A. V. Kozelov, J. Kraus, T. Kuhl, A. Kumar, A. Kupco, T. Kurča, V. A. Kuzmin, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, W.M. Lee, A. Leflat, J. Lellouch, J. Li, L. Li, Q. Z. Li, S.M. Lietti, J. K. Lim, J. G. R. Lima, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna, A. L. Lyon, A. K.A. Maciel, D. Mackin, R. J. Madaras, P. Mättig, C. Magass, A. Magerkurth, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, Y. Maravin, B. Martin, R. McCarthy, A. Melnitchouk, L. Mendoza, P. G. Mercadante, M. Merkin, K.W. Merritt, A. Meyer, J. Meyer,22,x J. Mitrevski, R.K. Mommsen, N.K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, N.A. Naumann, H.A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, V. O’Dell, D. C. O’Neil, G. Obrant, C. Ochando, D. Onoprienko, N. Oshima, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park,22,x S.K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, M. Petteni, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma,33,x V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, B.G. Pope, A.V. Popov, C. Potter, W. L. Prado da Silva, H. B. Prosper, S. Protopopescu, J. Qian, A. Quadt,22,k B. Quinn, A. Rakitine, M. S. Rangel, K. Ranjan, P. N. Ratoff, I. Razumov, P. Renkel, P. Rich, J. Rieger, M. Rijssenbeek, I. Ripp-Baudot, F. Rizatdinova, S. Robinson, R. F. Rodrigues, PRL 101, 171803 (2008) P HY S I CA L R EV I EW LE T T E R S week ending 24 OCTOBER 2008",,https://www.semanticscholar.org/paper/7cbb8c00bd352a27d8f1a0ab5d27e3c4095db245,
2502,Using an Inpatient Personal Health Record to Enhance Patient-Provider Communication,,,https://www.semanticscholar.org/paper/dedb783a986ae4031896150a9d45d12514def8df,American Medical Informatics Association Annual Symposium
2368,Luminol- and lucigenin-dependent chemiluminescence of neutrophils: role of degranulation.,"The role of myeloperoxidase in luminol- and lucigenin-dependent chemiluminescence of stimulated human neutrophils has been investigated using purified myeloperoxidase and anti-(human myeloperoxidase) antiserum. This antiserum has been used as a specific enzyme inhibitor to assess myeloperoxidase-dependent neutrophil functions in single preparations of cells, thus overcoming the limitations inherent in other approaches using non-specific haem-inhibitors or myeloperoxidase-deficient neutrophils. The results show that luminol-dependent chemiluminescence is largely dependent on both oxidase activity and degranulation (of myeloperoxidase), while lucigenin monitors oxidase activity independently of the extent of degranulation. Since oxidase activation can occur in the absence of degranulation, assays utilizing luminol-dependent chemiluminescence to measure oxidant generation by stimulated neutrophils should include saturating levels of exogenous myeloperoxidase to overcome this problem.",,https://www.semanticscholar.org/paper/06b0010fc3b5eed7c3dd4eb3847c16c9bc07c588,Journal of clinical & laboratory immunology
254,Horizons of Truth,,,https://www.semanticscholar.org/paper/882bd303fd61743a3463ae422706cb6ed37ff52d,
541,Complexity Characterizations of Attribute Grammar Languages,,,https://www.semanticscholar.org/paper/ec17837a5788dbe3620a29ebc440d0781a074f8d,Information and Computation
577,The Traveling Salesman Problem with Many Visits to Few Cities,"We study the version of the traveling salesman problem in which a relatively small number of cities—say, six—must be visited a huge number of times—e.g., several hundred times each. (It costs to go from one city to itself.) We develop an algorithm for this problem whose running time is exponentialin the number of cities, but logarithmic in the number of visits. Our algorithm is a practical approach to the problem for instances of size in the range indicated above. The implementation and analysis of our algorithm give rise to a number of interesting graph-theoretic and counting problems.",1984-02-01,https://www.semanticscholar.org/paper/bd4458ef949c671a42cd17ca12a65e4a5eb63b53,SIAM journal on computing (Print)
796,Hierarchical State Machines,,2000-08-17,https://www.semanticscholar.org/paper/77b54ddc90953ac13c62a77197b85ce22c457b68,IFIP TCS
2222,"Serine 162, an Essential Residue for the Mitochondrial Localization, Stability and Anti-Apoptotic Function of Mcl-1","Mcl-1 is an anti-apoptotic member of the Bcl-2 family that plays a key role in normal development, but also in pathologies such as cancer. It has some unusual properties compared to other anti-apoptotic members of the Bcl-2 family, and its expression and function are dynamically regulated by a variety of post-transcriptional and post-translational processes. Of note, Mcl-1 protein has a very short half life, and its stability and function may be regulated by reversible phosphorylation. There is also evidence to suggest that it may be localized to different subcellular compartments. The aim of this work was to determine whether residues within the PEST region of Mcl-1 that may undergo reversible phosphorylation, also regulate its subcellular distribution. We show that EGFP:Mcl-1 localizes mainly to the mitochondria of HeLa cells, with some additional cytoplasmic and nuclear localization. The mutations, S64A, S64E, S121A, S159A, T163A and T163E did not significantly affect the localization of Mcl-1. However, mutation of Ser162 to the phospho-null residue, Alanine resulted in an essentially nuclear localization, with some cytoplasmic but no mitochondrial localization. This mutant Mcl-1 protein, S162A, showed significantly decreased stability and it decreased the ability to protect against Bak-induced apoptosis. These data identify a new molecular determinant of Mcl-1 function, localization and stability that may be important for understanding the role of this protein in disease.",2012-09-14,https://www.semanticscholar.org/paper/51061405186d956e9b38bdc70be782ac53ab4b41,PLoS ONE
2334,Biochemistry and Physiology of the Neutrophil: The respiratory burst: The generation of reactive oxygen metabolites and their role in microbial killing,,,https://www.semanticscholar.org/paper/fd6e5874c4be9e3fd8a0fc5c50be21aec45d886c,
350,The Complexity of Pure Nash Equilibria (Extended Abstract),"We investigate from the computational viewpoint multi-player games that are guaranteed to have pure Nash equilibria. We focus on congestion games, and show that a pure Nash equilibrium can be computed in polynomial time in the symmetric network case, while the problem is PLS-complete in general. We discuss implications to non-atomic congestion games, and we explore the scope of the potential function method for proving existence of pure Nash equilibria.",,https://www.semanticscholar.org/paper/f913e221c0aba3d18580c57740919c8c989d96ad,
2190,242. METABOLIC ANALYSIS OF RHEUMATOID ARTHRITIS NEUTROPHILS: A NEW WAY TO MEASURE ACTIVATION OF CELLS IN DISEASE,,2017-04-01,https://www.semanticscholar.org/paper/451c7ae94d6b1370c5771be75b31f5734ee11057,
197,Understanding evolution through algorithms,Why is evolution so successful? What is the role of sex (recombination)? Why is there so much diversity in populations? How do novel traits arise? Are mutations random? And is evolution optimizing something? This talk will review recent work by the speaker and collaborators aiming at understanding the many persistent mysteries of evolution through computational ideas.,2016-10-03,https://www.semanticscholar.org/paper/48cfd81af14af7c7b478f51bcf293b5487f1747e,Formal Methods in Computer-Aided Design
2957,Impact of the X Chromosome and sex on regulatory variation,"The X chromosome, with its unique mode of inheritance, contributes to differences between the sexes at a molecular level, including sex-specific gene expression and sex-specific impact of genetic variation. We have conducted an analysis of the impact of both sex and the X chromosome on patterns of gene expression identified through transcriptome sequencing of whole blood from 922 individuals. We identified that genes on the X chromosome are more likely to have sex-specific expression compared to the autosomal genes. Furthermore, we identified a depletion of regulatory variants on the X chromosome, especially among genes under high selective constraint. In contrast, we discovered an enrichment of sex-specific regulatory variants on the X chromosome. To resolve the molecular mechanisms underlying such effects, we generated and connected sex-specific chromatin accessibility to sex-specific expression and regulatory variation. As sex-specific regulatory variants can inform sex differences in genetic disease prevalence, we have integrated our data with genome-wide association study data for multiple immune traits and to identify traits with significant sex biases. Together, our study provides genome-wide insight into how the X chromosome and sex shape human gene regulation and disease.",2015-08-07,https://www.semanticscholar.org/paper/5f97571deb7668228837070ea09f5c25e036a182,bioRxiv
2774,Workplane-Orientation – Sensing Techniques for Tablet PCs,"Many mobile applications could benefit from having more fine-grained awareness of user-to-device orientation than is possible with traditional landscape and portrait modes. In contrast to approaches that measure absolute orientation of a device in world coordinates, we argue for the need to measure workplane orientation: the angle of rotation, relative to the user, around the axis perpendicular to the user’s work surface. We present two complementary methods to determine workplane orientation for a hand-held writing surface: one using computer vision techniques and another based on stylus-pose.",,https://www.semanticscholar.org/paper/5eb090bf874cc0e6e80114ed2b6eeafb190ba95e,
100,Letter from the Special Issue Editor,,,https://www.semanticscholar.org/paper/7a6e96acb393774175ccc1c49c26a73372e646dc,IEEE Data Engineering Bulletin
853,Memory-Ecient Algorithms for the Verication of Temporal Properties,"This paper addresses the problem of designing memory-ecient algo- rithms for the verication of temporal properties of nite-state programs. Both the programs and their desired temporal properties are modeled as automata on innite words (Buchi automata). Verication is then reduced to checking the emptiness of the automaton resulting from the product of the program and the property. This problem is usually solved by com- puting the strongly connected components of the graph representing the product automaton. Here, we present algorithms which solve the empti- ness problem without explicitly constructing the strongly connected com- ponents of the product graph. By allowing the algorithms to err with some probability, we can implement them with a randomly accessed memory of size O(n) bits, where n is the number of states of the graph, instead of O(n logn) bits that the presently known algorithms require.",,https://www.semanticscholar.org/paper/d5c7635d8718126674f27a474a330fddb4dec041,
2487,Session details: Papers: manipulating video,,2013-04-27,https://www.semanticscholar.org/paper/b133b7ad22025357acf935dd5668df6c0810fc91,International Conference on Human Factors in Computing Systems
287,Discretized Multinomial Distributions and Nash Equilibria in Anonymous Games,"We show that there is a polynomial-time approximation scheme for computing Nash equilibria in anonymous games with any fixed number of strategies (a very broad and important class of games), extending the two-strategy result of Daskalakis and Papadimitriou 2007. The approximation guarantee follows from a probabilistic result of more general interest: The distribution of the sum of n independent unit vectors with values ranging over {e1,...,ek}, where ei is the unit vector along dimension i of the k-dimensional Euclidean space, can be approximated by the distribution of the sum of another set of independent unit vectors whose probabilities of obtaining each value are multiples of 1/z for some integer z, and so that the variational distance of the two distributions is at most eps, where eps is bounded by an inverse polynomial in z and a function of k, but with no dependence on n. Our probabilistic result specifies the construction of a surprisingly sparse epsi-cover- under the total variation distance - of the set of distributions of sums of independent unit vectors, which is of interest on its own right.",2008-08-20,https://www.semanticscholar.org/paper/51146d4e060094b2d99bb4e3f7fe353b38b4fd22,2008 49th Annual IEEE Symposium on Foundations of Computer Science
2750,"Computer Graphics - Principles and Practice, 3rd Edition","Computer Graphics: Principles And Practice (3rd Edition) PDF, Computer Graphics: Principles And Practice (3rd Edition) PDF Download, Download Computer Graphics: Principles And Practice (3rd Edition) PDF, Computer Graphics: Principles And Practice (3rd Edition) Download PDF, Computer Graphics: Principles And Practice (3rd Edition) by John F. Hughes, Andries Van Dam, Morgan McGuire, David F. Sklar, James D. Foley, Steven K. Feiner, Kurt Akeley Download, Free Download Computer Graphics: Principles And Practice (3rd Edition) Ebooks John F. Hughes, Andries Van Dam, Morgan McGuire, David F. Sklar, James D. Foley, Steven K. Feiner, Kurt Akeley, PDF Computer Graphics: Principles And Practice (3rd Edition) Popular Download, Read Online Computer Graphics: Principles And Practice (3rd Edition) E-Books, Read Computer Graphics: Principles And Practice (3rd Edition) Full Collection John F. Hughes, Andries Van Dam, Morgan McGuire, David F. Sklar, James D. Foley, Steven K. Feiner, Kurt Akeley, Computer Graphics: Principles And Practice (3rd Edition) Full Collection, Read Best Book Online Computer Graphics: Principles And Practice (3rd Edition), Free Download Computer Graphics: Principles And Practice (3rd Edition) Full Popular John F. Hughes, Andries Van Dam, Morgan McGuire, David F. Sklar, James D. Foley, Steven K. Feiner, Kurt Akeley, I Was So Mad Computer Graphics: Principles And Practice (3rd Edition) John F. Hughes, Andries Van Dam, Morgan McGuire, David F. Sklar, James D. Foley, Steven K. Feiner, Kurt Akeley Ebook Download, Free Download Computer Graphics: Principles And Practice (3rd Edition) Full Version John F. Hughes, Andries Van Dam, Morgan McGuire, David F. Sklar, James D. Foley, Steven K. Feiner, Kurt Akeley, PDF Computer Graphics: Principles And Practice (3rd Edition) Free Download, Read Online Computer Graphics: Principles And Practice (3rd Edition) Ebook Popular, Computer Graphics: Principles And Practice (3rd Edition) Free Read Online, PDF Computer Graphics: Principles And Practice (3rd Edition) Full Collection, full book Computer Graphics: Principles And Practice (3rd Edition), free online Computer Graphics: Principles And Practice (3rd Edition), online free Computer Graphics: Principles And Practice (3rd Edition), online pdf Computer Graphics: Principles And Practice (3rd Edition), pdf download Computer Graphics: Principles And Practice (3rd Edition), Download Free Computer Graphics: Principles And Practice (3rd Edition) Book, Download Online Computer Graphics: Principles And Practice (3rd Edition) Book, Download PDF Computer Graphics: Principles And Practice (3rd Edition), Download PDF Computer Graphics: Principles And Practice (3rd Edition) Free Online, pdf free download Computer Graphics: Principles And Practice (3rd Edition), read online free Computer Graphics: Principles And Practice (3rd Edition), Computer Graphics: Principles And Practice (3rd Edition) John F. Hughes, Andries Van Dam, Morgan McGuire, David F. Sklar, James D. Foley, Steven K. Feiner, Kurt Akeley pdf, by John F. Hughes, Andries Van Dam, Morgan McGuire, David F. Sklar, James D. Foley, Steven K. Feiner, Kurt Akeley Computer Graphics: Principles And Practice (3rd Edition), book pdf Computer Graphics: Principles And Practice (3rd Edition), by John F. Hughes, Andries Van Dam, Morgan McGuire, David F. Sklar, James D. Foley, Steven K. Feiner, Kurt Akeley pdf Computer Graphics: Principles And Practice (3rd Edition), John F. Hughes, Andries Van Dam, Morgan McGuire, David F. Sklar, James D. Foley, Steven K. Feiner, Kurt Akeley epub Computer Graphics: Principles And Practice (3rd Edition), pdf John F. Hughes, Andries Van Dam, Morgan McGuire, David F. Sklar, James D. Foley, Steven K. Feiner, Kurt Akeley Computer Graphics: Principles And Practice (3rd Edition), the book Computer Graphics: Principles And Practice (3rd Edition), John F. Hughes, Andries Van Dam, Morgan McGuire, David F. Sklar, James D. Foley, Steven K. Feiner, Kurt Akeley ebook Computer Graphics: Principles And Practice (3rd Edition), Download Computer Graphics: Principles And Practice (3rd Edition) E-Books, Download Online Computer Graphics: Principles And Practice (3rd Edition) Book, Download pdf Computer Graphics: Principles And Practice (3rd Edition), Download Computer Graphics: Principles And Practice (3rd Edition) E-Books, Download Computer Graphics: Principles And Practice (3rd Edition) Online Free, Read Best Book Online Computer Graphics: Principles And Practice (3rd Edition), Read Online Computer Graphics: Principles And Practice (3rd Edition) Book, Read Online Computer Graphics: Principles And Practice (3rd Edition) E-Books, Read Computer Graphics: Principles And Practice (3rd Edition) Online Free, Read Best Book Computer Graphics: Principles And Practice (3rd Edition) Online, Pdf Books Computer Graphics: Principles And Practice (3rd Edition), Read Computer Graphics: Principles And Practice (3rd Edition) Books Online Free, Read Computer Graphics: Principles And Practice (3rd Edition) Full Collection, Read Computer Graphics: Principles And Practice (3rd Edition) Book Free, Read Computer Graphics: Principles And Practice (3rd Edition) Ebook Download, Computer Graphics: Principles And Practice (3rd Edition) PDF read online, Computer Graphics: Principles And Practice (3rd Edition) Ebooks, Computer Graphics: Principles And Practice (3rd Edition) pdf read online, Free Download Computer Graphics: Principles And Practice (3rd Edition) Best Book, Computer Graphics: Principles And Practice (3rd Edition) Ebooks Free, Computer Graphics: Principles And Practice (3rd Edition) PDF Download, Computer Graphics: Principles And Practice (3rd Edition) Popular Download, Computer Graphics: Principles And Practice (3rd Edition) Read Download, Computer Graphics: Principles And Practice (3rd Edition) Full Download, Computer Graphics: Principles And Practice (3rd Edition) Free Download, Computer Graphics: Principles And Practice (3rd Edition) Free PDF Download, Computer Graphics: Principles And Practice (3rd Edition) Free PDF Online, Computer Graphics: Principles And Practice (3rd Edition) Books Online, Computer Graphics: Principles And Practice (3rd Edition) Ebook Download, Computer Graphics: Principles And Practice (3rd Edition) Book Download, PDF Download Computer Graphics: Principles And Practice (3rd Edition) Free Collection, Free Download Computer Graphics: Principles And Practice (3rd Edition) Books [E-BOOK] Computer Graphics: Principles And Practice (3rd Edition) Full eBook",,https://www.semanticscholar.org/paper/cabe41ad6fa6c1be42fe942cf4e1b145f79ae464,
658,Nonsurgical closure of femoral pseudoaneurysms complicating cardiac catheterization and percutaneous transluminal coronary angioplasty.,,1992-09-01,https://www.semanticscholar.org/paper/792eb127077cee8e547f17676a23db269b809da7,Journal of the American College of Cardiology
1950,OVERALL RESOURCE EFFECTIVENESS (ORE) INDICES FOR TOTAL RESOURCE MANAGEMENT AND CASE STUDIES,"High-tech industries are capital-intensive, in which capital effectiveness and productivity are critical for maintaining competitive advantages. Most of the existing studies focused on demand forecast, capacity planning, order allocation, and capacity management to enhance capital effectiveness. Few approaches are developed to address productivity and resource management, while one of critical roles for industry engineers is to enhance productivity and resource utilization effectiveness in practice. This study aims to propose a set of novel indices for Overall Resource Effectiveness (ORE) and drive various improvement directions for total resource management. A number of case studies are reviewed for illustration, while the proposed methodology is extended for medical instrument for cross validation. The results have shown practical viability of the proposed ORE to drive collaborative efforts to enhance total productivity and overall resource effectiveness. This paper concludes with discussions on value propositions of proposed ORE indices and future research directions.",2015-10-26,https://www.semanticscholar.org/paper/ea3e6877d95e60836d9f00152a2ecb0fcc09753b,
2790,Galectin-7 downregulation in lesional keratinocytes contributes to enhanced IL-17A signaling and skin pathology in psoriasis.,"Psoriasis is a chronic inflammatory skin disease characterized by inflammatory cell infiltration, as well as hyperproliferation of keratinocytes in skin lesions, and is considered a metabolic syndrome. We found that the expression of galectin-7 is reduced in the skin lesions of patients with psoriasis. IL-17A and TNF-α, two cytokines intimately involved in the development of psoriatic lesions, suppressed galectin-7 expression in human primary keratinocytes (HEKn cells) and the immortalized human keratinocyte cell line HaCaT. A galectin-7 knockdown in these cells elevated the production of IL-6 and IL-8 and enhanced ERK signaling when the cells were stimulated with IL-17A. Galectin-7 attenuated IL-17A-induced production of inflammatory mediators by keratinocytes via the miR-146a-ERK pathway. Moreover, galectin-7-deficient mice showed enhanced epidermal hyperplasia and skin inflammation in response to intradermal IL-23 injection. We identified fluvastatin as an inducer of galectin-7 expression by connectivity map (cMAP) analysis, confirmed this effect in keratinocytes, and demonstrated that fluvastatin attenuated IL-6 and IL-8 production induced by IL-17A. Thus, we validate a role of galectin-7 in the pathogenesis of psoriasis, in both epidermal hyperplasia and keratinocyte-mediated inflammatory responses, and formulated a rationale for the use of statins in the treatment of psoriasis.",2020-10-15,https://www.semanticscholar.org/paper/ef1365b63e11d75e6c0474452533535ab90ced13,Journal of Clinical Investigation
147,Automated Construction of Environment Models by a Mobile Robot,,,https://www.semanticscholar.org/paper/64033ad2fce488ca0c89972619f9ca3536720f0d,
1461,Investigation of the electromagnetic structure of eta and eta ' mesons by two-photon interactions.,"The TPC/Two-Gamma facility at the SLAC {ital e}{sup +}{ital e}{sup {minus}} storage ring PEP was used to study the reactions {gamma}{gamma}{sup *}{r arrow}{eta} and {gamma}{gamma}{sup *}{r arrow}{eta}{prime}. The {eta}{gamma}{sup *}{gamma} and {eta}{prime}{gamma}{sup *}{gamma} transition form factors were measured as functions of {ital Q}{sup 2}, the negative of the invariant mass squared of the tagged photon, in the range 0.1{lt}{ital Q}{sup 2}{lt}7 GeV{sup 2}. These determinations of the electromagnetic structure of the {eta} and {eta}{prime} mesons are consistent with both vector-meson dominance and QCD. They also provide new measurements of the pseudoscalar mixing angle and decay constants.",1990-01-08,https://www.semanticscholar.org/paper/7e68e8b1074df47dcc8ba48e8d68e900c0980dd0,Physical Review Letters
2773,Interactive Multimedia Explanation for Equipment Maintenance and Repair,,,https://www.semanticscholar.org/paper/24336b2326d3bf2935251a058d67bcd5e30f9244,Human Language Technology - The Baltic Perspectiv
946,An Analyzer for Message Sequence Charts 15 Lemma 4.1 the Timed M S C M Is Timing Inconsistent I the Graph G M 5 an Msc Analysis Tool 4 Mscs with Timing Constraints,"6 Conclusions We h a ve shown that message sequence charts are sensitive t o v arious semantic interpretations. Under diierent semantics, diierent race conditions may occur. We h a ve proposed and implemented a tool which can be used to analyze message sequence charts to locate and visualize design errors as early as possible in a design cycle. The tool conforms to ITU recommendation Z.120. We h a ve noted that extensions of the tool, to gently integrate formal veriication techniques further into the design process, are possible. It is our intention to use the formal representation of MSCs described here as a v ehicle for exploring such extensions. Acknowledgements: We t h a n k C h uck Kalmanek, Bob Kurshan, and Mi-halis Yannakakis for many fruitful discussions. We are also grateful to Brian Kernighan, who developed a port of the MSC analyzer for Windows PCs. by successive a p p r o ximation. The tool allows the user to construct, edit, and analyze MSCs interactively. The charts may be stored in the ITU standard form (Z.120), in textual form as conventional annotated scenarios, or in graphical form, as PostScript les. Annotations to the MSC can be entered in comment boxes that become part of the scenario as displayed. For the online analysis of interpreted MSCs, the tool supports the four pre-deened semantics choices listed in Figure 4 through menu choices. Other user-deened semantics can easily be incorporated. The analysis for race conditions is invoked by clicking on a button labeled`Check..'. A menu is then created listing all connicts that can occur for the chosen semantic interpretation of the chart. By selecting a connict from a menu-list, the corresponding event pair is highlighted in the chart. The user can also set preferences so that only certain types of connicts (eg. between two receives, or between a send and a receive) are entered into the connict menus. The user can also select an event e, with a mouse click, and ask the tool to identify all related (or optionally all unrelated) events. Related are all those events that necessarily precede or follow e in the partial order. T h e t wo t ypes of events (i.e., following or preceding the selected event) are marked in diierent colors. For timing analysis, the user can annotate the chart with intervals, both on message transmissions and on local process states (see …",,https://www.semanticscholar.org/paper/85f4c7c57d31239ae20722784fec7a2e56b0f566,
2498,Virtual projection: exploring optical projection as a metaphor for multi-device interaction,"Handheld optical projectors provide a simple way to overcome the limited screen real-estate on mobile devices. We present virtual projection (VP), an interaction metaphor inspired by how we intuitively control the position, size, and orientation of a handheld optical projector's image. VP is based on tracking a handheld device without an optical projector and allows selecting a target display on which to position, scale, and orient an item in a single gesture. By relaxing the optical projection metaphor, we can deviate from modeling perspective projection, for example, to constrain scale or orientation, create multiple copies, or offset the image. VP also supports dynamic filtering based on the projection frustum, creating overview and detail applications, and selecting portions of a larger display for zooming and panning. We show exemplary use cases implemented using our optical feature-tracking framework and present the results of a user study demonstrating the effectiveness of VP in complex interactions with large displays.",2012-05-05,https://www.semanticscholar.org/paper/8371b5478710a7cb1ebb7e488d8e6dd7fff2920a,International Conference on Human Factors in Computing Systems
1942,A novel approach to hedge and compensate the critical dimension variation of the developed-and-etched circuit patterns for yield enhancement in semiconductor manufacturing,,,https://www.semanticscholar.org/paper/06415b548501d440c37fec2db9aefabd77d570ee,Computers & Operations Research
3394,A general framework for handling commitment in online throughput maximization,,2018-11-20,https://www.semanticscholar.org/paper/0e0cced03fbc595cd997c6ede35c93b54017a6c9,Conference on Integer Programming and Combinatorial Optimization
2889,Expression and function of an IgE-binding animal lectin (ϵBP) in mast cells,,1993-11-01,https://www.semanticscholar.org/paper/d21f77dad14fa40162c2eb09ccd8ca5641f2b74b,
141,View planning and automated data acquisition for three-dimensional modeling of complex sites,"Constructing highly detailed three-dimensional (3-D) models of large complex sites using range scanners can be a time-consuming manual process. One of the main drawbacks is determining where to place the scanner to obtain complete coverage of a site. We have developed a system for automatic view planning called VuePlan. When combined with our mobile robot, AVENUE, we have a system that is capable of modeling large-scale environments with minimal human intervention throughout both the planning and acquisition phases. The system proceeds in two distinct stages. In the initial phase, the system is given a two-dimensional site footprint with which it plans a minimal set of sufficient and properly constrained covering views. We then use a 3-D laser scanner to take scans at each of these views. When this planning system is combined with our mobile robot it automatically computes and executes a tour of these viewing locations and acquires them with the robot's onboard laser scanner. These initial scans serve as an approximate 3-D model of the site. The planning software then enters a second phase in which it updates this model by using a voxel-based occupancy procedure to plan the next best view (NBV). This NBV is acquired, and further NBVs are sequentially computed and acquired until an accurate and complete 3-D model is obtained. A simulator tool that we developed has allowed us to test our entire view planning algorithm on simulated sites. We have also successfully used our two-phase system to construct precise 3-D models of real-world sites located in New York City: Uris Hall on the campus of Columbia University and Fort Jay on Governors Island. © 2009 Wiley Periodicals, Inc.",2009-11-01,https://www.semanticscholar.org/paper/d29f4c637a6b962e750ae97335b6866c84e5b9f4,
1312,Search for associated Higgs boson production WH ---> WWW* ---> l+- nu l-prime+- nu-prime + X in p anti-p collisions at s**(1/2) = 1.96-TeV,"The authors present a search for associated Higgs boson production in the process p{bar p} {yields} WH {yields} WWW* {yields} {ell}{sup {+-}}{nu} {ell}{prime}{sup {+-}} {nu}{prime} + X in final states containing two like-sign isolated electrons or muons (e{sup {+-}}e{sup {+-}}, e{sup {+-}} {mu}{sup {+-}}, or {mu}{sup {+-}} {mu}{sup {+-}}). The search is based on D0 Run II data samples corresponding to integrated luminosities of 360-380 pb{sup -1}. No excess is observed over the predicted standard model background. They set 95% C.L. upper limits on {sigma}(p{bar p} {yields} WH) x Br(H {yields} WW*) between 3.2 and 2.8 pb for Higgs masses from 115 to 175 GeV.",2006-07-01,https://www.semanticscholar.org/paper/449e34e1e8421c4c09869e8581280ff3bf70e4bb,
2724,Fast object-precision shadow generation for area light sources using BSP trees,"This paper introduces an efficient object-precision shadow generation algorithm for static polygonal environments directly illuminated by convex area light sources. Penumbra and umbra regions are calculated analytically and represented as a pair of BSP trees for each light source. As the trees are built, convex scene polygons are filtered down the trees, and split into fragments that are wholly lit, in penumbra, or in umbra. The illumination due to the light source is calculated at selected points within the wholly lit and penumbra regions by contour integration with the visible parts of the light source. We use a fast analytic algorithm to compute the fragments of the area light source visible from a point in penumbra. Rendering is done using hardwaresupported linear interpblated shading on a 3D graphics workstation. Because the scene itself is represented as a BSP tree, visible-surface determination may be performed by using either workstation-supported hardware (e.g., a z-buffer) or software BSP-tree traversal. We provide sample images created by our implementation, including timings and polygon counts. CR",1992-06-01,https://www.semanticscholar.org/paper/04d74e92025d68adc923b084b25bd9f58777d557,ACM Symposium on Interactive 3D Graphics and Games
367,Selfish behavior and stability of the internet:: a game-theoretic analysis of TCP,"For years, the conventional wisdom [7, 22] has been that the continued stability of the Internet depends on the widespread deployment of ""socially responsible"" congestion control. In this paper, we seek to answer the following fundamental question: If network end-points behaved in a selfish manner, would the stability of the Internet be endangered?.We evaluate the impact of greedy end-point behavior through a game-theoretic analysis of TCP. In this ""TCP Game"" each flowattempts to maximize the throughput it achieves by modifying its congestion control behavior. We use a combination of analysis and simulation to determine the Nash Equilibrium of this game. Our question then reduces to whether the network operates efficiently at these Nash equilibria.Our findings are twofold. First, in more traditional environments -- where end-points use TCP Reno-style loss recovery and routers use drop-tail queues -- the Nash Equilibria are reasonably efficient. However, when endpoints use more recent variations of TCP (e.g., SACK) and routers employ either RED or drop-tail queues, the Nash equilibria are very inefficient. This suggests that the Internet of the past could remain stable in the face of greedy end-user behavior, but the Internet of today is vulnerable to such behavior. Second, we find that restoring the efficiency of the Nash equilibria in these settings does not require heavy-weight packet scheduling techniques (e.g., Fair Queuing) but instead can be done with a very simple stateless mechanism based on CHOKe [21].",,https://www.semanticscholar.org/paper/10505a43a45d53b1653a8e34653dbfaaa0663343,"Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication"
2069,A UNISON framework for analyzing alternative strategies of IC final testing for enhancing overall operational effectiveness,,2007-05-01,https://www.semanticscholar.org/paper/807d587d546e76ff0efb5e57db2995f2219dbe56,
2905,Novel Computational Models of Evoked Dopamine Release In Vivo Measured by Fast Scan Cyclic Voltammetry Quantify the Regulation of Presynaptic Kinetics by Synucleins,"Dopamine neurotransmission in the striatum is central to many normal and disease functions. Ventral midbrain dopamine neurons exhibit ongoing tonic firing that produce low extrasynaptic levels of dopamine below the detection of extrasynaptic electrochemical recordings (∼10 – 20 nanomolar), with superimposed bursts that can saturate the dopamine uptake transporter and produce transient micromolar concentrations. The bursts have previously been shown to lead to presynaptic plasticity via multiple mechanisms, but analysis methods for these kinetic parameters are limited. To provide a deeper understanding of the mechanics of dopamine neurotransmission, we present three computational models of dopamine release with different levels of spatiotemporal complexity to analyze in vivo fast-scan cyclic voltammetry recordings from the dorsal striatum of mice. The models accurately fit to the cyclic voltammetry data and provide estimates of presynaptic dopamine facilitation/depression kinetics and dopamine transporter reuptake kinetics. We use the models to analyze the role of synuclein proteins in neurotransmission and quantify recent findings linking presynaptic protein α-synuclein to the short-term facilitation and long-term depression of dopamine release.",2022-05-05,https://www.semanticscholar.org/paper/63715dddc876973c251a416eb12eac9c9b496ae0,bioRxiv
2982,Character and Graphic OLED Displays,,,https://www.semanticscholar.org/paper/96cefe60a584d10e7452f3a4dda5aa41627fb61b,
1910,Circular economy meets industry 4.0: Can big data drive industrial symbiosis?,,2018-04-01,https://www.semanticscholar.org/paper/79f4ba320215fb0586d216f6ac4ba981307af4fb,
2639,Guest Editors' Introduction,"The term mixed reality (MR) was first used in the mid 1990s (Milgram & Kishino, 1994), after the popularization of virtual reality (VR). VR refers to the experience of users immersed in a virtual computer-created world. Thus, the world of VR exists within the computer. In contrast, MR attempts to correlate the virtual world with the real world. At one end of the spectrum of ways in which virtual and real worlds can be combined is augmented reality (AR), a term that was first used in the early 1990s (Caudell & Mizell, 1992). AR supplements the real world with information obtained from a virtual world; for example, a seethrough head-mounted display (HMD) may be used to superimpose a computer-generated image on the user’s view of the real world. Augmented virtuality (AV), in contrast, refers to augmenting a virtual world with information obtained from the real world. Using AV, a more realistic virtual world than that of VR can be realized; for example, complex shapes and actual images of naturally occurring objects can be incorporated into a virtual world. In 1997, Mixed Reality Systems Laboratory Inc. was inaugurated in Japan as the founding body for a four-year joint project between the Ministry of International Trade and Industry (MITI) and Canon Inc. Three universities, the University of Tokyo, Hokkaido University and the University of Tsukuba, joined the collaboration, and an MR research group comprising industry, government and academia was established. The editors of this special issue, Ohta and Hirose, are collaborative researchers involved in the project, and Feiner participated as an international advisor. As part of this project, the International Symposium on Mixed Reality (ISMR) was held twice, in 1999 and 2001, to encourage MR research worldwide. To compile this special issue, we selected some of the best papers presented at ISMR 2001, and asked their authors to submit revised versions for review. The following is a brief summary of the articles included in this special issue. Sawada and colleagues report on one of the core AR technologies: head tracking. Sawada’s group describes a hardware solution based on miniature high-precision gyroscopes. Hedley and colleagues and Walairacht and colleagues present studies of user interface devices for freely manipulating the AR environment. Lee and colleagues introduce a system that allows the user to model physical objects within AR. Mann and Fung describe an approach to obscure visually undesirable objects to create diminished reality. Ohta and colleagues, MacIntyre and colleagues, and Sakagawa and colleagues report on methods for fusing the real world and virtual worlds. Ohta’s group describes an augmented reality system that uses an interactively computed depth map of the real world. MacIntyre’s group reports on software for embedding 2D video actors in 3D augmented reality, while Sakagawa’s group presents hardware for incorporating 3D, real world, ray-space models into virtual reality. When MR was first introduced, it dealt with the fusion of real and virtual worlds, accomplished, in principle, with VR technology. However, as MR research has progressed, it has become clear that a broader perspective is required to better take into account the real world. In particular, this has meant that MR researchers have begun to address the real world beyond the laboratory, exploring mobile and wearable computing technology. The MR field is progressing rapidly, and we hope that this special issue helps convey its vitality. Finally, we express our sincere thanks to Prof. Hirota of the University of Tokyo, who handled the administration work for the submitted manuscripts. We also thank Dr. Tamura of MR Systems Laboratory, and the members of the ISMR Committee.",,https://www.semanticscholar.org/paper/f04f65e6244a8af66b4449bdd2d6efb0267a560a,Presence: Teleoperators & Virtual Environments
1793,Building and using a semantivisual image hierarchy,"A semantically meaningful image hierarchy can ease the human effort in organizing thousands and millions of pictures (e.g., personal albums), and help to improve performance of end tasks such as image annotation and classification. Previous work has focused on using either low-level image features or textual tags to build image hierarchies, resulting in limited success in their general usage. In this paper, we propose a method to automatically discover the “semantivisual” image hierarchy by incorporating both image and tag information. This hierarchy encodes a general-to-specific image relationship. We pay particular attention to quantifying the effectiveness of the learned hierarchy, as well as comparing our method with others in the end-task applications. Our experiments show that humans find our semantivisual image hierarchy more effective than those solely based on texts or low-level visual features. And using the constructed image hierarchy as a knowledge ontology, our algorithm can perform challenging image classification and annotation tasks more accurately.",2010-06-13,https://www.semanticscholar.org/paper/fbac75009db521a7dbe08344316bb538f039ac00,2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition
2572,Interaction Techniques for Exploring Historic Sites through Situated Media,"We present a set of augmented reality and virtual reality interaction techniques that enable mobile users to visualize and interact virtually with representations of past events. These approaches use historic photographic imagery registered with real and virtual 3D objects to depict events in situ, and to provide interactive timelines. We demonstrate our techniques through examples developed for an important landmark, the Cathedral of St. John the Divine.",2006-03-25,https://www.semanticscholar.org/paper/5ce18bcb93be61b600faa79cacb533b0c33c1ae5,IEEE Symposium on 3D User Interfaces
2944,Annotation-free quantification of RNA splicing using LeafCutter,,2017-11-09,https://www.semanticscholar.org/paper/92b8b08b3b73070e405c3b97483abdb7c2e8676c,Nature Genetics
674,Noise-tolerant fair classification,"Fairness-aware learning involves designing algorithms that do not discriminate with respect to some sensitive feature (e.g., race or gender). Existing work on the problem operates under the assumption that the sensitive feature available in one's training sample is perfectly reliable. This assumption may be violated in many real-world cases: for example, respondents to a survey may choose to conceal or obfuscate their group identity out of fear of potential discrimination. This poses the question of whether one can still learn fair classifiers given noisy sensitive features. In this paper, we answer the question in the affirmative: we show that if one measures fairness using the mean-difference score, and sensitive features are subject to noise from the mutually contaminated learning model, then owing to a simple identity we only need to change the desired fairness-tolerance. The requisite tolerance can be estimated by leveraging existing noise-rate estimators from the label noise literature. We finally show that our procedure is empirically effective on two case-studies involving sensitive feature censoring.",2019-01-30,https://www.semanticscholar.org/paper/c4ac496bf57410638260196a25d8ae3366ea03c7,Neural Information Processing Systems
2681,The Representation and Use of a Visual Lexicon for Automated Graphics Generation,"Most automated graphics generation systems employ either a constructive or a parametric graphics synthesis approach. Constructive graphics synthesis is a deductive approach that builds visual presentations from scratch by gluing together the most basic visual variables. Conversely, parametric graphics synthesis defines a set of parametrized visual models and interprets the information to be presented through instantiation of the selected model. To increase efficiency, we have combined parametric and constructive approaches in a system called IMPROVISE. In this paper, we focus on the parametric aspect of our approach. We present a comprehensive, general, and extensible formalism to represent a visual lexicon for use in automated graphics generation. A visual lexicon is a collection of parametrized primitive visual objects that serve as building blocks for constructing more complex visual presentations. We also illustrate how this representation can be effectively employed to aid the selection and instantiation of a visual lexical item in the graphics generation process. Examples are given from IMPROVISE to demonstrate the representation and use of this visual lexicon.",1997-08-23,https://www.semanticscholar.org/paper/01ba58fe5be3af5c1e8704556f2d1ab25d4d48e8,International Joint Conference on Artificial Intelligence
3752,Generating the Future with Adversarial Transformers,"We learn models to generate the immediate future in video. This problem has two main challenges. Firstly, since the future is uncertain, models should be multi-modal, which can be difficult to learn. Secondly, since the future is similar to the past, models store low-level details, which complicates learning of high-level semantics. We propose a framework to tackle both of these challenges. We present a model that generates the future by transforming pixels in the past. Our approach explicitly disentangles the models memory from the prediction, which helps the model learn desirable invariances. Experiments suggest that this model can generate short videos of plausible futures. We believe predictive models have many applications in robotics, health-care, and video understanding.",2017-07-01,https://www.semanticscholar.org/paper/6d2892f82a89bfc81f9924adb8bd070fe007adf7,Computer Vision and Pattern Recognition
2935,Genetic dysregulation of gene expression and splicing during a ten-year period of human aging,"Molecular and cellular changes are intrinsic to aging and age-related diseases. Prior cross-sectional studies have investigated the combined effects of age and genetics on gene expression and alternative splicing; however, there has been no long-term, longitudinal characterization of these molecular changes, especially in older age. We performed RNA sequencing in whole-blood from the same individuals from the PIVUS study at ages 70 and 80 to quantify how gene expression, alternative splicing, and their genetic regulation are altered during this 10-year period of advanced aging. We observe that individuals are more similar to their own expression profiles later in life than profiles of other individuals their own age; 93% of samples cluster with their own measurement at another age, and there is a strong correlation of genetic effects on expression between the two ages (median ρG = 0.96). Despite this, we identify 1,291 and 294 genes differentially expressed and alternatively spliced with age, as well as 529 genes with outlying individual trajectories of aging. Further, 7.8% and 9.6% of tested genes show a reduction in genetic associations with expression and alternative splicing in older age, with impacted genes enriched in DNA repair pathways. Together these findings indicate that, although gene expression and alternative splicing and their genetic regulation are mostly stable late in life, a small subset of genes is dynamic and is characterized by changes in expression and splicing and a reduction in genetic regulation.",2019-01-13,https://www.semanticscholar.org/paper/ad1be6f3c2150c099f0a82ac9c4c7f851f9d3c98,bioRxiv
3176,An observation of attempted infanticide and female–female cooperation in wild plains zebras (Equus quagga),"
 Male infanticide has been reported in a wide range of taxa as a strategy for redirecting maternal investment and increasing a male’s chance of siring future offspring. Plains zebras (Equus quagga) possess many of the social organization and life history traits found to favour infanticide. However, most documented cases are from captive animals, while it has not been detected in studies of free-ranging populations. Here, we report an apparent infanticide attempt in which the historical associations of all participants were known. In addition, we report the first instance of non-kin female–female cooperative defence against male aggression in this species. We discuss why this behaviour may not have been observed by other longitudinal studies. We then explore how intraspecific and inter-individual variation may factor into its relative rarity, how the reproductive biology of plains zebras relates to this behaviour, and how female–female cooperation between non-kin can operate as an effective counterstrategy.",2022-06-15,https://www.semanticscholar.org/paper/450f34922b318a2af2ece9951cb1281275725038,Behaviour
1776,"Uncovering, understanding, and predicting links","Network data, such as citation networks of documents, hyperlinked networks of web pages, and social networks of friends, are pervasive in applied statistics and machine learning. The statistical analysis of network data can provide both useful predictive models and descriptive statistics. Predictive models can point social network members towards new friends, scientific papers towards relevant citations, and web pages towards other related pages. Descriptive statistics can uncover the hidden community structure underlying a network data set. 
In this work we develop new models of network data that account for both links and attributes. We also develop the inferential and predictive tools around these models to make them widely applicable to large, real-world data sets. One such model, the Relational Topic Model can predict links using only a new node's attributes. Thus, we can suggest citations of newly written papers, predict the likely hyperlinks of a web page in development, or suggest friendships in a social network based only on a new user's profile of interests. Moreover, given a new node and its links, the model provides a predictive distribution of node attributes. This mechanism can be used to predict keywords from citations or a user's interests from his or her social connections. 
While explicit network data—network data in which the connections between people, places, genes, corporations, etc. are explicitly encoded—are already ubiquitous, most of these can only annotate connections in a limited fashion. Although relationships between entities are rich, it is impractical to manually devise complete characterizations of these relationships for every pair of entities on large, real-world corpora. To resolve this we present a probabilistic topic model to analyze text corpora and infer descriptions of its entities and of relationships between those entities. We show qualitatively and quantitatively that our model can construct and annotate graphs of relationships and make useful predictions.",,https://www.semanticscholar.org/paper/9e09017ba9f478da7163d667186dd6c47e678d7e,
131,"Requirements for deadlock-free, adaptive packet routing","This paper studies the problem of deadlock-free packet routing in parallel and distributed architectures. We present three main results. First, we show that the standard technique of ordering the queues so that every packet always has the possibility of moving to a higher ordered queue is not necessary for deadlock-freedom. Second, we show that every deadlock-free, adaptive packet routing algorithm can be restricted, by limiting the adaptivity available, to obtain an oblivious algorithm which is also deadlock-free. Third, we show that any packet routing algorithm for a cycle or torus network which is free of deadlock and which uses only minimal length paths must require at least three queues in some node. This matches the known upper bound of three queues per node for deadlock-free, minimal packet routing on cycle and torus networks.",1992-10-01,https://www.semanticscholar.org/paper/9813b72e279a203cd2aea483c451b887481fc471,ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing
896,How easy is local search?,,1985-10-21,https://www.semanticscholar.org/paper/72d54ba4fed488a31022b6f37333550e041e93bc,26th Annual Symposium on Foundations of Computer Science (sfcs 1985)
2668,Enveloping users and computers in a collaborative 3D augmented reality,"We present EMMIE (Environment Management for Multiuser Information Environments), a prototype experimental user interface to a collaborative augmented environment. Users share a 3D virtual space and manipulate virtual objects that represent information to be discussed. We refer to EMMIE as a hybrid user interface because it combines a variety of different technologies and techniques, including virtual elements such as 3D widgets, and physical objects such as tracked displays and input devices. See-through head-worn displays overlay the virtual environment on the physical environment, visualizing the pervasive ""virtual ether"" within which all interaction occurs. Our prototype includes additional 2D and 3D displays, ranging from palm-sized to wall-sized, allowing the most appropriate one to be used for any task. Objects can be moved among displays (including across dimensionalities) through drag-and-drop. In analogy to 2D window managers, we describe a prototype implementation of a shared 3D environment manager that is distributed across displays, machines, and operating systems. We also discuss two methods we are exploring for handling information privacy in such an environment.",1999-10-20,https://www.semanticscholar.org/paper/cebb6a4d86ff6d0158c30823c38c4d22ea6a232f,International Workshop on Automated Reasoning
530,Scheduling Dags to Minimize Time and Communication,,1988-06-28,https://www.semanticscholar.org/paper/8558a76e1f4607b7a22fd9838345704a42c4f70d,Aegean Workshop on Computing
2852,Inhibition of Advanced Glycation and Absence of Galectin-3 Prevent Blood-Retinal Barrier Dysfunction during Short-Term Diabetes,"Breakdown of the inner blood-retinal barrier (iBRB) occurs early in diabetes and is central to the development of sight-threatening diabetic macular edema (DME) as retinopathy progresses. In the current study, we examined how advanced glycation end products (AGEs) forming early in diabetes could modulate vasopermeability factor expression in the diabetic retina and alter inter-endothelial cell tight junction (TJ) integrity leading to iBRB dysfunction. We also investigated the potential for an AGE inhibitor to prevent this acute pathology and examined a role of the AGE-binding protein galectin-3 (Gal-3) in AGE-mediated cell retinal pathophysiology. Diabetes was induced in C57/BL6 wild-type (WT) mice and in Gal-3−/− transgenic mice. Blood glucose was monitored and AGE levels were quantified by ELISA and immunohistochemistry. The diabetic groups were subdivided, and one group was treated with the AGE-inhibitor pyridoxamine (PM) while separate groups of WT and Gal-3−/− mice were maintained as nondiabetic controls. iBRB integrity was assessed by Evans blue assay alongside visualisation of TJ protein complexes via occludin-1 immunolocalization in retinal flat mounts. Retinal expression levels of the vasopermeability factor VEGF were quantified using real-time RT-PCR and ELISA. WT diabetic mice showed significant AGE -immunoreactivity in the retinal microvasculature and also showed significant iBRB breakdown (P < .005). These diabetics had higher VEGF mRNA and protein expression in comparison to controls (P < .01). PM-treated diabetics had normal iBRB function and significantly reduced diabetes-mediated VEGF expression. Diabetic retinal vessels showed disrupted TJ integrity when compared to controls, while PM-treated diabetics demonstrated near-normal configuration. Gal-3−/− mice showed significantly less diabetes-mediated iBRB dysfunction, junctional disruption, and VEGF expression changes than their WT counterparts. The data suggests an AGE-mediated disruption of iBRB via upregulation of VEGF in the diabetic retina, possibly modulating disruption of TJ integrity, even after acute diabetes. Prevention of AGE formation or genetic deletion of Gal-3 can effectively prevent these acute diabetic retinopathy changes.",2007-04-05,https://www.semanticscholar.org/paper/8541f8204f735cc64b4e5e921439dae202f7fa24,International Journal of Experimental Diabetes Research
2113,DEVELOPING A DATA MINING METHOD FOR WAFER BINMAP CLUSTERING AND AN EMPIRICAL STUDY IN A SEMICONDUCTOR MANUFACTURING FAB,"ABSTRACT Mining potentially useful information from large database becomes increasingly important in both research and application in many fields. Because of the complex fabrication processes and the cost resulted from defects, it is critical to identify possible faults through examining the failure patterns of wafer bin-maps. However, little research has been done to develop methods for clustering and classifying wafer bin-maps. We first used spatial statistics to examine the independence among failed dies and thus classified the bin maps into four categories: random failure pattern, systematic repulsion failure pattern, systematic attraction failure pattern, and others. For WBM with systematic attraction failure patterns, we developed an ART neural network for clustering to assist the product engineers in narrowing possible causes of manufacturing defects. We used empirical data from a fab for demonstration and the results showed the practical viability of this approach for its consistency and efficiency. This study concludes with discussions and remarks on future research.",2002-01-01,https://www.semanticscholar.org/paper/ef7e301277e7dd3f9cff20737c8de15bb83dab61,
8,Discovering foodborne illness in online restaurant reviews,"Objective
We developed a system for the discovery of foodborne illness mentioned in online Yelp restaurant reviews using text classification. The system is used by the New York City Department of Health and Mental Hygiene (DOHMH) to monitor Yelp for foodborne illness complaints.


Materials and Methods
We built classifiers for 2 tasks: (1) determining if a review indicated a person experiencing foodborne illness and (2) determining if a review indicated multiple people experiencing foodborne illness. We first developed a prototype classifier in 2012 for both tasks using a small labeled dataset. Over years of system deployment, DOHMH epidemiologists labeled 13 526 reviews selected by this classifier. We used these biased data and a sample of complementary reviews in a principled bias-adjusted training scheme to develop significantly improved classifiers. Finally, we performed an error analysis of the best resulting classifiers.


Results
We found that logistic regression trained with bias-adjusted augmented data performed best for both classification tasks, with F1-scores of 87% and 66% for tasks 1 and 2, respectively.


Discussion
Our error analysis revealed that the inability of our models to account for long phrases caused the most errors. Our bias-adjusted training scheme illustrates how to improve a classification system iteratively by exploiting available biased labeled data.


Conclusions
Our system has been instrumental in the identification of 10 outbreaks and 8523 complaints of foodborne illness associated with New York City restaurants since July 2012. Our evaluation has identified strong classifiers for both tasks, whose deployment will allow DOHMH epidemiologists to more effectively monitor Yelp for foodborne illness investigations.",2018-12-01,https://www.semanticscholar.org/paper/e5f24e69d39cb25b2c75a58213abdd427435efe3,J. Am. Medical Informatics Assoc.
665,"A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level","Significance We demonstrate that a neural network automatically solves, explains, and generates university-level problems from the largest Massachusetts Institute of Technology (MIT) mathematics courses at a human level. Our methods combine three innovations: 1) using recent neural networks pretrained on text and fine-tuned on code rather than pretrained on text; 2) few-shot learning synthesizing programs that correctly solve course problems automatically; and 3) a pipeline to solve questions, explain solutions, and generate new questions indistinguishable by students from course questions. Our work solves university-level mathematics courses and improves upon state-of-the-art, increasing automatic accuracy on randomly sampled questions on a benchmark by order of magnitude. Implications for higher education include roles of artificial intelligence (AI) in automated course evaluation and content generation.",2021-12-31,https://www.semanticscholar.org/paper/166b64f2ae8e52f5779682fab756cbd617a6e74b,Proceedings of the National Academy of Sciences of the United States of America
3698,Shadows Shed Light on 3D Objects,"3D reconstruction is a fundamental problem in computer vision, and the task is especially challenging when the object to reconstruct is partially or fully occluded. We introduce a method that uses the shadows cast by an unobserved object in order to infer the possible 3D volumes behind the occlusion. We create a differentiable image formation model that allows us to jointly infer the 3D shape of an object, its pose, and the position of a light source. Since the approach is end-to-end differentiable, we are able to integrate learned priors of object geometry in order to generate realistic 3D shapes of different object categories. Experiments and visualizations show that the method is able to generate multiple possible solutions that are consistent with the observation of the shadow. Our approach works even when the position of the light source and object pose are both unknown. Our approach is also robust to real-world images where ground-truth shadow mask is unknown.",2022-06-17,https://www.semanticscholar.org/paper/571cfbddba05cd997c27dff0b0ae9b1e02f7eb17,arXiv.org
733,Computation of Least Fixed Points,,2012-08-27,https://www.semanticscholar.org/paper/5b40d4e4ecea846c70f5bd6c307188825d661b88,International Symposium on Mathematical Foundations of Computer Science
938,The Effect of a Connectivity Requirement on the Complexity of Maximum Subgraph Problems,"If Ir IS a property on graphs (or digraphs), the corresponding maximum subgraph problem is Given a graph G find a maximum (induced) subgraph of G satisfying property ~r The author has previously shown this problem to be NP-hard for a large class of properties (the class of properties that are hereditary on induced subgraphs) The effect of adding a connectwtty requirement to ~r is now considered It is shown that for the same class of properties the connected maximum subgraph problem is also NP-hard, moreover, for a certain important subclass of properties, even approximating the node-deletion version of it in any ""reasonable"" way is NP-hard A related set of problems is shown to testify to A~ # NP LI co-NP, In the case that NP # co-NP.",1979-10-01,https://www.semanticscholar.org/paper/48936d2b6d8686260876bafb6a47ca19e0f26f43,JACM
3174,Divergent water requirements partition exposure risk to parasites in wild equids,"Abstract For grazing herbivores, dung density in feeding areas is an important determinant of exposure risk to fecal‐orally transmitted parasites. When host species share the same parasite species, a nonrandom distribution of their cumulative dung density and/or nonrandom ranging and feeding behavior may skew exposure risk and the relative selection pressure parasites impose on each host. The arid‐adapted Grevy's zebra (Equus grevyi) can range more widely than the water‐dependent plains zebra (Equus quagga), with which it shares the same species of gastrointestinal nematodes. We studied how the spatial distribution of zebra dung relates to ranging and feeding behavior to assess parasite exposure risk in Grevy's and plains zebras at a site inhabited by both zebra species. We found that zebra dung density declined with distance from water, Grevy's zebra home ranges (excluding those of territorial males) were farther from water than those of plains zebras, and plains zebra grazing areas had higher dung density than random points while Grevy's zebra grazing areas did not, suggesting a greater exposure risk in plains zebras associated with their water dependence. Fecal egg counts increased with home range proximity to water for both species, but the response was stronger in plains zebras, indicating that this host species may be particularly vulnerable to the elevated exposure risk close to water. We further ran experiments on microclimatic effects on dung infectivity and showed that fewer nematode eggs embryonated in dung in the sun than in the shade. However, only 5% of the zebra dung on the landscape was in shade, indicating that the microclimatic effects of shade on the density of infective larvae is not a major influence on exposure risk dynamics. Ranging constraints based on water requirements appear to be key mediators of nematode parasite exposure in free‐ranging equids.",2022-02-01,https://www.semanticscholar.org/paper/3de4e95e82efd967b6bb87bd6656ae609ebdcb19,Ecology and Evolution
1935,Building energy saving performance indices for cleaner semiconductor manufacturing and an empirical study,,2016-09-01,https://www.semanticscholar.org/paper/80a14d259da55e24c85beab4f711923b9b40f01b,Computers & industrial engineering
2333,Neutrophil activation: The production of intracellular signalling molecules,,,https://www.semanticscholar.org/paper/e30718ba60530a5a32918204af28528b939acafa,
3105,Transparent Checkpoint-Restart of Distributed Applications on Commodity Clusters,"We have created ZapC, a novel system for transparent coordinated checkpoint-restart of distributed network applications on commodity clusters. ZapC provides a thin visualization layer on top of the operating system that decouples a distributed application from dependencies on the cluster nodes on which it is executing. This decoupling enables ZapC to checkpoint an entire distributed application across all nodes in a coordinated manner such that it can he restarted from the checkpoint on a different set of cluster nodes at a later time. ZapC checkpoint-restart operations execute in parallel across different cluster nodes, providing faster checkpoint-restart performance. ZapC uniquely supports network state in a transport protocol independent manner, including correctly saving and restoring socket and protocol state for both TCP and UDP connections. We have implemented a ZapC Linux prototype and demonstrate that it provides low visualization overhead and fast checkpoint-restart times for distributed network applications without any application, library, kernel, or network protocol modifications",2005-09-01,https://www.semanticscholar.org/paper/359928dfca1eb50ea392a266c6425bca9a9874db,IEEE International Conference on Cluster Computing
548,Searching and Pebbling,,1986-11-02,https://www.semanticscholar.org/paper/49ec7fe784eac2d8593a1d1b5b8953cfb79396f0,Theoretical Computer Science
2727,Annotating the real world with knowledge-based graphics on a see-through head-mounted display,"We describe an experimental, knowledge-based, virtual-world system that uses a monocular ""see-through"" head-mounted display to overlay graphics on the user's view of the real world. In a simple equipment maintenance domain that we have developed, the overlaid graphics include 3D represen tations of actual physical objects, textual annotations and cal louts, and virtual metaobjects, such as arrows. A set of 3D position and orientation sensors monitor the user's head and several of the objects in the world. Our system includes a knowledge-based graphics component that determines what information to present, a display-list-based display server that represents the models to be displayed, and a set of sensor servers that track the user and selected objects. The sensor servers directly modify the object transformations and view ing specification in the display list. The knowledge-based graphics component also receives the sensor data and uses it to redesign the information being presented.",1992-09-01,https://www.semanticscholar.org/paper/689dac0f6e0d3a2174318dd987bc19565fa5ac81,
885,"Optimization, Approximation, and Complexity Classes (Extended Abstract)",,,https://www.semanticscholar.org/paper/7c7484bb16789764ac8ccab671d3027f3bfc6376,Symposium on the Theory of Computing
1099,Silicon detector dark matter results from the final exposure of CDMS II.,"We report results of a search for weakly interacting massive particles (WIMPS) with the silicon detectors of the CDMS II experiment. This blind analysis of 140.2 kg day of data taken between July 2007 and September 2008 revealed three WIMP-candidate events with a surface-event background estimate of 0.41(-0.08)(+0.20)(stat)(-0.24)(+0.28)(syst). Other known backgrounds from neutrons and 206Pb are limited to <0.13 and <0.08 events at the 90% confidence level, respectively. The exposure of this analysis is equivalent to 23.4 kg day for a recoil energy range of 7-100 keV for a WIMP of mass 10  GeV/c2. The probability that the known backgrounds would produce three or more events in the signal region is 5.4%. A profile likelihood ratio test of the three events that includes the measured recoil energies gives a 0.19% probability for the known-background-only hypothesis when tested against the alternative WIMP+background hypothesis. The highest likelihood occurs for a WIMP mass of 8.6  GeV/c2 and WIMP-nucleon cross section of 1.9×10(-41)  cm2.",2013-04-15,https://www.semanticscholar.org/paper/17034b264acb33aa5e0c33738685fe456cba7193,Physical Review Letters
1688,Automatic Variational Inference in Stan,"Variational inference is a scalable technique for approximate Bayesian inference. Deriving variational inference algorithms requires tedious model-specific calculations; this makes it difficult for non-experts to use. We propose an automatic variational inference algorithm, automatic differentiation variational inference (ADVI); we implement it in Stan (code available), a probabilistic programming system. In ADVI the user provides a Bayesian model and a dataset, nothing else. We make no conjugacy assumptions and support a broad class of models. The algorithm automatically determines an appropriate variational family and optimizes the variational objective. We compare ADVI to MCMC sampling across hierarchical generalized linear models, nonconjugate matrix factorization, and a mixture model. We train the mixture model on a quarter million images. With ADVI we can use variational inference on any model we write in Stan.",2015-06-10,https://www.semanticscholar.org/paper/c02717b88beba6eb84e6a407f58f8705de649c5e,Neural Information Processing Systems
2711,Knowledge-based design of 3D graphics and virtual worlds,"INTRODUCTION There are many situations in which pictures are needed to fulfill a clearly stated purpose, such as describing the results of an experiment or explaining how to perform a physical task . While computer graphics research has given us fully automated solutions to rendering pictures, the process of designing pictures is typically addressed through the development of editors with which a user can express their design decisions. Designing pictures by hand is time-consuming, requires scarce expertise, and invariably must be done in advance of when the pictures are viewed. Consequently, the results are often overly general and do not meet the information needs of each individual viewer and situation . Know/edge-based graphics offers an alternative approach in which AI techniques are applied to automate the design of pictures to communicate specific information to a viewer.",,https://www.semanticscholar.org/paper/1fd6b448db5fc4e9c8e14b2862c9652d0ecfbeb7,
3512,Faster Approximation Algorithms for the Unit Capacity Concurrent Flow Problem with Applications to Routing and Finding Sparse Cuts,"This paper describes new algorithms for approximately solving the concurrent multicommodity flow problem with uniform capacities. These algorithms are much faster than algorithms discovered previously. Besides being an important problem in its own right, the uniform-capacity concurrent flow problem has many interesting applications. Leighton and Rao used uniform-capacity concurrent flow to find an approximately ""sparsest cut"" in a graph and thereby approximately solve a wide variety of graph problems, including minimum feedback arc set, minimum cut linear arrangement, and minimum area layout. However, their method appeared to be impractical as it required solving a large linear program. This paper shows that their method might be practical by giving an $O(m^2 \log m)$ expected-time randomized algorithm for their concurrent flow problem on an $m$-edge graph. Raghavan and Thompson used uniform-capacity concurrent flow to solve approximately a channel width minimization problem in very large scale integration. An $O(k^{3/2} (m + n \log n))$ expected-time randomized algorithm and an $O(k\min{n,k} (m+n\log n)\log k)$ deterministic algorithm is given for this problem when the channel width is $\Omega(\log n)$, where $k$ denotes the number of wires to be routed in an $n$-node, $m$-edge network.",1994-06-01,https://www.semanticscholar.org/paper/274968b9c2467687624e2c01269a8063d8e5fc2c,SIAM journal on computing (Print)
1005,Anterior Chamber Configuration Changes after Cataract Surgery in Eyes with Glaucoma,"Purpose To evaluate changes in anterior chamber depth (ACD) and angle width induced by phacoemulsification and intraocular lens (IOL) implantation in eyes with glaucoma, using anterior segment optical coherence tomography (AS-OCT). Methods Eleven eyes of 11 patients with angle-closure glaucoma (ACG) and 12 eyes of 12 patients with open-angle glaucoma (OAG) underwent phacoemulsification and IOL implantation. Using AS-OCT, ACD and angle parameters were measured before and 2 days after surgery. Change in intraocular pressure (IOP) and number of ocular hypotensive drugs were evaluated. Results After surgery, central ACD and angle parameters increased significantly in eyes with glaucoma (p < 0.05). Prior to surgery, mean central ACD in the ACG group was approximately 1.0 mm smaller than that in the OAG group (p < 0.001). Post surgery, mean ACD of the ACG group was still significantly smaller than that of the OAG group. No significant differences were found in angle parameters between the ACG and OAG groups. In the ACG group, postoperative IOP at the final visit was significantly lower than preoperative IOP (p = 0.018) and there was no significant change in the number of ocular hypotensive medications used, although clinically, patients required fewer medications. In the OAG group, the IOP and number of ocular hypotensive drugs were almost unchanged after surgery. Conclusions The ACD and angle width in eyes with glaucoma increased significantly after phacoemulsification and IOL implantation. Postoperative ACD significantly differed between the ACG and OAG groups, whereas angle parameters did not differ.",2012-03-22,https://www.semanticscholar.org/paper/9ff843f4c389ee532e777be16d5a1762c3cc5944,Korean Journal of Ophthalmology
2148,Improved Lower Bounds for the Capacity of i.i.d. Deletion and Duplication Channels,"This paper considers the capacity of binary deletion channels, where bits are deleted independently with probability d. It improves significantly upon the best previous framework used to obtain provable lower bounds on this capacity by utilizing a stronger definition of a typical output from the channel. The new results give the best known provable bounds on the capacity for all values of d. Moreover, the techniques presented here extend to yield lower bounds for channels with certain types of random insertions, namely, duplications, or combinations of duplications and deletions. To demonstrate these techniques in this context, two binary channels are analyzed: a channel where each transmitted bit is copied with probability nu and a channel where each transmitted bit is copied a geometrically distributed number of times.",2007-08-01,https://www.semanticscholar.org/paper/06f9b73c9afc6171f467e9467eb1cfc8dd0f4898,IEEE Transactions on Information Theory
943,Scheduling Interval-Ordered Tasks,We show that unit execution time jobs subject to a precedence constraint whose complement is chordal can be scheduled in linear time on m processors. Generalizations to arbitrary execution times are NP-complete.,1979-08-01,https://www.semanticscholar.org/paper/db659cb96064a84f7eae627cf99d4705d61a7649,SIAM journal on computing (Print)
626,Efficient Search for Rationals,,,https://www.semanticscholar.org/paper/95b31c5b81fc523db34fe1902e7c84d970525c80,Information Processing Letters
866,On Datalog vs. polynomial time (extended abstract),We show that certain monotonic polynomial time queries are not expressible in variants of Datalog. The proof techniques include lower bounds for monotone circuit size and a “Pumping Lemma” for Datalog queries.,1991-04-01,https://www.semanticscholar.org/paper/ee93243481ea145580f5b10d61bbd4998fa41260,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
2065,Constructing the OGE for promoting tool group productivity in semiconductor manufacturing,"Overall equipment efficiency (OEE) has been proposed as a comprehensive index for individual equipment performance. However, there are limitations for evaluating only OEE of single machine in semiconductor manufacturing. This study aims to propose overall tool group efficiency (OGE) indices to observe the equipment performance at the tool group level. In addition, rather than evaluating OEE for a fixed period of observation time, we also proposed a mechanism with statistical efficiency control charts to continuously monitor OGE over time. This study constructed a framework for monitoring equipment performances from critical tool groups to single machines via longitudinal analysis. Then, root-cause analysis of machine statuses is employed to identify possible performance detractors. Following the proposed framework, improvement actions can be thus triggered on those critical machine statuses to promote tool group productivity. We used a case study based on real data from a fab in Taiwan for illustration and concluded this study with discussion of future research directions.",2007-02-01,https://www.semanticscholar.org/paper/6b10d71d17b1a847cd322820c9f925d26960a3b2,
2397,Oscillations in protein and RNA content during synchronous growth of Acanthamoeba castellanii,,,https://www.semanticscholar.org/paper/4d21337680b56e8f4f2d25a6bab97c5bb8682757,FEBS Letters
506,The weighted region problem: finding shortest paths through a weighted planar subdivision,"The problem of determining shortest paths through a weighted planar polygonal subdivision with <italic>n</italic> vertices is considered. Distances are measured according to a weighted Euclidean metric: The length of a path is defined to be the weighted sum of (Euclidean) lengths of the subpaths within each region. An algorithm that constructs a (restricted) “shortest path map” with respect to a given source point is presented. The output is a partitioning of each edge of the subdivion into intervals of ε-optimality, allowing an ε-optimal path to be traced from the source to any query point along any edge. The algorithm runs in worst-case time <italic>O</italic>(<italic>ES</italic>) and requires <italic>O</italic>(<italic>E</italic>) space, where  <italic>E</italic> is  the number of “events” in our algorithm and <italic>S</italic> is the time it takes to run a numerical search procedure. In the worst case, <italic>E</italic> is bounded above by <italic>O</italic>(<italic>n</italic><supscrpt>4</supscrpt>) (and we give an &OHgr;(<italic>n</><supscrpt>4</supscrpt>) lower bound), but it is likeky that <italic>E</italic> will be much smaller in practice. We also show that <italic>S</italic> is bounded by <italic>O</italic>(<italic>n</italic><supscrpt>4</supscrpt><italic>L</italic>), where <italic>L</italic> is the precision of the problem instance (including the number of bits in the user-specified tolerance ε). Again, the value of <italic>S</italic> should be smaller in practice. The algorithm applies the “continuous  Dijkstra” paradigm  and exploits the fact that shortest paths obey Snell's Law of Refraction at region boundaries, a   local optimaly property of shortest paths that is well known from the analogous optics model. The algorithm generalizes to the multi-source case to compute Voronoi diagrams.",1991-01-03,https://www.semanticscholar.org/paper/d54b409eefbb5db295f0ee2e817caf006e6d804b,JACM
2200,Killing of Escherichia coli by Crohn's Disease Monocyte-derived Macrophages and Its Enhancement by Hydroxychloroquine and Vitamin D,"Background:Crohn's disease (CD) is associated with defective innate immunity, including impaired neutrophil chemotaxis, and mucosal invasion by bacteria, particularly adherent and invasive Escherichia coli that replicate inside macrophage phagolysosomes. We compared CD and healthy control (HC) macrophages for their abilities to kill E. coli and generate neutrophil chemoattractants and also assessed the effects of hydroxychloroquine (HCQ) and vitamin D on killing of phagocytosed E. coli. Methods:Peripheral blood monocyte-derived macrophages from CD and HC were compared for bacterial killing and generation of neutrophil chemoattractants in response to CD-derived E. coli. Escherichia coli replication was also assessed in the presence and absence of HCQ, alone and with antibiotics, and vitamin D. Results:Monocyte-derived macrophages from patients with CD were similar to HC in allowing replication of phagocytosed CD-derived E. coli: HM605 {CD: N = 10, mean fold replication in 3 hr = 1.08 (95% confidence interval [CI], 0.39–1.78); HC: N = 9, 1.50 (95% CI, 1.02–1.97); P = 0.15} and also in generation of neutrophil chemoattractants in response to E. coli (mean fold chemotaxis relative to control: CD = 2.55 [95% CI, 2.31–2.80]; HC = 2.65 [95% CI, 2.46–2.85], P = 0.42). HCQ and 1,25 OH2-vitamin D3 both caused dose-dependent inhibition of intramacrophage E. coli replication 3-hour postinfection; HCQ: 73.9% inhibition (P < 0.001) at 1 &mgr;g/mL, accompanied by raised intraphagosomal pH, and 1,25 OH2-vitamin D3: 80.7% inhibition (P < 0.05) at 80 nM. HCQ had synergistic effects with doxycycline and ciprofloxacin. Conclusions:CD and HC macrophages perform similarly in allowing replication of phagocytosed E. coli and generating neutrophil chemoattractants. Replication of phagocytosed E. coli was substantially decreased by HCQ and vitamin D. These warrant further therapeutic trials in CD in combination with relevant antibiotics.",2015-04-01,https://www.semanticscholar.org/paper/c3e79f1a38abb41b202dd156da5abc11dc85a81f,Inflammatory Bowel Diseases
232,The complexity of fairness through equilibrium,"Competitive equilibrium with equal incomes (CEEI) is a well-known fair allocation mechanism [Foley67:Resource, Varian74: Equity, Thomson85:Theories]; however, for indivisible resources a CEEI may not exist. It was shown in Budish [2011] that in the case of indivisible resources there is always an allocation, called A-CEEI, that is approximately fair, approximately truthful, and approximately efficient, for some favorable approximation parameters. This approximation is used in practice to assign business school students to classes. In this paper we show that finding the A-CEEI allocation guaranteed to exist by Budish's theorem is PPAD-complete. We further show that finding an approximate equilibrium with better approximation guarantees is even harder: NP-complete.",2014-06-01,https://www.semanticscholar.org/paper/a77fcd72e185271d23140699eebf8c460d793ebd,ACM Conference on Economics and Computation
2419,HoloFight: An Augmented Reality Fighting Game,"Augmented Reality (AR) provides opportunities to create exciting new kinds of digital entertainment, such as watching movies on a large virtual screen or playing games that interact with a real physical room. While a number of AR games have been built, many do not build on the control innovations found in modern console, PC, and mobile gaming [Von Itzstein et al. 2019]. To explore the space of immersive multiplayer experiences with support for control innovations found in common non-immersive video games, we present HoloFight, a multiplayer fighting game using two or more Microsoft HoloLens 2s, two or more Xbox controllers, and the various natural user interfaces supported by the Microsoft HoloLens 2.",2021-08-05,https://www.semanticscholar.org/paper/43e05dab2a106c57f64449cdf334355a88fd8493,SIGGRAPH Immersive Pavilion
2976,A nonparametric variable clustering model,"Factor analysis models effectively summarise the covariance structure of high dimensional data, but the solutions are typically hard to interpret. This motivates attempting to find a disjoint partition, i.e. a simple clustering, of observed variables into highly correlated subsets. We introduce a Bayesian non-parametric approach to this problem, and demonstrate advantages over heuristic methods proposed to date. Our Dirichlet process variable clustering (DPVC) model can discover block-diagonal covariance structures in data. We evaluate our method on both synthetic and gene expression analysis problems.",2012-12-03,https://www.semanticscholar.org/paper/8ff4f681a02be8bddcc69e831f9a7badb422a330,Neural Information Processing Systems
3682,Interpreting and Controlling Vision Foundation Models via Text Explanations,"Large-scale pre-trained vision foundation models, such as CLIP, have become de facto backbones for various vision tasks. However, due to their black-box nature, understanding the underlying rules behind these models' predictions and controlling model behaviors have remained open challenges. We present a framework for interpreting vision transformer's latent tokens with natural language. Given a latent token, our framework retains its semantic information to the final layer using transformer's local operations and retrieves the closest text for explanation. Our approach enables understanding of model visual reasoning procedure without needing additional model training or data collection. Based on the obtained interpretations, our framework allows for model editing that controls model reasoning behaviors and improves model robustness against biases and spurious correlations.",2023-10-16,https://www.semanticscholar.org/paper/34a4229372313f3741c579c9f48c8687e40f1f1b,
2460,Development and Evaluation of Mixed Reality Interaction Techniques,"We present our thoughts on the development and evaluation of novel interaction techniques for mixed reality (MR) systems, particularly those consisting of a heterogeneous mix of displays, devices, and users. Interaction work in MR has predominantly focused on two areas: glove or wand-based virtual reality (VR) interactions and tangible user interfaces. We believe that MR users should not be limited to these approaches, but should rather be able to utilize all available devices and interaction methods in their environment to make use of the most relevant ones for the current task at hand. Furthermore, we will discuss the difficulty in finding appropriate ways to evaluate new techniques, primarily due to the lack of standards of comparison. CR Categories: H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, augmented, and virtual realities, Evaluation/methodology; H.5.2 [Information Interfaces and Presentation]: User Interfaces—Graphical user interfaces (GUI), Interaction styles",2016-12-07,https://www.semanticscholar.org/paper/b28827c417f21d77fdeb8a70615c54a5c146328a,
204,Cortical Computation via Iterative Constructions,"We study Boolean functions of an arbitrary number of input variables that can be realized by simple iterative constructions based on constant-size primitives. This restricted type of construction needs little global coordination or control and thus is a candidate for neurally feasible computation. Valiant's construction of a majority function can be realized in this manner and, as we show, can be generalized to any uniform threshold function. We study the rate of convergence, finding that while linear convergence to the correct function can be achieved for any threshold using a fixed set of primitives, for quadratic convergence, the size of the primitives must grow as the threshold approaches 0 or 1. We also study finite realizations of this process and the learnability of the functions realized. We show that the constructions realized are accurate outside a small interval near the target threshold, where the size of the construction grows as the inverse square of the interval width. This phenomenon, that errors are higher closer to thresholds (and thresholds closer to the boundary are harder to represent), is a well-known cognitive finding.",2016-02-26,https://www.semanticscholar.org/paper/87c6bc4a1c2be24f89b6a2d542bbe7866644c563,Annual Conference Computational Learning Theory
1700,Bayesian Nonparametric Poisson Factorization for Recommendation Systems,"We develop a Bayesian nonparametric Poisson factorization model for recommendation systems. Poisson factorization implicitly models each user’s limited budget of attention (or money) that allows consumption of only a small subset of the available items. In our Bayesian nonparametric variant, the number of latent components is theoretically unbounded and eectively estimated when computing a posterior with observed user behavior data. To approximate the posterior, we develop an ecient variational inference algorithm. It adapts the dimensionality of the latent components to the data, only requires iteration over the user/item pairs that have been rated, and has computational complexity on the same order as for a parametric model with xed dimensionality. We studied our model and algorithm with large realworld data sets of user-movie preferences. Our model eases the computational burden of searching for the number of latent components and gives better predictive performance than its parametric counterpart.",2014-04-02,https://www.semanticscholar.org/paper/74771dad32d0b2ab67d901ddcb74d48d6649139b,International Conference on Artificial Intelligence and Statistics
3771,Assessing the Quality of Actions,,2014-09-06,https://www.semanticscholar.org/paper/6bb60de0e93c9df260ef3d20dbff0716ed1ec711,European Conference on Computer Vision
830,The Complexity of Multiterminal Cuts,"In the multiterminal cut problem one is given an edge-weighted graph and a subset of the vertices called terminals, and is asked for a minimum weight set of edges that separates each terminal from all the others. When the number $k$ of terminals is two, this is simply the mincut, max-flow problem, and can be solved in polynomial time. It is shown that the problem becomes NP-hard as soon as $k=3$, but can be solved in polynomial time for planar graphs for any fixed $k$. The planar problem is NP-hard, however, if $k$ is not fixed. A simple approximation algorithm for arbitrary graphs that is guaranteed to come within a factor of $2-2/k$ of the optimal cut weight is also described.",1994-08-01,https://www.semanticscholar.org/paper/1cf64c2bdd4f1c384a55910606a64c8d831a96ba,SIAM journal on computing (Print)
868,Towards an architecture-independent analysis of parallel algorithms,"A simple and efficient method for evaluating the performance of an algorithm, rendered as a directed acyclic graph, on any parallel computer is presented. The crucial ingredient is an efficient approximation algorithm for a particular scheduling problem. The only parameter of the parallel computer needed by our method is the message-to-instruction ratio $\tau$. Although the method used in this paper does not take into account the number of processors available, its application to several common algorithms shows that it is surprisingly accurate.",1990-04-01,https://www.semanticscholar.org/paper/6148ddf9fe6a835f4f92a591ff135a1c6bba70e1,Symposium on the Theory of Computing
2402,TERMINAL OXIDASES: A SUMMARY,,,https://www.semanticscholar.org/paper/6118f5a86d968019cfb2f6eada7105bfe9cc98b8,
3448,Budget optimization in search-based advertising auctions,"Internet search companies sell advertisement slots based on users' search queries via an auction. While there has been previous work onthe auction process and its game-theoretic aspects, most of it focuses on the Internet company. In this work, we focus on the advertisers, who must solve a complex optimization problem to decide how to place bids on keywords to maximize their return (the number of user clicks on their ads) for a given budget. We model the entire process and study this budget optimization problem. While most variants are NP-hard, we show, perhaps surprisingly, that simply randomizing between two uniform strategies that bid equally on all the keywordsworks well. More precisely, this strategy gets at least a 1-1/ε fraction of the maximum clicks possible. As our preliminary experiments show, such uniform strategies are likely to be practical. We also present inapproximability results, and optimal algorithms for variants of the budget optimization problem.",2006-12-08,https://www.semanticscholar.org/paper/2a800e0862a5c7cb1c4f1238e93d4bde44c46f0a,ACM Conference on Economics and Computation
1606,De novo gene signature identification from single‐cell RNA‐seq with hierarchical Poisson factorization,"Common approaches to gene signature discovery in single cell RNA-sequencing (scRNA-seq) depend upon predefined structures like clusters or pseudo-temporal order, require prior normalization, or do not account for the sparsity of single cell data. We present single cell Hierarchical Poisson Factorization (scHPF), a Bayesian factorization method that adapts Hierarchical Poisson Factorization [1] for de novo discovery of both continuous and discrete expression patterns from scRNA-seq. scHPF does not require prior normalization and captures statistical properties of single cell data better than other methods in benchmark datasets. Applied to scRNA-seq of the core and margin of a high-grade glioma, scHPF uncovers marked differences in the abundance of glioma subpopulations across tumor regions and subtle, regionally-associated expression biases within glioma subpopulations. scHFP revealed an expression signature that was spatially biased towards the glioma-infiltrated margins and associated with inferior survival in glioblastoma.",2018-07-11,https://www.semanticscholar.org/paper/9db5b92337a361a68207e3560704b541c23622cf,bioRxiv
2363,Gamma interferon enhances the killing of Staphylococcus aureus by human neutrophils.,"The effect of purified human interferon-gamma on the responsiveness of human neutrophils was investigated. Pre-incubation of neutrophils with 100 U interferon ml-1 for 10 min at 37 degrees C resulted in a 2.5-fold increase in N-formylmethionyl-leucyl-phenylalanine-stimulated reactive oxygen metabolite generation (as assayed by luminol-dependent chemiluminescence). Pre-treatment of neutrophils with interferon also potentiated their ability to kill Staphylococcus aureus, and thus it is proposed that this lymphokine may also enhance neutrophil function in vivo under certain pathological conditions.",,https://www.semanticscholar.org/paper/8a85d8d36040f60995cc2b6bdc3f330a02f28990,Journal of General Microbiology
715,On the Complexity of Bundle-Pricing and Simple Mechanisms,"We show that the problem of finding an optimal bundle-pricing for a single additive buyer is #P-hard, even when the distributions have support size 2 for each item and the optimal solution is guaranteed to be a simple one: the seller picks a price for the grand bundle and a price for each individual item; the buyer can purchase either the grand bundle at the given price or any bundle of items at their total individual prices. We refer to this simple and natural family of pricing schemes as discounted item-pricings. In addition to the hardness result, we show that when the distributions are i.i.d. with support size 2, a discounted item-pricing can achieve the optimal revenue obtainable by lottery-pricings and it can be found in polynomial time.",2017-02-22,https://www.semanticscholar.org/paper/230253dbefc3e959ee9072bb824a5f39e3c6d407,arXiv.org
1180,Search for a resonance decaying into WZ boson pairs in pp collisions.,"We present the first search for an electrically charged resonance W' decaying to a WZ boson pair using 4.1 fb(-1) of integrated luminosity collected with the D0 detector at the Fermilab Tevatron pp collider. The WZ pairs are reconstructed through their decays into three charged leptons (l=e, mu). A total of 9 data events is observed in good agreement with the background prediction. We set 95% C.L. limits on the W'WZ coupling and on the W' production cross section multiplied by the branching fractions. We also exclude W' masses between 188 and 520 GeV within a simple extension of the standard model and set the most restrictive limits to date on low-scale technicolor models.",2009-12-03,https://www.semanticscholar.org/paper/c28d43fc66b8c81880cfea1a805ac0d843cdc9db,Physical Review Letters
2740,Automating the generation of coordinated multimedia explanations,"An explanation system developed to overcome the disadvantages of conventional authoring in multimedia applications is presented. This experimental test bed for the automated generation of multimedia explanations is called COMET (coordinated multimedia explanation testbed), and has as its goal the coordinated, interactive generation of explanations that combine text and three-dimensional graphics, all of which is generated on the fly. In response to a user request for an explanation, COMET dynamically determines the explanation's content using constraints based on the type of request, the information available in a set of underlying knowledge bases, and information about the user's background and goals. Having determined what to say, COMET also determines how to express it at the time of generation. A brief overview of COMET's domain and architecture is followed by a description of the specific ways in which COMET can coordinate its text and graphics. The current status and limitations of COMET are discussed.<<ETX>>",1991-10-01,https://www.semanticscholar.org/paper/6ad11caa1f61fb19563f55cf84d20625523bc828,Computer
2152,Lower bounds for the capacity of channels with i.i.d. deletions and insertions,"Consider the simplest channel which introduces deletions; or binary i.i.d. deletion channel: each transmitted bit is independently deleted with probability d. The capacity C del of this channel remains unknown since Dobrushin's introduction of the problem in 1967. The topic of this thesis is provable lower bounds for Cdel by developping Shannon-style theorems. Although this implies that the codes considered in this work are of no practical interest, practical codes are not required to prove capacity bounds. Moreover, existing lower bounds for the capacity of this channel arising from the study of the performance of efficient codes are significantly below the theoretical bounds we prove. 
Previous theoretical approaches to lower bound C del implicitly attempt typical set decoding. The improvements in our work arise in two ways. First, we explicitly consider typical set decoding, thus establishing that one clear way to improve capacity lower bounds is to refine the definitions of the typical sets. We start by refining the definition of the typical received sequence after the i.i.d. deletion channel, by observing further structural properties of the received sequence. Then we refine the decoding algorithm by using a more sophisticated set of received sequences jointly typical with a codeword. Second, we introduce a new framework for generating codewords, which allows consideration of more general codebooks, while using our new definitions of typical sets; the analysis in previous frameworks was not amenable to such generalizations. Our approach allows for dramatic improvements on the lower bounds. Moreover, for d > 0.65, we surpass a combinatorial upper bound for channels with an asymptotic fraction of d synchronization errors. 
Another advantage of our framework is that it can be applied to analyze more general channels. Specifically, we consider the i.i.d. channel with deletions and insertions, where insertions only occur in the form of copies. We provide a general lower bound for the capacity of this channel (under the assumption of geometrically decreasing tails for the insertion distribution). We then use this result to show that Cdel > (1- d)/9, via a reduction argument.",,https://www.semanticscholar.org/paper/c53bdd8fd9703f0ff2d8254c1d092ed68a1ecc67,
1093,Search for Low-Mass Weakly Interacting Massive Particles with SuperCDMS Citation,,,https://www.semanticscholar.org/paper/9098f7c21a0de3222a76825815b40ba004b1c76e,
1509,Search for the Flavor-changing Neutral Current Decay B,,,https://www.semanticscholar.org/paper/e5ef60457afbb2d1cf5b2e9e11b1117894785943,
3672,‘Long return’: A technique for improving the efficiency of inter‐module communication,"This paper describes a concept called ‘long return’ for use in inter‐module communication systems. First an implementation which implies a simplification of—rather than an extension of—traditional inter‐module communication systems is outlined. This implementation allows long returns to be used as an optimization technique without violating the commonly accepted principles of system structuring. Thereafter an experiment that provides an estimate of the improvements in efficiency of a particular operating system is described. In the SIMOS operating systems (based on the Cambridge CAP operating system) about 20 per cent of all inter‐process communication operations can be avoided by using long returns, and as a consequence the amount of useful work done in the system is typically increased by about 2.0 per cent.",1981-02-01,https://www.semanticscholar.org/paper/165514669f7afeb93b3f2b9abfc141c3f82fe625,"Software, Practice & Experience"
1138,Evidence ofWW andWZ Production with leptonþ jets Final States,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, M. Ahsan, G. D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G.A. Alves, M. Anastasoaie, L. S. Ancu, T. Andeen, B. Andrieu, M. S. Anzelc, M. Aoki, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, A. C. S. Assis Jesus, O. Atramentov, C. Avila, F. Badaud, L. Bagby, B. Baldin, D. V. Bandurin, P. Banerjee, S. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, G. Blazey, F. Blekman, S. Blessing, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, E. E. Boos, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, X. B. Bu, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, T. H. Burnett, C. P. Buszello, P. Calfayan, S. Calvet, J. Cammin, M.A. Carrasco-Lizarraga, E. Carrera, W. Carvalho, B. C. K. Casey, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K.M. Chan, A. Chandra, E. Cheu, D. K. Cho, S. Choi, B. Choudhary, L. Christofek, T. Christoudias, S. Cihangir, D. Claes, J. Clutter, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, V. Cuplov, D. Cutts, M. Ćwiok, H. daMotta, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, K. DeVaughan, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, T. Dorland, A. Dubey, L. V. Dudko, L. Duflot, S. R. Dugad, D. Duggan, A. Duperrin, S. Dutt, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V. D. Elvira, Y. Enari, S. Eno, P. Ermolov,38,xx H. Evans, A. Evdokimov, V.N. Evdokimov, A.V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, C. Garcia, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, W. Geng, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, B. Gómez, A. Goussiou, P. D. Grannis, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, F. Guo, J. Guo, G. Gutierrez, P. Gutierrez, A. Haas, N. J. Hadley, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, K. Harder, A. Harel, J.M. Hauptman, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, A. P. Heinson, U. Heintz, C. Hensel,22,x K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, T. Hoang, J. D. Hobbs, B. Hoeneisen, M. Hohlfeld, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, C. Jarvis, R. Jesik, K. Johns, C. Johnson, M. Johnson, D. Johnston, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, D. Karmanov, P. A. Kasper, I. Katsanos, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y. N. Kharzheev, D. Khatidze, T. J. Kim, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, J.-P. Konrath, A.V. Kozelov, J. Kraus, T. Kuhl, A. Kumar, A. Kupco, T. Kurča, V. A. Kuzmin, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, W.M. Lee, A. Leflat, J. Lellouch, J. Li,78,xx L. Li, Q. Z. Li, S.M. Lietti, J. K. Lim, J. G. R. Lima, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna-Garcia,33,k A.L. Lyon, A.K.A. Maciel, D. Mackin, R. J. Madaras, P. Mättig, A. Magerkurth, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, Y. Maravin, B. Martin, R. McCarthy, M.M. Meijer, A. Melnitchouk, L. Mendoza, P. G. Mercadante, M. Merkin, K.W. Merritt, A. Meyer, J. Meyer,22,x J. Mitrevski, R.K. Mommsen, N. K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, H. A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, D. C. O’Neil, G. Obrant, C. Ochando, D. Onoprienko, N. Oshima, N. Osman, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park,22,x S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, M. Petteni, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma,33,{ V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, B. G. Pope, A. V. Popov, C. Potter, W. L. Prado da Silva, H. B. Prosper, S. Protopopescu, J. Qian, A. Quadt,22,x B. Quinn, A. Rakitine, M. S. Rangel, K. Ranjan, P. N. Ratoff, P. Renkel, P. Rich, M. Rijssenbeek, I. Ripp-Baudot, F. Rizatdinova, S. Robinson, R. F. Rodrigues, M. Rominsky, C. Royon, P. Rubinov, PRL 102, 161801 (2009) P HY S I CA L R EV I EW LE T T E R S week ending 24 APRIL 2009",,https://www.semanticscholar.org/paper/003d61a584fd1c8abbfcaa8881cc610295440547,
3201,Boat to bowl: resilience through network rewiring of a community-supported fishery amid the COVID-19 pandemic,"Fisheries are coupled human–natural systems locally, regionally, and globally. However, human–nature interactions within and between adjacent and distant systems (metacouplings) are rarely studied in fisheries despite their prevalence and policy relevance. We filled this knowledge gap by using network models to identify how the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) pandemic has rewired couplings and reshaped resilience of Fishadelphia, a community-supported fishery program (CSF) in New Jersey and Pennsylvania, USA. As abstractions illustrating interactions among supply-chain actors, networks are helpful for characterizing flows and assessing resilience to disturbances such as those induced by the SARS-CoV-2 pandemic. Since Fall 2018, 18 seafood (finfish and shellfish) species totaling 6273 lbs have flowed from harvesters (n = 4), to processors (n = 2), to a distributor, to retailers (n = 2), and finally to customers (n = 183). The pandemic reduced the number of seafood harvesters and processors (−50%), seafood flow quantity (−25%), species diversity in the marketplace (−67%), and species per supplier (−50%) before stopping flows in mid-March 2020, when Fishadelphia closed for 3 months. Models of network optimality indicated that the pandemic fragmented metacouplings that previously allowed multiple seafood suppliers to provide diverse products to customers. However, demand-side resilience increased through dispersed, socially distanced, efficient seafood delivery that expanded the customer base and generally increased customer satisfaction. This resilience dichotomy—wherein the post-closure network was less resilient than the pre-closure network in supply-side species diversity, but more resilient in demand-side social distancing, delivery efficiency, and customer satisfaction—has implications for rewiring networks to sustain CSFs and other local food systems amid ecological and social disturbances.",2021-03-01,https://www.semanticscholar.org/paper/e903eeb3acd54c5439a5592b8caa580fb610c36c,
1979,Master production schedule and system for excelling enterprise resources (SEER) in the LED industry,"Every enterprise is pursuing energy conservation and carbon reduction development. Under this trend, light-emitting diodes (LEDs) are becoming the focus of the lighting industry. Because of the different levels or types of chips and substrates, the characteristics of products will be different. LED products are categorized according to characteristics such as luminescence efficiency, wavelength (color), and the reference voltage level. Traditionally, lack of good communication channels for production and sales department led to excessive inventories, even though the demand was satisfied. These products face the risk of being unsalable due to the short product life cycle. Therefore, this study developed a system for excelling enterprise resources (SEER) for LED manufacturing that optimizes chip procurement and production planning by linear programming. The system considered the deviation of the output distribution during the production to allocate the amount of chip and process to maximize profit. This study chooses the LED packaging company in Taiwan Hsinchu Science Park as an empirical case. We analyzed the different planning criteria to find some management rules and let this system become a communication tool between the production and sales department.",2013-08-01,https://www.semanticscholar.org/paper/8310b911c9d303d460b071e2521fb34146aec52b,2013 IEEE International Conference on Automation Science and Engineering (CASE)
3290,Group structure in a restricted entry system is mediated by both resident and joiner preferences,,2010-03-05,https://www.semanticscholar.org/paper/50ddda1a11259688837e23c26cf2851da689b02a,Behavioral Ecology and Sociobiology
809,On the complexity of protein folding (extended abstract),forefront of today’s science (often referred to dramatically as “breaking the genetic code” or “the last phase of the We ahow that the protein folding problem in the two-dimensional Mendelian revolution”). This mapping cm be rou&ly &H-P model io NP-complete.,1998-05-23,https://www.semanticscholar.org/paper/a56ef182b5d7484ed4bd3602cfe7829ed53636f6,Symposium on the Theory of Computing
1635,Science and data science,"Data science has attracted a lot of attention, promising to turn vast amounts of data into useful predictions and insights. In this article, we ask why scientists should care about data science. To answer, we discuss data science from three perspectives: statistical, computational, and human. Although each of the three is a critical component of data science, we argue that the effective combination of all three components is the essence of what data science is about.",2017-08-07,https://www.semanticscholar.org/paper/c0225f99c9b1619c3be74b63241faffe02d275d7,Proceedings of the National Academy of Sciences of the United States of America
316,The complexity of computing a Nash equilibrium,"We resolve the question of the complexity of Nash equilibrium by showing that the problem of computing a Nash equilibrium in a game with 4 or more players is complete for the complexity class PPAD. Our proof uses ideas from the recently-established equivalence between polynomial time solvability of normal form games and graphical games, establishing that these kinds of games can simulate a PPAD-complete class of Brouwer functions.",2006-05-21,https://www.semanticscholar.org/paper/2982faa144efe77492e13e64917a7337d0b96008,Symposium on the Theory of Computing
3122,Using certes to infer client response time at the web server,"As businesses continue to grow their World Wide Web presence, it is becoming increasingly vital for them to have quantitative measures of the mean client perceived response times of their web services. We present Certes (CliEnt Response Time Estimated by the Server), an online server-based mechanism that allows web servers to estimate mean client perceived response time, as if measured at the client. Certes is based on a model of TCP that quantifies the effect that connection drops have on mean client perceived response time by using three simple server-side measurements: connection drop rate, connection accept rate and connection completion rate. The mechanism does not require modifications to HTTP servers or web pages, does not rely on probing or third party sampling, and does not require client-side modifications or scripting. Certes can be used to estimate response times for any web content, not just HTML. We have implemented Certes and compared its response time estimates with those obtained with detailed client instrumentation. Our results demonstrate that Certes provides accurate server-based estimates of mean client response times in HTTP 1.0/1.1 environments, even with rapidly changing workloads. Certes runs online in constant time with very low overhead. It can be used at websites and server farms to verify compliance with service level objectives.",2004-02-01,https://www.semanticscholar.org/paper/5afd1c7147cb182d9841cb67ffd9e572206f837d,TOCS
446,The future of computational complexity theory: part I,"As you probably already know, there is an active discussion going on---in forums ranging from lunch-table conversations to workshops on ""strategic directions"" to formal reports---regarding the future of theoretical computer science. Since your complexity columnist does not know The Answer, I've asked a number of people to contribute their comments on the narrower issue of the future of complexity theory. The only ground rule was a loose 1-page limit; each contributor could choose what aspect(s) of the future to address, and the way in which to address them. The first installment of contributions appears in this issue, and one or two more installments will appear among the next few issues.Also coming during the next few issues: the search for the perfect theory journal, and (for the sharp-eyed) Lance Fortnow dons a clown suit. Finally, let me mention that work of Russell Impagliazzo resolves one of the open questions from Complexity Theory Column 11.",1996-09-01,https://www.semanticscholar.org/paper/1f0284fc0958d3316d4d9c55ae7a4fb7c23df248,SIGA
2608,"Proceedings of the 17th Annual ACM Symposium on User Interface Software and Technology, Santa Fe, NM, USA, October 24-27, 2004",,,https://www.semanticscholar.org/paper/bba9f646d92e21ddbd6870a230c394a4c4a2d886,ACM Symposium on User Interface Software and Technology
686,CitiSense ± Adaptive Services for Community-Driven Behavioral and Environmental Monitoring to Induce Change,"In this work we present CitiSense, a new kind RI 3FLWL]HQ LQIUDVWUXFWXUH ́ for the monitoring of pollution and environmental conditions that users are exposed to. By utilizing mobile phones and affordable, small sensors placed in the environment and carried by users, data about pollutants such as ozone and carbon monoxide is collected and used to provide real-time feedback to users and enable them to make healthy changes in their behavior. Results can be reported to a back-end server for further processing and learning, allowing other stakeholders to better understand how diseases such as asthma develop and to help coordinate efforts within a user's community to improve conditions. What differentiates CitiSense from previous projects of this sort is the design of a complete system that addresses issues of mobile power management, data security, privacy, inference with commodity sensors, and integration into a highly extensible and adaptive infrastructure comprising of Open Rich Services (ORS). We discuss the design goals of the CitiSense project, our progress towards the vision of ubiquitous environmental sensing in San Diego, and preliminary results for energy management policies for sensor nodes and mobile phones.",,https://www.semanticscholar.org/paper/29842e4f36b3e57f856b10d68e81d8971b2726b4,
3117,Improving web browsing performance on wireless pdas using thin-client computing,"Web applications are becoming increasingly popular for mobile wireless PDAs. However, web browsing on these systems can be quite slow. An alternative approach is handheld thin-client computing, in which the web browser and associated application logic run on a server, which then sends simple screen updates to thePDA for display. To assess the viability of this thin-client approach, we compare the web browsing performance of thin clients against fat clients that run the web browser locally on a PDA. Our results show that thin clients can provide better web browsing performance compared to fat clients, both in terms of speed and ability to correctly display web content. Surprisingly, thin clients are faster even when having to send more data over the network. We characterize and analyze different design choices in various thin-client systems and explain why these approaches can yield superior web browsing performance on mobile wireless PDAs.",2004-05-17,https://www.semanticscholar.org/paper/1a2ff6a4c321174d26eacbd63c8b67f48077077c,The Web Conference
1610,Dose-response modeling in high-throughput cancer drug screenings: an end-to-end approach.,"Personalized cancer treatments based on the molecular profile of a patient's tumor are an emerging and exciting class of treatments in oncology. As genomic tumor profiling is becoming more common, targeted treatments for specific molecular alterations are gaining traction. To discover new potential therapeutics that may apply to broad classes of tumors matching some molecular pattern, experimentalists and pharmacologists rely on high-throughput, in vitro screens of many compounds against many different cell lines. We propose a hierarchical Bayesian model of how cancer cell lines respond to drugs in these experiments and develop a method for fitting the model to real-world high-throughput screening data. Through a case study, the model is shown to capture nontrivial associations between molecular features and drug response, such as requiring both wild type TP53 and overexpression of MDM2 to be sensitive to Nutlin-3(a). In quantitative benchmarks, the model outperforms a standard approach in biology, with $\approx20\%$ lower predictive error on held out data. When combined with a conditional randomization testing procedure, the model discovers markers of therapeutic response that recapitulate known biology and suggest new avenues for investigation. All code for the article is publicly available at https://github.com/tansey/deep-dose-response.",2018-12-13,https://www.semanticscholar.org/paper/ba84afa9279d794cada027bed70e9a343b9add6e,Biostatistics
1083,TeV in the fully hadronic decay channel,,,https://www.semanticscholar.org/paper/9b87c2eda9cd9acd6324c8dfab3115090749af2d,
228,"Algorithms, games, and evolution","Significance Theoretical biology was founded on the mathematical tools of statistics and physics. We believe there are productive connections to be made with the younger field of theoretical computer science, which shares with it an interest in complexity and functionality. In this paper, we find that the mathematical description of evolution in the presence of sexual recombination and weak selection is equivalent to a repeated game between genes played according to the multiplicative weight updates algorithm, an algorithm that has surprised computer scientists time and again in its usefulness. This equivalence is informative for the pursuit of two key problems in evolution: the role of sex and the maintenance of variation. Even the most seasoned students of evolution, starting with Darwin himself, have occasionally expressed amazement that the mechanism of natural selection has produced the whole of Life as we see it around us. There is a computational way to articulate the same amazement: “What algorithm could possibly achieve all this in a mere three and a half billion years?” In this paper we propose an answer: We demonstrate that in the regime of weak selection, the standard equations of population genetics describing natural selection in the presence of sex become identical to those of a repeated game between genes played according to multiplicative weight updates (MWUA), an algorithm known in computer science to be surprisingly powerful and versatile. MWUA maximizes a tradeoff between cumulative performance and entropy, which suggests a new view on the maintenance of diversity in evolution.",2014-06-16,https://www.semanticscholar.org/paper/61e2e06431c6245f3bd4f8668517044f6f459a75,Proceedings of the National Academy of Sciences of the United States of America
3671,Classes: an abstract data type facility for the C language,"Language constructs for definition and use of abstract data types ease the design and maintenance of large programs. This paper describes the C class concept, an extension to the C language providing such constructs. A class is defined using standard C data types and functions, and it can itself be used as a building block for new classes. A class provides a way of restricting access to a data structure to a specific set of functions associated with it, without incurring significant overheads at compile time or at run time.The C class concept is introduced by small examples of its use, and familiarity with the C language [2] is assumed. Appendix A is a complete small C program using classes.Classes have been in use for more than a year on a dozen PDP11 and VAX UNIX systems [1], and they are currently used for a diverse set of projects on more than 30 systems. Classes are currently implemented by an intermediate pass of the cc compiler, called the class pre-processor, which is invoked when the directive #class is found in a C source file. The class pre-processor is easily ported to a system with a version of the portable C compiler. A Motorola68000 version is in use.",,https://www.semanticscholar.org/paper/645dcc2de160209d6d547c557348ff9d61b9b619,SIGP
1055,"Erratum: First Dark Matter Constraints from a SuperCDMS Single-Charge Sensitive Detector [Phys. Rev. Lett. 121, 051301 (2018)].",This corrects the article DOI: 10.1103/PhysRevLett.121.051301.,2019-02-11,https://www.semanticscholar.org/paper/02895170aa33fe8a6f5bd764fec2c1e140bc3834,Physical Review Letters
3303,"Fecal glucocorticoid metabolite analysis as an indicator of stress during translocation and acclimation in an endangered large mammal, the Grevy's zebra","Fecal glucocorticoid metabolite (FGM) analysis provides a non‐invasive method for studying the physiological response of wildlife to a variety of stressors and is a ground‐breaking monitoring technique in wildlife management and conservation. The conservation benefits of successful wildlife translocation restocking efforts are significant but understandably stressful for the animals being captured, removed from familiar habitat, held in captivity in many cases and subsequently released into an unfamiliar environment. It is imperative that we identify non‐invasive methods for evaluating stress in translocated animals, especially in endangered species. Twenty Grevy's zebra Equus grevyi were translocated to Meru National Park as part of a Kenya Wildlife Service re‐population initiative. FGMs were monitored from the time of capture, during captivity and post‐release as an indicator of the stress of translocation and acclimation to the new environment. FGMs from representative non‐translocated zebra were used as a further control. When held in pens at Meru Park 3–4 and 5–6 weeks after capture, the zebra had higher FGMs (25.1±1.2 and 23.4±1.3 ng g−1) than either at the time of capture (14.6±2.1 ng g−1) or non‐translocated controls (16.2±1.2 ng g−1). This suggests that the stress of captivity elevated FGMs. FGM concentrations returned to pre‐capture concentrations c. 11–18 weeks after the zebra were released into Meru Park. The return of FGM concentrations to baseline suggests successful acclimation to the new environment. This study supports the use of FGM analysis as an assessment technique in wildlife management projects involving the movement of endangered large mammals with application for monitoring stress in a wide array of conservation projects involving translocation, reintroduction and rehabilitation.",2008-08-01,https://www.semanticscholar.org/paper/90d476ce0caa01809b30da7094c1bb0063de9ed0,
663,Contrastive Loss is All You Need to Recover Analogies as Parallel Lines,"While static word embedding models are known to represent linguistic analogies as parallel lines in high-dimensional space, the underlying mechanism as to why they result in such geometric structures remains obscure. We find that an elementary contrastive-style method employed over distributional information performs competitively with popular word embedding models on analogy recovery tasks, while achieving dramatic speedups in training time. Further, we demonstrate that a contrastive loss is sufficient to create these parallel structures in word embeddings, and establish a precise relationship between the co-occurrence statistics and the geometric structure of the resulting word embeddings.",2023-06-14,https://www.semanticscholar.org/paper/abdc56442fdf09a08b8495d57a1e5a22840c3f8c,Workshop on Representation Learning for NLP
2111,A Portfolio-Evaluation Framework for Selecting R&D Projects,"This study aims to form the basis for constructing a framework for evaluating alternative portfolios of R&D projects. This study provides an extensive literature review on portfolio selection. Most of the existing studies deal with the portfolio selection problem by evaluating individual projects and then seeking ways to combine them for an R&D portfolio. However, the combination of individually good projects unnecessarily constitutes the optimal portfolio. In particular, this study discusses three portfolio effects: (1) the difference between the preference for the portfolio as a whole and the preference for the projects, (2) the interrelation among projects, (3) the size of portfolio selection problems. This study develops a three-phase framework for evaluating R&D portfolios and proposes a new taxonomy of the portfolio attributes (i.e. independent, interrelated, and synergistic). This study concludes with a discussion of future research, directed toward increasing the applicability of portfolio-selection approaches for managing R&D portfolios.",2002-09-01,https://www.semanticscholar.org/paper/8f55fede85d9f9572f4035034b7681ac50b91cdb,
1376,Search for narrow t(t)over-bar resonances in p(p)over-bar collisions at root s=1.8 TeV,"A search for narrow resonances that decay into t (t) over bar pairs has been performed using 130 pb(-1) of data in the lepton + jets channel collected by the DO detector in p (p) over bar collisions at roots=1.8 TeV. There is no significant deviation observed from the standard-model predictions at a top-quark mass of 175 GeV/c(2). We therefore present upper limits at the 95% confidence level on the product of the production cross section and branching fraction to t (t) over bar for narrow resonances as a function of the resonance mass M-X. These limits are used to exclude the existence of a leptophobic top-color particle with mass M-X<560 GeV/c(2), using a theoretical cross section for a width Gamma(X)=0.012M(X).",2004-06-04,https://www.semanticscholar.org/paper/bee93743cb70536cb37ed137662b87387301686e,
3332,The Ups and Downs of Researching Cycling Populations,,1990-04-01,https://www.semanticscholar.org/paper/74a5ddbe0920a5c6848f184b3765b685427cfc47,
3668,The UNIX system: Data abstraction in C,"C++ is a superset of the C programming language; it is fully implemented and has been used for nontrivial projects. There are now more than one hundred C++ installations. This paper describes the facilities for data abstraction provided in C++. These include Simula-like classes providing (optional) data hiding, (optional) guaranteed initialization of data structures, (optional) implicit type conversion for user-defined types, and (optional) dynamic typing; mechanisms for overloading function names and operators; and mechanisms for user-controlled memory management. It is shown how a new data type, like complex numbers, can be implemented, and how an “object-based” graphics package can be structured. A program using these data abstraction facilities is at least as efficient as an equivalent program not using them, and the compiler is faster than older C compilers.",1984-10-01,https://www.semanticscholar.org/paper/51b06d367a1f343157ace7b2abec69e7fb42bdbe,AT&T Bell Laboratories Technical Journal
3233,Striping patterns may not influence social interactions and mating in zebra: Observations from melanic zebra in South Africa,"Colouration serves many functions in animals including crypsis, aposematism, mimicry, intraspecific communication, communication between species and thermoregulation (Caro, Caswell Stoddard, & Stuard-Fox, 2017). On occasions, abnormalities or discontinuous variations in colouration and/or patterning of an individual within a population can occur, leading to albinism (Osinga, ‘t Hart, & Vader, 2010), leucism (Reisinger, Mufanadzo, de Bruyn, & Bester, 2009) or melanism (Eizirik et al., 2003; Majerus, 1998). Melanism, a rare condition occurring when a group of pigments (pheomelanin or eumelanin) is overproduced, has been reported in a variety of mammal species. Zebra (Equus spp.) are widely distributed in southern Africa in a variety of ecosystems with two species found in South Africa: the plains zebra (Equus quagga) and the Cape mountain zebra (Equus zebra) (Caro, 2005; Marais, Nel, Bertschinger, Schoeman, & Zimmerman, 2007). These animals have distinctive white and black striping patterns which can vary regionally from heavy black and white striping over the entire body to areas of reduced stripe coverage with thinner and lighter stripes (Rubenstein, 2011). Pigmentation decisions occur at around 3–5 weeks of development, while the hairs that show the pattern do not grow until about 6 months (Bard, 1981). Many hypotheses exist to explain striping in zebra; including camouflage against predators, disrupting predatory attacks, thermoregulation, social cohesion and avoidance of ectoparasite attacks from biting flies and other insects (Blaho et al., 2012, 2013; Caro, 2016; Egri et al., 2012; Horvath et al., 2010; Larison et al., 2015; Melin, Kline, Hiramatsu, & Caro, 2016; Ruxton, 2002). This manuscript describes two cases of melanic plains zebra observed inside the Mkambati Nature Reserve in the Eastern Cape Province of South Africa. This reserve of 7,736 ha is managed by the Eastern Cape and Tourism Agency (ECPTA) and is located approximately 25 km south of the coastal town of Port Edward (KwaZulu-Natal). Zebra were introduced in the reserve in 1979, along with several other ungulate species. At that time of introduction, no large predators were present and none are present today (De Villiers & Costello, 2006). During two field excursions (3 June 2015–24 June 2015 and 20 November 2016–7 December 2016), opportunistic photographs of melanic zebra were taken from as close to the animal as possible (approximately 20 m) and from both sides. The number of animals in each melanic zebra’s group, defined as all animals within 100 m of each other, was also noted and photographed for later identification. In 2016, observations were taken at least every 2 days, when animals were within viewable range. To quantify the colouration patterns, the amount of black/saturated area and percentage of striped areas were visually estimated for different parts of the body (head and neck, flank, rump and legs) to the nearest 5% or 10% depending on photograph quality. The intensity of the black colouration was scored as “light” (<30%), “medium” (30%–60%) or “dark” (>60%). Where there was striping, the number of stripes was counted and the shape of the stripes was described.",2018-06-01,https://www.semanticscholar.org/paper/eb68d37cfb43a0ac24c135a8098497302c1c773b,
1604,Readmission prediction via deep contextual embedding of clinical concepts,"Objective Hospital readmission costs a lot of money every year. Many hospital readmissions are avoidable, and excessive hospital readmissions could also be harmful to the patients. Accurate prediction of hospital readmission can effectively help reduce the readmission risk. However, the complex relationship between readmission and potential risk factors makes readmission prediction a difficult task. The main goal of this paper is to explore deep learning models to distill such complex relationships and make accurate predictions. Materials and methods We propose CONTENT, a deep model that predicts hospital readmissions via learning interpretable patient representations by capturing both local and global contexts from patient Electronic Health Records (EHR) through a hybrid Topic Recurrent Neural Network (TopicRNN) model. The experiment was conducted using the EHR of a real world Congestive Heart Failure (CHF) cohort of 5,393 patients. Results The proposed model outperforms state-of-the-art methods in readmission prediction (e.g. 0.6103 ± 0.0130 vs. second best 0.5998 ± 0.0124 in terms of ROC-AUC). The derived patient representations were further utilized for patient phenotyping. The learned phenotypes provide more precise understanding of readmission risks. Discussion Embedding both local and global context in patient representation not only improves prediction performance, but also brings interpretable insights of understanding readmission risks for heterogeneous chronic clinical conditions. Conclusion This is the first of its kind model that integrates the power of both conventional deep neural network and the probabilistic generative models for highly interpretable deep patient representation learning. Experimental results and case studies demonstrate the improved performance and interpretability of the model.",2018-04-09,https://www.semanticscholar.org/paper/888ba07b575eda30a26edc69ef846c3a387f8394,PLoS ONE
3386,Queuing Safely for Elevator Systems Amidst a Pandemic,"The requirement of social distancing during the COVID-19 pandemic has presented significant challenges for high-rise buildings, which heavily rely on elevators for vertical transportation. In particular, the need for social distancing has reduced elevator capacity by by at least half and as much as two-thirds the normal amount. This reduction is a serious concern, as reduced elevator capacities cause large queues to build up in lobbies, which makes social distancing a challenge. The objective of this study was to propose simple interventions for safely managing the elevator queues that drastically reduce the waiting time and length of lobby queues. We use mathematical modeling, epidemiological principles, and simulation to design and evaluate our interventions. The key idea is to explicitly or implicitly group passengers that are going to the same floor into the same elevator as much as possible. In the Cohorting intervention, we attempt to find passengers going to the same floor as the first person in the queue. In the Queue Splitting intervention, we create a different queue for different groups of floors. Based on simulation studies, Cohorting and Queue Splitting can significantly reduce queue length and wait time, while also maintaining safety from viral transmission in otherwise crowded elevators, building lobbies, and entrances. The interventions we propose do not require programming the elevators, and rely on using signage and/or a queue manager to guide passengers.",2020-12-21,https://www.semanticscholar.org/paper/cb2bd44198aff5dcdf0fbf037c2261ccc7d831c7,Social Science Research Network
3581,What Makes the History of Software Hard,,,https://www.semanticscholar.org/paper/4d56dd7e1638a71dfda03782c8a264f968d94848,
2963,Allelic Expression of Deleterious Protein-Coding Variants across Human Tissues,"Personal exome and genome sequencing provides access to loss-of-function and rare deleterious alleles whose interpretation is expected to provide insight into individual disease burden. However, for each allele, accurate interpretation of its effect will depend on both its penetrance and the trait's expressivity. In this regard, an important factor that can modify the effect of a pathogenic coding allele is its level of expression; a factor which itself characteristically changes across tissues. To better inform the degree to which pathogenic alleles can be modified by expression level across multiple tissues, we have conducted exome, RNA and deep, targeted allele-specific expression (ASE) sequencing in ten tissues obtained from a single individual. By combining such data, we report the impact of rare and common loss-of-function variants on allelic expression exposing stronger allelic bias for rare stop-gain variants and informing the extent to which rare deleterious coding alleles are consistently expressed across tissues. This study demonstrates the potential importance of transcriptome data to the interpretation of pathogenic protein-coding variants.",2014-05-01,https://www.semanticscholar.org/paper/339ae721e765c79f1f4b169f57a82ff21d1058f4,PLoS Genetics
2537,Evaluating the benefits of augmented reality for task localization in maintenance of an armored personnel carrier turret,"We present the design, implementation, and user testing of a prototype augmented reality application to support military mechanics conducting routine maintenance tasks inside an armored vehicle turret. Our prototype uses a tracked head-worn display to augment a mechanic's natural view with text, labels, arrows, and animated sequences designed to facilitate task comprehension, location, and execution. A within-subject controlled user study examined professional military mechanics using our system to complete 18 common tasks under field conditions. These tasks included installing and removing fasteners and indicator lights, and connecting cables, all within the cramped interior of an armored personnel carrier turret. An augmented reality condition was tested against two baseline conditions: an untracked headworn display with text and graphics and a fixed flat panel display representing an improved version of the laptop-based documentation currently employed in practice. The augmented reality condition allowed mechanics to locate tasks more quickly than when using either baseline, and in some instances, resulted in less overall head movement. A qualitative survey showed mechanics found the augmented reality condition intuitive and satisfying for the tested sequence of tasks.",2009-10-19,https://www.semanticscholar.org/paper/c0e9ba5a47d70049e9feae8b033c1d8e711c0f28,2009 8th IEEE International Symposium on Mixed and Augmented Reality
3757,Learning Aligned Cross-Modal Representations from Weakly Aligned Data,"People can recognize scenes across many different modalities beyond natural images. In this paper, we investigate how to learn cross-modal scene representations that transfer across modalities. To study this problem, we introduce a new cross-modal scene dataset. While convolutional neural networks can categorize cross-modal scenes well, they also learn an intermediate representation not aligned across modalities, which is undesirable for crossmodal transfer applications. We present methods to regularize cross-modal convolutional neural networks so that they have a shared representation that is agnostic of the modality. Our experiments suggest that our scene representation can help transfer representations across modalities for retrieval. Moreover, our visualizations suggest that units emerge in the shared representation that tend to activate on consistent concepts independently of the modality.",2016-06-27,https://www.semanticscholar.org/paper/7e64992091458256f438fbe1bd44fffcc197b76c,Computer Vision and Pattern Recognition
694,"Extremal combinatorics, iterated pigeonhole arguments, and generalizations of PPP","We study the complexity of computational problems arising from existence theorems in extremal combinatorics. For some of these problems, a solution is guaranteed to exist based on an iterated application of the Pigeonhole Principle. This results in the definition of a new complexity class within TFNP, which we call PLC (for""polynomial long choice""). PLC includes all of PPP, as well as numerous previously unclassified total problems, including search problems related to Ramsey's theorem, the Sunflower theorem, the Erd\H{o}s-Ko-Rado lemma, and K\""onig's lemma. Whether the first two of these four problems are PLC-complete is an important open question which we pursue; in contrast, we show that the latter two are PPP-complete. Finally, we reframe PPP as an optimization problem, and define a hierarchy of such problems related to Tur\'an's theorem.",2022-09-15,https://www.semanticscholar.org/paper/2fa43041e7d7c8badb18902ae06ccd8bd2cd8058,Information Technology Convergence and Services
1021,Deep Reinforcement Learning for Snake Robot Locomotion,,,https://www.semanticscholar.org/paper/dc01cfaa8a42db58c0f98900b99362819693467f,
1202,Measurement of theProduction Cross Section inCollisions at,,2008-05-15,https://www.semanticscholar.org/paper/157cb499da640f55fc17f80cd09f3de9f284e014,
2272,Anaplasma phagocytophilum Reduces Neutrophil Apoptosis In Vivo,"ABSTRACT Ovine neutrophils spontaneously underwent apoptosis during culture in vitro, as assessed by morphological changes and exposure of annexin V binding sites on their cell surfaces. The addition of conditioned medium from concanavalin A-treated ovine peripheral blood mononuclear cells (PBMC) could partially protect against this progression into apoptosis, but dexamethasone and sodium butyrate could not. Actinomycin D accelerated the rate at which ovine neutrophils underwent apoptosis. Neutrophils isolated from sheep experimentally infected with Anaplasma phagocytophilum showed significantly delayed apoptosis during culture ex vivo, and the addition of conditioned medium from PBMC to these cells could not delay apoptosis above the protective effects observed after in vivo infection. The ability of neutrophils from A. phagocytophilum-infected sheep to activate a respiratory burst was increased compared to the activity measured in neutrophils from uninfected sheep, but chemotaxis was decreased in neutrophils from infected sheep. These data are the first demonstration that in vivo infection with A. phagocytophilum results in changes in rates of apoptosis of infected immune cells. This may help explain how these bacteria replicate in these normally short-lived cells.",2003-04-01,https://www.semanticscholar.org/paper/b7bbe6734e076d9f2b8b45b2b3810387adea1f12,Infection and Immunity
3267,High carbon and biodiversity costs from converting Africa’s wet savannahs to cropland,,2015-05-01,https://www.semanticscholar.org/paper/ffb18dfdf0c196fc673480b3cb3193cc69166210,
3593,Proposed Wording for Concepts,"Introduction This document provides proposed wording for concepts. Readers unfamiliar with concepts are encouraged to read the complete proposal [1]. It is recommended that readers “tour” this concepts wording using N2399=07-0259, which provides an examples-directed view of the major language features involved in concepts, cross-referenced with this document. This document provides wording for changes to the core language. Changes to the standard library are discussed in separate documents: — Concepts for the C++0x Standard Library: Approach [N2036=06-0106] — Concepts for the C++0x Standard Library: Introduction [N2037=06-0107] — Core Concepts for the C++0x Standard Library [N2502=08-0012] — Concepts for the C++0x Standard Library: Utilities (Revision 2) [N2322=07-0182] — Concepts for the C++0x Standard Library: Containers [N2085=06-0155] — Iterator Concepts for the C++0x Standard Library [N2500=08-0010] — Concepts for the C++0x Standard Library: Iterators (Revision 2) [N2323=07-0183] — Concepts for the C++0x Standard Library: Algorithms (Revision 1) [N2084=06-0154] — Concepts for the C++0x Standard Library: Numerics [N2041=06-0111]",,https://www.semanticscholar.org/paper/c6eaafa80f5cca5e5678cc5096b57aa4673b68c6,
685,Latent variables based data estimation for sensing applications,"Recovering missing sensor data is a critical problem for sensor networks, especially when nodes duty cycle their activity or may experience periodic downtimes due to limited energy. Fortunately, sensor readings are often correlated across different nodes and sensor types. Among state-of-the-art statistical data estimation techniques, latent variable based factor models have emerged as a powerful framework for recovering missing data. In this paper we propose the use of latent variable models to estimate missing data in heterogeneous sensor networks. Our model not only correlates data across different sensor locations and types, but also takes advantage of the temporal structure that is often present in sensor readings. We analyze how this model can effectively reconstruct missing sensor data when the individual sensor nodes have to duty-cycle their activity in order to extend network lifetime. We evaluate our model on a real life sensor network consisting of 122 environmental monitoring stations that periodically collect data from 13 different sensors. Results show that our proposed model can effectively reconstruct over 50% of missing data with less than 10% error.",2011-12-01,https://www.semanticscholar.org/paper/c43ec6a8ddefb32a703a71eb4316ad64476d59ec,"2011 Seventh International Conference on Intelligent Sensors, Sensor Networks and Information Processing"
3660,A set of c++ classes for co-routine style programming,,,https://www.semanticscholar.org/paper/ae06cfbcd9f75b7c5e26eef56a7e7ea52f71658a,
3325,Mortality risk of spatial positions in animal groups: The danger of being in the front,"We modified Hamilton's (1971) selfish herd model by introducing directional movement to the prey groups and the predators. The consequences of this modification with regards to differential predation risks are compared to Hamilton's original model (using stationary prey groups) and tested against empirical data. In model 1, we replicated Hamilton's original predator-prey system. In models 2 and 3, prey groups were mobile and predators were mobile (model 2) or stationary (model 3). Our results indicate that additional to the positive risk gradient from centre to periphery predicted by Hamilton's model for stationary groups, there might be another positive risk gradient from the rear to the front part in moving groups. Furthermore, models 2 and 3 suggest that moving groups should generally exhibit an elongated shape (longer than wide along the axis of locomotion) if risk minimisation is the only factor concerned. Also smaller inter-individual distances are predicted for front individuals than individuals elsewhere in the group. Empirical data based on the three-dimensional structure of fish shoals (using roach, Rutilus rutilus) were consistent with the above two predictions. A second experiment which involved lake chub, Semotilus atromaculatus, as prey and rock bass, Ambloplites rupestris, as predators, provided direct support for the hypothesis that individuals in front positions of groups incurred a significantly higher predation risk than fish in rear positions. Finally, we discuss the differential risks of different group positions in the context of potential foraging gains which provides the basis for a dynamic model of position preferences in group-living animals.",,https://www.semanticscholar.org/paper/33a52569f8a00a0174ae6935393386ee369e8b69,
797,On the approximability of trade-offs and optimal access of Web sources,"We study problems in multiobjective optimization, in which solutions to a combinatorial optimization problem are evaluated with respect to several cost criteria, and we are interested in the trade-off between these objectives (the so-called Pareto curve). We point out that, under very general conditions, there is a polynomially succinct curve that /spl epsiv/-approximates the Pareto curve, for any /spl epsiv/>0. We give a necessary and sufficient condition under which this approximate Pareto curve can be constructed in time polynomial in the size of the instance and 1//spl epsiv/. In the case of multiple linear objectives, we distinguish between two cases: when the underlying feasible region is convex, then we show that approximating the multi-objective problem is equivalent to approximating the single-objective problem. If however the feasible region is discrete, then we point out that the question reduces to an old and recurrent one: how does the complexity of a combinatorial optimization problem change when its feasible region is intersected with a hyperplane with small coefficients; we report some interesting new findings in this domain. Finally, we apply these concepts and techniques to formulate and solve approximately a cost-time-quality trade-off for optimizing access to the World-Wide Web, in a model first studied by Etzioni et al. (1996) (which was actually the original motivation for this work).",2000-11-12,https://www.semanticscholar.org/paper/87e3b80fa6a8902a1f00b336c1a2134991d2f44e,Proceedings 41st Annual Symposium on Foundations of Computer Science
1555,The Multi-Outcome Medical Deconfounder: Assessing Treatment Effect on Multiple Renal Measures,,,https://www.semanticscholar.org/paper/4438483026e4f34b3b6349554543447991f4eef1,American Medical Informatics Association Annual Symposium
697,Technical Perspective,"The paper Structure and Complexity of Bag Consistency by Albert Atserias and Phokion Kolaitis [1] studies fundamental structural and algorithmic questions on the global consistency of databases in the context of bag semantics. A collection D of relations is called globally consistent if there is a (so-called ""universal"") relation over all the attributes that appear in all the relations of D whose projections yield the relations in D. The basic algorithmic problem for consistency is: given a database D, determine whether D is globally consistent. An obvious necessary condition for global consistency is local (or pairwise) consistency: every pair of relations in D must be consistent. This condition is not sufficient however: It is possible that every pair is consistent, but there is no single global relation over all the attributes whose projections yield the relations in D. A natural structural question is: Which database schemas have the property that every locally consistent database over the schema is also globally consistent?",2022-05-31,https://www.semanticscholar.org/paper/c666ae62e0f726989ffd48a521493f9a4ead8952,SIGMOD record
2245,Microbial mannan inhibits bacterial killing by macrophages: a possible pathogenic mechanism for Crohn's disease.,"BACKGROUND & AIMS
Crohn's disease (CD) is mimicked by inherited phagocyte disorders and is associated with circulating antibodies against yeast mannan (anti-Saccharomyces cerevisiae antibody; ASCA). We speculated that mannans might impair phagocyte function.


METHODS
S cerevisiae mannan was assessed for its effects on human peripheral blood neutrophils, adherent monocytes, and monocyte-derived macrophages (MDM).


RESULTS
Mannan caused dose-related increased survival of CD Escherichia coli HM605 within adherent monocytes from 24% +/- 10.5% (control) to 114% +/- 22.7% with mannan 1 mg/mL at 2 hours (mean +/- SEM, n = 9; P = .0002). Electron microscopy showed E coli HM605 surviving and probably replicating within macrophage vesicles. Mannan (1 mg/mL) inhibited the respiratory burst in neutrophils and monocytes (both P = .002) and bacterial killing within MDM (P < .001). E coli survival was increased within macrophages from TLR4(-/-) (126% +/- 3.5% survival at 2 hours) and MyD88(-/-) (134.8% +/- 6.5%) mice compared with wild-type mice (both P < .0001). Mannan had no additional effect, showing that TLR4 and MyD88 are involved in bacterial killing by macrophages and its inhibition by mannan. Putative CD-associated micro-organisms were screened for the ASCA mannan epitope by Galanthus nivalis lectin (GNA) blotting. ASCA epitope was expressed by Candida albicans and Mycobacterium paratuberculosis but not by Mycobacterium tuberculosis or E coli. Supernatants from M paratuberculosis culture inhibited killing of E coli HM605 by adherent human monocytes and murine macrophages. The inhibitory activity was removed by GNA-affinity chromatography.


CONCLUSIONS
Suppression of mucosal phagocyte function by microbial mannans, possibly of Mycobacterial origin, may contribute to CD pathogenesis.",2007-11-01,https://www.semanticscholar.org/paper/142507867e5018cf96a4418b52d8a4c163e95d67,Gastroenterology
2723,Towards Coordinated Temporal Multimedia Presentations,,1993-01-02,https://www.semanticscholar.org/paper/d404cf581be53ba316587ce470ca50f3c5b26df1,AAAI Workshop on Intelligent Multimedia Interfaces
1186,Measurement of the Semileptonic Branching Ratio of B 0 s to an Orbitally Excited,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, S. H. Ahn, M. Ahsan, G.D. Alexeev, G. Alkhazov, A. Alton, G. Alverson, G. A. Alves, M. Anastasoaie, L. S. Ancu, T. Andeen, S. Anderson, B. Andrieu, M. S. Anzelc, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, A. C. S. Assis Jesus, O. Atramentov, C. Autermann, C. Avila, C. Ay, F. Badaud, A. Baden, L. Bagby, B. Baldin, D.V. Bandurin, S. Banerjee, P. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, C. Biscarat, G. Blazey, F. Blekman, S. Blessing, D. Bloch, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, S. Bunichev, S. Burdin, S. Burke, T. H. Burnett, C. P. Buszello, J.M. Butler, P. Calfayan, S. Calvet, J. Cammin, W. Carvalho, B. C. K. Casey, N.M. Cason, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K.M. Chan, K. Chan, A. Chandra, F. Charles,* E. Cheu, F. Chevallier, D.K. Cho, S. Choi, B. Choudhary, L. Christofek, T. Christoudias, S. Cihangir, D. Claes, Y. Coadou, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, D. Cutts, M. Ćwiok, H. da Motta, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, J. D. Degenhardt, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, H. Dong, L. V. Dudko, L. Duflot, S. R. Dugad, D. Duggan, A. Duperrin, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V. D. Elvira, Y. Enari, S. Eno, P. Ermolov, H. Evans, A. Evdokimov, V.N. Evdokimov, A. V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Ford, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, E. Gallas, E. Galyaev, C. Garcia, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, D. Gelé, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, N. Gollub, B. Gómez, A. Goussiou, P. D. Grannis, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grüendahl, M.W. Grünewald, J. Guo, F. Guo, P. Gutierrez, G. Gutierrez, A. Haas, N. J. Hadley, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, P. Hansson, K. Harder, A. Harel, R. Harrington, J.M. Hauptman, R. Hauser, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, J.M. Heinmiller, A. P. Heinson, U. Heintz, C. Hensel, K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, J. D. Hobbs, B. Hoeneisen, H. Hoeth, M. Hohlfeld, S. J. Hong, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, C. Jarvis, R. Jesik, K. Johns, C. Johnson, M. Johnson, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, A.M. Kalinin, J. R. Kalk, J.M. Kalk, S. Kappler, D. Karmanov, P. A. Kasper, I. Katsanos, D. Kau, R. Kaur, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y.M. Kharzheev, D. Khatidze, T. J. Kim, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, J.-P. Konrath, V.M. Korablev, A.V. Kozelov, D. Krop, T. Kuhl, A. Kumar, S. Kunori, A. Kupco, T. Kurča, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, W.M. Lee, A. Leflat, F. Lehner, J. Lellouch, J. Leveque, J. Li, Q. Z. Li, L. Li, S.M. Lietti, J. G. R. Lima, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna, A. L. Lyon, A.K. A. Maciel, D. Mackin, R. J. Madaras, P. Mättig, C. Magass, A. Magerkurth, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, H. S. Mao, Y. Maravin, B. Martin, R. McCarthy, A. Melnitchouk, L. Mendoza, P. G. Mercadante, M. Merkin, K.W. Merritt, J. Meyer, A. Meyer, T. Millet, J. Mitrevski, J. Molina, R. K. Mommsen, N.K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulders, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, N. A. Naumann, H.A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, V. O’Dell, D. C. O’Neil, G. Obrant, C. Ochando, D. Onoprienko, N. Oshima, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park, S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, M. Petteni, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma, V.M. Podstavkov, PRL 102, 051801 (2009) P HY S I CA L R EV I EW LE T T E R S week ending 6 FEBRUARY 2009",,https://www.semanticscholar.org/paper/ddabf1ed737028ac5d47e5df235a2ec5a907ace1,
251,Mechanisms for complement-free procurement,"We study procurement auctions when the buyer has complement-free (subadditive) objectives in the budget feasibility model (Singer 2010). For general subadditive functions we give a randomized universally truthful mechanism which is an O(log2 n) approximation, and an O(log3 n) deterministic truthful approximation mechanism; both mechanisms are in the demand oracle model. For cut functions, an interesting case of nonincreasing objectives, we give both randomized and deterministic truthful and budget feasible approximation mechanisms that achieve a constant approximation factor.",2011-06-05,https://www.semanticscholar.org/paper/3fb51b4a41e143c8c664e59b9f62b52f939cb176,ACM Conference on Economics and Computation
640,On the complexity of edge traversing,"It is shown that the Chinese Postman Problem, although tractable in the totally directed and the totally undirected cases, is NP-complete in the mixed case. A simpler version of the same problem is shown algorithmically equivalent to the max-flow problem with unit edge capacities.",1976-07-01,https://www.semanticscholar.org/paper/ca0442ff09eab30ceb3b883da3cd45fbe902f719,Journal of the ACM
154,Optimal Scheduling of the Leaves of a Tree and the SVO Frequencies of Languages,,,https://www.semanticscholar.org/paper/d0ad972391c11d83b181d5dd313697b9dc590985,Learning and Intelligent Optimization
2505,Exploring the Benefits of Augmented Reality Documentation for Maintenance and Repair,"We explore the development of an experimental augmented reality application that provides benefits to professional mechanics performing maintenance and repair tasks in a field setting. We developed a prototype that supports military mechanics conducting routine maintenance tasks inside an armored vehicle turret, and evaluated it with a user study. Our prototype uses a tracked headworn display to augment a mechanic's natural view with text, labels, arrows, and animated sequences designed to facilitate task comprehension, localization, and execution. A within-subject controlled user study examined professional military mechanics using our system to complete 18 common tasks under field conditions. These tasks included installing and removing fasteners and indicator lights, and connecting cables, all within the cramped interior of an armored personnel carrier turret. An augmented reality condition was tested against two baseline conditions: the same headworn display providing untracked text and graphics and a fixed flat panel display representing an improved version of the laptop-based documentation currently employed in practice. The augmented reality condition allowed mechanics to locate tasks more quickly than when using either baseline, and in some instances, resulted in less overall head movement. A qualitative survey showed that mechanics found the augmented reality condition intuitive and satisfying for the tested sequence of tasks.",2011-10-01,https://www.semanticscholar.org/paper/3244243bd0ab1790dfda1128390fd56674c24389,IEEE Transactions on Visualization and Computer Graphics
2511,"Dynamic, Abstract Representations of Audio in a Mobile Augmented Reality Conferencing System",,,https://www.semanticscholar.org/paper/b331fa7794d58d42ae37094f104e54068f996710,
2349,Neutrophils isolated from the synovial fluid of patients with rheumatoid arthritis: priming and activation in vivo.,"The oxidative metabolism of neutrophils isolated from the bloodstream and synovial fluid of 16 patients with rheumatoid arthritis was compared by measuring the ability of neutrophils to generate luminol dependent chemiluminescence and to secrete O2-. Measurements of receptor mediated--that is, N-formyl-methionyl-leucyl-phenylalanine stimulated--activation or receptor and second message independent--that is phorbol myristate acetate stimulated--activation showed that synovial fluid neutrophils had biochemical characteristics to suggest that they had been either up-regulated (primed) or down-regulated (activated) in vivo. These conclusions were confirmed by comparison of these responses with the changes in oxidative metabolism observed during in vitro priming and activation of control neutrophils: synovial fluid neutrophils possessed lower levels of myeloperoxidase than paired bloodstream cells, and unlike bloodstream cells could not be primed in vitro. These data thus suggest that synovial fluid neutrophils have been exposed to both priming and activating agents within rheumatoid joints.",1991-03-01,https://www.semanticscholar.org/paper/fddd4788538e89229954578529db0c43fe9f459c,Annals of the Rheumatic Diseases
2257,Cellular Interactions and Immunological Mechanisms,,2005-03-01,https://www.semanticscholar.org/paper/92a38bc7a7d4b38bd7abf0fbb32322dce2f8e024,
1594,Technical perspective: Expressive probabilistic models and scalable method of moments,,2018-03-26,https://www.semanticscholar.org/paper/3c94e61000c01763e785242a199e358f7a99446a,Communications of the ACM
7,Evaluating Twitter for Foodborne Illness Outbreak Detection in New York City,"Objective To incorporate data from Twitter into the New York City Department of Health and Mental Hygiene foodborne illness surveillance system and evaluate its utility and impact on foodborne illness complaint and outbreak detection. Introduction An estimated one in six Americans experience illness from the consumption of contaminated food (foodborne illness) annually; most are neither diagnosed nor reported to health departments 1 . Eating food prepared outside of the home is an established risk factor for foodborne illness 2 . New York City (NYC) has approximately 24,000 restaurants and >8.5 million residents, of whom 78% report eating food prepared outside of the home at least once per week 3 . Residents and visitors can report incidents of restaurant-associated foodborne illness to a citywide non-emergency information service, 311. In 2012, the NYC Department of Health and Mental Hygiene (DOHMH) began collaborating with Columbia University to improve the detection of restaurant-associated foodborne illness complaints using a machine learning algorithm and a daily feed of Yelp reviews to identify reports of foodborne illness 4 . Annually, DOHMH manages over 4,000 restaurant-associated foodborne illness reports received via 311 and identified on Yelp which lead to the detection of about 30 outbreaks associated with a restaurant in NYC. Given the small number of foodborne illness outbreaks identified, it is probable that many restaurant-associated foodborne illness incidents remain unreported. DOHMH sought to incorporate and evaluate an additional data source, Twitter, to enhance foodborne illness complaint and outbreak detection efforts in NYC. Methods DOHMH epidemiologists continue to collaborate with computer scientists at Columbia University who developed a text mining algorithm that identifies tweets indicating foodborne illness. Twitter data are received via a targeted application program interface query that searches for foodborne illness key words and uses metadata to select for tweets with a possible NYC location. Each tweet is assigned a sick score between 0–1; those meeting a threshold value of 0.5 are manually reviewed by an epidemiologist, and a survey link is tweeted to users who have tweeted about foodborne illness, requesting more information regarding the date and time of the foodborne illness event, restaurant details, and user contact information. Survey data are used to validate complaints and are incorporated in a daily analysis using all sources of complaint data to identify restaurants with multiple foodborne illness complaints within a 30-day period. This system was launched on November 29, 2016. Results During November 29, 2016–September 27, 2017, 12,015 tweets qualified for review (39/day on average); 2,288 (19.0%) indicated foodborne illness in NYC, and 1,778 (14.8%) were tweeted a survey link (510 foodborne illness tweets were either deleted by the Twitter user or were tweets from a user who was already sent a survey for the same foodborne illness incident). The survey tweets resulted in 92 likes, 12 retweets, 65 replies, 232 profile views and 348 survey link clicks. Of the 1,778 surveys sent, 27 were completed (response rate 1.5%), of which 20 (74.7%) confirmed foodborne illness associated with a NYC restaurant; none had been reported via 311/Yelp. Of those, 11 (55%) provided a phone number, of which 10 (90.9%) completed phone interviews. The completed surveys contributed to the identification of two restaurants with multiple foodborne illness complaints within a 30-day period. Conclusions The utility of Twitter for foodborne illness outbreak detection continues to be evaluated. While the survey response rate has been low, the identification of new complaints not otherwise reported to 311 and Yelp suggests this will be a useful tool. Future plans include using feedback data collected by DOHMH epidemiologist review to increase the sensitivity and specificity of the text mining algorithm and improve the location detection for Twitter users. In addition, we plan to implement enhancements to the survey and create a web page to promote survey responses. Furthermore, we intend to share this system with other health departments so that they might incorporate Twitter in their outbreak detection and public health surveillance activities. References 1. Scallan E, Griffin PM, Angulo FJ, Tauxe RV, Hoekstra RM. Foodborne illness acquired in the United States--unspecified agents. Emerg Infect Dis. 2011 Jan;17(1):16-22. 2. Jones TF, Angulo FJ. Eating in restaurants: a risk factor for foodborne disease? Clin Infect Dis. 2006 Nov 15;43(10):1324-8. 3. New York City Health and Nutrition Examination Survey, 2013-2014 [Internet]. New York: New York City Department of Health and Mental Hygiene and The City University of New York; 2017 [cited 2017 Aug 28]. Available from: http://nychanes.org/data/ 4. Harrison C, Jorder M, Stern H, Stavinsky F, Reddy V, Hanson H, Waechter H, Lowe L, Gravano L, Balter S; Centers for Disease Control and Prevention (CDC).. Using online reviews by restaurant patrons to identify unreported cases of foodborne illness - New York City, 2012-2013. MMWR Morb Mortal Wkly Rep. 2014 May 23;63(20):441-5.",2018-05-22,https://www.semanticscholar.org/paper/5da218d8f5303e1a93a17842b6762c6ea45fd7e8,Online Journal of Public Health Informatics
3753,Following Gaze Across Views,"Following the gaze of people inside videos is an important signal for understanding people and their actions. In this paper, we present an approach for following gaze across views by predicting where a particular person is looking throughout a scene. We collect VideoGaze, a new dataset which we use as a benchmark to both train and evaluate models. Given one view with a person in it and a second view of the scene, our model estimates a density for gaze location in the second view. A key aspect of our approach is an end-to-end model that solves the following sub-problems: saliency, gaze pose, and geometric relationships between views. Although our model is supervised only with gaze, we show that the model learns to solve these subproblems automatically without supervision. Experiments suggest that our approach follows gaze better than standard baselines and produces plausible results for everyday situations.",2016-12-09,https://www.semanticscholar.org/paper/1145d3d5c96157a9b19c1bedb090a5157537ad97,arXiv.org
537,The weighted region problem,"<italic>We present an algorithm for determining the shortest path between a source and a destination through a planar subdivision in which each region has an associated weight. Distances are measured according to a weighted Euclidean metric: Each region of the subdivision has associated with it a weight, and the weighted distance between two points in a convex region is the product of the corresponding weight and the Euclidean distance between them. Our algorithm runs in time &Ogr;</italic>(<italic>n</italic><supscrpt>7</supscrpt> <italic>L</italic>) <italic>and requires &Ogr;</italic>(<italic>n</italic><supscrpt>3</supscrpt>) <italic>space, where n is the number of edges of the subdivision, and L is the precision of the problem instance (including the number of bits in a user-specified tolerance ∈, which is the percentage the solution is allowed to differ from an optimal solution). The algorithm uses the fact that shortest paths obey Snell's Law of Refraction at region boundaries, a local optimality property of shortest paths that is well-known from the analogous optics model.</italic>",1987-10-01,https://www.semanticscholar.org/paper/3206d6f93bebaca6f41dee4a9aea3e9f5e4732fb,SCG '87
2221,Neutrophil-derived reactive oxygen species in SSc.,"OBJECTIVE
Reactive oxygen species (ROS) are implicated in the pathogenesis of SSc. Neutrophils constitute a major source of ROS during inflammation. Here, we examined endogenous and stimulated ex vivo ROS production of SSc neutrophils compared with control neutrophils with and without prior priming with TNF-α.


METHODS
ROS generation was measured using luminol-enhanced chemiluminescence. Neutrophils isolated from SSc patients and healthy controls were unprimed or were primed with TNF-α. ROS production was stimulated in vitro with phorbol 12-myristate 13-acetate (PMA) and formyl-met-leu-phe (fMLP). To examine the effects of serum mediators on ROS generation, control neutrophils were also stimulated with SSc or control serum.


RESULTS
Neutrophil stimulation with PMA and fMLP resulted in a greater increase in ROS generation in SSc neutrophils compared with controls. However, unstimulated SSc neutrophils generated lower levels of ROS than controls. SSc neutrophils demonstrated an increased response to fMLP in the absence of in vitro TNF-α priming indicating priming of SSc neutrophils in vivo. SSc serum did not stimulate neutrophil ROS generation in vitro.


CONCLUSION
SSc neutrophils are primed for ROS generation. Neutrophils binding to activated endothelium in SSc, may induce local production of ROS, perpetuating endothelial dysfunction and mediating fibrosis.",2012-07-01,https://www.semanticscholar.org/paper/4e7c9ab6932a8adbaafe5ecead395a07b5e3d7e8,Rheumatology
2040,Modeling semiconductor testing job scheduling and dynamic testing machine configuration,,2008-07-01,https://www.semanticscholar.org/paper/291dffa4ee142582c4f332be019d0c6787d98261,Expert systems with applications
463,The complexity of optimal queueing network control,"We consider the classical problem of optimal control (routing and sequencing) of a network of queues. We prove that this problem is EXP-complete and, therefore, provably intractable. Similar results are established for restricted versions of the problem. A weaker result is also established for the restless bandit problem.<<ETX>>",1994-06-28,https://www.semanticscholar.org/paper/101418b1a67f3fe27c842c70482b6d5f1b899a7c,Proceedings of IEEE 9th Annual Conference on Structure in Complexity Theory
2883,Modulation of functional properties of galectin-3 by monoclonal antibodies binding to the non-lectin domains.,"Galectin-3 is a member of a newly defined family of animal lectins, which is composed of three domains: a small amino-terminal domain, a domain containing repeating elements, and a carboxyl-terminal domain containing the carbohydrate-recognition site. Various functions have been described or proposed for this lectin, and it appears that galectin-3 has diverse roles. Murine monoclonal antibodies (MAbs) have been generated from mice hyperimmunized with recombinant human galectin-3 or galectin-3C (the carboxyl-terminal domain), and seven MAbs have been characterized in detail. All MAbs generated against the intact galectin-3 recognize the amino-terminal region of the molecule, as demonstrated by ELISA and immunoblotting using recombinant galectin-3C and galectin-3NR, which contains the amino-terminal domain and all the repeating elements. Their epitopes were all found to be within the first 45 amino acids of galectin-3, as determined by using galectin-3 mutants with a truncated amino-terminal region. However, these MAbs were found to profoundly modulate the lectin activities of galectin-3. The MAb B2C10 inhibited (i) the binding of 125I-labeled galectin-3 to IgE coated on microtiter plates; (ii) the galectin-3's hemagglutination activity; and (iii) galectin-3-induced superoxide production by human neutrophils. Other MAbs, especially A3A12, caused marked potentiation of these activities. The results support our model that the lectin function of galectin-3 is influenced by protein homodimerization resulting from self-association of the amino-terminal region of the molecule. The potentiating activities of some MAbs are probably due to facilitation of dimerization galectin-3, and the inhibitory activity of MAb B2C10 is probably the result of its disruption of the self-association process.",1996-05-14,https://www.semanticscholar.org/paper/afa5ad4f05c9b1c75e4556ca7586f0fe15e004b3,Biochemistry
3277,"Stigmergy, collective actions, and animal social spacing","Significance Marking animals avoid locations recently visited by others. We conceptualized this time nonlocal avoidance behavior as stigmergy, a form of mediated interaction that gives rise to coordinated behavior from seemingly independent individuals. In so doing, the concept of stigmergy is used beyond the realm of eusocial insects. To link the population spatiotemporal patterns that emerge from the individual nonlocal rules of interaction, we construct a collective movement model whereby randomly moving animals have the tendency to avoid marks left by a conspecific, depending on the age of the mark. As a result, we are able to quantify animal decision-making processes in terms of current and past locations of other individuals, linking behavior to history-dependent actions. Collective animal behavior studies have led the way in developing models that account for a large number of individuals, but mostly have considered situations in which alignment and attraction play a key role, such as in schooling and flocking. By quantifying how animals react to one another’s presence, when interaction is via conspecific avoidance rather than alignment or attraction, we present a mechanistic insight that enables us to link individual behavior and space use patterns. As animals respond to both current and past positions of their neighbors, the assumption that the relative location of individuals is statistically and history independent is not tenable, underscoring the limitations of traditional space use studies. We move beyond that assumption by constructing a framework to analyze spatial segregation of mobile animals when neighbor proximity may elicit a retreat, and by linking conspecific encounter rate to history-dependent avoidance behavior. Our approach rests on the knowledge that animals communicate by modifying the environment in which they live, providing a method to analyze social cohesion as stigmergy, a form of mediated animal–animal interaction. By considering a population of animals that mark the terrain as they move, we predict how the spatiotemporal patterns that emerge depend on the degree of stigmergy of the interaction processes. We find in particular that nonlocal decision rules may generate a nonmonotonic dependence of the animal encounter rate as a function of the tendency to retreat from locations recently visited by other conspecifics, which has fundamental implications for epidemic disease spread and animal sociality.",2013-09-30,https://www.semanticscholar.org/paper/3b66088991868728d65dcc1c8848492a1c1aa747,Proceedings of the National Academy of Sciences of the United States of America
677,Time-Accuracy Tradeoffs in Kernel Prediction: Controlling Prediction Quality,"Kernel regression or classification (also referred to as weighted e-NN methods in Machine Learning) are appealing for their simplicity and therefore ubiquitous in data analysis. However, practical implementations of kernel regression or classification consist of quantizing or sub-sampling data for improving time efficiency, often at the cost of prediction quality. While such tradeoffs are necessary in practice, their statistical implications are generally not well understood, hence practical implementations come with few performance guarantees. In particular, it is unclear whether it is possible to maintain the statistical accuracy of kernel prediction--crucial in some applications--while improving prediction time. 
 
The present work provides guiding principles for combining kernel prediction with data-quantization so as to guarantee good tradeoffs between prediction time and accuracy, and in particular so as to approximately maintain the good accuracy of vanilla kernel prediction. Furthermore, our tradeoff guarantees are worked out explicitly in terms of a tuning parameter which acts as a knob that favors either time or accuracy depending on practical needs. On one end of the knob, prediction time is of the same order as that of single-nearestneighbor prediction (which is statistically inconsistent) while maintaining consistency; on the other end of the knob, the prediction risk is nearly minimax-optimal (in terms of the original data size) while still reducing time complexity. The analysis thus reveals the interaction between the data-quantization approach and the kernel prediction method, and most importantly gives explicit control of the tradeoff to the practitioner rather than fixing the tradeoff in advance or leaving it opaque. 
 
The theoretical results are validated on data from a range of real-world application domains; in particular we demonstrate that the theoretical knob performs as expected.",,https://www.semanticscholar.org/paper/f68f682f9bf329dbba8c228989162ac7b4855e2c,Journal of machine learning research
1288,Search for the pair production of scalar top quarks in the acoplanar charm jet final state in pp̄ collisions at √ s = 1 . 96 TeV,"A search for the pair production of scalar top quarks, t̃ , has been performed in 360 pb−1 of data from pp̄ collisions at a center-of-mass energy of 1.96 TeV, collected by the DØ detector at the Fermilab Tevatron collider. The t̃ decay mode considered is t̃ → cχ̃0 1 , where χ̃0 1 is the lightest supersymmetric particle. The topology analyzed therefore consists of a pair of acoplanar heavy-flavor jets with missing transverse energy. The data and standard model expectation are in agreement, and a 95% C.L. exclusion domain in the (mt̃ ,mχ̃0 1 ) plane has been determined, extending the domain excluded by previous experiments. © 2006 Elsevier B.V. All rights reserved. PACS: 14.80.Ly; 12.60.Jv Supersymmetric (SUSY) models [1] predict the existence of new particles, carrying the same quantum numbers as their Standard Model (SM) partners, but differing by half a unit of spin. For instance, there are two scalar-quark fields asso* Corresponding author. E-mail address: grivaz@lal.in2p3.fr (J.-F. Grivaz). 1 Visitor from Helsinki Institute of Physics, Helsinki, Finland. ciated with the leftand right-handed degrees of freedom of each ordinary quark. The mass eigenstates result from the diagonalization of a mass matrix, with elements determined by the specific SUSY-breaking pattern. A light SUSY partner of the top quark, or stop, is a generic prediction of models in which the scalar quark masses are equal at the grand unification scale. A first reason is that, due to the impact of the large top quark Yukawa coupling in the renormalization group equations, DØ Collaboration / Physics Letters B 645 (2007) 119–127 123 the diagonal elements of the mass matrix are driven to values smaller than those for the other scalar quarks at the electroweak scale [2]. A second reason is that the off-diagonal terms are proportional to the relevant quark mass, and hence are much larger in the case of the top quark. The mass eigenstates are therefore broadly split, with the mass of the lighter stop t̃ thus driven to an even lower value [3]. Finally, a light stop is a necessary ingredient in the context of electroweak baryogenesis [4]. In models with R-parity conservation [5], the lightest SUSY particle (LSP) is stable, and cosmological constraints imply that it should be neutral and colorless [6]. In a large class of SUSY models, the lightest of the neutralinos—the mass eigenstates resulting from the mixing of the SUSY partners of the neutral gauge and Higgs bosons—is the LSP, which furthermore appears as a viable dark matter candidate. In the following, it will be assumed that R-parity is conserved and that the LSP is the lightest neutralino χ̃0 1 . The dominant stop decay modes are expected to be t̃ → t χ̃0 1 and t̃ → bχ̃+ 1 , where the chargino χ̃+ 1 is the lighter of the two mass eigenstates resulting from the mixing of the SUSY partners of the charged gauge and Higgs bosons. However, in the t̃ mass range of interest in this Letter, the t̃ → t χ̃0 1 decay mode is kinematically forbidden. In the following, the region of SUSY parameter space with mt̃ < mb + mχ̃+ 1 and mt̃ < MW + mb + mχ̃0 1 is considered, and it is assumed that t̃ → cχ̃0 1 , a flavor-changing loop decay [7], is the only relevant decay mode, i.e., that the tree-level four-body decays [8] t̃ → bf f̄ ′χ̃0 1 can be neglected. In pp̄ collisions, stop pair production proceeds via qq̄ annihilation and gluon–gluon fusion. The cross section has very little dependence on SUSY parameters other than the stop mass. At the center-of-mass energy of 1.96 TeV available in Run II of the Fermilab Tevatron collider, it ranges from 15 to 2.25 pb for stop masses from 100 to 140 GeV, as calculated at nextto-leading order (NLO) with PROSPINO [9], for equal renormalization and factorization scales μrf = mt̃ and using the CTEQ6.1M parton distribution functions (PDFs) [10]. The final state topology resulting from the t̃ → cχ̃0 1 decay is a pair of acoplanar jets, with large missing transverse energy / ET carried away by the two weakly interacting LSPs. Previous searches in this topology performed at LEP excluded stop masses smaller than ≈ 100 GeV, essentially independent of the stop-χ̃0 1 mass difference [11]. Searches in data from the Run I of the Tevatron [12,13] extended the domain excluded at LEP to larger stop masses, but for χ̃0 1 masses not exceeding ≈ 50 GeV. The largest stop mass excluded was 122 GeV, for mχ̃0 1 = 45 GeV [13]. In this Letter, we report on a similar search, performed in data collected using the DØ detector during Run II of the Tevatron. The acoplanar jet topology may arise from new physics processes other than stop pair production. Recently, the DØ Collaboration performed a search for pair production of leptoquarks decaying into a quark and a neutrino [14], which leads to the same topology. The analysis reported here is largely based on that leptoquark search. In the following, only a brief summary of the common aspects is given, while the specific features relevant for the stop search are presented in greater detail. The main differences arise from the LSP mass, which leads to smaller jet transverse energies and to a reduced / ET , compared to the case of leptoquark decays which involve nearly massless neutrinos. Another characteristic feature of stop decays is that charm jets are produced, while first-generation leptoquarks decay to light-flavor jets. A thorough description of the DØ detector can be found in Ref. [15]. The central tracking system consists of a silicon microstrip tracker and a fiber tracker, both located within a 2 T superconducting solenoidal magnet. A liquid-argon and uranium calorimeter covers pseudorapidities |η| 4.2, where η = − ln[tan(θ/2)] and θ is the polar angle with respect to the proton beam direction. An outer muon system, covering |η| < 2, consists of layers of tracking detectors and scintillation counters on both sides of 1.8 T iron toroids. For this search, ≈ 14 million events collected from April 2003 to August 2004 with a jets + / ET trigger were analyzed, corresponding to an integrated luminosity2 of 360 pb−1. The offline analysis utilized jets reconstructed with the iterative midpoint cone algorithm [17] with a cone size of 0.5. Only jets with transverse momentum pT > 15 GeV were considered in the analysis. The / ET was calculated using all calorimeter cells, corrected for the energy calibration of reconstructed jets, as determined from the transverse momentum balance in photon + jet events, and for the momentum of reconstructed muons. Signal efficiencies and SM backgrounds were evaluated using a full GEANT-3 [18] based simulation of events, with a Poisson average of 0.8 minimum-bias events superimposed, corresponding to the luminosity profile of the data sample analyzed. These simulated events were reconstructed in the same way as the data. In the bulk of events from QCD multijet production, no significant / ET is expected. Jet energy mismeasurements due to the limited detector resolution may however lead to large measured / ET values. This “instrumental background” was not simulated, and its contribution estimated directly from the data. In the following, “Standard Model (SM) background” stands for “non-QCD Standard Model (SM) background”. Leptonic W decays, as well as Z → νν are sources of energetic neutrinos, hence of genuine / ET . The SM processes expected to yield the largest background contributions are therefore vector boson production in association with jets. They were generated with ALPGEN 1.3 [19], interfaced with PYTHIA 6.202 [20] for the simulation of initial and final state radiation and for jet hadronization. The PDFs used were CTEQ5L [21]. The NLO cross sections for vector boson production in association with jets were calculated with MCFM 3.4.4 [22]. Vector-boson pair, t t̄ , and single top quark production were also considered. Signal samples of 10 000 events were generated with PYTHIA and the CTEQ5L PDFs for stop masses ranging from 95 to 145 GeV and for χ̃0 1 masses from 40 to 70 GeV, both in steps of 5 GeV. The following selection criteria were applied, independent of the stop and χ̃0 1 masses: there had to be at least two jets; the vec2 This value differs from the one used in Ref. [14] due to a recent adjustment of the DØ luminosity constant [16]. 124 DØ Collaboration / Physics Letters B 645 (2007) 119–127 Fig. 1. Distributions of the asymmetry A = (/ ET − / HT )/(/ ET + / HT ) with the cut on D = Φmax − Φmin inverted (top-left) or applied (bottom-left) and of D with the cut on A inverted (top-right) or applied (bottom-right) for data (points with error bars), for SM backgrounds (filled histogram), and for a signal with mt̃ = 140 GeV and χ̃0 1 = 60 GeV (hatched histogram). The / ET cut at 60 GeV has been applied. In the bottom plots, the excesses in data for A < −0.05 and for D > 120◦ are attributed to the residual non-simulated instrumental background. tor sum / HT of all jet transverse momenta (/ HT = |∑jets pT |) as well as the missing transverse energy had to exceed 40 GeV; the leading and subleading jets (where jets are ordered according to their transverse momentum) had to be central (|ηdet| < 1.5, where ηdet is the pseudorapidity measured from the detector center), with transverse momenta exceeding 40 and 20 GeV, respectively, and they had to be confirmed by charged particle tracks [14]; the acoplanarity Φ of the two leading jets had to be smaller than 165◦, where Φ is the difference between the two jet azimuthal angles; the longitudinal position of the primary vertex had to be less than 60 cm away from the center of the detector. At this point, 99 884 events were selected, largely dominated by instrumental background from multijet events. The efficiency for a reference signal with mt̃ = 140 GeV and mχ̃0 1 = 60 GeV was 30%. The jet multiplicity distribution revealed that most of the selected events contained at least three jets, due to the acoplanarity requirement. Therefore, only events containing exactly two ",,https://www.semanticscholar.org/paper/af3266c3f5855948ba5c707498096c8aae455df9,
3335,The greenhouse effect and biological diversity,,1989-03-01,https://www.semanticscholar.org/paper/250ba2b545e6a192e38781acae975461d79fe7f5,
928,On Minimal Eulerian Graphs,,1981-08-13,https://www.semanticscholar.org/paper/d5cf61d4919c01a7d2e02904820b00a37edfba9f,Information Processing Letters
2489,The Development of Mobile Augmented Reality,,,https://www.semanticscholar.org/paper/031a79ddfc901299466d1b5708524cc680355606,Expanding the Frontiers of Visual Analytics and Visualization
3078,ASSURE: automatic software self-healing using rescue points,"Software failures in server applications are a significant problem for preserving system availability. We present ASSURE, a system that introduces rescue points that recover software from unknown faults while maintaining both system integrity and availability, by mimicking system behavior under known error conditions. Rescue points are locations in existing application code for handling a given set of programmer-anticipated failures, which are automatically repurposed and tested for safely enabling fault recovery from a larger class of (unanticipated) faults. When a fault occurs at an arbitrary location in the program, ASSURE restores execution to an appropriate rescue point and induces the program to recover execution by virtualizing the program's existing error-handling facilities. Rescue points are identified using fuzzing, implemented using a fast coordinated checkpoint-restart mechanism that handles multi-process and multi-threaded applications, and, after testing, are injected into production code using binary patching. We have implemented an ASSURE Linux prototype that operates without application source code and without base operating system kernel changes. Our experimental results on a set of real-world server applications and bugs show that ASSURE enabled recovery for all of the bugs tested with fast recovery times, has modest performance overhead, and provides automatic self-healing orders of magnitude faster than current human-driven patch deployment methods.",2009-02-28,https://www.semanticscholar.org/paper/f7226ce7103c263d9c1ec2310019125aa1572369,International Conference on Architectural Support for Programming Languages and Operating Systems
1560,Towards Clarifying the Theory of the Deconfounder,"Wang and Blei (2019) studies multiple causal inference and proposes the deconfounder algorithm. The paper discusses theoretical requirements and presents empirical studies. Several refinements have been suggested around the theory of the deconfounder. Among these, Imai and Jiang clarified the assumption of ""no unobserved single-cause confounders."" Using their assumption, this paper clarifies the theory. Furthermore, Ogburn et al. (2020) proposes counterexamples to the theory. But the proposed counterexamples do not satisfy the required assumptions.",2020-03-10,https://www.semanticscholar.org/paper/85a988216a1c6590fc762050eb24ff69cf732a6e,arXiv.org
1939,A dynamic task assignment approach based on individual worklists for minimizing the cycle time of business processes,,2016-09-01,https://www.semanticscholar.org/paper/bfc3510149ceaea912167ad9d7916625b5443edd,Computers & industrial engineering
2654,A study of communication in the Cardiac Surgery Intensive Care Unit and its implications for automated briefing,"We present a study of the information transferred among caregivers in the context of cardiac surgery and use the study to evaluate a system, MAGIC, that we are developing for automated generation of briefings. Our framework integrates cognitive and quantitative evaluation methods and features three standards that reflect current practice in the Cardiothoracic Intensive Care Unit (CTICU). Using experimental design to compare human-generated and machine-generated briefings, we show that MAGIC's current level of performance is useful. Moreover, MAGIC could help improve information flow in the CTICU by providing a consistent set of information earlier than in current practice. The separate standards are also consistent in suggesting specific modifications that may be necessary for iterative design and further system development.",,https://www.semanticscholar.org/paper/a43b08dab508794496b0eb12d4275be5bec0d7b5,American Medical Informatics Association Annual Symposium
1967,Manufacturing intelligence and innovation for digital manufacturing and operational excellence,,2014-10-01,https://www.semanticscholar.org/paper/9de0053e27006d20c99be1ea158db6592447beec,Journal of Intelligent Manufacturing
3235,Pastoralist societies in flux: A conceptual framework analysis of herding and land use among the Mukugodo Maasai of Kenya,,2017-07-04,https://www.semanticscholar.org/paper/022cb5f4d7c6edb67cbbebfc2b8ad87a02b6d9cd,Pastoralism
2325,Interferon-gamma enhances monocyte cytotoxicity via enhanced reactive oxygen intermediate production. Absence of an effect on macrophage cytotoxicity is due to failure to enhance reactive nitrogen intermediate production.,"Interferon-gamma (IFN-gamma) enhanced the cytotoxic capability of freshly isolated human blood monocytes but failed to enhance the tumoricidal competence of monocyte-derived macrophages. Treatment of monocytes with IFN-gamma (100 U/ml) caused a significant increase (P < 0.001) in lucigenin-dependent chemiluminescence and O2- production stimulated by N-formyl-L-methionyl-L-leucyl-L-phenylalanine (FMLP) during the first few days in culture but IFN-gamma was unable to prevent the decline to negligible levels of chemiluminescence and O2- production which occurred during the later days in vitro. Culture of monocytes in the presence of IFN-gamma had no effect on phorbol 12-myristate 13-acetate (PMA)-stimulated O2- production. However, IFN-gamma decreased PMA-stimulated lucigenin-dependent chemiluminescence during the first 24 hr in vitro but then significantly enhanced (P < 0.001) chemiluminescence after 2-4 days in culture. IFN-gamma was unable to prevent the eventual decline to undetectable levels in PMA-stimulated chemiluminescence during the later days in vitro. Nitrite production by macrophages was unaffected by IFN-gamma treatment. It is concluded therefore, that IFN-gamma enhanced the cytotoxicity of freshly isolated human blood monocytes by increasing reactive oxygen intermediate generation but was unable to enhance the tumoricidal competence of macrophages as reactive nitrogen intermediate production was unaffected.",1994-04-01,https://www.semanticscholar.org/paper/884f13b1b623b66463011887f80975c2295a873c,Immunology
2097,Using process experienced correlation table to improve the accuracy and reliability of data mining for yield improvement,"The rapid innovation of new process technologies in the semiconductor industry, especially 12 inches Fab, along with continuously growing amounts of data, it is difficult to find root cause when problems occur in some process steps. It causes large amount of wafer scrapping. The analysis methods of traditional EDA system rely on experience of senior engineers. They need to define the suspected process step by their experience and then perform analysis. The analysis methods consume large amounts of human resources in order to determine the root cause of process and yield excursions. Hence, it is important that a knowledge retention method be incorporated to improve the efficiency of root cause analysis. Data mining, a new data analysis method that combines information science and technology of statistical analysis, is developed recently. The new generation data analysis method includes statistical, information science and mathematical calculation to find correlation between the target parameter, for example yield and other parameters. It will provide important clue to the analyzer. In addition, it also provides a direction to find root cause rapidly. It is difficult to find the correlation between the target parameter and other parameters by traditional statistical analysis method, and data mining can solve the blind point of the traditional method. This article discusses the design of how to define the relation between all data sources of semiconductor industry based on the experience of senior engineers. And it installs the relation to data mining analysis, it performs the analysis to identify relationship among all data sources. So, engineers can find the root cause of process issue in a short period of time",2004-09-09,https://www.semanticscholar.org/paper/ced06d058175269b386cf4305f63645e0373c334,2004 Semiconductor Manufacturing Technology Workshop Proceedings (IEEE Cat. No.04EX846)
1852,A latent mixed membership model for relational data,"Modeling relational data is an important problem for modern data analysis and machine learning. In this paper we propose a Bayesian model that uses a hierarchy of probabilistic assumptions about the way objects interact with one another in order to learn latent groups, their typical interaction patterns, and the degree of membership of objects to groups. Our model explains the data using a small set of parameters that can be reliably estimated with an efficient inference algorithm. In our approach, the set of probabilistic assumptions may be tailored to a specific application domain in order to incorporate intuitions and/or semantics of interest. We demonstrate our methods on simulated data and we successfully apply our model to a data set of protein-to-protein interactions.",2005-08-21,https://www.semanticscholar.org/paper/48291923daa6a5d3174c3150444d2996141f78b2,LinkKDD '05
3054,"Finding Concurrency Errors in Sequential Code - OS-level, In-vivo Model Checking of Process Races","While thread races have drawn huge attention from the research community, little has been done for process races, where multiple--possibly sequential--processes access a shared resource, such as a file, without proper synchronization. We present a preliminary study of real process races and show that they are numerous, dangerous, and difficult to detect. To address this problem, we present the design of RACEPRO, an in-vivo model checking system for automatically detecting process races in deployed systems, along with preliminary results from a RACEPRO prototype. To the best of our knowledge, we are the first to study real process races, and RACEPRO is the first system to detect them.",2011-05-09,https://www.semanticscholar.org/paper/c4b0d2557ecf70a53a7255a66dd7b31599dcd73c,USENIX Workshop on Hot Topics in Operating Systems
3778,AVSS 2011 demo session: A large-scale benchmark dataset for event recognition in surveillance video,"Summary form only given. We present a concept for automatic construction site monitoring by taking into account 4D information (3D over time), that is acquired from highly-overlapping digital aerial images. On the one hand today's maturity of flying micro aerial vehicles (MAVs) enables a low-cost and an efficient image acquisition of high-quality data that maps construction sites entirely from many varying viewpoints. On the other hand, due to low-noise sensors and high redundancy in the image data, recent developments in 3D reconstruction workflows have benefited the automatic computation of accurate and dense 3D scene information. Having both an inexpensive high-quality image acquisition and an efficient 3D analysis workflow enables monitoring, documentation and visualization of observed sites over time with short intervals. Relating acquired 4D site observations, composed of color, texture, geometry over time, largely supports automated methods toward full scene understanding, the acquisition of both the change and the construction site's progress.",2011-08-30,https://www.semanticscholar.org/paper/2c305fa65fed336e6be1d15a6567075c6ea6e51b,Advanced Video and Signal Based Surveillance
124,"Fully Adaptive Minimal Deadlock-Free Packet Routing in Hypercubes, Meshes, and other Networks: Algorithms and Simulations","This paper deals with the problem of packet-switched routing in parallel machines. Several new routing algorithms for different interconnection networks are presented. While the new techniques apply to a wide variety of networks, routing algorithms will be shown for the hypercube, the two-dimensional mesh, and the shuffle-exchange. Although the new techniques are designed for packet routing, they can be used alternatively for virtual cut-through routing models. The techniques presented for hypercubes and meshes are fully-adaptive and minimal. A fully-adaptive and minimal routing is one in which all possible minimal paths between a source and a destination are of potential use at the time a message is injected into the network. Minimal paths followed by messages ultimately depend on the local congestion encountered in each node of the network. All of the new techniques are completely free of deadlock situations. >",1994-03-01,https://www.semanticscholar.org/paper/405b70a06edf58884990df609a622bd245f816d6,IEEE Trans. Parallel Distributed Syst.
3123,ksniffer: Determining the Remote Client Perceived Response Time from Live Packet Streams,"As dependence on the World Wide Web continues to grow, so does the need for businesses to have quantitative measures of the client perceived response times of their Web services. We present ksniffer, a kernel-based traffic monitor capable of determining pageview response times as perceived by remote clients, in real-time at gigabit traffic rates. ksniffer is based on novel, online mechanisms that take a ""look once, then drop"" approach to packet analysis to reconstruct TCP connections and learn client pageview activity. These mechanisms are designed to operate accurately with live network traffic even in the presence of packet loss and delay, and can be efficiently implemented in kernel space. This enables ksniffer to perform analysis that exceeds the functionality of current traffic analyzers while doing so at high bandwidth rates. ksniffer requires only to passively monitor network traffic and can be integrated with systems that perform server management to achieve specified response time goals. Our experimental results demonstrate that ksniffer can run on an inexpensive, commodity, Linux-based PC and provide online pageview response time measurements, across a wide range of operating conditions, that are within five percent of the response times measured at the client by detailed instrumentation.",2004-12-06,https://www.semanticscholar.org/paper/66e91238ed494600f18b79b94aa45acfc5650e71,USENIX Symposium on Operating Systems Design and Implementation
3563,Support for the Evolution of C++ Generic Functions,,2010-10-12,https://www.semanticscholar.org/paper/a005b52922ebb34ed6edf7f44a6305cddf50ddc6,Software Language Engineering
1745,Factor Topographic Latent Source Analysis : Factor Analysis for Brain Images ?,"Traditional approaches to analyzing experimental functional magnetic resonance imaging (fMRI) data entail fitting per-voxel parameters to explain how the observed images reflect the thoughts and stimuli a participant experienced during the experiment. These methods implicitly assume that voxel responses are independent and that the unit of analysis should be the voxel. However, both of these assumptions are known to be untrue: it is well known that voxel activations exhibit strong spatial correlations, and common sense tells us that the true underlying brain activations are independent of the resolution at which the brain image happened to be taken. Here we propose a fundamentally different approach, whereby brain images are represented as weighted sums of spatial functions. Our technique yields compact representations of the brain images that leverage spatial correlations in the data and are independent of the image resolution.",,https://www.semanticscholar.org/paper/24fc405aea2faf86ac27f51fbe403433c8fddc7c,
1161,Measurement of the Semileptonic Branching Ratio of Bs(0) to an Orbitally Excited D-s** State: Br(Bs(0) -> Ds1(-)(2536)mu(+)nu X),"In a data sample of approximately 1.3 fb(-1) collected with the D0 detector between 2002 and 2006, the orbitally excited charm state D-s1(+/-)(2536) has been observed with a measured mass of 2535.7 +/- 0.6(stat) +/- 0.5(syst) MeV/c(2) via the decay mode B-s(0) -> D-s1(-)(2536)mu(+)nu X-mu. A first measurement is made of the branching ratio product Br((b) over bar -> D-s1(-)(2536)mu(+)nu X-mu) x Br(D-s1(-) -> D*K--(S)0). Assuming that D-s1(-)(2536) production in semileptonic decay is entirely from B-s(0), an extraction of the semileptonic branching ratio Br(B-s(0) -> D-s1(-)(2536)mu(+)nu X-mu) is made.",2009-02-03,https://www.semanticscholar.org/paper/7cb4f887e2b7bbf4ddd465b53d6483373ef59f9e,
3035,Synapse: New Data Integration Abstractions for Agile Web Application Development,,2015-04-21,https://www.semanticscholar.org/paper/f43e4affdf8603bcbffc02049294fde979cceef9,
3315,Social Behavior,,,https://www.semanticscholar.org/paper/6e791fccda0ecd4a4a16a443ca05c5cf138130cb,
1149,Measurement of the Zgamma --> nunu[over ]gamma production cross section and limits on anomalous ZZgamma and Zgammagamma couplings in pp[over] collisions at sqrt[s] = 1.96 TeV.,"We present the first observation of the Zgamma --> nunu[over ]gamma process at the Fermilab Tevatron at 5.1 standard deviations significance, based on 3.6 fb;{-1} of integrated luminosity collected with the D0 detector at the Fermilab Tevatron pp[over ] Collider at sqrt[s] = 1.96 TeV. The measured Zgamma production cross section multiplied by the branching fraction of Z --> nunu[over] is 32 +/- 9(stat + syst) +/-2 (lumi) fb for the photon E_{T} > 90 GeV. It is in agreement with the standard model prediction of 39 +/- 4 fb. We set limits on anomalous trilinear Zgammagamma and ZZgamma gauge boson couplings, most of which are the most restrictive to date.",,https://www.semanticscholar.org/paper/364da6d89c96e08edc49042e8481e5e70c08dbeb,Physical Review Letters
2570,Mobile augmented reality interaction techniques for authoring situated media on-site,"We present a set of mobile augmented reality interaction techniques for authoring situated media: multimedia and hypermedia that are embedded within the physical environment. Our techniques are designed for use with a tracked hand-held tablet display with an attached camera, and rely on ""freezing"" the frame for later editing.",2006-10-22,https://www.semanticscholar.org/paper/404682c45eacebc7bf01237cc7a6f400d91a6522,2006 IEEE/ACM International Symposium on Mixed and Augmented Reality
3129,Secure Isolation and Migration of Untrusted Legacy Applications,"Existing applications often contain security holes that are not patched until after the system has already been compromised. Even when software updates are applied to address security issues, they often result in system services being unavailable for some time. To address these system security and availability issues, we have developed peas and pods. A pea provides a least privilege environment that can restrict processes to the minimal subset of system resources needed to run. This mechanism enables the creation of environments for privileged program execution that can help with intrusion prevention and containment. A pod provides a group of processes and associated users with a consistent, machine-independent virtualized environment. Pods are coupled with a novel checkpoint-restart mechanism which allows processes to be migrated across minor operating system kernel versions with different security patches. This mechanism allows system administrators the flexibility to patch their operating systems immediately without worrying over potential loss of data or needing to schedule system downtime. We have implemented peas and pods in Linux without requiring any application or operating system kernel changes. Our measurements on real world desktop and server applications demonstrate that peas and pods impose little overhead and enable secure isolation and migration of untrusted applications.",,https://www.semanticscholar.org/paper/fbdefe8a250c2589c779a8496bb06955ae90c7c2,
1232,Measurement of the Forward-Backward Charge Asymmetry and Extraction ofinEvents Produced at,,2008-11-06,https://www.semanticscholar.org/paper/7f54a82eab6105cdeb0fefddd262d404719adb19,
3092,Secure Isolation of Untrusted Legacy Applications,"Existing applications often contain security holes that are not patched until after the system has already been compromised. Even when software updates are available, applying them often results in system services being unavailable for some time. This can force administrators to leave system services in an insecure state for extended periods. To address these system security issues, we have developed the PeaPod virtualization layer. The PeaPod virtualization layer provides a group of processes and associated users with two virtualization abstractions, pods and peas. A pod provides an isolated virtualized environment that is decoupled from the underlying operating system instance. A pea provides an easy-to-use least privilege model for fine grain isolation amongst application components that need to interact with one another. As a result, the system easily enables the creation of lightweight environments for privileged program execution that can help with intrusion prevention and containment. Our measurements on real world desktop and server applications demonstrate that the PeaPod virtualization layer imposes little overhead and enables secure isolation of untrusted applications.",2007-11-01,https://www.semanticscholar.org/paper/e12037d5aeb225ef51a78cdce69fcd279231411f,LiSA
3724,What’s Missing From Self-Supervised Representation Learning?,"Despite tremendous effort to train visual recognition systems without human supervision, there is still no substitute for large, labeled training datasets. We perform a large-scale analysis to quantitatively understand the difference between the representations learned by self-supervised learning and supervised learning. Adopting a large collection of trained models for different computer vision tasks, we probe for functional similarities between visual recognition systems. Experiments and visualizations suggest that two key differences between self-supervised and supervised models are its representations for 3D geometry and deformable objects, which also substantially contribute to its failures. Our hope is that such analysis will expose future research directions in self-supervised visual learning.",,https://www.semanticscholar.org/paper/cc8a78b43b5e14643dbf8991b585314cdee6a341,
1580,Relational Dose-Response Modeling for Cancer Drug Studies.,"Exploratory cancer drug studies test multiple tumor cell lines against multiple candidate drugs. The goal in each paired (cell line, drug) experiment is to map out the dose-response curve of the cell line as the dose level of the drug increases. The level of natural variation and technical noise in these experiments is high, even when multiple replicates are run. Further, running all possible combinations of cell lines and drugs may be prohibitively expensive, leading to missing data. Thus, estimating the dose-response curve is a denoising and imputation task. We cast this task as a functional matrix factorization problem: finding low-dimensional structure in a matrix where every entry is a noisy function evaluated at a set of discrete points. We propose Bayesian Tensor Filtering (BTF), a hierarchical Bayesian model of matrices of functions. BTF captures the smoothness in each individual function while also being locally adaptive to sharp discontinuities. The BTF model can incorporate many types of likelihoods, making it flexible enough to handle a wide variety of data. We derive efficient Gibbs samplers for three classes of likelihoods: (i) Gaussian, for which updates are fully conjugate; (ii) binomial and related likelihoods, for which updates are conditionally conjugate through Polya-Gamma augmentation; and (iii) non-conjugate likelihoods, for which we develop an analytic truncated elliptical slice sampling routine. We compare BTF against a state-of-the-art method for dynamic Poisson matrix factorization, showing BTF better reconstructs held out data in synthetic experiments. Finally, we build a dose-response model around BTF and apply it to real data from two multi-sample, multi-drug cancer studies. We show that the BTF-based dose-response model outperforms the current standard approach in biology. Code is available at this https URL.",2019-06-10,https://www.semanticscholar.org/paper/c4b38500c9cc0a09c3265e34d8ca652017d201df,
2373,"Control of oxygen production by polymorphonuclear leukocytes monitored by luminol-dependent chemiluminescence: the roles of intracellular calcium, oxygen concentration and redox components",,,https://www.semanticscholar.org/paper/6ba9f0975d37967443705c0250ee1fbfb7cb82ac,
2418,Using Multi-Level Precueing to Improve Performance in Path-Following Tasks in Virtual Reality,"Work on VR and AR task interaction and visualization paradigms has typically focused on providing information about the current step (a cue) immediately before or during its performance. Some research has also shown benefits to simultaneously providing information about the next step (a precue). We explore whether it would be possible to improve efficiency by precueing information about multiple upcoming steps before completing the current step. To accomplish this, we developed a remote VR user study comparing task completion time and subjective metrics for different levels and styles of precueing in a path-following task. Our visualizations vary the precueing level (number of steps precued in advance) and style (whether the path to a target is communicated through a line to the target, and whether the place of a target is communicated through graphics at the target). Participants in our study performed best when given two to three precues for visualizations using lines to show the path to targets. However, performance degraded when four precues were used. On the other hand, participants performed best with only one precue for visualizations without lines, showing only the places of targets, and performance degraded when a second precue was given. In addition, participants performed better using visualizations with lines than ones without line",2021-08-27,https://www.semanticscholar.org/paper/1be8fef777f6499ca5b9f44eca322b5628acaa73,IEEE Transactions on Visualization and Computer Graphics
2602,Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology,"It is a pleasure to welcome you to Santa Fe for UIST 2004, the Seventeenth Annual ACM Symposium on User Interface Software and Technology. This year's symposium continues the UIST tradition of being the premier forum for presentation of research innovations in the software and technology of human-computer interfaces. UIST brings together researchers and practitioners from diverse areas that include traditional graphical and web user interfaces, tangible and ubiquitous computing, virtual and augmented reality, multimedia, new input and output devices, and CSCW. The intimate size, the single track, and comfortable surroundings make this symposium an ideal opportunity to exchange research results and implementation experience. 
 
The call for papers attracted 118 full paper submissions and 52 TechNote submissions from Asia, Europe, North and South America, and the South Pacific. The program committee accepted 24 full papers (20%) and 12 TechNotes (23%) that cover a variety of exciting topics, including augmented reality, design tools, toolkits, pen and tactile input, and ambient interfaces. In addition, the program includes a keynote speech by Mary Czerwisnki on using theory as a basis for human-computer interaction research and two invited surveys by Saul Greenberg and Joseph Kaye on Physical User Interfaces and Olfactory Displays, respectively. Posters, demos, and our second annual doctoral symposium round out our program; UIST attendees receive a separate document that contains the accepted submissions for those categories. The UIST proceedings are in color for the first time ever and we hope that they will serve as a valuable reference for user interface researchers and practitioners. We have supplemented the proceedings with a DVD containing videos for almost all of the papers, TechNotes, posters, and demonstrations.",2004-10-24,https://www.semanticscholar.org/paper/854e1020fa9eed596767152ef38431fccabd2d55,
2812,Contribution of spinal galectin-3 to acute herpetic allodynia in mice,,2012-03-01,https://www.semanticscholar.org/paper/d29380944c7eaafecbf187535dfff30935a913bc,Pain
690,A Concentration Theorem for Projections,"X in R^D has mean zero and finite second moments. We show that there is a precise sense in which almost all linear projections of X into R^d (for d < D) look like a scale-mixture of spherical Gaussians -- specifically, a mixture of distributions N(0, sigma^2 I_d) where the weight of the particular sigma component is P (| X |^2 = sigma^2 D). The extent of this effect depends upon the ratio of d to D, and upon a particular coefficient of eccentricity of X's distribution. We explore this result in a variety of experiments.",2006-07-13,https://www.semanticscholar.org/paper/4526320dd1be5d52789953faa04419f2c620862f,Conference on Uncertainty in Artificial Intelligence
1315,Measurement of B(t→Wb)/B(t→Wq)B(t→Wb)/B(t→Wq) at s=1.96TeV,,2006-08-24,https://www.semanticscholar.org/paper/5e97e6b65922cd5aa50dbcdfb21663def6abe15e,
1264,Measurement of the ttbar production cross section in ppbar collisions at sqrt{s} = 1.96 TeV,"We measure the ttbar production cross section in ppbar collisions at sqrt{s}=1.96 TeV in the lepton+jets channel. Two complementary methods discriminate between signal and background, b-tagging and a kinematic likelihood discriminant. Based on 0.9 fb-1 of data collected by the D0 detector at the Fermilab Tevatron Collider, we measure sigma_ttbar=7.62+/-0.85 pb, assuming the current world average m_t=172.6 GeV. We compare our cross section measurement with theory predictions to determine a value for the top quark mass of 170+/-7 GeV.",2008-03-19,https://www.semanticscholar.org/paper/e7c05ee9cee5c099d2d048770d3a6d48742e2ed7,
2107,Analyzing repair decisions in the site imbalance problem of semiconductor test machines,"Test machines can test multiple IC devices simultaneously. When testing the same group of devices, unusual deviations in yield rates of specific sites from the other sites (i.e., site imbalance) imply a fault in the corresponding sites and the machine. This study develops a decision analysis framework for maximizing profit and customer satisfaction under uncertain conditions. The proposed framework can provide the on-site operators specific decision rules to help decide whether they should continue the test, close specific sites, or shut the machine down to repair it. A numerical example is used for illustration.",2003-11-10,https://www.semanticscholar.org/paper/647b5d2af550cbe3e128cd12964f9ba46c61aebc,
221,Can Almost Everybody be Almost Happy? PCP for PPAD and the Inapproximability of Nash,"We conjecture that PPAD has a PCP-like complete problem, seeking a near equilibrium in which all but very few players have very little incentive to deviate. We show that, if one assumes that this problem requires exponential time, several open problems in this area are settled. The most important implication, proved via a ""birthday repetition"" reduction, is that the n^O(log n) approximation scheme of [LMM03] for the Nash equilibrium of two-player games is essentially optimum. Two other open problems in the area are resolved once one assumes this conjecture, establishing that certain approximate equilibria are PPAD-complete: Finding a relative approximation of two-player Nash equilibria (without the well-supported restriction of [Das13]), and an approximate competitive equilibrium with equal incomes [Bud11] with small clearing error and near-optimal Gini coefficient.",2015-04-09,https://www.semanticscholar.org/paper/dda357a1e242ee27aaaaa4f0ca35e3e79a20dc32,arXiv.org
2094,Rough set theory for data mining for fault diagnosis on distribution feeder,"Distribution feeder faults cause power outages, therefore it is crucial to diagnose and thus locate the fault quickly to reduce the duration of the outage. In practice, feeder patrols usually identify the fault locations by referencing the regional distribution of the calls reporting trouble, the abnormal observations of the feeders that have been reported in the calls, and the observed conditions in the surrounding environments. Feeder patrols in Taiwan have recorded each fault on a table that includes time, date, month, year, address, equipment at fault, causes or accidents, and etc. The database has accumulated a large base of information for many years. This study aims to use rough set theory as a data-mining tool to derive useful patterns and rules for distribution feeder faulty equipment diagnosis and fault location. In particular, the historical data of distribution feeder faults of Taiwan Power Company was used for validation and the results show the practical viability of the proposed approach.",2004-11-01,https://www.semanticscholar.org/paper/4fc2a9ce63a0368b2dd5589a75b9d572798eec87,
2765,6.2 Experimental Results,We have developed a technique for color image enhancement based on a model of the Human Visual System HVS A color image represented by RGB is rst transformed into a color space based on the HVS cone response characteristics Subsequently chromatic correlation reduction and energy compression is realized by using a multispectral Karhunen Lo eve transform KLT of the cone responses This yields a color opponent space related to the HVS characteristics Spatial energy distribution is highly skewed the chromatic channels contain signi cantly less relative energy than in standard opponent spaces such as Y UV A constant transform which closely approximates the input dependent KLT has been found In spite of the little spatial en ergy in the chromatic channels chromatic edge enhancement in this space does add signi cantly to the perception of image detail and enhances its chromatic delity as compared with stan dard edge enhancement of only the luminance channel Chromatic edge enhancement is also less sensitive to noise than achromatic edge enhancement Owing to the simplicity of the transform and enhancement processes they can be employed for processing real time video signals,,https://www.semanticscholar.org/paper/a364bcf3448173d65d0b748b68ed70121b140169,
3709,Towards a Unifying Framework for Formal Theories of Novelty,"Managing inputs that are novel, unknown, or out-of-distribution is critical as an agent moves from the lab to the open world. Novelty-related problems include being tolerant to novel perturbations of the normal input, detecting when the input includes novel items, and adapting to novel inputs. While significant research has been undertaken in these areas, a noticeable gap exists in the lack of a formalized definition of novelty that transcends problem domains. As a team of researchers spanning multiple research groups and different domains, we have seen, first hand, the difficulties that arise from ill-specified novelty problems, as well as inconsistent definitions and terminology. Therefore, we present the first unified framework for formal theories of novelty and use the framework to formally define a family of novelty types. Our framework can be applied across a wide range of domains, from symbolic AI to reinforcement learning, and beyond to open world image recognition. Thus, it can be used to help kick-start new research efforts and accelerate ongoing work on these important novelty-related problems.",2021-05-18,https://www.semanticscholar.org/paper/357411070c0779e6c29db11532e690db2bb8a64c,AAAI Conference on Artificial Intelligence
1990,Coordinated capacity migration and expansion planning for semiconductor manufacturing under demand uncertainties,,2012-02-01,https://www.semanticscholar.org/paper/05789006fa18226cb2e71362c54fbe7f53b59598,
3379,Selected Solutions Introduction to Algorithms,,,https://www.semanticscholar.org/paper/7a8c05466b113e7a5fdf55f6d9881167cf306a33,
895,Deadlock-freedom (and saftey) of transactions in a distributed database,,1985-03-25,https://www.semanticscholar.org/paper/50d420f40db135a231cb28b4636e4f15e814512a,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
257,"Games, algorithms, and the Internet","The advent of the Internet brought parallel paradigm shifts to both Economics and Computer Science. Computer scientists realized that large-scale performing systems can emerge from the interaction of selfish agents and that incentives are a quintessential part of a good system design. And economists saw that the default platforms of economic transactions are computational and interconnected. Algorithmic Game Theory is a subdiscipline that emerged from this turmoil, revisiting some of the most important problems in Economics and Game Theory from a computational and network perspective. This talk will survey some of the major themes, results and challenges in this field.",2011-03-28,https://www.semanticscholar.org/paper/bb149415a6f994f19558b455d1366c429b2249cc,The Web Conference
1466,Production of four-prong final states in photon-photon collisions.,"Results are presented on the exclusive production of four-prong final states in photon-photon collisions from the TPC/Two-Gamma detector at the SLAC e/sup +/e/sup -/ storage ring PEP. Measurement of dE/dx and momentum in the time-projection chamber (TPC) provides identification of the final states 2..pi../sup +/2..pi../sup -/, K/sup +/K/sup -/..pi../sup +/..pi../sup -/, and 2K/sup +/2K/sup -/. For two quasireal incident photons, both the 2..pi../sup +/2..pi../sup -/ and K/sup +/K/sup -/..pi../sup +/..pi../sup -/ cross sections show a steep rise from threshold to a peak value, followed by a decrease at higher mass. Cross sections for the production of the final states rho/sup 0/rho/sup 0/, rho/sup 0/..pi../sup +/..pi../sup -/, and phi..pi../sup +/..pi../sup -/ are presented, together with upper limits for phirho/sup 0/, phiphi, and K/sup *//sup 0/K-bar /sup *//sup 0/. The rho/sup 0/rho/sup 0/ contribution dominates the four-pion cross section at low masses, but falls to nearly zero above 2 GeV. Such behavior is inconsistent with expectations from vector dominance but can be accommodated by four-quark resonance models or by t-channel factorization. Angular distributions for the part of the data dominated by rho/sup 0/rho/sup 0/ final states are consistent with the production of J/sup P/ = 2/sup +/ or 0/sup +/ resonances butmore » also with isotropic (nonresonant) production. When one of the virtual photons has mass (m/sub ..gamma..//sup 2/ = -Q/sup 2/not =0), the four-pion cross section is still dominated by rho/sup 0/rho/sup 0/ at low final-state masses W/sub ..gamma..//sub ..gamma../ and by 2..pi../sup +/2..pi../sup -/ at higher mass. Further, the dependence of the cross section on Q/sup 2/ becomes increasingly flat as W/sub ..gamma..//sub ..gamma../ increases.« less",,https://www.semanticscholar.org/paper/741bad4e4321699d7b5fa5f84acfe4e6eca6d466,"Physical Review D, Particles and fields"
3443,Speed scaling for weighted flow time,"In addition to the traditional goal of efficiently managing time and space, many computers now need to efficiently manage power usage. For example, Intel's SpeedStep and AMD's PowerNOW technologies allow the Windows XP operating system to dynamically change the speed of the processor to prolong battery life. In this setting, the operating system must not only have a job selection policy to determine which job to run, but also a speed scaling policy to determine the speed at which the job will be run. These policies must be online since the operating system does not in general have knowledge of the future. In current CMOS based processors, the speed satisfies the well known cube-root-rule, that the speed is approximately the cube root of the power [Mud01, BBS+00]. Thus, in this work, we make the standard generalization that the power is equal to speed to some power α ≥ 1, where one should think of α as being approximately 3 [YDS95, BKP04]. Energy is power integrated over time. The operating system is faced with a dual objective optimization problem as it both wants to conserve energy, and optimize some Quality of Service (QoS) measure of the resulting schedule.",2007-01-07,https://www.semanticscholar.org/paper/8a1664d7f0ec5591e7193966c1180526355bb291,ACM-SIAM Symposium on Discrete Algorithms
2437,Hands-free augmented reality for vascular interventions,"During a vascular intervention (a type of minimally invasive surgical procedure), physicians maneuver catheters and wires through a patient's blood vessels to reach a desired location in the body. Since the relevant anatomy is typically not directly visible in these procedures, virtual reality and augmented reality systems have been developed to assist in 3D navigation. Because both of a physician's hands may already be occupied, we developed an augmented reality system supporting hands-free interaction techniques that use voice and head tracking to enable the physician to interact with 3D virtual content on a head-worn display while leaving both hands available intraoperatively. We demonstrate how a virtual 3D anatomical model can be rotated and scaled using small head rotations through first-order (rate) control, and can be rigidly coupled to the head for combined translation and rotation through zero-order control. This enables easy manipulation of a model while it stays close to the center of the physician's field of view.",2018-08-12,https://www.semanticscholar.org/paper/8a15675fb927224db6c465ef36037f0ad4a6c343,SIGGRAPH Emerging Technologies
3048,Pervasive detection of process races in deployed systems,"Process races occur when multiple processes access shared operating system resources, such as files, without proper synchronization. We present the first study of real process races and the first system designed to detect them. Our study of hundreds of applications shows that process races are numerous, difficult to debug, and a real threat to reliability. To address this problem, we created RacePro, a system for automatically detecting these races. RacePro checks deployed systems in-vivo by recording live executions then deterministically replaying and checking them later. This approach increases checking coverage beyond the configurations or executions covered by software vendors or beta testing sites. RacePro records multiple processes, detects races in the recording among system calls that may concurrently access shared kernel objects, then tries different execution orderings of such system calls to determine which races are harmful and result in failures. To simplify race detection, RacePro models under-specified system calls based on load and store micro-operations. To reduce false positives and negatives, RacePro uses a replay and go-live mechanism to distill harmful races from benign ones. We have implemented RacePro in Linux, shown that it imposes only modest recording overhead, and used it to detect a number of previously unknown bugs in real applications caused by process races.",2011-10-23,https://www.semanticscholar.org/paper/388794ec80deec7754c65a4c2fb3f12eb7b3bac6,Symposium on Operating Systems Principles
737,Polynomial time algorithms for multi-type branching processesand stochastic context-free grammars,"We show that one can approximate the least fixed point solution for a multivariate system of monotone probabilistic polynomial equations in time polynomial in both the encoding size of the system of equations and in log(1/ε), where ε>0 is the desired additive error bound of the solution. (The model of computation is the standard Turing machine model.)
 We use this result to resolve several open problems regarding the computational complexity of computing key quantities associated with some classic and heavily studied stochastic processes, including multi-type branching processes and stochastic context-free grammars.",2012-01-11,https://www.semanticscholar.org/paper/ecf67f34bf98245d89785a0f392f44c30de14acb,Symposium on the Theory of Computing
1903,A hybrid multi-subpopulation genetic algorithm for textile batch dyeing scheduling and an empirical study,,2018-11-01,https://www.semanticscholar.org/paper/55f277a3d5b6254de108a7812943c0320bacbf29,Computers & industrial engineering
911,Algebraic Dependencies,,,https://www.semanticscholar.org/paper/3fd4adf51111cc0b126b2ae5353e66b7cef80330,Journal of computer and system sciences (Print)
1584,Using Embeddings to Correct for Unobserved Confounding in Networks,"We consider causal inference in the presence of unobserved confounding. We study the case where a proxy is available for the unobserved confounding in the form of a network connecting the units. For example, the link structure of a social network carries information about its members. We show how to effectively use the proxy to do causal inference. The main idea is to reduce the causal estimation problem to a semi-supervised prediction of both the treatments and outcomes. Networks admit high-quality embedding models that can be used for this semi-supervised prediction. We show that the method yields valid inferences under suitable (weak) conditions on the quality of the predictive model. We validate the method with experiments on a semi-synthetic social network dataset. Code is available at this http URL.",2019-02-11,https://www.semanticscholar.org/paper/f432e55bfb342435da59e5c3f896778f436117f2,Neural Information Processing Systems
3559,Understanding and Effectively Preventing the ABA Problem in Descriptor-Based Lock-Free Designs,"An increasing number of modern real-time systems and the nowadays ubiquitous multicore architectures demand the application of programming techniques for reliable and efficient concurrent synchronization. Some recently developed Compare-And-Swap (CAS) based nonblocking techniques hold the promise of delivering practical and safer concurrency. The ABA problem is a fundamental problem to many CAS-based designs. Its significance has increased with the suggested use of CAS as a core atomic primitive for the implementation of portable lock-free algorithms. The ABA problem's occurrence is due to the intricate and complex interactions of the application's concurrent operations and, if not remedied, ABA can significantly corrupt the semantics of a nonblocking algorithm. The current state of the art leaves the elimination of the ABA hazards to the ingenuity of the software designer. In this work we provide the first systematic and detailed analysis of the ABA problem in lock-free Descriptor-based designs. We study the semantics of Descriptor-based lock-free data structures and propose a classification of their operations that helps us better understand the ABA problem and subsequently derive an effective ABA prevention scheme. Our ABA prevention approach outperforms by a large factor the use of the alternative CAS-based ABA prevention schemes. It offers speeds comparable to the use of the architecture-specific CAS2 instruction used for version counting. We demonstrate our ABA prevention scheme by integrating it into an advanced nonblocking data structure, a lock-free dynamically resizable array.",2010-05-05,https://www.semanticscholar.org/paper/2fe159422eab95c284b6a9b3e9fef52a310c4527,IEEE International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing
3486,Experimental Evaluation of Approximation Algorithms for Single-Source Unsplittable Flow,,1999-06-09,https://www.semanticscholar.org/paper/842591f79f6c7613f3dcc6b527cab169308152d2,Conference on Integer Programming and Combinatorial Optimization
1125,Search for inelastic dark matter with the CDMS II experiment,"Results are presented from a reanalysis of the entire five-tower data set acquired with the Cryogenic Dark Matter Search (CDMS II) experiment at the Soudan Underground Laboratory, with an exposure of 969 kg-days. The analysis window was extended to a recoil energy of 150 keV, and an improved surface-event background-rejection cut was defined to increase the sensitivity of the experiment to the inelastic dark matter (iDM) model. Three dark matter candidates were found between 25 keV and 150 keV. The probability to observe three or more background events in this energy range is 11%. Because of the occurrence of these events, the constraints on the iDM parameter space are slightly less stringent than those from our previous analysis, which used an energy window of 10–100 keV.",2010-12-22,https://www.semanticscholar.org/paper/250afc0d8ca33eeba2a1ee177f92a307749c8bd0,
3662,"The C++ Programming Language, First Edition",,,https://www.semanticscholar.org/paper/931b53921b5db6c7864303cbe13a5383913de4ff,
163,Total Functions in the Polynomial Hierarchy,". We identify several genres of search problems beyond NP for which existence of solutions is guaranteed. One class that seems especially rich in such problems is PEPP (for “polynomial empty pigeonhole principle”), which includes problems related to existence theorems proved through the union bound, such as ﬁnding a bit string that is far from all codewords, ﬁnding an explicit rigid matrix, as well as a problem we call Complexity, capturing Complexity Theory’s quest. When the union bound is generous, in that solutions constitute at least a polynomial fraction of the domain, we have a family of seemingly weaker classes α - PEPP, which are inside FP NP | poly. Higher in the hierarchy, we identify the constructive version of the Sauer-Shelah lemma and the appropriate generalization of PPP that contains it. The resulting total function hierarchy turns out to be more stable than the polynomial hierarchy: it is known that, under oracles, total functions within FNP may be easy, but total functions a level higher may still be harder than FP NP . ,",,https://www.semanticscholar.org/paper/99aa888d13c646985616f4a8b85095b70206a711,Electron. Colloquium Comput. Complex.
3356,"Role assessment, reserve strategy, and acquisition of information in asymmetric animal conflicts",,1981-02-01,https://www.semanticscholar.org/paper/992341bdf241ddd725ec2b75b5b3bae1c87e733d,Animal Behaviour
807,On the Complexity of Protein Folding,We show that the protein folding problem in the two-dimensional H-P model is NP-complete.,,https://www.semanticscholar.org/paper/492cbadcc1bb2875209004e6ad93f391d2e6cf9b,J. Comput. Biol.
3227,Tightly Bunched Herding Improves Cattle Performance in African Savanna Rangeland☆,,2018-07-01,https://www.semanticscholar.org/paper/7c92d54a511c1fc915a1f8c0d6001946b623f5a4,Rangeland Ecology & Management
3337,Life history and social organization in arid adapted ungulates,,1989-09-01,https://www.semanticscholar.org/paper/9a1b1041dda3fed0ced348e11b79be27f1de40d6,
1097,Working Group Report: Dark Matter Complementarity (Dark Matter in the Coming Decade: Complementary Paths to Discovery and Beyond),"In this Report we discuss the four complementary searches for the identity of dark matter: direct detection experiments that look for dark matter interacting in the lab, indirect detection experiments that connect lab signals to dark matter in our own and other galaxies, collider experiments that elucidate the particle properties of dark matter, and astrophysical probes sensitive to non-gravitational interactions of dark matter. The complementarity among the different dark matter searches is discussed qualitatively and illustrated quantitatively in several theoretical scenarios. Our primary conclusion is that the diversity of possible dark matter candidates requires a balanced program based on all four of those approaches.",2013-10-31,https://www.semanticscholar.org/paper/068192211b043982812b3203e751d90715a9296c,
447,On the Difficulty of Designing Good Classifiers,"It is a very interesting and well-studied problem, given two point sets W, B\(\subseteq\)ℜn, to design a linear decision tree that classifies them —that is, no leaf subdivision contains points from both B and W — and is as simple as possible, either in terms of the total number of nodes, or in terms of its depth. We show that, unless ZPP=NP, the depth of a classifier cannot be approximated within a factor smaller than 6/5, and that the total number of nodes cannot be approximated within a factor smaller than n1/5. Our proof relies on a simple connection between this problem and graph coloring, and uses recent nonapproximability results for graph coloring. We also study the problem of designing a classifier with a single inequality that involves as few variables as possible, and point out certain aspects of the difficulty of this problem.",1996-06-17,https://www.semanticscholar.org/paper/72964363b75234ccfba32010ac8c1e8966ea13e5,SIAM journal on computing (Print)
873,Markov Decision Processes and Regular Events (Extended Abstract),,1990-07-16,https://www.semanticscholar.org/paper/adc3b3836ce5fba21550a04c8159fbc4f0f52c7f,"International Colloquium on Automata, Languages and Programming"
901,Querying weak instances,"1. INTRODUCTION The universal relation model gives the user a view of the data as though it was stored in a single relation, in which every attribute plays a unique role. Thus, in posing queries, the user does not have to navigate among the different base relations; the system performs this navigation automatically by transforming the query on the universal relation into one involving the stored base relations. For example, in a films database with relations FP (Film-Producer) and FD (Film-Diiwtor), ln response to the query rcrrieve P where D-FelJmi (which producers has Fellmi worked for), the system would "" know "" that diiectors are related to produc-ers' through films. Thus, the relation between producers and directors would be constructed by taking the join of relations FP and FD and projecting on the attributes P, D. The fust approach towards defmlng the relationship between the actual database (the base relations) and the universal relation is known as the pure universal instance assumption. This assumption postulates that the database is formed by projecting some universal relation (satisfying the dependencies), and the universal relation is formed by taking the join of all the base relations. This assumption places very severe restrictions on the database, since incomplete information is not allowed-each tuple of a base relation must match with tuples in all the other relations. One could allow dao-glmg tuples (tuples that don't match), but then in taking the joii of all the relations these tuples would get lost. For example, suppose that in the films database we have also a relation FA (Film-Actor). Then, if we take the join of all three relations FP, FD, FA , we loose the relationship between directors of documentaries and their",1984-04-02,https://www.semanticscholar.org/paper/6faa1e2ba9b70392faff6e3baa7dba2603bedd3b,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
359,On the complexity of price equilibria,,2003-09-01,https://www.semanticscholar.org/paper/aab30ce2f074d94c47b0a8782214fd64bf360ded,Journal of computer and system sciences (Print)
3613,Sibling Rivalry: C and C++,"This article presents a view of the relationship between K&R C’s most prominent descendants: ISO C and ISO C++. It gives a rough chronology of the exchanges of features between the various versions of C and C++ and presents some technical details related to their most significant current incompatibilities. My focus here is the areas where C and C++ differ slightly (‘‘the incompatibilities’’), rather than the large area of commonality or the areas where one language provide facilities not offered by the other. In addition to presenting incompatibilities, this paper briefly discusses some implications of these incompatibilities, reflects on the ‘‘Spirit of C’’ and ‘‘Spirit of C++’’ notions, and states some opinions about the relationship between C and C++. This article is written in support of the view that C/C++ incompatibilities can and should be eliminated.",,https://www.semanticscholar.org/paper/872263322c374319c7306a22fa5e1f2bcbf7949c,
3699,Landscape Learning for Neural Network Inversion,"Many machine learning methods operate by inverting a neural network at inference time, which has become a popular technique for solving inverse problems in computer vision, robotics, and graphics. However, these methods often involve gradient descent through a highly non-convex loss landscape, causing the optimization process to be unstable and slow. We introduce a method that learns a loss landscape where gradient descent is efficient, bringing massive improvement and acceleration to the inversion process. We demonstrate this advantage on a number of methods for both generative and discriminative tasks, including GAN inversion, adversarial defense, and 3D human pose reconstruction.",2022-06-17,https://www.semanticscholar.org/paper/5dad3748e8d4d8c659005903062e5d8e855fa86c,arXiv.org
867,On the complexity of local search,We prove a number of complexity results on the computational paradigm of local op-timality. Our main results are these: (a) Finding a local optimum under the Lin-Kernighan heuristic for the traveling salesman problemis PLS-complete. (b) Finding stable configurations in neural networks in the Hopfield mode/is PLS-complete. (c) We show that a host of simple unweighted local optimality problems are P-complete. (d) We introduce a general framework for establishing exponential worst-case bounds for local optimization heuristics. (e) And we show that local search problems become PSPACE-complete if we insist that the local optimum returned be attainable by local improvements from a given initial solution.,1990-04-01,https://www.semanticscholar.org/paper/058c1da6d4bf925e57d89c4708bdebe1360d62f1,Symposium on the Theory of Computing
1931,Manufacturing intelligence and smart production for industry 3.5 and empirical study of decision-based virtual metrology for controlling overlay errors,"Focusing on the challenges of wafer fabs with multiple tools and high-mix products, this study aims to propose a decision-based virtual metrology framework to reduce the metrology cost and enhance productivity. An empirical study was conducted in a leading semiconductor company in Taiwan to validate the effectiveness of proposed approach for controlling overlay errors in lithography processes while ensuring the quality level. The results have shown practical viability of the proposed approach for reducing sampling rate and metrology cost.",2016-04-25,https://www.semanticscholar.org/paper/2c4c8916291778c271f2cf7851ed5bcfd2995363,"International Symposium on VLSI Design, Automation and Test"
743,An impossibility theorem for price-adjustment mechanisms,"We show that there is no discrete-time price-adjustment mechanism (any process that at each period looks at the history of prices and excess demands and updates the prices) such that for any market (a set of goods and consumers with endowments and strictly concave utilities) the price-adjustment mechanism will achieve excess demands that are at most an ϵ fraction of the total supply within a number of periods that is polynomial in the number of goods and . This holds even if one restricts markets so that excess demand functions are differentiable with derivatives bounded by a small constant. For the convergence time to the actual price equilibrium, we show by a different method a stronger result: Even in the case of three goods with a unique price equilibrium, there is no function of ϵ that bounds the number of periods needed by a price-adjustment mechanism to arrive at a set of prices that is ϵ-close to the equilibrium.",2010-01-19,https://www.semanticscholar.org/paper/65404b8164eb33d082bedc59b7dcc18c52db7839,Proceedings of the National Academy of Sciences of the United States of America
1090,Title Dark Matter in the Coming Decade : Complementary Paths to Discovery and Beyond Permalink,,,https://www.semanticscholar.org/paper/2efc46d0f10afe340f6da0fc587f557d3ec172ff,
2554,Redefining the User Interface : Augmented Reality,"Virtual worlds (a.k.a. virtual realities) are 3D computer-generated environments created through the use of high-performance computers, 3D interaction devices, and 3D display systems. Most of the virtual worlds systems that have been so well publicized over the past five years use head-mounted displays that block off the wearer from the surrounding real world, effectively immersing her within a synthesized world. These systems can be particularly effective for many applications, ranging from fantasy games to scientific research. In contrast, we believe that the most powerful and commonplace virtual worlds of the future will not replace the real world, but will rather augment it with additional information. This approach is called augmented reality and was pioneered by Ivan Sutherland, who, over a quarter century ago, developed the first see-through head-mounted display [8]. His system presented graphics to the user on a pair of stereo displays, worn on the user’s head. The image produced by the displays was combined with the user’s view of the world using half-silvered mirrors. A 3D tracking system determined the position and orientation of the user’s head. This enabled the system to change the view, based on the direction in which the wearer was looking. Consider some of the possibilities: Graphics, text, and sound overlaid on the surrounding world could explain how to operate, maintain, or repair equipment, without requiring that the user refer to a separate paper or electronic manual. Similarly, participants in a business meeting could interact with a dynamic shared financial or organizational model, represented in 3D and selectively supplemented with each user’s private personal annotations. This brief paper provides an overview of the work being done at Columbia’s Computer Graphics and User Interfaces Laboratory to address fundamental issues in designing effective augmented reality systems. We describe “hybrid user interfaces” that merge 2D and 3D displays and interaction devices, augmented realities that annotate the surrounding physical world with knowledge-based 3D graphics, and augmented realities that extend a contemporary window-based environment so that it becomes part of a wearable information surround. These projects all use the head-mounted display shown in Figure 1. We assembled it from a Reflection Technology Private Eye, a Logitech ultrasonic 3D position and orientation tracker, and a mirror beam splitter. The Private Eye is a small 720 ×280 resolution bitmapped display [6]. We positioned the beam splitter so that the user can see the surrounding world through it and the Private Eye reflected from it. The triangle at the top of the visor contains the sensors for the ultrasonic tracker.",,https://www.semanticscholar.org/paper/519dbc99438278913ef3866b24729df881f9e5f5,
2827,Intracellular colocalization of galectin-3 with Listeria monocytogenes in macrophages and its implications,,2010-04-01,https://www.semanticscholar.org/paper/20f3f9da56e04cf1099ae4f86a22e33092305768,
2385,Complement-mediated lysis of pigeon erythrocyte ghosts analysed by flow cytometry. Evidence for the involvement of a 'threshold' phenomenon.,"Flow-cytometric analysis of complement-mediated lysis of antibody-coated pigeon erythrocyte ghosts containing fluorescein was carried out to determine whether lysis involved a gradual release of fluorescein or a 'threshold' release from individual cells. Antibody-coated ghosts were comprised of three subpopulations identified by fluorescence and scatter (size). These were: (a) highly fluorescent, medium scatter, (b) medium fluorescence, high scatter, and (c) low (or zero) fluorescence, low scatter. Lysed ghosts and isolated nuclei were identified by fluorescence microscopy and scanning electron microscopy. Fluorescence distributions analysed by flow cytometry indicated that, after complement attack, those ghosts remaining intact retained all their fluorescent label. A time course of changes in ratios of the three subpopulations indicated that once lysis of an individual ghost was initiated, release of label was complete within 1 min; no stages of intermediary fluorescence appeared, and those ghosts remaining at the end of the experiment retained the same fluorescence intensity as control ghosts. The results supported the hypothesis that complement-mediated cell lysis is a 'threshold' phenomenon; a submaximal response by a cell population representing a complete response by only some of the cells rather than a partial response by all of the cells.",1983-10-15,https://www.semanticscholar.org/paper/9e592fd58c84f802ad7d134b39f835ba12b2ee22,Biochemical Journal
466,On the Complexity of Cooperative Solution Concepts,"We study from a complexity theoretic standpoint the various solution concepts arising in cooperative game theory. We use as a vehicle for this study a game in which the players are nodes of a graph with weights on the edges, and the value of a coalition is determined by the total weight of the edges contained in it. The Shapley value is always easy to compute. The core is easy to characterize when the game is convex, and is intractable (NP-complete) otherwise. Similar results are shown for the kernel, the nucleolus, the e-core, and the bargaining set. As for the von Neumann-Morgenstern solution, we point out that its existence may not even be decidable. Many of these results generalize to the case in which the game is presented by a hypergraph with edges of size k > 2.",1994-05-01,https://www.semanticscholar.org/paper/42ae40a85a2b9e41197bacfdecd1576b02ab8827,Mathematics of Operations Research
3608,Concepts – Design choices for template argument checking,"This note presents problems, ideals, and design ideas for ways of checking template arguments. The aim is to simplify the writing and use of templates without loss of run-time performance or expressive power compared to the original template design while maintaining complete backwards compatibility with the original template design. A specification of the requirements on a set of template arguments is called a concept. Because specifying and using such requirements are central to thinking about templates, several apparently independent suggestions for language extensions, such as a uniform function call syntax, are also briefly presented.",,https://www.semanticscholar.org/paper/2bdd01edb4551bf4b08e6113b3201bceacebadf5,
1206,Measurement of the forward-backward charge asymmetry and extraction of sin2thetaWeff in pp-->Z/gamma* + X-->e+e- +X events produced at sqrt[s] = 1.96 TeV.,"We present a measurement of the forward-backward charge asymmetry (A FB) in pp-->Z/gamma* + X-->e+e(-) + X events at a center-of-mass energy of 1.96 TeV using 1.1 fb(-1) of data collected with the D0 detector at the Fermilab Tevatron collider. A FB is measured as a function of the invariant mass of the electron-positron pair, and found to be consistent with the standard model prediction. We use the A FB measurement to extract the effective weak mixing angle sin2thetaWeff = 0.2326+/-0.0018(stat)+/-0.0006(syst).",,https://www.semanticscholar.org/paper/3d92c77d75d51ff3c2eefb44327fec7d23b066ae,Physical Review Letters
153,The Computational Complexity of Multi-player Concave Games and Kakutani Fixed Points,"Kakutani's Fixed Point theorem is a fundamental theorem in topology with numerous applications in game theory and economics. Formally, Kakutani's theorem states that for any set-valued function mapping F, also known as correspondence, from a compact, convex set to itself in a locally convex topological vector space, if the function is upper hemicontinuous, has a closed graph, and its output at any given point is a non-empty and convex set, then there exists a fixed point x, namely a point in the domain which is mapped to itself by the function x ∈ F(x). Interestingly, computational formulations of Kakutani exist only in special cases and are too restrictive to be useful in reductions.",2022-07-15,https://www.semanticscholar.org/paper/c54611e2a4f60862b3c3e9075cbf289164387d7c,ACM Conference on Economics and Computation
1574,The Dynamic Embedded Topic Model,"Topic modeling analyzes documents to learn meaningful patterns of words. For documents collected in sequence, dynamic topic models capture how these patterns vary over time. We develop the dynamic embedded topic model (D-ETM), a generative model of documents that combines dynamic latent Dirichlet allocation (D-LDA) and word embeddings. The D-ETM models each word with a categorical distribution parameterized by the inner product between the word embedding and a per-time-step embedding representation of its assigned topic. The D-ETM learns smooth topic trajectories by defining a random walk prior over the embedding representations of the topics. We fit the D-ETM using structured amortized variational inference with a recurrent neural network. On three different corpora---a collection of United Nations debates, a set of ACL abstracts, and a dataset of Science Magazine articles---we found that the D-ETM outperforms D-LDA on a document completion task. We further found that the D-ETM learns more diverse and coherent topics than D-LDA while requiring significantly less time to fit.",2019-07-12,https://www.semanticscholar.org/paper/853be905f533fb347d58c463a61bc365e133c2ca,arXiv.org
2712,Introduction to Computer Graphics,"From the Publisher: 
This new introductory text to computer graphics is an adaptation of Computer Graphics: Principles and Practice, Second Edition, which remains the most comprehensive and authoritative work in the field. While retaining the currency and accuracy of the larger book, this abbreviated version focuses on topics essential for all beginners in computer graphics and provides expanded explanations for readers with little or no technical background. Worked examples have been added to illustrate important concepts and techniques, and program code has been written in the C language to enhance the book's usefulness. In addition, the book contains an extensive illustration program, with more than 50 full-color images. 
 
Topic coverage includes basic graphics programming, hardware, and applications. Important algorithms are included to facilitate implementation of both 2D and 3D graphics. A separate chapter covers SPHIGSa simplified dialect of the PHIGS 3D standardand coincides with the availability of an updated version of the software. Chapter 9 and presents a concise overview of interaction issues and techniques. Advanced material from the larger book has been condensed, and the mathematics needed for it has been explained carefully . 
 
The result is an accessible introduction to computer graphics, crafted to provide a solid foundation for further work in this exciting field. 
Features 
Adaptation of the definitive computer graphics book in the fieldhalf the length. 
Presents key concepts geared toward students with minimal technical background. 
Provides worked examples in C. 
Retains the highlevel of teaching standards of the parent graphics text.",,https://www.semanticscholar.org/paper/359dbf805046f8272943c7b37e18ebc1b3646033,
3520,Distributed Scheduling in Finite Capacity Networks,We consider the problem of scheduling unit-sized jobs in a distributed network of processors. Each processor only knows the number of jobs it and its neighbors have. We give an analysis of intuitive algorithm and prove that the algorithm produces schedules that are within a logarithmic factor of the length of the optimal schedule given that the optimal schedule is sufficiently long.,1994-11-01,https://www.semanticscholar.org/paper/e7d12c715a591f5e506f1808bf0326f06ab94807,
2882,"Human T lymphotropic virus-I infection of human T lymphocytes induces expression of the beta-galactoside-binding lectin, galectin-3.","Animal lectins play important roles in a variety of biological processes via their recognition of glycoconjugates. Galectin-3 is a beta-galactoside-binding lectin previously designated as epsilon BP (IgE-binding protein), CBP35, Mac-2, L-29, and L-34, and its expression has been associated with various physiological and pathological processes, including cell growth, tumor transformation, and metastasis. Galectin-3 is widely distributed in various tissues and cell types and is expressed in many leukocytes, with the notable exception of B and T lymphocytes. We now report that galectin-3 is abundantly expressed in a number of human T lymphotropic virus (HTLV)-I-infected human T cell lines, including F6T, HUT 102, K3T, MT-2, and SLB-I, but is not expressed in non-HTLV-I-infected T cell lines such as Jurkat, CEM, and MOLT-4. In addition, the galectin-3 level was markedly increased in human thymocytes after infection with HTLV-I as compared with uninfected thymocytes. The up-regulation of galectin-3 expression appeared to correlate well with HTLV-I gene expression, as undetectable or very low levels of galectin-3 were found in the S1T and ATL-1K cell lines, which are nonproductively infected with HTLV-I. In co-transfection experiments, the galectin-3 promoter was significantly up-regulated by expression vectors encoding the 40-kd Tax protein, a potent transactivator in HTLV-I. Analysis of various Tax mutants suggested that galectin-3 promoter induction is dependent on activation of the cyclic-AMP-responsive element binding protein/activation transcription factor family of transcription factors and, to a lesser extent, nuclear factor-kappa B/Rel induction. Transfection of human promonocytic U-937 cells with an HTLV-I Tax expression vector induced galectin-3 expression in this cell line. Functionally, galectin-3 was shown to activate interleukin-2 production in Jurkat T cells. Together, these findings raise the possibility that HTLV-I Tax production induces the transcription and subsequent synthesis and secretion of galectin-3, which in turn may further activate these T cells and contribute to the altered properties of cell growth found in adult T cell leukemia induced by HTLV-I.",1996-05-01,https://www.semanticscholar.org/paper/a9f9ab94664b80312e5414019c9f1dfc18103fb5,American Journal of Pathology
695,Center-Embedding and Constituency in the Brain and a New Characterization of Context-Free Languages,"A computational system implemented exclusively through the spiking of neurons was re-cently shown capable of syntax, that is, of carrying out the dependency parsing of simple English sentences. We address two of the most important questions left open by that work: constituency (the identification of key parts of the sentence such as the verb phrase) and the processing of dependent sentences, especially center-embedded ones. We show that these two aspects of language can also be implemented by neurons and synapses in a way that is com-patible with what is known, or widely believed, about the structure and function of the language organ 1 . Surprisingly, the way we implement center embedding points to a new characterization of context-free languages.",2022-06-27,https://www.semanticscholar.org/paper/9bae9312babddd5707e38f81fcba6579fae6ad82,NALOMA
2674,Automated Visual Presentation: From Heterogeneous Information to Coherent Visual Discourse,,1998-11-01,https://www.semanticscholar.org/paper/5d65c060e7f23f996ccabab6aae3f8a90c096015,Journal of Intelligence and Information Systems
1203,Search for excited electrons in p p collisions at ffiffi s p 1⁄4 1 : 96 TeV,"V.M. Abazov, B. Abbott, M. Abolins, B. S. Acharya, M. Adams, T. Adams, E. Aguilo, S. H. Ahn, M. Ahsan, G.D. Alexeev, G. Alkhazov, A. Alton,* G. Alverson, G.A. Alves, M. Anastasoaie, L. S. Ancu, T. Andeen, S. Anderson, B. Andrieu, M. S. Anzelc, Y. Arnoud, M. Arov, M. Arthaud, A. Askew, B. Åsman, A. C. S. Assis Jesus, O. Atramentov, C. Autermann, C. Avila, C. Ay, F. Badaud, A. Baden, L. Bagby, B. Baldin, D.V. Bandurin, S. Banerjee, P. Banerjee, E. Barberis, A.-F. Barfuss, P. Bargassa, P. Baringer, J. Barreto, J. F. Bartlett, U. Bassler, D. Bauer, S. Beale, A. Bean, M. Begalli, M. Begel, C. Belanger-Champagne, L. Bellantoni, A. Bellavance, J. A. Benitez, S. B. Beri, G. Bernardi, R. Bernhard, I. Bertram, M. Besançon, R. Beuselinck, V. A. Bezzubov, P. C. Bhat, V. Bhatnagar, C. Biscarat, G. Blazey, F. Blekman, S. Blessing, D. Bloch, K. Bloom, A. Boehnlein, D. Boline, T. A. Bolton, G. Borissov, T. Bose, A. Brandt, R. Brock, G. Brooijmans, A. Bross, D. Brown, N. J. Buchanan, D. Buchholz, M. Buehler, V. Buescher, V. Bunichev, S. Burdin, S. Burke, T. H. Burnett, C. P. Buszello, J.M. Butler, P. Calfayan, S. Calvet, J. Cammin, W. Carvalho, B. C. K. Casey, N.M. Cason, H. Castilla-Valdez, S. Chakrabarti, D. Chakraborty, K.M. Chan, K. Chan, A. Chandra, F. Charles,19,{ E. Cheu, F. Chevallier, D.K. Cho, S. Choi, B. Choudhary, L. Christofek, T. Christoudias, S. Cihangir, D. Claes, Y. Coadou, M. Cooke, W. E. Cooper, M. Corcoran, F. Couderc, M.-C. Cousinou, S. Crépé-Renaudin, D. Cutts, M. Ćwiok, H. da Motta, A. Das, G. Davies, K. De, S. J. de Jong, E. De La Cruz-Burelo, C. De Oliveira Martins, J. D. Degenhardt, F. Déliot, M. Demarteau, R. Demina, D. Denisov, S. P. Denisov, S. Desai, H. T. Diehl, M. Diesburg, A. Dominguez, H. Dong, L. V. Dudko, L. Duflot, S. R. Dugad, D. Duggan, A. Duperrin, J. Dyer, A. Dyshkant, M. Eads, D. Edmunds, J. Ellison, V. D. Elvira, Y. Enari, S. Eno, P. Ermolov, H. Evans, A. Evdokimov, V.N. Evdokimov, A. V. Ferapontov, T. Ferbel, F. Fiedler, F. Filthaut, W. Fisher, H. E. Fisk, M. Ford, M. Fortner, H. Fox, S. Fu, S. Fuess, T. Gadfort, C. F. Galea, E. Gallas, E. Galyaev, C. Garcia, A. Garcia-Bellido, V. Gavrilov, P. Gay, W. Geist, D. Gelé, C. E. Gerber, Y. Gershtein, D. Gillberg, G. Ginther, N. Gollub, B. Gómez, A. Goussiou, P. D. Grannis, H. Greenlee, Z. D. Greenwood, E.M. Gregores, G. Grenier, Ph. Gris, J.-F. Grivaz, A. Grohsjean, S. Grünendahl, M.W. Grünewald, J. Guo, F. Guo, P. Gutierrez, G. Gutierrez, A. Haas, N. J. Hadley, P. Haefner, S. Hagopian, J. Haley, I. Hall, R. E. Hall, L. Han, P. Hansson, K. Harder, A. Harel, R. Harrington, J.M. Hauptman, R. Hauser, J. Hays, T. Hebbeker, D. Hedin, J. G. Hegeman, J.M. Heinmiller, A. P. Heinson, U. Heintz, C. Hensel, K. Herner, G. Hesketh, M.D. Hildreth, R. Hirosky, J. D. Hobbs, B. Hoeneisen, H. Hoeth, M. Hohlfeld, S. J. Hong, S. Hossain, P. Houben, Y. Hu, Z. Hubacek, V. Hynek, I. Iashvili, R. Illingworth, A. S. Ito, S. Jabeen, M. Jaffré, S. Jain, K. Jakobs, C. Jarvis, R. Jesik, K. Johns, C. Johnson, M. Johnson, A. Jonckheere, P. Jonsson, A. Juste, E. Kajfasz, A.M. Kalinin, J. R. Kalk, J.M. Kalk, S. Kappler, D. Karmanov, P. A. Kasper, I. Katsanos, D. Kau, R. Kaur, V. Kaushik, R. Kehoe, S. Kermiche, N. Khalatyan, A. Khanov, A. Kharchilava, Y.M. Kharzheev, D. Khatidze, T. J. Kim, M.H. Kirby, M. Kirsch, B. Klima, J.M. Kohli, J.-P. Konrath, V.M. Korablev, A.V. Kozelov, D. Krop, T. Kuhl, A. Kumar, S. Kunori, A. Kupco, T. Kurča, J. Kvita, F. Lacroix, D. Lam, S. Lammers, G. Landsberg, P. Lebrun, W.M. Lee, A. Leflat, F. Lehner, J. Lellouch, J. Leveque, J. Li, Q. Z. Li, L. Li, S.M. Lietti, J. G. R. Lima, D. Lincoln, J. Linnemann, V.V. Lipaev, R. Lipton, Y. Liu, Z. Liu, A. Lobodenko, M. Lokajicek, P. Love, H. J. Lubatti, R. Luna, A. L. Lyon, A.K. A. Maciel, D. Mackin, R. J. Madaras, P. Mättig, C. Magass, A. Magerkurth, P. K. Mal, H. B. Malbouisson, S. Malik, V. L. Malyshev, H. S. Mao, Y. Maravin, B. Martin, R. McCarthy, A. Melnitchouk, L. Mendoza, P. G. Mercadante, M. Merkin, K.W. Merritt, J. Meyer,22,x A. Meyer, T. Millet, J. Mitrevski, J. Molina, R. K. Mommsen, N.K. Mondal, R.W. Moore, T. Moulik, G. S. Muanza, M. Mulders, M. Mulhearn, O. Mundal, L. Mundim, E. Nagy, M. Naimuddin, M. Narain, N. A. Naumann, H.A. Neal, J. P. Negret, P. Neustroev, H. Nilsen, H. Nogima, S. F. Novaes, T. Nunnemann, V. O’Dell, D. C. O’Neil, G. Obrant, C. Ochando, D. Onoprienko, N. Oshima, J. Osta, R. Otec, G. J. Otero y Garzón, M. Owen, P. Padley, M. Pangilinan, N. Parashar, S.-J. Park, S. K. Park, J. Parsons, R. Partridge, N. Parua, A. Patwa, G. Pawloski, B. Penning, M. Perfilov, K. Peters, Y. Peters, P. Pétroff, M. Petteni, R. Piegaia, J. Piper, M.-A. Pleier, P. L.M. Podesta-Lerma, V.M. Podstavkov, Y. Pogorelov, M.-E. Pol, P. Polozov, B.G. Pope, A.V. Popov, C. Potter, W. L. Prado da Silva, H. B. Prosper, S. Protopopescu, J. Qian, A. Quadt,22,x B. Quinn, A. Rakitine, PHYSICAL REVIEW D 77, 091102(R) (2008) RAPID COMMUNICATIONS",,https://www.semanticscholar.org/paper/1d8026080ae2003a5e359e36155d7ecdc349b163,
858,Fundamental discrepancies between average-case analyses under discrete and continuous distributions: a bin packing case study,"We consider the average case behavior of onedmensional bin paekmg algorithms in the case where bins have unit capacity and item sizes are chosen according to the ‘ ‘dficrete uniform” distribution U~; k), 1 s j < k, where each item size in the set {llk,21k,..., ji k) has probability 1/j of beiig chosen. Note that for fixed j,k the distributions U{?nj;mk]’ approach the continuous distribution U(O, jlk] as m A W, where in U(O, jl k] the item sizes are chosen uniformly horn the half-open interval (O,jik]. In this paper, we show that average case behavior can differ substantially under the two types of distributions. We show that for all j, k, j < k-1, there exist on-line algorithms that have constant expected waste under U~; k], whereas no on-line algorithm can have less than C2(n1’2) waste under U(O, U] for any u s 1. Conmariwise, although the First Fit Decreasing (off-line) algorithm has constant expected waste under U(O, u] for all u < 1/2, there are many combinations j,k with j < k/2 such that First Fit Decreasing has t3(tI) expected waste under U(j;k). The constant of proportionality is maxtilzed for j = 6 and k = 13, in which case the expected waste k nl 624.",1991-01-03,https://www.semanticscholar.org/paper/48097d98a358c85aa9b2885e79df00d45c9b4648,Symposium on the Theory of Computing
2046,An indirect workforce (re)allocation model for semiconductor manufacturing,"Semiconductor industry is a capital intensive and knowledge intensive industry, in which human resource management and human capital enhancement is increasingly important. To maintain competitive human resource, it is critical to develop a decision framework for headcount planning and workforce allocation for indirect labors. Motivated by the needs in real setting, this study aims to develop a model for allocating indirect workforce among semiconductor fabrication facilities to meet expected outputs and labor productivity improvement. Workforce allocation and reallocation based on the overall corporate workforce level is essential so that the shortage or exceed workforce will be balanced among different production sites. The key to achieve this purpose is the proper understanding of real requirements of each production site according to its corresponding tasks assigned. Non-parametric activity analysis approach is used for the workforce requirement estimation given delegated tasks. The estimation is based on the best performance from the past with adjustments reflecting the expected productivity growth.",2008-12-07,https://www.semanticscholar.org/paper/571005a8da0f402fdce7a6dcb48fdf18b61f4dc4,Online World Conference on Soft Computing in Industrial Applications
2486,Subtle cueing for visual search in head-tracked head worn displays,"Goal-oriented visual search in augmented reality can be facilitated by using visual cues to call attention to a target. However, traditional use of explicit cues can degrade visual search performance due to scene distortion, occlusion and addition of visual clutter. In contrast, Subtle Cueing has been previously proposed as an alter-native to explicit cueing, but little is known about how well it works for head-tracked head worn displays (HWDs). We investigated the effect of Subtle Cueing for head-tracked head worn displays, using visual search research methods in simulated augmented reality environments. Our user study found that Subtle Cueing improves visual search performance, and serves as a feasible cueing mechanism for AR environments using HWDs.",2013-10-01,https://www.semanticscholar.org/paper/6f7f4b48357b104fb3ddf8778f70a0be33a421a6,International Symposium on Mixed and Augmented Reality
1234,Present Status of the SuperCDMS program,,2008-01-25,https://www.semanticscholar.org/paper/830b2c6105f1e16e48f845059eff4e15547a50bb,
2539,Relaxed selection techniques for querying time-series graphs,"Time-series graphs are often used to visualize phenomena that change over time. Common tasks include comparing values at different points in time and searching for specified patterns, either exact or approximate. However, tools that support time-series graphs typically separate query specification from the actual search process, allowing users to adapt the level of similarity only after specifying the pattern. We introduce relaxed selection techniques, in which users implicitly define a level of similarity that can vary across the search pattern, while creating a search query with a single-gesture interaction. Users sketch over part of the graph, establishing the level of similarity through either spatial deviations from the graph, or the speed at which they sketch (temporal deviations). In a user study, participants were significantly faster when using our temporally relaxed selection technique than when using traditional techniques. In addition, they achieved significantly higher precision and recall with our spatially relaxed selection technique compared to traditional techniques.",2009-10-04,https://www.semanticscholar.org/paper/f61ed852eca18bd3d99d68538b0234204eed314b,ACM Symposium on User Interface Software and Technology
3353,Combat and communication in the Everglades pygmy sunfish,,1981-02-01,https://www.semanticscholar.org/paper/0bfc5320c0a8b58a58bf4fa173d48c8145408dfb,Animal Behaviour
3095,Feasibility of Voice over IP on the Internet,"VoIP (Voice over IP) services are using the Internet infrastructure to enable new forms of communication and collaboration. A growing number of VoIP service providers such as Skype, Vonage, Broadvoice, as well as many cable services are using the Internet to offer telephone services at much lower costs. However, VoIP services rely on the user’s Internet connection, and this can often translate into lower quality communication. Overlay networks offer a potential solution to this problem by improving the default Internet routing and overcome failures. To assess the feasibility of using overlays to improve VoIP on the Internet, we have conducted a detailed experimental study to evaluate the benefits of using an overlay on PlanetLab nodes for improving voice communication connectivity and performance around the world. Our measurements demonstrate that an overlay architecture can significantly improve VoIP communication across most regions and provide their greatest benefit for locations with poorer default Internet connectivity. We explore overlay topologies and show that a small number of well-connected intermediate nodes is sufficient to improve VoIP performance. We show that there is significant variation over time in the best overlay routing paths and argue for the need for adaptive routing to account for this variation to deliver the best performance.",,https://www.semanticscholar.org/paper/2dee1dc33195afc5c293f8176ae8473ba31826d8,
399,On the approximability of the traveling salesman problem (extended abstract),"We show that the traveling salesman problem with triangle inequality cannot be approximated within ~0 when the edge lengths are allowed to be asymmetric and within 12_~9 z2s when the edge lengths are symmetric. The best previous 2s05 _ j 53s1 respectively. The reduction lower bounds were ~ ~ttt is from H£stad's maximum satisfiability of linear equations modulo 2, and is nonconstructive.",2000-05-01,https://www.semanticscholar.org/paper/b1f427b2c3a7bf7e548172c6f26fde1ee0605fa6,Symposium on the Theory of Computing
1095,First Measurements of SuperCDMS SNOLAB 100 mm Diameter Germanium Dark Matter Detectors with Interleaved Charge and Phonon Channels,"H. Chagani, D. A. Bauer, D. Brandt, P. L. Brink, R. Bunker, B. Cabrera, M. Cherry, G. A. Codoreanu, E. Do Couto e Silva, P. Cushman, G. L. Godfrey, J. Hall, S. Hansen, J. Hasi, M. Kelsey, A. Kennedy, C. J. Kenney, S. W. Leman, f V. Mandic, N. Mirabolfathi, S. Monin, D. Nagasawa, L. Novak, R. Partridge, C. Phenicie, K. Page, M. Pyle, R. Radpour, W. Rau, R. Resch, B. Sadoulet, D. N. Seitz, B. Serfass, B. Shank, D. Strandberg, A. Tomada, A. N. Villano, J. Yen, B. A. Young and J. Zhang School of Physics & Astronomy, University of Minnesota, Minneapolis, MN 55455, USA Fermi National Accelerator Laboratory, Batavia, IL 60510, USA SLAC National Accelerator Laboratory, Menlo Park, CA 94025, USA Department of Physics, Syracuse University, Syracuse, NY 13244, USA Department of Physics, Stanford University, Stanford, CA 94305, USA f Department of Physics, Massachusetts Institute of Technology, Cambridge, MA 02139, USA Department of Physics, University of California, Berkeley, Berkeley, CA 94720, USA Department of Physics, Physics Engineering & Astronomy, Queen’s University, Kingston, ON",2015-07-03,https://www.semanticscholar.org/paper/b5ee60957dd62f354684f63da98354576c1048e5,
2283,Minireview Molecular control of neutrophil apoptosis,"Abstract Human neutrophils constitutively undergo apoptosisand this process is critical for the resolution of inflammation.Whilst neutrophil apoptosis can be modulated by a wide varietyof agents including GM-CSF, LPS and TNF-K, the molecularmechanisms underlying neutrophil death and survival remainlargely undefined. Recent studies have shown the involvement ofmembers of the Bcl-2 protein family (especially Mcl-1 and A1)and caspases in the regulation and execution of neutrophilapoptosis. Cell surface receptors and protein kinases, particu-larly mitogen-activated protein kinases, also play critical roles intransducing the signals that result in neutrophil apoptosis orextended survival. This review summarises current knowledge onthe molecular mechanisms and components of neutrophilapoptosis. s 2001 Federation of European Biochemical Soci-eties. Published by Elsevier Science B.V. All rights reserved.Key words: Bcl-2 family; Caspase; Protein kinase;Mitogen-activated protein kinase; Mcl-1; A11. IntroductionNeutrophils are polymorphonuclear leukocytes that are es-sential components of the natural immune system. They formthe ¢rst line of defence against bacterial and fungal infections.Neutrophils are terminally diierentiated cells and are pro-duced in the bone marrow from myeloid stem cells by theprocess called ‘phagocytopoiesis’. Whilst they have a veryshort half life in the circulation (8^20 h), this can increaseseveral fold once they enter infected or in£amed tissues [1].Aged neutrophils undergo spontaneous apoptosis (pro-grammed cell death) in the absence of cytokines or otherproin£ammatory agents prior to their removal by macro-phages [2]. This phagocytic removal of intact, apoptotic neu-trophils prevents them from releasing their cytotoxic contentinto the extracellular milieu that would occur if the cells diedby necrosis. In acute in£ammation, neutrophil numbers withintissues can be extremely high because of targeted in£ux fromthe circulation and because their constitutive apoptotic path-way is delayed by the action of local in£ammatory mediators[3]. Thus, the potential for in£ammatory neutrophils to causetissue damage via the release of toxic reactive oxygen speciesand granule enzymes such as proteases is very high. Death byapoptosis and safe removal by phagocytic cells thus helps tolimit tissue damage during the resolution of in£ammation.Understanding the processes that regulate constitutive neutro-phil apoptosis and cytokine-mediated delay of cell death willlead to a better understanding of the molecular pathology ofin£ammatory diseases in which neutrophil apoptosis may beperturbed and could also identify new therapeutic targets.2. Molecular changes in neutrophils during apoptosisNeutrophils lose their functional properties during apopto-sis and they display morphological and biochemical character-istics of an apoptotic cell, including cell shrinkage, compac-tion of chromatin and loss of the multilobed shape of thenucleus [4^6]. They also show molecular alterations on theircell surface that result from either decreased expression ofcertain receptors or else the appearance of new surface mole-cules. Neutrophil apoptosis is accompanied by the down-reg-ulation of the immunoglobulin superfamily members (e.g.CD31, CD50, CD66acde, CD66b, CD63 and CD87) andcell surface receptors (e.g. CD15, CD16, CD32, CD35,CD88, CD120b [8,9]). Phosphatidylserine, a molecular markerof apoptotic cells, also appears on the surface of apoptoticneutrophils as the symmetry of their plasma membrane phos-pholipids is altered [9,10]. The externalisation of this moleculefacilitates the recognition of apoptotic neutrophils by macro-phages and it is also a convenient indicator of apoptotic neu-trophils as phosphatidylserine can bind £uorescently labelledannexin V [11].Apoptotic neutrophils are non-functional and lose the abil-ity to move by chemotaxis, generate a respiratory burst ordegranulate. This loss of functional capacity results from thedisablement of their activation pathways, and the decreasedexpression of surface receptors aids in this shutdown in activ-ity by preventing them e⁄ciently binding extracellular ligands.These inactive neutrophils, with altered surface epitopes, arethen phagocytosed [4,5]. Fibroblasts ingesting apoptotic neu-trophils employ both K",,https://www.semanticscholar.org/paper/11127c364a21aebbd684299d8fe0774b4c948396,
1457,Physics possibilities at a photon linear collider,,,https://www.semanticscholar.org/paper/4d0e01bd44f14b3a06bb21bad4bf00e9dd40bca8,
2497,Using augmented snapshots for viewpoint switching and manipulation in augmented reality,"SnapAR is a magic-lens-based hand-held augmented reality application that allows its user to store snapshots of a scene and revisit them virtually at a later time. By storing a still image of the unaugmented background along with the 6DOF camera pose, this approach allows augmentations to remain dynamic and interactive. This makes it possible for the user to quickly switch between vantage points at different locations from which to view and manipulate virtual objects, without the overhead of physically traveling between those locations.",2012-05-05,https://www.semanticscholar.org/paper/825ac8d02f18c1daff59f45b5cdb86490dededab,CHI Extended Abstracts
680,Distance Preserving Embeddings for General n-Dimensional Manifolds,"Low dimensional embeddings of manifold data have gained popularity in the last decade. However, a systematic finite sample analysis of manifold embedding algorithms largely eludes researchers. Here we present two algorithms that embed a general n-dimensionalmanifold into Rd (where d only depends on some key manifold properties such as its intrinsic dimension, volume and curvature) that guarantee to approximately preserve all interpoint geodesic distances.",2012-06-16,https://www.semanticscholar.org/paper/68762c51b68ef689e9809bbc42f1b9abf141fa5e,Annual Conference Computational Learning Theory
2838,Nonalcoholic steatohepatitis and hepatocellular carcinoma in galectin‐3 knockout mice,"Aim:  Nonalcoholic fatty liver disease (NAFLD) represents a growing health concern due to its rapidly increasing prevalence worldwide. Nonalcoholic steatohepatitis (NASH) is a progressing form of NAFLD, and recently many studies have reported that it could eventually develop into hepatocellular carcinoma (HCC). We previously reported that 6‐month‐old male galectin‐3 knockout (gal3−/−) mice developed clinicopathological features similar to those of NAFLD in humans. Our aim was to investigate the changes in liver histology in gal3−/− mice by long‐term observation.",2008-12-01,https://www.semanticscholar.org/paper/0edb56a38b7b2d4587be10eeca9b018aa4779513,Hepatology Research
613,Flowshop scheduling with limited temporary storage,"We examine the problem of scheduling 2-machine flowshops in order to minimize makespan, using a limited amount of intermediate storage buffers. Although there are efficient algorithms for the extreme cases of zero and infinite buffer capacities, we show that all the intermediate (finite capacity) cases are NP-complete. We prove exact bounds for the relative improvement of execution times when a given buffer capacity is used. We also analyze an efficient heuristic for solving the 1-buffer problem, showing that it has a 3/2 worst-case performance. Furthermore, we show that the ""no-wait"" (i.e., zero buffer) flowshop scheduling problem with 4 machines is NP-complete. This partly settles a well-known open question, although the 3-machine case is left open here.",1980-07-01,https://www.semanticscholar.org/paper/007089460cf583bc9ae297878d36bf23721e71c9,JACM
1706,Bayesian Nonnegative Matrix Factorization with Stochastic Variational Inference,,2014-11-06,https://www.semanticscholar.org/paper/87224164eef14589b137547a3fa81f06eef9bbf4,Handbook of Mixed Membership Models and Their Applications
324,Ian and Turing,"Our hero is Turing, an interactive tutoring program and namesake (or virtual emanation?) of Alan Turing, World War II code breaker and father of computer science. In this unusual novel, Turing's idiosyncratic version of intellectual history from a computational point of view unfolds in tandem with the story of a love affair involving Ethel, a successful computer executive, Alexandros, a melancholy archaeologist, and Ian, a charismatic hacker. After Ethel (who shares her first name with Alan Turing's mother) abandons Alexandros following a sundrenched idyll on Corfu, Turing appears on Alexandros's computer screen to unfurl a tutorial on the history of ideas. He begins with the philosopher-mathematicians of ancient Greece -- ""discourse, dialogue, argument, proof... can only thrive in an egalitarian society"" -- and the Arab scholar in ninth-century Baghdad who invented algorithms; he moves on to many other topics, including cryptography and artificial intelligence, even economics and developmental biology. (These lessons are later critiqued amusingly and developed further in postings by a fictional newsgroup in the book's afterword.) As Turing's lectures progress, the lives of Alexandros, Ethel, and Ian converge in dramatic fashion, and the story takes us from Corfu to Hong Kong, from Athens to San Francisco -- and of course to the Internet, the disruptive technological and social force that emerges as the main locale and protagonist of the novel.Alternately pedagogical and romantic, Turing (A Novel about Computation) should appeal both to students and professionals who want a clear and entertaining account of the development of computation and to the general reader who enjoys novels of ideas.",,https://www.semanticscholar.org/paper/03746f5e394a15fabf8fc828ca1979796cc076f2,
1063,Vibration and EMF Backgrounds at NEXUS,,2019-07-08,https://www.semanticscholar.org/paper/c17fe85ac6317262d03fc90b989018dbba6780cf,
840,Linear programming without the matrix,"We study the problem facing a set of decision-makers who must select values for the variables of a linear program, when only parts of the matrix are available to each of them. The goal is to find a feasible solution that is as close to the true optimum as possible, When each decision-maker decides one variable and knows all constraints involving this variable, we show that the worst-case ratio is related tc,the maximum number of variables appearing in each constraint, and a simple “safe” heuristic is optimal. Since this problem involves constrained optimization, there is a novel criterion, besides the competitive ratio, comparing the performance of a heuristic with the best feasible distributed algorithm, perhaps specializing on the current inst ante; we show different bounds for this parameter. When the constraint structure (the zero-nonzero pattern of the matrix) is known in advance, and the variables are partitioned bet ween decision-makers, then the optimum ratio is a complicated parameter of the associated hypergraph, which we bound from above and below in terms of variants of clique and graph coloring; but several interesting special cases are characterized completely. 1 Department of Computer Science and Engineering, University of California at San Diego. Research supported by the National Science Foundation. 2 AT&T Bell Laboratories, Murray Hill, NJ 07974. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee arrd/or specific permission. 25th ACM STOC ‘93-51931CA, LE3A e 1993 ACM 0-89791-591-7/93/0005/0121 . ..$l .50",1993-06-01,https://www.semanticscholar.org/paper/86ce7307b8a84ae45f30a61821d40b01da2c0308,Symposium on the Theory of Computing
1481,Measurement of tau branching ratios.,"We have measured the branching ratios for several tau decay modes. We use e/sup +/e/sup -/..-->..tau/sup +/tau/sup -/ events accumulated with the TPC/Two-Gamma facility at the SLAC e/sup +/e/sup -/ storage ring PEP. The data correspond to an integrated luminosity of 77 pb/sup -1/ at a center-of-mass energy of 29 GeV. The one- and three-charged-particle inclusive branching ratios of the tau decay are measured to be B/sub 1/ = (84.7 +- 1.0)% and B/sub 3/ = (15.1 +- 1.0)%, where B/sub 1/+B/sub 3/ is constrained to be 99.85%. The branching ratios of the two leptonic decay modes are B(tau/sup -/..-->..e/sup -/ nu-bar/sub e/..nu../sub tau/) = (18.4 +- 1.6)% and B(tau/sup -/..--> mu../sup -/ nu-bar/sub ..mu../..nu../sub tau/) = (17.7 +- 1.4)%. If we then assume lepton universality, we obtain B(tau/sup -/..-->..e/sup -/ nu-bar/sub e/..nu../sub tau/) = (18.3 +- 0.9)% and B(tau/sup -/..--> mu../sup -/ nu-bar/sub ..mu../..nu../sub tau/) = (17.8 +- 0.9)%. We measure the Cabibbo-allowed semihadronic decay mode B(tau/sup -/..--> pi../sup -/+neutral particles) = (47.0 +- 1.5)%, and the Cabibbo-suppressed tau decay mode B(tau/sup -/..-->..K/sup -/+neutral particles) = (1.6 +- 0.4)%. By looking for associated photons, we find B(tau/sup -/..-->..K/sup -/..pi../sup 0/+neutral particles) to be (1.2 +- 0.6)%.",1987-03-01,https://www.semanticscholar.org/paper/94f89220aed31df78dfd3f2893e5f4cffac2cb2b,
1370,A Search for the Flavor-Changing Neutral Current Decay B 0 ! µ + µ in pp Collisions at p s = 1.96 TeV with the DØ Detector,,,https://www.semanticscholar.org/paper/5b2090116aa4141e5c51fe2752ada80ceb80ce88,
1787,The Ideal Point Topic Model : Predicting Legislative Roll Calls from Text,"We develop the ideal point topic model, a probabilistic model of legislative text. Our model – drawing on ideas from ideal point estimation and topic modeling – predicts voting patterns based on the contents of bills and the inferred political leanings of legislators. It also provides an exploratory window into how legislative language is correlated with political support. Across 14 years of legislative data, we predict specific voting patterns with high accuracy.",,https://www.semanticscholar.org/paper/be98bc6a2694b150fff2394f88c2b84e06e5a510,
2761,Knowledge-based graphical interfaces for presenting technical information,"Designing effective presentations of technical information is extremely difficult and time-consuming. Moreover, the combination of increasing task complexity and declining job skills makes the need for high-quality technical presentations especially urgent. We believe that this need can ultimately be met through the development of knowledge-based graphical interfaces that can design and present technical information. Since much material is most naturally communicated through pictures, our work has stressed the importance of well-designed graphics, concentrating on generating pictures and laying out displays containing them. We describe APEX, a testbed picture generation system that creates sequences of pictures that depict the performance of simple actions in a world of 3D objects. Our system supports rules for determining automatically the objects to be shown in a picture, the style and level of detail with which they should be rendered, the method by which the action itself should be indicated, and the picture's camera specification. We then describe work on GRIDS, an experimental display layout system that addresses some of the problems in designing displays containing these pictures, determining the position and size of the material to be presented.",1988-11-01,https://www.semanticscholar.org/paper/07dbaf8581205d72fc397f4cdfe5c93943826a1d,
3149,Fist: a system for stackable file-system code generation,FiST: A Systemfor StackableFile-SystemCodeGeneration,,https://www.semanticscholar.org/paper/faaec4e2a49a161d11bc79c3f836ea06790bb520,
2700,Managing networks through a virtual world,"As network services become more sophisticated to handle multimedia exchange, demands for real-time network control are increasing. With 2D workstations, managers can observe network activities only at a distance. Direct observation requires a 3D interface combined with a structured control architecture. >",1995-06-01,https://www.semanticscholar.org/paper/4b9a15dd00a738b6425cf0de6b45d07b802fad6f,IEEE Parallel Distributed Technol. Syst. Appl.
469,Information caching for delivery of personalized video programs on home entertainment channels,"The synergy between computing and information systems promises to herald a new epoch in which users not only have access to mundane services, such as television, radio, and telephones, but they also have access to an entirely new variety of entertainment services that are automatically customized to suit their individual needs. The authors explore the architectural considerations that underlie the realization of personalized multimedia entertainment services over metropolitan-area broadband networks, and devise near-optimal information caching strategies to determine when, where, and for how long video programs must be cached, so as to minimize the cumulative storage and network costs borne by users.<<ETX>>",1994-05-15,https://www.semanticscholar.org/paper/752b50425a2b634e8d332e400c2e895342435262,1994 Proceedings of IEEE International Conference on Multimedia Computing and Systems
1,Quantifying the Effects of COVID-19 on Restaurant Reviews,"The COVID-19 pandemic has implications beyond physical health, affecting society and economies. Government efforts to slow down the spread of the virus have had a severe impact on many businesses, including restaurants. Mandatory policies such as restaurant closures, bans on social gatherings, and social distancing restrictions have affected restaurant operations as well as customer preferences (e.g., prompting a demand of stricter hygiene standards). As of now, however, it is not clear how and to what extent the pandemic has affected restaurant reviews, an analysis of which could potentially inform policies for addressing this ongoing situation. In this work, we present our efforts to understand the effects of COVID-19 on restaurant reviews, with a focus on Yelp reviews produced during the pandemic for New York City and Los Angeles County restaurants. Overall, we make the following contributions. First, we assemble a dataset of 600 reviews with manual annotations of fine-grained COVID-19 aspects related to restaurants (e.g., hygiene practices, service changes, sympathy and support for local businesses). Second, we address COVID-19 aspect detection using supervised classifiers, weakly-supervised approaches based on keywords, and unsupervised topic modeling approaches, and experimentally show that classifiers based on pre-trained BERT representations achieve the best performance (F1=0.79). Third, we analyze the number and evolution of COVID-related aspects over time and show that the resulting time series have substantial correlation (Spearman’s \rho=0.84) with critical statistics related to the COVID-19 pandemic, including the number of new COVID-19 cases. To our knowledge, this is the first work analyzing the effects of COVID-19 on Yelp restaurant reviews and could potentially inform policies by public health departments, for example, to cover resource utilization.",2021-06-01,https://www.semanticscholar.org/paper/9fafc9896d2b81d1328791e4c2fd7ab096f155f3,International Workshop on Natural Language Processing for Social Media
655,Predictors of thrombotic complications after placement of the flexible coil stent.,,1994-06-15,https://www.semanticscholar.org/paper/f72a198d0c5eae595e07dc8648d91c5b26c8424c,American Journal of Cardiology
1474,Limits on heavy leptons with massive neutrinos,,,https://www.semanticscholar.org/paper/40ba9db106ce3ab6e1202b8f5cb7fb45a64bb24a,
3382,Incremental Edge Orientation in Forests,"For any forest $G = (V, E)$ it is possible to orient the edges $E$ so that no vertex in $V$ has out-degree greater than $1$. This paper considers the incremental edge-orientation problem, in which the edges $E$ arrive over time and the algorithm must maintain a low-out-degree edge orientation at all times. We give an algorithm that maintains a maximum out-degree of $3$ while flipping at most $O(\log \log n)$ edge orientations per edge insertion, with high probability in $n$. The algorithm requires worst-case time $O(\log n \log \log n)$ per insertion, and takes amortized time $O(1)$. The previous state of the art required up to $O(\log n / \log \log n)$ edge flips per insertion. We then apply our edge-orientation results to the problem of dynamic Cuckoo hashing. The problem of designing simple families $\mathcal{H}$ of hash functions that are compatible with Cuckoo hashing has received extensive attention. These families $\mathcal{H}$ are known to satisfy \emph{static guarantees}, but do not come typically with \emph{dynamic guarantees} for the running time of inserts and deletes. We show how to transform static guarantees (for $1$-associativity) into near-state-of-the-art dynamic guarantees (for $O(1)$-associativity) in a black-box fashion. Rather than relying on the family $\mathcal{H}$ to supply randomness, as in past work, we instead rely on randomness within our table-maintenance algorithm.",2021-07-05,https://www.semanticscholar.org/paper/df478052482b7248606768347c76c50326b6629f,Embedded Systems and Applications
127,Adaptive Deadlock- and Livelock-Free Routing in the Hypercube Network,"This paper consists of two parts. In the first one, two new algorithms for wormhole routing on the hypercube network are presented. These techniques are adaptive and are ensured to be deadlock- and livelock-free. These properties are guaranteed by using a small number of resources in the routing node. The first algorithm is adaptive and nonminimal and will be referred to as Nonminimal. In this technique, some moderate derouting is allowed in order to alleviate the potential congestion arising from highly structured communication patterns. The second algorithm, dubbed Subcubes, is adaptive and minimal, and is based on partitioning the hypercube into subcubes of smaller dimension; This technique requires only two virtual channels per physical link of the node. In the second part of the paper, a wide variety of techniques for wormhole routing in the hypercube are evaluated from an algorithmic point of view. Five partially adaptive algorithms are considered: the Hanging algorithm, the Zenith algorithm, the Hanging-Order algorithm, the Nonminimal algorithm; and the Subcubes algorithm. One oblivious algorithm, the Dimension-Order, or E-Cube routing algorithm, is also used. Finally, a Fully Adaptive Minimal algorithm is tried. A simple node model was designed and adapted to all the algorithms. >",1994-11-01,https://www.semanticscholar.org/paper/90242db49d74e120e96ef1a66ecda0f0a92e1faa,IEEE Trans. Parallel Distributed Syst.
3083,"Proceedings of the 1st ACM Workshop on Virtual Machine Security, VMSec 2008, Alexandria, VA, USA, October 27, 2008",,,https://www.semanticscholar.org/paper/d64c4eb79f76bcf77d313c4be1605b00be3d6db3,VMSec
5,Leveraging Just a Few Keywords for Fine-Grained Aspect Detection Through Weakly Supervised Co-Training,"User-generated reviews can be decomposed into fine-grained segments (e.g., sentences, clauses), each evaluating a different aspect of the principal entity (e.g., price, quality, appearance). Automatically detecting these aspects can be useful for both users and downstream opinion mining applications. Current supervised approaches for learning aspect classifiers require many fine-grained aspect labels, which are labor-intensive to obtain. And, unfortunately, unsupervised topic models often fail to capture the aspects of interest. In this work, we consider weakly supervised approaches for training aspect classifiers that only require the user to provide a small set of seed words (i.e., weakly positive indicators) for the aspects of interest. First, we show that current weakly supervised approaches fail to leverage the predictive power of seed words for aspect detection. Next, we propose a student-teacher approach that effectively leverages seed words in a bag-of-words classifier (teacher); in turn, we use the teacher to train a second model (student) that is potentially more powerful (e.g., a neural network that uses pre-trained word embeddings). Finally, we show that iterative co-training can be used to cope with noisy seed words, leading to both improved teacher and student models. Our proposed approach consistently outperforms previous weakly supervised approaches (by 14.1 absolute F1 points on average) in six different domains of product reviews and six multilingual datasets of restaurant reviews.",2019-09-01,https://www.semanticscholar.org/paper/7ab1f41d7bdfd9133167d92bca787fac888103cd,Conference on Empirical Methods in Natural Language Processing
3403,An O(Log Log m)-Competitive Algorithm for Online Machine Minimization,"This paper considers the online machine minimization problem, a basic real time scheduling problem. The setting for this problem consists of n jobs that arrive over time, where each job has a deadline by which it must be completed. The goal is to design an online scheduler that feasibly schedules the jobs on a nearly minimal number of machines. An algorithm is c-machine optimal if the algorithm will feasibly schedule a collection of jobs on c ·m machines if there exists a feasible schedule on m machines. For over two decades the best known result was a O(log P)-machine optimal algorithm, where P is the ratio of the maximum to minimum job size. In a recent breakthrough, a O(log m)-machine optimal algorithm was given. In this paper, we exponentially improve on this recent result by giving a O(log log m)-machine optimal algorithm.",2017-08-29,https://www.semanticscholar.org/paper/ba3b847a21e431961ef60e466afa2df2334ef125,IEEE Real-Time Systems Symposium
1266,Measurement of the CP-violation parameter of B 0 mixing and decay with pp̄ → μ μ X data,,,https://www.semanticscholar.org/paper/eafba31c133c1f49ae20a35651ed033618dc80ef,
1356,Search for supersymmetry via associated production of charginos and neutralinos in final states with three leptons.,"A search for associated production of charginos and neutralinos is performed using data recorded with the D0 detector at a pp center-of-mass energy of 1.96 TeV at the Fermilab Tevatron Collider. This analysis considers final states with missing transverse energy and three charged leptons, of which at least two are electrons or muons. No evidence for supersymmetry is found in a data set corresponding to an integrated luminosity of 320 pb-1. Limits on the product of the production cross section and leptonic branching fraction are set. For the minimal supergravity model, a chargino lower mass limit of 117 GeV at the 95% C.L. is derived in regions of parameter space with enhanced leptonic branching fractions.",2005-04-18,https://www.semanticscholar.org/paper/adbe9c8beed480277d170cdf2807b7fb85ec174b,Physical Review Letters
337,An economic model of the worldwide web,"We believe that much novel insight into the worldwide web can be obtained from taking into account the important fact that it is created, used, and run by selfish optimizing agents: users, document authors, and search engines. On-going theoretical and experimental analysis of a simple abstract model of www creation and search based on user utilities illustrates this point: We find that efficiency is higher when the utilities are more clustered, and that power-law statistics of document degrees emerge very naturally in this context. More importantly, our work sets up many more elaborate questions, related, e.g., to www search algorithms seen as author incentives, to search engine spam, and to search engine quality and competition.",2005-05-10,https://www.semanticscholar.org/paper/bb604ec86a36e95920ad0468590bc587532d23ae,The Web Conference
3521,Long Tours and Short Superstrings (Preliminary Version),,,https://www.semanticscholar.org/paper/f14b57f477b4024ab2b584617d3dc7e10a622b2c,IEEE Annual Symposium on Foundations of Computer Science
1412,Table 8 ; High-$p_T$ jets in $\bar{p}p$ collisions at $\sqrt{s} = 630$ GeV and 1800 GeV,,,https://www.semanticscholar.org/paper/8aee291ef201d9ed56b668b8c8b46d851c0a4d0b,
3200,Both Prey and Predator Features Determine Predation Risk and Survival of Schooling Prey,"Predation is one of the main evolutionary drivers of social grouping. While it is well appreciated that predation risk is likely not shared equally among individuals within groups, its detailed quantification has remained difficult due to the speed of attacks and the highly-dynamic nature of collective prey response. Here, using high-resolution tracking of solitary predators (Northern pike) hunting schooling fish (golden shiners), we not only provide detailed insights into predator decision-making but show which key spatial and kinematic features of predator and prey influence individual’s risk to be targeted and survive attacks. Pike tended to stealthily approach the largest groups, and were often already inside the school when launching their attack, making prey in this frontal “strike zone” the most vulnerable to be targeted. From the prey’s perspective, those fish in central locations, but relatively far from, and less aligned with, neighbours, were most likely to be targeted. While the majority of attacks (70%) were successful, targeted individuals that did manage to avoid capture exhibited a higher maximum acceleration response just before the attack and were further away from the pike‘s head. Our results highlight the crucial interplay between predators’ attack strategy and response of prey in determining predation risk in mobile animal groups.",2021-12-14,https://www.semanticscholar.org/paper/e7dae451255c279aef1f0118ce70579f165ad1c6,bioRxiv
3619,Learning standard C++ as a new language,"To get the most out of Standard C++ [C++,1998], we must rethink the way we write C++ programs. An approach to such a ""rethink"" is to consider how C++ can be learned (and taught). What design and programming techniques do we want to emphasize? What subsets of the language do we want to learn first? What subsets of the language do we want to emphasize in real code? This paper compares a few examples of simple C++ programs written in a modern style using the standard library to traditional C-style solutions. It argues briefly that lessons from these simple examples are relevant to large programs. More generally, it argues for a use of C++ as a higher-level language that relies on abstraction to provide elegance without loss of efficiency compared to lower-level styles. We want our programs to be easy to write, correct, maintainable, and acceptably efficient. It follows that we ought to use C++ ‐ and any other programming language ‐ in ways that most closely approximate this ideal. It is my conjecture that C++ community has yet to internalize the facilities offered by Standard C ++ so that major improvements relative to the ideal can be obtained from reconsidering our style of C ++ use. This paper focuses on the styles of programming that the facilities offered by Standard C ++ support ‐ not the facilities themselves. The key to major improvements is a reduction of the size and complexity of the code we write through the use of libraries. Below, I demonstrate and quantify these reductions for a couple of simple examples such as might be part of a introductory C++ course. By reducing size and complexity, we reduce development time, ease maintenance, and decrease the cost of testing. Importantly, we also simplify the task of learning C ++. For toy programs and for students who program only to get a good grade in a nonessential course, this simplification would be sufficient. However, for professional programmers efficiency is a major issue. Only if efficiency isn’t sacrificed can we expect our programming styles to scale to be usable in systems dealing with the data volumes and real-time requirements regularly encountered by modern services and businesses. Consequently, I present measurements that demonstrate that the reduction in complexity can be obtained without loss of efficiency. Finally, I discuss the implications of this view on approaches to learning and teaching C ++",1999-05-01,https://www.semanticscholar.org/paper/4cceee85ce11c298ec04d2da0e91ea955329bc78,
646,Intracoronary Stenting for Closure PTCA 917 nomic problems associated with CABG for failed,"Background. Acute closure remains a significant limitation of percutaneous transluminal coronary angioplasty (PTCA) and underlies the majority of ischemic complications. This study details the clinical and angiographic characteristics of a series of patients receiving an intracoronary stent device to manage acute and threatened closure and presents the early clinical results. Methods and Results. From October 1989 through June 1991, 115 patients undergoing PTCA received intracoronary stents to treat acute or threatened closure in 119 vessels. Sixty-three percent had multivessel coronary disease, 33 (29%Y7) had undergone prior coronary artery bypass grafting (CABG), and 52 (45%) had had previous PTCA. Using the American College of Cardiology/American Heart Association (ACC/AHA) classification, 15% of lesions were class A, 55% were class B, and 30% were class C. Eight patients were referred with severe coronary dissection and unstable angina after PTCA at other institutions. Acute closure was defined as occlusion of the vessel with TIMI (Thrombolysis in Myocardial Infarction) 0 or 1 flow immediately before stent placement. Threatened closure required two or more of the following criteria: 1) a residual stenosis greater than 50%o, 2) TIMI grade 2 flow, 3) angiographic dissection comprising extraluminal dye extravasation and/or a length of greater than 15 mm, 4) evidence of clinical ischemia (either typical angina or ECG changes). Twelve vessels (10%) met the criteria for acute closure, and 87 vessels (73%) satisfied the criteria for threatened closure. Twenty vessels (17%) failed to meet two criteria. Stenting produced optimal angiographic results in 111 vessels (93%), with mean diameter stenosis (±1 SD) reduced from 83±12% before to 18±29% after stenting. Overall, in-hospital mortality was 1.7% and CABG was required in 4.2%; Q wave myocardial infarction (MI) occurred in 7% and non-Q wave MI in 91%. Stent thrombosis occurred in nine patients (7.6%). For the 108 patients who presented to the catheterization laboratory without evolving MI, Q wave MI occurred in 4% and non-Q wave MI occurred in 7%. Angiographic follow-up has been performed in 81 eligible patients (76%), and 34 patients (41%) had a lesion of .50%o. Conclusions. This stent may be a useful adjunct to balloon dilatation in acute or threatened closure. Randomized studies comparing this stent with alternative technologies are required. (Circulation 1992;85:916-927)",,https://www.semanticscholar.org/paper/3a03a26bc7fb6675b7761756874aac5e54762f48,
104,Characterizing Web Resources for Improved Search,"As an important initial step to exploit such dimensions for web search, we have focused on geographical relevance. Web sites containing information on restaurants or apartment rentals, for instance, are relevant primarily to web users in geographical proximity to these locations. In contrast, an on-line newspaper may be relevant to users across the United States. We have studied how to mine the web and automatically estimate the geographical scope of web resources by using web hyperlinks and the actual content of web pages. For example, we can map every web page to a location based on where its hosting site resides. Then, we can consider the location of all the pages that point to, say, the Stanford Daily home page. By examining the distribution of these pointers, we can conclude that the Stanford Daily is of interest mainly to residents of the Stanford area, while The Wall Street Journal is of nation-wide interest. Similar conclusions can be drawn for other resources by analyzing the geographical locations that are mentioned in their pages.",,https://www.semanticscholar.org/paper/db8e062f6cba4e914460018de2291d03f1231839,DELOS Workshops / Conferences
3569,Minimizing dependencies within generic classes for faster and smaller programs,"Generic classes can be used to improve performance by allowing compile-time polymorphism. But the applicability of compile-time polymorphism is narrower than that of runtime polymorphism, and it might bloat the object code. We advocate a programming principle whereby a generic class should be implemented in a way that minimizes the dependencies between its members (nested types, methods) and its generic type parameters. Conforming to this principle (1) reduces the bloat and (2) gives rise to a previously unconceived manner of using the language that expands the applicability of compile-time polymorphism to a wider range of problems. Our contribution is thus a programming technique that generates faster and smaller programs. We apply our ideas to GCC's STL containers and iterators, and we demonstrate notable speedups and reduction in object code size (real application runs 1.2x to 2.1x faster and STL code is 1x to 25x smaller). We conclude that standard generic APIs (like STL) should be amended to reflect the proposed principle in the interest of efficiency and compactness. Such modifications will not break old code, simply increase flexibility. Our findings apply to languages like C++, C#, and D, which realize generic programming through multiple instantiations.",2009-10-25,https://www.semanticscholar.org/paper/1ae79c162636fb99316896916af62954df761ae8,"Conference on Object-Oriented Programming Systems, Languages, and Applications"
3498,Distributed Job Scheduling in Rings,"We give a distributed approximation algorithm for job scheduling in a ring architecture. In contrast to many other parallel scheduling models, the model we consider captures the influence of the underlying communications network by specifying that task migration from one processor to another takes time proportional to the distance between those two processors in the network. As a result, our algorithm must balance computational load and communication time. The algorithm is simple, requires no global control, and yields schedules of length at most 4.22 times optimal. We also give a lower bound on the performance of any distributed algorithm and the results of simulation experiments which suggest better performance than does our worst-case analysis.",1997-09-15,https://www.semanticscholar.org/paper/93305a605a37c444041bb3c5350790cd6f004cea,J. Parallel Distributed Comput.
30,Session details: Research session 9: data on the web,,2009-06-29,https://www.semanticscholar.org/paper/6e629e0276c4fa3396c351657d918f91ec873a42,ACM SIGMOD Conference
3517,Job scheduling in rings,"We give distributed approximation algorithms for job scheduling in a ring architecture. In contrast to almost all other parallel scheduling models, the model we consider captures the influence of the underlying communications network by specifying that task migration from one processor to another takes time proportional to the distance between those two processors in the network. As a result, our algorithms must balance both computational load and communication time. The algorithms are simple, require no global control, and work in a variety of settings. All come with small constant-factor approximation guarantees; the basic algorithm yields schedules of length at most 4.22 times optimal. We also give a lower bound on the performance of any distributed algorithm some results for a simple capacitated case, and the results of simulation experiments, which give better results than our worst-case analysis.",1994-08-01,https://www.semanticscholar.org/paper/a9a951376e571894eba6f7668a727b81a2e816c1,ACM Symposium on Parallelism in Algorithms and Architectures
98,Automatic Classification of Text Databases Through Query Probing,,2000-03-08,https://www.semanticscholar.org/paper/485107f8f5d2581aa935ef1148a5bbd23f39f9fc,International Workshop on the Web and Databases
1735,Deep Learning with Hierarchical Convolutional Factor Analysis,"Unsupervised multilayered (“deep”) models are considered for imagery. The model is represented using a hierarchical convolutional factor-analysis construction, with sparse factor loadings and scores. The computation of layer-dependent model parameters is implemented within a Bayesian setting, employing a Gibbs sampler and variational Bayesian (VB) analysis that explicitly exploit the convolutional nature of the expansion. To address large-scale and streaming data, an online version of VB is also developed. The number of dictionary elements at each layer is inferred from the data, based on a beta-Bernoulli implementation of the Indian buffet process. Example results are presented for several image-processing applications, with comparisons to related models in the literature.",2013-08-01,https://www.semanticscholar.org/paper/8d6227e26a4bfc5482c12b8f072496ac6e97ed21,IEEE Transactions on Pattern Analysis and Machine Intelligence
1914,A bi-objective genetic algorithm for intelligent rehabilitation scheduling considering therapy precedence constraints,,2018-06-01,https://www.semanticscholar.org/paper/aada62d312f8a0c9915da3099334983035b62f21,Journal of Intelligent Manufacturing
2874,"Cell Cycle Regulation by Galectin-12, a New Member of the Galectin Superfamily*","Galectins are a family of β-galactoside-binding animal lectins with conserved carbohydrate recognition domains (CRDs). Here we report the identification and characterization of a new galectin, galectin-12, which contains two domains that are homologous to the galectin CRD. The N-terminal domain contains all of the sequence elements predicted to form the two β-sheets found in other galectins, as well as conserved carbohydrate-interacting residues. The C-terminal domain shows considerable divergence from the consensus sequence, and many of these conserved residues are not present. Nevertheless, the protein has lactose binding activity, most likely due to the contribution of the N-terminal domain. The mRNA for galectin-12 contains features coding for proteins with growth-regulatory functions. These include start codons in a context that are suboptimal for translation initiation and AU-rich motifs in the 3′-untranslated region, which are known to confer instability to mRNA. Galectin-12 mRNA is sparingly expressed or undetectable in many tissues and cell lines tested, but it is up-regulated in cells synchronized at the G1 phase or the G1/S boundary of the cell cycle. Ectopic expression of galectin-12 in cancer cells causes cell cycle arrest at the G1 phase and cell growth suppression. We conclude that galectin-12 is a novel regulator of cellular homeostasis.",2001-06-08,https://www.semanticscholar.org/paper/f8e7b7784940cb2b5fdbfd91be5620f371b492eb,Journal of Biological Chemistry
2254,The pathogenesis of systemic sclerosis - insights from the innate immune system,,,https://www.semanticscholar.org/paper/0010271777d3efb50b59adcbc8e0c37f80217305,
3232,Temporal structuring of vigilance behaviour by female Thomson's gazelles with hidden fawns,,2018-11-01,https://www.semanticscholar.org/paper/cf9f84c44e8ca0e6cf867b66fee55bf28a6bd404,Animal Behaviour
3222,Resolving a conservation dilemma: Vulnerable lions eating endangered zebras,"When predators are removed or suppressed for generations, prey populations tend to increase and when predators are re-introduced, prey densities should fall back to pre-control levels. In cases of apparent competition where there are alternate abundant and rare prey species, rare species may decline further than expected or disappear altogether. Recently, concern about the impact of recovering predator populations on wildlife in Laikipia County, Kenya, has led to questions of whether lions (Panthera leo, IUCN Red List Vulnerable) exert top-down pressure on Grevy’s zebra (Equus grevyi, IUCN Red List Endangered). We examined effects of lion predation on Plain’s zebra (E. quagga, IUCN Red List Near Threatened) and Grevy’s zebra populations in a 2,105 km2 area defined by lion movements. We used line transect surveys to estimate density of Grevy’s (0.71/km2) and Plain’s (15.9/km2) zebras, and satellite telemetry to measure movements for lions and both zebras. We tracked lions to potential feeding sites to estimate predation rates on zebras. We compared field-based estimates of predation rates on both zebras to random gas models of encounters that result in predation to ask if lions prey preferentially on Grevy’s zebra at a sufficient rate to drive population declines. Lions preyed on Grevy’s zebra significantly less than expected in 15 of 16 (94%) scenarios considered and lions preyed on Plain’s zebras as expected or significantly less than expected in 15 of 16 scenarios. Population trend of Grevy’s zebra indicates that the Kenya population may be stabilizing. Recruitment rate to the population has tripled since 2004, making it unlikely that lions are having an impact on Grevy’s zebras. In Laikipia County, competitive displacement by livestock (Livestock: Grevy’s zebra ratio = 864:1) and interference competition for grass with Plain’s zebra (Plain’s zebra:Grevy’s zebra ratio = 22:1) are most likely the predominant threats to Grevy’s Zebra recovery.",2018-08-29,https://www.semanticscholar.org/paper/34484d636900b210d49daceb0b6edb5033f6a558,PLoS ONE
1420,The Cryogenic Dark Matter Search Low-Background Facility and Cryostat,"The remainder of this dissertation describes the experimental apparatus of and results obtained during Run 19 of the shallow-site stage of the Cryogenic Dark Matter Search, CDMS I. In this chapter, I discuss the low-background aspects of CDMS I: the expected background-particle rates at the Stanford Underground Facility (SUF), the shield and muon veto designed to attenuate these fluxes, and the radiopure cryostat that holds the detectors. The detailed work to assess background-particle fluxes at SUF during the design of the shield and veto was done by a group consisting of Angela Da Silva from UCB/UBC, Brian Dougherty from Stanford, and Steve Yellin from UCSB. These studies defined the veto and shield design and helped to determine the expected sensitivity of CDMS I. Angela Da Silva's dissertation thoroughly describes this work [91]. The veto and shield were built by the UCSB group, includings dissertation covers in detail the performance of the veto as built [8]. During the operation of CDMS detectors at SUF between 1996 and 2000, simulation work for CDMS I has been taken over by Thushara Perera and Dan Akerib with significant contributions from Steve Eichblatt and Steve Yellin. Pre-screening of most of the materials placed inside the shield was performed by Donna Hurley, Dick McDonald, and Al Smith of LBNL's Low-Background Counting Facility. CDMS's unique cryostat, the Icebox, was designed by a team consisting of many members of the Berkeley, LBNL, and Stanford groups. The Icebox was built at LBNL by a team led by Ron Ross and John Taylor in the Building 77 shops. Assembly and testing was done in the UCB campus labs, also by a large team. The design and construction of the Icebox comprised a significant part of Peter Barnes's graduate work and is fully documented in his dissertation [92]. It is questionable how much of this work to discuss here. Clearly, I cannot do as comprehensive or as high-quality a job as those who were intimately involved in the work. More appropriate is a brief discussion of the "" why's "" of the design of the veto, shield, and Icebox. However, I present",,https://www.semanticscholar.org/paper/1a7a0ef6f393c208135a7ada3ccc441d0acb1ad5,
1632,"Scalable Topic Modeling: Online Learning, Diagnostics, and Recommendation","Abstract : The main activity of my research group is to build and develop the probabilistic pipeline. When solving problems with data, we take the following steps. 1. We make assumptions about our data, embedding it in a probability model containing hidden and observed random variables. 2. Given observations, we use inference algorithms to estimate the conditional distribution of the hidden variables. This is the central statistical and computational problem. 3. With the results of inference, we use our model to form predictions about the future, explore the data, or otherwise apply what we learned to solve a problem. 4. We criticize our model, understand where it went right and wrong, and repeat the process to revise it.",2017-03-01,https://www.semanticscholar.org/paper/9a69c7ef2940f1770acba9033f8d4220d69f41d3,
2341,"Neutrophil function in whole blood and after purification: Changes in receptor expression, oxidase activity and responsiveness to cytokines",,1992-04-01,https://www.semanticscholar.org/paper/b0b66c84f79ca045fa3e2fa9484310b0b894ffaf,Bioscience Reports
272,The ACM PODS Alberto O. Mendelzon test-of-time-award 2009,"In 2007, the PODS Executive Committee decided to establish a Test-of-Time Award, named after the late Alberto O. Mendelzon, in recognition of his scientific legacy, and his service and dedication to the database community. Mendelzon was an international leader in database theory, whose pioneering and fundamental work has inspired and influenced both database theoreticians and practitioners, and continues to be applied in a variety of advanced settings. He served the database community in many ways; in particular, he served as the General Chair of the PODS conference, and was instrumental in bringing together the PODS and SIGMOD conferences. He also was an outstanding educator, who guided the research of numerous doctoral students and postdoctoral fellows. The Award is to be awarded each year to a paper or a small number of papers published in the PODS proceedings ten years prior, that had the most impact (in terms of research, methodology, or transfer to practice) over the intervening decade. The decision was approved by SIGMOD and the ACM. The funds for the Award were contributed by IBM Toronto.",2009-06-29,https://www.semanticscholar.org/paper/10add187b910d4df9340cc0e23282ad657dfa8b3,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
2048,Demand forecast of semiconductor products based on technology diffusion,"Demand forecast plays a critical role to determine capital investment for capacity planning. Given the involved uncertainties and long lead-time for capacity expansion, semiconductor companies have to predict future demands as a basis for related manufacturing strategic decisions. As semiconductor products in a consumer era become more diversified with shortening life cycle, demand forecast also becomes more complex and difficult. This study aims to develop a demand forecast model based on product life cycle and technology diffusion. While little research has been done to employ diffusion models to forecast the demands of semiconductor products. The proposed model modifies a multi-generation diffusion model incorporating marketing variables into the model for semiconductor product and uses nonlinear least square method to estimate the parameters. An empirical study is conducted to validate the proposed model with real data of semiconductor products. This research concludes with discussion on future research directions.",2008-12-07,https://www.semanticscholar.org/paper/610882d6b882729e9fd9fc99a285c82599b41e3c,Online World Conference on Soft Computing in Industrial Applications
2380,Oxygen-radical production during inflammation may be limited by oxygen concentration.,The relationship between oxygen-radical production by rat polymorphonuclear leucocytes and O2 concentration was established by the measurement of luminol-dependent chemiluminescence at defined O2 concentrations. The O2 concentration that gave 50% of the maximum stimulated oxygen-radical production was 31 +/- 9 microM for non-opsonized latex beads and 22 +/- 9 microM for chemotactic peptide. The O2 concentration in rheumatoid synovial fluid was approx. 30 microM. It is therefore proposed that radical production at an inflammatory site may be limited by O2 concentration.,1984-02-01,https://www.semanticscholar.org/paper/ac5d1d220dfd1176e337724b78cf3335167ddfa6,Biochemical Journal
2614,Free-Space Transparency: Exposing Hidden Content Through Unimportant Screen Space,"We present free-space transparency, a method that renders unimportant regions of a window as transparent. This allows users to view screen content that lies beneath these regions. By maximizing the amount of simultaneously visible content, while keeping window sizes and locations constant, users can be made more productive with minimal window layout manipulation.",,https://www.semanticscholar.org/paper/2dcd7cb86dc7dc96f18b5f0af191d6fdc2acad1f,
2623,Rubbing the Fisheye: Precise Touch-Screen Interaction with Gestures and Fisheye Views,"Fisheye lenses are powerful tools for visualizing dense data while simultaneously providing focus and context. Unfortunately, target acquisition in fisheye lenses is complicated by magnification effects that make it seem as if objects in the fisheye view are moving when the view is changed. These problems become even more evident with touchscreen–controlled fisheye views, where there is no continuous navigation and pointing is inaccurate. We show how rapid targeting can be facilitated in fisheye views through transparency and additional stabilized representations of the view. We also present rub-pointing, an interaction technique based on simple gestures that allows precise target acquisition in fisheye lenses on touch screens.",,https://www.semanticscholar.org/paper/96a0ababef0a04c663c52b52a40f50ccdc72d18c,
2714,Management of broadband networks using 3D virtual world,"Just as broadband networks will enable user-to-user communications to extend from textural services to those employing multimedia, they will also enable a management environment that can take advantage of increased bandwidth and multimedia technology. The fundamental advances incorporated in such an environment can provide efficient solutions to the problem of information management. To establish this environment, the authors tackle the fundamental problems of observability and controllability of broadband networks. A virtual world provides a next-generation network management interface through which a user can observe and interact with the network directly in real time. The system that the authors are developing uses a 3D virtual world as the user interface for managing a large gigabit ATM network. It provides the capability for experimentation in all aspects of network transport, control and management.<<ETX>>",1993-07-20,https://www.semanticscholar.org/paper/437c2f3f2a496ae388468abbd2afe5b3add4fb6e,[1993] Proceedings The 2nd International Symposium on High Performance Distributed Computing
72,Parallel Probing of Web Databases for Top-k Query Processing,"A “top-k query” specifies a set of preferredvalues for the attributes of a relation and expects as a result thek objects that are “closest” to the given preferences according to some distance function. In many web applications, the relation attributes are only available viaprobesto autonomous webaccessible sources. Probing these sources sequentially to process a topk query is inefficient, since web accesses exhibit high and variable latency. Fortunately, web sources can be probed in parallel, and each source can typically process concurrent requests, although sources may impose some restrictions on the type and number of probes that they are willing to accept. These characteristics of web sources motivate the introduction of parallel top-k query processing strategies, which are the focus of this paper. We present efficient techniques that maximize source-access parallelism to minimize query response time, while satisfying source access constraints. A thorough experimental evaluation over both synthetic and real web sources shows that our techniques can be significantly more efficient than previously proposed sequential strategies. In addition, we adapt our parallel algorithms for the alternate optimization goal of minimizing source load while still exploiting source-access parallelism.",,https://www.semanticscholar.org/paper/a89dab25098559779eb5ff6fdd5fff966c893976,
855,"Optimization, approximation, and complexity classes","We define a natural variant of NP, MAX NP, and also a subclass called MAX SNP. These are classes of optimization problems, and in fact contain several natural, well-studied ones. We show that problems in these classes can be approximated with some bounded error. Furthermore, we show that a number of common optimization problems are complete under a kind of careful transformation (called L-reduction) that preserves approximability. It follows that such a complete problem has a polynomial-time approximation scheme iff the whole class does. These results may help explain the lack of progress on the approximability of a host of optimization problems.",1991-12-01,https://www.semanticscholar.org/paper/2a078f34447498e5eff8e3922f076c24fdb26f4d,Symposium on the Theory of Computing
759,Multi-Objective Model Checking of Markov Decision Processes,"We study and provide efficient algorithms for multi-objective model checking problems for Markov Decision Processes (MDPs). Given an MDP, M, and given multiple linear-time (ω-regular or LTL) properties ϕi, and probabilities ri ∈ [0, 1], i = 1, . . . , k, we ask whether there exists a strategy α for the controller such that, for all i, the probability that a trajectory of M controlled by α satisfies ϕi is at least ri. We provide an algorithm that decides whether there exists such a strategy and if so produces it, and which runs in time polynomial in the size of the MDP. Such a strategy may require the use of both randomization and memory. We also consider more general multi-objective ω-regular queries, which we motivate with an application to assume-guarantee compositional reasoning for probabilistic systems. 
 
Note that there can be trade-offs between different properties: satisfying property ϕ1 with high probability may necessitate satisfying ϕ2 with low probability. Viewing this as a multi-objective optimization problem, we want information about the ""trade-off curve"" or Pareto curve for maximizing the probabilities of different properties. We show that one can compute an approximate Pareto curve with respect to a set of ω-regular properties in time polynomial in the size of the MDP. 
 
Our quantitative upper bounds use LP methods. We also study qualitative multi-objective model checking problems, and we show that these can be analysed by purely graph-theoretic methods, even though the strategies may still require both randomization and memory.",2007-03-24,https://www.semanticscholar.org/paper/973a2cb018d44d37cbc47944fc7d4e1150b5c5d8,Log. Methods Comput. Sci.
1294,Measurement of the pp̄→WZ+X cross section at s=1.96TeV and limits on WWZ trilinear gauge couplings,"We present measurements of the process p[overline p]-->WZ+X-->[script-l][prime]nu[script-l][prime][script-l][overline [script-l]] at sqrt(s)=1.96 TeV, where [script-l] and [script-l][prime] are electrons or muons. Using 1 fb-1 of data from the D0 experiment, we observe 13 candidates with an expected background of 4.5±0.6 events and measure a cross section sigma(WZ)=2.7-1.3+1.7 pb. From the number of observed events and the Z boson transverse momentum distribution, we limit the trilinear WWZ gauge couplings to -0.17<=lambdaZ<=0.21(DeltakappaZ=0) at the 95% C.L. for a form factor scale Lambda=2 TeV. Further, assuming that Deltag1Z=DeltakappaZ, we find -0.12<=DeltakappaZ<=0.29(lambdaZ=0) at the 95% C.L. These are the most restrictive limits on the WWZ couplings available to date.",2007-09-18,https://www.semanticscholar.org/paper/da62a1bbcb4e212bc6e2d55cd3f9fb7db44ab808,
110,Querying multiple document collections across the internet,"Information sources are available everywhere, both within the internal networks of organizations and on the Internet. The source contents are often hidden behind search interfaces and models that vary from source to source. Furthermore, these sources are usually numerous, and users cannot evaluate their queries over all of them. Consequently, it is crucial for users to have metasearchers, which are services that provide unified query interfaces to multiple information sources. Given a user query, the metasearcher first chooses the best sources to evaluate the query. Second, the metasearcher submits the query to these sources. Finally, the metasearcher merges the query results from the sources. To address the first task, we designed GlOSS, a scalable system that chooses the best document sources for a query. The GlOSS information about each source is orders of magnitude smaller than the source contents. To address the other two tasks above and to facilitate the extraction of the GlOSS information from the sources, we coordinated the design of STARTS, an emerging protocol for Internet retrieval and search involving around 11 companies and organizations. Unfortunately, extracting the best objects for a query according to the metasearcher might be an expensive operation, since the sources' ranking algorithms might differ radically from that of the metasearcher's. We studied a result merging condition that characterizes what sources are ""good"" with respect to result merging. Finally, we also studied the metasearching problem for a novel application: the detection of illegal dissemination of copyrighted material. To address this problem we developed dSCAM an ""illegal copy"" metasearcher that finds potential copies of a document over distributed text sources.",1998-03-17,https://www.semanticscholar.org/paper/53bcd6e9ae8e9143ddb61178a02a6aef3d8995f2,
1400,Search for leptoquark pairs decaying into nunu+jets in pp collisions at square root[s] = 1.8 TeV.,"We present the results of a search for leptoquark (LQ) pairs in (85.2+/-3.7) pb(-1) of pp* collider data collected by the D0 experiment at the Fermilab Tevatron. We observe no evidence for leptoquark production and set a limit on sigma(pp*-->LQLQ-->nunu+jets) as a function of the mass of the leptoquark (m(LQ)). Assuming the decay LQ-->nuq, we exclude scalar leptoquarks for m(LQ) < 98 GeV/c(2), and vector leptoquarks for m(LQ) < 200 GeV/c(2) and coupling which produces the minimum cross section, at a 95% confidence level.",,https://www.semanticscholar.org/paper/ca31f931e15f2a28f26f600a6a39de9ed95fd05d,Physical Review Letters
3629,A Brief Look at C,"This note describes some key aspects of what C++ is and of how C++ has developed over the years. The perspective is that of an experienced C++ user looking at C++ as a practical tool. No attempts are made to compare C++ to other languages, though I have tried to answer some questions that I have often heard asked by Lisp programmers.",,https://www.semanticscholar.org/paper/8bf93a5cbdc8d214f71733828496067114ac3773,
2741,COMET: generating coordinated multimedia explanations,"COMET (Coordinated Multimedia Explanation Testbed) is an experimental system that generates interactive multimedia instructions for equipment maintenance and repair [3, 4]. COMET combines research in natural language generation and in knowledge-based graphics. The form and content of all text and graphics is created interactively. Thus, instructions can be customized on the fly for the individual user and situation.",1991-03-01,https://www.semanticscholar.org/paper/6c177657e47f25938c05ee21e421d79c506b2154,International Conference on Human Factors in Computing Systems
1982,Stochastic programming for vendor portfolio selection and order allocation under delivery uncertainty,,2013-09-03,https://www.semanticscholar.org/paper/c96a2ace9bb7c8db5eda964b694b4ebf0f844f5f,OR Spectr.
829,On complexity as bounded rationality (extended abstract),"It has been hoped that computational approaches can help resolve some well-known paradoxes in game theory. We prove that tf the repeated prisoner’s dilemma M played by finite automata with less than exponentially (in the number of rounds) many states, then cooperation can be achieved an equilibrium (while with ezponentiaily many states, defection is the only equtlibrzum). We furthermore prove a generalization to arbitrary games and Pareto optimai points. Finally, we present a general model of poiynomially computable games, and characterize in terms of fami!iar complexity classes ranging from NP to NEXP the natural problems that arise in relation with such games. 1. GAMES AND BOUNDED RATIONALITY The theory of games [AH], founded by von Neumann and Morgenstern, is supposed to model the behavior of rational economic agents. Very often, however, game theory predicts behavior that can be criticized as unnatural and nonrational —we describe a famous instance below. It has been hoped that the situation can be remedied if the model is modified to take into account appropriate notions of complexity. This work is a contribution in this line of research. To describe and motivate the results, we shall first need some definitions and",1994-05-23,https://www.semanticscholar.org/paper/0620514c01c0aa861af19e9142864f4088af0535,Symposium on the Theory of Computing
1414,Ratio of isolated photon cross sections in pp macro collisions at square root of s = 630 and 1800 GeV.,The inclusive cross section for production of isolated photons has been measured in pp macro collisions at square root of s = 630 GeV with the D0 detector at the Fermilab Tevatron Collider. The photons span a transverse energy (E(T)) range from 7-49 GeV and have pseudorapidity absolute value of eta < 2.5. This measurement is combined with the previous D0 result at square root of s = 1800 GeV to form a ratio of the cross sections. Comparison of next-to-leading-order QCD with the measured cross section at 630 GeV and the ratio of cross sections show satisfactory agreement in most of the E(T) range.,2001-11-01,https://www.semanticscholar.org/paper/c0614ca5dda80264184297b9e460f64496081220,Physical Review Letters
2504,A tablet computer application for patients to participate in their hospital care.,"Building on our institution's commercial electronic health record and custom personal health record Web portal, we developed a tablet computer application to provide interactive information to hospital patients. Using Apple iPad devices, the prototype application was provided to five patients in a cardiology step-down unit. We conducted detailed interviews to assess patients' knowledge of their inpatient care, as well as their perceptions of the usefulness of the application. While patients exhibited varying levels of comfort with using the tablet computer, they were highly enthusiastic about the application's ability to supply health information such as their inpatient medication histories and photographs of their care providers. Additional research is warranted to assess the benefit such applications may have for addressing inpatient information needs, enhancing patient-provider communication and improving patient satisfaction.",,https://www.semanticscholar.org/paper/13537ea0991b9b93963c71c99da9a4960220c059,AMIA ... Annual Symposium proceedings. AMIA Symposium
939,Topological Characterization of Families of Graphs Generated by Certain Types of Graph Grammars,,1979-07-01,https://www.semanticscholar.org/paper/658fd83c4c1aa045745284e09275629c7ec28d8b,Information and Control
815,Existence of Reduction Hierarchies,,1997-08-23,https://www.semanticscholar.org/paper/cc96794ae18da7d47a1290cf3975502e15b3e26f,Annual Conference for Computer Science Logic
52,Evaluation of top-k queries over structured and semi-structured data,"This thesis addresses fundamental issues in defining and efficiently processing top-k queries for a variety of scenarios, presenting different query processing challenges. In all these scenarios, our query processing algorithms attempt to focus on the objects that are most likely to be among the top-k matches for a given query, and discard---as early as possible---objects that are guaranteed not to qualify for the top- k answer, thus minimizing query processing time. 
One important top-k query scenario that we study is web applications where the data objects are only available through remote, autonomous web sources. During query processing, these sources have to be queried repeatedly for a potentially large set of candidate objects. Processing top-k queries efficiently in such a scenario is challenging, as web sources exhibit diverse probing costs and access interfaces, as well as constraints on the degree of concurrency that they support. By considering the peculiarities of the sources and potentially designing object-specific query execution plans, our adaptive algorithms efficiently prune non-top- k answers and produce significantly more efficient query executions than previously existing algorithms, which select ""global"" query execution plans and do not fully take advantage of source-access parallelism. 
As another contribution of this thesis, we extend our query processing algorithms to handle natural variations of the basic top-k query model. Specifically, we develop algorithms for queries that, in addition to fuzzy conditions, include some hard Boolean constraints (e.g., to allow the users to specify a more complex set of preferences). We also study extensions of our algorithms to handle scenarios where individual objects can be combined through joint operations. (Abstract shortened by UMI.)",,https://www.semanticscholar.org/paper/5a88c22a9312e5c50717569c6fe4a8e93bfc5cbb,
289,Logicomix: An Epic Search for Truth,"This brilliantly illustrated tale of reason, insanity, love and truth recounts the story of Bertrand Russell's life. Raised by his paternal grandparents, young Russell was never told the whereabouts of his parents. Driven by a desire for knowledge of his own history, he attempted to force the world to yield to his yearnings: for truth, clarity and resolve. As he grew older, and increasingly sophisticated as a philosopher and mathematician, Russell strove to create an objective language with which to describe the world - one free of the biases and slippages of the written word. At the same time, he began courting his first wife, teasing her with riddles and leaning on her during the darker days, when his quest was bogged down by paradoxes, frustrations and the ghosts of his family's secrets. Ultimately, he found considerable success - but his career was stalled when he was outmatched by an intellectual rival: his young, strident, brilliantly original student, Ludwig Wittgenstein. An insightful and complexly layered narrative, Logicomix reveals both Russell's inner struggle and the quest for the foundations of logic. Narration by an older, wiser Russell, as well as asides from the author himself, make sense of the story's heady and powerful ideas. At its heart, Logicomix is a story about the conflict between pure reason and the persistent flaws of reality, a narrative populated by great and august thinkers, young lovers, ghosts and insanity.",2008-10-20,https://www.semanticscholar.org/paper/5a67c71c2bba7dd1211f359ac8f10a14b6dd1fe8,
18,Effective Event Identification in Social Media,"Online social media sites are extensively used by individuals to produce and distribute content related to real-world events. Unfortunately, this social media content associated with an event is generally not provided in any structured and readily available form. Thus, identifying the event-related content on social media sites is a challenging task. Prior work has addressed the event identification task under two different scenarios, namely, when the events are known ahead of time, as is sometimes the case for planned events, and when the events are unknown, as is the case for spontaneous, unplanned events. In this article, we discuss both the unknown- and known-event identification scenarios, and attempt to characterize the key factors in the identification process, including the nature of social media content as well as the behavior and characteristics of event content over time. Furthermore, we propose enhancements to our earlier techniques that consider these factors and improve the state-of-the-art unknown-event identification strategies. Specifically, we propose novel features of the social media content that we can exploit, as well as the modeling of the typical time decay of event-related content. Large-scale experiments show that our approach exhibits improved effectiveness relative to the state-of-the-art approaches.",,https://www.semanticscholar.org/paper/957104cb5951987380e6263ddc498fca1f008798,IEEE Data Engineering Bulletin
2707,Proceedings of the conference on Virtual reality software and technology,,1994-08-26,https://www.semanticscholar.org/paper/5283f546532dc44d0ddd4c6f64c72edc6be5c8a8,
1763,The Stick-Breaking Construction of the Beta Process as a Poisson Process,"We show that the stick-breaking construction of the beta process due to Paisley, et al. (2010) can be obtained from the characterization of the beta process as a Poisson process. Specifically, we show that the mean measure of the underlying Poisson process is equal to that of the beta process. We use this underlying representation to derive error bounds on truncated beta processes that are tighter than those in the literature. We also develop a new MCMC inference algorithm for beta processes, based in part on our new Poisson process construction.",2011-09-02,https://www.semanticscholar.org/paper/2ac8aea06688995e14fc0b8a1bb19cbfc1d4f974,
3506,A new approach to the minimum cut problem,"This paper present a new approach to finding minimum cuts in undirected graphs. The fundamental principle is simple: the edges in a graph's minimum cut form an extremely small fraction of the graph's edges. Using this idea, we give a randomized, strongly polynomial algorithm that finds the minimum cut in an arbitrarily weighted undirected graph with high probability. The algorithm runs in <italic>O(n<supscrpt>2</supscrpt>log<supscrpt>3</supscrpt>n)</italic> time, a significant improvement over the previous <italic>O˜(mn)</italic> time bounds based on maximum flows. It is simple and intuitive and uses no complex data structures. Our algorithm can be parallelized to run in <italic>RNC</italic> with <italic>n<supscrpt>2</supscrpt></italic> processors; this gives the first proof   that the minimum cut problem can be solved in <italic>RNC</italic>. The algorithm does more than find a single minimum cut; it finds all of them.
With minor modifications, our algorithm solves two other problems of interest. Our algorithm finds all cuts with value within a multiplicative factor of α of the minimum cut's in expected <italic>O˜(n<supscrpt>2α</supscrpt>)</italic> time, or in <italic>RNC</italic> with <italic>n<supscrpt>2α</supscrpt></italic> processors. The problem of finding a minimum multiway cut of graph into <italic>r</italic> pieces is solved in expected <italic>O˜(n<supscrpt>2(r-1)</supscrpt>)</italic> time, or in <italic>RNC</italic> with <italic>n<supscrpt>2(r-1)</supscrpt></italic> processors. The “trace” of the    algorithm's execution on these two problems forms a new compact data structure for representing all small cuts and all multiway cuts in a graph. This data structure can be efficiently transformed into the more standard cactus representing for minimum cuts.",1996-07-01,https://www.semanticscholar.org/paper/9c4f25dc2739b8fff579264374e6ded0679958b5,JACM
2235,Neutrophil function in inflammation and inflammatory diseases.,"In inflammatory conditions such as RA, the neutrophil has tended to be dismissed as a short-lived, terminally differentiated, irrelevant bystander cell. However, this is clearly not the case. A better understanding of the complex heterogeneous pathways and processes that constitute RA, in parallel with a more sophisticated knowledge of neutrophil biology has identified many potential roles for these cells in the persistence of inflammation and progression of joint damage, which should not be underestimated. Not only are neutrophils found in high numbers within the rheumatoid joint, both in synovial tissue and in joint fluid, they have a huge potential to directly inflict damage to tissue, bone and cartilage via the secretion of proteases and toxic oxygen metabolites, as well as driving inflammation through antigen presentation and secretion of cytokines, chemokines, prostaglandins and leucotrienes. Drugs already used to treat RA down-regulate many neutrophil functions, including migration to the joint, degranulation and production of inflammatory mediators, and these cells should be considered as important targets for the development of new therapies in the future.",2010-09-01,https://www.semanticscholar.org/paper/f7a35e22338cbf7d4e37140df4ea26aba878eb62,Rheumatology
2603,My own private kiosk: privacy-preserving public displays,"Ubiquitous, high-resolution, large public displays offer an attractive complement to wearable displays. Unfortunately, the inherently public nature of these public displays makes them unsuitable for displaying sensitive information. We present EyeGuide, a wearable system that allows the user to obtain information quickly from a public display without sacrificing privacy. To this end, EyeGuide employs a lightweight head-worn eye-tracker for hands-free object selection and an earphone for private communication. Our system supports public displays that are dynamic (e.g., a large plasma screen) and static (e.g., a large printed map). In our printed map scenario, EyeGuide whispers verbal directions via earphone to a user, based on where they are looking on the map. Using a technique we call ""gaze steering,"" the system guides the user's eye position to specific locations. In our dynamic public display scenarios, EyeGuide presents documents (e.g., maps) that contain sensitive data in a way that preserves privacy.",2004-10-31,https://www.semanticscholar.org/paper/9b65c3f2aa4542e2d87c50f6e0d33e103697d33c,Eighth International Symposium on Wearable Computers
345,The Origins of the Deadline: Optimizing Communication in Organizations,,,https://www.semanticscholar.org/paper/8242a1b14e01c636b1afe24c70363d4bfa6bb886,
1911,Multi-objective demand fulfillment problem for solar cell industry,,2018-11-01,https://www.semanticscholar.org/paper/808dcbb9267f5c36eacc3d6caea84e5a5b2fdc66,Computers & industrial engineering
3482,Rounding algorithms for a geometric embedding of minimum multiway cut,"Given an undirected graph with edge costs and a subset of k ≥ 3 nodes called terminals, a multiway, or k-way, cut is a subset of the edges whose removal disconnects each terminal from the others. The multiway cut problem is to find a minimum-cost multiway cut. T his problem is Max-SNP hard. Recently Calinescu, Karloff, and Rabani (STOC’98) gave a novel geometric relaxation of the problem and a rounding scheme that produced a (3/2 − 1/k)-approximation algorithm. In this paper, we study their geometric relaxation. In parti cular, we study the worst-case ratio between the value of the relaxation and the value of the minimum multicut (the so-called integrality gap of the relaxation). For k = 3, we show the integrality gap is 12/11, giving tight upper and lower bounds. That is, we exhibit a family of graphs with integrality gaps arbit rarily close to 12/11 and give an algorithm that finds a cut of value 12/11 times the relaxation value. Our lower bound shows that this is the best",1999-05-01,https://www.semanticscholar.org/paper/1dee324b815b462f7f9715cbed197049a628e163,Symposium on the Theory of Computing
2576,Augmented Reality User Interfaces to an Electronic Field Guide,"We demonstrate a prototype mobile augmented reality user interface for automated identification of botanical species in the field, developed for the Columbia University, University of Maryland, and Smithsonian Institution Electronic Field Guide Project. Leaf images are captured with a head-worn digital video camera. A computer-vision component developed by our colleagues finds the best set of matching species, and our user interface presents the results as virtual representations along the side of a hand-held clipboard next to the physical leaf sample. A tangible card morphs into a given plant when placed over its representation. Virtual representations can be inspected and changed (e.g., from leaf image to full plant image) through gesture and movement through spatial zones. Samples are matched with existing species or marked unknown for further study. The system is being tested by botanists at the Smithsonian Institution. H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, augmented, and virtual realities; H.5.2 [Information Interfaces and Presentation]: User Interfaces—GUI; J.3 [Life and Medical Sciences]",,https://www.semanticscholar.org/paper/e62a9ab857f0e3137eb25ed2f0a1c1726b93ecd8,
2637,Guest editor's introduction special issue on mixed reality,"The term mixed reality (MR) was first used in the mid 1990s (Milgram & Kishino, 1994), after the popularization of virtual reality (VR). VR refers to the experience of users immersed in a virtual computer-created world. Thus, the world of VR exists within the computer. In contrast, MR attempts to correlate the virtual world with the real world. At one end of the spectrum of ways in which virtual and real worlds can be combined is augmented reality (AR), a term that was first used in the early 1990s (Caudell & Mizell, 1992). AR supplements the real world with information obtained from a virtual world; for example, a seethrough head-mounted display (HMD) may be used to superimpose a computer-generated image on the user’s view of the real world. Augmented virtuality (AV), in contrast, refers to augmenting a virtual world with information obtained from the real world. Using AV, a more realistic virtual world than that of VR can be realized; for example, complex shapes and actual images of naturally occurring objects can be incorporated into a virtual world. In 1997, Mixed Reality Systems Laboratory Inc. was inaugurated in Japan as the founding body for a four-year joint project between the Ministry of International Trade and Industry (MITI) and Canon Inc. Three universities, the University of Tokyo, Hokkaido University and the University of Tsukuba, joined the collaboration, and an MR research group comprising industry, government and academia was established. The editors of this special issue, Ohta and Hirose, are collaborative researchers involved in the project, and Feiner participated as an international advisor. As part of this project, the International Symposium on Mixed Reality (ISMR) was held twice, in 1999 and 2001, to encourage MR research worldwide. To compile this special issue, we selected some of the best papers presented at ISMR 2001, and asked their authors to submit revised versions for review. The following is a brief summary of the articles included in this special issue. Sawada and colleagues report on one of the core AR technologies: head tracking. Sawada’s group describes a hardware solution based on miniature high-precision gyroscopes. Hedley and colleagues and Walairacht and colleagues present studies of user interface devices for freely manipulating the AR environment. Lee and colleagues introduce a system that allows the user to model physical objects within AR. Mann and Fung describe an approach to obscure visually undesirable objects to create diminished reality. Ohta and colleagues, MacIntyre and colleagues, and Sakagawa and colleagues report on methods for fusing the real world and virtual worlds. Ohta’s group describes an augmented reality system that uses an interactively computed depth map of the real world. MacIntyre’s group reports on software for embedding 2D video actors in 3D augmented reality, while Sakagawa’s group presents hardware for incorporating 3D, real world, ray-space models into virtual reality. When MR was first introduced, it dealt with the fusion of real and virtual worlds, accomplished, in principle, with VR technology. However, as MR research has progressed, it has become clear that a broader perspective is required to better take into account the real world. In particular, this has meant that MR researchers have begun to address the real world beyond the laboratory, exploring mobile and wearable computing technology. The MR field is progressing rapidly, and we hope that this special issue helps convey its vitality. Finally, we express our sincere thanks to Prof. Hirota of the University of Tokyo, who handled the administration work for the submitted manuscripts. We also thank Dr. Tamura of MR Systems Laboratory, and the members of the ISMR Committee.",2002-04-01,https://www.semanticscholar.org/paper/d42d1aca6de8a3f91c18bfbd552d4e047e110f3a,
1515,Variational Inference with Gaussian Score Matching,"Variational inference (VI) is a method to approximate the computationally intractable posterior distributions that arise in Bayesian statistics. Typically, VI fits a simple parametric distribution to the target posterior by minimizing an appropriate objective such as the evidence lower bound (ELBO). In this work, we present a new approach to VI based on the principle of score matching, that if two distributions are equal then their score functions (i.e., gradients of the log density) are equal at every point on their support. With this, we develop score matching VI, an iterative algorithm that seeks to match the scores between the variational approximation and the exact posterior. At each iteration, score matching VI solves an inner optimization, one that minimally adjusts the current variational estimate to match the scores at a newly sampled value of the latent variables. We show that when the variational family is a Gaussian, this inner optimization enjoys a closed form solution, which we call Gaussian score matching VI (GSM-VI). GSM-VI is also a ``black box'' variational algorithm in that it only requires a differentiable joint distribution, and as such it can be applied to a wide class of models. We compare GSM-VI to black box variational inference (BBVI), which has similar requirements but instead optimizes the ELBO. We study how GSM-VI behaves as a function of the problem dimensionality, the condition number of the target covariance matrix (when the target is Gaussian), and the degree of mismatch between the approximating and exact posterior distribution. We also study GSM-VI on a collection of real-world Bayesian inference problems from the posteriorDB database of datasets and models. In all of our studies we find that GSM-VI is faster than BBVI, but without sacrificing accuracy. It requires 10-100x fewer gradient evaluations to obtain a comparable quality of approximation.",2023-07-15,https://www.semanticscholar.org/paper/4707587fc67fd590c0f8c767869bb7ba73f3e56e,arXiv.org
802,A convex relaxation for the asymmetric TSP,"1 The problem The Traveling Salesman Problem (TSP) has been widely studied. Given a graph with lengths on its edges, the problem is to find a tour of minimum length that visits every vertex once. One usually makes the assumption that the edge lengths satisfy the triangle inequality, in which case the problem is equivalent to requiring the tour to visit every vertex at least (instead of exactly) once. With the further assumption that the edge lengths are symmetric (in other words, the graph is undirected), it is well-known that the optimum can be approximated to within a factor of 3/2. Without the latter assumption, i.e., when the graph is directed, the best-known approximation is a factor of log n ,[l]. Unfortunately, this algorithm can be nearly logn off from the optimum even when the edge lengths are all 1, and the underlying graph is known to be Hamiltonian. Here we study a linear programming relaxation for the problem. Our main result is that one can find a fractional solution to the relaxation that is very sparse ( with < 3n edges). We also show that in the special case when the underlying graph is Hamiltonian with edge lengths 1 and the (inand out-) degrees of every vertex are each at most 2, a solution to the relaxation can be rounded to an integral solution (a tour) whose length is at most twice the optimum. Note that even this special case of the problem is NP-hard! (and the previous algorithm is 0( $$&) off).",,https://www.semanticscholar.org/paper/55fd55189f6caa9d764a5dfdf091be11e0892578,ACM-SIAM Symposium on Discrete Algorithms
2035,A fuzzy-knowledge resource-allocation model of the semiconductor final test industry,,2009-02-01,https://www.semanticscholar.org/paper/b551fb2a9fcd870055e4493ba890587777ff7a03,
2009,Measuring relative performance of wafer fabrication operations: a case study,,2011-06-01,https://www.semanticscholar.org/paper/076cc57437eb11c919af45b7dc3a4c68e25dfb0a,Journal of Intelligent Manufacturing
2104,A Study of Variance of Locational Price in a Deregulated Generation Market,,,https://www.semanticscholar.org/paper/2fd5d204eebba4dc65c23120ad1aa356937a61c9,
2247,"Soluble TNF-like cytokine (TL1A) production by immune complexes stimulated monocytes in rheumatoid arthritis (Journal of Immunology (2007) 178, (7325-7333))",,2007-07-15,https://www.semanticscholar.org/paper/b02009637941bdafb375cbcccc020dc41bbc1ba7,
1157,The Cryogenic Dark Matter Search (CDMS) : Present Status and Future,"The CDMS collaboration utilizes Ge detectors for their Weakly Interacting Massive Particle (WIMP) search at the Soudan mine, Minnesota. The final data run of CDMS II is complete and a detector upgrade for SuperCDMS has commenced. A SuperTower of five 1‐inch thick Ge crystals has been installed and undergoing commissioning. Its surface‐event rejection capability should allow SuperCDMS to continue to run background free for the next proposed phases: 15 kg Ge deployment at Soudan, and up to 150 kg Ge deployment at SNOLAB. Recent detector advances to allow a 1 tonne Ge experiment are also discussed.",2009-12-30,https://www.semanticscholar.org/paper/6f1a20f68f89e3a6f1f62822f64ec15a2669b44b,
3096,Measuring and managing the remote client perceived response time for web transactions using server-side techniques,"As businesses continue to grow their dependence on the World Wide Web, it is increasingly vital for them to accurately measure and manage response time of their Web services. This dissertation shows that it is possible to determine the remote client perceived response time for Web transactions using only server-side techniques and that doing so is useful and essential for the management of latency based service level agreements. 
First, we present Certes, a novel modeling algorithm, that accurately estimates connection establishment latencies as perceived by the remote clients, even in the presence of admission control drops. We present a non-linear optimization that models this effect and then we present an O(c) time and space online approximation algorithm. Second, we present ksniffer, an intelligent traffic monitor which accurately determines the pageview response times experienced by a remote client without any changes to existing systems or Web content. Novel algorithms for inferring the remote client perceived response time on a per pageview basis are presented which take into account network loss, RTT, and incomplete information. Third, we present Remote Latency-based Management (RLM), a system that controls the latencies experienced by the remote client by manipulating the packet traffic into and out of the Web server complex. RLM tracks the progress of each pageview download in real-time, as each embedded object is requested, making fine grained decisions on the processing of each request as it pertains to the overall pageview latency. RLM introduces fast SYN and SYN/ACID retransmission and embedded object rewrite and removal techniques to control the latency perceived by the remote client. 
We have implemented these mechanisms in Linux and demonstrated their effectiveness across a wide-range of realistic workloads. Our experimental results demonstrate for the first time that server-side response time measurements can be done in real-time at giga-bit traffic rates to within 5This is an order of magnitude better than common application-level techniques run at the Web server. Our results also demonstrate for the first time how both the mean and the shape of the per pageview client perceived response time distribution can be dynamically controlled at the server complex.",,https://www.semanticscholar.org/paper/3630c510be519563ba598c3ecbf6942954abcc72,
2860,"Galectin-3 Induces Death of Candida Species Expressing Specific β-1,2-Linked Mannans1","Lectins play a critical role in host protection against infection. The galectin family of lectins recognizes saccharide ligands on a variety of microbial pathogens, including viruses, bacteria, and parasites. Galectin-3, a galectin expressed by macrophages, dendritic cells, and epithelial cells, binds bacterial and parasitic pathogens including Leishmania major, Trypanosoma cruzi, and Neisseria gonorrhoeae. However, there have been no reports of galectins having direct effects on microbial viability. We found that galectin-3 bound only to Candida albicans species that bear β-1,2-linked oligomannans on the cell surface, but did not bind Saccharomyces cerevisiae that lacks β-1,2-linked oligomannans. Surprisingly, binding directly induced death of Candida species containing specific β-1,2-linked oligomannosides. Thus, galectin-3 can act as a pattern recognition receptor that recognizes a unique pathogen-specific oligosaccharide sequence. This is the first description of antimicrobial activity for a member of the galectin family of mammalian lectins; unlike other lectins of the innate immune system that promote opsonization and phagocytosis, galectin-3 has direct fungicidal activity against opportunistic fungal pathogens.",2006-10-01,https://www.semanticscholar.org/paper/f4d0dea0115146ad68f373ba78a4c2db6be2fb95,Journal of Immunology
2742,Editable graphical histories: the video,"INTRODUCTION Command histories are an important component of good user interfaces [3]. They allow users to review sequences of previously executed commands, and can provide an interface to an undo facility. Furthermore, they can support either a simple redo mechanism, or a more sophisticated macro-by-demonstration capability. Providing a visual representation of command histories in a graphical user interface presents a number of difficulties. Editable graphical histories [1, 2], a history representation that we have developed based on a comic-strip metaphor, overcomes many of these. Here we describe editable graphical histories, and in the accompanying videotape we demonstrate our test-bed implementation in the graphical editing mode of Chimera, a multi-modal editor.",1991-03-01,https://www.semanticscholar.org/paper/acf272f3f2d5f40cad6842f7f50f462e4c5ab94f,International Conference on Human Factors in Computing Systems
3741,Counterfactual Image Networks,"We capitalize on the natural compositional structure of images in order to learn object segmentation with weakly labeled images. The intuition behind our approach is that removing objects from images will yield natural images, however removing random patches will yield unnatural images. We leverage this signal to develop a generative model that decomposes an image into layers, and when all layers are combined, it reconstructs the input image. However, when a layer is removed, the model learns to produce a different image that still looks natural to an adversary, which is possible by removing objects. Experiments and visualizations suggest that this model automatically learns object segmentation on images labeled only by scene better than baselines.",2018-02-15,https://www.semanticscholar.org/paper/2c6442460c325f8267c75002d77a72035e36f14b,
1537,Hierarchical Inducing Point Gaussian Process for Inter-domain Observations,"We examine the general problem of inter-domain Gaussian Processes (GPs): problems where the GP realization and the noisy observations of that realization lie on different domains. When the mapping between those domains is linear, such as integration or differentiation, inference is still closed form. However, many of the scaling and approximation techniques that our community has developed do not apply to this setting. In this work, we introduce the hierarchical inducing point GP (HIP-GP), a scalable inter-domain GP inference method that enables us to improve the approximation accuracy by increasing the number of inducing points to the millions. HIP-GP, which relies on inducing points with grid structure and a stationary kernel assumption, is suitable for low-dimensional problems. In developing HIP-GP, we introduce (1) a fast whitening strategy, and (2) a novel preconditioner for conjugate gradients which can be helpful in general GP settings. Our code is available at https: //github.com/cunningham-lab/hipgp.",2021-02-28,https://www.semanticscholar.org/paper/1006312979506add9e3e1dadd012b0fb858ca40d,International Conference on Artificial Intelligence and Statistics
3564,Programming language evolution and source code rejuvenation,"Programmers rely on programming idioms, design patterns, and workaround techniques to express fundamental design not directly supported by the language. Evolving languages often address frequently encountered problems by adding language and library support to subsequent releases. By using new features, programmers can express their intent more directly. As new concerns, such as parallelism or security, arise, early idioms and language facilities can become serious liabilities. Modern code sometimes benefits from optimization techniques not feasible for code that uses less expressive constructs. Manual source code migration is expensive, time-consuming, and prone to errors. 
This dissertation discusses the introduction of new language features and libraries, exemplified by open-methods and a non-blocking growable array library. We describe the relationship of open-methods to various alternative implementation techniques. The benefits of open-methods materialize in simpler code, better performance, and similar memory footprint when compared to using alternative implementation techniques. 
Based on these findings, we develop the notion of source code rejuvenation, the automated migration of legacy code. Source code rejuvenation leverages enhanced program language and library facilities by finding and replacing coding patterns that can be expressed through higher-level software abstractions. Raising the level of abstraction improves code quality by lowering software entropy. In conjunction with extensions to programming languages, source code rejuvenation offers an evolutionary trajectory towards more reliable, more secure, and better performing code. 
We describe the tools that allow us efficient implementations of code rejuvenations. The Pivot source-to-source translation infrastructure and its traversal mechanism forms the core of our machinery. In order to free programmers from representation details, we use a light-weight pattern matching generator that turns a C++ like input language into pattern matching code. The generated code integrates seamlessly with the rest of the analysis framework. 
We utilize the framework to build analysis systems that find common workaround techniques for designated language extensions of C++0x (e.g., initializer lists). Moreover, we describe a novel system (TACE — template analysis and concept extraction) for the analysis of uninstantiated template code. Our tool automatically extracts requirements from the body of template functions. TACE helps programmers understand the requirements that their code de facto imposes on arguments and compare those de facto requirements to formal and informal specifications.",,https://www.semanticscholar.org/paper/b629f7dbe4cb3fae101fb4a878177f23479bb7e3,
3725,Globetrotter: Connecting Languages by Connecting Images,"Machine translation between many languages at once is highly challenging, since training with ground truth re-quires supervision between all language pairs, which is dif-ficult to obtain. Our key insight is that, while languages may vary drastically, the underlying visual appearance of the world remains consistent. We introduce a method that uses visual observations to bridge the gap between languages, rather than relying on parallel corpora or topo-logical properties of the representations. We train a model that aligns segments of text from different languages if and only if the images associated with them are similar and each image in turn is well-aligned with its textual description. We train our model from scratch on a new dataset of text in over fifty languages with accompanying images. Experiments show that our method outperforms previous work on unsupervised word and sentence translation using retrieval. Code, models and data are available on globetrotter.cs.columbia.edu",2020-12-08,https://www.semanticscholar.org/paper/ec19b41534219677864c473a379067d18b3c0908,Computer Vision and Pattern Recognition
2195,Wolbachia endosymbionts induce neutrophil extracellular trap formation in human onchocerciasis,,2016-10-18,https://www.semanticscholar.org/paper/9cee1f7d2ff2c942392bcb854d481ecde2266974,Scientific Reports
2506,Enabling large-scale outdoor Mixed Reality and Augmented Reality,"While there is significant recent progress in technologies supporting augmented reality for small indoor environments, there is still much work to be done for large outdoor environments. This workshop focuses primarily on research that enables high-quality outdoor Mixed Reality (MR) and Augmented Reality (AR) applications. These research topics include, but are not restricted to: — 3D geo-referenced data (images, point clouds, and models) — Algorithms for object recognition from large databases of geo-referenced data — Algorithms for object tracking in outdoor environment — Multi-cue fusion to achieve improved performance of object detection and tracking — Novel representation schemes to facilitate large-scale content distribution — 3D reasoning to support intelligent augmentation — Novel and improved mobile capabilities for data capture (device sensors), processing, and display — Applications, experiences, and user interface techniques. The workshop will also showcase existing prototypes of applications enabled by these technologies: mirror worlds, high-fidelity virtual environments, applications of panoramic imagery, and user studies relating to these media types. This workshop aims to bring together academic and industrial researchers and to foster discussion amongst participants on the current state of the art and future directions for technologies that enable large-scale outdoor MR and AR applications. The workshop will start with a session in which position statements and overviews of the state of the art are presented. In the afternoon, we will follow up with discussion sessions and a short closing session.",2011-10-26,https://www.semanticscholar.org/paper/458898fc29d3c57d62c98de5218947a66326a57d,"2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities"
442,Complexity aspects of knowledge representation,"The ultimate goal of Artificial Intelligence (to come up with a machine that is able to reason as humans do) is still a long term one; developing schemes for knowledge representation and common-sense reasoning are important and widely accepted tactical goals. This thesis is about the application of the methods of the theory of computational complexity in order to choose among the possible approaches towards an effective mathematical model of common sense. 
We develop a methodology for comparing knowledge representation formalisms in terms of their ""representational succinctness,"" and use this framework for comparing many important formalisms for knowledge representation. We also show that adding new variables improves the effective expressibility of certain knowledge representation formalisms. 
Approximating a general formula from above and below by Horn formulas was proposed by Kautz and Selman as a form of ""knowledge compilation,"" supporting rapid approximate reasoning; as we point out, this scheme is static in that it supports no updates, and has certain complexity drawbacks. In our work we propose a new, very efficient scheme, incremental recompilation, which combines Horn approximation and model-based updates. 
Finally, we look closer at two knowledge representation formalisms that have the same expressive power--Horn formulas and characteristic model--and try to tell which one is better to use for representing knowledge in various contexts.",,https://www.semanticscholar.org/paper/036014e0edb5e1ea2f086940d569f3eab086660b,
1319,First CDMS II WIMP Search Results from the Soudan Underground Laboratory,,,https://www.semanticscholar.org/paper/6b850ede3a09f1eb81530f490035c28cd1777e8a,
1062,Measurement of the CP-violation parameter of B0 mixing and decay with ppÌ– âƒTM Î1⁄4Î1⁄4X data,,,https://www.semanticscholar.org/paper/b5b37664b4a839bd1593c478d77e8225e7e2b076,
1301,Search for particles decaying into a Z boson and a photon in p ¯ p collisions at √ s = 1 . 96 TeV,"We present the results of a search for a new particle X produced in p ¯ p collisions at √ s = 1 . 96 TeV and subsequently decaying to Zγ . The search uses 0.3 fb − 1 of data collected with the DØ detector at the Fermilab Tevatron Collider. We set limits on the production cross section times the branching fraction σ(p ¯ p → X) × B(X → Zγ) that range from 0.4 to 3.5 pb at the 95% C.L. for X with invariant masses between 100 and 1000 GeV /c 2 , over a wide range of X decay widths. ©",,https://www.semanticscholar.org/paper/09c10795c076c6cd1993f84fdd20f051dfe2c2b7,
865,High-Probability Parallel Transitive-Closure Algorithms,"There is a straightforward algorithm for computing the transitive-closure of an n-node graph in $O(\log ^2 n)$ time on an EREW-PRAM, using $n^3 / \log n$ processors, or indeed with $M(n) / \log n$ processors if serial matrix multiplication in $M(n)$ time can be done. This algorithm is within a log factor of optimal in work (processor-time product), for solving the all-pairs transitive-closure problem for dense graphs. However, this algorithm is far from optimal when either (a) the graph is sparse, or (b) we want to solve the single-source transitive-closure problem. It would be ideal to have an $\mathcal{NC}$ algorithm for transitive-closure that took about e processors for the single-source problem on a graph with n nodes and $e \geqq n$ arcs, or about $en$ processors for the all-pairs problem on the same graph. While an algorithm that good cannot be offered, algorithms with the following performance can be offered. (1) For single-source, $\tilde{O}(n^\varepsilon )$ time with $\tilde O(en^{1 - 2\varepsil...",1991-02-01,https://www.semanticscholar.org/paper/db9d3796a8b0543c442127f164efd193ef3853fb,SIAM journal on computing (Print)
3223,"Citizen Science in Schools: Students Collect Valuable Mammal Data for Science, Conservation, and Community Engagement","Citizen science has been touted as an effective means to collect large-scale data while engaging the public. We demonstrate that children as young as 9 years old can collect valuable mammal monitoring data using camera traps while connecting with nature and learning through their own scientific discoveries. Indian, Kenyan, Mexican, and American students used camera traps near their schools and detected 13–37 species, all of which were verified by professionals. These data describe rich mammal faunas near schools, sometimes surpassing nearby protected areas, and included five endangered species. Ninety-four percent of the camera traps were set in accordance with scientific protocols, and the teachers reported the experience as highly engaging for their students. Furthermore, the generated photos and results had community-wide impacts involving local politicians, community members, and the media. We show that children can run sensors to contribute valid scientific data important for conservation and research.",2018-12-12,https://www.semanticscholar.org/paper/35c7d3265161ac30cb359d0ca243b66593656544,BioScience
1620,Appendix to Variational Inference: A Review for Statisticians,"One of the core problems of modern statistics is to approximate diﬃcult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference ( vi ), a method from machine learning that ap-proximates probability densities through optimization. vi has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind vi is to ﬁrst posit a family of densities and then to ﬁnd the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-ﬁeld variational inference, discuss the special case of vi applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in vi and highlight important open problems. vi is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.",,https://www.semanticscholar.org/paper/1e4e25d69d599f7b8ac010ddf57692b51950a132,
11,k-Shape: Efficient and Accurate Clustering of Time Series,"The proliferation and ubiquity of temporal data across many disciplines has generated substantial interest in the analysis and mining of time series. Clustering is one of the most popular data mining methods, not only due to its exploratory power, but also as a preprocessing step or subroutine for other techniques. In this paper, we describe k-Shape, a novel algorithm for time-series clustering. k-Shape relies on a scalable iterative refinement procedure, which creates homogeneous and well-separated clusters. As its distance measure, k-Shape uses a normalized version of the cross-correlation measure in order to consider the shapes of time series while comparing them. Based on the properties of that distance measure, we develop a method to compute cluster centroids, which are used in every iteration to update the assignment of time series to clusters. An extensive experimental evaluation against partitional, hierarchical, and spectral clustering methods, with the most competitive distance measures, showed the robustness of k-Shape. Overall, k-Shape emerges as a domain-independent, highly accurate, and efficient clustering approach for time series with broad applications.",,https://www.semanticscholar.org/paper/229f87832bc93cc4a4ba9a228e33135799dcf4bf,SGMD
3086,Transparent Checkpoint-Restart of Multiple Processes on Commodity Operating Systems,"The ability to checkpoint a running application and restart it later can provide many useful benefits including fault recovery, advanced resources sharing, dynamic load balancing and improved service availability. However, applications often involve multiple processes which have dependencies through the operating system. We present a transparent mechanism for commodity operating systems that can checkpoint multiple processes in a consistent state so that they can be restarted correctly at a later time. We introduce an efficient algorithm for recording process relationships and correctly saving and restoring shared state in a manner that leverages existing operating system kernel functionality. We have implemented our system as a loadable kernel module and user-space utilities in Linux. We demonstrate its ability on real-world applications to provide transparent checkpoint-restart functionality without modifying, recompiling, or relinking applications, libraries, or the operating system kernel. Our results show checkpoint and restart times 3 to 55 times faster than OpenVZ and 5 to 1100 times faster than Xen.",2007-06-17,https://www.semanticscholar.org/paper/3ec5430347717ff2f02f435cdcf951f35cd1479a,USENIX Annual Technical Conference
2238,Neutrophil TLR4 expression is reduced in the airways of infants with severe bronchiolitis,"Background: In respiratory syncytial virus (RSV) bronchiolitis, neutrophils account for >80% of cells recovered from the airways in bronchoalveolar lavage (BAL) fluid. This study investigated neutrophil activation and Toll-like receptor (TLR) expression in the blood and lungs of infants with severe RSV bronchiolitis. Methods: BAL fluid and (blood) samples were collected from 24 (16) preterm and 23 (15) term infants ventilated with RSV bronchiolitis, and 12 (8) control infants. Protein levels and mRNA expression of CD11b, myeloperoxidase (MPO) and TLRs 2, 4, 7, 8 and 9 were measured in neutrophils. Results: Blood neutrophils had more CD11b in preterm and term infants with RSV bronchiolitis than control infants (p<0.025) but similar amounts of MPO. BAL fluid neutrophils from infants with RSV bronchiolitis had greater amounts of CD11b and MPO than blood neutrophils and BAL fluid neutrophils from controls (p<0.01). Blood neutrophils from term infants with RSV bronchiolitis had less total TLR4 protein than preterm infants with RSV bronchiolitis (p = 0.005), and both had less than controls (p<0.04). Total TLR4 for each group was greater in BAL fluid neutrophils than in blood neutrophils. Blood neutrophils from preterm infants with RSV bronchiolitis had greater TLR4 mRNA expression than term infants with RSV bronchiolitis (p = 0.005) who had similar expression to controls (p = 0.625). Conclusions: In infants with severe RSV bronchiolitis, neutrophil activation starts in the blood and progresses as they are recruited into the airways. Total neutrophil TLR4 remains low in both compartments. TLR4 mRNA expression is unimpaired. This suggests that neutrophil TLR4 expression is deficient in these infants, which may explain why they develop severe RSV bronchiolitis.",2009-06-03,https://www.semanticscholar.org/paper/eadc04f5e385bf86f84e175b7662bddad9eef0e7,Thorax
3349,Toward a Realistic Sociobiology.,,,https://www.semanticscholar.org/paper/439912044bdf31e5d959f0d786ae19744742c76c,
3393,"MapReduce Meets Fine-Grained Complexity: MapReduce Algorithms for APSP, Matrix Multiplication, 3-SUM, and Beyond","Distributed processing frameworks, such as MapReduce, Hadoop, and Spark are popular systems for processing large amounts of data. The design of efficient algorithms in these frameworks is a challenging problem, as the systems both require parallelism---since datasets are so large that multiple machines are necessary---and limit the degree of parallelism---since the number of machines grows sublinearly in the size of the data. Although MapReduce is over a dozen years old~\cite{dean2008mapreduce}, many fundamental problems, such as Matrix Multiplication, 3-SUM, and All Pairs Shortest Paths, 
lack efficient MapReduce algorithms. We study these problems in the MapReduce setting. Our main contribution is to exhibit smooth trade-offs between the memory available on each machine, and the total number of machines necessary for each problem. Overall, we take the memory available to each machine as a parameter, and aim to minimize the number of rounds and number of machines. 
In this paper, we build on the well-known MapReduce theoretical framework initiated by Karloff, Suri, and Vassilvitskii ~\cite{karloff2010model} and give algorithms for many of these problems. The key to efficient algorithms in this setting lies in defining a sublinear number of large (polynomially sized) subproblems, that can then be solved in parallel. We give strategies for MapReduce-friendly partitioning, that result in new algorithms for all of the above problems. Specifically, we give constant round algorithms for the Orthogonal Vector (OV) and 3-SUM problems, and $O(\log n)$-round algorithms for Matrix Multiplication, All Pairs Shortest Paths (APSP), and Fast Fourier Transform (FFT), among others. In all of these we exhibit trade-offs between the number of machines and memory per machine.",2019-05-05,https://www.semanticscholar.org/paper/eae59abe363694d4b1797d07463cfa7c03cc8cc1,arXiv.org
1806,Modeling Influence in Text Corpora,"Identifying the most influential documents in a corpus is an important problem in a wide range of fields, ranging from information science and historiography to text summarization and news aggregation. We propose using changes in the linguistic content of these documents over time to predict the importance of individual documents within the collection and describe a dynamic topic model for both quantifying and qualifying the impact of each document in the corpus. Introduction In many fields, identifying the most influential documents is an important challenge; researchers in information science, historiography, text summarization, and news aggregation, for example, are all interested in identifying influential documents in their respective fields. Researchers in fields like these often use traditional methods of assessing the impact of an article such as analyzing the citations to it: the impact factor of a journal, for example, is based largely on academic citation analysis; and Google’s successful PageRank algorithm is based on hyperlink citations between Webpages [1]. Often, however, citation information is not present: certain legal documents, news stories, blog posts, and email, for example, all might lack such citation metadata, while there is a clear notion of influence among articles in these collections. The goal of this work is to develop an unsupervised method for determining the influence of a document in the absense of citations. Our intuition is that language changes over time, and that influential documents contribute to this change. We formalize this intuition and present an algorithm which takes a sequence of documents as input and computes a vector of ”influence” for each document. This vector characterizes the document’s influence in terms of themes discovered using a topic model we have developed. We validate this method by measuring how well the computed impact predicts citations and demonstrate that this method provides a citation-free measure of bibliometric impact. The Document Influence Model We base our model, the Document Influence Model (DIM), on the the Dynamic Topic Model (DTM) [2]. The DTM models corpora by assuming that documents are mixtures of themes; it models these themes, in turn, by allowing them to change over time. The concept of a theme in the DTM is formalized as a topic using Latent Dirichlet Allocation (LDA) [3]. Figure 1: The Document Influence Model. We extend the DTM by associating each document dt with a vector of topic weights ldt ,k (see Figure 1). These weights express how much the language used in document dt affects the drift of these topics over a period of time. The more influential a document is in a topic k, the larger its topic weights should be, making it more likely that future documents about topic k will use the same language. The influence of a document on each topic k works as follows. We assume that document dt at time t may have some influence on the language used within each topic. The more influential dt is on topic k (i.e., the higher its weight for this topic)–and the more its words are ”about” topic k in the first place–the more it “nudges” this topic’s natural parameters βt,k in log space. In LDA, and hence the DIM, the topic assignment for word n is given by the random variable zn; its role is clarified below the generative model. The full generative model at time t is then: 1. For topic k = 1, . . . ,K: Draw natural parameters βt,k|βt−1,k,zs",,https://www.semanticscholar.org/paper/9dc9f0551b9dcb5837b75a8286fc0d8121d0de7a,
3590,Report on language support for Multi-Methods and Open-Methods for C++,"Multiple dispatch – the selection of a function to be invoked based on the dynamic type of two or more arguments – is a solution to several classical problems in object-oriented programm ing. We present the rationale, design, and implementation of a lang u ge feature, called open multi-methods, for C ++. Open multi-methods support both repeated and virtual inheritance and our call reso lution rules generalize both virtual function dispatch and overlo ad resolution semantics. After using all information from argumen t types, these rules can resolve further ambiguities by using covari ant return types. We describe a model implementation and compare i ts performance and space requirements to existing open multiethod extensions and workaround techniques for C ++. Compared to these techniques, our approach is simpler to use, catches more use mi takes (such as ambiguities), performs significantly better , and requires less memory. For example, our implementation of a mul timethod call is constant-time and more than twice as fast as do uble dispatch only 4% slower than a C ++ virtual function call. Finally, we provide a sketch of a design for open multi-methods in the p resence of dynamic loading and linking of libraries.",,https://www.semanticscholar.org/paper/87190aec6a1befeac0d2b1d2dc9555e1235919df,
1210,05 07 19 0 v 1 8 J ul 2 00 5 Exclusion Limits on the WIMP-Nucleon Cross-Section from the First Run of the Cryogenic Dark Matter Search in the Soudan Underground Lab,"D.S. Akerib, M.S. Armel-Funkhouser, M.J. Attisha, C.N. Bailey, L. Baudis, D.A. Bauer, P.L. Brink, R. Bunker, B. Cabrera, D.O. Caldwell, C.L. Chang, M.B. Crisler, P. Cushman, M. Daal, R. Dixon, M.R. Dragowsky, D.D. Driscoll, L. Duong, R. Ferril, J. Filippini, R.J. Gaitskell, R. Hennings-Yeomans, D. Holmgren, M.E. Huber, S. Kamat, A. Lu, R. Mahapatra, V. Mandic, J.M. Martinis, P. Meunier, N. Mirabolfathi, H. Nelson, R. Nelson, R.W. Ogburn, T.A. Perera, M.C. Perillo Issac, E. Ramberg, W. Rau, A. Reisetter, R.R. Ross, 11, ∗ T. Saab, B. Sadoulet, 11 J. Sander, C. Savage, R.W. Schnee, D.N. Seitz, B. Serfass, K.M. Sundqvist, J-P.F. Thompson, G. Wang, S. Yellin, 7 and B.A. Young (CDMS Collaboration) Department of Physics, Case Western Reserve University, Cleveland, OH 44106, USA Department of Physics, University of California, Berkeley, CA 94720, USA Department of Physics, Brown University, Providence, RI 02912, USA Department of Physics, University of Florida, Gainesville, FL 32611, USA Fermi National Accelerator Laboratory, Batavia, IL 60510, USA Department of Physics, Stanford University, Stanford, CA 94305, USA Department of Physics, University of California, Santa Barbara, CA 93106, USA School of Physics & Astronomy, University of Minnesota, Minneapolis, MN 55455, USA Department of Physics, University of Colorado at Denver and Health Sciences Center, Denver, CO 80217, USA National Institute of Standards and Technology, Boulder, CO 80303, USA Lawrence Berkeley National Laboratory, Berkeley, CA 94720, USA Department of Physics, Santa Clara University, Santa Clara, CA 95053, USA (Dated: February 5, 2008)",,https://www.semanticscholar.org/paper/40177757a4f5ad86c3ceb352e3847b3c40e8523e,
2940,Inferring Relevant Cell Types for Complex Traits by Using Single-Cell Gene Expression.,,2017-11-02,https://www.semanticscholar.org/paper/368fce9778dd4680a025b4551e7c137794bf5194,American Journal of Human Genetics
3399,Scheduling When You Don't Know the Number of Machines,"Often in a scheduling problem, there is uncertainty about the jobs to be processed. The issue of uncertainty regarding the machines has been much less studied. In this paper, we study a scheduling environment in which jobs first need to be grouped into some sets before the number of machines is known, and then the sets need to be scheduled on machines without being separated. In order to evaluate algorithms in such an environment, we introduce the idea of an α-robust algorithm, one which is guaranteed to return a schedule on any number m of machines that is within an α factor of the optimal schedule on m machine, where the optimum is not subject to the restriction that the sets cannot be separated. Under such environment, we give a [EQUATION]-robust algorithm for scheduling on parallel machines to minimize makespan, and show a lower bound [EQUATION]. For the special case when the jobs are infinitesimal, we give a 1.233-robust algorithm with an asymptotic lower bound of 1.207. We also study a case of fair allocation, where the objective is to minimize the difference between the maximum and minimum machine load.",2018-01-07,https://www.semanticscholar.org/paper/9f61d2ed6d80685f12e0909a175b5bb8cea54ae9,ACM-SIAM Symposium on Discrete Algorithms
1562,Causal Inference for Recommender Systems,"The task of recommender systems is classically framed as a prediction of users’ preferences and users’ ratings. However, its spirit is to answer a counterfactual question: “What would the rating be if we ‘forced’ the user to watch the movie?” This is a question about an intervention, that is a causal inference question. The key challenge of this causal inference is unobserved confounders, variables that affect both which items the users decide to interact with and how they rate them. To this end, we develop an algorithm that leverages classical recommendation models for causal recommendation. Across simulated and real datasets, we demonstrate that the proposed algorithm is more robust to unobserved confounders and improves recommendation.",2020-09-22,https://www.semanticscholar.org/paper/ca94b305307b8df8997fc14ffaf90fa96623cc1e,ACM Conference on Recommender Systems
3635,Foundations for native C++ styles,"Over the past decade, C++ has become the most commonly used language for introducing object‐oriented programming and other abstraction techniques into production software. During this period, C++ has evolved to meet the challenges of production systems. In this, C++ differs radically from languages that come primarily from academic or research environments, and from less widely used languages. Although C++ has also been extensively used in academia and for research, its evolution was driven primarily by feedback from its use in industrial applications.",1995-12-01,https://www.semanticscholar.org/paper/6df7bdb60f18b033930a69f934174d28e42de301,"Software, Practice & Experience"
97,An investigation of linguistic features and clustering algorithms for topical document clustering,"We investigate four hierarchical clustering methods (single-link, complete-link, groupwise-average, and single-pass) and two linguistically motivated text features (noun phrase heads and proper names) in the context of document clustering. A statistical model for combining similarity information from multiple sources is described and applied to DARPA's Topic Detection and Tracking phase 2 (TDT2) data. This model, based on log-linear regression, alleviates the need for extensive search in order to determine optimal weights for combining input features. Through an extensive series of experiments with more than 40,000 documents from multiple news sources and modalities, we establish that both the choice of clustering algorithm and the introduction of the additional features have an impact on clustering performance. We apply our optimal combination of features to the TDT2 test data, obtaining partitions of the documents that compare favorably with the results obtained by participants in the official TDT2 competition.",2000-07-01,https://www.semanticscholar.org/paper/36609db38881b34a896f0cca58f9942f451e4815,Annual International ACM SIGIR Conference on Research and Development in Information Retrieval
615,Local Search for the Asymmetric Traveling Salesman Problem,We present an extension of the Lin-Kernighan local search algorithm for the solution of the asymmetric traveling salesman problem. Computational results suggest that our heuristic is feasible for fairly large instances. We also present some theoretical results which guided our design of the heuristic.,1980-10-01,https://www.semanticscholar.org/paper/315b95c957a5e13d33e743b5f86a6ee996635af3,Operational Research
3135,Mobile Communication with Virtual Network Address Translation,"Virtual Network Address Translation (VNAT) is a novel architecture that allows transparent migration of end-to-end live network connections associated with various computation units. Such computation units can be either a single process, or a group of processes, or an entire host. VNAT virtualizes network connections perceived by transport protocols so that identification of network connections is decoupled from stationary hosts. Such virtual connections are then remapped into physical connections to be carried on the physical network using network address translation. VNAT requires no modification to existing applications, operating systems, or protocol stacks. Furthermore, it is fully compatible with the existing communication infrastructure; virtual and normal connections can coexist without interfering each other. VNAT functions entirely within end systems and requires no third party services. We have implemented a VNAT prototype with the Linux 2.4 kernel and demonstrated its functionality on a wide range of popular real-world network applications. Our performance results show that VNAT has essentially no network performance overhead except when connections are migrated, in which case the overhead of our Linux prototype is less than 7 percent over a stock RedHat Linux system.",,https://www.semanticscholar.org/paper/1fd752f08584b38b3f2b9957ad973add4f7c17d4,
3675,Runtime Concepts for the C++ Standard Template Library,"A key benefit of generic programming is its support for producing modules with clean separation. In particular, generic algorithms are written to work with a wide variety of unmodified types. The Runtime concept idiom extends this support by allowing unmodified concrete types to behave in a runtime polymorphic manner. In this paper, we describe one implementation of the runtime concept idiom, in the domain of the C++ standard template library (STL). We describe and measure the performance of runtime-polymorphic analogs of several STL algorithms. We augment the runtime concept idiom by employing a dispatch mechanism that considers both type and concept information to maximize performance when selecting algorithm implementations. We use our implementation to demonstrate the effects of different compile-time vs. run-time algorithm selection choices, and we indicate where improved language and compiler support would be useful.",,https://www.semanticscholar.org/paper/4e148ab99b46d8a2177864c817ceeaa8217cfcc5,
3264,Water Use Patterns of Sympatric Przewalski’s Horse and Khulan: Interspecific Comparison Reveals Niche Differences,"Acquiring water is essential for all animals, but doing so is most challenging for desert-living animals. Recently Przewalski’s horse has been reintroduced to the desert area in China where the last wild surviving member of the species was seen before it vanished from China in the1960s. Its reintroduction placed it within the range of a close evolutionary relative, the con-generic Khulan. Determining whether or not these two species experience competition and whether or not such competition was responsible for the extinction of Przewalski’s horses in the wild over 50 years ago, requires identifying the fundamental and realized niches of both species. We remotely monitored the presence of both species at a variety of water points during the dry season in Kalamaili Nature Reserve, Xinjiang, China. Przewalski’s horses drank twice per day mostly during daylight hours at low salinity water sources while Khulans drank mostly at night usually at high salinity water points or those far from human residences. Spatial and temporal differences in water use enables coexistence, but suggest that Przewalski’s horses also restrict the actions of Khulan. Such differences in both the fundamental and realized niches were associated with differences in physiological tolerances for saline water and human activity as well as differences in aggression and dominance.",2015-07-10,https://www.semanticscholar.org/paper/f59f18091bcd9b1ede379b90d1cfadcd44aaf07c,PLoS ONE
1840,Dynamic topic models,"A family of probabilistic time series models is developed to analyze the time evolution of topics in large document collections. The approach is to use state space models on the natural parameters of the multinomial distributions that represent the topics. Variational approximations based on Kalman filters and nonparametric wavelet regression are developed to carry out approximate posterior inference over the latent topics. In addition to giving quantitative, predictive models of a sequential corpus, dynamic topic models provide a qualitative window into the contents of a large document collection. The models are demonstrated by analyzing the OCR'ed archives of the journal Science from 1880 through 2000.",2006-06-25,https://www.semanticscholar.org/paper/2dd53efa74850c6b60bc7bb0dcfca049a4a71474,International Conference on Machine Learning
755,Small Approximate Pareto Sets for Bi-objective Shortest Paths and Other Problems,,2007-08-20,https://www.semanticscholar.org/paper/151681cb721d1fffaacc852d7760a82bff40f088,"International Workshop and International Workshop on Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques"
3110,Breaking the Ties That Bind: Application Isolation and Migration,,,https://www.semanticscholar.org/paper/c66d9503817cacab0238d71b73adacb17f9d82bd,Login: The Usenix Magazine
2071,A novel timetabling algorithm for a furnace process for semiconductor fabrication with constrained waiting and frequency-based setups,,2007-05-23,https://www.semanticscholar.org/paper/99c24785b64c6e94ee4fb8f89fb3b11662cb862a,OR Spectr.
2910,Faithful Heteroscedastic Regression with Neural Networks,"Heteroscedastic regression models a Gaussian variable's mean and variance as a function of covariates. Parametric methods that employ neural networks for these parameter maps can capture complex relationships in the data. Yet, optimizing network parameters via log likelihood gradients can yield suboptimal mean and uncalibrated variance estimates. Current solutions side-step this optimization problem with surrogate objectives or Bayesian treatments. Instead, we make two simple modifications to optimization. Notably, their combination produces a heteroscedastic model with mean estimates that are provably as accurate as those from its homoscedastic counterpart (i.e.~fitting the mean under squared error loss). For a wide variety of network and task complexities, we find that mean estimates from existing heteroscedastic solutions can be significantly less accurate than those from an equivalently expressive mean-only model. Our approach provably retains the accuracy of an equally flexible mean-only model while also offering best-in-class variance calibration. Lastly, we show how to leverage our method to recover the underlying heteroscedastic noise variance.",2022-12-18,https://www.semanticscholar.org/paper/934ef7a5f1e876ceb4bcbf5c59cbacd7e12e4733,International Conference on Artificial Intelligence and Statistics
2999,"DuoAI: Fast, Automated Inference of Inductive Invariants for Verifying Distributed Protocols","Distributed systems are complex and difficult to build correctly. Formal verification can provably rule out bugs in such systems, but finding an inductive invariant that implies the safety property of the system is often the hardest part of the proof. We present DuoAI, an automated system that quickly finds inductive invariants for verifying distributed protocols by reducing SMT query costs in checking invariants with existential quantifiers. DuoAI enumerates the strongest candidate invariants that hold on validate states from protocol simulations, then applies two methods in parallel, returning the result from the method that succeeds first. One checks all candidate invariants and weakens them as needed until it finds an inductive invariant that implies the safety property. Another checks invariants without existential quantifiers to find an inductive invariant without the safety property, then adds candidate invariants with existential quantifiers to strengthen it until the safety property holds. Both methods are guaranteed to find an inductive invariant that proves desired safety properties, if one exists, but the first reduces SMT query costs when more candidate invariants with existential quantifiers are needed, while the second reduces SMT query costs when few candidate invariants with existential quantifiers suffice. We show that DuoAI verifies more than two dozen common distributed protocols automatically, including various versions of Paxos, and outperforms alternative methods both in the number of protocols it verifies and the speed at which it does so,including solving Paxos more than two orders of magnitude faster than previous methods. which is difficult to do without first knowing the ground-truth invariants. The 4 protocols have much simpler inductive invariants when expressed on top of these clauses, with all except the simplest, client server db ae, becoming ∃ -free. Ivy fails when checking the invariants generated by IC3PO for Paxos and flexible Paxos. The IC3PO authors [9] imply that the invariants had to be manually checked against the human-expert invariants.",,https://www.semanticscholar.org/paper/23d2ce87033bbeaddcfbeb889c6d30b00d12ad7f,USENIX Symposium on Operating Systems Design and Implementation
687,Which Spatial Partition Trees are Adaptive to Intrinsic Dimension?,"Recent theory work has found that a special type of spatial partition tree -- called a random projection tree -- is adaptive to the intrinsic dimension of the data from which it is built. Here we examine this same question, with a combination of theory and experiments, for a broader class of trees that includes k-d trees, dyadic trees, and PCA trees. Our motivation is to get a feel for (i) the kind of intrinsic low dimensional structure that can be empirically verified, (ii) the extent to which a spatial partition can exploit such structure, and (iii) the implications for standard statistical tasks such as regression, vector quantization, and nearest neighbor search.",2009-06-18,https://www.semanticscholar.org/paper/6782ca4b600d823ef5734f11779f7b8a41dc4812,Conference on Uncertainty in Artificial Intelligence
3684,Sin3DM: Learning a Diffusion Model from a Single 3D Textured Shape,"Synthesizing novel 3D models that resemble the input example has long been pursued by researchers and artists in computer graphics. In this paper, we present Sin3DM, a diffusion model that learns the internal patch distribution from a single 3D textured shape and generates high-quality variations with fine geometry and texture details. Training a diffusion model directly in 3D would induce large memory and computational cost. Therefore, we first compress the input into a lower-dimensional latent space and then train a diffusion model on it. Specifically, we encode the input 3D textured shape into triplane feature maps that represent the signed distance and texture fields of the input. The denoising network of our diffusion model has a limited receptive field to avoid overfitting, and uses triplane-aware 2D convolution blocks to improve the result quality. Aside from randomly generating new samples, our model also facilitates applications such as retargeting, outpainting and local editing. Through extensive qualitative and quantitative evaluation, we show that our model can generate 3D shapes of various types with better quality than prior methods.",2023-05-24,https://www.semanticscholar.org/paper/4cb4303e79acef4c276a87615641f94cd77a3e4a,arXiv.org
2578,Automated layout of information presentations,"Layout refers to the process of determining the sizes and positions of the visual objects that are part of an information presentation. Automated layout refers to the use of a computer program to automate either all or part of the layout process. This field of research lies at the crossroads of artificial intelligence and human computer interaction. Automated layout of presentations is becoming increasingly important as the amount of data that we need to present rapidly overtakes our ability to present it manually. 
We present a set of novel techniques that can assist an automated layout system to produce an effective presentation of information, given a set of components to display and metadata describing relationships between those components. Unlike the vast majority of previous approaches to layout and numerous related problems, our techniques attempt to mimic the workflow used by a human graphic designer when manually creating a presentation. 
Our techniques include a method to control the length of text being displayed that is inspired by the capability of a designer to ask a copy editor for a change in the content length to suit a particular layout. We have also developed a method for automatically evaluating and improving the visual balance of a layout that closely mirrors the process used by graphic designers. Finally, we have developed a method to deliver layouts produced by our techniques using a thin-client approach. 
Our techniques are uniquely capable of capturing the irregular and sometimes counterintuitive tactics used by human designers to create layouts. When combined with a model of the workflow used by human graphic designers, our techniques allow systems to automatically generate layouts that are highly effective, superior in both form and function to those generated by investigations into this field to date.",,https://www.semanticscholar.org/paper/18fd8b8906b9afa991c1e2082254681365d7fb1b,
2513,Designing for Ease of Use of Inpatient Technology to Communicate Medication Therapies,"The fields of health services, medical informatics, and human–computer interaction have begun to investigate electronic approaches to providing detailed health information to patients. Building on a custom Personal Health Record portal infrastructure that we have developed to provide access to real-time medication information for hospitalized patients, we are currently engaging clinicians and patients in user-centered design sessions to explore patient-friendly views of the information. Through interactive browsing of organized views of this medication information in our portal, patients can maintain awareness of scheduled and completed medication therapies, and learn more about them by accessing educational summaries. To evaluate the impact of providing timely access to our portal in the inpatient setting, validated surveys will be used to measure patient satisfaction, engagement and knowledge of inpatient medications.",,https://www.semanticscholar.org/paper/c976fd920173b510f514df05b9cc01737bf03dba,
2289,Neutrophil infiltration into human gliomas,,1999-10-01,https://www.semanticscholar.org/paper/0cfb22ee9011ba4de118748fe03c18b095a384f5,Acta Neuropathologica
1333,Production of WZ events in pp collisions at square root(s) = 1.96 TeV and limits on anomalous WWZ couplings.,"We present results from a search for WZ production with subsequent decay to l nu l' l' (l and l' = e or mu) using 0.30 fb(-1) of data collected by the D0 experiment between 2002 and 2004 at the Fermilab Tevatron. Three events with WZ decay characteristics are observed. With an estimated background of 0.71 +/- 0.08 events, we measure the WZ production cross section to be 4.5(-2.6)(+3.8) pb, with a 95% C.L. upper limit of 13.3 pb. The 95% C.L. limits for anomalous WWZ couplings are found to be -2.0 < delta kappaZ < 2.4 for form factor scale lambda = 1 TeV, and -0.48 < lambdaZ < 0.48 and -0.49 < delta g(1)(Z) < 0.66 for lambda = 1.5 TeV.",,https://www.semanticscholar.org/paper/157f94c7eeadbda7752a6557f808f3e82413fd4c,Physical Review Letters
1015,Effects of pertussis toxin on caudate neuron electrophysiology: studies with dopamine D1 and D2 agonists,,1990-11-19,https://www.semanticscholar.org/paper/b30552656a12b5d8760996e43a9b6ee9705a9e25,Brain Research
2943,Interactions between genetic variation and cellular environment in skeletal muscle gene expression,"From whole organisms to individual cells, responses to environmental conditions are influenced by genetic makeup, where the effect of genetic variation on a trait depends on the environmental context. RNA-sequencing quantifies gene expression as a molecular trait, and is capable of capturing both genetic and environmental effects. In this study, we explore opportunities of using allele-specific expression (ASE) to discover cis acting genotype-environment interactions (GxE) - genetic effects on gene expression that depend on an environmental condition. Treating 17 common, clinical traits as approximations of the cellular environment of 267 skeletal muscle biopsies, we identify 10 candidate interaction quantitative trait loci (iQTLs) across 6 traits (12 unique gene-environment trait pairs; 10% FDR per trait) including sex, systolic blood pressure, and low-density lipoprotein cholesterol. Although using ASE is in principle a promising approach to detect GxE effects, replication of such signals can be challenging as validation requires harmonization of environmental traits across cohorts and a sufficient sampling of heterozygotes for a transcribed SNP. Comprehensive discovery and replication will require large human transcriptome datasets, or the integration of multiple transcribed SNPs, coupled with standardized clinical phenotyping.",2017-02-03,https://www.semanticscholar.org/paper/7ece4ee052fe88f8f535b60c82d19a70065f91d4,bioRxiv
1012,Patterns of Parapapillary Atrophy in Children,,2011-04-22,https://www.semanticscholar.org/paper/f8c4b27bcd1404e802bfb7c2163bf0ba2b903bce,
229,On the Complexity of Dynamic Mechanism Design,"We introduce a dynamic mechanism design problem in which the designer wants to offer for sale an item to an agent, and another item to the same agent at some point in the future. The agent's joint distribution of valuations for the two items is known, and the agent knows the valuation for the current item (but not for the one in the future). The designer seeks to maximize expected revenue, and the auction must be deterministic, truthful, and ex post individually rational. The optimum mechanism involves a protocol whereby the seller elicits the buyer's current valuation, and based on the bid makes two take-it-or-leave-it offers, one for now and one for the future. We show that finding the optimum deterministic mechanism in this situation --- arguably the simplest meaningful dynamic mechanism design problem imaginable --- is NP-hard. We also prove several positive results, among them a polynomial linear programming-based algorithm for the optimum randomized auction (even for many bidders and periods), and we show strong separations in revenue between non-adaptive, adaptive, and randomized auctions, even when the valuations in the two periods are uncorrelated. Finally, for the same problem in an environment in which contracts cannot be enforced, and thus perfection of equilibrium is necessary, we show that the optimum randomized mechanism requires multiple rounds of cheap talk-like interactions.",2014-07-21,https://www.semanticscholar.org/paper/6f2ec53689a5c3ba0ee3c148b7ac5a93093e1b0a,ACM-SIAM Symposium on Discrete Algorithms
3154,"The design, implementation, and evaluation of SMART",,,https://www.semanticscholar.org/paper/6d3e34e7ff8e70130f60dfc1dc43df81b0670d66,
3099,Highly Reliable Mobile Desktop Computing in Your Pocket,"We present DeskPod, a portable system that provides a highly reliable desktop computing environment for mobile users by leveraging rapid improvements in capacity, cost, and size of portable storage devices. DeskPod enables a user's live computing environment to be suspended to portable storage, carried around, easily copied for fault-resilience, and resumed from the storage device to provide the user with the same persistent, personalized computing environment on another computer DeskPod achieves this by providing a virtualization and checkpoint/restart mechanism that decouples a desktop computing environment from any single hardware device so that it can be stored and executed anywhere, improving desktop computing reliability by eliminating a potential single point of failure. We have implemented a Linux DeskPod prototype and demonstrate its ability to quickly suspend and resume desktop sessions, enabling a seamless mobile experience",2006-09-17,https://www.semanticscholar.org/paper/add36c24029f050c751cb7f030de802e89795d09,Annual International Computer Software and Applications Conference
2873,Accelerated diabetic glomerulopathy in galectin‐3/AGE receptor 3 knockout mice,"Several molecules were shown to bind advanced glycation end products (AGEs) in vitro, but it is not known whether they all serve as AGE receptors and which functional role they play in vivo. We investigated the role of galectin‐3, a multifunctional lectin with (anti)adhesive and growth‐regulating properties, as an AGE receptor and its contribution to the development of diabetic glomerular disease, using a knockout mouse model. Galectin‐3 knockout mice obtained by gene ablation and the corresponding wild‐type mice were rendered diabetic with streptozotocin and killed 4 months later, together with age‐matched nondiabetic controls. Despite a comparable degree of metabolic derangement, galectin‐3‐deficient mice developed ac‐celerated glomerulopathy vs. the wild‐type animals, as evidenced by the more pronounced increase in protein‐uria, extracellular matrix gene expression, and mesan‐gial expansion. This was associated with a more marked renal/glomerular AGE accumulation, indicating it was attributable to the lack of galectin‐3 AGE receptor function. The galectin‐3‐deficient genotype was associated with reduced expression of receptors implicated in AGE removal (macrophage scavenger receptor A and AGE‐R1) and increased expression of those mediating cell activation (RAGE and AGE‐R2). These results show that the galectin‐3‐regulated AGE receptor pathway is operating in vivo and protects toward AGE‐induced tissue injury in contrast to that through RAGE.—Pugliese, G., Pricci, F., Iacobini, C., Leto, G., Amadio, L., Barsotti, P., Frigeri L., Hsu, D. K., Vlassara, H., Liu, F.‐T., Di Mario, U. Accelerated diabetic glomerulopathy in galectin‐3/AGE receptor 3 knockout mice. FASEB J. 15, 2471–2479 (2001)",2001-11-01,https://www.semanticscholar.org/paper/acd430ad1deac678ea6e8b09bfdd123708c68005,The FASEB Journal
90,Summarizing and Searching Hidden-Web Databases Hierarchically Using Focused Probes,"Many valuable text databases on the web have non-crawlable contents that are “hidden” behind search interfaces. Metasearchers are helpful tools for searching over many such databases at once through a unified query interface. A critical task for a metasearcher to process a query efficiently and effectively is the selection of the most promising databases for the query, a task that typically relies on statistical summaries of the database contents. Unfortunately, web-accessible text databases do not generally export content summaries. In this paper, we present an algorithm to derive content summaries from “uncooperative” databases by using “focused query probes,” which adaptively zoom in on and extract documents that are representative of the topic coverage of the databases. The content summaries that result from this algorithm are efficient to derive and more accurate than those from previously proposed probing techniques for content-summary extraction. We also present a novel database selection algorithm that exploits both the extracted content summaries and a hierarchical classification of the databases, automatically derived during probing, to produce accurate results even for imperfect content summaries. Finally, we evaluate our techniques thoroughly using a variety of databases, including 50 real web-accessible text databases.",,https://www.semanticscholar.org/paper/6df03d95e357ebbd2dd2b6f2e9da6d477f21ae3a,
3664,An overview of C++ (abstract only),,1986-10-01,https://www.semanticscholar.org/paper/cba93c9362c4bea2e55db5eac1d7f19ef007dea4,OOPWORK '86
617,The Complexity of Coloring Circular Arcs and Chords,"The word problem for products of symmetric groups, the circular arc graph coloring problem, and the circle graph coloring problem, as well as several related problems, are proved to be $NP$-complete. For any fixed number K of colors, the problem of determining whether a given circular arc graph is K-colorable is shown to be solvable in polynomial time.",1980-06-01,https://www.semanticscholar.org/paper/b2997317ace4ee970ea960218d0ad3e8fc4ecc36,SIAM J. Algebraic Discret. Methods
2078,A novel method for determining machine subgroups and backups with an empirical study for semiconductor manufacturing,,2006-08-01,https://www.semanticscholar.org/paper/898e6d08e1e5a6b8156f8b0cebc77a3ebab79740,Journal of Intelligent Manufacturing
3497,Approximation techniques for average completion time scheduling,"We consider the problem of nonpreemptive scheduling to minimize average (weighted) completion time, allowing for release dates, parallel machines, and precedence constraints. Recent work has led to constant-factor approximations for this problem, based on solving a preemptive or linear programming relaxation and then using the solution to get an ordering on the jobs. We introduce several new techniques which generalize this basic paradigm. We use these ideas to obtain improved approximation algorithms for one-machine scheduling to minimize average completion time with release dates. In the process, we obtain an optimal randomized on-line algorithm for the same problem that beats a lower bound for deterministic on-line algorithms. We consider extensions to the case of parallel machine scheduling, and for this we introduce two new ideas: first, we show that a preemptive one-machine relaxation is a powerful tool for designing parallel machine scheduling algorithms that simultaneously produce good approximations and have small running times; second, we show that a non-greedy {open_quotes}rounding{close_quotes} of the relaxation yields better approximations than a greedy one. We also prove a general theorem relating the value of one-machine relaxations to that of the schedules obtained for the original m-machine problems. This theorem applies even when there are precedencemore » constraints on the jobs. We apply this result to precedence graphs such as in-trees, out-trees, and series- parallel graphs; these are of particular interest in compiler applications that partly motivated our work.« less",1997-01-05,https://www.semanticscholar.org/paper/6d1e977ee1b083430af9f15e731b9a3b7b88bc3e,ACM-SIAM Symposium on Discrete Algorithms
1394,Subjet of Gluon and Quark Jets Reconstructed with the k ? Algorithm in,"The D(cid:31) Collaboration has studied for the (cid:12)rst time the properties of hadron-collider jets reconstructed with a successive-combination algorithm based on relative transverse momenta ( k ? ) of energy clusters. Using the standard value D = 1 : 0 of the jet-separation parameter in the k ? algorithm, we (cid:12)nd that the p T of such jets is higher than the E T of matched jets reconstructed with cones of radius R = 0 : 7, by about 5 (8) GeV at p T (cid:25) 90 (240) GeV. To examine internal jet structure, the k ? algorithm is applied within D = 0 : 5 jets to resolve any subjets. The multiplicity of subjets in jet samples at p s = 1800 GeV and 630 GeV is extracted separately for gluons ( M g ) and quarks ( M q ), and the ratio of average subjet multiplicities in gluon and quark jets is measured as h M g i(cid:0) 1 h M q i(cid:0) 1 = 1 : 84 (cid:6) 0 : 15 (stat.) (cid:6) 0 : 22 0 : 18 (sys.). This ratio is in agreement with the expectations from the HERWIG Monte Carlo event generator and a resummation calculation, and with observations in e + e (cid:0) annihilations, and is close to the naive prediction for the ratio of color charges of C A =C F = 9 = 4 = 2 : 25. Rev.",,https://www.semanticscholar.org/paper/86871aad57be16c78488e0be2e84f29bae1af1a3,
3371,Behavioral Biology of the Crayfish Orconectes virilis I. Home Range,"The movements of individual crayfish, Orconectes virilis, were followed by hand captures of marked animals for over a year. Considerable variability was found in both the total home-range length recorded for individuals and in the capture-to-capture movement (both ranged from zero to 308 m). The average of the capture-to-capture movements was 33 m; the mode was 0-5 m (crayfish found in same grid area). Males and females did not differ in size of home-range or capture-to-capture movement, but several aspects of the data indicate that males moved more. Size was significantly correlated with movement for females but not males. Animals frequently moved farther after a molt, and many animals moved into shallow, sandy areas around the time of a molt.",1974-10-01,https://www.semanticscholar.org/paper/07c9a5055c18b67bbf53567d3f1b6c938140dec8,
947,Succinct Approximate Convex Pareto Curves ( Extended Abstract ),"We study the succinct approximation of convex Pareto curves of multiobjective optimization problems. We propose the concept of -convex Pareto ( -CP) set as the appropriate one for the convex setting, and observe that it can offer arbitrarily more compact representations than -Pareto sets in this context. We characterize when an -CP can be constructed in polynomial time in terms of an efficient routine Comb for optimizing (exactly or approximately) monotone linear combinations of the objectives. We investigate the problem of computing minimum size -convex Pareto sets, both for discrete (combinatorial) and continuous (convex) problems, and present general algorithms using a Comb routine. For bi-objective problems, we show that if we have an exact Comb optimization routine, then we can compute the minimum -CP for continuous problems (this applies for example to bi-objective Linear Programming and Markov Decision Processes), and factor 2 approximation to the minimum -CP for discrete problems (this applies for example to bi-objective versions of polynomial-time solvable combinatorial problems such as Shortest Paths, Spanning Tree, etc.). If we have an approximate Comb routine, then we can compute factor 3 and 6 approximations respectively to the minimum -CP for continuous and discrete bi-objective problems. We consider also the case of three and more objectives and present some upper and lower bounds.",,https://www.semanticscholar.org/paper/f14a7426a075f7240789392177ce108e9b4b2828,
2149,Directly Lower Bounding the Information Capacity for Channels With I.I.D. Deletions and Duplications,"In this paper, we directly lower bound the information capacity for channels with independent identically distributed (i.i.d.) deletions and duplications. Our approach differs from previous work in that we focus on the information capacity using ideas from renewal theory, rather than focusing on the transmission capacity by analyzing the error probability of some randomly generated code using a combinatorial argument. Of course, the transmission and information capacities are equal, but our change of perspective allows for a much simpler analysis that gives more general theoretical results. We then apply these results to the binary deletion channel to improve existing lower bounds on its capacity.",2007-06-24,https://www.semanticscholar.org/paper/64d382fb00a3677109dec9bd5d08f45452d74fe0,IEEE Transactions on Information Theory
342,Quantum Information Processing,"Abstract : This effort supported a Quantum Information Workshop at the University of California, Berkeley. After a cut in funding, the remaining unspent funding was used to support: (I) research related to the internet involving the interplay between mechanism design and computational complexity, (2) improved understanding of the connections between phase transitions in statistical mechanics and mixing times of Markov chain Monte Carlo algorithms, and (3) an investigation of the logic of transcriptional control of various model organisms, with emphasis on characterizing the binding sites of key transcription factors via stochastic models.",2004-11-01,https://www.semanticscholar.org/paper/25636dd2bad9ba9273d5e3b1107a38051bdd6713,
2066,Optimize die size design to enhance owe for design for manufacturing,"To enhance competitive advantages, it is crucial for wafer fabs to reduce average die cost through productivity improvement via increasing the number of gross dies per wafer and throughput. However, gross die number is influenced by die size in design phase, while the existing size of integrated circuit die was designed without considering the effect on wafer throughput in fabrication phase. This research aims to develop a die size optimization algorithm based on decision tree to construct the rules between the number of gross dies per wafer, mask utilization, and the die feature including length, width, and area. Without losing generality, an empirical study has been done for validation by using transformed data from a fab in Taiwan.",2007-10-01,https://www.semanticscholar.org/paper/6d561e3b6aa64dad1eb239492d39b69bc700a11a,International Symposium on Semiconductor Manufacturing
2785,Galectin-3 as a Therapeutic Target for NSAID-Induced Intestinal Ulcers,"Non-steroidal anti-inflammatory drugs (NSAIDs) induce ulcers in the gastrointestinal tract, including the stomach and small intestine. NSAID-induced gastric ulcers can be prevented by taking acid-neutralizing/inhibitory drugs and cytoprotective agents. In contrast, there are no medicines to control NSAID-induced small intestinal ulcers, which are accompanied by a mucosal invasion of bacteria and subsequent activation of immune cells. Galectin-3 (Gal3), an endogenous lectin, has anti-microbial and pro-inflammatory functions. In the small intestine, since Gal3 is highly expressed in epithelial cells constitutively and macrophages inducibly, the Gal3 level can affect microbiota composition and macrophage activation. We hypothesized that the modulation of Gal3 expression could be beneficial in NSAID-induced intestinal ulcers. Using Gal3 knockout (Gal3KO) mice, we determined whether Gal3 could be a therapeutic target in NSAID-induced intestinal ulcers. Following the administration of indomethacin, an NSAID, we found that small intestinal ulcers were less severe in Gal3KO mice than in wild-type (WT) mice. We also found that the composition of intestinal microbiota was different between WT and Gal3KO mice and that bactericidal antibiotic polymyxin B treatment significantly suppressed NSAID-induced ulcers. Furthermore, clodronate, a macrophage modulator, attenuated NSAID-induced ulcers. Therefore, Gal3 could be an exacerbating factor in NSAID-induced intestinal ulcers by affecting the intestinal microbiota population and macrophage activity. Inhibition of Gal3 may be a therapeutic strategy in NSAID-induced intestinal ulcers. Clinical Trial Registration www.ClinicalTrials.gov, identifier NCT03832946.",2020-09-23,https://www.semanticscholar.org/paper/36631769f28b10c853bac05de55f14812455240e,Frontiers in Immunology
836,Recent Developments on the Approximability of Combinatorial Problems,,1993-12-15,https://www.semanticscholar.org/paper/1fa69a8d690f3603b27a09d7206fe641602ea823,International Symposium on Algorithms and Computation
2837,Galectin‐3 regulates T‐cell functions,"Summary:  Galectin‐3 is absent in resting CD4+ and CD8+ T cells but is inducible by various stimuli. These include viral transactivating factors, T‐cell receptor (TCR) ligation, and calcium ionophores. In addition, galectin‐3 is constitutively expressed in human regulatory T cells and CD4+ memory T cells. Galectin‐3 exerts extracellular functions because of its lectin activity and recognition of cell surface and extracellular matrix glycans. These include cell activation, adhesion, induction of apoptosis, and formation of lattices with cell surface glycoprotein receptors. Formation of lattices can result in restriction of receptor mobility and cause attenuation of receptor functions. Consistent with the presence of galectin‐3 in intracellular locations, several functions have been described for this protein inside T cells. These include inhibition of apoptosis, promotion of cell growth, and regulation of TCR signal transduction. Studies of cell surface glycosylation have led to convergence of glycobiology and galectin biology and provided new clues on how galectin‐3 may participate in the regulation of cell surface receptor activities. The rapid expansion of the field of galectin research has positioned galectin‐3 as a key regulator in T‐cell functions.",2009-07-01,https://www.semanticscholar.org/paper/ef99c0482d3e4c7c8cc9e3b9f2a9d05430adc4b1,Immunological Reviews
542,Optimum Grip of a Polygon,"It has been shown by Baker, Fortune and Grosse that any two-dimensional polygonal object can be prehended stably with three fingers, so that its weight (along the third dimension) is balanced. Besides, in this paper we show that form closure of a polygon object can be achieved by four fingers (previous proofs were not complete). We formulate and solve the problem of finding the optimum stable grip or form closure of any given polygon. For stable grip it is most natural to minimize the forces needed to balance through friction the object''s weight along the third dimension. For form closure, we minimize the worst-case forces needed to balance any unit force acting on the center of gravity of the object. The mathematical techniques used in the two instances are an interesting mix of Optimization and Euclidean geometry. Our results lead to algorithms for the efficient computation of the optimum grip in each case.",1987-04-01,https://www.semanticscholar.org/paper/f05f41e1c53a670ecfab1340ac8f54a357cb9da7,Int. J. Robotics Res.
805,Black Box Checking,"Two main approaches are used for increasing the quality of systems: in model checking , one checks properties of a known design of a system; in testing, one usually checks whether a given implementation, whose internal structure is often unknown, conforms with an abstract design. We are interested in the combination of these techniques. Namely, we would like to be able to test whether an implementation with unknown structure satisfies some given properties. We propose and formalize this problem of black box checking and suggest several algorithms. Since the input to black box checking is not given initially, as is the case in the classical model of computation, but is learned through experiments, we propose a computational model based on games with incomplete information. We use this model to analyze the complexity of the problem. We also address the more practical question of finding an approach that can detect errors in the implementation before completing an exhaustive search.",1999-10-05,https://www.semanticscholar.org/paper/8ab91a1d00b1e4bda4c800672fb196541622a998,Formal Techniques for (Networked and) Distributed Systems
718,REACT to Cyber Attacks on Power Grids,"Motivated by the recent cyber attack on the Ukrainian power grid, we study cyber attacks on power grids that affect both the physical infrastructure and the data at the control center–which therefore are cyber-physical in nature. In particular, we assume that an adversary attacks an area by: (i) remotely disconnecting some lines within the attacked area, and (ii) modifying the information received from the attacked area to mask the line failures and hide the attacked area from the control center. For the latter, we consider two types of attacks: (i) data distortion: which distorts the data by adding powerful noise to the actual data, and (ii) data replay: which replays a locally consistent old data instead of the actual data. We use the DC power flow model and prove that the problem of finding the set of line failures given the phase angles of the nodes outside of the attacked area is strongly NP-hard, even when the attacked area is known. However, we introduce the polynomial time REcurrent Attack Containment and deTection (REACT) Algorithm to approximately detect the attacked area and line failures after a cyber-physical attack. We numerically show that it performs well in detecting the attacked area, and detecting single, double, and triple line failures in small and large attacked areas.",2017-09-20,https://www.semanticscholar.org/paper/df2d7000ff4292d81df29f5b1f3efcb6c5921e8e,IEEE Transactions on Network Science and Engineering
3414,Minimizing the Total Weighted Completion Time of Coflows in Datacenter Networks,"Communications in datacenter jobs (such as the shuffle operations in MapReduce applications) often involve many parallel flows, which may be processed simultaneously. This highly parallel structure presents new scheduling challenges in optimizing job-level performance objectives in data centers. Chowdhury and Stoica introduced the coflow abstraction to capture these communication patterns, and recently Chowdhury et al. developed effective heuristics to schedule coflows. In this paper, we consider the problem of efficiently scheduling coflows with release dates so as to minimize the total weighted completion time, which has been shown to be strongly NP-hard. Our main result is the first polynomial-time deterministic approximation algorithm for this problem, with an approximation ratio of 67/3, and a randomized version of the algorithm, with a ratio of 9+16√2/3. Our results use techniques from both combinatorial scheduling and matching theory, and rely on a clever grouping of coflows. We also run experiments on a Facebook trace to test the practical performance of several algorithms, including our deterministic algorithm. Our experiments suggest that simple algorithms provide effective approximations of the optimal, and that our deterministic algorithm has near-optimal performance.",2015-06-13,https://www.semanticscholar.org/paper/bd87cc38abc992be2d154a522729cddfa90dc4fc,ACM Symposium on Parallelism in Algorithms and Architectures
931,The Node-Deletion Problem for Hereditary Properties is NP-Complete,,1980-04-01,https://www.semanticscholar.org/paper/0df73f3939d60578b09d59ac0d1d7c0dbdb53c6e,Journal of computer and system sciences (Print)
3198,"Characterization of intestinal microbiota and fecal cortisol, T3, and IgA in forest musk deer (Moschus berezovskii) from birth to weaning","Abstract Analysis of the intestinal microbiota and physiological parameters in mammalian infancy can reveal health status. In this study, we used a combination of molecular and immunochemical approaches to assess fecal microbiota as well as Cortisol (Cor), Triiodothyronine (T3), and immunoglobulin A (IgA) levels of young forest musk deer (FMD), from birth to one month after weaning (7 days of age–110 days of age). During development as the diet of FMD changes from consuming milk to eating plants, the richness and diversity of intestinal microbiota of young FMD increased significantly. Cor levels remained unchanged throughout early development while significantly increased after weaning, T3 and IgA initially were derived from milk during lactation, significantly decreased after weaning. Correlation network analysis showed that the community of food‐oriented microbes were highly structured and that many genera were correlated. Overall, this study provides scientific insights into effective management strategies for the protection of FMD population.",2021-01-16,https://www.semanticscholar.org/paper/cfae7858676245aba8003626c6872a5ce0e55ed3,Integrative Zoology
893,"Addendum: Simple Linear-Time Algorithms to Test Chordality of Graphs, Test Acyclicity of Hypergraphs, and Selectively Reduce Acyclic Hypergraphs",,,https://www.semanticscholar.org/paper/27c19e1522fd1acb03402086961161f8e1498f89,SIAM journal on computing (Print)
653,"Balloon angioplasty for treatment of in-stent restenosis: feasibility, safety, and efficacy.","Sixty patients with 1 or 2 stainless steel intracoronary stents (Cook, Inc.) underwent balloon angioplasty for in-stent restenosis 1.5-13.5 months after stenting. Seventy-five in-stent redilatation procedures were performed. Seventy-three restenotic lesions (97%) were successfully recrossed and dilated, reducing the mean pre-angioplasty intrastent diameter stenosis from 77 +/- 12% to 20 +/- 11% residual. Although one angioplasty (1.3%) was complicated by non-Q-wave infarction, no angioplasty-related death, acute closure, need for additional stenting, emergent coronary bypass surgery, side branch occlusion, or vascular sequelae occurred. Post-procedure heparin was not used in 83% of successful cases. Most patients were discharged the day following redilatation (mean in-hospital stay 1.7 +/- 1.3 days). At 5.4 +/- 3.4 months following in-stent angioplasty, 84% of patients were in Canadian Cardiovascular Society class 0 or I. In conclusion, balloon dilatation in this stent for restenosis appears simple and efficacious in the short term, and may entail less risk than dilatation of unprotected coronary vessels.",1994-06-01,https://www.semanticscholar.org/paper/53d92d9ec3553d72923d2884c1a71f8d58863690,Catheterization and Cardiovascular Diagnosis
2214,differential effects on expression of Mcl-1 and Bfl-1 on neutrophil apoptosis are mediated via α The dual effects of TNF,,,https://www.semanticscholar.org/paper/24278647e1a29652c652dc740fd8ce4380989882,
116,Data structures for efficient broker implementation,"With the profusion of text databases on the Internet, it is becoming increasingly hard to find the most useful databases for a given query. To attack this problem, several existing and proposed systems employ brokers to direct user queries, using a local database of summary information about the available databases. This summary information must effectively distinguish relevant databases and must be compact while allowing efficient access. We offer evidence that one broker, GlOSS, can be effective at locating databases of interest even in a system of hundreds of databased and can examine the performance of accessing theGlOSS summeries for two promising storage methods: the grid file and partitioned hashing. We show that both methods can be tuned to provide good performance for a particular workload (within a broad range of workloads), and we discuss the tradeoffs between the two data structures. As a side effect of our work, we show that grid files are more broadly applicable than previously thought; inparticular, we show that by varying the policies used to construct the grid file we can provide good performance for a wide range of workloads even when storing highly skewed data.",1997-07-01,https://www.semanticscholar.org/paper/2b5d18de54908db492dbc9315c9eea1ed86ac521,TOIS
3480,Approximation Algorithms for the Minimum Bends Traveling Salesman Problem,,2000-04-01,https://www.semanticscholar.org/paper/aea0f6bd91a4a3b2a7fd459919d71fd4301f67f3,Conference on Integer Programming and Combinatorial Optimization
2865,PC7 ADVANCED GLYCATION ENDPRODUCT-INDUCED BREAKDOWN OF THE BLOOD RETINAL BARRIER IS MEDIATED BY GALECTIN 3,,2004-09-01,https://www.semanticscholar.org/paper/8eb6d349009df2a205db8aa8f5bdf33d848b81df,
688,Mathematical Advances in Manifold Learning,Manifold learning has recently gained a lot of interest by machine learning practitioners. Here we provide a mathematically rigorous treatment of some of the techniques in unsupervised learning in context of manifolds. We will study the problems of dimension reduction and density estimation and present some recent results in terms of fast convergence rates when the data lie on a manifold.,,https://www.semanticscholar.org/paper/8ac9c17dc8e7fb6ffdf47ae3a1b5efd36668d999,
1401,Search for mSUGRA in single-electron events with jets and large missing transverse energy in pp collisions at p s = 1.8 TeV,"We describe a search for evidence of minimal supergravity (MSUGRA) in 92.7 pb(-1) of data collected with the D empty set detector at the Fermilab Tevatron p (p) over bar collider at roots=1.8 TeV. Events with a single electron, four or more jets, and large missing transverse energy were used in this search. The major backgrounds are from W+jets, misidentified multijet, t (t) over bar, and WW production. We observe no excess above the expected number of background events in our data. A new limit in terms of MSUGRA model parameters is obtained.",2002-05-01,https://www.semanticscholar.org/paper/e1496d3d1c464c4ae3c733db0b1fa0f095f877fa,
2691,"Future multimedia user interfaces
",,1996-10-01,https://www.semanticscholar.org/paper/2eff111a86f0f570b01fb49ce67399dcf7626f13,Multimedia Systems
716,On the Complexity of Simple and Optimal Deterministic Mechanisms for an Additive Buyer,"We show that the Revenue-Optimal Deterministic Mechanism Design problem for a single additive buyer is #P-hard, even when the distributions have support size 2 for each item and, more importantly, even when the optimal solution is guaranteed to be of a very simple kind: the seller picks a price for each individual item and a price for the grand bundle of all the items; the buyer can purchase either the grand bundle at its given price or any subset of items at their total individual prices. The following problems are also #P-hard, as immediate corollaries of the proof: 
1. determining if individual item pricing is optimal for a given instance, 
2. determining if grand bundle pricing is optimal, and 
3. computing the optimal (deterministic) revenue. 
On the positive side, we show that when the distributions are i.i.d. with support size 2, the optimal revenue obtainable by any mechanism, even a randomized one, can be achieved by a simple solution of the above kind (individual item pricing with a discounted price for the grand bundle) and furthermore, it can be computed in polynomial time. The problem can be solved in polynomial time too when the number of items is constant.",2017-02-22,https://www.semanticscholar.org/paper/4bc3c3a49403ca19f67cbda2dac6850eaea4ac62,ACM-SIAM Symposium on Discrete Algorithms
3246,"Effects of holistic grazing management on milk production, weight gain, and visitation to grazing areas by livestock and wildlife in Laikipia County, Kenya",,2016-10-29,https://www.semanticscholar.org/paper/2ee68de7112bf894afac4c7d141dac23cb0d1838,Ecological Processes
1292,Search for supersymmetry in di-photon final states at √ s = 1 . 96 TeV,"We report results of a search for supersymmetry (SUSY) with gauge-mediated symmetry breaking in di-photon events collected by the D0 experiment at the Fermilab Tevatron Collider in 2002–2006. In 1.1 fb−1 of data, we find no significant excess beyond the background expected from the standard model and set the most stringent lower limits to date for a standard benchmark model on the lightest neutralino and chargino masses of 125 GeV and 229 GeV, respectively, at 95% confidence. © 2007 Elsevier B.V. All rights reserved. PACS: 14.80.Ly; 12.60.Jv; 13.85.Rm Low-scale SUSY is one of the most promising solutions to the hierarchy problem associated with the intrinsic disparity between the electroweak and Planck scales. It postulates that for each known particle there exists a superpartner, thereby stabilizing the radiative corrections to the Higgs boson mass. Bosons have fermion superpartners, and vice versa. None of the superpartners have yet been observed, and superpartner masses * Corresponding author. E-mail address: gershtein@hep.fsu.edu (Yu. Gershtein). 1 Visitor from Augustana College, Sioux Falls, SD, USA. 2 Visitor from The University of Liverpool, Liverpool, UK. 3 Fermilab International Fellow. 4 Visitor from II. Physikalisches Institut, Georg-August-University Göttingen, Germany. 5 Visitor from ICN-UNAM, Mexico City, Mexico. 6 Visitor from Helsinki Institute of Physics, Helsinki, Finland. 7 Visitor from Universität Zürich, Zürich, Switzerland. Deceased. must therefore be much larger than those of their partners, i.e., SUSY is a broken symmetry. Experimental signatures of supersymmetry are determined through the manner and scale of SUSY breaking. In models with gauge-mediated supersymmetry breaking (GMSB) [1,2], it is achieved through the introduction of new chiral supermultiplets, called messengers that couple to the ultimate source of supersymmetry breaking and to the SUSY particles. At colliders, assuming R-parity conservation [3], superpartners are produced in pairs (χ̃+ 1 χ̃ − 1 and χ̃ ± 1 χ̃ 0 2 production dominates in most cases) and decay to the standard model particles and next-to-lightest SUSY particle (NLSP), which can be either a neutralino or a slepton. In the former case, which is considered in this note, the NLSP decays into a photon and a gravitino (the lightest superpartner in GMSB SUSY models, with mass less than ≈ 1 keV). The gravitino is stable, and escapes detection, creating an apparent imbalance in transverse momentum (/ ET ) in the event. GMSB SUSY final states are therefore characterized by two energetic photons and large missing transverse momentum. The differences in event 860 DØ Collaboration / Physics Letters B 659 (2008) 856–863 kinematics between particular GMSB SUSY models result in slightly different experimental sensitivities [4], and to obtain a quantitative measure of limits on SUSY we consider a model referred to as “Snowmass Slope SPS 8” [5]. This model has only a single dimensioned parameter: an energy scale Λ that determines the effective scale of SUSY breaking. The minimal GMSB parameters correspond to a messenger mass Mm = 2Λ, the number of messengers N5 = 1, the ratio of the vacuum expectation values of the two Higgs fields tanβ = 15, and the sign of the Higgsino mass term μ > 0. The neutralino lifetime is not defined within the model. For this analysis, it is assumed to be sufficiently short to yield decays with prompt photons. Searches for GMSB SUSY were carried out by collaborations at the CERN LEP collider [6] and at the Fermilab Tevatron collider in both Run I [7] and early in Run II [4,8]. The initial limits from CDF and D0 for Run II, based on the SPS 8 model, were combined [9] to yield Λ > 84.6 TeV corresponding to the limit on the chargino mass of 209 GeV, at 95% confidence. Complementary searches for GMSB SUSY with R-parity violation were performed by the H1 experiment at HERA [10]. This analysis is an update of that described in Ref. [4], with about a factor of three more data and improved photon identification based on: (i) an electromagnetic (EM) cluster “pointing” algorithm that predicts the origin of a photon with a resolution of about 2 cm along the beam axis, thereby eliminating the largest instrumental background associated with misreconstruction of the primary interaction vertex, and (ii) an improved track veto requirement that suppresses sources of background with electrons in the final state. We also use an improved likelihood fitter [11] to set limits on the scale parameter Λ. The data in this analysis were recorded using single EM triggers with the D0 detector [12], the main components of which are an inner tracker, liquid-argon/uranium calorimeters, and a muon spectrometer. The inner tracker consists of silicon microstrip and central scintillating-fiber trackers located in a 2 T superconducting solenoidal magnet, providing measurements up to pseudorapidities8 of |η| ≈ 3.0 and |η| ≈ 1.8, respectively. The calorimeters are finely segmented and consist of a central section (CC) covering |η| < 1.2 and two endcap calorimeters extending coverage to |η| ≈ 4, all housed in separate cryostats [13]. The electromagnetic section of the calorimeter has four longitudinal layers and transverse segmentation of 0.1 × 0.1 in η–φ space (where φ is the azimuthal angle), except in the third layer, where it is 0.05×0.05. The central preshower (CPS) system is placed between the solenoid and the calorimeter cryostat and covers |η| 1.2. The CPS provides precise measurement of positions of EM showers. The axes of EM showers are reconstructed by fitting straight lines to shower positions measured in the four longitudinal calorimeter layers and the CPS (EM “pointing”). The data for this study were collected between 2002 and summer 2006, using inclusive single EM triggers that are almost 100% efficient to select signal data. The integrated luminosity [14] of the sample is 1100 ± 70 pb−1. 8 Pseudorapidity is defined as − log(tan( θ2 )), where θ is the angle between the particle and the proton beam direction. Photons and electrons are identified based on reconstructed EM clusters using calorimetric information and further classified into electron and photon candidates, based on tracking information. The EM clusters are selected from calorimeter clusters using the simple cone method (of radius R = √ ( η)2 + ( φ)2 = 0.4) by requiring that (i) at least 90% of the energy is deposited in the EM section of the calorimeter, (ii) the calorimeter isolation variable I = [Etot(0.4) − EEM(0.2)]/EEM(0.2) is less than 0.07, where Etot(0.4) is the total shower energy in a cone of radius R= 0.4, and EEM(0.2) is the EM energy in a cone of radius R = 0.2, (iii) the transverse, energy-weighted, width of the EM cluster in the third EM calorimeter layer is smaller than 0.04 rad, and (iv) the scalar sum of the transverse momenta (pT ) of all tracks originating from the primary vertex in an annulus of 0.05 <R< 0.4 around the cluster is less than 2 GeV. The isolation criteria are tuned so that photons that convert in the tracker material are not rejected. The EM cluster is further defined as an electron candidate if it is spatially matched to activity in the tracker, and as a photon candidate otherwise. The tracker activity can be either a reconstructed track or a density of hits in the silicon microstrip and central fiber trackers consistent with a track, i.e., an electron. The latter requirement allows for increasing electron track-matching efficiency, trk, measured in Z → ee data, from (93.0 ± 0.1)% to (98.6 ± 0.1)% by identifying electrons with lost tracks due to hard bremsstrahlung and/or inefficiency of the inner trackers. This reduces electron backgrounds to photons by a factor of five, while keeping the efficiency of anti-track activity requirement high. We measure that (91 ± 3)% of photon candidates in Z → eeγ data satisfy the anti-track activity requirement. Jets are reconstructed using the iterative, midpoint cone algorithm [15] with a cone size of R = 0.5. The missing transverse energy is determined from the energy deposited in the calorimeter for |η| < 4 and is corrected for the EM and jet energy scales. We select γ γ candidates by requiring events to have two photon candidates, each with transverse energy ET > 25 GeV identified in the CC with |η| < 1.1. We require that at least one of the photon candidates be matched to a CPS cluster, and that the primary vertex be consistent with that of the photon candidate (obtained from the EM pointing). The accuracy of the determination of the photon vertex is measured using photons from final state radiation in Z → eeγ data sample and found to be 2.3 ± 0.3 cm. The requirement of consistency between the photon and primary vertices ensures correct calculation of the transverse energies and tracking isolation requirements. The accuracy of primary vertex association is studied in GMSB SUSY Monte Carlo simulated events, where the primary vertex is identified correctly in (98.5 ± 0.1)% of the events while the photon vertex matches the primary vertex in (95.8 ± 0.1)%. To reduce potential bias in the measurement of / ET from mismeasurement of jet transverse momentum, we also require that the jet with the highest ET (if jets are present in the event) be separated from the / ET in azimuth by no more than 2.5 radians. This selection yields 2341 events (the γ γ sample). DØ Collaboration / Physics Letters B 659 (2008) 856–863 861 All instrumental backgrounds arise from standard model processes, with either genuine / ET (Wγ , W + jet, and t t̄ production) or without inherent / ET (direct photon, multi-jet, and Z → ee production). All these backgrounds are measured using data. The former source always has an electron in the final state which is misidentified as a photon. The contribution of this background to the / ET distribution in data can be estimated using an eγ sample (selected by requiring an electron and a photon candidate and using the same kinemati",,https://www.semanticscholar.org/paper/b99c391ec4b8122c036296600c57d3e7f20179cd,
2998,UPGRADVISOR: Early Adopting Dependency Updates Using Hybrid Program Analysis and Hardware Tracing,"Applications often have fast-paced release schedules, but adoption of software dependency updates can lag by years, leaving applications susceptible to security risks and unexpected breakage. To address this problem, we present U PGRADVISOR , a system that reduces developer effort in evaluating dependency updates and can, in many cases, automatically determine which updates are backward-compatible versus API-breaking. U PGRADVISOR introduces a novel co-designed static analysis and dynamic tracing mechanism to gauge the scope and effect of dependency updates on an application. Static analysis prunes changes irrelevant to an application and clusters relevant ones into targets . Dynamic tracing needs to focus only on whether targets affect an application, making it fast and accurate. U PGRADVISOR handles dynamic interpreted languages and introduces call graph over-approximation to account for their lack of type information and selective hardware tracing to capture program execution while ignoring interpreter machinery. We have implemented U PGRADVISOR for Python and evaluated it on 172 dependency updates previously blocked from being adopted in widely-used open-source software, including Django , aws-cli , tfx , and Celery . U PGRADVISOR automatically determined that 56% of dependencies were safe to update and reduced by more than an order of magnitude the number of code changes that needed to be considered by dynamic tracing. Evaluating U PGRADVISOR ’s tracer in a production-like environment incurred only 3% overhead on average, making it fast enough to deploy in practice. We submitted safe updates that were previously blocked as pull requests for nine projects, and their developers have already merged most of them. Abstract The version of U PGRADVISOR used to perform the experiments described in the paper may be downloaded from figshare.com. Theartifactcontainsthecodeforthepackagesur-vey, the static analyzer, and the hardware tracer. It also contains scripts to compile the tracer, run the experiments described in the paper, and produce most of the figures. For the most up to We provide the analyzer pre-installed in a docker container. The tracer requires a bare-metal machine. It directly employs a tracing capability found in Intel 5th generation CPUs (Broadwell) and above. Installing the tracer software requires root access to the OS. This artifact will run on a i7-10700 CPU workstation with 16GB RAM. A slower machine may result in reduced performance. We set up the docker container on the tracer machine and encourage you to do the same.",,https://www.semanticscholar.org/paper/11bcdf664ee392ba1cec9a0ecc0f7d59a7f497eb,USENIX Symposium on Operating Systems Design and Implementation
211,Some additional notes on Max Flow and Min Cut 1 Flows and Cuts in Networks,"A flow in a network is a specification of how to route “stuff” from s to t so that no link is used beyond its capacity, and so that every link, except the sender s and the receiver t, relays out “stuff” at exactly the same rate at which it receives from other vertices. In the motivating example of a communication network, if nodes where sending out less data than they receive, there would be data loss, and they cannot send out more data than they receive because they are simply forwarding data. Formally, we have the following definition.",,https://www.semanticscholar.org/paper/dd7d60c9fe5f5a48f896f13c2e329da87377499a,
1367,Search for Narrow tt Resonances in pp Collisions at s p 1 : 8 TeV,"Disclaimer/Complaints regulations If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. In case of a legitimate complaint, the Library will make the material inaccessible and/or remove it from the website. Please Ask the Library: http://uba.uva.nl/en/contact, or a letter to: Library of the University of Amsterdam, Secretariat, Singel 425, 1012 WP Amsterdam, The Netherlands. You will be contacted as soon as possible.",,https://www.semanticscholar.org/paper/432ed3ff9f04a513eaebb519df23769fe078c877,
1539,Optimization-based Causal Estimation from Heterogenous Environments,"This paper presents a new optimization approach to causal estimation. Given data that contains covariates and an outcome, which covariates are causes of the outcome, and what is the strength of the causality? In classical machine learning (ML), the goal of optimization is to maximize predictive accuracy. However, some covariates might exhibit a non-causal association to the outcome. Such spurious associations provide predictive power for classical ML, but they prevent us from causally interpreting the result. This paper proposes CoCo, an optimization algorithm that bridges the gap between pure prediction and causal inference. CoCo leverages the recently-proposed idea of environments, datasets of covariates/response where the causal relationships remain invariant but where the distribution of the covariates changes from environment to environment. Given datasets from multiple environments -- and ones that exhibit sufficient heterogeneity -- CoCo maximizes an objective for which the only solution is the causal solution. We describe the theoretical foundations of this approach and demonstrate its effectiveness on simulated and real datasets. Compared to classical ML and existing methods, CoCo provides more accurate estimates of the causal model.",2021-09-24,https://www.semanticscholar.org/paper/34ee368fc2f5de1a95d408811b809ae234c137bc,arXiv.org
142,Data acquisition and view planning for 3-D modeling tasks,"In this paper we address the joint problems of automated data acquisition and view planning for large-scale indoor and outdoor sites. Our method proceeds in two distinct stages. In the initial stage, the system is given a 2-D map with which it plans a minimal set of sufficient covering views. We then use a 3-D laser scanner to take scans at each of these views. When this planning system is combined with our mobile robot, it automatically computes and executes a tour of these viewing locations and acquires the views with the robot's onboard laser scanner. These initial scans serve as an approximate 3-D model of the site. The planning software then enters a second stage in which it updates this model by using a voxel-based occupancy procedure to plan the next best view. This next best view is acquired, and further next best views are sequentially computed and acquired until a complete 3-D model is obtained. Results are shown for Fort Jay on Governors Island in the City of New York and for the church of Saint Menoux in the Bourbonnais region of France.",2007-12-10,https://www.semanticscholar.org/paper/034bd82b3c3928facbe0f3a2fd6f3fb07d46ceed,2007 IEEE/RSJ International Conference on Intelligent Robots and Systems
3538,A brief introduction to C++'s model for type- and resource-safety,"You can write C++ programs that are statically type safe and have no resource leaks. You can do that simply, without loss of performance, and without limiting C++’s expressive power. This model for typeand resource-safe C++ has been implemented using a combination of ISO standard C++ language facilities, static analysis, and a tiny support library (written in ISO standard C++). This supports the general thesis that garbage collection is neither necessary nor sufficient for quality software. This paper describes the techniques used to eliminate dangling pointers and to ensure resource safety. Other aspects – also necessary for safe and effective use of C++ – have conventional solutions so they are mentioned only briefly here. The techniques and facilities presented are supported by the Core C++ Guidelines [Stroustrup,2015] and enforced by a static analysis tool for those [Sutter,2015].",,https://www.semanticscholar.org/paper/738ad38b3de6b717d53db522258d87a52c5a5654,
1437,Status and Results from the Cryogenic Dark Matter Search (CDMS),"The Cryogenic Dark Matter Search (CDMS) experiment utilizes novel cryogenic particle detectors for a direct search of dark matter particles in the form of WIMPs in our galaxy. The detectors are able to discriminate between nuclear and electron recoils through the simultaneous measurement of ionization and phonons. We report on the latest results from several kg-day exposure of Ge and Si detectors. Despite exposure times that are 100 times smaller than previous experiments, our sensitivity is comparable to the currently reported dark matter limits.",,https://www.semanticscholar.org/paper/c51d32daea7ebdb9044264d6ca3bcae070c30259,
2306,GTPγS-Stimulated Phospholipase D Activation in Human Neutrophils Occurs by Protein Kinase C-Dependent and -Independent Pathways but Not via Tyrosine Kinases,"Abstract Addition of GTPγS to saponin-permeabilised human neutrophils activated both the NADPH oxidase and phospholipase D (PLD). This PLD activation was hardly affected by staurosporine or Ro31-8220 (at concentrations which inhibited PMA stimulated PLD activity), indicating that it was largely independent of protein kinase C (PKC). This GTPγS stimulated PLD activity was enhanced by 1 mM ATP, but this ATP-enhanced activity was blocked by inhibitors of PKC. Addition of GTPγS resulted in very low levels of phosphorylation on tyrosine residues, but higher levels of phosphorylation on serine/threonine residues. Addition of pervanadate hydroperoxides stimulated phosphorylation on tyrosine residues and activated PLD which was blocked by addition of inhibitors of tyrosine kinases. Thus, GTPγS can stimulate PKC-dependent and -independent pathways of PLD activation. Whilst phosphorylation on tyrosine residues can result in activation of PLD, this is regulated independently of activation via G-proteins.",1996-03-27,https://www.semanticscholar.org/paper/9da51d0d2df10534dc7b0d8fa318afcffa483a4b,
3534,Lambda expressions and closures for C++,"This proposal describes a design for direct support for lambda expressions in C++. The design space for lambda expressions is large, and involves many tradeoffs. We include a thorough discussion of the benefits and the drawbacks of our design. In addition, we describe several other viable alternatives that warrant consideration.",,https://www.semanticscholar.org/paper/e7bd466d1c2b7fea00789fc6bef2e2abed3351f2,
3419,Introduction to Algorithms -3/Ed.,,2012-07-01,https://www.semanticscholar.org/paper/93e98d0c4cabd81bc2bfe61ce9d83c047be606ad,
2491,Message from the Paper Chairs and Guest Editors,"The IEEE Virtual Reality 2012 full papers program, contained in this special issue, includes 15 papers that present research, applications, and systems in the field of virtual reality. They were selected from 95 submissions by an international program committee of 63 members, supported by 147 external expert reviewers, leading to an acceptance rate for IEEE Virtual Reality 2012 of 15.8%. All papers appearing in this issue have undergone a two-round review process. In the first round review, at least four expert reviewers reviewed the work. The paper chairs selected the primary and secondary reviewers from the international program committee, and the primary reviewer then recruited at least two external experts. After completion of all reviews, the primary reviewer led an online discussion phase, which resulted in an initial recommendation for acceptance or rejection and a set of modifications that were deemed necessary. Based on this recommendation, the program committee, at the two-day online web meeting, selected an initial set of papers for preliminary acceptance. The authors of these papers were given the opportunity to refine and resubmit their work. In the second round review, IPC members checked whether the changes made were sufficient to warrant final acceptance. Based on their input, paper chairs made the final decisions for papers appearing in the TVCG issue. The IEEE VR scientific program also includes 13 short papers published in a separate report. Many individuals have contributed a great deal of time and energy to making the IEEE Virtual Reality 2012 conference and this special issue a success. We would like to thank the authors of all submitted papers, the members of the Program Committee, as well as all the other reviewers for their many hours of hard work. We also wish to acknowledge James Stewart for his outstanding and timely support with the PCS review system. This year, the Program Committee meeting was run under the Elluminate web conferencing system, access to which was graciously provided by University of Florida. We are grateful to Ben Lok for his help and his expertise with Elluminate. As usual, the paper chairs are indebted to the IEEE Visualization and Graphics Technical Committee (VGTC) publication team, especially the Publications Coordinator, Meghan Haley, for coordinating schedules, collecting materials, and producing these conference proceedings. We warmly thank the Virtual Reality steering committee, especially its chair Doug Bowman for his valuable advice at every stage, and Ming C. Lin, Editor-in-Chief …",,https://www.semanticscholar.org/paper/1c4ebd55bbe510738b1484adb99cdc3f80eafa8e,IEEE Transactions on Visualization and Computer Graphics
974,Two Cases of Double-layered Anterior Lens Capsule Found in Cataract Surgery,,2019-12-25,https://www.semanticscholar.org/paper/fd90f6654301bb1a6978e733cbc1d34299d45cd4,
3775,Do We Need More Training Data or Better Models for Object Detection?,"Datasets for training object recognition systems are steadily growing in size. This paper investigates the question of whether existing detectors will continue to improve as data grows, or if models are close to saturating due to limited model complexity and the Bayes risk associated with the feature spaces in which they operate. We focus on the popular paradigm of scanning-window templates defined on oriented gradient features, trained with discriminative classifiers. We investigate the performance of mixtures of templates as a function of the number of templates (complexity) and the amount of training data. We find that additional data does help, but only with correct regularization and treatment of noisy examples or “outliers” in the training data. Surprisingly, the performance of problem domain-agnostic mixture models appears to saturate quickly (∼10 templates and ∼100 positive training examples per template). However, compositional mixtures (implemented via composed parts) give much better performance because they share parameters among templates, and can synthesize new templates not encountered during training. This suggests there is still room to improve performance with linear classifiers and the existing feature space by improved representations and learning algorithms.",,https://www.semanticscholar.org/paper/4cb1494e547f1eaf51bab8038c8fab904dda9026,British Machine Vision Conference
614,Symmetric Space-Bounded Computation (Extended Abstract),,1980-07-14,https://www.semanticscholar.org/paper/0e6e6ad899f7f35dd294d73c8cd081f76f03f6ab,"International Colloquium on Automata, Languages and Programming"
1828,PUTOP: Turning Predominant Senses into a Topic Model for Word Sense Disambiguation,"We extend on McCarthy et al.'s predominant sense method to create an unsupervised method of word sense disambiguation that uses automatically derived topics using Latent Dirichlet allocation. Using topic-specific synset similarity measures, we create predictions for each word in each document using only word frequency information. It is hoped that this procedure can improve upon the method for larger numbers of topics by providing more relevant training corpora for the individual topics. This method is evaluated on SemEval-2007 Task 1 and Task 17.",2007-06-23,https://www.semanticscholar.org/paper/ad3ca6979f82d7926dfcae949b099b2aa36f3df1,International Workshop on Semantic Evaluation
2047,建構模糊決策樹及其在有交互作用之半導體資料之資料挖礦以提昇良率之研究; Construct Fuzzy Decision Tree for Mining Interrelated Semiconductor Manufacturing Data for Yield Enhancement,,,https://www.semanticscholar.org/paper/5ae585ff7c8a3ab3c83a7776c47dc19e4249ce84,
46,Efficient summarization-aware search for online news articles,"News portals gather and organize news articles published daily on the Internet. Typically, news articles are clustered into 'events' and each cluster is displayed with a short description of its contents. A particularly interesting choice for describing the contents of a cluster is a machine-generated multi-document summary of the articles in the cluster. Such summaries are informative and help news readers to identify and explore only clusters of interest. Naturally, multi-document clusters and summaries are also valuable to help users navigate the results of keyword-search queries. Unfortunately, current document summarizers are still slow; as a result, search strategies that define document clusters and their multi-document summaries online, in a query-specific manner, are prohibitively expensive. In contrast, search strategies that only return offline, query-independent document clusters are efficient, but might return clusters whose (query-independent) summaries are of little relevance to the queries. In this paper, we present an efficient Hybrid search strategy to address the limitations of fully online and fully offline summarization-aware search approaches. Extensive experiments involving user relevance judgments and real news articles show that the quality of our Hybrid results is high, and that these results are computed in substantially less time than with the fully online strategy. We have implemented our strategy and made it available on the Newsblaster news summarization system, which crawls and summarizes news articles from a variety of web sources on a daily basis.",2007-06-18,https://www.semanticscholar.org/paper/80b259d1f832a00c3f10c1aa477be1c1f85d7786,ACM/IEEE Joint Conference on Digital Libraries
1196,Search for Third Generation Scalar Leptoquarks Decaying to $\tau b$,We have searched for third generation leptoquarks (LQ3) using 1.05 inverse femtobarns of data collected with the D0 detector at the Fermilab Tevatron Collider operating at sqrt(s)=1.96 TeV. We set a 95% C.L. lower limit of 210 GeV on the mass of a scalar LQ3 state decaying solely to a b quark and a tau lepton.,2008-06-21,https://www.semanticscholar.org/paper/054f112ed765193e7bce54df999ec0d7c3fa39ef,
904,Permuting Elements Within Columns of a Matrix in Order to Minimize Maximum Row Sum,"We study the problem of permuting the elements within columns of a given m × n matrix A so as to minimize its maximum row sum (sum of the elements in a row). We introduce and analyze an approximation algorithm of greedy type for this NP-complete problem. We prove that our algorithm produces matrices with maximum row sums no more than 3/2 − 1/2m times greater than those found by an optimization rule. Moreover, examples are presented which achieve this relative performance. Thus, our algorithm represents a substantial improvement in that all earlier algorithms have a worst-case performance that is asymptotically twice that of an optimization rule. We verify that our algorithm requires at most O(m2n) time, which is a modest increase over the earlier algorithms requiring Θ(mn log n) time in the worst-case.",1984-08-01,https://www.semanticscholar.org/paper/dbed55666e673619435ab8bc32b3588dd0305456,Mathematics of Operations Research
1148,Search for neutral Higgs Bosons at high tanbeta in the b(h/H/A)-->btau;{+}tau;{-} channel.,"The first search in pp[over ] collisions at sqrt[s]=1.96 TeV for the production of neutral Higgs bosons in association with bottom quarks and decaying in two tau leptons is presented. The cross section for this process is enhanced in many extensions of the standard model, such as its minimal supersymmetric extension (MSSM) at large tanbeta. The data, corresponding to an integrated luminosity of 328 pb;{-1}, were collected with the D0 detector at the Fermilab Tevatron Collider. An upper limit is set on the production cross section of neutral Higgs bosons in the mass range of 90 to 150 GeV, and this limit is used to exclude part of the MSSM parameter space.",,https://www.semanticscholar.org/paper/2d2009e0f6024bc9da7cb8716322e827a46fe666,Physical Review Letters
1282,Search for Third-Generation Scalar Leptoquarks inCollisions at,,2007-08-06,https://www.semanticscholar.org/paper/822f2711efb89739f1ec7b08f5a799fd37b40ada,
1403,Search for Leptoquark Pairs Decaying into nn 1 jets in p ¯ p Collisions at p s 5 1.8 TeV,"V. M. Abazov,23 B. Abbott,57 A. Abdesselam,11 M. Abolins,50 V. Abramov,26 B. S. Acharya,17 D. L. Adams,59 M. Adams,37 S. N. Ahmed,21 G. D. Alexeev,23 A. Alton,49 G. A. Alves,2 N. Amos,49 E. W. Anderson,42 Y. Arnoud,9 C. Avila,5 M. M. Baarmand,54 V. V. Babintsev,26 L. Babukhadia,54 T. C. Bacon,28 A. Baden,46 B. Baldin,36 P. W. Balm,20 S. Banerjee,17 E. Barberis,30 P. Baringer,43 J. Barreto,2 J. F. Bartlett,36 U. Bassler,12 D. Bauer,28 A. Bean,43 F. Beaudette,11 M. Begel,53 A. Belyaev,35 S. B. Beri,15 G. Bernardi,12 I. Bertram,27 A. Besson,9 R. Beuselinck,28 V. A. Bezzubov,26 P. C. Bhat,36 V. Bhatnagar,15 M. Bhattacharjee,54 G. Blazey,38 F. Blekman,20 S. Blessing,35 A. Boehnlein,36 N. I. Bojko,26 F. Borcherding,36 K. Bos,20 T. Bose,52 A. Brandt,59 R. Breedon,31 G. Briskin,58 R. Brock,50 G. Brooijmans,36 A. Bross,36 D. Buchholz,39 M. Buehler,37 V. Buescher,14 V. S. Burtovoi,26 J. M. Butler,47 F. Canelli,53 W. Carvalho,3 D. Casey,50 Z. Casilum,54 H. Castilla-Valdez,19 D. Chakraborty,38 K. M. Chan,53 S. V. Chekulaev,26 D. K. Cho,53 S. Choi,34 S. Chopra,55 J. H. Christenson,36 M. Chung,37 D. Claes,51 A. R. Clark,30 L. Coney,41 B. Connolly,35 W. E. Cooper,36 D. Coppage,43 S. Crépé-Renaudin,9 M. A. C. Cummings,3,8 D. Cutts,58 G. A. Davis,53 K. Davis,29 K. De,59 S. J. de Jong,21 K. Del Signore,49 M. Demarteau,36 R. Demina,44 P. Demine,9 D. Denisov,36 S. P. Denisov,26 S. Desai,54 H. T. Diehl,36 M. Diesburg,36 S. Doulas,48 Y. Ducros,13 L. V. Dudko,25 S. Duensing,21 L. Duflot,11 S. R. Dugad,17 A. Duperrin,10 A. Dyshkant,38 D. Edmunds,50 J. Ellison,34 J. T. Eltzroth,59 V. D. Elvira,36 R. Engelmann,54 S. Eno,46 G. Eppley,61 P. Ermolov,25 O. V. Eroshin,26 J. Estrada,53 H. Evans,52 V. N. Evdokimov,26 T. Fahland,33 S. Feher,36 D. Fein,29 T. Ferbel,53 F. Filthaut,21 H. E. Fisk,36 Y. Fisyak,55 E. Flattum,36 F. Fleuret,12 M. Fortner,38 H. Fox,39 K. C. Frame,50 S. Fu,52 S. Fuess,36 E. Gallas,36 A. N. Galyaev,26 M. Gao,52 V. Gavrilov,24 R. J. Genik II,27 K. Genser,36 C. E. Gerber,37 Y. Gershtein,58 R. Gilmartin,35 G. Ginther,53 B. Gómez,5 G. Gómez,46 P. I. Goncharov,26 J. L. González Solís,19 H. Gordon,55 L. T. Goss,60 K. Gounder,36 A. Goussiou,28 N. Graf,55 G. Graham,46 P. D. Grannis,54 J. A. Green,42 H. Greenlee,36 Z. D. Greenwood,45 S. Grinstein,1 L. Groer,52 S. Grünendahl,36 A. Gupta,17 S. N. Gurzhiev,26 G. Gutierrez,36 P. Gutierrez,57 N. J. Hadley,46 H. Haggerty,36 S. Hagopian,35 V. Hagopian,35 R. E. Hall,32 P. Hanlet,48 S. Hansen,36 J. M. Hauptman,42 C. Hays,52 C. Hebert,43 D. Hedin,38 J. M. Heinmiller,37 A. P. Heinson,34 U. Heintz,47 M. D. Hildreth,41 R. Hirosky,62 J. D. Hobbs,54 B. Hoeneisen,8 Y. Huang,49 I. Iashvili,34 R. Illingworth,28 A. S. Ito,36 M. Jaffré,11 S. Jain,17 R. Jesik,28 K. Johns,29 M. Johnson,36 A. Jonckheere,36 H. Jöstlein,36 A. Juste,36 W. Kahl,44 S. Kahn,55 E. Kajfasz,10 A. M. Kalinin,23 D. Karmanov,25 D. Karmgard,41 R. Kehoe,50 A. Khanov,44 A. Kharchilava,41 S. K. Kim,18 B. Klima,36 B. Knuteson,30 W. Ko,31 J. M. Kohli,15 A. V. Kostritskiy,26 J. Kotcher,55 B. Kothari,52 A. V. Kotwal,52 A. V. Kozelov,26 E. A. Kozlovsky,26 J. Krane,42 M. R. Krishnaswamy,17 P. Krivkova,6 S. Krzywdzinski,36 M. Kubantsev,44 S. Kuleshov,24 Y. Kulik,54 S. Kunori,46 A. Kupco,7 V. E. Kuznetsov,34 G. Landsberg,58 W. M. Lee,35 A. Leflat,25 C. Leggett,30 F. Lehner,36,* C. Leonidopoulos,52 J. Li,59 Q. Z. Li,36 X. Li,4 J. G. R. Lima,3 D. Lincoln,36 S. L. Linn,35 J. Linnemann,50 R. Lipton,36 A. Lucotte,9 L. Lueking,36 C. Lundstedt,51 C. Luo,40 A. K. A. Maciel,3,8 R. J. Madaras,30 V. L. Malyshev,23 V. Manankov,25 H. S. Mao,4 T. Marshall,40 M. I. Martin,38 K. M. Mauritz,42 A. A. Mayorov,40 R. McCarthy,54 T. McMahon,56 H. L. Melanson,36 M. Merkin,25 K. W. Merritt,36 C. Miao,58 H. Miettinen,61 D. Mihalcea,38 C. S. Mishra,36 N. Mokhov,36 N. K. Mondal,17 H. E. Montgomery,36 R. W. Moore,50 M. Mostafa,1 H. da Motta,2 E. Nagy,10 F. Nang,29 M. Narain,47 V. S. Narasimham,17 N. A. Naumann,21 H. A. Neal,49 J. P. Negret,5 S. Negroni,10 T. Nunnemann,36 D. O’Neil,50 V. Oguri,3 B. Olivier,12 N. Oshima,36 P. Padley,61 L. J. Pan,39 K. Papageorgiou,37 A. Para,36 N. Parashar,48 R. Partridge,58 N. Parua,54 M. Paterno,53 A. Patwa,54 B. Pawlik,22 J. Perkins,59 O. Peters,20 P. Pétroff,11 R. Piegaia,1 B. G. Pope,50 E. Popkov,47 H. B. Prosper,35 S. Protopopescu,55 M. B. Przybycien,39,† J. Qian,49 R. Raja,36 S. Rajagopalan,55 E. Ramberg,36 P. A. Rapidis,36 N. W. Reay,44 S. Reucroft,48 M. Ridel,11 M. Rijssenbeek,54 F. Rizatdinova,44 T. Rockwell,50 M. Roco,36 C. Royon,13 P. Rubinov,36 R. Ruchti,41 J. Rutherfoord,29 B. M. Sabirov,23 G. Sajot,9 A. Santoro,2 L. Sawyer,45 R. D. Schamberger,54 H. Schellman,39 A. Schwartzman,1 N. Sen,61 E. Shabalina,37 R. K. Shivpuri,16 D. Shpakov,48 M. Shupe,29 R. A. Sidwell,44 V. Simak,7 H. Singh,34 J. B. Singh,15 V. Sirotenko,36 P. Slattery,53 E. Smith,57 R. P. Smith,36 R. Snihur,39 G. R. Snow,51 J. Snow,56 S. Snyder,55 J. Solomon,37 Y. Song,59 V. Sorín,1 M. Sosebee,59 N. Sotnikova,25 K. Soustruznik,6 M. Souza,2 N. R. Stanton,44 G. Steinbrück,52 R. W. Stephens,59 F. Stichelbaut,55 D. Stoker,33 V. Stolin,24 A. Stone,45 D. A. Stoyanova,26 M. A. Strang,59 M. Strauss,57 M. Strovink,30 L. Stutte,36 A. Sznajder,3 M. Talby,10 W. Taylor,54 S. Tentindo-Repond,35 S. M. Tripathi,31 T. G. Trippe,30",,https://www.semanticscholar.org/paper/fb14620f8e6e00454396f4627dadca99c32698a1,
2218,Analysis of SF and plasma cytokines provides insights into the mechanisms of inflammatory arthritis and may predict response to therapy.,"OBJECTIVES
Biologic drugs have revolutionized the care of RA, but are expensive and not universally effective. To further understand the inflammatory mechanisms underlying RA and identify potential biomarkers predicting response to therapy, we measured multiple cytokine concentrations in SF of patients with inflammatory arthritides (IAs) and, in a subset of patients with RA, correlated this with response to TNF-α inhibition.


METHODS
SF from 42 RA patients and 19 non-RA IA patients were analysed for 12 cytokines using a multiplex cytokine assay. Cytokines were also measured in the plasma of 16 RA patients before and following treatment with anti-TNF-α. Data were analysed using Mann-Whitney U-test, Spearman's rank correlation and cluster analysis with the Kruskal-Wallis test with Dunn's post-test analysis.


RESULTS
RA SF contained significantly elevated levels of IL-1β, IL-1ra, IL-2, IL-4, IL-8, IL-10, IL-17, IFN-γ, G-CSF, GM-CSF and TNF-α compared with other IA SF. RA patients who did not respond to anti-TNF therapy had elevated IL-6 in their SF pre-therapy (P < 0.05), whereas responders had elevated IL-2 and G-CSF (P < 0.05). Plasma cytokine concentrations were not significantly modulated by TNF inhibitors, with the exception of IL-6, which decreased after 12 weeks (P < 0.05).


CONCLUSIONS
Cytokine profiles in RA SF vary with treatment and response to therapy. Cytokine concentrations are significantly lower in plasma than in SF and relatively unchanged by TNF inhibitor therapy. Concentrations of IL-6, IL-2 and G-CSF in SF may predict response to TNF inhibitors.",2012-03-01,https://www.semanticscholar.org/paper/04673c6ede6b8c18a81ad3f99582b194b0327a16,Rheumatology
3055,Record and transplay: partial checkpointing for replay debugging across heterogeneous systems,"Software bugs that occur in production are often difficult to reproduce in the lab due to subtle differences in the application environment and nondeterminism. To address this problem, we present Transplay, a system that captures production software bugs into small per-bug recordings which are used to reproduce the bugs on a completely different operating system without access to any of the original software used in the production environment. Transplay introduces partial checkpointing, a new mechanism that efficiently captures the partial state necessary to reexecute just the last few moments of the application before it encountered a failure. The recorded state, which typically consists of a few megabytes of data, is used to replay the application without requiring the specific application binaries, libraries, support data, or the original execution environment. Transplay integrates with existing debuggers to provide standard debugging facilities to allow the user to examine the contents of variables and other program state at each source line of the application's replayed execution. We have implemented a Transplay prototype that can record unmodified Linux applications and replay them on different versions of Linux as well as Windows. Experiments with several applications including Apache and MySQL show that Transplay can reproduce real bugs and be used in production with modest recording overhead.",,https://www.semanticscholar.org/paper/ebdbd137674e8f1d077228c6cb9be23c213295aa,PERV
3164,Using Special-Purpose Computing to Examine Chaotic Behavior in Nonlinear Mappings,"Abstract : Most physical phenomena are nonlinear in nature and exhibit the complicated and seemingly random behavior known as chaos. Studying chaotic behavior in nonlinear systems requires numerous computations in order to simulate the behavior of such systems. The Standard Map Machine (SMM) was designed and implemented as a special computer for performing these intensive computations with high-speed and high-precision. SMM's impressive performance is due to its simple architecture specialized to the numerical computations required to nonlinear systems. This report discusses the design and implementation of the Standard Map Machine and its use in the study of nonlinear mappings, in particular, the study of the standard map.",1989-09-01,https://www.semanticscholar.org/paper/7dd65eb5d91f65e21ff1c8b85fbff6faa155ad6a,
1061,The LUX-ZEPLIN (LZ) experiment,,2019-10-21,https://www.semanticscholar.org/paper/a1d27c9d6784e1372056b39260dcd3710c1dbd19,"Nuclear Instruments and Methods in Physics Research Section A : Accelerators, Spectrometers, Detectors and Associated Equipment"
596,Is distributed locking harder?,"We examine the problem of determining whether a set of locked transactions, accessing a distributed database, is guaranteed to produce only serializable schedules. For a pair of transactions we prove that this concurrency control problem (which is polynomially solvable for centralized databases) is in general coNP-complete. We employ a new graph-theoretic technique and provide an efficient test for the special case of databases distributed between two sites only.",1982-03-29,https://www.semanticscholar.org/paper/a6e21280448a5adf4a6d3423837f5053f0ce59ed,Journal of computer and system sciences (Print)
1043,"101 golden rules of golf : wiles, wit and wisdom to inform and entertain","Golf is a mystery that sometimes pleases, sometimes frustrates, but always enthrals. Its nuances can take a lifetime to unravel and ""101 Golden Rules of Golf"" is the perfect companion for that journey - by turns fun and wise, frivolous and fascinating. Not only does the book include anecdotes about the glorious game that will bring a knowing smile to any golfer's face, it also provides valuable drills, hints, and lessons that will improve their game and reduce their handicap. Each of these pearls of wisdom is illustrated with a specially commissioned colour artwork to point you in the right direction. This charming giftbook is a must-have for all armchair and fairway golf enthusiasts - packed with hints, rules, and fascinating insights it's required reading for any golfer.",,https://www.semanticscholar.org/paper/feb686d88e00f626b113ad8241ba6efe0a661cbd,
2165,Internalization of Neutrophil-Derived Microvesicles Modulates TNFα-Stimulated Proinflammatory Cytokine Production in Human Fibroblast-Like Synoviocytes,"Neutrophil-derived microvesicles (NDMVs) have the potential to exert anti-inflammatory effects. Our study aimed to explore the effects of NDMVs on proinflammatory cytokines expressed by tumor necrosis factor α (TNFα)-stimulated fibroblast-like synoviocytes (FLS). FLS were isolated from the synovium of knee osteoarthritis (OA) patients undergoing surgery. NDMVs, isolated from TNFα-stimulated healthy neutrophils, were characterized by electron microscopy and nanoparticle tracking analysis. MTT and scratch wound healing assays were used to measure FLS viability and migration after treatment with NDMVs, while internalization of fluorescently labeled NDMVs was appraised by flow cytometry and confocal microscopy. Levels of proinflammatory cytokines in supernatants were quantified by the Bio-Plex system. Incubation of FLS with NDMVs at a vesicle/cell ratio of 100 resulted in a time-dependent uptake, with 35% of synoviocytes containing microvesicles over a 6–24 h time period, with no significant change in cell viability. TNFα stimulated the cytokine expression in FLS, and NDMVs down-regulated TNFα-induced expression of IL-5, IL-6, IL-8, MCP-1, IFNγ and MIP-1β. However, this down-regulation was selective, as NDMVs had no significant effects on TNFα-stimulated expression of IL-2 or IL-4. NDMVs were internalized by FLS to inhibit TNFα-stimulated broad-spectrum proinflammatory cytokine secretion. NDMVs, therefore, may exhibit an anti-inflammatory role in the regulation of the FLS function.",2021-07-01,https://www.semanticscholar.org/paper/73c5e6ff619e1037b4ee4fd4eac75932119d26d3,International Journal of Molecular Sciences
2493,Workshop 2: Classifying the AR presentation space,"Already 3D visualization environments provide a large design space not being investigated to the same extent as traditional WIMP-spaces. When using this design space in combination with AR, the design space even further grows. Information can not only be presented in a 3D space, AR also puts virtual information in relation to real objects, locations or events. The different properties of presentation in AR need to be investigated to develop a comprehensive set of dimensions of presentation principles.",2012-11-05,https://www.semanticscholar.org/paper/2b674383830eaf50f59399841907966dfbdf6635,International Symposium on Mixed and Augmented Reality
2936,Genetic regulation of gene expression and splicing during a 10-year period of human aging,,2019-11-04,https://www.semanticscholar.org/paper/e5440fdee0c0de339c5fa4507f0e6d9323b7c66f,Genome Biology
1104,Demonstration of surface electron rejection with interleaved germanium detectors for dark matter searches,"The SuperCDMS experiment in the Soudan Underground Laboratory searches for dark matter with a 9-kg array of cryogenic germanium detectors. Symmetric sensors on opposite sides measure both charge and phonons from each particle interaction, providing excellent discrimination between electron and nuclear recoils, and between surface and interior events. Surface event rejection capabilities were tested with two ^(210)Pb sources producing ∼130 beta decays/hr. In ∼800 live hours, no events leaked into the 8–115 keV signal region, giving upper limit leakage fraction 1.7 × 10^(−5) at 90% C.L., corresponding to < 0.6 surface event background in the future 200-kg SuperCDMS SNOLAB experiment.",2013-05-10,https://www.semanticscholar.org/paper/5135552ecf54aba57b4653b4b606f4083af7214a,
3453,LP decoding achieves capacity,"We give a linear programming (LP) decoder that achieves the capacity (optimal rate) of a wide range of probabilistic binary communication channels. This is the first such result for LP decoding. More generally, as far as the authors are aware this is the first known polynomial-time capacity-achieving decoder with the maximum-likelihood (ML) certificate property---where output codewords come with a proof of optimality. Additionally, this result extends the capacity-achieving property of expander codes beyond the binary symmetric channel to a larger family of communication channels.Perhaps most importantly, since LP decoding performs well in practice on turbo codes and low-density parity-check (LDPC) codes (comparable to the popular ""belief propagation"" algorithm), this result exhibits the power of a new, widely applicable ""dual witness"" technique (Feldman, Malkin, Servedio, Stein and Wainwright, ISIT '04) for bounding decoder performance.For expander codes over an adversarial channel, we prove that LP decoding corrects a constant fraction of errors. To show this, we provide a new combinatorial characterization of error events that is of independent interest, and which we expect will lead to further improvements.",2005-01-23,https://www.semanticscholar.org/paper/10197d1e071a5dc054c075a9856e1808b7613a05,ACM-SIAM Symposium on Discrete Algorithms
1326,Current and future searches for dark matter,Recent experimental data confirms that approximately one quarter of the universe consists of cold dark matter. Particle theories provide natural candidates for this dark matter in the form of either Axions or Weakly Interacting Massive Particles (WIMPs). A growing body of experiments is aimed at direct or indirect detection of particle dark matter. I summarize the current status of these experiments and offer projections of their future sensitivity.,2006-02-01,https://www.semanticscholar.org/paper/be50dc0c70560d1eaa17035c5a72d50a75bd0b3b,
3550,A Concept Design for the STL,"This report presents a concept design for the algorithms part of the STL and outlines the design of the supporting language mechanism. Both are radical simplifications of what was proposed in the C++0x draft. In particular, this design consists of only 41 concepts (including supporting concepts), does not require concept maps, and (perhaps most importantly) does not resemble template metaprogramming.",,https://www.semanticscholar.org/paper/a6aec2be2422b6c300f95b9c90a7b560b308e120,
1614,The Markov link method: a nonparametric approach to combine observations from multiple experiments,"This paper studies measurement linkage. An example from cell biology helps explain the problem: imagine for a given cell we can either sequence the cell’s RNA or we can examine its morphology, but not both. Given a cell’s morphology, what do we expect to see in its RNA? Given a cell’s RNA, what do we expect in its morphology? More broadly, given a measurement of one type, can we predict measurements of the other type? This measurement linkage problem arises in many scientific and technological fields. To solve this problem, we develop a nonparametric approach we dub the “Markov link method” (MLM). The MLM makes a conditional independence assumption that holds in many multi-measurement contexts and provides a a way to estimate the link, the conditional probability of one type of measurement given the other. We derive conditions under which the MLM estimator is consistent and we use simulated data to show that it provides accurate measures of uncertainty. We evaluate the MLM on real data generated by a pair of single-cell RNA sequencing techniques. The MLM characterizes the link between them and helps connect the two notions of cell type derived from each technique. Further, the MLM reveals that some aspects of the link cannot be determined from the available data, and suggests new experiments that would allow for better estimates.",2018-10-30,https://www.semanticscholar.org/paper/f3ec477307e0ea7840debfc8826af5fe22990ca4,bioRxiv
2766,Computer generation of pictorial explanations,"Although much work has been done on planning and generating textual explanations, relatively little attention has been devoted to automating the design of pictures that could be used to explain things. This thesis presents a three part conceptual architecture for generating pictorial explanations, such as maintenance and repair manuals, in which pictures play a crucial role. One part determines the material to be presented, for example, the solution to a maintenance and repair task. A second part plans the explanation, determines the spatial and temporal layout of the displays, and designs the pictures and text. A third part interfaces to rendering and typesetting software that scan-converts the displays. 
APEX (Automated Pictorial EXplanations) is a partial testbed implementation of the architecture. It can generate sequences of pictures that show how to perform simple actions, such as turning or pulling, in a world of 3D objects. Each picture crystallizes around those objects that participate directly in the action being depicted. Whether additional objects will be included and how they will be rendered are determined by the relationships that the objects bear to those already in the picture. For example, an object that is similar to one of the participating objects is added with enough detail to disambiguate it and is drawn with a rendering style intended to mark it as less important. 
Although APEX needs to depict objects at varying levels of detail, the original object database is a hierarchy with physical objects located only at the leaves. Selective display of leaves, however, will not produce effective pictures. A method for controlling the level of detail in a picture is presented in which the object hierarchy is processed to yield one whose internal nodes are associated with automatically created approximations of their children. Decisions made during the picture design process control the depth to which different parts of this hierarchy are traversed, determining the level of detail with which each part is rendered.",1987-07-01,https://www.semanticscholar.org/paper/3a53cf97c2f793b0e5bc4ad500c3b19a9884288c,
3588,Open multi-methods for c++,"Multiple dispatch - the selection of a function to be invoked based on the dynamic type of two or more arguments - is a solution to several classical problems in object-oriented programming. Open multi-methods generalize multiple dispatch towards open-class extensions, which improve separation of concerns and provisions for retroactive design. We present the rationale, design, implementation, and performance of a language feature, called open multi-methods, for C++. Our open multi-methods support both repeated and virtual inheritance. Our call resolution rules generalize both virtual function dispatch and overload resolution semantics. After using all information from argument types, these rules can resolve further ambiguities by using covariant return types. Great care was taken to integrate open multi-methods with existing C++ language features and rules. We describe a model implementation and compare its performance and space requirements to existing open multi-method extensions and workaround techniques for C++. Compared to these techniques, our approach is simpler to use, catches more user mistakes, and resolves more ambiguities through link-time analysis, runs significantly faster, and requires less memory. In particular, the runtime cost of calling an open multi method is constant and less than the cost of a double dispatch (two virtual function calls). Finally, we provide a sketch of a design for open multi-methods in the presence of dynamic loading and linking of libraries.",2007-10-01,https://www.semanticscholar.org/paper/3710838c07fca4a6e55af64b1a7d1c563e3f04a7,International Conference on Generative Programming: Concepts and Experiences
190,TFNP: An Update,,2017-05-24,https://www.semanticscholar.org/paper/b30712d457f99b58c15e1a6a27442bda56b0f100,International/Italian Conference on Algorithms and Complexity
1890,Empirical Study of Multi-Objective Parameter Optimization in Wire Bonding Process,"Wire bonding is one of the key processes which connects the wafer die and the lead frame in the IC packaging process. It is noted that process parameters influence both the speed and quality of bonding. Parameters, such as descending speed and cycles affect the bonding speed; while parameters such as bonding force and ultrasonic energy level affect the strength of joint. Both situations will affect the output (unit per hour, UPH), and lead to the variation of the production capacity as well.Nowadays, most companies in Taiwan still follow the rule of thumb when setting the process parameters. However, the large number of parameters in the bonding process makes it difficult for engineers to find appropriate parameters at once efficiently based on their experience only. When new products are introduced into mass production, engineers must go through multiple adjustments in a repeated trial and error way to find out the appropriate parameters, which takes lots of time, manpower and material resources.Using data mining techniques to establish predictive models for process parameters can not only increase the production capacity but also reduce the cost of the operation during adjustments. However, most studies in the field of wire bonding parameter optimization focused on increasing the bonding quality, while little consider the operation time and quality simultaneously. In this study, a data mining framework is proposed to extract the relationship between the bonding speed, bonding quality and the parameters.This study aims to increase production capacity by enhancing the bonding quality and the bonding speed simultaneously via recommending optimized process parameters. The proposed framework is based on a defect classification model constructed by random forest (RF) and extreme gradient boosting (XGBoost) method, and a multi-objective process parameters optimization model applying particle swarm optimization (PSO) method.An empirical study was conducted in a leading IC packaging and assembly company in Taiwan. The empirical result on 2 testing products reveals that the proposed approach increases the bonding quality by 70%, whereas the bonding speed is enhanced by 20%; overall, the proposed approach benefits output UPH by 26.6%, 5.0% for each product. Besides improving the production capacity, the proposed framework can also recommend parameters systematically and more quickly to enhance engineers’ parameter tuning efficiency on-line and achieve the goal of reducing the introduction time of new products.",2019-10-01,https://www.semanticscholar.org/paper/184270bd767757b255573120137f351c814905a3,Impact
1352,Measurement of inclusive differential cross sections for Y(1S) production in p p collisions at √s = 1.96 TeV,,,https://www.semanticscholar.org/paper/9c231b821d09e9e4fd74b39cfcace532f6ee030f,
2529,"Session details: Interacting with hands, eyes, and images",,2009-07-27,https://www.semanticscholar.org/paper/1a8ed39de75d588455b6a1df1fe8da9f2bebb6f6,ACM SIGGRAPH 2009 papers
410,Algorithmic aspects of protein structure similarity,"We show that calculating contact map overlap (a measure of similarity of protein structures) is NP-hard, but can be solved in polynomial time for several interesting and relevant special cases. We identify an important special case of this problem corresponding to self-avoiding walks, and prove a decomposition theorem and a corollary approximation result for this special case. These are the first approximation algorithms with guaranteed error bounds, and NP-completeness results in the literature in the area of protein structure alignment/fold recognition for measures of structure similarity of practical interest.",1999-10-17,https://www.semanticscholar.org/paper/92b2a92790e787b122741ef136d36c3737bdd445,40th Annual Symposium on Foundations of Computer Science (Cat. No.99CB37039)
478,The parallel complexity of simple logic programs,"We consider logic programs with a single recursive rules, whose right-hand side consists of binary relations forming a chain. We give a complete characterization of all programs of this form that are computable in NC (assuming that <italic>P</italic> <inline-equation> <f>≠</f> </inline-equation>). Our proof uses ideas from automata and language theory, and the combinatorics of strings.",1993-09-01,https://www.semanticscholar.org/paper/440b760f09081084667b1c6caf431381a55dcd08,JACM
1146,"Publisher's Note: Relative rates of B meson decays into {psi}(2S) and J/{psi} mesons [Phys. Rev. D 79, 111102 (2009)]",,2009-06-01,https://www.semanticscholar.org/paper/25af675b4badf4c97a1035f1300954c1132a66c4,
1519,An Invariant Learning Characterization of Controlled Text Generation,"Controlled generation refers to the problem of creating text that contains stylistic or semantic attributes of interest. Many approaches reduce this problem to training a predictor of the desired attribute. For example, researchers hoping to deploy a large language model to produce non-toxic content may use a toxicity classifier to filter generated text. In practice, the generated text to classify, which is determined by user prompts, may come from a wide range of distributions.In this paper, we show that the performance of controlled generation may be poor if the distributions of text in response to user prompts differ from the distribution the predictor was trained on. To address this problem, we cast controlled generation under distribution shift as an invariant learning problem: the most effective predictor should be invariant across multiple text environments. We then discuss a natural solution that arises from this characterization and propose heuristics for selecting natural environments.We study this characterization and the proposed method empirically using both synthetic and real data. Experiments demonstrate both the challenge of distribution shift in controlled generation and the potential of invariance methods in this setting.",2023-05-31,https://www.semanticscholar.org/paper/d95b441c2838888d7ac1af73b5f9c800f22fad3a,Annual Meeting of the Association for Computational Linguistics
3562,Introducing C++0x,"We have a draft for a revised ISO C++ standard, C++0x. I present the background for C++, its aims, a bit about the standards process (with opinions), some of the guiding principles (with tiny code examples), and a case study. This case study is concurrency support facilities (memory model, threads, locks and futures).",2010-11-10,https://www.semanticscholar.org/paper/5da1e30fffeb6d271424704d27900d88df8c30f7,
532,Why not negation by fixpoint?,"There is a fixpoint semantics for DATALOG programs with negation that is a natural generalization of the standard semantics for DATALOG programs without negation. We show that, unfortunately, several compelling complexity-theoretic obstacles rule out its efficient implementation. As an alternative, we propose Inflationary DATALOG, an efficiently implementable semantics for negation, based on inflationary fixpoints",1988-03-01,https://www.semanticscholar.org/paper/d0e7b3ebabb926f50846c75b9af7d25433c5a41e,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
1556,Markovian Score Climbing: Variational Inference with KL(p||q),"Modern variational inference (VI) uses stochastic gradients to avoid intractable expectations, enabling large-scale probabilistic inference in complex models. VI posits a family of approximating distributions $q$ and then finds the member of that family that is closest to the exact posterior $p$. Traditionally, VI algorithms minimize the ""exclusive KL"" KL$(q\|p)$, often for computational convenience. Recent research, however, has also focused on the ""inclusive KL"" KL$(p\|q)$, which has good statistical properties that makes it more appropriate for certain inference problems. This paper develops a simple algorithm for reliably minimizing the inclusive KL. Consider a valid MCMC method, a Markov chain whose stationary distribution is $p$. The algorithm we develop iteratively samples the chain $z[k]$, and then uses those samples to follow the score function of the variational approximation, $\nabla \log q(z[k])$ with a Robbins-Monro step-size schedule. This method, which we call Markovian score climbing (MSC), converges to a local optimum of the inclusive KL. It does not suffer from the systematic errors inherent in existing methods, such as Reweighted Wake-Sleep and Neural Adaptive Sequential Monte Carlo, which lead to bias in their final estimates. In a variant that ties the variational approximation directly to the Markov chain, MSC further provides a new algorithm that melds VI and MCMC. We illustrate convergence on a toy model and demonstrate the utility of MSC on Bayesian probit regression for classification as well as a stochastic volatility model for financial data.",2020-03-23,https://www.semanticscholar.org/paper/464c366ed20aa4c3fa57d71332dceb460586ed40,Neural Information Processing Systems
2611,An Evaluation of Automatically Generated Briefings of Patient Status,"We report on an evaluation of MAGIC, a system that automatically generates briefings of patient status after coronary bypass surgery, completed in the Cardio Thoracic Intensive Care Unit at New York Presbyterian Hospital. Through enhancements in system design, robustness and speed, we compared information obtained by nurses against two briefings, one automatically generated by MAGIC and one provided by physicians upon the patient's arrival to the ICU. Our results show that MAGIC and the physician briefing provide a substantial increase in the amount of information than is available prior to the patient's arrival and that the information MAGIC provides is accurate. In many aspects, MAGIC out-performs the physician briefing; information is reported earlier and is always available. We conclude that MAGIC provides the CT ICU staff early on with a better assessment of the patient's status than in current practice and allows them to better prepare for the patient's arrival.",,https://www.semanticscholar.org/paper/f1cb1e0c92dd7740e1b14fed663d99cb0b5a7b22,Medinfo
1891,A Machine Learning based Intelligent Agent for Human Resource Planning in IC Design Service Industry,"IC Design has been an industry which provides flexible application-specific integrated circuit (ASIC) services enabling semiconductor manufacturing companies for flexible decision. Although the industry influences semiconductor supply chain significantly, capacity portfolio and planning issues of IC design industry is seldom mentioned in the past studies. For IC design service industry, the main productivity denotes to IC design which is influenced by the performance of project management from workforce allocation. The purpose of this study is to develop an intelligent agent to predict the workforce required for each wafer production service project, and thus based on the prediction, the intelligent agent is able to provide an IC design service company with workforce allocation strategy. Featuring learning algorithms and analyzing from the existing data, the study trains a XG Boosting model combining Genetic Algorithm based parameter optimization mechanism. The proposed intelligent agent contributes to Total Resource Management (TRM) to enhance productivity, reduce costs and intelligence management.",,https://www.semanticscholar.org/paper/1b8abafa639da227a46f6d110e6a3e5302c23f34,
3761,Who is Mistaken?,"Recognizing when people have false beliefs is crucial for understanding their actions. We introduce the novel problem of identifying when people in abstract scenes have incorrect beliefs. We present a dataset of scenes, each visually depicting an 8-frame story in which a character has a mistaken belief. We then create a representation of characters' beliefs for two tasks in human action understanding: predicting who is mistaken, and when they are mistaken. Experiments suggest that our method for identifying mistaken characters performs better on these tasks than simple baselines. Diagnostics on our model suggest it learns important cues for recognizing mistaken beliefs, such as gaze. We believe models of people's beliefs will have many applications in action understanding, robotics, and healthcare.",2016-12-04,https://www.semanticscholar.org/paper/fac17d4bb7268bbf33290de2915c33e6e57647da,arXiv.org
1363,Search for supersymmetry with gauge-mediated breaking in diphoton events at D0.,"We report the results of a search for supersymmetry (SUSY) with gauge-mediated breaking in the missing transverse energy distribution of inclusive diphoton events using 263 pb(-1) of data collected by the D0 experiment at the Fermilab Tevatron Collider in 2002-2004. No excess is observed above the background expected from standard model processes, and lower limits on the masses of the lightest neutralino and chargino of about 108 and 195 GeV, respectively, are set at the 95% confidence level. These are the most stringent limits to date for models with gauge-mediated SUSY breaking with a short-lived neutralino as the next-to-lightest SUSY particle.",2004-08-30,https://www.semanticscholar.org/paper/0729fb5586404cf7f666dba612cea89b317f9d4b,Physical Review Letters
1719,"Build, Compute, Critique, Repeat: Data Analysis with Latent Variable Models","We survey latent variable models for solving data-analysis problems. A latent variable model is a probabilistic model that encodes hidden patterns in the data. We uncover these patterns from their conditional distribution and use them to summarize data and form predictions. Latent variable models are important in many fields, including computational biology, natural language processing, and social network analysis. Our perspective is that models are developed iteratively: We build a model, use it to analyze data, assess how it succeeds and fails, revise it, and repeat. We describe how new research has transformed these essential activities. First, we describe probabilistic graphical models, a language for formulating latent variable models. Second, we describe mean field variational inference, a generic algorithm for approximating conditional distributions. Third, we describe how to use our analyses to solve problems: exploring the data, forming predictions, and pointing us in the direction of improved mo...",2014-01-03,https://www.semanticscholar.org/paper/deda6f8719d751402307512dcf1fb2e4014010b5,
1900,Hybrid Particle Swarm Optimization Combined With Genetic Operators for Flexible Job-Shop Scheduling Under Uncertain Processing Time for Semiconductor Manufacturing,"Semiconductor manufacturing is a complicated flexible job-shop scheduling problem (FJSP) of combinatorial complexity. Because of the adoption of advanced process control and advanced equipment control, the processing time in advanced wafer fabs become uncertain. Existing approaches considering constant processing time may not be appropriate to address the present problem in a real setting. In practice, processing times can be represented as intervals with the most probable completion time somewhere near the middle of the interval. A fuzzy number that is a generalized interval can represent this processing time interval exactly and naturally. This paper developed a hybrid approach integrating a particle swarm optimization algorithm with a Cauchy distribution and genetic operators (HPSO+GA) for solving an FJSP by finding a job sequence that minimizes the makespan with uncertain processing time. In particular, the proposed hybridized HPSO+GA approach employs PSO for creating operation sequences and assigning the time and resources for each operation, and then uses genetic operators to update the particles for improving the solution. To estimate the validity of the proposed approaches, experiments were conducted to compare the proposed approach with conventional approaches. The results show the practical viability of this approach. This paper concludes with discussions of contributions and recommends directions for future research.",2018-02-01,https://www.semanticscholar.org/paper/22e3ff3ef15e892cc5edd3b493248a173fab5612,IEEE transactions on semiconductor manufacturing
3404,Extending Search Phases in the Micali-Vazirani Algorithm,"The Micali-Vazirani algorithm is an augmenting path algorithm that offers the best theoretical runtime of O(n0.5m) for solving the maximum cardinality matching problem for non-bipartite graphs. This paper builds upon the algorithm by focusing on the bottleneck caused by its search phase structure and proposes a new implementation that improves efficiency by extending the search phases in order to find more augmenting paths. Experiments on different types of randomly generated and real world graphs demonstrate this new implementation’s effectiveness and limitations. 1998 ACM Subject Classification G.2.2 Graph Theory, F.2.2 Nonnumerical Algorithms and Problems",,https://www.semanticscholar.org/paper/e6caff814bba9949fce6a48c76e3b158a8ddafbb,The Sea
3541,Open pattern matching for C++,"Pattern matching is an abstraction mechanism that can greatly simplify source code. We present functional-style pattern matching for C++ implemented as a library, called Mach71. All the patterns are user-definable, can be stored in variables, passed among functions, and allow the use of class hierarchies. As an example, we implement common patterns used in functional languages.
 Our approach to pattern matching is based on compile-time composition of pattern objects through concepts. This is superior (in terms of performance and expressiveness) to approaches based on run-time composition of polymorphic pattern objects. In particular, our solution allows mapping functional code based on pattern matching directly into C++ and produces code that is only a few percent slower than hand-optimized C++ code.
 The library uses an efficient type switch construct, further extending it to multiple scrutinees and general patterns. We compare the performance of pattern matching to that of double dispatch and open multi-methods in C++.",2014-03-05,https://www.semanticscholar.org/paper/391c58a1a7510f6c975d29349705b1058bb05efc,International Conference on Generative Programming: Concepts and Experiences
2606,An interaction system for watch computers using tactile guidance and bidirectional segmented strokes,"We introduce an input system that is based on bidirectional strokes that are segmented by tactile landmarks. By giving the user tactile feedback about the length of a stroke during input, we decrease the dependence of the GUI on the visual display. By concatenating separate strokes into multistrokes, complex commands may be entered, which may encode commands, data content, or both simultaneously. To demonstrate their power, we show how multistrokes can be used to traverse a menu hierarchy quickly. In addition, we show how inter-landmark segments of the sensor may be used for continuous and discrete parameter entry, resulting in a multifunctional interaction paradigm. We also introduce multiwidgets, which allow the direct control of multiple virtual widgets without the need to change the state of the device or use modifier buttons. This approach to input does not depend on material displayed visually to the user, and, thanks to tactile guidance, may be used by expert users as an eyes-free user interface. We believe that these benefits make this interaction system especially suitable for wearable computer systems that use a head-worn display and wrist-worn watch-style devices.",2004-10-31,https://www.semanticscholar.org/paper/ae56689440b28be8c442ec088a111c64424ff052,Eighth International Symposium on Wearable Computers
3199,Modeling Atlantic herring fisheries as multiscalar human-natural systems,,2021-04-01,https://www.semanticscholar.org/paper/e1a02a0639bcb8a634d1ba843dd717b85a286f7d,
3018,Protecting Cloud Virtual Machines from Hypervisor and Host Operating System Exploits,"Hypervisors are widely deployed by cloud computing providers to support virtual machines, but their growing complexity poses a security risk as large codebases contain many vulnerabilities. We have created HypSec, a new hypervisor design for retrofitting an existing commodity hypervisor using microkernel principles to reduce its trusted computing base while protecting the confidentiality and integrity of virtual machines. HypSec partitions the hypervisor into an untrusted host that performs most complex hypervisor functionality without access to virtual machine data, and a trusted core that provides access control to virtual machine data and performs basic CPU and memory virtualization. Hardware virtualization support is used to isolate and protect the trusted core and execute it at a higher privilege level so it can mediate virtual machine exceptions and protect VM data in CPU and memory. HypSec takes an end-to-end approach to securing I/O to simplify its design, with applications increasingly using secure network connections in the cloud. We have used HypSec to retrofit KVM, showing how our approach can support a widely-used full-featured hypervisor integrated with a commodity operating system. The implementation has a trusted computing base of only a few thousand lines of code, many orders of magnitude less than KVM. We show that HypSec protects the confidentiality and integrity of virtual machines running unmodified guest operating systems while only incurring modest performance overhead for real application workloads.",,https://www.semanticscholar.org/paper/6c5c5be93b58e417220e0841ed5da62d1e8c7b5b,USENIX Security Symposium
1669,Overdispersed Black-Box Variational Inference,"We introduce overdispersed black-box variational inference, a method to reduce the variance of the Monte Carlo estimator of the gradient in black-box variational inference. Instead of taking samples from the variational distribution, we use importance sampling to take samples from an overdispersed distribution in the same exponential family as the variational approximation. Our approach is general since it can be readily applied to any exponential family distribution, which is the typical choice for the variational approximation. We run experiments on two non-conjugate probabilistic models to show that our method effectively reduces the variance, and the overhead introduced by the computation of the proposal parameters and the importance weights is negligible. We find that our overdispersed importance sampling scheme provides lower variance than black-box variational inference, even when the latter uses twice the number of samples. This results in faster convergence of the black-box inference procedure.",2016-03-03,https://www.semanticscholar.org/paper/fccf3f8fea450a32a5c1f85e113127d70ed9ad7c,Conference on Uncertainty in Artificial Intelligence
3137,Limits of wide-area thin-client computing,"While many application service providers have proposed using thin-client computing to deliver computational services over the Internet, little work has been done to evaluate the effectiveness of thin-client computing in a wide-area network. To assess the potential of thin-client computing in the context of future commodity high-bandwidth Internet access, we have used a novel, non-invasive slow-motion benchmarking technique to evaluate the performance of several popular thin-client computing platforms in delivering computational services cross-country over Internet2. Our results show that using thin-client computing in a wide-area network environment can deliver acceptable performance over Internet2, even when client and server are located thousands of miles apart on opposite ends of the country. However, performance varies widely among thin-client platforms and not all platforms are suitable for this environment. While many thin-client systems are touted as being bandwidth efficient, we show that network latency is often the key factor in limiting wide-area thin-client performance. Furthermore, we show that the same techniques used to improve bandwidth efficiency often result in worse overall performance in wide-area networks. We characterize and analyze the different design choices in the various thin-client platforms and explain which of these choices should be selected for supporting wide-area computing services.",2002-06-01,https://www.semanticscholar.org/paper/229dbf2af37c45b151801851271559e0123aeb2f,Measurement and Modeling of Computer Systems
3384,Distributed Algorithms for Matching in Hypergraphs,,2020-09-21,https://www.semanticscholar.org/paper/71a42ecba04a76c376e767adbe8443afcf47bd62,Workshop on Approximation and Online Algorithms
1351,Background reduction in cryogenic detectors,"This paper discusses the background reduction and rejection strategy of the Cryogenic Dark Matter Search (CDMS) experiment. Recent measurements of background levels from CDMS II at Soudan are presented, along with estimates for future improvements in sensitivity expected for a proposed SuperCDMS experiment at SNOLAB.",2005-09-02,https://www.semanticscholar.org/paper/9a9bb5fba9e1ee8a4251ea02029aae2193daf591,
944,Node-and edge-deletion NP-complete problems,"If &pgr; is a graph property, the general node(edge) deletion problem can be stated as follows: Find the minimum number of nodes(edges), whose deletion results in a subgraph satisfying property &pgr;. In this paper we show that if &pgr; belongs to a rather broad class of properties (the class of properties that are hereditary on induced subgraphs) then the node-deletion problem is NP-complete, and the same is true for several restrictions of it. For the same class of properties, requiring the remaining graph to be connected does not change the NP-complete status of the problem; moreover for a certain subclass, finding any ""reasonable"" approximation is also NP-complete. Edge-deletion problems seem to be less amenable to such generalizations. We show however that for several common properties (e.g. planar, outer-planar, line-graph, transitive digraph) the edge-deletion problem is NP-complete.",1978-05-01,https://www.semanticscholar.org/paper/1855866d7433853989ed01cf3851a5d7d3c2b286,Symposium on the Theory of Computing
473,Motion Planning on a Graph (Extended Abstract),"We are given a connected. undirected graph G on n vertices. There is a mobile robot on one of the vertices; this vertex is labeled s. Each of several other vertices contains a single movable obsracle. The robot and the obstacles may only reside at vertices, although they may be moved across edges. A vertex may never contain more than one object (robot/obstacle). In one step, we may move either the robot or one of the obstacles from its current position to a vacant vertex adjacent to U. Our goal is to move the robot to a designated vertex t using the smallest number of steps possible. The problem is a simple abstraction of a robot motion planning problem. with the geometry replaced by the adjacencies in the graph. Wc point out its connections to robot motion planning. We study its complexity. giving exact and approximate algorithms for several cases.",,https://www.semanticscholar.org/paper/b0acd8d6d928657549da06735164c478afff34ae,IEEE Annual Symposium on Foundations of Computer Science
584,Proceedings of the fifteenth annual ACM symposium on Theory of computing,,1983-12-01,https://www.semanticscholar.org/paper/d55b456551771bdb5a4b2ddc942ecd1c7b6c162e,Symposium on the Theory of Computing
1133,Results from a low-energy analysis of the CDMS II germanium data.,"We report results from a reanalysis of data from the Cryogenic Dark Matter Search (CDMS II) experiment at the Soudan Underground Laboratory. Data taken between October 2006 and September 2008 using eight germanium detectors are reanalyzed with a lowered, 2 keV recoil-energy threshold, to give increased sensitivity to interactions from weakly interacting massive particles (WIMPs) with masses below ∼10  GeV/c(2). This analysis provides stronger constraints than previous CDMS II results for WIMP masses below 9  GeV/c(2) and excludes parameter space associated with possible low-mass WIMP signals from the DAMA/LIBRA and CoGeNT experiments.",2010-11-10,https://www.semanticscholar.org/paper/847a4c27c7119cb1ece4396714246b23270a9a83,Physical Review Letters
2796,Analysis of the intracellular role of galectins in cell growth and apoptosis.,,,https://www.semanticscholar.org/paper/8962f119f52770d58cb6059d6192ae40de658a66,Methods in molecular biology
3022,AnDrone,,2019-03-25,https://www.semanticscholar.org/paper/d67144e90c7efa4a656cadd0e38cf3328e7afc2b,Proceedings of the Fourteenth EuroSys Conference 2019
1814,Continuous Time Dynamic Topic Models,"In this paper, we develop the continuous time dynamic topic model (cDTM). The cDTM is a dynamic topic model that uses Brownian motion to model the latent topics through a sequential collection of documents, where a ""topic"" is a pattern of word use that we expect to evolve over the course of the collection. We derive an efficient variational approximate inference algorithm that takes advantage of the sparsity of observations in text, a property that lets us easily handle many time points. In contrast to the cDTM, the original discrete-time dynamic topic model (dDTM) requires that time be discretized. Moreover, the complexity of variational inference for the dDTM grows quickly as time granularity increases, a drawback which limits fine-grained discretization. We demonstrate the cDTM on two news corpora, reporting both predictive perplexity and the novel task of time stamp prediction.",2008-07-09,https://www.semanticscholar.org/paper/411277565d6182b40d301df1d2179f5c2b634bb3,Conference on Uncertainty in Artificial Intelligence
1868,A Topographic Latent Source Model for Fmri Data,"a r t i c l e i n f o We describe and evaluate a new statistical generative model of functional magnetic resonance imaging (fMRI) data. The model, topographic latent source analysis (TLSA), assumes that fMRI images are generated by a covariate-dependent superposition of latent sources. These sources are defined in terms of basis functions over space. The number of parameters in the model does not depend on the number of voxels, enabling a parsimonious description of activity patterns that avoids many of the pitfalls of traditional voxel-based approaches. We develop a multi-subject extension where latent sources at the subject-level are perturbations of a group-level template. We evaluate TLSA according to prediction, reconstruction and reproducibility. We show that it compares favorably to a Naive Bayes model while using fewer parameters. We also describe a hypothesis testing framework that can be used to identify significant latent sources. Introduction Most current approaches to functional magnetic resonance imaging (fMRI) take the basic spatial unit of analysis to be the voxel, and attempt to learn a set of parameters characterizing the voxel's response to a set of covariates (e.g., experimental manipulations). Traditionally, each voxel's response is assumed to be independent of all the other voxels, and is modeled as a linear function of the covariates convolved with a hemodynamic response function (Friston et al., 1994). Although this approach, which we refer to as the mass-univariate general linear model (MU-GLM), has been productive, it suffers from two shortcomings. First, the assumption that responses of voxels are independent of one another is rarely true, necessitating post-hoc correction procedures to account for these dependencies (Friston et al., 1996). Second, and more fundamentally, modeling neural responses at the voxel level does not enable direct inferences about what are arguably the variables of real interest, the responses of the underlying neuroanatomical regions. To sidestep this issue, regionally specific activations are typically extracted from the voxel-specific parameters by looking for spatially extended excursions from a null distribution (Worsley et al. More recently, two modeling trends have emerged that attempt to move beyond the mass-univariate GLM towards more realistic spatial assumptions. The first retains the GLM, but assumes that the parameters vary smoothly over voxels within a spatial neighborhood. The smoothness assumption is enforced in a Bayesian framework by encoding spatial dependencies between voxels in the prior (Woolrich et al. We refer to this approach as the spatially regularized GLM …",,https://www.semanticscholar.org/paper/387f273a54fd7b5795abd6ca6a6ec1acf8755b08,
2403,CYANIDE-INSENSITIVE RESPIRATION IN ACANTHAMOEBA CASTELLANII,,,https://www.semanticscholar.org/paper/813100280034d337427934ebd167cd332b70d2b2,
2206,A lack of confirmation with alternative assays questions the validity of IL-17A expression in human neutrophils using immunohistochemistry.,,2014-12-01,https://www.semanticscholar.org/paper/31a15d46e7b827789c555cf60e18741593ca33ef,Immunology Letters
2684,An analysis of COMET and MAGIC using the standard reference model for intelligent multimedia presentation systems,,1997-12-01,https://www.semanticscholar.org/paper/205405a599d124ac61946d47f83efa3d2a99ed98,Comput. Stand. Interfaces
2462,Combating VR sickness through subtle dynamic field-of-view modification,"Virtual Reality (VR) sickness can cause intense discomfort, shorten the duration of a VR experience, and create an aversion to further use of VR. High-quality tracking systems can minimize the mismatch between a user's visual perception of the virtual environment (VE) and the response of their vestibular system, diminishing VR sickness for moving users. However, this does not help users who do not or cannot move physically the way they move virtually, because of preference or physical limitations such as a disability. It has been noted that decreasing field of view (FOV) tends to decrease VR sickness, though at the expense of sense of presence. To address this tradeoff, we explore the effect of dynamically, yet subtly, changing a physically stationary person's FOV in response to visually perceived motion as they virtually traverse a VE. We report the results of a two-session, multi-day study with 30 participants. Each participant was seated in a stationary chair, wearing a stereoscopic head-worn display, and used control and FOV-modifying conditions in the same VE. Our data suggests that by strategically and automatically manipulating FOV during a VR session, we can reduce the degree of VR sickness perceived by participants and help them adapt to VR, without decreasing their subjective level of presence, and minimizing their awareness of the intervention.",2016-03-19,https://www.semanticscholar.org/paper/c2378b9809763e862533c1edd2771b1b68fde5ad,IEEE Symposium on 3D User Interfaces
1048,Enhancing the sensitivity of the LUX-ZEPLIN (LZ) dark matter experiment to low energy signals,"D.S. Akerib, 2 A.K. Al Musalhi, S.K. Alsum, C.S. Amarasinghe, A. Ames, 2 T.J. Anderson, 2 N. Angelides, H.M. Araújo, J.E. Armstrong, M. Arthurs, X. Bai, J. Balajthy, S. Balashov, J. Bang, J.W. Bargemann, D. Bauer, A. Baxter, P. Beltrame, E.P. Bernard, 16 A. Bernstein, A. Bhatti, A. Biekert, 16 T.P. Biesiadzinski, 2 H.J. Birch, G.M. Blockinger, B. Boxer, C.A.J. Brew, P. Brás, S. Burdin, J.K. Busenitz, M. Buuck, 2 R. Cabrita, M.C. Carmona-Benitez, M. Cascella, C. Chan, N.I. Chott, A. Cole, M.V. Converse, A. Cottle, 23 G. Cox, J.E. Cutter, C.E. Dahl, 23 L. de Viveiros, J.E.Y. Dobson, E. Druszkiewicz, S.R. Eriksen, A. Fan, 2 S. Fayer, N.M. Fearon, S. Fiorucci, H. Flaecher, E.D. Fraser, T. Fruth, R.J. Gaitskell, J. Genovesi, C. Ghag, E. Gibson, S. Gokhale, M.G.D. van der Grinten, C.B. Gwilliam, C.R. Hall, S.J. Haselschwardt, S.A. Hertel, M. Horn, D.Q. Huang, C.M. Ignarra, 2 O. Jahangir, R.S. James, W. Ji, 2 J. Johnson, A.C. Kaboth, 11 A.C. Kamaha, K. Kamdin, 15 K. Kazkaz, D. Khaitan, A. Khazov, I. Khurana, D. Kodroff, L. Korley, E.V. Korolkova, H. Kraus, S. Kravitz, L. Kreczko, B. Krikler, V.A. Kudryavtsev, E.A. Leason, K.T. Lesko, C. Levy, J. Li, J. Liao, J. Lin, 16 A. Lindote, R. Linehan, 2 W.H. Lippincott, 23 X. Liu, M.I. Lopes, E. Lopez Asamar, B. López Paredes, ∗ W. Lorenzon, S. Luitz, P.A. Majewski, A. Manalaysay, L. Manenti, R.L. Mannino, N. Marangou, M.E. McCarthy, D.N. McKinsey, 16 J. McLaughlin, E.H. Miller, 2 E. Mizrachi, 8 A. Monte, 23 M.E. Monzani, 2 J.A. Morad, J.D. Morales Mendoza, 2 E. Morrison, B.J. Mount, A.St.J. Murphy, D. Naim, A. Naylor, C. Nedlik, H.N. Nelson, F. Neves, J.A. Nikoleyczik, I. Olcina, 16 K.C. Oliver-Mallory, S. Pal, K.J. Palladino, 4 J. Palmer, N. Parveen, E.K. Pease, B. Penning, G. Pereira, A. Piepke, Y. Qie, J. Reichenbacher, C.A. Rhyne, A. Richards, Q. Riffard, 16 G.R.C. Rischbieter, R. Rosero, P. Rossiter, D. Santone, A.B.M.R. Sazzad, R.W. Schnee, P.R. Scovell, S. Shaw, T.A. Shutt, 2 J.J. Silk, C. Silva, R. Smith, 16 M. Solmaz, V.N. Solovov, P. Sorensen, I. Stancu, A. Stevens, K. Stifter, 2 B. Suerfu, 16 T.J. Sumner, N. Swanson, M. Szydagis, W.C. Taylor, R. Taylor, D.J. Temples, P.A. Terman, D.R. Tiedt, M. Timalsina, W.H. To, 2 M. Tripathi, D.R. Tronstad, W. Turner, U. Utku, A. Vaitkus, B. Wang, J.J. Wang, W. Wang, 27 J.R. Watson, 16 R.C. Webb, R.G. White, 2 T.J. Whitis, 1 M. Williams, F.L.H. Wolfs, D. Woodward, C.J. Wright, X. Xiang, J. Xu, M. Yeh, and P. Zarzhitsky SLAC National Accelerator Laboratory, Menlo Park, CA 94025-7015, USA Kavli Institute for Particle Astrophysics and Cosmology,",2021-01-21,https://www.semanticscholar.org/paper/d3db005ea3ed9332b83a0553f7b1bb531d9137f3,
2229,A POTENTIAL ROLE FOR INTERLEUKIN-6 IN THE PATHOGENESIS OF SYSTEMIC SCLEROSIS,"Barnes, Theresa Spiller, Dave Anderson, Marina Edwards, Steven Moots, Robert Annual Meeting of the British-Society-Rheumatology/Spring Meeting of British-Health-Professional-in-Rheumatology Apr 21-23, 2010 Birmingham, ENGLAND Suppl. 1",,https://www.semanticscholar.org/paper/2298ca514201840e5c22207c1ee57f7498d6a134,
2753,Near real-time shadow generation using BSP trees,"This paper describes an object-space shadow generation algorithm for static polygonal environments illuminated by movable point light sources. The algorithm can be easily implemented on any graphics system that provides fast polygon scan-conversion and achieves near real-time performance for environments of modest size. It combines elements of two kinds of current shadow generation algorithms: two-pass object-space approaches and shadow volume approaches. For each light source a Binary Space Partitioning (BSP) tree is constructed that represents the shadow volume of the polygons facing it. As each polygon's contribution to a light source's shadow volume is determined, the polygon's shadowed and lit fragments are computed by filtering it down the shadow volume BSP tree. The polygonal scene with its computed shadows can be rendered with any polygon-based visible-surface algorithm. Since the shadow volumes and shadows are computed in object space, they can be used for further analysis of the scene. Pseudocode is provided, along with pictures and timings from an interactive implementation.",1989-07-01,https://www.semanticscholar.org/paper/5a915172497f568e9e94071966cbccffe90439d2,International Conference on Computer Graphics and Interactive Techniques
3491,Exact and approximation algorithms for network flow and disjoint-path problems,"Network flow problems form a core area of Combinatorial Optimization. Their significance arises both from their very large number of applications and their theoretical importance. This thesis focuses on efficient exact algorithms for network flow problems in P and on approximation algorithms for NP-hard variants such as disjoint paths and unsplittable flow. 
Given an n-vertex, m-edge directed network G with real costs on the edges we give new algorithms to compute single-source shortest paths and the minimum mean cycle. Our algorithm is deterministic with $O(n\sp2$ log n) expected running time over a large class of input distributions. This is the first strongly polynomial algorithm in over 35 years to improve upon some aspect of the O(nm) running time of the Bellman-Ford shortest-path algorithm. 
In the single-source unsplittable flow problem, we are given a network G, a source vertex s and k commodities with sinks $t\sb{i}$ and real-valued demands $\rho\sb{i},\ 1\leq i \leq k$. We seek to route the demand $\rho\sb{i}$ of each commodity i along a single s-$t\sb{i}$ flow path, so that the total flow routed across any edge e is bounded by the edge capacity $u\sb{e}$. This NP-hard problem combines the difficulty of bin-packing with routing through an arbitrary graph and has many interesting and important variations. We give a generic framework, which yields approximation algorithms that are simpler than the previously known and achieve significant improvements upon the approximation ratios. 
In a packing integer program, we seek a vector x of integers, which maximizes $c\sp{T}{\cdot}x$, subject to $Ax\leq b,\ A,\ b,\ c\geq 0.$ The edge and vertex-disjoint path problems together with their multiple-source unsplittable flow generalization are NP-hard problems with a multitude of applications in areas such as routing, scheduling and bin packing. We explore the topic of approximating disjoint-path problems using polynomial-size packing integer programs. Motivated by the disjoint paths applications, we initiate the study of a class of packing integer programs, called column-restricted. We derive approximation algorithms for column-restricted packing integer programs that we believe are of independent interest.",,https://www.semanticscholar.org/paper/8edec23b4d9ed9d691469ff90016f2020ceb35cd,
3206,The non-invasive measurement of faecal immunoglobulin in African equids,,2020-05-18,https://www.semanticscholar.org/paper/3989fbbb1d30150cbc55ed211bd0f16bb956a2e9,International Journal for Parasitology: Parasites and Wildlife
2286,In vivo localisation and stability of human Mcl‐1 using green fluorescent protein (GFP) fusion proteins,,2000-07-28,https://www.semanticscholar.org/paper/6e228b663d66c0d20c96f599ecacbbc3afcc7bf0,FEBS Letters
753,Succinct approximate convex pareto curves,"We study the succinct approximation of convex Pareto curves of multiobjective optimization problems. We propose the concept of ε-convex Pareto (ε-CP) set as the appropriate one for the convex setting, and observe that it can offer arbitrarily more compact representations than ε-Pareto sets in this context. We characterize when an ε-CP can be constructed in polynomial time in terms of an efficient routine Comb for optimizing (exactly or approximately) monotone linear combinations of the objectives. We investigate the problem of computing minimum size ε-convex Pareto sets, both for discrete (combinatorial) and continuous (convex) problems, and present general algorithms using a Comb routine. For bi-objective problems, we show that if we have an exact Comb optimization routine, then we can compute the minimum ε-CP for continuous problems (this applies for example to bi-objective Linear Programming and Markov Decision Processes), and factor 2 approximation to the minimum ε-CP for discrete problems (this applies for example to bi-objective versions of polynomial-time solvable combinatorial problems such as Shortest Paths, Spanning Tree, etc.). If we have an approximate Comb routine, then we can compute factor 3 and 6 approximations respectively to the minimum ε-CP for continuous and discrete bi-objective problems. We consider also the case of three and more objectives and present some upper and lower bounds.",2008-01-20,https://www.semanticscholar.org/paper/c2870f43813bbff5d3c7d1276ece79816bc5ebe7,ACM-SIAM Symposium on Discrete Algorithms
833,Testing Finite-State Machines: State Identification and Verification,"We study the complexity of two fundamental problems in the testing of finite-state machines. 1) Distinguishing sequences (state identification). We show that it is PSPACE-complete to determine whether a finite-state machine has a preset distinguishing sequence. There are machines that have distinguishing sequences, but only of exponential length. We give a polynomial time algorithm that determines whether a finite-state machine has an adaptive distinguishing sequence. (The previous classical algorithms take exponential time.) Furthermore, if there is an adaptive distinguishing sequence, then we give an efficient algorithm that constructs such a sequence of length at most n(n/spl minus/1)/2 (which is the best possible), where n is the number of states. 2) Unique input output sequences (state verification). It is PSPACE-complete to determine whether a state of a machine has a unique input output sequence. There are machines whose states have unique input output sequences but only of exponential length. >",1994-03-01,https://www.semanticscholar.org/paper/7b66fa6b859eac503906e2147980d5b47ba4d814,IEEE Trans. Computers
982,Change of parapapillary atrophy during axial elongation - β-zone parapapillary atrophy induced by mechanical stretching: Boramae Myopia Cohort Study,,2018-07-13,https://www.semanticscholar.org/paper/ff5d1441522bb82e9edbe1e71b882fa3500458af,
2522,Experiences on Attention Direction through Manipulation of Salient Features,"In this paper we present a study on the impact on user’s fixations by localized modifications of the color properties of an image. We outline the technique used to influence the fixations of the participants, where it succeeded and where it failed. The question we address is whether pixel-wise modifications are sufficient to influence the order of fixations of the users and how strong this effect is. We developed a technique that performs localized adjustment in value, saturation and hue and conducted a user study with an eye tracker to asses its effectiveness. The results of our study imply that one can effectively influence the order and the duration of fixations of users based on localized adjustments.",,https://www.semanticscholar.org/paper/806c988662992534f3b976b937ee67ce030faff2,
3305,SEASONAL CHANGES IN THE FEEDING BEHAVIOUR OF FLOCKS OF SEEDEATERS AND GRASSQUITS,,2008-04-03,https://www.semanticscholar.org/paper/dff582ca7ab00d380940db753621c88da7abeee8,
1381,Observation and properties of the X(3872) decaying to J/psipi(+)pi(-) in pp collisions at sqrt[s]=1.96 TeV.,"We report the observation of the X(3872) in the J/psipi(+)pi(-) channel, with J/psi decaying to mu(+)mu(-), in pp collisions at sqrt[s]=1.96 TeV. Using approximately 230 pb(-1) of data collected with the Run II D0 detector, we observe 522+/-100 X(3872) candidates. The mass difference between the X(3872) state and the J/psi is measured to be 774.9+/-3.1(stat)+/-3.0(syst) MeV/c(2). We have investigated the production and decay characteristics of the X(3872) and find them to be similar to those of the psi(2S) state.",2004-05-04,https://www.semanticscholar.org/paper/f410d876f09095bc64cc696f3b4d748a018a62c8,Physical Review Letters
706,"Tarski's Theorem, Supermodular Games, and the Complexity of Equilibria","The use of monotonicity and Tarski's theorem in existence proofs of equilibria is very widespread in economics, while Tarski's theorem is also often used for similar purposes in the context of verification. However, there has been relatively little in the way of analysis of the complexity of finding the fixed points and equilibria guaranteed by this result. We study a computational formalism based on monotone functions on the $d$-dimensional grid with sides of length $N$, and their fixed points, as well as the closely connected subject of supermodular games and their equilibria. It is known that finding some (any) fixed point of a monotone function can be done in time $\log^d N$, and we show it requires at least $\log^2 N$ function evaluations already on the 2-dimensional grid, even for randomized algorithms. We show that the general Tarski problem of finding some fixed point, when the monotone function is given succinctly (by a boolean circuit), is in the class PLS of problems solvable by local search and, rather surprisingly, also in the class PPAD. Finding the greatest or least fixed point guaranteed by Tarski's theorem, however, requires $d\cdot N$ steps, and is NP-hard in the white box model. For supermodular games, we show that finding an equilibrium in such games is essentially computationally equivalent to the Tarski problem, and finding the maximum or minimum equilibrium is similarly harder. Interestingly, two-player supermodular games where the strategy space of one player is one-dimensional can be solved in $O(\log N)$ steps. We also observe that computing (approximating) the value of Condon's (Shapley's) stochastic games reduces to the Tarski problem. An important open problem highlighted by this work is proving a $\Omega(\log^d N)$ lower bound for small fixed dimension $d \geq 3$.",2019-09-07,https://www.semanticscholar.org/paper/a41a42b359497ef929f288ed06bac3fb2b6cbbc4,Information Technology Convergence and Services
394,Approximability and completeness in the polynomial hierarchy,,,https://www.semanticscholar.org/paper/4f8d597654e43b2cab27a58b682b05b942a2af57,
222,On the Computational Complexity of Limit Cycles in Dynamical Systems,"We study the Poincare-Bendixson theorem for two-dimensional continuous dynamical systems in compact domains from the point of view of computation, seeking algorithms for finding the limit cycle promised by this classical result. We start by considering a discrete analogue of this theorem and show that both finding a point on a limit cycle, and determining if a given point is on one, are PSPACE-complete. For the continuous version, we show that both problems are uncomputable in the real complexity sense; i.e., their complexity is arbitrarily high. Subsequently, we introduce a notion of an approximate cycle and prove an approximate Poincare-Bendixson theorem guaranteeing that some orbits come very close to forming a cycle in the absence of approximate fixpoints; surprisingly, it holds for all dimensions. The corresponding computational problem defined in terms of arithmetic circuits is PSPACE-complete.",2015-11-24,https://www.semanticscholar.org/paper/f05328b33d4b04161ef866194e923eeb61d2bcf1,Information Technology Convergence and Services
1581,Topic Modeling in Embedding Spaces,"Abstract Topic modeling analyzes documents to learn meaningful patterns of words. However, existing topic models fail to learn interpretable topics when working with large and heavy-tailed vocabularies. To this end, we develop the embedded topic model (etm), a generative model of documents that marries traditional topic models with word embeddings. More specifically, the etm models each word with a categorical distribution whose natural parameter is the inner product between the word’s embedding and an embedding of its assigned topic. To fit the etm, we develop an efficient amortized variational inference algorithm. The etm discovers interpretable topics even with large vocabularies that include rare words and stop words. It outperforms existing document models, such as latent Dirichlet allocation, in terms of both topic quality and predictive performance.",2019-07-08,https://www.semanticscholar.org/paper/d5f47453a6d00ede2881dfb65fc7ea141a50deeb,Transactions of the Association for Computational Linguistics
2885,"Expression and function of galectin-3, a beta-galactoside-binding lectin, in human monocytes and macrophages.","A family of beta-galactoside-binding animal lectins has recently been designated as galectins. One member of this family, galectin-3, has been known as epsilon BP for its IgE-binding activity and as Mac-2, a macrophage surface antigen, CBP35, CBP30, L-29, and L-34. Although much information has accumulated on the expression of this lectin in murine macrophages and human monocytic cell lines, little is known about the expression and function of this protein in normal human monocytes/macrophages. We now report that galectin-3 is expressed in normal human peripheral blood monocytes and its level increases dramatically as human monocytes differentiate into macrophages upon culturing in vitro. Immunoblot analysis showed that there was a 5-fold increase in the level of galectin-3 after 1 day of culture and greater than a 12-fold increase after 5 days. Immunocytochemical analysis confirmed this progressive increase of galectin-3 expression in cultured monocytes. Immunogold cytochemistry/electron microscopy analysis revealed that galectin-3 was expressed on the surface of human monocytes and that the level of cell surface galectin-3 increased progressively as these cells differentiated into macrophages. The level of galectin-3 in human monocytes/macrophages was modulated by stimuli such as lipopolysaccharide and interferon-gamma, and galectin-3 was secreted when monocytes were stimulated by calcium ionophore A23187 Soluble galectin-3 caused superoxide release from human monocytes; this activity was dependent on the lectin property of galectin-3, as it was inhibitable by lactose. Thus, galectin-3 may modulate the function of this cell type in an autocrine or paracrine fashion through binding to cell surface glycoconjugates.",1995-10-01,https://www.semanticscholar.org/paper/e0aff9505a9147b9cdbf025e9b05868712edbf77,American Journal of Pathology
2052,Modeling and analysis of semiconductor manufacturing in a shrinking world: Challenges and successes,"A panel session on the role of modeling and analysis in semiconductor manufacturing in a shrinking world is presented. Therefore, two participants are from Asia, two from Europe, and two from US and there are two panel organizers/ moderators (Fowler and Monch). One panelist from each continent is from industry and one from academia. Only initial position statements are included in the proceedings. However, these initial statements form the basis for the panel discussion. The statements of the panelists from industry relate to modeling and analysis problems found in their own companies. The position statements of the panelists from academia describe the role that modeling and analysis is expected to play in their current and ongoing research in semiconductor manufacturing. Furthermore, their views on the challenges and successes of modeling and analysis in a globalized world are also included.",2008-12-01,https://www.semanticscholar.org/paper/73e98a6f781d522b95d536c935fcc8409dbaa413,Online World Conference on Soft Computing in Industrial Applications
1141,"The Cryogenic Dark Matter Search (CDMS) experiment: Results, status and perspective","The Cryogenic Dark Matter Search experiment (CDMS) is using Phonon+Ionization detectors to search for Dark Matter in the form of Weakly Interactive Massive Particles (WIMPs). We report on new results from the operation of CDMS five “towers” at Soudan underground laboratory. With new and more massive detectors, SuperCDMS project has been started since March 2009. We report on the current status of SuperCDMS and its perspective.",2009-12-16,https://www.semanticscholar.org/paper/0596d575a165ec7cfeab4195b260998a29d9d39b,
1668,Bayesian Poisson Tucker Decomposition for Learning the Structure of International Relations,"We introduce Bayesian Poisson Tucker decomposition (BPTD) for modeling country--country interaction event data. These data consist of interaction events of the form ""country $i$ took action $a$ toward country $j$ at time $t$."" BPTD discovers overlapping country--community memberships, including the number of latent communities. In addition, it discovers directed community--community interaction networks that are specific to ""topics"" of action types and temporal ""regimes."" We show that BPTD yields an efficient MCMC inference algorithm and achieves better predictive performance than related models. We also demonstrate that it discovers interpretable latent structure that agrees with our knowledge of international relations.",2016-06-06,https://www.semanticscholar.org/paper/f2485ee93ef70bc307a418ec904271ebe54af76d,International Conference on Machine Learning
455,The Comparative Linguistics of Knowledge Representation,"We develop a methodology for comparing knowledge representation formalisms in terms of their ""representational succinctness,"" that is, their ability to express knowledge situations relatively efficiently. We use this framework for comparing many important formalisms for knowledge base representation: propositional logic, default logic, circumscription, and model preference defaults; and, at a lower level, Horn formulas, characteristic models, decision trees, disjunctive normal form, and conjunctive normal form. We also show that adding new variables improves the effective expressibility of certain knowledge representation formalisms.",1995-08-20,https://www.semanticscholar.org/paper/9fad50544027f4b7b6fd87fa145b6ae5cb0c310c,International Joint Conference on Artificial Intelligence
2746,Issues in the automated generation of animated presentations,"Much research in computer animation has concentrated on motion planning, ranging from high-level script design to low-level specification of how each character moves. Generating an animated presentation, however, also requires decisions about camera planning, the selection of what material should be shown and how it should be ordered, the maintenance of visual continuity, and viewport selection. If the presentation is to communicate informa,tion coherently, these decisions must be based in part on knowledge about the content domain and about filmmaking techniques. In this paper, we describe some of the principal techniques for generating good animated presentations, and point out some of the issues in developing systems that could apply these techniques automatically. Some of these issues are illustrated with examples made using ESPLANADE (Expert System for PLANning Animation Design and Editing) , a rule-based test bed that we are developing for exploring the automated generation of animated presentations.",1990-06-01,https://www.semanticscholar.org/paper/3b274db6f6541b764b9b55fdbafb886d753a2086,
2394,Changes in cytochrome levels during growth of the yeast-like fungusAureobasidium pullulans,,1981-05-01,https://www.semanticscholar.org/paper/9709bfbadb2aa7ece3b3b0340e87fcab02f82667,Current Microbiology
1082,Deposited in DRO : 01 December 2016 Version of attached le : Published Version Peer-review status of attached le :,"Agnese, R. and Anderson, A. J. and Balakishiyeva, D. and Thakur, R. Basu and Bauer, D. A. and Borgland, A. and Brink, P. L. and Bunker, R. and Cabrera, B. and Caldwell, D. O. and Cerdeno, D. G. and Chagani, H. and Cherry, M. and Cooley, J. and Cornell, B. and Crewdson, C.H. and Cushman, P. and Daal, M. and Di Stefano, P.C.F. and Do Couto E Silva, E. and Doughty, T. and Esteban, L. and Fallows, S. and Figueroa-Feliciano, E. and Fox, J. and Fritts, M. and Godfrey, G.L. and Golwala, S.R. and Hall, J. and Harris, H.R. and Hasi, J. and Hertel, S.A. and Hines, B.A. and Hofer, T. and Holmgren, D. and Hsu, L. and Huber, M.E. and Jastram, A. and Kamaev, O. and Kara, B. and Kelsey, M.H. and Kenany, S.A. and Kennedy, A. and Kenney, C.J. and Kiveni, M. and Koch, K. and Loer, B. and Lopez Asamar, E. and Mahapatra, R. and Mandic, V. and Martinez, C. and McCarthy, K.A. and Mirabolfathi, N. and Mo att, R.A. and Moore, D.C. and Nadeau, P. and Nelson, R.H. and Novak, L. and Page, K. and Partridge, R. and Pepin, M. and Phipps, A. and Prasad, K. and Pyle, M. and Qiu, H. and Radpour, R. and Rau, W. and Redl, P. and Reisetter, A. and Resch, R.W. and Ricci, Y. and Saab, T. and Sadoulet, B. and Sander, J. and Schmitt, R. and Schneck, K. and Schnee, R.W. and Scorza, S. and Seitz, D. and Serfass, B. and Shank, B. and Speller, D. and Tomada, A. and Villano, A.N. and Welliver, B. and Wright, D.H. and Yellin, S. and Yen, J.J. and Young, B.A. and Zhang, J. and The SuperCDMS Collaboration, (2013) 'Demonstration of surface electron rejection with interleaved germanium detectors for dark matter searches.', Applied physics letters., 103 (16). p. 164105.",,https://www.semanticscholar.org/paper/991844a9f99bb9edfeeb537c09aea2db80c3f431,
3598,Lock-Free Dynamically Resizable Arrays,,2006-12-12,https://www.semanticscholar.org/paper/a2975daae9ad05d9b1e084021ccb153d35cdf8dc,International Conference on Principles of Distributed Systems
1811,Multilingual Topic Models for Unaligned Text,"We develop the multilingual topic model for unaligned text (MuTo), a probabilistic model of text that is designed to analyze corpora composed of documents in two languages. From these documents, MuTo uses stochastic EM to simultaneously discover both a matching between the languages and multilingual latent topics. We demonstrate that MuTo is able to find shared topics on real-world multilingual corpora, successfully pairing related documents across languages. MuTo provides a new framework for creating multilingual topic models without needing carefully curated parallel corpora and allows applications built using the topic model formalism to be applied to a much wider class of corpora.",2009-06-18,https://www.semanticscholar.org/paper/b737b228865eefb4a5627d77a0c0984c64fb98ed,Conference on Uncertainty in Artificial Intelligence
1542,Unsupervised Representation Learning via Neural Activation Coding,"We present neural activation coding (NAC) as a novel approach for learning deep representations from unlabeled data for downstream applications. We argue that the deep encoder should maximize its nonlinear expressivity on the data for downstream predictors to take full advantage of its representation power. To this end, NAC maximizes the mutual information between activation patterns of the encoder and the data over a noisy communication channel. We show that learning for a noise-robust activation code increases the number of distinct linear regions of ReLU encoders, hence the maximum nonlinear expressivity. More interestingly, NAC learns both continuous and discrete representations of data, which we respectively evaluate on two downstream tasks: (i) linear classification on CIFAR-10 and ImageNet-1K and (ii) nearest neighbor retrieval on CIFAR-10 and FLICKR-25K. Empirical results show that NAC attains better or comparable performance on both tasks over recent baselines including SimCLR and DistillHash. In addition, NAC pretraining provides significant benefits to the training of deep generative models. Our code is available at https://github.com/yookoon/nac.",2021-12-07,https://www.semanticscholar.org/paper/5cdfc4fa6cf6a297599182a80f2460027070183b,International Conference on Machine Learning
3064,Mediapod: a pocket-Sized and Personalized Multimedia Desktop,"We present MediaPod, a portable system that allows mobile users to maintain the same persistent, personalized multimedia desktop environment on any available computer. Regardless of which computer is being used, MediaPod provides a consistent multimedia desktop session, maintaining all of a user's applications, documents and configuration settings. This is achieved by leveraging rapid improvements in capacity, cost, and size of portable storage devices. MediaPod provides a virtualization and checkpoint-restart mechanism that decouples a desktop environment and its applications from the host, enabling multimedia desktop sessions to be suspended to portable storage, carried around, and resumed from the storage device on another computer. MediaPod virtualization also isolates desktop sessions from the host, protecting the privacy of the user and preventing malicious applications from damaging the host. We have implemented a Linux MediaPod prototype and demonstrate its ability to quickly suspend and resume multimedia desktop sessions, enabling a seamless computing experience for mobile users as they move among computers.",2010-06-01,https://www.semanticscholar.org/paper/9b4df8b1d6894adf590e5a7e43c3588247ca7a7e,International Journal of Semantic Computing
391,Auditing Boolean attributes,"We study the problem of auditing databases which support statistical sum queries to protect the security of sensitive information; we focus on the special case in which the sensitive information is Boolean. Principles and techniques developed for the security of statistical database in the case of continuous attributes do not apply here. We prove certain strong complexity results suggesting that there is no general efficient solution for the auditing problem in this case. We propose two efficient algorithms: The first is applicable when the sum queries are one-dimensional range queries (we prove that the problem is NP-hard even in the two-dimensional case). The second is an approximate algorithm that maintains security, although it may be too restrictive. Finally, we consider a “dual” variant, with continuous data but an aggregate function that is combinatorial in nature. Specifically, we provide algorithms for two natural definitions of the auditing condition when the aggregate function is MAX.",2000-05-01,https://www.semanticscholar.org/paper/333a016bc00ff74da51ebf51f1c4f80298db7122,ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
520,The bisection width of grid graphs,,,https://www.semanticscholar.org/paper/ff4c5479bfc075b6829a9d5f2005cf26763af099,ACM-SIAM Symposium on Discrete Algorithms
2808,Galectin-3 regulates intracellular trafficking of epidermal growth factor receptor through Alix and promotes keratinocyte migration,,2012-07-06,https://www.semanticscholar.org/paper/7dab6ea0ddf6f7655ac9be008f73a9c36b520399,Journal of Investigative Dermatology
3458,Alenex workshop preface,,2005-12-01,https://www.semanticscholar.org/paper/9687f2597f13933dda307ee37bfac8f5c7689fb8,
1041,Problem statement and motivation,"Volume production at industrial scale of miniaturised multi-material 3D components or sub-components (polymer-polymer, metal-polymer, metal-metal, polymer-ceramics,...) still offers important challenges to overcome ( until now , the main effort has been focused on the development of high quality and accurate mass production/replication technologies for micro mono-material parts ), challenges not only in terms of precision manufacturing (precision engineering iniaturised components (micro injection moulding and hot-embossing ), although are quite developed technologies, would need an improvement (precision, high throughput,...) and also be part of a process chains which integrates additional technologies in order to be cost efficient and fulfil the requirements the market of microsystem-based products demands (new material combinations with complex geometric forms and increased functionalities).",,https://www.semanticscholar.org/paper/431336f7f719b62e776ece4282eaa2724832ab35,
3098,Understanding the management of client perceived response time,"Understanding and managing the response time of web services is of key importance as dependence on the World Wide Web continues to grow. We present Remote Latency-based Management (RLM), a novel server-side approach for managing pageview response times as perceived by remote clients, in real-time. RLM passively monitors server-side network traffic, accurately tracks the progress of page downloads and their response times in real-time, and dynamically adapts connection setup behavior and web page content as needed to meet response time goals. To manage client perceived pageview response times, RLM builds a novel event node model to guide the use of several techniques for manipulating the packet traffic in and out of a web server complex, including fast SYN and SYN/ACK retransmission, and embedded object removal and rewrite. RLM operates as a stand-alone appliance that simply sits in front of a web server complex, without any changes to existing web clients, servers, or applications. We have implemented RLM on an inexpensive, commodity, Linux-based PC and present experimental results that demonstrate its effectiveness in managing client perceived pageview response times on transactional e-commerce web workloads.",2006-06-26,https://www.semanticscholar.org/paper/9bd7e19452c102069042971617e0b7a10aeef8ce,SIGMETRICS '06/Performance '06
1708,Posterior predictive checks to quantify lack-of-fit in admixture models of latent population structure,"Significance Bayesian models, including admixture models, are a powerful framework for articulating complex assumptions about large-scale genetic data; such models are widely used to explore data or to study population-level statistics of interest. However, we assume that a Bayesian model does not oversimplify the complexities in the data, to the point of invalidating our analyses. Here, we develop and study procedures for quantitatively evaluating admixture models of genetic data. Using four large genetic studies, we demonstrate that model checking should be an important part of the modern genetic data analysis pipeline. Our methods help to support inferences drawn from recovered population structure, to protect scientists from being misled by a misspecified model class, and to point scientists toward useful model extensions. Admixture models are a ubiquitous approach to capture latent population structure in genetic samples. Despite the widespread application of admixture models, little thought has been devoted to the quality of the model fit or the accuracy of the estimates of parameters of interest for a particular study. Here we develop methods for validating admixture models based on posterior predictive checks (PPCs), a Bayesian method for assessing the quality of fit of a statistical model to a specific dataset. We develop PPCs for five population-level statistics of interest: within-population genetic variation, background linkage disequilibrium, number of ancestral populations, between-population genetic variation, and the downstream use of admixture parameters to correct for population structure in association studies. Using PPCs, we evaluate the quality of the admixture model fit to four qualitatively different population genetic datasets: the population reference sample (POPRES) European individuals, the HapMap phase 3 individuals, continental Indians, and African American individuals. We found that the same model fitted to different genomic studies resulted in highly study-specific results when evaluated using PPCs, illustrating the utility of PPCs for model-based analyses in large genomic studies.",2014-06-30,https://www.semanticscholar.org/paper/9df7ebe156cc341beb75b48e78b06d96ad86572c,Proceedings of the National Academy of Sciences of the United States of America
1432,Cryogenic Searches for Dark Matter,,1998-09-01,https://www.semanticscholar.org/paper/130911cd828ef0bde5554df260761c016c0f4dee,
3594,An Early-Reply Based Framework: Reliable Concurrency that Is Verifiable,"Despite its widespread use, concurrent programming is still plagued by reliability problems, such as race conditions and deadlock, not found in sequential programs. We present a concurrency framework to help developers avoid these error conditions, and make it possible to verify their absence through static analysis.",2007-11-14,https://www.semanticscholar.org/paper/cdaccb20f518fce93dc417fe13af130e1f48813f,IEEE International Symposium on High-Assurance Systems Engineering
3269,Maternal tactics for mitigating neonate predation risk during the postpartum period in Thomson’s gazelle,"The time immediately following birth is a period of high predation risk for ungulate neonates. Ungulate mothers exhibit perinatal behaviors that appear to mitigate offspring risk during this time. However, few studies of infant mortality include the postpartum period. Therefore, the function and effectiveness of these maternal behaviors are untested. We observed perinatal behavior in 11 Thomson’s gazelle (Eudorcas thomsoni) mother–infant pairs in a free-ranging population under predation pressure. Five of the six fawns that were detected by predators during the perinatal period were killed. Fawn survival therefore depended on avoiding detection by predators. Considered individually, neither prepartum isolation from conspecifics nor birth site selection affected the risk of being detected by a predator. However, analyses revealed two distinct perinatal tactics: mothers either isolated and gave birth in tall grass or remained in their social groups and gave birth in short grass. Both of these tactics resulted in lower risk of predator detection compared to behavior that was inconsistent with either tactic. The tactics represent a maternal trade-off between minimizing the duration of the highly vulnerable postpartum period and minimizing conspicuousness to predators.",,https://www.semanticscholar.org/paper/2595b220dc4c5e288ba50913bbf23061ffdf2ef2,
3039,KVM/ARM: the design and implementation of the linux ARM hypervisor,"As ARM CPUs become increasingly common in mobile devices and servers, there is a growing demand for providing the benefits of virtualization for ARM-based devices. We present our experiences building the Linux ARM hypervisor, KVM/ARM, the first full system ARM virtualization solution that can run unmodified guest operating systems on ARM multicore hardware. KVM/ARM introduces split-mode virtualization, allowing a hypervisor to split its execution across CPU modes and be integrated into the Linux kernel. This allows KVM/ARM to leverage existing Linux hardware support and functionality to simplify hypervisor development and maintainability while utilizing recent ARM hardware virtualization extensions to run virtual machines with comparable performance to native execution. KVM/ARM has been successfully merged into the mainline Linux kernel, ensuring that it will gain wide adoption as the virtualization platform of choice for ARM. We provide the first measurements on real hardware of a complete hypervisor using ARM hardware virtualization support. Our results demonstrate that KVM/ARM has modest virtualization performance and power costs, and can achieve lower performance and power costs compared to x86-based Linux virtualization on multicore hardware.",2014-02-24,https://www.semanticscholar.org/paper/ba9115479d13f06bb448b34310c026237b65a051,International Conference on Architectural Support for Programming Languages and Operating Systems
2515,Putting the Surface in Context Final Report 2009 – 2010,,,https://www.semanticscholar.org/paper/efd736c118336d821c6753f02d9d81d9b70ced51,
143,Two Stage View Planning for Large-Scale Site Modeling,"We present a systematic view planning method to assist construction of 3-D models of large outdoor sites using a mobile robot platform with mounted scanner. In the first stage, we begin with a 2-D site footprint and the planner generates a minimal set of sufficient covering views. These views which incorporate constraints on the scanner, including field of view, minimum and maximum scanning distance, and grazing angle, serve as the initial set of scans which yields an approximate 3-D model of the site. In the second stage, we update this model by using a voxel-based occupancy procedure to plan and acquire the next best view. The algorithm continues to update the model sequentially until an accurate and complete 3-D model is obtained. Results are shown for a segment of the Columbia University campus. The system can also be used as a planning tool for manual construction of 3-D site models.",2006-06-14,https://www.semanticscholar.org/paper/036124d58d5152f0e557f9d526473ecfb8ff93bc,3D Data Processing Visualization and Transmission
976,Effect of Nitric Oxide on Acanthamoeba castellanii.,"Purpose
Acanthamoeba keratitis is a well-known intractable corneal infectious disease. We investigated the anti-Acanthamoeba effect of exogenous nitric oxide (NO).


Methods
Acanthamoeba castellanii was axenically cultured and exposed to various concentrations of NO donors, such as sodium nitrite, sodium nitroprusside (SNP), and NO-releasing silica nanoparticles (coated in branched polyethylene imine, size:100 nm), for 1 to 7 days (sodium nitrite and SNP: 0, 0.1, 1, 10, 100, and 1000 μM; silica nanoparticles: 0, 6.25, 12.5, 25, 50, and 100 μg/mL). Human corneal epithelial cells (HCECs) were cultured and exposed to sodium nitrite, SNP (0, 0.1, 1, 10, 100, and 1000 μM), and silica nanoparticles for 1, 2, and 3 days.


Results
Sodium nitrite and SNP showed a dose-dependent inhibitory effect on A. castellanii viability. A more prominent inhibitory effect was observed with SNP (less than 10% of organisms survived at 7-day culture with 1000 μM) compared with sodium nitrite. However, more cytotoxicity on HCEC was observed with SNP. NO-releasing silica nanoparticles were successfully internalized into the amoebic cytoplasm and accumulated in large vacuoles. Although blank silica nanoparticles had no inhibitory effect on A. castellanii viability, NO-releasing silica nanoparticles showed a dose-dependent amoebicidal effect. Furthermore, no cystic transformation of A. castellanii was observed under a phase contrast microscope or transmission electron microscope after exogenous NO treatment.


Conclusions
Our results demonstrated the anti-Acanthamoeba effect of exogenous NO. This finding suggests that NO-releasing drug platforms, including nano-carriers, can be a promising therapeutic strategy for Acanthamoeba keratitis.",2018-07-02,https://www.semanticscholar.org/paper/1f192626400dd46c6eee42dc9710bfec3aa079fa,Investigative Ophthalmology and Visual Science
3640,Possible Directions for C++,,1993-09-07,https://www.semanticscholar.org/paper/37898643665993ab75c50e6e06c2cebe6626aa68,C++ Workshop
2169,"Rheumatoid Arthritis Synovial Fluid Neutrophils Drive Inflammation Through Production of Chemokines, Reactive Oxygen Species, and Neutrophil Extracellular Traps","Rheumatoid arthritis (RA) is a chronic inflammatory disorder affecting synovial joints. Neutrophils are believed to play an important role in both the initiation and progression of RA, and large numbers of activated neutrophils are found within both synovial fluid (SF) and synovial tissue from RA joints. In this study we analyzed paired blood and SF neutrophils from patients with severe, active RA (DAS28>5.1, n=3) using RNA-seq. 772 genes were significantly different between blood and SF neutrophils. IPA analysis predicted that SF neutrophils had increased expression of chemokines and ROS production, delayed apoptosis, and activation of signaling cascades regulating the production of NETs. This activated phenotype was confirmed experimentally by incubating healthy control neutrophils in cell-free RA SF, which was able to delay apoptosis and induce ROS production in both unprimed and TNFα primed neutrophils (p<0.05). RA SF significantly increased neutrophil migration through 3μM transwell chambers (p<0.05) and also increased production of NETs by healthy control neutrophils (p<0.001), including exposure of myeloperoxidase (MPO) and citrullinated histone-H3-positive DNA NETs. IPA analysis predicted NET production was mediated by signaling networks including AKT, RAF1, SRC, and NF-κB. Our results expand the understanding of the molecular changes that take place in the neutrophil transcriptome during migration into inflamed joints in RA, and the altered phenotype in RA SF neutrophils. Specifically, RA SF neutrophils lose their migratory properties, residing within the joint to generate signals that promote joint damage, as well as inflammation via recruitment and activation of both innate and adaptive immune cells. We propose that this activated SF neutrophil phenotype contributes to the chronic inflammation and progressive damage to cartilage and bone observed in patients with RA.",2020-07-19,https://www.semanticscholar.org/paper/3e9e7d8192ae3f5b9d88a2008447be689bab73b8,Frontiers in Immunology
2383,"Decrease in apparent K
m for oxygen after stimulation of respiration of rat polymorphonuclear leukocytes",,1983-09-05,https://www.semanticscholar.org/paper/8769c2bbce94889c9a1c2b85fa235a89420a1b87,FEBS Letters
389,On the value of private information,"As individuals increasingly take advantage of on-line services, the value of the private information they possess emerges as a problem of fundamental concern. We believe that the principle underlying privacy should be simple: Individuals are entitled to control the dissemination of private information, disclosing it as part of a transaction only when they are fairly compensated. We show how this principle can be made precise in several diverse settings --- in the use of marketing surveys by a vendor designing a product; and in the design of collaborative filtering and recommendation systems, where we seek to quantify the value of each user's participation. Our approach draws on the analysis of coalitional games, making use of the core and Shapley value of such games as fair allocation principles.",2001-07-08,https://www.semanticscholar.org/paper/eafe46f618bd2be380fe70b273123abb8118a747,
2378,Involvement of Adenosine 3':5'-Cyclic Monophosphate in the Yeast-Mycelium Transition of Aureobasidium pullulans,"Summary: The yeast-mycelium transition of Aureobasidium pullulans (IMI 45533) was induced by adenosine and adenosine 5'-monophosphate (AMP) in defined liquid medium. During the yeast-mycelium transition uptake of adenosine or AMP and transformation to adenosine 3’ :5'-cyclic monophosphate (cAMP) occurred; intracellular cAMP levels increased and maximum levels coincided with maximum germination. This, coupled with the findings that the cAMP phosphodiesterase inhibitors theophylline and caffeine also induced germination, indicated the involvement of cAMP in the regulation of the yeast-mycelium transition.",1985-07-01,https://www.semanticscholar.org/paper/f4526578d740a4e3fe7ed9fd54e8705e38f0b1f5,
3641,The Evolution of C++: 1985 to 1989,"The Ct+ Programming Language [Stroustrup 1986] describes Cr+ as defrned and implemented in August 1985. This paper describes the growth of the language since then and clarifies a few points in the defrnition. It is emphasized that these language modifications are extensions; Cr+ has been and will remain a stable language suitable for long term software development. The main new featurei of Cr-+ are: multiple inheritance, type-safe linkage, better resolution of overloaded functions, recuriive definition of assignment and initialization, better facilities for user-defrned memory management, abstract classes, static member functions, const member functions, protected members, overloading of operator ->, and pointers to members. These features are provided in the 2.0 release of Cr+. This paper is a revised and expanded version of a paper with a similar title. prer.iið¿ ""t the USENIX C++ Workshop in Sanla Fe, New Mexico, November 1987. @ Computing Systems,Vol. 2'No. 3'Summer 1989 191",1993-09-07,https://www.semanticscholar.org/paper/9e6edd54b7b46bc13cb38718ebbd1de01175f690,Computing Systems
871,ON THE COMPLEXITY OF LOCAL SEARCH (Extended Abstract),,,https://www.semanticscholar.org/paper/86e638c69caad65dbdc93690c8ee1be7f00ef528,Symposium on the Theory of Computing
3197,Stewardship of global collective behavior,"Collective behavior provides a framework for understanding how the actions and properties of groups emerge from the way individuals generate and share information. In humans, information flows were initially shaped by natural selection yet are increasingly structured by emerging communication technologies. Our larger, more complex social networks now transfer high-fidelity information over vast distances at low cost. The digital age and the rise of social media have accelerated changes to our social systems, with poorly understood functional consequences. This gap in our knowledge represents a principal challenge to scientific progress, democracy, and actions to address global crises. We argue that the study of collective behavior must rise to a “crisis discipline” just as medicine, conservation, and climate science have, with a focus on providing actionable insight to policymakers and regulators for the stewardship of social systems.",2021-06-21,https://www.semanticscholar.org/paper/ce5f44e3e62c3223629792fdd5c1e6c80deaac48,Proceedings of the National Academy of Sciences of the United States of America
2686,Top-down hierarchical planning of coherent visual discourse,"A visual discourse is a series of connected visual displays. A coherent visual discourse requires smooth transitions between displays, consistent design within and across displays, and successful integration of new information into existing displays. We present an approach for automatically designing a coherent visual discourse. A top-down, hierarchical-decomposition partial-order planner is used to efficiently plan the visual discourse. Visual representations are modelled as visual objects, graphical techniques are employed as planning operators, and design policies are encoded as constraints. This approach not only improves the computational efficiency compared to search-based approaches, but also facilitates knowledge encoding, and ensures global coherency.",1997-01-06,https://www.semanticscholar.org/paper/3836a4548a1ea682c54c5a425b112c19a946924d,International Conference on Intelligent User Interfaces
910,A polynomial algorithm for the MIN CUT linear arrangement of trees,An algorithm is presented which finds a min-cut linear arrangement of a tree in O(nlogn) time. An extension of the algorithm determines the number of pebbles needed to play the black and white pebble game on a tree.,1983-11-07,https://www.semanticscholar.org/paper/e706a00fffa188b409c40e3e13fc4a70330efbc9,24th Annual Symposium on Foundations of Computer Science (sfcs 1983)
1110,Experimental Limit on the Decay,"We set an upper limit on the branching fraction BR( T- -+ v 7 K- K 0 ) < 0.26% at the 95% confidence level. The data sample, obtained with the TPC/Two-Gamma detector facility at PEP, corresponds to an integrated luminosity of 144 pb- 1 taken at 29 GeV center of mass energy. The process T- -+ v 7 K- K 0 is related via SU(3) to the second-class current decay T- -+ V 7 11'-TJ. Our limit is nearly 20 times smaller than the recently reported branching fraction BR( T- -+ V 7 11'-TJ) of (5.1± 1.0±1.2)%, whereas SU(3) symmetry predicts the ratio of 11'TJ to K K production to be at most 5:1.",,https://www.semanticscholar.org/paper/f223dc61b689e4e0fd3a3b8cdb6e063fb291d621,
2908,"Correlation study on tensile properties of Cu, CuCrZr and W by small punch test and uniaxial tensile test",,2022-04-01,https://www.semanticscholar.org/paper/8d1d5ec9df0707f9193afa157f30cc33420226fd,Fusion engineering and design
1281,in the fully hadronic decay channel,,,https://www.semanticscholar.org/paper/81589c3d6565814aca6305823e201efe4a3997ac,
3162,Volume rendering on scalable shared-memory MIMD architectures,"Volume rendering is a useful visualization technique for understanding the large amounts of data generated in a variety of scientific disciplines. Routine use of this technique is currently limited by its computational expense. We have designed a parallel volume rendering algorithm for MIMD architectures based on ray tracing and a novel task queue image partitioning technique. The combination of ray tracing and MIMD architectures allows us to employ algorithmic optimizations such as hierarchical opacity enumeration, early ray termination, and adaptive image sampling. The use of task queue image partitioning makes these optimizations efficient in a parallel framework. We have implemented our algorithm on the Stanford DASH Multiprocessor, a scalable shared-memory MIMD machine. Its single address-space and coherent caches provide programming ease and good performance for our algorithm. With only a few days of programming effort, we have obtained nearly linear speedups and near real-time frame update rates on a 48 processor machine. Since DASH is constructed from Silicon Graphics multiprocessors, our code runs on any Silicon Graphics workstation without modification.",1992-12-01,https://www.semanticscholar.org/paper/f797376771e2ea038ba1ff496371dc7b615fbc3b,Symposium on Volume Visualization
1153,Measurement ofandProduction Cross Sections inCollisions at,,2009-05-12,https://www.semanticscholar.org/paper/4d3415a8339cb87916340f89196a0826fd74ee05,
401,Communication in hierarchies: explaining deadlines,,,https://www.semanticscholar.org/paper/e8faca3f8a4fef5c5598429732274ae262ca19ef,
270,Inapproximability for VCG-based combinatorial auctions,"The existence of incentive-compatible, computationally-efficient mechanisms for combinatorial auctions with good approximation ratios is the paradigmatic problem in algorithmic mechanism design. It is believed that, in many cases, good approximations for combinatorial auctions may be unattainable due to an inherent clash between truthfulness and computational efficiency. In this paper, we prove the first computational-complexity in-approximability results for incentive-compatible mechanisms for combinatorial auctions. Our results are tight, hold for the important class of VCG-based mechanisms, and are based on the complexity assumption that NP has no polynomial-size circuits. We show two different techniques to obtain such lower bounds: one for deterministic mechanisms that attains optimal dependence on the number of players and number of items, and one that also applies to a class of randomized mechanisms and attains optimal dependence on the number of players. Both techniques are based on novel VC dimension machinery.",2010-01-17,https://www.semanticscholar.org/paper/c64c1db9296224c95957d40882df1cbaffab63e3,ACM-SIAM Symposium on Discrete Algorithms
3080,The REmote Patient Education in a Telemedicine Environment Architecture (REPETE).,"The objective of the study was to develop and implement an architecture for remote training that can be used in the narrowband home telemedicine environment. A remote training architecture, the REmote Patient Education in a Telemedicine Environment (REPETE) architecture, using a remote control protocol (RCP) was developed. A set of design criteria was specified. The developed architecture was integrated into the IDEATel home telemedicine unit (HTU) and evaluated against these design criteria using a combination of technical and expert evaluations. Technical evaluation of the architecture demonstrated that remote cursor movements and positioning displayed on the HTU were smooth and effectively real-time. The trainers were able to observe within approximately 2 seconds lag what the patient sees on their HTU screen. Evaluation of the architecture by experts was favorable. Responses to a Likert scale questionnaire regarding audio quality and remote control performance indicated that the expert evaluators thought that the audio quality and remote control performance were adequate for remote training. All evaluators strongly agreed that the system would be useful for training patients. The REPETE architecture supports basic training needs over a narrowband dial-up connection. We were able to maintain an audio chat simultaneously with performing a remote training session, while maintaining both acceptable audio quality and remote control performance. The RCP provides a mechanism to provide training without requiring a trainer to go to the patient's home and effectively supports deictic referencing to on screen objects.",2008-05-01,https://www.semanticscholar.org/paper/8498a23215226060b06e8b694e359a32f4128695,Telemedicine journal and e-health
