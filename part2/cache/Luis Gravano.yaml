interactions:
- request:
    body: null
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - python-requests/2.31.0
    method: GET
    uri: https://api.semanticscholar.org/graph/v1/author/search?query=Luis%20Gravano&fields=affiliations,aliases,authorId,citationCount,externalIds,hIndex,homepage,name,paperCount,papers,papers.abstract,papers.authors,papers.citationCount,papers.corpusId,papers.externalIds,papers.fieldsOfStudy,papers.influentialCitationCount,papers.isOpenAccess,papers.journal,papers.openAccessPdf,papers.paperId,papers.publicationDate,papers.publicationTypes,papers.publicationVenue,papers.referenceCount,papers.s2FieldsOfStudy,papers.title,papers.url,papers.venue,papers.year,url&offset=0&limit=1000
  response:
    body:
      string: '{"total": 3, "offset": 0, "data": [{"authorId": "1684012", "externalIds":
        {"DBLP": ["Luis Gravano"]}, "url": "https://www.semanticscholar.org/author/1684012",
        "name": "L. Gravano", "aliases": ["L. Gravano", "Luis Gravano"], "affiliations":
        [], "homepage": null, "paperCount": 139, "citationCount": 13459, "hIndex":
        52, "papers": [{"paperId": "9fafc9896d2b81d1328791e4c2fd7ab096f155f3", "externalIds":
        {"ACL": "2021.socialnlp-1.4", "DBLP": "conf/acl-socialnlp/CaoLKHG21", "MAG":
        "3168872769", "DOI": "10.18653/V1/2021.SOCIALNLP-1.4", "CorpusId": 235097238},
        "corpusId": 235097238, "publicationVenue": {"id": "c9c1948f-4092-4a54-8e9a-a02519194626",
        "name": "International Workshop on Natural Language Processing for Social
        Media", "type": "conference", "alternate_names": ["SocialNLP", "Int Workshop
        Nat Lang Process Soc Media"]}, "url": "https://www.semanticscholar.org/paper/9fafc9896d2b81d1328791e4c2fd7ab096f155f3",
        "title": "Quantifying the Effects of COVID-19 on Restaurant Reviews", "abstract":
        "The COVID-19 pandemic has implications beyond physical health, affecting
        society and economies. Government efforts to slow down the spread of the virus
        have had a severe impact on many businesses, including restaurants. Mandatory
        policies such as restaurant closures, bans on social gatherings, and social
        distancing restrictions have affected restaurant operations as well as customer
        preferences (e.g., prompting a demand of stricter hygiene standards). As of
        now, however, it is not clear how and to what extent the pandemic has affected
        restaurant reviews, an analysis of which could potentially inform policies
        for addressing this ongoing situation. In this work, we present our efforts
        to understand the effects of COVID-19 on restaurant reviews, with a focus
        on Yelp reviews produced during the pandemic for New York City and Los Angeles
        County restaurants. Overall, we make the following contributions. First, we
        assemble a dataset of 600 reviews with manual annotations of fine-grained
        COVID-19 aspects related to restaurants (e.g., hygiene practices, service
        changes, sympathy and support for local businesses). Second, we address COVID-19
        aspect detection using supervised classifiers, weakly-supervised approaches
        based on keywords, and unsupervised topic modeling approaches, and experimentally
        show that classifiers based on pre-trained BERT representations achieve the
        best performance (F1=0.79). Third, we analyze the number and evolution of
        COVID-related aspects over time and show that the resulting time series have
        substantial correlation (Spearman\u2019s \\rho=0.84) with critical statistics
        related to the COVID-19 pandemic, including the number of new COVID-19 cases.
        To our knowledge, this is the first work analyzing the effects of COVID-19
        on Yelp restaurant reviews and could potentially inform policies by public
        health departments, for example, to cover resource utilization.", "venue":
        "International Workshop on Natural Language Processing for Social Media",
        "year": 2021, "referenceCount": 25, "citationCount": 7, "influentialCitationCount":
        2, "isOpenAccess": true, "openAccessPdf": {"url": "https://aclanthology.org/2021.socialnlp-1.4.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science", "Business"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Business",
        "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2021-06-01",
        "journal": {"pages": "36-60"}, "authors": [{"authorId": "2101321053", "name":
        "Ivy Cao"}, {"authorId": "103391392", "name": "Zizhou Liu"}, {"authorId":
        "8458211", "name": "Giannis Karamanolakis"}, {"authorId": "143724861", "name":
        "Daniel J. Hsu"}, {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId":
        "10b7e11424bd8778d4def8f0a4b2c5f2eff9a632", "externalIds": {"ACL": "2020.louhi-1.15",
        "DBLP": "journals/corr/abs-2010-05194", "ArXiv": "2010.05194", "MAG": "3098266722",
        "DOI": "10.18653/v1/2020.louhi-1.15", "CorpusId": 222291217}, "corpusId":
        222291217, "publicationVenue": {"id": "96bce4f4-d6bc-4b8f-8a7d-e343e9a5eb67",
        "name": "International Workshop on Health Text Mining and Information Analysis",
        "type": "conference", "alternate_names": ["Louhi", "Int Workshop Health Text
        Min Inf Anal"]}, "url": "https://www.semanticscholar.org/paper/10b7e11424bd8778d4def8f0a4b2c5f2eff9a632",
        "title": "Detecting Foodborne Illness Complaints in Multiple Languages Using
        English Annotations Only", "abstract": "Health departments have been deploying
        text classification systems for the early detection of foodborne illness complaints
        in social media documents such as Yelp restaurant reviews. Current systems
        have been successfully applied for documents in English and, as a result,
        a promising direction is to increase coverage and recall by considering documents
        in additional languages, such as Spanish or Chinese. Training previous systems
        for more languages, however, would be expensive, as it would require the manual
        annotation of many documents for each new target language. To address this
        challenge, we consider cross-lingual learning and train multilingual classifiers
        using only the annotations for English-language reviews. Recent zero-shot
        approaches based on pre-trained multi-lingual BERT (mBERT) have been shown
        to effectively align languages for aspects such as sentiment. Interestingly,
        we show that those approaches are less effective for capturing the nuances
        of foodborne illness, our public health application of interest. To improve
        performance without extra annotations, we create artificial training documents
        in the target language through machine translation and train mBERT jointly
        for the source (English) and target language. Furthermore, we show that translating
        labeled documents to multiple languages leads to additional performance improvements
        for some target languages. We demonstrate the benefits of our approach through
        extensive experiments with Yelp restaurant reviews in seven languages. Our
        classifiers identify foodborne illness complaints in multilingual reviews
        from the Yelp Challenge dataset, which highlights the potential of our general
        approach for deployment in health departments.", "venue": "International Workshop
        on Health Text Mining and Information Analysis", "year": 2020, "referenceCount":
        15, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": true,
        "openAccessPdf": {"url": "https://www.aclweb.org/anthology/2020.louhi-1.15.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle",
        "Review"], "publicationDate": "2020-10-11", "journal": {"pages": "138-146"},
        "authors": [{"authorId": "2145254149", "name": "Ziyi Liu"}, {"authorId": "8458211",
        "name": "Giannis Karamanolakis"}, {"authorId": "143724861", "name": "Daniel
        J. Hsu"}, {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "2c6161e57952eca8dabf25c1a48de1f40e2c9b5e",
        "externalIds": {"ACL": "2020.findings-emnlp.323", "DBLP": "conf/emnlp/Karamanolakis0G20",
        "ArXiv": "2010.02562", "MAG": "3103065189", "DOI": "10.18653/v1/2020.findings-emnlp.323",
        "CorpusId": 222142647}, "corpusId": 222142647, "publicationVenue": {"id":
        "479d5605-51be-4346-b1d6-4334084504df", "name": "Findings", "type": "journal",
        "issn": "2652-8800", "url": "https://findingspress.org/"}, "url": "https://www.semanticscholar.org/paper/2c6161e57952eca8dabf25c1a48de1f40e2c9b5e",
        "title": "Cross-Lingual Text Classification with Minimal Resources by Transferring
        a Sparse Teacher", "abstract": "Cross-lingual text classification alleviates
        the need for manually labeled documents in a target language by leveraging
        labeled documents from other languages. Existing approaches for transferring
        supervision across languages require expensive cross-lingual resources, such
        as parallel corpora, while less expensive cross-lingual representation learning
        approaches train classifiers without target labeled documents. In this work,
        we propose a cross-lingual teacher-student method, CLTS, that generates \u201cweak\u201d
        supervision in the target language using minimal cross-lingual resources,
        in the form of a small number of word translations. Given a limited translation
        budget, CLTS extracts and transfers only the most important task-specific
        seed words across languages and initializes a teacher classifier based on
        the translated seed words. Then, CLTS iteratively trains a more powerful student
        that also exploits the context of the seed words in unlabeled target documents
        and outperforms the teacher. CLTS is simple and surprisingly effective in
        18 diverse languages: by transferring just 20 seed words, even a bag-of-words
        logistic regression student outperforms state-of-the-art cross-lingual methods
        (e.g., based on multilingual BERT). Moreover, CLTS can accommodate any type
        of student classifier: leveraging a monolingual BERT student leads to further
        improvements and outperforms even more expensive approaches by up to 12% in
        accuracy. Finally, CLTS addresses emerging tasks in low-resource languages
        using just a small number of word translations.", "venue": "Findings", "year":
        2020, "referenceCount": 57, "citationCount": 15, "influentialCitationCount":
        1, "isOpenAccess": true, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/2020.findings-emnlp.323.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "2020-10-06", "journal": {"pages": "3604-3622"}, "authors":
        [{"authorId": "8458211", "name": "Giannis Karamanolakis"}, {"authorId": "143724861",
        "name": "Daniel J. Hsu"}, {"authorId": "1684012", "name": "L. Gravano"}]},
        {"paperId": "217be3119fe32cdfda39cec4af00ce646317d153", "externalIds": {"ACL":
        "D19-5501", "MAG": "2978262124", "DBLP": "journals/corr/abs-1910-00054", "ArXiv":
        "1910.00054", "DOI": "10.18653/v1/D19-5501", "CorpusId": 203610686}, "corpusId":
        203610686, "publicationVenue": {"id": "41bf9ed3-85b3-4c90-b015-150e31690253",
        "name": "Conference on Empirical Methods in Natural Language Processing",
        "type": "conference", "alternate_names": ["Empir Method Nat Lang Process",
        "Empirical Methods in Natural Language Processing", "Conf Empir Method Nat
        Lang Process", "EMNLP"], "url": "https://www.aclweb.org/portal/emnlp"}, "url":
        "https://www.semanticscholar.org/paper/217be3119fe32cdfda39cec4af00ce646317d153",
        "title": "Weakly Supervised Attention Networks for Fine-Grained Opinion Mining
        and Public Health", "abstract": "In many review classification applications,
        a fine-grained analysis of the reviews is desirable, because different segments
        (e.g., sentences) of a review may focus on different aspects of the entity
        in question. However, training supervised models for segment-level classification
        requires segment labels, which may be more difficult or expensive to obtain
        than review labels. In this paper, we employ Multiple Instance Learning (MIL)
        and use only weak supervision in the form of a single label per review. First,
        we show that when inappropriate MIL aggregation functions are used, then MIL-based
        networks are outperformed by simpler baselines. Second, we propose a new aggregation
        function based on the sigmoid attention mechanism and show that our proposed
        model outperforms the state-of-the-art models for segment-level sentiment
        classification (by up to 9.8% in F1). Finally, we highlight the importance
        of fine-grained predictions in an important public-health application: finding
        actionable reports of foodborne illness. We show that our model achieves 48.6%
        higher recall compared to previous models, thus increasing the chance of identifying
        previously unknown foodborne outbreaks.", "venue": "Conference on Empirical
        Methods in Natural Language Processing", "year": 2019, "referenceCount": 37,
        "citationCount": 8, "influentialCitationCount": 1, "isOpenAccess": true, "openAccessPdf":
        {"url": "https://www.aclweb.org/anthology/D19-5501.pdf", "status": null},
        "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle", "Conference", "Review"], "publicationDate":
        "2019-09-30", "journal": {"volume": "abs/1910.00054", "name": "ArXiv"}, "authors":
        [{"authorId": "8458211", "name": "Giannis Karamanolakis"}, {"authorId": "143724861",
        "name": "Daniel J. Hsu"}, {"authorId": "1684012", "name": "L. Gravano"}]},
        {"paperId": "7ab1f41d7bdfd9133167d92bca787fac888103cd", "externalIds": {"DBLP":
        "journals/corr/abs-1909-00415", "MAG": "2971994113", "ACL": "D19-1468", "ArXiv":
        "1909.00415", "DOI": "10.18653/v1/D19-1468", "CorpusId": 202537869}, "corpusId":
        202537869, "publicationVenue": {"id": "41bf9ed3-85b3-4c90-b015-150e31690253",
        "name": "Conference on Empirical Methods in Natural Language Processing",
        "type": "conference", "alternate_names": ["Empir Method Nat Lang Process",
        "Empirical Methods in Natural Language Processing", "Conf Empir Method Nat
        Lang Process", "EMNLP"], "url": "https://www.aclweb.org/portal/emnlp"}, "url":
        "https://www.semanticscholar.org/paper/7ab1f41d7bdfd9133167d92bca787fac888103cd",
        "title": "Leveraging Just a Few Keywords for Fine-Grained Aspect Detection
        Through Weakly Supervised Co-Training", "abstract": "User-generated reviews
        can be decomposed into fine-grained segments (e.g., sentences, clauses), each
        evaluating a different aspect of the principal entity (e.g., price, quality,
        appearance). Automatically detecting these aspects can be useful for both
        users and downstream opinion mining applications. Current supervised approaches
        for learning aspect classifiers require many fine-grained aspect labels, which
        are labor-intensive to obtain. And, unfortunately, unsupervised topic models
        often fail to capture the aspects of interest. In this work, we consider weakly
        supervised approaches for training aspect classifiers that only require the
        user to provide a small set of seed words (i.e., weakly positive indicators)
        for the aspects of interest. First, we show that current weakly supervised
        approaches fail to leverage the predictive power of seed words for aspect
        detection. Next, we propose a student-teacher approach that effectively leverages
        seed words in a bag-of-words classifier (teacher); in turn, we use the teacher
        to train a second model (student) that is potentially more powerful (e.g.,
        a neural network that uses pre-trained word embeddings). Finally, we show
        that iterative co-training can be used to cope with noisy seed words, leading
        to both improved teacher and student models. Our proposed approach consistently
        outperforms previous weakly supervised approaches (by 14.1 absolute F1 points
        on average) in six different domains of product reviews and six multilingual
        datasets of restaurant reviews.", "venue": "Conference on Empirical Methods
        in Natural Language Processing", "year": 2019, "referenceCount": 55, "citationCount":
        33, "influentialCitationCount": 2, "isOpenAccess": true, "openAccessPdf":
        {"url": "https://www.aclweb.org/anthology/D19-1468.pdf", "status": null},
        "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle", "Conference", "Review"], "publicationDate":
        "2019-09-01", "journal": {"volume": "abs/1909.00415", "name": "ArXiv"}, "authors":
        [{"authorId": "8458211", "name": "Giannis Karamanolakis"}, {"authorId": "143724861",
        "name": "Daniel J. Hsu"}, {"authorId": "1684012", "name": "L. Gravano"}]},
        {"paperId": "d76a010abcf1db4b687809393b0e6c2338249d1d", "externalIds": {"MAG":
        "2955405999", "CorpusId": 198330700}, "corpusId": 198330700, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/d76a010abcf1db4b687809393b0e6c2338249d1d",
        "title": "Training Neural Networks for Aspect Extraction Using Descriptive
        Keywords Only", "abstract": null, "venue": "", "year": 2019, "referenceCount":
        0, "citationCount": 2, "influentialCitationCount": 0, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Economics",
        "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate": "2019-03-14",
        "journal": {"volume": "", "name": ""}, "authors": [{"authorId": "8458211",
        "name": "Giannis Karamanolakis"}, {"authorId": "143724861", "name": "Daniel
        J. Hsu"}, {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "5da218d8f5303e1a93a17842b6762c6ea45fd7e8",
        "externalIds": {"MAG": "2811062641", "PubMedCentral": "6087902", "DOI": "10.5210/OJPHI.V10I1.8894",
        "CorpusId": 52050126}, "corpusId": 52050126, "publicationVenue": {"id": "aa4667d1-2b39-4535-843a-afe997710038",
        "name": "Online Journal of Public Health Informatics", "type": "journal",
        "alternate_names": ["Online J Public Health Informatics"], "issn": "1947-2579",
        "url": "http://www.uic.edu/htbin/cgiwrap/bin/ojs/index.php/ojphi", "alternate_urls":
        ["http://journals.uic.edu/ojphi", "https://journals.uic.edu/ojs/index.php/ojphi"]},
        "url": "https://www.semanticscholar.org/paper/5da218d8f5303e1a93a17842b6762c6ea45fd7e8",
        "title": "Evaluating Twitter for Foodborne Illness Outbreak Detection in New
        York City", "abstract": "Objective To incorporate data from Twitter into the
        New York City Department of Health and Mental Hygiene foodborne illness surveillance
        system and evaluate its utility and impact on foodborne illness complaint
        and outbreak detection. Introduction An estimated one in six Americans experience
        illness from the consumption of contaminated food (foodborne illness) annually;
        most are neither diagnosed nor reported to health departments 1 . Eating food
        prepared outside of the home is an established risk factor for foodborne illness
        2 . New York City (NYC) has approximately 24,000 restaurants and >8.5 million
        residents, of whom 78% report eating food prepared outside of the home at
        least once per week 3 . Residents and visitors can report incidents of restaurant-associated
        foodborne illness to a citywide non-emergency information service, 311. In
        2012, the NYC Department of Health and Mental Hygiene (DOHMH) began collaborating
        with Columbia University to improve the detection of restaurant-associated
        foodborne illness complaints using a machine learning algorithm and a daily
        feed of Yelp reviews to identify reports of foodborne illness 4 . Annually,
        DOHMH manages over 4,000 restaurant-associated foodborne illness reports received
        via 311 and identified on Yelp which lead to the detection of about 30 outbreaks
        associated with a restaurant in NYC. Given the small number of foodborne illness
        outbreaks identified, it is probable that many restaurant-associated foodborne
        illness incidents remain unreported. DOHMH sought to incorporate and evaluate
        an additional data source, Twitter, to enhance foodborne illness complaint
        and outbreak detection efforts in NYC. Methods DOHMH epidemiologists continue
        to collaborate with computer scientists at Columbia University who developed
        a text mining algorithm that identifies tweets indicating foodborne illness.
        Twitter data are received via a targeted application program interface query
        that searches for foodborne illness key words and uses metadata to select
        for tweets with a possible NYC location. Each tweet is assigned a sick score
        between 0\u20131; those meeting a threshold value of 0.5 are manually reviewed
        by an epidemiologist, and a survey link is tweeted to users who have tweeted
        about foodborne illness, requesting more information regarding the date and
        time of the foodborne illness event, restaurant details, and user contact
        information. Survey data are used to validate complaints and are incorporated
        in a daily analysis using all sources of complaint data to identify restaurants
        with multiple foodborne illness complaints within a 30-day period. This system
        was launched on November 29, 2016. Results During November 29, 2016\u2013September
        27, 2017, 12,015 tweets qualified for review (39/day on average); 2,288 (19.0%)
        indicated foodborne illness in NYC, and 1,778 (14.8%) were tweeted a survey
        link (510 foodborne illness tweets were either deleted by the Twitter user
        or were tweets from a user who was already sent a survey for the same foodborne
        illness incident). The survey tweets resulted in 92 likes, 12 retweets, 65
        replies, 232 profile views and 348 survey link clicks. Of the 1,778 surveys
        sent, 27 were completed (response rate 1.5%), of which 20 (74.7%) confirmed
        foodborne illness associated with a NYC restaurant; none had been reported
        via 311/Yelp. Of those, 11 (55%) provided a phone number, of which 10 (90.9%)
        completed phone interviews. The completed surveys contributed to the identification
        of two restaurants with multiple foodborne illness complaints within a 30-day
        period. Conclusions The utility of Twitter for foodborne illness outbreak
        detection continues to be evaluated. While the survey response rate has been
        low, the identification of new complaints not otherwise reported to 311 and
        Yelp suggests this will be a useful tool. Future plans include using feedback
        data collected by DOHMH epidemiologist review to increase the sensitivity
        and specificity of the text mining algorithm and improve the location detection
        for Twitter users. In addition, we plan to implement enhancements to the survey
        and create a web page to promote survey responses. Furthermore, we intend
        to share this system with other health departments so that they might incorporate
        Twitter in their outbreak detection and public health surveillance activities.
        References 1. Scallan E, Griffin PM, Angulo FJ, Tauxe RV, Hoekstra RM. Foodborne
        illness acquired in the United States--unspecified agents. Emerg Infect Dis.
        2011 Jan;17(1):16-22. 2. Jones TF, Angulo FJ. Eating in restaurants: a risk
        factor for foodborne disease? Clin Infect Dis. 2006 Nov 15;43(10):1324-8.
        3. New York City Health and Nutrition Examination Survey, 2013-2014 [Internet].
        New York: New York City Department of Health and Mental Hygiene and The City
        University of New York; 2017 [cited 2017 Aug 28]. Available from: http://nychanes.org/data/
        4. Harrison C, Jorder M, Stern H, Stavinsky F, Reddy V, Hanson H, Waechter
        H, Lowe L, Gravano L, Balter S; Centers for Disease Control and Prevention
        (CDC).. Using online reviews by restaurant patrons to identify unreported
        cases of foodborne illness - New York City, 2012-2013. MMWR Morb Mortal Wkly
        Rep. 2014 May 23;63(20):441-5.", "venue": "Online Journal of Public Health
        Informatics", "year": 2018, "referenceCount": 3, "citationCount": 3, "influentialCitationCount":
        0, "isOpenAccess": true, "openAccessPdf": {"url": "https://journals.uic.edu/ojs/index.php/ojphi/article/download/8894/7343",
        "status": null}, "fieldsOfStudy": ["Psychology"], "s2FieldsOfStudy": [{"category":
        "Psychology", "source": "external"}, {"category": "Medicine", "source": "s2-fos-model"}],
        "publicationTypes": ["Review"], "publicationDate": "2018-05-22", "journal":
        {"volume": "10", "name": "Online Journal of Public Health Informatics"}, "authors":
        [{"authorId": "32874656", "name": "Katelynn Devinney"}, {"authorId": "2078301324",
        "name": "Adile Bekbay"}, {"authorId": "3149900", "name": "Thomas Effland"},
        {"authorId": "1684012", "name": "L. Gravano"}, {"authorId": "2072509326",
        "name": "David Howell"}, {"authorId": "143724861", "name": "Daniel J. Hsu"},
        {"authorId": "1423391267", "name": "Daniel O\u2019Hallorhan"}, {"authorId":
        "145571127", "name": "V. Reddy"}, {"authorId": "5144868", "name": "Faina Stavinsky"},
        {"authorId": "4051940", "name": "H. Waechter"}, {"authorId": "9797851", "name":
        "B. Gutelius"}]}, {"paperId": "e5f24e69d39cb25b2c75a58213abdd427435efe3",
        "externalIds": {"MAG": "2783923625", "DBLP": "journals/jamia/EfflandLBDRWGH18",
        "DOI": "10.1093/jamia/ocx093", "CorpusId": 3516081, "PubMed": "29329402"},
        "corpusId": 3516081, "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/e5f24e69d39cb25b2c75a58213abdd427435efe3",
        "title": "Discovering foodborne illness in online restaurant reviews", "abstract":
        "Objective\nWe developed a system for the discovery of foodborne illness mentioned
        in online Yelp restaurant reviews using text classification. The system is
        used by the New York City Department of Health and Mental Hygiene (DOHMH)
        to monitor Yelp for foodborne illness complaints.\n\n\nMaterials and Methods\nWe
        built classifiers for 2 tasks: (1) determining if a review indicated a person
        experiencing foodborne illness and (2) determining if a review indicated multiple
        people experiencing foodborne illness. We first developed a prototype classifier
        in 2012 for both tasks using a small labeled dataset. Over years of system
        deployment, DOHMH epidemiologists labeled 13\u2009526 reviews selected by
        this classifier. We used these biased data and a sample of complementary reviews
        in a principled bias-adjusted training scheme to develop significantly improved
        classifiers. Finally, we performed an error analysis of the best resulting
        classifiers.\n\n\nResults\nWe found that logistic regression trained with
        bias-adjusted augmented data performed best for both classification tasks,
        with F1-scores of 87% and 66% for tasks 1 and 2, respectively.\n\n\nDiscussion\nOur
        error analysis revealed that the inability of our models to account for long
        phrases caused the most errors. Our bias-adjusted training scheme illustrates
        how to improve a classification system iteratively by exploiting available
        biased labeled data.\n\n\nConclusions\nOur system has been instrumental in
        the identification of 10 outbreaks and 8523 complaints of foodborne illness
        associated with New York City restaurants since July 2012. Our evaluation
        has identified strong classifiers for both tasks, whose deployment will allow
        DOHMH epidemiologists to more effectively monitor Yelp for foodborne illness
        investigations.", "venue": "J. Am. Medical Informatics Assoc.", "year": 2018,
        "referenceCount": 16, "citationCount": 37, "influentialCitationCount": 2,
        "isOpenAccess": true, "openAccessPdf": {"url": "https://academic.oup.com/jamia/article-pdf/25/12/1586/27090541/ocx093.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science", "Medicine"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Medicine",
        "source": "external"}, {"category": "Medicine", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2018-12-01",
        "journal": {"volume": "25", "pages": "1586\u20131592", "name": "Journal of
        the American Medical Informatics Association"}, "authors": [{"authorId": "3149900",
        "name": "Thomas Effland"}, {"authorId": "100554418", "name": "A. Lawson"},
        {"authorId": "4016664", "name": "S. Balter"}, {"authorId": "32874656", "name":
        "Katelynn Devinney"}, {"authorId": "145571127", "name": "V. Reddy"}, {"authorId":
        "4051940", "name": "H. Waechter"}, {"authorId": "1684012", "name": "L. Gravano"},
        {"authorId": "143724861", "name": "Daniel J. Hsu"}]}, {"paperId": "5242b843cd4543b575bd093d63711ef6cc8a9bad",
        "externalIds": {"DBLP": "journals/tods/PaparrizosG17", "MAG": "2622816133",
        "DOI": "10.1145/3044711", "CorpusId": 523464}, "corpusId": 523464, "publicationVenue":
        {"id": "e35a87a3-a6c4-47bf-acca-3e615ddb9c58", "name": "ACM Transactions on
        Database Systems", "type": "journal", "alternate_names": ["ACM Trans Database
        Syst"], "issn": "0362-5915", "url": "http://www.acm.org/pubs/contents/journals/tods/",
        "alternate_urls": ["http://tods.acm.org/", "http://www.acm.org/tods/", "http://portal.acm.org/tods",
        "https://tods.acm.org/"]}, "url": "https://www.semanticscholar.org/paper/5242b843cd4543b575bd093d63711ef6cc8a9bad",
        "title": "Fast and Accurate Time-Series Clustering", "abstract": "The proliferation
        and ubiquity of temporal data across many disciplines has generated substantial
        interest in the analysis and mining of time series. Clustering is one of the
        most popular data-mining methods, not only due to its exploratory power but
        also because it is often a preprocessing step or subroutine for other techniques.
        In this article, we present k-Shape and k-MultiShapes (k-MS), two novel algorithms
        for time-series clustering. k-Shape and k-MS rely on a scalable iterative
        refinement procedure. As their distance measure, k-Shape and k-MS use shape-based
        distance (SBD), a normalized version of the cross-correlation measure, to
        consider the shapes of time series while comparing them. Based on the properties
        of SBD, we develop two new methods, namely ShapeExtraction (SE) and MultiShapesExtraction
        (MSE), to compute cluster centroids that are used in every iteration to update
        the assignment of time series to clusters. k-Shape relies on SE to compute
        a single centroid per cluster based on all time series in each cluster. In
        contrast, k-MS relies on MSE to compute multiple centroids per cluster to
        account for the proximity and spatial distribution of time series in each
        cluster. To demonstrate the robustness of SBD, k-Shape, and k-MS, we perform
        an extensive experimental evaluation on 85 datasets against state-of-the-art
        distance measures and clustering methods for time series using rigorous statistical
        analysis. SBD, our efficient and parameter-free distance measure, achieves
        similar accuracy to Dynamic Time Warping (DTW), a highly accurate but computationally
        expensive distance measure that requires parameter tuning. For clustering,
        we compare k-Shape and k-MS against scalable and non-scalable partitional,
        hierarchical, spectral, density-based, and shapelet-based methods, with combinations
        of the most competitive distance measures. k-Shape outperforms all scalable
        methods in terms of accuracy. Furthermore, k-Shape also outperforms all non-scalable
        approaches, with one exception, namely k-medoids with DTW, which achieves
        similar accuracy. However, unlike k-Shape, this approach requires tuning of
        its distance measure and is significantly slower than k-Shape. k-MS performs
        similarly to k-Shape in comparison to rival methods, but k-MS is significantly
        more accurate than k-Shape. Beyond clustering, we demonstrate the effectiveness
        of k-Shape to reduce the search space of one-nearest-neighbor classifiers
        for time series. Overall, SBD, k-Shape, and k-MS emerge as domain-independent,
        highly accurate, and efficient methods for time-series comparison and clustering
        with broad applications.", "venue": "ACM Transactions on Database Systems",
        "year": 2017, "referenceCount": 127, "citationCount": 143, "influentialCitationCount":
        11, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "2017-06-01", "journal":
        {"volume": "42", "pages": "1 - 49", "name": "ACM Transactions on Database
        Systems (TODS)"}, "authors": [{"authorId": "2516699", "name": "John Paparrizos"},
        {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "b358851d198a0fe1797bdcae52cf625c10b68986",
        "externalIds": {"MAG": "2559989503", "DBLP": "journals/ipm/0002G17", "DOI":
        "10.1016/j.ipm.2016.11.006", "CorpusId": 17881617}, "corpusId": 17881617,
        "publicationVenue": {"id": "37f5b9b7-f828-4ae1-a174-45b538cbd4e4", "name":
        "Information Processing & Management", "type": "journal", "alternate_names":
        ["Inf Process Manag", "Inf Process  Manag", "Information Processing and Management"],
        "issn": "0306-4573", "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/244/description#description",
        "alternate_urls": ["https://www.journals.elsevier.com/information-processing-and-management/",
        "http://www.sciencedirect.com/science/journal/03064573", "http://www.journals.elsevier.com/information-processing-and-management/"]},
        "url": "https://www.semanticscholar.org/paper/b358851d198a0fe1797bdcae52cf625c10b68986",
        "title": "Sampling strategies for information extraction over the deep web",
        "abstract": null, "venue": "Information Processing & Management", "year":
        2017, "referenceCount": 67, "citationCount": 9, "influentialCitationCount":
        0, "isOpenAccess": true, "openAccessPdf": {"url": "http://manuscript.elsevier.com/S0306457316306318/pdf/S0306457316306318.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "2017-03-01", "journal": {"volume": "53", "pages": "309-331",
        "name": "Inf. Process. Manag."}, "authors": [{"authorId": "2065995286", "name":
        "Pablo Barrio"}, {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId":
        "229f87832bc93cc4a4ba9a228e33135799dcf4bf", "externalIds": {"DBLP": "journals/sigmod/PaparrizosG16",
        "DOI": "10.1145/2949741.2949758", "CorpusId": 52862551}, "corpusId": 52862551,
        "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/229f87832bc93cc4a4ba9a228e33135799dcf4bf",
        "title": "k-Shape: Efficient and Accurate Clustering of Time Series", "abstract":
        "The proliferation and ubiquity of temporal data across many disciplines has
        generated substantial interest in the analysis and mining of time series.
        Clustering is one of the most popular data mining methods, not only due to
        its exploratory power, but also as a preprocessing step or subroutine for
        other techniques. In this paper, we describe k-Shape, a novel algorithm for
        time-series clustering. k-Shape relies on a scalable iterative refinement
        procedure, which creates homogeneous and well-separated clusters. As its distance
        measure, k-Shape uses a normalized version of the cross-correlation measure
        in order to consider the shapes of time series while comparing them. Based
        on the properties of that distance measure, we develop a method to compute
        cluster centroids, which are used in every iteration to update the assignment
        of time series to clusters. An extensive experimental evaluation against partitional,
        hierarchical, and spectral clustering methods, with the most competitive distance
        measures, showed the robustness of k-Shape. Overall, k-Shape emerges as a
        domain-independent, highly accurate, and efficient clustering approach for
        time series with broad applications.", "venue": "SGMD", "year": 2016, "referenceCount":
        71, "citationCount": 464, "influentialCitationCount": 76, "isOpenAccess":
        false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": null, "journal": {"volume": "45", "pages": "69-76", "name":
        "SIGMOD Rec."}, "authors": [{"authorId": "2516699", "name": "John Paparrizos"},
        {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "52b58e71ca56ae725fd40b88c411a58a8322b872",
        "externalIds": {"MAG": "2479682262", "DBLP": "journals/jasis/McKeownDCPTBBBC16",
        "DOI": "10.1002/asi.23612", "CorpusId": 6351001}, "corpusId": 6351001, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/52b58e71ca56ae725fd40b88c411a58a8322b872",
        "title": "Predicting the impact of scientific concepts using full\u2010text
        features", "abstract": "New scientific concepts, interpreted broadly, are
        continuously introduced in the literature, but relatively few concepts have
        a long\u2010term impact on society. The identification of such concepts is
        a challenging prediction task that would help multiple parties\u2014including
        researchers and the general public\u2014focus their attention within the vast
        scientific literature. In this paper we present a system that predicts the
        future impact of a scientific concept, represented as a technical term, based
        on the information available from recently published research articles. We
        analyze the usefulness of rich features derived from the full text of the
        articles through a variety of approaches, including rhetorical sentence analysis,
        information extraction, and time\u2010series analysis. The results from two
        large\u2010scale experiments with 3.8 million full\u2010text articles and
        48 million metadata records support the conclusion that full\u2010text features
        are significantly more useful for prediction than metadata\u2010only features
        and that the most accurate predictions result from combining the metadata
        and full\u2010text features. Surprisingly, these results hold even when the
        metadata features are available for a much larger number of documents than
        are available for the full\u2010text features.", "venue": "J. Assoc. Inf.
        Sci. Technol.", "year": 2016, "referenceCount": 107, "citationCount": 60,
        "influentialCitationCount": 1, "isOpenAccess": false, "openAccessPdf": null,
        "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
        Science", "source": "external"}, {"category": "Computer Science", "source":
        "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
        "2016-11-01", "journal": {"volume": "67", "name": "Journal of the Association
        for Information Science and Technology"}, "authors": [{"authorId": "145590324",
        "name": "K. McKeown"}, {"authorId": "1722360", "name": "Hal Daum\u00e9"},
        {"authorId": "37202877", "name": "Snigdha Chaturvedi"}, {"authorId": "2516699",
        "name": "John Paparrizos"}, {"authorId": "2695187", "name": "K. Thadani"},
        {"authorId": "2065995286", "name": "Pablo Barrio"}, {"authorId": "20402453",
        "name": "Or Biran"}, {"authorId": "2362037", "name": "Suvarna Bothe"}, {"authorId":
        "144426392", "name": "Michael Collins"}, {"authorId": "3079031", "name": "K.
        Fleischmann"}, {"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "144598922", "name": "Rahul Jha"}, {"authorId": "145310840", "name": "Ben
        King"}, {"authorId": "7422938", "name": "Kevin McInerney"}, {"authorId": "47858323",
        "name": "Taesun Moon"}, {"authorId": "2072676", "name": "Arvind Neelakantan"},
        {"authorId": "8311581", "name": "Diarmuid \u00d3 S\u00e9aghdha"}, {"authorId":
        "9215251", "name": "Dragomir R. Radev"}, {"authorId": "35885685", "name":
        "T. C. Templeton"}, {"authorId": "2480901", "name": "Simone Teufel"}]}, {"paperId":
        "0316c64a5eb9152c18433fa4b92e023881e87287", "externalIds": {"DBLP": "conf/edbt/0002SGG15",
        "MAG": "2294284203", "DOI": "10.5441/002/edbt.2015.22", "CorpusId": 8014629},
        "corpusId": 8014629, "publicationVenue": {"id": "74f47cf8-2839-4a56-959a-524dd0ed9e3e",
        "name": "International Conference on Extending Database Technology", "type":
        "conference", "alternate_names": ["Int Conf Extending Database Technol", "Extending
        Database Technology", "Extending Database Technol", "EDBT"], "url": "http://www.edbt.org/"},
        "url": "https://www.semanticscholar.org/paper/0316c64a5eb9152c18433fa4b92e023881e87287",
        "title": "Learning to Rank Adaptively for Scalable Information Extraction",
        "abstract": "Information extraction systems extract structured data from natural
        language text, to support richer querying and analysis of the data than would
        be possible over the unstructured text. Unfortunately, information extraction
        is a computationally expensive task, so exhaustively processing all documents
        of a large collection might be prohibitive. Such exhaustive processing is
        generally unnecessary, though, because many times only a small set of documents
        in a collection is useful for a given information extraction task. Therefore,
        by identifying these useful documents, and not processing the rest, we could
        substantially improve the efficiency and scalability of an extraction task.
        Existing approaches for identifying such documents often miss useful documents
        and also lead to the processing of useless documents unnecessarily, which
        in turn negatively impacts the quality and efficiency of the extraction process.
        To address these limitations of the state-of-the-art techniques, we propose
        a principled, learning-based approach for ranking documents according to their
        potential usefulness for an extraction task. Our low-overhead, online learning-to-rank
        methods exploit the information collected during extraction, as we process
        new documents and the fine-grained characteristics of the useful documents
        are revealed. Then, these methods decide when the ranking model should be
        updated, hence significantly improving the document ranking quality over time.
        Our experiments show that our approach achieves higher accuracy than the state-of-the-art
        alternatives. Importantly, our approach is lightweight and efficient, and
        hence is a substantial step towards scalable information extraction.", "venue":
        "International Conference on Extending Database Technology", "year": 2015,
        "referenceCount": 35, "citationCount": 3, "influentialCitationCount": 0, "isOpenAccess":
        false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle",
        "Conference"], "publicationDate": null, "journal": {"pages": "241-252"}, "authors":
        [{"authorId": "2065995286", "name": "Pablo Barrio"}, {"authorId": "143976871",
        "name": "Gon\u00e7alo Sim\u00f5es"}, {"authorId": "2540160", "name": "H. Galhardas"},
        {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "767dcce161a6a2a2bb8c404e08b2e169b36e6c1c",
        "externalIds": {"MAG": "2095007791", "DBLP": "conf/cikm/0002GD15", "DOI":
        "10.1145/2806416.2806581", "CorpusId": 11130113}, "corpusId": 11130113, "publicationVenue":
        {"id": "7431ff67-91dc-41fa-b322-1b1ca657025f", "name": "International Conference
        on Information and Knowledge Management", "type": "conference", "alternate_names":
        ["Conference on Information and Knowledge Management", "Conf Inf Knowl Manag",
        "Int Conf Inf Knowl Manag", "CIKM"], "url": "http://www.cikm.org/"}, "url":
        "https://www.semanticscholar.org/paper/767dcce161a6a2a2bb8c404e08b2e169b36e6c1c",
        "title": "Ranking Deep Web Text Collections for Scalable Information Extraction",
        "abstract": "Information extraction (IE) systems discover structured information
        from natural language text, to enable much richer querying and data mining
        than possible directly over the unstructured text. Unfortunately, IE is generally
        a computationally expensive process, and hence improving its efficiency, so
        that it scales over large volumes of text, is of critical importance. State-of-the-art
        approaches for scaling the IE process focus on one text collection at a time.
        These approaches prioritize the extraction effort by learning keyword queries
        to identify the \"useful\" documents for the IE task at hand, namely, those
        that lead to the extraction of structured \"tuples.\" These approaches, however,
        do not attempt to predict which text collections are useful for the IE task---and
        hence merit further processing---and which ones will not contribute any useful
        output---and hence should be ignored altogether, for efficiency. In this paper,
        we focus on an especially valuable family of text sources, the so-called deep
        web collections, whose (remote) contents are only accessible via querying.
        Specifically, we introduce and study techniques for ranking deep web collections
        for an IE task, to prioritize the extraction effort by focusing on collections
        with substantial numbers of useful documents for the task. We study both (adaptations
        of) state-of-the-art resource selection strategies for distributed information
        retrieval, and IE-specific approaches. Our extensive experimental evaluation
        over realistic deep web collections, and for several different IE tasks, shows
        the merits and limitations of the alternative families of approaches, and
        provides a roadmap for addressing this critically important building block
        for efficient, scalable information extraction.", "venue": "International
        Conference on Information and Knowledge Management", "year": 2015, "referenceCount":
        39, "citationCount": 5, "influentialCitationCount": 1, "isOpenAccess": true,
        "openAccessPdf": {"url": "https://biblio.ugent.be/publication/7235609/file/7235611.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["Book", "JournalArticle",
        "Conference"], "publicationDate": "2015-10-17", "journal": {"name": "Proceedings
        of the 24th ACM International on Conference on Information and Knowledge Management"},
        "authors": [{"authorId": "2065995286", "name": "Pablo Barrio"}, {"authorId":
        "1684012", "name": "L. Gravano"}, {"authorId": "2489892", "name": "Chris Develder"}]},
        {"paperId": "8278ca04c4ffafef80abfbe0ce3c6cfc07b2792d", "externalIds": {"DBLP":
        "conf/sigmod/PaparrizosG15", "MAG": "2037537012", "DOI": "10.1145/2723372.2737793",
        "CorpusId": 207223470}, "corpusId": 207223470, "publicationVenue": null, "url":
        "https://www.semanticscholar.org/paper/8278ca04c4ffafef80abfbe0ce3c6cfc07b2792d",
        "title": "k-Shape: Efficient and Accurate Clustering of Time Series", "abstract":
        "The proliferation and ubiquity of temporal data across many disciplines has
        generated substantial interest in the analysis and mining of time series.
        Clustering is one of the most popular data mining methods, not only due to
        its exploratory power, but also as a preprocessing step or subroutine for
        other techniques. In this paper, we present k-Shape, a novel algorithm for
        time-series clustering. k-Shape relies on a scalable iterative refinement
        procedure, which creates homogeneous and well-separated clusters. As its distance
        measure, k-Shape uses a normalized version of the cross-correlation measure
        in order to consider the shapes of time series while comparing them. Based
        on the properties of that distance measure, we develop a method to compute
        cluster centroids, which are used in every iteration to update the assignment
        of time series to clusters. To demonstrate the robustness of k-Shape, we perform
        an extensive experimental evaluation of our approach against partitional,
        hierarchical, and spectral clustering methods, with combinations of the most
        competitive distance measures. k-Shape outperforms all scalable approaches
        in terms of accuracy. Furthermore, k-Shape also outperforms all non-scalable
        (and hence impractical) combinations, with one exception that achieves similar
        accuracy results. However, unlike k-Shape, this combination requires tuning
        of its distance measure and is two orders of magnitude slower than k-Shape.
        Overall, k-Shape emerges as a domain-independent, highly accurate, and highly
        efficient clustering approach for time series with broad applications.", "venue":
        "SIGMOD Conference", "year": 2015, "referenceCount": 94, "citationCount":
        289, "influentialCitationCount": 19, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["Book", "JournalArticle",
        "Conference"], "publicationDate": "2015-05-27", "journal": {"name": "Proceedings
        of the 2015 ACM SIGMOD International Conference on Management of Data"}, "authors":
        [{"authorId": "2516699", "name": "John Paparrizos"}, {"authorId": "1684012",
        "name": "L. Gravano"}]}, {"paperId": "f28f1dc630b73175c331aa8857dd32fd8737c2a8",
        "externalIds": {"DBLP": "conf/jcdl/BarrioSGG14", "MAG": "2164135737", "DOI":
        "10.1109/JCDL.2014.6970222", "CorpusId": 14227536}, "corpusId": 14227536,
        "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/f28f1dc630b73175c331aa8857dd32fd8737c2a8",
        "title": "REEL: A Relation Extraction Learning framework", "abstract": "We
        introduce the REEL (RElation Extraction Learning) framework, an open source
        framework that facilitates the development and evaluation of relation extraction
        systems over text collections. To define a relation extraction system for
        a new relation and text collection, users only need to specify the parsers
        to load the collection, the relation and its constraints, and the learning
        and extraction techniques to be used. This makes REEL a powerful framework
        to enable the deployment and evaluation of relation extraction systems for
        both application building and research.", "venue": "IEEE/ACM Joint Conference
        on Digital Libraries", "year": 2014, "referenceCount": 10, "citationCount":
        8, "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
        "http://www.cs.columbia.edu/%7Egravano/Papers/2014/jcdl2014.pdf", "status":
        null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle", "Conference"],
        "publicationDate": "2014-09-08", "journal": {"pages": "455-456", "name": "IEEE/ACM
        Joint Conference on Digital Libraries"}, "authors": [{"authorId": "2065995286",
        "name": "Pablo Barrio"}, {"authorId": "143976871", "name": "Gon\u00e7alo Sim\u00f5es"},
        {"authorId": "2540160", "name": "H. Galhardas"}, {"authorId": "1684012", "name":
        "L. Gravano"}]}, {"paperId": "2f770beab965bbc9df0575b9883e83f2e9678583", "externalIds":
        {"MAG": "2004087619", "DBLP": "journals/pvldb/SimoesGG13", "DOI": "10.14778/2536258.2536259",
        "CorpusId": 17423770}, "corpusId": 17423770, "publicationVenue": {"id": "fcbcaf18-8ab1-43e1-a973-604bbc7e344e",
        "name": "Proceedings of the VLDB Endowment", "type": "journal", "alternate_names":
        ["Proceedings of The Vldb Endowment", "Proc VLDB Endow", "Proc Vldb Endow"],
        "issn": "2150-8097", "url": "http://dl.acm.org/toc.cfm?id=J1174", "alternate_urls":
        ["http://portal.acm.org/toc.cfm?CFID=21632689&CFTOKEN=99329904&WantType=Affiliated%20Organizations&coll=ACM&dl=ACM&id=J1174&idx=J1174&part=affil&title=VLDB%20Endowment&type=periodical"]},
        "url": "https://www.semanticscholar.org/paper/2f770beab965bbc9df0575b9883e83f2e9678583",
        "title": "When Speed Has a Price: Fast Information Extraction Using Approximate
        Algorithms", "abstract": "A wealth of information produced by individuals
        and organizations is expressed in natural language text. This is a problem
        since text lacks the explicit structure that is necessary to support rich
        querying and analysis. Information extraction systems are sophisticated software
        tools to discover structured information in natural language text. Unfortunately,
        information extraction is a challenging and time-consuming task. In this paper,
        we address the limitations of state-of-the-art systems for the optimization
        of information extraction programs, with the objective of producing efficient
        extraction executions. Our solution relies on exploiting a wide range of optimization
        opportunities. For efficiency, we consider a wide spectrum of execution plans,
        including approximate plans whose results differ in their precision and recall.
        Our optimizer accounts for these characteristics of the competing execution
        plans, and uses accurate predictors of their extraction time, recall, and
        precision. We demonstrate the efficiency and effectiveness of our optimizer
        through a large-scale experimental evaluation over real-world datasets and
        multiple extraction tasks and approaches.", "venue": "Proceedings of the VLDB
        Endowment", "year": 2013, "referenceCount": 24, "citationCount": 7, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "2013-08-29", "journal":
        {"volume": "6", "pages": "1462-1473", "name": "Proc. VLDB Endow."}, "authors":
        [{"authorId": "143976871", "name": "Gon\u00e7alo Sim\u00f5es"}, {"authorId":
        "2540160", "name": "H. Galhardas"}, {"authorId": "1684012", "name": "L. Gravano"}]},
        {"paperId": "957104cb5951987380e6263ddc498fca1f008798", "externalIds": {"DBLP":
        "journals/debu/PsallidasBNG13", "MAG": "2181430957", "CorpusId": 612028},
        "corpusId": 612028, "publicationVenue": {"id": "7bf8fd30-543b-48f6-bb8a-8c518006bdd2",
        "name": "IEEE Data Engineering Bulletin", "type": "journal", "alternate_names":
        ["IEEE Data Eng Bull"], "url": "https://tc.computer.org/tcde/tcde-bulletin-issues/"},
        "url": "https://www.semanticscholar.org/paper/957104cb5951987380e6263ddc498fca1f008798",
        "title": "Effective Event Identification in Social Media", "abstract": "Online
        social media sites are extensively used by individuals to produce and distribute
        content related to real-world events. Unfortunately, this social media content
        associated with an event is generally not provided in any structured and readily
        available form. Thus, identifying the event-related content on social media
        sites is a challenging task. Prior work has addressed the event identification
        task under two different scenarios, namely, when the events are known ahead
        of time, as is sometimes the case for planned events, and when the events
        are unknown, as is the case for spontaneous, unplanned events. In this article,
        we discuss both the unknown- and known-event identification scenarios, and
        attempt to characterize the key factors in the identification process, including
        the nature of social media content as well as the behavior and characteristics
        of event content over time. Furthermore, we propose enhancements to our earlier
        techniques that consider these factors and improve the state-of-the-art unknown-event
        identification strategies. Specifically, we propose novel features of the
        social media content that we can exploit, as well as the modeling of the typical
        time decay of event-related content. Large-scale experiments show that our
        approach exhibits improved effectiveness relative to the state-of-the-art
        approaches.", "venue": "IEEE Data Engineering Bulletin", "year": 2013, "referenceCount":
        11, "citationCount": 24, "influentialCitationCount": 6, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": null, "journal": {"volume": "36", "pages": "42-50", "name":
        "IEEE Data Eng. Bull."}, "authors": [{"authorId": "2493657", "name": "Fotis
        Psallidas"}, {"authorId": "47503402", "name": "H. Becker"}, {"authorId": "1687465",
        "name": "Mor Naaman"}, {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId":
        "4d76072a133a39144b5fe4b16611b603b641d487", "externalIds": {"DBLP": "conf/wsdm/BeckerING12",
        "MAG": "1977931290", "DOI": "10.1145/2124295.2124360", "CorpusId": 17745119},
        "corpusId": 17745119, "publicationVenue": {"id": "ea38228f-6ed3-4222-a3ce-d963d8cc9516",
        "name": "Web Search and Data Mining", "type": "conference", "alternate_names":
        ["Web Search Data Min", "WSDM"], "url": "http://www.wikicfp.com/cfp/program?id=3158"},
        "url": "https://www.semanticscholar.org/paper/4d76072a133a39144b5fe4b16611b603b641d487",
        "title": "Identifying content for planned events across social media sites",
        "abstract": "User-contributed Web data contains rich and diverse information
        about a variety of events in the physical world, such as shows, festivals,
        conferences and more. This information ranges from known event features (e.g.,
        title, time, location) posted on event aggregation platforms (e.g., Last.fm
        events, EventBrite, Facebook events) to discussions and reactions related
        to events shared on different social media sites (e.g., Twitter, YouTube,
        Flickr). In this paper, we focus on the challenge of automatically identifying
        user-contributed content for events that are planned and, therefore, known
        in advance, across different social media sites. We mine event aggregation
        platforms to extract event features, which are often noisy or missing. We
        use these features to develop query formulation strategies for retrieving
        content associated with an event on different social media sites. Further,
        we explore ways in which event content identified on one social media site
        can be used to retrieve additional relevant event content on other social
        media sites. We apply our strategies to a large set of user-contributed events,
        and analyze their effectiveness in retrieving relevant event content from
        Twitter, YouTube, and Flickr.", "venue": "Web Search and Data Mining", "year":
        2012, "referenceCount": 27, "citationCount": 190, "influentialCitationCount":
        11, "isOpenAccess": true, "openAccessPdf": {"url": "http://www.cs.columbia.edu/%7Egravano/Papers/2012/wsdm12.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}, {"category": "Sociology", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "2012-02-08", "journal":
        {"pages": "533-542"}, "authors": [{"authorId": "47503402", "name": "H. Becker"},
        {"authorId": "3310951", "name": "Dan Iter"}, {"authorId": "1687465", "name":
        "Mor Naaman"}, {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId":
        "7d30a3891840a188bea22dba8d6ebd0ac1a59bd7", "externalIds": {"CorpusId": 55519390},
        "corpusId": 55519390, "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/7d30a3891840a188bea22dba8d6ebd0ac1a59bd7",
        "title": "A Protocol and Toolkit for Metasearching", "abstract": "This paper
        describes how SDLIP and STARTS, two complementary protocols for searching
        over distributed document collections, were combined. The resulting protocol,
        called SDARTS, is simple yet expressible enough to enable building sophisticated
        metasearch engines. SDARTS can be viewed as an instantiation of SDLIP with
        metasearch-specific elements from STARTS. The paper also reports on the experience
        of building three SDARTS-compliant wrappers: for locally available plain-text
        document collections, for locally available XML document collections, and
        for external Web-accessible collections. These wrappers were developed to
        be easily customizable for new collections. This work was developed as part
        of Columbia University''s Digital Libraries Initiative-Phase 2 (DLI2) project,
        which involves the departments of Computer Science, Medical Informatics, and
        Electrical Engineering, the Columbia University libraries, and a large number
        of industrial partners. The main goal of the project is to provide personalized
        access to a distributed patient-care digital library. (Contains 24 references.)
        (Author/AEF) Reproductions supplied by EDRS are the best that can be made
        from the original document. PERMISSION TO REPRODUCE AND DISSEMINATE THIS MATERIAL
        HAS BEEN GRANTED BY", "venue": "", "year": 2012, "referenceCount": 19, "citationCount":
        0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": null, "s2FieldsOfStudy": [{"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate": null,
        "journal": null, "authors": [{"authorId": "2053843048", "name": "Noah Green"},
        {"authorId": "2942126", "name": "Panagiotis G. Ipeirotis"}, {"authorId": "1684012",
        "name": "L. Gravano"}]}, {"paperId": "24dab89bcd046a9cbe4a7a2e8eb9e9478d9a7c56",
        "externalIds": {"MAG": "2222139048", "DBLP": "conf/icwsm/BeckerNG11a", "DOI":
        "10.1609/icwsm.v5i1.14145", "CorpusId": 7960357}, "corpusId": 7960357, "publicationVenue":
        {"id": "7dc964d5-49e6-4c37-b1c4-a7f0de1fa425", "name": "International Conference
        on Web and Social Media", "type": "conference", "alternate_names": ["Int Conf
        Weblogs Soc Media", "International Conference on Weblogs and Social Media",
        "Int Conf Web Soc Media", "ICWSM"], "url": "http://www.aaai.org/Library/ICWSM/icwsm-library.php"},
        "url": "https://www.semanticscholar.org/paper/24dab89bcd046a9cbe4a7a2e8eb9e9478d9a7c56",
        "title": "Selecting Quality Twitter Content for Events", "abstract": "\n \n
        Social media sites such as Twitter contain large amounts of user contributed
        messages for a wide variety of real-world events. While some of these \"event
        messages\" might contain interesting and useful information (e.g., event time,
        location, participants, opinions), others might provide little value (e.g.,
        using heavy slang, incomprehensible language) to people interested in learning
        about an event. Techniques for effective selection of quality event content
        may therefore help improve applications such as event browsing and search.In
        this paper, we explore approaches for finding representative messages among
        a set of Twitter messages that correspond to the same event, with the goal
        of identifying high quality, relevant messages that provide useful event information.
        We evaluate our approaches using a large-scale dataset of Twitter messages,
        and show that we can automatically select event messages that are both relevant
        and useful.\n \n", "venue": "International Conference on Web and Social Media",
        "year": 2011, "referenceCount": 10, "citationCount": 118, "influentialCitationCount":
        8, "isOpenAccess": true, "openAccessPdf": {"url": "https://ojs.aaai.org/index.php/ICWSM/article/download/14145/13994",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "2011-07-05", "journal": {"name": "Proceedings of the International
        AAAI Conference on Web and Social Media"}, "authors": [{"authorId": "47503402",
        "name": "H. Becker"}, {"authorId": "1687465", "name": "Mor Naaman"}, {"authorId":
        "1684012", "name": "L. Gravano"}]}, {"paperId": "4a51879c9e7af33b3e3599f1168f93e42a624ad7",
        "externalIds": {"MAG": "2552423137", "CorpusId": 6039380}, "corpusId": 6039380,
        "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/4a51879c9e7af33b3e3599f1168f93e42a624ad7",
        "title": "Quality Impact of Value Matching and Scoring in Top-k Entity Attribute
        Extraction", "abstract": "The entity attribute extraction problem, or how
        to extract entities and their attribute values from natural language Web documents,
        is of critical importance for Web search and information access in general.
        Unfortunately, because of the noisy nature of the Web and its scale, entity
        attribute extraction is notoriously challenging in terms of both extraction
        efficiency and quality. In our earlier work [24], we proposed a top-k extraction
        processing approach that addressed the efficiency challenge: Our approach
        leveraged a popularitybased scoring function to rank Web pages according to
        their entity-specific importance, and focused the extraction effort over the
        highly ranked pages for each entity of interest. The extraction quality resulting
        from this efficiency-motivated extraction approach, however, has not been
        studied and is the focus of this paper. Specifically, we make progress toward
        addressing the quality challenge through an in-depth analysis of two critical
        components of the extraction process, namely, matching and scoring of extracted
        attribute values. The design choices for these components can substantially
        impact the quality of the entity attribute extraction process, as we demonstrate
        with experiments with a state-of-the-art extraction system and entities from
        two domains of interest.", "venue": "", "year": 2011, "referenceCount": 28,
        "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate":
        null, "journal": {"volume": "", "name": ""}, "authors": [{"authorId": "2073285911",
        "name": "Matthew Solomon"}, {"authorId": "1684012", "name": "L. Gravano"}]},
        {"paperId": "aedca557e79d36d4c3f81f76a247a98f1cfffcc4", "externalIds": {"MAG":
        "2056076776", "DBLP": "journals/jasis/NaamanBG11", "DOI": "10.1002/asi.21489",
        "CorpusId": 6216878}, "corpusId": 6216878, "publicationVenue": null, "url":
        "https://www.semanticscholar.org/paper/aedca557e79d36d4c3f81f76a247a98f1cfffcc4",
        "title": "Hip and trendy: Characterizing emerging trends on Twitter", "abstract":
        "Twitter, Facebook, and other related systems that we call social awareness
        streams are rapidly changing the information and communication dynamics of
        our society. These systems, where hundreds of millions of users share short
        messages in real time, expose the aggregate interests and attention of global
        and local communities. In particular, emerging temporal trends in these systems,
        especially those related to a single geographic area, are a significant and
        revealing source of information for, and about, a local community. This study
        makes two essential contributions for interpreting emerging temporal trends
        in these information systems. First, based on a large dataset of Twitter messages
        from one geographic area, we develop a taxonomy of the trends present in the
        data. Second, we identify important dimensions according to which trends can
        be categorized, as well as the key distinguishing features of trends that
        can be derived from their associated messages. We quantitatively examine the
        computed features for different categories of trends, and establish that significant
        differences can be detected across categories. Our study advances the understanding
        of trends on Twitter and other social awareness streams, which will enable
        powerful applications and activities, including user-driven real-time information
        services for local communities. \u00a9 2011 Wiley Periodicals, Inc.", "venue":
        "J. Assoc. Inf. Sci. Technol.", "year": 2011, "referenceCount": 89, "citationCount":
        293, "influentialCitationCount": 12, "isOpenAccess": true, "openAccessPdf":
        {"url": "http://www.cs.columbia.edu/%7Egravano/Papers/2011/jasist11.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "2011-05-01", "journal": {"volume": "62", "pages": "902-918",
        "name": "J. Assoc. Inf. Sci. Technol."}, "authors": [{"authorId": "1687465",
        "name": "Mor Naaman"}, {"authorId": "47503402", "name": "H. Becker"}, {"authorId":
        "1684012", "name": "L. Gravano"}]}, {"paperId": "b16f594e3ed94e864cf4aa1ff183532107bffed0",
        "externalIds": {"DBLP": "conf/icwsm/BeckerCING11", "MAG": "2108324945", "DOI":
        "10.1609/icwsm.v5i1.14081", "CorpusId": 14611795}, "corpusId": 14611795, "publicationVenue":
        {"id": "7dc964d5-49e6-4c37-b1c4-a7f0de1fa425", "name": "International Conference
        on Web and Social Media", "type": "conference", "alternate_names": ["Int Conf
        Weblogs Soc Media", "International Conference on Weblogs and Social Media",
        "Int Conf Web Soc Media", "ICWSM"], "url": "http://www.aaai.org/Library/ICWSM/icwsm-library.php"},
        "url": "https://www.semanticscholar.org/paper/b16f594e3ed94e864cf4aa1ff183532107bffed0",
        "title": "Automatic Identification and Presentation of Twitter Content for
        Planned Events", "abstract": "\n \n We demonstrate a system for augmenting
        information about planned events with Twitter messages, using a set of automatic
        query building strategies. We present two alternative interfaces to our system,
        namely, a browser plug-in and a customizable Web interface.\n \n", "venue":
        "International Conference on Web and Social Media", "year": 2011, "referenceCount":
        5, "citationCount": 44, "influentialCitationCount": 4, "isOpenAccess": true,
        "openAccessPdf": {"url": "https://ojs.aaai.org/index.php/ICWSM/article/download/14081/13930",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "2011-07-05", "journal": {"name": "Proceedings of the International
        AAAI Conference on Web and Social Media"}, "authors": [{"authorId": "47503402",
        "name": "H. Becker"}, {"authorId": null, "name": "Feiyang Chen"}, {"authorId":
        "3310951", "name": "Dan Iter"}, {"authorId": "1687465", "name": "Mor Naaman"},
        {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "bb7965a9dbeab34cec56e19aae949690f2463f20",
        "externalIds": {"MAG": "1534625513", "DBLP": "conf/icwsm/BeckerNG11", "DOI":
        "10.7916/D81V5NVX", "CorpusId": 3246176}, "corpusId": 3246176, "publicationVenue":
        {"id": "7dc964d5-49e6-4c37-b1c4-a7f0de1fa425", "name": "International Conference
        on Web and Social Media", "type": "conference", "alternate_names": ["Int Conf
        Weblogs Soc Media", "International Conference on Weblogs and Social Media",
        "Int Conf Web Soc Media", "ICWSM"], "url": "http://www.aaai.org/Library/ICWSM/icwsm-library.php"},
        "url": "https://www.semanticscholar.org/paper/bb7965a9dbeab34cec56e19aae949690f2463f20",
        "title": "Beyond Trending Topics: Real-World Event Identification on Twitter",
        "abstract": "\n \n User-contributed messages on social media sites such as
        Twitter have emerged aspowerful, real-time means of information sharing on
        the Web. These short messages tend to reflect a variety of events in real
        time, making Twitter particularly well suited as a source of real-time event
        content. In this paper, we explore approaches for analyzing the stream of
        Twitter messages to distinguish between messages about real-world events andnon-event
        messages. Our approach relies on a rich family of aggregatestatistics of topically
        similar message clusters. Large-scale experiments over millions of Twitter
        messages show the effectiveness of our approach for surfacing real-world event
        content on Twitter.\n \n", "venue": "International Conference on Web and Social
        Media", "year": 2011, "referenceCount": 27, "citationCount": 809, "influentialCitationCount":
        55, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "2011-07-05", "journal":
        {"name": "Proceedings of the International AAAI Conference on Web and Social
        Media"}, "authors": [{"authorId": "47503402", "name": "H. Becker"}, {"authorId":
        "1687465", "name": "Mor Naaman"}, {"authorId": "1684012", "name": "L. Gravano"}]},
        {"paperId": "f80385633d6e95aa3e9c2e7091a56f6407914fa3", "externalIds": {"MAG":
        "2187753188", "CorpusId": 131232796}, "corpusId": 131232796, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/f80385633d6e95aa3e9c2e7091a56f6407914fa3",
        "title": "Hip andTrendy: Characterizing EmergingTrends onTwitter", "abstract":
        "Twitter, Facebook, and other related systems that we call social awareness
        streams are rapidly changing the information and communication dynamics of
        our society.These systems, where hundreds of millions of users share short
        messages in real time, expose the aggregate interests and attention of global
        and local communities. In particular, emerging temporal trends in these systems,
        especially those related to a single geographic area, are a significant and
        revealing source of information for, and about, a local community. This study
        makestwoessentialcontributionsforinterpretingemerging temporal trends in these
        information systems. First, based on a large dataset of Twitter messages from
        one geographic area, we develop a taxonomy of the trends present in the data.
        Second,we identify important dimensions according to which trends can be categorized,
        as well as the key distinguishing features of trends that can be derived from
        their associated messages. We quantitatively examine the computed features
        for different categories of trends, and establish that significant differences
        can be detected across categories. Our study advances the understanding of
        trends on Twitter and other social awareness streams, which will enable powerful
        applications and activities, including user-driven real-time information services
        for local communities.", "venue": "", "year": 2011, "referenceCount": 37,
        "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Geography"], "s2FieldsOfStudy":
        [{"category": "Geography", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate": null,
        "journal": {"volume": "", "name": ""}, "authors": [{"authorId": "1687465",
        "name": "Mor Naaman"}, {"authorId": "47503402", "name": "H. Becker"}, {"authorId":
        "1684012", "name": "L. Gravano"}]}, {"paperId": "d55e2998548a8fc202413ebe473f5e74ad69e800",
        "externalIds": {"MAG": "2079973394", "DBLP": "conf/webdb/SolomonYG10", "DOI":
        "10.1145/1859127.1859139", "CorpusId": 3472105}, "corpusId": 3472105, "publicationVenue":
        {"id": "008c1686-e07c-419a-a0e6-f2c5cbde842e", "name": "International Workshop
        on the Web and Databases", "type": "conference", "alternate_names": ["Int
        Workshop Web Database", "WebDB"], "url": "http://www.wikicfp.com/cfp/program?id=3033"},
        "url": "https://www.semanticscholar.org/paper/d55e2998548a8fc202413ebe473f5e74ad69e800",
        "title": "Popularity-guided top-k extraction of entity attributes", "abstract":
        "Recent progress in information extraction technology has enabled a vast array
        of applications that rely on structured data that is embedded in natural-language
        text. In particular, the extraction of concepts from the Web---with their
        desired attributes---is important to provide applications with rich, structured
        access to information. In this paper, we focus on an important family of concepts,
        namely, entities (e.g., people or organizations) and their attributes, and
        study how to efficiently and effectively extract them from Web-accessible
        text documents. Unfortunately, information extraction over the Web is challenging
        for both quality and efficiency reasons. Regarding quality, many sources on
        the Web contain misleading or invalid information; furthermore, extraction
        systems often return incorrect data. Regarding efficiency, information extraction
        is a time-consuming process, often involving expensive text-processing steps.
        We present a top-k extraction processing approach that addresses both the
        quality and efficiency challenges: for each entity and attribute of interest,
        we return the top-k values of the attribute for the entity according to a
        scoring function for extracted attribute values. This scoring function weighs
        the extraction confidence from individual documents, as well as the \"importance\"
        of the documents where the information originates. We define the document
        importance in terms of entity-specific document \"popularity\" statistics
        from a major search engine. Overall, our top-k extraction processing approach
        manages to identify the top attribute values for the entities of interest
        efficiently, as we demonstrate with a large-scale experimental evaluation
        over real-life data.", "venue": "International Workshop on the Web and Databases",
        "year": 2010, "referenceCount": 13, "citationCount": 10, "influentialCitationCount":
        2, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "2010-06-06", "journal":
        {"name": "Procceedings of the 13th International Workshop on the Web and Databases
        - WebDB ''10"}, "authors": [{"authorId": "2073285911", "name": "Matthew Solomon"},
        {"authorId": "40592227", "name": "Cong Yu"}, {"authorId": "1684012", "name":
        "L. Gravano"}]}, {"paperId": "d7f72ac79527b9e3fd612fc5202b5c83721d9d52", "externalIds":
        {"MAG": "1973897992", "DBLP": "conf/wsdm/BeckerNG10", "DOI": "10.1145/1718487.1718524",
        "CorpusId": 8609299}, "corpusId": 8609299, "publicationVenue": {"id": "ea38228f-6ed3-4222-a3ce-d963d8cc9516",
        "name": "Web Search and Data Mining", "type": "conference", "alternate_names":
        ["Web Search Data Min", "WSDM"], "url": "http://www.wikicfp.com/cfp/program?id=3158"},
        "url": "https://www.semanticscholar.org/paper/d7f72ac79527b9e3fd612fc5202b5c83721d9d52",
        "title": "Learning similarity metrics for event identification in social media",
        "abstract": "Social media sites (e.g., Flickr, YouTube, and Facebook) are
        a popular distribution outlet for users looking to share their experiences
        and interests on the Web. These sites host substantial amounts of user-contributed
        materials (e.g., photographs, videos, and textual content) for a wide variety
        of real-world events of different type and scale. By automatically identifying
        these events and their associated user-contributed social media documents,
        which is the focus of this paper, we can enable event browsing and search
        in state-of-the-art search engines. To address this problem, we exploit the
        rich \"context\" associated with social media content, including user-provided
        annotations (e.g., title, tags) and automatically generated information (e.g.,
        content creation time). Using this rich context, which includes both textual
        and non-textual features, we can define appropriate document similarity metrics
        to enable online clustering of media to events. As a key contribution of this
        paper, we explore a variety of techniques for learning multi-feature similarity
        metrics for social media documents in a principled manner. We evaluate our
        techniques on large-scale, real-world datasets of event images from Flickr.
        Our evaluation results suggest that our approach identifies events, and their
        associated social media documents, more effectively than the state-of-the-art
        strategies on which we build.", "venue": "Web Search and Data Mining", "year":
        2010, "referenceCount": 41, "citationCount": 430, "influentialCitationCount":
        40, "isOpenAccess": true, "openAccessPdf": {"url": "http://www.cs.columbia.edu/~hila/papers/wsdm10-becker.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "2010-02-04", "journal": {"pages": "291-300"}, "authors":
        [{"authorId": "47503402", "name": "H. Becker"}, {"authorId": "1687465", "name":
        "Mor Naaman"}, {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId":
        "42ddfcde1bb3d71550318ee79988cb4a9c77e66e", "externalIds": {"DOI": "10.1145/3264076",
        "CorpusId": 52099464}, "corpusId": 52099464, "publicationVenue": null, "url":
        "https://www.semanticscholar.org/paper/42ddfcde1bb3d71550318ee79988cb4a9c77e66e",
        "title": "Session details: Special section on managing information extraction",
        "abstract": null, "venue": "SGMD", "year": 2009, "referenceCount": 0, "citationCount":
        2, "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
        "https://dl.acm.org/doi/pdf/10.1145/3264076?download=true", "status": null},
        "fieldsOfStudy": null, "s2FieldsOfStudy": [], "publicationTypes": null, "publicationDate":
        null, "journal": null, "authors": [{"authorId": "3030274", "name": "A. Doan"},
        {"authorId": "1684012", "name": "L. Gravano"}, {"authorId": "1709145", "name":
        "R. Ramakrishnan"}, {"authorId": "2066721", "name": "Shivakumar Vaithyanathan"}]},
        {"paperId": "6e629e0276c4fa3396c351657d918f91ec873a42", "externalIds": {"MAG":
        "2913140078", "DOI": "10.1145/3257457", "CorpusId": 53236463}, "corpusId":
        53236463, "publicationVenue": {"id": "f68b9e7e-ad3d-46cb-857d-23e49384143c",
        "name": "ACM SIGMOD Conference", "type": "conference", "alternate_names":
        ["SIGMOD", "ACM SIGMOD Conf"], "url": "https://sigmod.org/conferences/"},
        "url": "https://www.semanticscholar.org/paper/6e629e0276c4fa3396c351657d918f91ec873a42",
        "title": "Session details: Research session 9: data on the web", "abstract":
        null, "venue": "ACM SIGMOD Conference", "year": 2009, "referenceCount": 0,
        "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}], "publicationTypes":
        ["Book"], "publicationDate": "2009-06-29", "journal": {"name": "Proceedings
        of the 2009 ACM SIGMOD International Conference on Management of data"}, "authors":
        [{"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "7acdfa6c26662376079d924e731fa795597122f0",
        "externalIds": {"DBLP": "journals/sigmod/JainIG08", "MAG": "2026469784", "DOI":
        "10.1145/1519103.1519108", "CorpusId": 16392717}, "corpusId": 16392717, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/7acdfa6c26662376079d924e731fa795597122f0",
        "title": "Building query optimizers for information extraction: the SQoUT
        project", "abstract": "Text documents often embed data that is structured
        in nature. This structured data is increasingly exposed using information
        extraction systems, which generate structured relations from documents, introducing
        an opportunity to process expressive, structured queries over text databases.
        This paper discusses our SQoUT1 project, which focuses on processing structured
        queries over relations extracted from text databases. We show how, in our
        extraction-based scenario, query processing can be decomposed into a sequence
        of basic steps: retrieving relevant text documents, extracting relations from
        the documents, and joining extracted relations for queries involving multiple
        relations. Each of these steps presents different alternatives and together
        they form a rich space of possible query execution strategies. We identify
        execution efficiency and output quality as the two critical properties of
        a query execution, and argue that an optimization approach needs to consider
        both properties. To this end, we take into account the userspecified requirements
        for execution efficiency and output quality, and choose an execution strategy
        for each query based on a principled, cost-based comparison of the alternative
        execution strategies.", "venue": "SGMD", "year": 2009, "referenceCount": 22,
        "citationCount": 22, "influentialCitationCount": 1, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "2009-03-20", "journal": {"volume": "37", "pages": "28-34",
        "name": "SIGMOD Rec."}, "authors": [{"authorId": "1777385", "name": "Alpa
        Jain"}, {"authorId": "2942126", "name": "Panagiotis G. Ipeirotis"}, {"authorId":
        "1684012", "name": "L. Gravano"}]}, {"paperId": "ba44bd05bff54484803abd54f20625b0e8c07847",
        "externalIds": {"MAG": "2168561231", "DBLP": "conf/icde/JainIDG09", "DOI":
        "10.1109/ICDE.2009.138", "CorpusId": 183305}, "corpusId": 183305, "publicationVenue":
        {"id": "764e3630-ddac-4c21-af4b-9d32ffef082e", "name": "IEEE International
        Conference on Data Engineering", "type": "conference", "alternate_names":
        ["ICDE", "Int Conf Data Eng", "IEEE Int Conf Data Eng", "International Conference
        on Data Engineering"], "url": "http://www.wikicfp.com/cfp/program?id=1331"},
        "url": "https://www.semanticscholar.org/paper/ba44bd05bff54484803abd54f20625b0e8c07847",
        "title": "Join Optimization of Information Extraction Output: Quality Matters!",
        "abstract": "Information extraction (IE) systems are trained to extract specific
        relations from text databases. Real-world applications often require that
        the output of multiple IE systems be joined to produce the data of interest.
        To optimize the execution of a join of multiple extracted relations, it is
        not sufficient to consider only execution time. In fact, the quality of the
        join output is of critical importance: unlike in the relational world, different
        join execution plans can produce join results of widely different quality
        whenever IE systems are involved. In this paper, we develop a principled approach
        to understand, estimate, and incorporate output quality into the join optimization
        process over extracted relations. We argue that the output quality is affected
        by (a) the configuration of the IE systems used to process documents, (b)
        the document retrieval strategies used to retrieve documents, and (c) the
        actual join algorithm used. Our analysis considers several alternatives for
        these factors, and predicts the output quality---and, of course, the execution
        time---of the alternate execution plans. We establish the accuracy of our
        analytical models, as well as study the effectiveness of a quality-aware join
        optimizer, with a large-scale experimental evaluation over real-world text
        collections and state-of-the-art IE systems.", "venue": "IEEE International
        Conference on Data Engineering", "year": 2009, "referenceCount": 19, "citationCount":
        23, "influentialCitationCount": 4, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle", "Conference"],
        "publicationDate": "2009-03-29", "journal": {"pages": "186-197", "name": "2009
        IEEE 25th International Conference on Data Engineering"}, "authors": [{"authorId":
        "1777385", "name": "Alpa Jain"}, {"authorId": "2942126", "name": "Panagiotis
        G. Ipeirotis"}, {"authorId": "3030274", "name": "A. Doan"}, {"authorId": "1684012",
        "name": "L. Gravano"}]}, {"paperId": "e4521648675cc58d2c2bbe3b479e2085ebdf1a25",
        "externalIds": {"DBLP": "conf/sigmod/Gravano09", "MAG": "2059653319", "DOI":
        "10.1145/1557670.1557674", "CorpusId": 10741005}, "corpusId": 10741005, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/e4521648675cc58d2c2bbe3b479e2085ebdf1a25",
        "title": "Querying text databases and the web: beyond traditional keyword
        search", "abstract": "Traditional keyword search---where a query is a list
        of keywords and query results are a relevance-ordered list of documents---is,
        of course, a powerful query paradigm for text databases and the Web. However,
        more expressive query paradigms, where both queries and their results can
        exhibit a richer structure than in traditional keyword search, are often desirable.
        Information extraction systems identify and extract intrinsically structured
        data that is embedded in natural-language text documents, hence enabling these
        alternative query paradigms. Unfortunately, information extraction is a time-consuming
        process, often involving complex text analysis, so exhaustively processing
        all documents in a large text database --or on the Web-- could be prohibitively
        expensive. Beyond efficiency, query result quality is also important: information
        extraction is error-prone and not all extracted data is equally likely to
        be correct, so result quality is an important consideration during query processing.
        In this talk, I will discuss recent work on cost-based optimization of structured
        queries in this information extraction scenario, where modeling query result
        quality--in addition to execution efficiency-- is a distinctive and important
        challenge.", "venue": "KEYS ''09", "year": 2009, "referenceCount": 0, "citationCount":
        1, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
        "2009-06-28", "journal": {"pages": "2"}, "authors": [{"authorId": "1684012",
        "name": "L. Gravano"}]}, {"paperId": "f3a6725548c22d5bea6a0cb0b0a705d2e81475c9",
        "externalIds": {"DBLP": "conf/webdb/BeckerNG09", "MAG": "96282607", "CorpusId":
        5849258}, "corpusId": 5849258, "publicationVenue": {"id": "008c1686-e07c-419a-a0e6-f2c5cbde842e",
        "name": "International Workshop on the Web and Databases", "type": "conference",
        "alternate_names": ["Int Workshop Web Database", "WebDB"], "url": "http://www.wikicfp.com/cfp/program?id=3033"},
        "url": "https://www.semanticscholar.org/paper/f3a6725548c22d5bea6a0cb0b0a705d2e81475c9",
        "title": "Event Identification in Social Media", "abstract": "Social media
        sites such as Flickr, YouTube, and Facebook host substantial amounts of user-contributed
        materials (e.g., photographs, videos, and textual content) for a wide variety
        of real-world events. These range from widely known events, such as the presidential
        inauguration, to smaller, community-specific events, such as annual conventions
        and local gatherings. By identifying these events and their associated user-contributed
        social media documents, which is the focus of this paper, we can greatly improve
        local event browsing and search in state-of-the-art search engines. To address
        our problem of focus, we exploit the rich \u201ccontext\u201d associated with
        social media content, including user-provided annotations (e.g., title, tags)
        and automatically generated information (e.g., content creation time). We
        form a variety of representations of social media documents using different
        context dimensions, and combine these dimensions in a principled way into
        a single clustering solution\u2014where each document cluster ideally corresponds
        to one event\u2014using a weighted ensemble approach. We evaluate our approach
        on a large-scale, real-world dataset of event images, and report promising
        performance with respect to several baseline approaches. Our preliminary experiments
        suggest that our ensemble approach identifies events, and their associated
        images, more effectively than the state-of-the-art strategies on which we
        build.", "venue": "International Workshop on the Web and Databases", "year":
        2009, "referenceCount": 27, "citationCount": 93, "influentialCitationCount":
        5, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": null,
        "journal": {"volume": "", "name": ""}, "authors": [{"authorId": "47503402",
        "name": "H. Becker"}, {"authorId": "1687465", "name": "Mor Naaman"}, {"authorId":
        "1684012", "name": "L. Gravano"}]}, {"paperId": "1714b50567728933b261d072b5b6ffdcafd76935",
        "externalIds": {"CorpusId": 5169203}, "corpusId": 5169203, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/1714b50567728933b261d072b5b6ffdcafd76935",
        "title": "Introduction to the Special Issue on Managing Information Extraction",
        "abstract": "The field of information extraction (IE) focuses on extracting
        structured data, such as person names and organizations, from unstructured
        text. This field has had a long history. It attracted steady attention in
        the 80s and 90s, largely in the AI community. In the past decade, however,
        spurred on by the explosion of unstructured data on the World-Wide Web, this
        attention has turned into a torrent, gathering the efforts of researchers
        in the AI, DB, WWW, KDD, Semantic Web and IR communities. New IE problems
        have been identified, new IE techniques developed, many workshops organized,
        tutorials presented, companies founded, academic and industrial products deployed,
        and opensource prototypes developed (e.g., [5, 4, 3, 1, 2]; see [5] for the
        latest survey). The next few years are poised to witness even more accelerated
        activities in these areas. It is against this vibrant backdrop that we assemble
        this special issue. Our objective is threefold. First, we want to provide
        a glimpse into the current state of the field, highlighting in particular
        the wide range of IE problems. Second, we want to show that many IE problems
        can significantly benefit from the wealth of work on managing structured data
        in the database community. We believe therefore that our community can make
        a substantial contribution to the IE field. Finally, we hope that examining
        IE problems can in turn help us gain valuable insights into managing data
        in this Internet-centric world, a long-term goal of our community. Keeping
        in mind the above goals, we end this introduction by briefly describing the
        nine papers assembled for the issue. These papers fall into four broad categories.",
        "venue": "", "year": 2008, "referenceCount": 6, "citationCount": 20, "influentialCitationCount":
        1, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": null, "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
        ["Review"], "publicationDate": null, "journal": null, "authors": [{"authorId":
        "3030274", "name": "A. Doan"}, {"authorId": "1684012", "name": "L. Gravano"},
        {"authorId": "1709145", "name": "R. Ramakrishnan"}, {"authorId": "2066721",
        "name": "Shivakumar Vaithyanathan"}]}, {"paperId": "24a28b80b45b5e2f1eaeeefd7702701211f42b8f",
        "externalIds": {"MAG": "2127711252", "CorpusId": 110288949}, "corpusId": 110288949,
        "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/24a28b80b45b5e2f1eaeeefd7702701211f42b8f",
        "title": "Introduction to the Special Issue on Man aging Information Extraction",
        "abstract": "The field of information extraction (IE) focuses on extracting
        structured data, such as person names and organizations, from unstructured
        text. This field has had a long history. It attracted steady attention in
        the 80s and 90s, largely in the AI community. In the past decade, however,
        spurred on by the explosion of unstructured data on the World-Wide Web, this
        attention has turned into a torrent, gathering the efforts of researchers
        in the AI, DB, WWW, KDD, Semantic Web and IR communities. New IE problems
        have been identified, new IE techniques developed, many workshops organized,
        tutorials presented, companies founded, academic and industrial products deployed,
        and opensource prototypes developed (e.g., [5, 4, 3, 1, 2]; see [5] for the
        latest survey). The next few years are poised to witness even more accelerated
        activities in these areas. It is against this vibrant backdrop that we assemble
        this special issue. Our objective is threefold. First, we want to provide
        a glimpse into the current state of the field, highlighting in particular
        the wide range of IE problems. Second, we want to show that many IE problems
        can significantly benefit from the wealth of work on managing structured data
        in the database community. We believe therefore that our community can make
        a substantial contribution to the IE field. Finally, we hope that examining
        IE problems can in turn help us gain valuable insights into managing data
        in this Internet-centric world, a long-term goal of our community. Keeping
        in mind the above goals, we end this introduction by briefly describing the
        nine papers assembled for the issue. These papers fall into four broad categories.",
        "venue": "", "year": 2008, "referenceCount": 0, "citationCount": 16, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Engineering"],
        "s2FieldsOfStudy": [{"category": "Engineering", "source": "external"}, {"category":
        "Computer Science", "source": "s2-fos-model"}], "publicationTypes": ["Review"],
        "publicationDate": null, "journal": {"volume": "", "name": ""}, "authors":
        [{"authorId": "3030274", "name": "A. Doan"}, {"authorId": "1684012", "name":
        "L. Gravano"}, {"authorId": "1709145", "name": "R. Ramakrishnan"}, {"authorId":
        "2066721", "name": "Shivakumar Vaithyanathan"}]}, {"paperId": "62baadac0b75c742bb5e63314cc41c4a5aaeddbc",
        "externalIds": {"MAG": "2070633821", "DBLP": "conf/cikm/DakkaGI08", "DOI":
        "10.1145/1458082.1458320", "CorpusId": 6336049}, "corpusId": 6336049, "publicationVenue":
        {"id": "c6840156-ee10-4d78-8832-7f8909811576", "name": "IEEE Transactions
        on Knowledge and Data Engineering", "type": "journal", "alternate_names":
        ["IEEE Trans Knowl Data Eng"], "issn": "1041-4347", "url": "https://www.computer.org/web/tkde",
        "alternate_urls": ["http://ieeexplore.ieee.org/servlet/opac?punumber=69"]},
        "url": "https://www.semanticscholar.org/paper/62baadac0b75c742bb5e63314cc41c4a5aaeddbc",
        "title": "Answering General Time-Sensitive Queries", "abstract": "Time is
        an important dimension of relevance for a large number of searches, such as
        over blogs and news archives. So far, research on searching over such collections
        has largely focused on locating topically similar documents for a query. Unfortunately,
        topic similarity alone is not always sufficient for document ranking. In this
        paper, we observe that, for an important class of queries that we call time-sensitive
        queries, the publication time of the documents in a news archive is important
        and should be considered in conjunction with the topic similarity to derive
        the final document ranking. Earlier work has focused on improving retrieval
        for \u201crecency\u201d queries that target recent documents. We propose a
        more general framework for handling time-sensitive queries and we automatically
        identify the important time intervals that are likely to be of interest for
        a query. Then, we build scoring techniques that seamlessly integrate the temporal
        aspect into the overall ranking mechanism. We present an extensive experimental
        evaluation using a variety of news article data sets, including TREC data
        as well as real web data analyzed using the Amazon Mechanical Turk. We examine
        several techniques for detecting the important time intervals for a query
        over a news archive and for incorporating this information in the retrieval
        process. We show that our techniques are robust and significantly improve
        result quality for time-sensitive queries compared to state-of-the-art retrieval
        techniques.", "venue": "IEEE Transactions on Knowledge and Data Engineering",
        "year": 2008, "referenceCount": 34, "citationCount": 161, "influentialCitationCount":
        24, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "2008-10-26", "journal":
        {"volume": "24", "pages": "220-235", "name": "IEEE Transactions on Knowledge
        and Data Engineering"}, "authors": [{"authorId": "2278277", "name": "Wisam
        Dakka"}, {"authorId": "1684012", "name": "L. Gravano"}, {"authorId": "2942126",
        "name": "Panagiotis G. Ipeirotis"}]}, {"paperId": "87ecb3fd0071f0c58904cab78c8b18a7c821f7af",
        "externalIds": {"MAG": "2297599353", "CorpusId": 61895827}, "corpusId": 61895827,
        "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/87ecb3fd0071f0c58904cab78c8b18a7c821f7af",
        "title": "Faceted searching and browsing over large collections of textual
        and text-annotated objects", "abstract": "The vast majority of Internet users
        utilize search functionality to navigate the text and text-annotated collections
        of a variety of web sites. Users of sites such as The New York Times archive,
        YouTube, and others often face long lists of results for their queries due
        to the large size of the collections. Processing numerous items is also a
        hurdle for \"exploratory\" users who have no specific query in mind, such
        as a new shopper in an online store or a researcher accessing a news archive.
        In this thesis, we attempt to address this problem. We investigate faceted
        searching and browsing to provide users with access methods that are useful
        for discovering the content and the structure of long search results or large
        collections. Hierarchies that organize items based on their topics are common
        for browsing a large set of items. For example, Yahoo! uses a topic-based
        hierarchy to guide users to their web pages of interest. Google News and Newsblaster
        enable news readers to quickly navigate the daily news based on a hierarchy
        of topics and related events. We first present a technique for summarization-aware
        topic faceted searching and browsing, which integrates clustering and summarization
        so that users can browse a list of summarized clusters in the query results
        instead of individual documents. We have built a fully functional summarization-aware
        search system for daily news. In addition to the topic facet, time can be
        used as an alternative facet for browsing search results. We explore time
        as an important dimension and suggest a general framework for time-based language
        models to incorporate time into the retrieval task. In fact, many facets,
        other than topic and time, can be useful for faceted searching and browsing.
        As a result, we propose supervised and unsupervised methods to identify and
        extract multiple relevant facets from collections. Yet incorporating such
        facets in searching or browsing is not an easy task. A typical approach to
        utilize facets in searching and browsing is to build individual hierarchies
        for each facet. Unfortunately, these hierarchies are currently manually or
        semi-manually constructed and populated, which prevents deploying such hierarchies
        for large collections due to the cost of manually annotating each item in
        the collections. To solve this problem, we propose a system to automate the
        construction of hierarchies for the extracted facets, and show its effectiveness
        through appropriate user studies. We apply the faceted hierarchies to a range
        of large data sets, including collections of annotated images, television
        programming schedules, and web pages.", "venue": "", "year": 2008, "referenceCount":
        0, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate":
        null, "journal": {"volume": "", "name": ""}, "authors": [{"authorId": "1684012",
        "name": "L. Gravano"}, {"authorId": "2278277", "name": "Wisam Dakka"}]}, {"paperId":
        "8e568809e0d8b46b9a0ab47de3996633c2035620", "externalIds": {"MAG": "2125121047",
        "DBLP": "journals/tois/IpeirotisG08", "DOI": "10.1145/1344411.1344412", "CorpusId":
        2988469}, "corpusId": 2988469, "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/8e568809e0d8b46b9a0ab47de3996633c2035620",
        "title": "Classification-aware hidden-web text database selection", "abstract":
        "Many valuable text databases on the web have noncrawlable contents that are
        \u201chidden\u201d behind search interfaces. Metasearchers are helpful tools
        for searching over multiple such \u201chidden-web\u201d text databases at
        once through a unified query interface. An important step in the metasearching
        process is database selection, or determining which databases are the most
        relevant for a given user query. The state-of-the-art database selection techniques
        rely on statistical summaries of the database contents, generally including
        the database vocabulary and associated word frequencies. Unfortunately, hidden-web
        text databases typically do not export such summaries, so previous research
        has developed algorithms for constructing approximate content summaries from
        document samples extracted from the databases via querying. We present a novel
        \u201cfocused-probing\u201d sampling algorithm that detects the topics covered
        in a database and adaptively extracts documents that are representative of
        the topic coverage of the database. Our algorithm is the first to construct
        content summaries that include the frequencies of the words in the database.
        Unfortunately, Zipf''s law practically guarantees that for any relatively
        large database, content summaries built from moderately sized document samples
        will fail to cover many low-frequency words; in turn, incomplete content summaries
        might negatively affect the database selection process, especially for short
        queries with infrequent words. To enhance the sparse document samples and
        improve the database selection decisions, we exploit the fact that topically
        similar databases tend to have similar vocabularies, so samples extracted
        from databases with a similar topical focus can complement each other. We
        have developed two database selection algorithms that exploit this observation.
        The first algorithm proceeds hierarchically and selects the best categories
        for a query, and then sends the query to the appropriate databases in the
        chosen categories. The second algorithm uses \u201cshrinkage,\u201d a statistical
        technique for improving parameter estimation in the face of sparse data, to
        enhance the database content summaries with category-specific words. We describe
        how to modify existing database selection algorithms to adaptively decide
        (at runtime) whether shrinkage is beneficial for a query. A thorough evaluation
        over a variety of databases, including 315 real web databases as well as TREC
        data, suggests that the proposed sampling methods generate high-quality content
        summaries and that the database selection algorithms produce significantly
        more relevant database selection decisions and overall search results than
        existing algorithms.", "venue": "TOIS", "year": 2008, "referenceCount": 93,
        "citationCount": 21, "influentialCitationCount": 1, "isOpenAccess": true,
        "openAccessPdf": {"url": "http://www1.cs.columbia.edu/~gravano/Papers/2008/tois08.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "2008-03-01", "journal": {"volume": "26", "pages": "6:1-6:66",
        "name": "ACM Trans. Inf. Syst."}, "authors": [{"authorId": "2942126", "name":
        "Panagiotis G. Ipeirotis"}, {"authorId": "1684012", "name": "L. Gravano"}]},
        {"paperId": "abe9e21b18ae3934dcaa4d449c25ceced0a4866b", "externalIds": {"MAG":
        "1539182761", "CorpusId": 56356402}, "corpusId": 56356402, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/abe9e21b18ae3934dcaa4d449c25ceced0a4866b",
        "title": "Understanding, Estimating, and Incorporating Output Quality Into
        Join Algorithms For Information Extraction", "abstract": "Information extraction
        (IE) systems are trained to extract specific relations from text databases.
        Real-world applications often require that the output of multiple IE systems
        be joined to produce the data of interest. To optimize the execution of a
        join of multiple extracted relations, it is not sufficient to consider only
        execution time. In fact, the quality of the join output is of critical importance:
        unlike in the relational world, different join execution plans can produce
        join results of widely different quality whenever IE systems are involved.
        In this paper, we develop a principled approach to understand, estimate, and
        incorporate output quality into the join optimization process over extracted
        relations. We argue that the output quality is affected by (a) the configuration
        of the IE systems used to process the documents, (b) the document retrieval
        strategies used to retrieve documents, and (c) the actual join algorithm used.
        Our analysis considers a variety of join algorithms from relational query
        optimization, and predicts the output quality \u2013and, of course, the execution
        time\u2013 of the alternate execution plans. We establish the accuracy of
        our analytical models, as well as study the effectiveness of a quality-aware
        join optimizer, with a large-scale experimental evaluation over real-world
        text collections and state-of-the-art IE systems.", "venue": "", "year": 2008,
        "referenceCount": 26, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess":
        false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate":
        "2008-06-27", "journal": {"volume": "", "name": ""}, "authors": [{"authorId":
        "1777385", "name": "Alpa Jain"}, {"authorId": "2942126", "name": "Panagiotis
        G. Ipeirotis"}, {"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "3030274", "name": "A. Doan"}]}, {"paperId": "c81a0b8e4bb79cd72dc22bcf966a58504a04e979",
        "externalIds": {"DBLP": "conf/icde/JainDG08", "MAG": "2045463753", "DOI":
        "10.1109/ICDE.2008.4497472", "CorpusId": 6723468}, "corpusId": 6723468, "publicationVenue":
        {"id": "764e3630-ddac-4c21-af4b-9d32ffef082e", "name": "IEEE International
        Conference on Data Engineering", "type": "conference", "alternate_names":
        ["ICDE", "Int Conf Data Eng", "IEEE Int Conf Data Eng", "International Conference
        on Data Engineering"], "url": "http://www.wikicfp.com/cfp/program?id=1331"},
        "url": "https://www.semanticscholar.org/paper/c81a0b8e4bb79cd72dc22bcf966a58504a04e979",
        "title": "Optimizing SQL Queries over Text Databases", "abstract": "Text documents
        often embed data that is structured in nature, and we can expose this structured
        data using information extraction technology. By processing a text database
        with information extraction systems, we can materialize a variety of structured
        \"relations,\" over which we can then issue regular SQL queries. A key challenge
        to process SQL queries in this text-based scenario is efficiency: information
        extraction is time-consuming, so query processing strategies should minimize
        the number of documents that they process. Another key challenge is result
        quality: in the traditional relational world, all correct execution strategies
        for a SQL query produce the same (correct) result; in contrast, a SQL query
        execution over a text database might produce answers that are not fully accurate
        or complete, for a number of reasons. To address these challenges, we study
        a family of select-project-join SQL queries over text databases, and characterize
        query processing strategies on their efficiency and - critically - on their
        result quality as well. We optimize the execution of SQL queries over text
        databases in a principled, cost-based manner, incorporating this tradeoff
        between efficiency and result quality in a user-specific fashion. Our large-scale
        experiments- over real data sets and multiple information extraction systems
        - show that our SQL query processing approach consistently picks appropriate
        execution strategies for the desired balance between efficiency and result
        quality.", "venue": "IEEE International Conference on Data Engineering", "year":
        2008, "referenceCount": 29, "citationCount": 53, "influentialCitationCount":
        5, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2008-04-07",
        "journal": {"pages": "636-645", "name": "2008 IEEE 24th International Conference
        on Data Engineering"}, "authors": [{"authorId": "1777385", "name": "Alpa Jain"},
        {"authorId": "3030274", "name": "A. Doan"}, {"authorId": "1684012", "name":
        "L. Gravano"}]}, {"paperId": "d3fdaff1414ddc65196545cb8f4918f773e5d401", "externalIds":
        {"MAG": "2277214757", "CorpusId": 61543899}, "corpusId": 61543899, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/d3fdaff1414ddc65196545cb8f4918f773e5d401",
        "title": "Query processing over relations extracted from text databases",
        "abstract": "Text documents often embed data that is structured in nature,
        and this structured data is increasingly exposed using information extraction
        systems. Information extraction systems generate structured relations from
        documents, thus enabling expressive, structured queries over text databases.
        This dissertation studies the problem of processing structured queries over
        relations extracted from text databases. \nTo process structured queries over
        text databases, we face multiple challenges. One key challenge is efficiency:
        information extraction is a time-consuming process, so query processing strategies
        should minimize the number of documents that they process. Another key challenge
        is output quality: information extraction systems are often far from perfect,
        and might output erroneous information or miss information that they should
        capture, hence hurting output accuracy and completeness. At the same time,
        query processing decisions, such as the choice of information extraction systems
        or document retrieval strategies, also impact the output quality. Finally,
        depending on the nature of the information need, users may have varying preferences
        regarding the execution efficiency and quality expected from the querying
        process. This dissertation builds on the critical observation that, in addition
        to efficiency, which is important just as in traditional relational query
        optimization, the output quality of an execution is critical. \nIn our extraction-based
        scenario, query processing can be decomposed into a sequence of basic steps:
        retrieving relevant text documents, extracting relations from the documents,
        and joining extracted relations for queries involving multiple relations.
        Each of these steps presents different alternatives and together they form
        a space of possible query execution strategies. Our goal is to consider the
        user-specified requirements for execution efficiency and quality, and choose
        an execution strategy for each query based on a principled, cost-based comparison
        of the alternative execution strategies. We first introduce a simple, integrative
        optimization approach for processing queries involving single as well as multiple
        extracted relations. This approach considers each execution strategy as a
        whole and exploits database-specific statistics to predict the execution strategy
        characteristics. We then move towards an in-depth understanding of the impact
        of each component of an execution strategy on the overall execution. With
        this in mind, we rigorously analyze the critical components of an execution
        strategy and build statistically robust representations for information extraction
        systems, as well as statistical models for document retrieval strategies and
        join processing algorithms. These models help predict the efficiency and output
        quality of a variety of query execution strategies. Finally, we also consider
        the common scenario where information extraction systems report the extracted
        tuple together with scores that reflect the confidence in the correctness
        of the extracted tuples. Specifically, we present query processing algorithms
        that leverage these confidence scores and efficiently produce the high-confidence
        tuples, in turn discarding extracted tuples that are likely to be incorrect.
        \nIn summary, this thesis presents a principled query optimization approach
        for processing structured queries over text databases, taking into consideration
        both the efficiency and the output quality of the query execution strategies.
        Our hope is that the contributions of this work will help shrink the gap between
        structured databases and text databases, by enabling the seamless and expressive
        querying of all available information, regardless of whether it is in structured
        databases or embedded in natural language text.", "venue": "", "year": 2008,
        "referenceCount": 10, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess":
        false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate":
        null, "journal": {"volume": "", "name": ""}, "authors": [{"authorId": "1684012",
        "name": "L. Gravano"}, {"authorId": "1777385", "name": "Alpa Jain"}]}, {"paperId":
        "16d388dc0275c888776859884a309168cd5aac0e", "externalIds": {"DBLP": "conf/slte/XuVMTM07",
        "MAG": "225213018", "CorpusId": 953645}, "corpusId": 953645, "publicationVenue":
        {"id": "3bf02d32-1ee7-4657-9a34-cbec9d77bb5e", "name": "Slate", "type": "conference",
        "alternate_names": ["Symposium on Languages, Applications and Technologies",
        "Symp Lang Appl Technol", "SLATE"], "issn": "1090-6584", "url": "http://www.slate.com/"},
        "url": "https://www.semanticscholar.org/paper/16d388dc0275c888776859884a309168cd5aac0e",
        "title": "DeSIGN: an intelligent tutor to teach american sign language", "abstract":
        "This paper presents the development of DeSIGN, an educational software application
        for those deaf students who are taught to communicate using American Sign
        Language (ASL). The software reinforces English vocabulary and ASL signs by
        providing two essential components of a tutor, lessons and tests. The current
        version was designed for 5 th and 6 th graders, whose literacy skills lag
        by a grade or more on average. In addition, a game that allows the students
        to be creative has been integrated into the tests. Another feature of DeSIGN
        is its ability to intelligently adapt its tests to the changing knowledge
        of the student as determined by a knowledge tracing algorithm. A separate
        interface for the teacher enables additions and modifications to the content
        of the tutor and provides progress monitoring. These dynamic aspects help
        motivate the students to use the software repeatedly. This software prototype
        aims at a feasible and sustainable approach to increase the participation
        of deaf people in society. DeSIGN has undergone an iteration of testing and
        is currently in use at a school for the deaf in Pittsburgh.", "venue": "Slate",
        "year": 2007, "referenceCount": 2, "citationCount": 6, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": null, "journal":
        {"pages": "45-48"}, "authors": [{"authorId": "1685296", "name": "Eugene Agichtein"},
        {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "430d8e89c6466987f637d9a2f3642679de3844ba",
        "externalIds": {"MAG": "2156580346", "DBLP": "conf/icde/SayyadianLDG07", "DOI":
        "10.1109/ICDE.2007.367880", "CorpusId": 6543662}, "corpusId": 6543662, "publicationVenue":
        {"id": "764e3630-ddac-4c21-af4b-9d32ffef082e", "name": "IEEE International
        Conference on Data Engineering", "type": "conference", "alternate_names":
        ["ICDE", "Int Conf Data Eng", "IEEE Int Conf Data Eng", "International Conference
        on Data Engineering"], "url": "http://www.wikicfp.com/cfp/program?id=1331"},
        "url": "https://www.semanticscholar.org/paper/430d8e89c6466987f637d9a2f3642679de3844ba",
        "title": "Efficient Keyword Search Across Heterogeneous Relational Databases",
        "abstract": "Keyword search is a familiar and potentially effective way to
        find information of interest that is \"locked\" inside relational databases.
        Current work has generally assumed that answers for a keyword query reside
        within a single database. Many practical settings, however, require that we
        combine tuples from multiple databases to obtain the desired answers. Such
        databases are often autonomous and heterogeneous in their schemas and data.
        This paper describes Kite, a solution to the keyword-search problem over heterogeneous
        relational databases. Kite combines schema matching and structure discovery
        techniques to find approximate foreign-key joins across heterogeneous databases.
        Such joins are critical for producing query results that span multiple databases
        and relations. Kite then exploits the joins - discovered automatically across
        the databases - to enable fast and effective querying over the distributed
        data. Our extensive experiments over real-world data sets show that (1) our
        query processing algorithms are efficient and (2) our approach manages to
        produce high-quality query results spanning multiple heterogeneous databases,
        with no need for human reconciliation of the different databases.", "venue":
        "IEEE International Conference on Data Engineering", "year": 2007, "referenceCount":
        27, "citationCount": 133, "influentialCitationCount": 4, "isOpenAccess": true,
        "openAccessPdf": {"url": "http://www.cs.columbia.edu/~gravano/Papers/2007/icde07a.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}, {"category": "Economics", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2007-04-15",
        "journal": {"pages": "346-355", "name": "2007 IEEE 23rd International Conference
        on Data Engineering"}, "authors": [{"authorId": "2659396", "name": "Mayssam
        Sayyadian"}, {"authorId": "2260413", "name": "Hieu LeKhac"}, {"authorId":
        "3030274", "name": "A. Doan"}, {"authorId": "1684012", "name": "L. Gravano"}]},
        {"paperId": "560877311db77387ce1e822e3374f43eb41be692", "externalIds": {"MAG":
        "2134145495", "DBLP": "conf/icde/JainDG07", "DOI": "10.1109/ICDE.2007.368986",
        "CorpusId": 1788457}, "corpusId": 1788457, "publicationVenue": {"id": "764e3630-ddac-4c21-af4b-9d32ffef082e",
        "name": "IEEE International Conference on Data Engineering", "type": "conference",
        "alternate_names": ["ICDE", "Int Conf Data Eng", "IEEE Int Conf Data Eng",
        "International Conference on Data Engineering"], "url": "http://www.wikicfp.com/cfp/program?id=1331"},
        "url": "https://www.semanticscholar.org/paper/560877311db77387ce1e822e3374f43eb41be692",
        "title": "SQL Queries Over Unstructured Text Databases", "abstract": "Text
        documents often embed data that is structured in nature. By processing a text
        database with information extraction systems, we can define a variety of structured
        \"relations\" over which we can then issue SQL queries. Processing SQL queries
        in this text-based scenario presents multiple challenges. One key challenge
        is efficiency: information extraction is a time-consuming process, so query
        processing strategies should pick efficient extraction systems whenever possible,
        and also minimize the number of documents that they process. Another key challenge
        is result quality: extraction systems might output erroneous information or
        miss information that they should capture; also, efficiency-related query
        processing decisions (e.g., to avoid processing large numbers of useless documents)
        may compromise result completeness. To address these challenges, we characterize
        SQL query processing strategies in terms of their efficiency and result quality,
        and discuss the (user-specific) tradeoff between these two properties.", "venue":
        "IEEE International Conference on Data Engineering", "year": 2007, "referenceCount":
        7, "citationCount": 37, "influentialCitationCount": 0, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle",
        "Conference"], "publicationDate": "2007-04-15", "journal": {"pages": "1255-1257",
        "name": "2007 IEEE 23rd International Conference on Data Engineering"}, "authors":
        [{"authorId": "1777385", "name": "Alpa Jain"}, {"authorId": "3030274", "name":
        "A. Doan"}, {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "80b259d1f832a00c3f10c1aa477be1c1f85d7786",
        "externalIds": {"MAG": "2001300472", "DBLP": "conf/jcdl/DakkaG07", "DOI":
        "10.1145/1255175.1255187", "CorpusId": 3129918}, "corpusId": 3129918, "publicationVenue":
        {"id": "1da7d7d7-0481-489f-b27d-98cce1ebdf43", "name": "ACM/IEEE Joint Conference
        on Digital Libraries", "type": "conference", "alternate_names": ["ACM/IEEE
        Jt Conf Digit Libr", "JCDL"], "url": "http://www.jcdl.org/"}, "url": "https://www.semanticscholar.org/paper/80b259d1f832a00c3f10c1aa477be1c1f85d7786",
        "title": "Efficient summarization-aware search for online news articles",
        "abstract": "News portals gather and organize news articles published daily
        on the Internet. Typically, news articles are clustered into ''events'' and
        each cluster is displayed with a short description of its contents. A particularly
        interesting choice for describing the contents of a cluster is a machine-generated
        multi-document summary of the articles in the cluster. Such summaries are
        informative and help news readers to identify and explore only clusters of
        interest. Naturally, multi-document clusters and summaries are also valuable
        to help users navigate the results of keyword-search queries. Unfortunately,
        current document summarizers are still slow; as a result, search strategies
        that define document clusters and their multi-document summaries online, in
        a query-specific manner, are prohibitively expensive. In contrast, search
        strategies that only return offline, query-independent document clusters are
        efficient, but might return clusters whose (query-independent) summaries are
        of little relevance to the queries. In this paper, we present an efficient
        Hybrid search strategy to address the limitations of fully online and fully
        offline summarization-aware search approaches. Extensive experiments involving
        user relevance judgments and real news articles show that the quality of our
        Hybrid results is high, and that these results are computed in substantially
        less time than with the fully online strategy. We have implemented our strategy
        and made it available on the Newsblaster news summarization system, which
        crawls and summarizes news articles from a variety of web sources on a daily
        basis.", "venue": "ACM/IEEE Joint Conference on Digital Libraries", "year":
        2007, "referenceCount": 26, "citationCount": 11, "influentialCitationCount":
        1, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "2007-06-18", "journal":
        {"pages": "63-72"}, "authors": [{"authorId": "2278277", "name": "Wisam Dakka"},
        {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "a968bb1dea8969d062e4f68059ce94ad7ce734f9",
        "externalIds": {"DBLP": "journals/tods/IpeirotisAJG07", "MAG": "2155737120",
        "DOI": "10.1145/1292609.1292611", "CorpusId": 1554037}, "corpusId": 1554037,
        "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/a968bb1dea8969d062e4f68059ce94ad7ce734f9",
        "title": "Towards a query optimizer for text-centric tasks", "abstract": "Text
        is ubiquitous and, not surprisingly, many important applications rely on textual
        data for a variety of tasks. As a notable example, information extraction
        applications derive structured relations from unstructured text; as another
        example, focused crawlers explore the Web to locate pages about specific topics.
        Execution plans for text-centric tasks follow two general paradigms for processing
        a text database: either we can scan, or \u201ccrawl,\u201d the text database
        or, alternatively, we can exploit search engine indexes and retrieve the documents
        of interest via carefully crafted queries constructed in task-specific ways.
        The choice between crawl- and query-based execution plans can have a substantial
        impact on both execution time and output \u201ccompleteness\u201d (e.g., in
        terms of recall). Nevertheless, this choice is typically ad hoc and based
        on heuristics or plain intuition. In this article, we present fundamental
        building blocks to make the choice of execution plans for text-centric tasks
        in an informed, cost-based way. Towards this goal, we show how to analyze
        query- and crawl-based plans in terms of both execution time and output completeness.
        We adapt results from random-graph theory and statistics to develop a rigorous
        cost model for the execution plans. Our cost model reflects the fact that
        the performance of the plans depends on fundamental task-specific properties
        of the underlying text databases. We identify these properties and present
        efficient techniques for estimating the associated parameters of the cost
        model. We also present two optimization approaches for text-centric tasks
        that rely on the cost-model parameters and select efficient execution plans.
        Overall, our optimization approaches help build efficient execution plans
        for a task, resulting in significant efficiency and output completeness benefits.
        We complement our results with a large-scale experimental evaluation for three
        important text-centric tasks and over multiple real-life data sets.", "venue":
        "TODS", "year": 2007, "referenceCount": 67, "citationCount": 44, "influentialCitationCount":
        1, "isOpenAccess": true, "openAccessPdf": {"url": "http://archive.nyu.edu/bitstream/2451/14812/1/CEDER-06-12.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "2007-11-01", "journal": {"volume": "32", "pages": "21",
        "name": "ACM Trans. Database Syst."}, "authors": [{"authorId": "2942126",
        "name": "Panagiotis G. Ipeirotis"}, {"authorId": "1685296", "name": "Eugene
        Agichtein"}, {"authorId": "2066976803", "name": "Pranay Jain"}, {"authorId":
        "1684012", "name": "L. Gravano"}]}, {"paperId": "cf3f1cb8fb7fbf9d8393c24eb20d11a585a46b65",
        "externalIds": {"MAG": "2036074375", "DBLP": "journals/tods/IpeirotisNCG07",
        "DOI": "10.1145/1272743.1272744", "CorpusId": 14615675}, "corpusId": 14615675,
        "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/cf3f1cb8fb7fbf9d8393c24eb20d11a585a46b65",
        "title": "Modeling and managing changes in text databases", "abstract": "Large
        amounts of (often valuable) information are stored in web-accessible text
        databases. \u201cMetasearchers\u201d provide unified interfaces to query multiple
        such databases at once. For efficiency, metasearchers rely on succinct statistical
        summaries of the database contents to select the best databases for each query.
        So far, database selection research has largely assumed that databases are
        static, so the associated statistical summaries do not evolve over time. However,
        databases are rarely static and the statistical summaries that describe their
        contents need to be updated periodically to reflect content changes. In this
        article, we first report the results of a study showing how the content summaries
        of 152 real web databases evolved over a period of 52 weeks. Then, we show
        how to use \u201csurvival analysis\u201d techniques in general, and Cox''s
        proportional hazards regression in particular, to model database changes over
        time and predict when we should update each content summary. Finally, we exploit
        our change model to devise update schedules that keep the summaries up to
        date by contacting databases only when needed, and then we evaluate the quality
        of our schedules experimentally over real web databases.", "venue": "TODS",
        "year": 2007, "referenceCount": 43, "citationCount": 19, "influentialCitationCount":
        0, "isOpenAccess": true, "openAccessPdf": {"url": "http://www1.cs.columbia.edu/~gravano/Papers/2007/tods07a.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "2007-08-01", "journal": {"volume": "32", "pages": "14",
        "name": "ACM Trans. Database Syst."}, "authors": [{"authorId": "2942126",
        "name": "Panagiotis G. Ipeirotis"}, {"authorId": "2397437", "name": "A. Ntoulas"},
        {"authorId": "4658767", "name": "Junghoo Cho"}, {"authorId": "1684012", "name":
        "L. Gravano"}]}, {"paperId": "f934522657189b4accc47317af2770029999d0eb", "externalIds":
        {"DBLP": "conf/sigmod/IpeirotisAJG06", "MAG": "2103224511", "DOI": "10.1145/1142473.1142504",
        "CorpusId": 52799295}, "corpusId": 52799295, "publicationVenue": null, "url":
        "https://www.semanticscholar.org/paper/f934522657189b4accc47317af2770029999d0eb",
        "title": "To search or to crawl?: towards a query optimizer for text-centric
        tasks", "abstract": "Text is ubiquitous and, not surprisingly, many important
        applications rely on textual data for a variety of tasks. As a notable example,
        information extraction applications derive structured relations from unstructured
        text; as another example, focused crawlers explore the web to locate pages
        about specific topics. Execution plans for text-centric tasks follow two general
        paradigms for processing a text database: either we can scan, or ''crawl,\"
        the text database or, alternatively, we can exploit search engine indexes
        and retrieve the documents of interest via carefully crafted queries constructed
        in task-specific ways. The choice between crawl- and query-based execution
        plans can have a substantial impact on both execution time and output \"completeness\"
        (e.g., in terms of recall). Nevertheless, this choice is typically ad-hoc
        and based on heuristics or plain intuition. In this paper, we present fundamental
        building blocks to make the choice of execution plans for text-centric tasks
        in an informed, cost-based way. Towards this goal, we show how to analyze
        query- and crawl-based plans in terms of both execution time and output completeness.
        We adapt results from random-graph theory and statistics to develop a rigorous
        cost model for the execution plans. Our cost model reflects the fact that
        the performance of the plans depends on fundamental task-specific properties
        of the underlying text databases. We identify these properties and present
        efficient techniques for estimating the associated cost-model parameters.
        Overall, our approach helps predict the most appropriate execution plans for
        a task, resulting in significant efficiency and output completeness benefits.
        We complement our results with a large-scale experimental evaluation for three
        important text-centric tasks and over multiple real-life data sets.", "venue":
        "SIGMOD Conference", "year": 2006, "referenceCount": 40, "citationCount":
        85, "influentialCitationCount": 2, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["Book", "JournalArticle",
        "Conference"], "publicationDate": "2006-06-27", "journal": {"name": "Proceedings
        of the 2006 ACM SIGMOD international conference on Management of data"}, "authors":
        [{"authorId": "2942126", "name": "Panagiotis G. Ipeirotis"}, {"authorId":
        "1685296", "name": "Eugene Agichtein"}, {"authorId": "2066976803", "name":
        "Pranay Jain"}, {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId":
        "09c86f8704518f3cf1d6e559128167be0cfbd6ac", "externalIds": {"MAG": "2096565380",
        "DBLP": "conf/icde/IpeirotisNCG05", "DOI": "10.1109/ICDE.2005.91", "CorpusId":
        7057212}, "corpusId": 7057212, "publicationVenue": {"id": "764e3630-ddac-4c21-af4b-9d32ffef082e",
        "name": "IEEE International Conference on Data Engineering", "type": "conference",
        "alternate_names": ["ICDE", "Int Conf Data Eng", "IEEE Int Conf Data Eng",
        "International Conference on Data Engineering"], "url": "http://www.wikicfp.com/cfp/program?id=1331"},
        "url": "https://www.semanticscholar.org/paper/09c86f8704518f3cf1d6e559128167be0cfbd6ac",
        "title": "Modeling and managing content changes in text databases", "abstract":
        "Large amounts of (often valuable) information are stored in Web-accessible
        text databases. \"Metasearchers\" provide unified interfaces to query multiple
        such databases at once. For efficiency, metasearchers rely on succinct statistical
        summaries of the database contents to select the best databases for each query.
        So far, database selection research has largely assumed that databases are
        static, so the associated statistical summaries do not need to change over
        time. However, databases are rarely static and the statistical summaries that
        describe their contents need to be updated periodically to reflect content
        changes. In this paper, we first report the results of a study showing how
        the content summaries of 152 real Web databases evolved over a period of 52
        weeks. Then, we show how to use \"survival analysis\" techniques in general,
        and Cox''s proportional hazards regression in particular, to model database
        changes over time and predict when we should update each content summary.
        Finally, we exploit our change model to devise update schedules that keep
        the summaries up to date by contacting databases only when needed, and then
        we evaluate the quality of our schedules experimentally over real Web databases.",
        "venue": "IEEE International Conference on Data Engineering", "year": 2005,
        "referenceCount": 36, "citationCount": 41, "influentialCitationCount": 0,
        "isOpenAccess": true, "openAccessPdf": {"url": "https://academiccommons.columbia.edu/doi/10.7916/D8J10B0G/download",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle",
        "Conference"], "publicationDate": "2005-04-05", "journal": {"pages": "606-617",
        "name": "21st International Conference on Data Engineering (ICDE''05)"}, "authors":
        [{"authorId": "2942126", "name": "Panagiotis G. Ipeirotis"}, {"authorId":
        "2397437", "name": "A. Ntoulas"}, {"authorId": "4658767", "name": "Junghoo
        Cho"}, {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "2adfbbd25f971c2a6fc5ed0bddcb62a9f2abbb6f",
        "externalIds": {"MAG": "191965751", "CorpusId": 56525080}, "corpusId": 56525080,
        "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/2adfbbd25f971c2a6fc5ed0bddcb62a9f2abbb6f",
        "title": "Extracting relations from large text collections", "abstract": "A
        wealth of information is hidden within unstructured text. Often, this information
        can be beat exploited in structured or relational form, which is well suited
        for sophisticated query processing, for integration with relational database
        management systems, and for data mining. This thesis addresses two fundamental
        problems in extracting relations from large text collections: (1)\u00a0portability:
        tuning extraction systems for new domains and (2)\u00a0scalability: scaling
        up information extraction to large collections of documents. To address the
        first problem, we developed the Snowball information extraction system, a
        domain-independent system that learns to extract relations from unstructured
        text based on only a handful of user-provided example relation instances.
        Snowball can then be adapted to extract new relations with minimum human effort.
        Snowball improves the extraction accuracy by automatically evaluating the
        quality of both the acquired extraction patterns and the extracted relation
        instances. To address the second problem, we developed the QXtract system,
        which learns search engine queries that retrieve the documents that are relevant
        to a given information extraction system and extraction task. QXtract can
        dramatically improve the efficiency of the information extraction process,
        and provides a building block for extracting structured information and text
        data mining from the web at large.", "venue": "", "year": 2005, "referenceCount":
        77, "citationCount": 29, "influentialCitationCount": 3, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate":
        null, "journal": {"volume": "", "name": ""}, "authors": [{"authorId": "1684012",
        "name": "L. Gravano"}, {"authorId": "52467911", "name": "Yevgeny Agichtein"}]},
        {"paperId": "5a88c22a9312e5c50717569c6fe4a8e93bfc5cbb", "externalIds": {"MAG":
        "2477134663", "CorpusId": 63646173}, "corpusId": 63646173, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/5a88c22a9312e5c50717569c6fe4a8e93bfc5cbb",
        "title": "Evaluation of top-k queries over structured and semi-structured
        data", "abstract": "This thesis addresses fundamental issues in defining and
        efficiently processing top-k queries for a variety of scenarios, presenting
        different query processing challenges. In all these scenarios, our query processing
        algorithms attempt to focus on the objects that are most likely to be among
        the top-k matches for a given query, and discard---as early as possible---objects
        that are guaranteed not to qualify for the top- k answer, thus minimizing
        query processing time. \nOne important top-k query scenario that we study
        is web applications where the data objects are only available through remote,
        autonomous web sources. During query processing, these sources have to be
        queried repeatedly for a potentially large set of candidate objects. Processing
        top-k queries efficiently in such a scenario is challenging, as web sources
        exhibit diverse probing costs and access interfaces, as well as constraints
        on the degree of concurrency that they support. By considering the peculiarities
        of the sources and potentially designing object-specific query execution plans,
        our adaptive algorithms efficiently prune non-top- k answers and produce significantly
        more efficient query executions than previously existing algorithms, which
        select \"global\" query execution plans and do not fully take advantage of
        source-access parallelism. \nAs another contribution of this thesis, we extend
        our query processing algorithms to handle natural variations of the basic
        top-k query model. Specifically, we develop algorithms for queries that, in
        addition to fuzzy conditions, include some hard Boolean constraints (e.g.,
        to allow the users to specify a more complex set of preferences). We also
        study extensions of our algorithms to handle scenarios where individual objects
        can be combined through joint operations. (Abstract shortened by UMI.)", "venue":
        "", "year": 2005, "referenceCount": 65, "citationCount": 0, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": null, "publicationDate": null, "journal": {"volume": "",
        "name": ""}, "authors": [{"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "144173226", "name": "A. Marian"}]}, {"paperId": "9c72ac1af5630f2a27eff0e5d7726722424f1be9",
        "externalIds": {"DBLP": "series/ads/BrunoGKS05", "MAG": "163120950", "DOI":
        "10.1007/0-387-25229-0_4", "CorpusId": 7419668}, "corpusId": 7419668, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/9c72ac1af5630f2a27eff0e5d7726722424f1be9",
        "title": "XML & Data Streams", "abstract": null, "venue": "Stream Data Management",
        "year": 2005, "referenceCount": 39, "citationCount": 2, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": null, "publicationDate": null, "journal": {"pages": "59-81"},
        "authors": [{"authorId": "2362833", "name": "Nicolas Bruno"}, {"authorId":
        "1684012", "name": "L. Gravano"}, {"authorId": "1721062", "name": "Nick Koudas"},
        {"authorId": "145860176", "name": "D. Srivastava"}]}, {"paperId": "26790b8ed0c5df8a11cb931e3eb58e5661b6f7f2",
        "externalIds": {"MAG": "2105995744", "CorpusId": 14678636}, "corpusId": 14678636,
        "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/26790b8ed0c5df8a11cb931e3eb58e5661b6f7f2",
        "title": "Classifying and searching hidden-web text databases", "abstract":
        "The World-Wide Web continues to grow rapidly, which makes exploiting all
        available information a challenge. Search engines such as Google index an
        unprecedented amount of information, but still do not provide access to valuable
        content in text databases \u201chidden\u201d behind search interfaces. For
        example, current search engines largely ignore the contents of the Library
        of Congress, the US Patent and Trademark database, newspaper archives, and
        many other valuable sources of information because their contents are not
        \u201ccrawlable.\u201d However, users should be able to find the information
        that they need with as little effort as possible, regardless of whether this
        information is crawlable or not. As a significant step towards this goal,
        we have designed algorithms that support browsing and searching\u2014the two
        dominant ways of finding information on the web\u2014over \u201chidden-web\u201d
        text databases. \nTo support browsing, we have developed QProber, a system
        that automatically categorizes hidden-web text databases in a classification
        scheme, according to their topical focus. QProber categorizes databases without
        retrieving any document. Instead, QProber uses just the number of matches
        generated from a small number of topically focused query probes. The query
        probes are automatically generated using state-of-the-art supervised machine
        learning techniques and are typically short. QProber''s classification approach
        is sometimes orders of magnitude faster than approaches that require document
        retrieval. \nTo support searching, we have developed crucial building blocks
        for constructing sophisticated metasearchers, which search over many text
        databases at once through a unified query interface. For scalability and effectiveness,
        it is crucial for a metasearcher to have a good database selection component
        and send queries only to databases with relevant content. Usually, database
        selection algorithms rely on statistics that characterize the contents of
        each database. Unfortunately, many hidden-web text databases are completely
        autonomous and do not report any summaries of their contents. To build content
        summaries for such databases, we extract a small, topically focused document
        sample from each database during categorization and use it to build the respective
        content summaries. A potential problem with content summaries derived from
        document samples is that any reasonably small sample will suffer from data
        sparseness and will riot contain many words that appear in the database. (Abstract
        shortened by UMI.)", "venue": "", "year": 2004, "referenceCount": 139, "citationCount":
        11, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate": null,
        "journal": {"volume": "", "name": ""}, "authors": [{"authorId": "1684012",
        "name": "L. Gravano"}, {"authorId": "2942126", "name": "Panagiotis G. Ipeirotis"}]},
        {"paperId": "2889d7f93a9cdb0f2cc00464b0da6c2708523913", "externalIds": {"DOI":
        "10.1145/3249238", "CorpusId": 255908242}, "corpusId": 255908242, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/2889d7f93a9cdb0f2cc00464b0da6c2708523913",
        "title": "Session details: Search engineering 1", "abstract": null, "venue":
        "Proceedings of the 13th international conference on World Wide Web", "year":
        2004, "referenceCount": 0, "citationCount": 0, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": null, "s2FieldsOfStudy":
        [], "publicationTypes": ["Conference"], "publicationDate": "2004-05-17", "journal":
        {"name": "Proceedings of the 13th international conference on World Wide Web"},
        "authors": [{"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "31ccc944afda623530f81e980a864d62e82a446e",
        "externalIds": {"MAG": "596082102", "CorpusId": 60185761}, "corpusId": 60185761,
        "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/31ccc944afda623530f81e980a864d62e82a446e",
        "title": "CIKM 2004 : proceedings of the Thirteenth ACM Conference on Information
        and Knowledge Management, November 8-13, 2004, Washington, DC, USA", "abstract":
        null, "venue": "", "year": 2004, "referenceCount": 0, "citationCount": 2,
        "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
        "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
        Science", "source": "external"}, {"category": "Economics", "source": "s2-fos-model"}],
        "publicationTypes": null, "publicationDate": null, "journal": {"volume": "",
        "name": ""}, "authors": [{"authorId": "1405842291", "name": "David A. Evans"},
        {"authorId": "1684012", "name": "L. Gravano"}, {"authorId": "2083993", "name":
        "O. Herzog"}, {"authorId": "143869012", "name": "Chengxiang Zhai"}, {"authorId":
        "1940080", "name": "M. Ronthaler"}]}, {"paperId": "4d2d2e3d02ba66be54be5170099ee4ba0d923958",
        "externalIds": {"DBLP": "journals/toit/AgichteinLG04", "MAG": "2156368555",
        "DOI": "10.1145/990301.990303", "CorpusId": 9398338}, "corpusId": 9398338,
        "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/4d2d2e3d02ba66be54be5170099ee4ba0d923958",
        "title": "Learning to find answers to questions on the Web", "abstract": "We
        introduce a method for learning to find documents on the Web that contain
        answers to a given natural language question. In our approach, questions are
        transformed into new queries aimed at maximizing the probability of retrieving
        answers from existing information retrieval systems. The method involves automatically
        learning phrase features for classifying questions into different types, automatically
        generating candidate query transformations from a training set of question/answer
        pairs, and automatically evaluating the candidate transformations on target
        information retrieval systems such as real-world general purpose search engines.
        At run-time, questions are transformed into a set of queries, and reranking
        is performed on the documents retrieved. We present a prototype search engine,
        Tritus, that applies the method to Web search engines. Blind evaluation on
        a set of real queries from a Web search engine log shows that the method significantly
        outperforms the underlying search engines, and outperforms a commercial search
        engine specializing in question answering. Our methodology cleanly supports
        combining documents retrieved from different search engines, resulting in
        additional improvement with a system that combines search results from multiple
        Web search engines.", "venue": "TOIT", "year": 2004, "referenceCount": 51,
        "citationCount": 63, "influentialCitationCount": 2, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "2004-05-01", "journal": {"volume": "4", "pages": "129-162",
        "name": "ACM Trans. Internet Techn."}, "authors": [{"authorId": "1685296",
        "name": "Eugene Agichtein"}, {"authorId": "145840115", "name": "S. Lawrence"},
        {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "52667eff2fea8af809465233b8667277e1e47ecb",
        "externalIds": {"MAG": "2128756912", "DBLP": "journals/tkde/ChaudhuriGM04",
        "DOI": "10.1109/TKDE.2004.30", "CorpusId": 9471669}, "corpusId": 9471669,
        "publicationVenue": {"id": "c6840156-ee10-4d78-8832-7f8909811576", "name":
        "IEEE Transactions on Knowledge and Data Engineering", "type": "journal",
        "alternate_names": ["IEEE Trans Knowl Data Eng"], "issn": "1041-4347", "url":
        "https://www.computer.org/web/tkde", "alternate_urls": ["http://ieeexplore.ieee.org/servlet/opac?punumber=69"]},
        "url": "https://www.semanticscholar.org/paper/52667eff2fea8af809465233b8667277e1e47ecb",
        "title": "Optimizing top-k selection queries over multimedia repositories",
        "abstract": "Repositories of multimedia objects having multiple types of attributes
        (e.g., image, text) are becoming increasingly common. A query on these attributes
        will typically, request not just a set of objects, as in the traditional relational
        query model (filtering), but also a grade of match associated with each object,
        which indicates how well the object matches the selection condition (ranking).
        Furthermore, unlike in the relational model, users may just want the k top-ranked
        objects for their selection queries for a relatively small k. In addition
        to the differences in the query model, another peculiarity of multimedia repositories
        is that they may allow access to the attributes of each object only through
        indexes. We investigate how to optimize the processing of top-k selection
        queries over multimedia repositories. The access characteristics of the repositories
        and the above query model lead to novel issues in query optimization. In particular,
        the choice of the indexes used to search the repository strongly influences
        the cost of processing the filtering condition. We define an execution space
        that is search-minimal, i.e., the set of indexes searched is minimal. Although
        the general problem of picking an optimal plan in the search-minimal execution
        space is NP-hard, we present an efficient algorithm that solves the problem
        optimally with respect to our cost model and execution space when the predicates
        in the query are independent. We also show that the problem of optimizing
        top-k selection queries can be viewed, in many cases, as that of evaluating
        more traditional selection conditions. Thus, both problems can be viewed together
        as an extended filtering problem to which techniques of query processing and
        optimization may be adapted.", "venue": "IEEE Transactions on Knowledge and
        Data Engineering", "year": 2004, "referenceCount": 51, "citationCount": 154,
        "influentialCitationCount": 2, "isOpenAccess": true, "openAccessPdf": {"url":
        "https://academiccommons.columbia.edu/doi/10.7916/D8FX7NMZ/download", "status":
        null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
        "2004-08-01", "journal": {"volume": "16", "pages": "992-1009", "name": "IEEE
        Transactions on Knowledge and Data Engineering"}, "authors": [{"authorId":
        "145647476", "name": "S. Chaudhuri"}, {"authorId": "1684012", "name": "L.
        Gravano"}, {"authorId": "144173226", "name": "A. Marian"}]}, {"paperId": "5b777468a9e4dceef957872dfc033e790e352dab",
        "externalIds": {"MAG": "2167439683", "DBLP": "conf/icde/ChaudhuriGG04", "DOI":
        "10.1109/ICDE.2004.1319999", "CorpusId": 3033085}, "corpusId": 3033085, "publicationVenue":
        {"id": "f4d9ff4f-5eeb-4aaa-a916-8246dda89fad", "name": "Proceedings / International
        Conference on Data Engineering", "alternate_names": ["Proc  Int Conf Data
        Eng"], "issn": "1084-4627", "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000178"},
        "url": "https://www.semanticscholar.org/paper/5b777468a9e4dceef957872dfc033e790e352dab",
        "title": "Selectivity estimation for string predicates: overcoming the underestimation
        problem", "abstract": "Queries with (equality or LIKE) selection predicates
        over string attributes are widely used in relational databases. However, state-of-the-art
        techniques for estimating selectivities of string predicates are often biased
        towards severely underestimating selectivities. We develop accurate selectivity
        estimators for string predicates that adapt to data and query characteristics,
        and which can exploit and build on a variety of existing estimators. A thorough
        experimental evaluation over real data sets demonstrates the resilience of
        our estimators to variations in both data and query characteristics.", "venue":
        "Proceedings / International Conference on Data Engineering", "year": 2004,
        "referenceCount": 18, "citationCount": 68, "influentialCitationCount": 10,
        "isOpenAccess": true, "openAccessPdf": {"url": "http://www1.cs.columbia.edu/~gravano/Papers/2004/icde04.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle",
        "Conference"], "publicationDate": "2004-03-30", "journal": {"pages": "227-238",
        "name": "Proceedings. 20th International Conference on Data Engineering"},
        "authors": [{"authorId": "145647476", "name": "S. Chaudhuri"}, {"authorId":
        "1688230", "name": "Venkatesh Ganti"}, {"authorId": "1684012", "name": "L.
        Gravano"}]}, {"paperId": "71de6625e881220fad562972f0af288cb5649e85", "externalIds":
        {"DBLP": "conf/sigmod/IpeirotisG04", "MAG": "2112276485", "DOI": "10.1145/1007568.1007655",
        "CorpusId": 2198686}, "corpusId": 2198686, "publicationVenue": {"id": "f68b9e7e-ad3d-46cb-857d-23e49384143c",
        "name": "ACM SIGMOD Conference", "type": "conference", "alternate_names":
        ["SIGMOD", "ACM SIGMOD Conf"], "url": "https://sigmod.org/conferences/"},
        "url": "https://www.semanticscholar.org/paper/71de6625e881220fad562972f0af288cb5649e85",
        "title": "When one sample is not enough: improving text database selection
        using shrinkage", "abstract": "Database selection is an important step when
        searching over large numbers of distributed text databases. The database selection
        task relies on statistical summaries of the database contents, which are not
        typically exported by databases. Previous research has developed algorithms
        for constructing an approximate content summary of a text database from a
        small document sample extracted via querying. Unfortunately, Zipf''s law practically
        guarantees that content summaries built this way for any relatively large
        database will fail to cover many low-frequency words. Incomplete content summaries
        might negatively affect the database selection process, especially for short
        queries with infrequent words. To improve the coverage of approximate content
        summaries, we build on the observation that topically similar databases tend
        to have related vocabularies. Therefore, the approximate content summaries
        of topically related databases can complement each other and increase their
        coverage. Specifically, we exploit a (given or derived) hierarchical categorization
        of the databases and adapt the notion of \"shrinkage\" -a form of smoothing
        that has been used successfully for document classification-to the content
        summary construction task. A thorough evaluation over 315 real web databases
        as well as over TREC data suggests that the shrinkage-based content summaries
        are substantially more complete than their \"unshrunk\" counterparts. We also
        describe how to modify existing database selection algorithms to adaptively
        decide -at run-time-whether to apply shrinkage for a query. Our experiments,
        which rely on TREC data sets, queries, and the associated \"relevance judgments,\"
        show that our shrinkage-based approach significantly improves state-of-the-art
        database selection algorithms, and also outperforms a recently proposed hierarchical
        strategy that exploits database classification as well.", "venue": "ACM SIGMOD
        Conference", "year": 2004, "referenceCount": 36, "citationCount": 61, "influentialCitationCount":
        5, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "2004-06-13", "journal":
        {"pages": "767-778"}, "authors": [{"authorId": "2942126", "name": "Panagiotis
        G. Ipeirotis"}, {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId":
        "c88d258d8820bd2c2d227794382b07fa4b933919", "externalIds": {"DBLP": "conf/webdb/2004",
        "MAG": "267249765", "DOI": "10.1145/1017074", "CorpusId": 3529561}, "corpusId":
        3529561, "publicationVenue": {"id": "008c1686-e07c-419a-a0e6-f2c5cbde842e",
        "name": "International Workshop on the Web and Databases", "type": "conference",
        "alternate_names": ["Int Workshop Web Database", "WebDB"], "url": "http://www.wikicfp.com/cfp/program?id=3033"},
        "url": "https://www.semanticscholar.org/paper/c88d258d8820bd2c2d227794382b07fa4b933919",
        "title": "Proceedings of the Seventh International Workshop on the Web and
        Databases, WebDB 2004, June 17-18, 2004, Maison de la Chimie, Paris, France,
        Colocated with ACM SIGMOD/PODS 2004", "abstract": null, "venue": "International
        Workshop on the Web and Databases", "year": 2004, "referenceCount": 0, "citationCount":
        0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}], "publicationTypes": ["Conference"],
        "publicationDate": null, "journal": null, "authors": [{"authorId": "1403657578",
        "name": "S. Amer-Yahia"}, {"authorId": "1684012", "name": "L. Gravano"}]},
        {"paperId": "df601aeb0734178e660944b5381c328063f2e62c", "externalIds": {"MAG":
        "1594249656", "CorpusId": 60939835}, "corpusId": 60939835, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/df601aeb0734178e660944b5381c328063f2e62c",
        "title": "Proceedings of the 7th International Workshop on the Web and Databases:
        colocated with ACM SIGMOD/PODS 2004", "abstract": null, "venue": "", "year":
        2004, "referenceCount": 0, "citationCount": 2, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": null, "publicationDate": "2004-06-17", "journal": {"volume":
        "", "name": ""}, "authors": [{"authorId": "1684012", "name": "L. Gravano"},
        {"authorId": "1403657578", "name": "S. Amer-Yahia"}]}, {"paperId": "eea35842b6621527b5ea0f2f4f02f449a42741d5",
        "externalIds": {"DBLP": "conf/cikm/2004", "MAG": "282675016", "CorpusId":
        3845604}, "corpusId": 3845604, "publicationVenue": {"id": "7431ff67-91dc-41fa-b322-1b1ca657025f",
        "name": "International Conference on Information and Knowledge Management",
        "type": "conference", "alternate_names": ["Conference on Information and Knowledge
        Management", "Conf Inf Knowl Manag", "Int Conf Inf Knowl Manag", "CIKM"],
        "url": "http://www.cikm.org/"}, "url": "https://www.semanticscholar.org/paper/eea35842b6621527b5ea0f2f4f02f449a42741d5",
        "title": "Proceedings of the 2004 ACM CIKM International Conference on Information
        and Knowledge Management, Washington, DC, USA, November 8-13, 2004", "abstract":
        null, "venue": "International Conference on Information and Knowledge Management",
        "year": 2004, "referenceCount": 0, "citationCount": 2, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Economics", "source": "s2-fos-model"}], "publicationTypes":
        ["Conference"], "publicationDate": null, "journal": null, "authors": [{"authorId":
        "1693690", "name": "D. Grossman"}, {"authorId": "1684012", "name": "L. Gravano"},
        {"authorId": "1736467", "name": "ChengXiang Zhai"}, {"authorId": "2083993",
        "name": "O. Herzog"}, {"authorId": "1405842291", "name": "David A. Evans"}]},
        {"paperId": "15c71e9d0b467796ecc0519fe64203a4a79f76e5", "externalIds": {"MAG":
        "2148942721", "DBLP": "conf/vldb/HristidisGP03", "DOI": "10.1016/B978-012722442-8/50080-X",
        "CorpusId": 237524}, "corpusId": 237524, "publicationVenue": {"id": "a5c58053-0673-4cdb-b2b8-b6b0ad6911d1",
        "name": "Very Large Data Bases Conference", "type": "conference", "alternate_names":
        ["Very Large Data Bases", "Very Large Data Base", "VLDB", "Very Large Data
        Base Conf"], "url": "https://www.vldb.org/conference.html"}, "url": "https://www.semanticscholar.org/paper/15c71e9d0b467796ecc0519fe64203a4a79f76e5",
        "title": "Efficient IR-Style Keyword Search over Relational Databases", "abstract":
        null, "venue": "Very Large Data Bases Conference", "year": 2003, "referenceCount":
        20, "citationCount": 638, "influentialCitationCount": 96, "isOpenAccess":
        false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}, {"category": "Economics", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2003-09-09",
        "journal": {"pages": "850-861"}, "authors": [{"authorId": "1754970", "name":
        "Vagelis Hristidis"}, {"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "1786049", "name": "Y. Papakonstantinou"}]}, {"paperId": "1c474ca9904e9915a85a18683c6be1aa86631375",
        "externalIds": {"DBLP": "conf/webdb/AgichteinIG03", "MAG": "1586176254", "CorpusId":
        13160210}, "corpusId": 13160210, "publicationVenue": {"id": "008c1686-e07c-419a-a0e6-f2c5cbde842e",
        "name": "International Workshop on the Web and Databases", "type": "conference",
        "alternate_names": ["Int Workshop Web Database", "WebDB"], "url": "http://www.wikicfp.com/cfp/program?id=3033"},
        "url": "https://www.semanticscholar.org/paper/1c474ca9904e9915a85a18683c6be1aa86631375",
        "title": "Modeling Query-Based Access to Text Databases", "abstract": "Searchable
        text databases abound on the web. Applications that require access to such
        databases often resort to querying to extract relevant documents because of
        two main reasons. First, some text databases on the web are not \u201ccrawlable,\u201d
        and hence the only way to retrieve their documents is via querying. Second,
        applications often require only a small fraction of a database\u2019s contents,
        so retrieving relevant documents via querying is an attractive choice from
        an efficiency viewpoint, even for crawlable databases. Often an application\u2019s
        query-based strategy starts with a small number of user-provided queries.
        Then, new queries are extracted \u2010in an application-dependent way\u2010
        from the documents in the initial query results, and the process iterates.
        The success of this common type of strategy relies on retrieved documents
        \u201ccontributing\u201d new queries. If new documents fail to produce new
        queries, then the process might stall before all relevant documents are retrieved.
        In this paper, we develop a graph-based \u201creachability\u201d metric that
        allows to characterize when an application\u2019s query-based strategy will
        successfully \u201creach\u201d all documents that the application needs. We
        complement our metric with an efficient sampling-based technique that accurately
        estimates the reachability associated with a text database and an application\u2019s
        query-based strategy. We report preliminary experiments backing the usefulness
        of our metric and the accuracy of the associated estimation technique over
        real text databases and for two applications.", "venue": "International Workshop
        on the Web and Databases", "year": 2003, "referenceCount": 12, "citationCount":
        44, "influentialCitationCount": 1, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle", "Conference"],
        "publicationDate": null, "journal": {"pages": "87-92"}, "authors": [{"authorId":
        "1685296", "name": "Eugene Agichtein"}, {"authorId": "2942126", "name": "Panagiotis
        G. Ipeirotis"}, {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId":
        "5e13887f269b61c14142b6286665579abe5a9f45", "externalIds": {"MAG": "2116341550",
        "DBLP": "journals/tois/GravanoIS03", "DOI": "10.1145/635484.635485", "CorpusId":
        6732651}, "corpusId": 6732651, "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/5e13887f269b61c14142b6286665579abe5a9f45",
        "title": "QProber: A system for automatic classification of hidden-Web databases",
        "abstract": "The contents of many valuable Web-accessible databases are only
        available through search interfaces and are hence invisible to traditional
        Web \"crawlers.\" Recently, commercial Web sites have started to manually
        organize Web-accessible databases into Yahoo!-like hierarchical classification
        schemes. Here we introduce QProber, a modular system that automates this classification
        process by using a small number of query probes, generated by document classifiers.
        QProber can use a variety of types of classifiers to generate the probes.
        To classify a database, QProber does not retrieve or inspect any documents
        or pages from the database, but rather just exploits the number of matches
        that each query probe generates at the database in question. We have conducted
        an extensive experimental evaluation of QProber over collections of real documents,
        experimenting with different types of document classifiers and retrieval models.
        We have also tested our system with over one hundred Web-accessible databases.
        Our experiments show that our system has low overhead and achieves high classification
        accuracy across a variety of databases.", "venue": "TOIS", "year": 2003, "referenceCount":
        57, "citationCount": 142, "influentialCitationCount": 6, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": null, "journal": {"volume": "21", "pages": "1-41", "name":
        "ACM Trans. Inf. Syst."}, "authors": [{"authorId": "1684012", "name": "L.
        Gravano"}, {"authorId": "2942126", "name": "Panagiotis G. Ipeirotis"}, {"authorId":
        "1764547", "name": "M. Sahami"}]}, {"paperId": "667f5206d5afab49f830a24849bf14d5a6ad5564",
        "externalIds": {"MAG": "2152401660", "DBLP": "conf/icde/GravanoIKS03", "DOI":
        "10.1109/ICDE.2003.1260850", "CorpusId": 7283546}, "corpusId": 7283546, "publicationVenue":
        {"id": "f4d9ff4f-5eeb-4aaa-a916-8246dda89fad", "name": "Proceedings / International
        Conference on Data Engineering", "alternate_names": ["Proc  Int Conf Data
        Eng"], "issn": "1084-4627", "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000178"},
        "url": "https://www.semanticscholar.org/paper/667f5206d5afab49f830a24849bf14d5a6ad5564",
        "title": "Text joins for data cleansing and integration in an RDBMS", "abstract":
        "An organization''s data records are often noisy because of transcription
        errors, incomplete information, lack of standard formats for textual data
        or combinations thereof. A fundamental task in a data cleaning system is matching
        textual attributes that refer to the same entity (e.g., organization name
        or address). This matching is effectively performed via the cosine similarity
        metric from the information retrieval field. For robustness and scalability,
        these \"text joins\" are best done inside an RDBMS, which is where the data
        is likely to reside. Unfortunately, computing an exact answer to a text join
        can be expensive. We propose an approximate, sampling-based text join execution
        strategy that can be robustly executed in a standard, unmodified RDBMS.",
        "venue": "Proceedings / International Conference on Data Engineering", "year":
        2003, "referenceCount": 14, "citationCount": 68, "influentialCitationCount":
        3, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2003-03-05",
        "journal": {"pages": "729-731", "name": "Proceedings 19th International Conference
        on Data Engineering (Cat. No.03CH37405)"}, "authors": [{"authorId": "1684012",
        "name": "L. Gravano"}, {"authorId": "2942126", "name": "Panagiotis G. Ipeirotis"},
        {"authorId": "1721062", "name": "Nick Koudas"}, {"authorId": "145860176",
        "name": "D. Srivastava"}]}, {"paperId": "78b729049a0135dc75a021ce5bbc127902253fde",
        "externalIds": {"MAG": "2116544254", "DBLP": "conf/www/GravanoIKS03", "DOI":
        "10.1145/775152.775166", "CorpusId": 2075534}, "corpusId": 2075534, "publicationVenue":
        {"id": "e07422f9-c065-40c3-a37b-75e98dce79fe", "name": "The Web Conference",
        "type": "conference", "alternate_names": ["Web Conf", "WWW"], "url": "http://www.iw3c2.org/"},
        "url": "https://www.semanticscholar.org/paper/78b729049a0135dc75a021ce5bbc127902253fde",
        "title": "Text joins in an RDBMS for web data integration", "abstract": "The
        integration of data produced and collected across autonomous, heterogeneous
        web services is an increasingly important and challenging problem. Due to
        the lack of global identifiers, the same entity (e.g., a product) might have
        different textual representations across databases. Textual data is also often
        noisy because of transcription errors, incomplete information, and lack of
        standard formats. A fundamental task during data integration is matching of
        strings that refer to the same entity. In this paper, we adopt the widely
        used and established cosine similarity metric from the information retrieval
        field in order to identify potential string matches across web sources. We
        then use this similarity metric to characterize this key aspect of data integration
        as a join between relations on textual attributes, where the similarity of
        matches exceeds a specified threshold. Computing an exact answer to the text
        join can be expensive. For query processing efficiency, we propose a sampling-based
        join approximation strategy for execution in a standard, unmodified relational
        database management system (RDBMS), since more and more web sites are powered
        by RDBMSs with a web-based front end. We implement the join inside an RDBMS,
        using SQL queries, for scalability and robustness reasons. Finally, we present
        a detailed performance evaluation of an implementation of our algorithm within
        a commercial RDBMS, using real-life data sets. Our experimental results demonstrate
        the efficiency and accuracy of our techniques.", "venue": "The Web Conference",
        "year": 2003, "referenceCount": 25, "citationCount": 184, "influentialCitationCount":
        5, "isOpenAccess": true, "openAccessPdf": {"url": "http://www1.cs.columbia.edu/~gravano/Papers/2003/www03.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "2003-05-20", "journal": {"pages": "90-101"}, "authors":
        [{"authorId": "1684012", "name": "L. Gravano"}, {"authorId": "2942126", "name":
        "Panagiotis G. Ipeirotis"}, {"authorId": "1721062", "name": "Nick Koudas"},
        {"authorId": "145860176", "name": "D. Srivastava"}]}, {"paperId": "8e5f1448c34cfd78b85ef2601ddc2fda84fde101",
        "externalIds": {"MAG": "1985182453", "DBLP": "conf/cikm/GravanoHL03", "DOI":
        "10.1145/956863.956925", "CorpusId": 8623241}, "corpusId": 8623241, "publicationVenue":
        {"id": "7431ff67-91dc-41fa-b322-1b1ca657025f", "name": "International Conference
        on Information and Knowledge Management", "type": "conference", "alternate_names":
        ["Conference on Information and Knowledge Management", "Conf Inf Knowl Manag",
        "Int Conf Inf Knowl Manag", "CIKM"], "url": "http://www.cikm.org/"}, "url":
        "https://www.semanticscholar.org/paper/8e5f1448c34cfd78b85ef2601ddc2fda84fde101",
        "title": "Categorizing web queries according to geographical locality", "abstract":
        "Web pages (and resources, in general) can be characterized according to their
        geographical locality. For example, a web page with general information about
        wildflowers could be considered a global page, likely to be of interest to
        a geographically broad audience. In contrast, a web page with listings on
        houses for sale in a specific city could be regarded as a local page, likely
        to be of interest only to an audience in a relatively narrow region. Similarly,
        some search engine queries (implicitly) target global pages, while other queries
        are after local pages. For example, the best results for query [wildflowers]
        are probably global pages about wildflowers such as the one discussed above.
        However, local pages that are relevant to, say, San Francisco are likely to
        be good matches for a query [houses for sale] that was issued by a San Francisco
        resident or by somebody moving to that city. Unfortunately, search engines
        do not analyze the geographical locality of queries and users, and hence often
        produce sub-optimal results. Thus query [wildflowers] might return pages that
        discuss wildflowers in specific U.S. states (and not general information about
        wildflowers), while query [houses for sale] might return pages with real estate
        listings for locations other than that of interest to the person who issued
        the query. Deciding whether an unseen query should produce mostly local or
        global pages---without placing this burden on the search engine users---is
        an important and challenging problem, because queries are often ambiguous
        or underspecify the information they are after. In this paper, we address
        this problem by first defining how to categorize queries according to their
        (often implicit) geographical locality. We then introduce several alternatives
        for automatically and efficiently categorizing queries in our scheme, using
        a variety of state-of-the-art machine learning tools. We report a thorough
        evaluation of our classifiers using a large sample of queries from a real
        web search engine, and conclude by discussing how our query categorization
        approach can help improve query result quality.", "venue": "International
        Conference on Information and Knowledge Management", "year": 2003, "referenceCount":
        21, "citationCount": 165, "influentialCitationCount": 6, "isOpenAccess": true,
        "openAccessPdf": {"url": "http://www1.cs.columbia.edu/~gravano/Papers/2003/cikm03.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "2003-11-03", "journal": {"pages": "325-333"}, "authors":
        [{"authorId": "1684012", "name": "L. Gravano"}, {"authorId": "1799688", "name":
        "V. Hatzivassiloglou"}, {"authorId": "102479964", "name": "R. Lichtenstein"}]},
        {"paperId": "9cc3da2719436dfae9f76ae494aa0af0de4b16a7", "externalIds": {"MAG":
        "2153251667", "CorpusId": 20316930}, "corpusId": 20316930, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/9cc3da2719436dfae9f76ae494aa0af0de4b16a7",
        "title": "Statistics on query expressions in relational database management
        systems", "abstract": "The query optimizer is the component in a relational
        database system that identifies efficient execution plans for input queries.
        Modern optimizers generally explore many alternative query plans in a cost-based
        manner. Specifically, the resource consumption and associated cost of each
        candidate plan is estimated, and the plan with the least expected cost is
        chosen for execution. The cost estimation for a plan depends on several factors,
        including resource availability during execution, the specific operators that
        compose the plan, and the size of intermediate results that would be generated
        during the plan execution. Among these factors, the intermediate-result size
        (or cardinality) estimation is the main source of inaccuracies during optimization:
        cardinality estimation typically relies on several simplifying assumptions
        that often do not hold in practice. Optimizers then sometimes base their decisions
        on inaccurate information and produce low-quality execution plans. To address
        this limitation, in this thesis we introduce the concept of SITS, which are
        statistics built on query expressions. SITS directly and accurately model
        intermediate results in a query execution plan, and therefore avoid error-prone
        simplifying assumptions during cardinality estimation. If optimizers have
        appropriate SITS available during optimization, the resulting query plans
        can be dramatically better than otherwise. Although SITs are a fairly simple
        concept, challenging problems need to be addressed before SITs can be seamlessly
        integrated into modern relational database systems. In this thesis we study
        three important challenges associated with SITS. First, we show how to modify
        query optimizers to exploit the additional statistical information provided
        by SITs without significantly increasing optimization time. Second, we study
        a spectrum of alternatives to create SITs, which balance efficiency of construction
        and accuracy of the resulting estimators. Third, we present techniques to
        recommend a small but highly beneficial set of SITs to materialize in a database
        system for a given query workload. In summary, we address the main obstacles
        for enabling SITs for optimization, namely which SITs to build, how to build
        them, and how to exploit them during optimization. Overall, SITs constitute
        a well-founded approach for dealing with complex data correlations, and positively
        impact the efficiency of relational database systems.", "venue": "", "year":
        2003, "referenceCount": 83, "citationCount": 5, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": null, "publicationDate": null, "journal": {"volume": "",
        "name": ""}, "authors": [{"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "2362833", "name": "Nicolas Bruno"}]}, {"paperId": "9fb27fb5d86ece45b7e0529de70c446d4c37041d",
        "externalIds": {"DOI": "10.1145/635484.635485", "CorpusId": 248401277}, "corpusId":
        248401277, "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/9fb27fb5d86ece45b7e0529de70c446d4c37041d",
        "title": "QProber", "abstract": "The contents of many valuable Web-accessible
        databases are only available through search interfaces and are hence invisible
        to traditional Web \"crawlers.\" Recently, commercial Web sites have started
        to manually organize Web-accessible databases into Yahoo!-like hierarchical
        classification schemes. Here we introduce QProber, a modular system that automates
        this classification process by using a small number of query probes, generated
        by document classifiers. QProber can use a variety of types of classifiers
        to generate the probes. To classify a database, QProber does not retrieve
        or inspect any documents or pages from the database, but rather just exploits
        the number of matches that each query probe generates at the database in question.
        We have conducted an extensive experimental evaluation of QProber over collections
        of real documents, experimenting with different types of document classifiers
        and retrieval models. We have also tested our system with over one hundred
        Web-accessible databases. Our experiments show that our system has low overhead
        and achieves high classification accuracy across a variety of databases.",
        "venue": "ACM Transactions on Information Systems", "year": 2003, "referenceCount":
        10, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": null, "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "s2-fos-model"}], "publicationTypes": null,
        "publicationDate": "2003-01-01", "journal": {"volume": "21", "pages": "1-41",
        "name": "ACM Transactions on Information Systems"}, "authors": [{"authorId":
        "1684012", "name": "L. Gravano"}, {"authorId": "2942126", "name": "Panagiotis
        G. Ipeirotis"}, {"authorId": "1764547", "name": "M. Sahami"}]}, {"paperId":
        "a89dab25098559779eb5ff6fdd5fff966c893976", "externalIds": {"MAG": "1876061170",
        "DOI": "10.7916/D8BV7QHT", "CorpusId": 13914360}, "corpusId": 13914360, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/a89dab25098559779eb5ff6fdd5fff966c893976",
        "title": "Parallel Probing of Web Databases for Top-k Query Processing", "abstract":
        "A \u201ctop-k query\u201d specifies a set of preferredvalues for the attributes
        of a relation and expects as a result thek objects that are \u201cclosest\u201d
        to the given preferences according to some distance function. In many web
        applications, the relation attributes are only available viaprobesto autonomous
        webaccessible sources. Probing these sources sequentially to process a topk
        query is inefficient, since web accesses exhibit high and variable latency.
        Fortunately, web sources can be probed in parallel, and each source can typically
        process concurrent requests, although sources may impose some restrictions
        on the type and number of probes that they are willing to accept. These characteristics
        of web sources motivate the introduction of parallel top-k query processing
        strategies, which are the focus of this paper. We present efficient techniques
        that maximize source-access parallelism to minimize query response time, while
        satisfying source access constraints. A thorough experimental evaluation over
        both synthetic and real web sources shows that our techniques can be significantly
        more efficient than previously proposed sequential strategies. In addition,
        we adapt our parallel algorithms for the alternate optimization goal of minimizing
        source load while still exploiting source-access parallelism.", "venue": "",
        "year": 2003, "referenceCount": 12, "citationCount": 0, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": null, "publicationDate": null, "journal": {"volume": "",
        "name": ""}, "authors": [{"authorId": "144173226", "name": "A. Marian"}, {"authorId":
        "1684012", "name": "L. Gravano"}]}, {"paperId": "dda99e75f4c54db13bb891060c63cb796cb44466",
        "externalIds": {"DBLP": "conf/icde/AgichteinG03", "MAG": "2096891167", "DOI":
        "10.1109/ICDE.2003.1260786", "CorpusId": 8177615}, "corpusId": 8177615, "publicationVenue":
        {"id": "f4d9ff4f-5eeb-4aaa-a916-8246dda89fad", "name": "Proceedings / International
        Conference on Data Engineering", "alternate_names": ["Proc  Int Conf Data
        Eng"], "issn": "1084-4627", "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000178"},
        "url": "https://www.semanticscholar.org/paper/dda99e75f4c54db13bb891060c63cb796cb44466",
        "title": "Querying text databases for efficient information extraction", "abstract":
        "A wealth of information is hidden within unstructured text. This information
        is often best exploited in structured or relational form, which is suited
        for sophisticated query processing, for integration with relational databases,
        and for data mining. Current information extraction techniques extract relations
        from a text database by examining every document in the database, or use filters
        to select promising documents for extraction. The exhaustive scanning approach
        is not practical or even feasible for large databases, and the current filtering
        techniques require human involvement to maintain and to adapt to new databases
        and domains. We develop an automatic query-based technique to retrieve documents
        useful for the extraction of user-defined relations from large text databases,
        which can be adapted to new domains, databases, or target relations with minimal
        human effort. We report a thorough experimental evaluation over a large newspaper
        archive that shows that we significantly improve the efficiency of the extraction
        process by focusing only on promising documents.", "venue": "Proceedings /
        International Conference on Data Engineering", "year": 2003, "referenceCount":
        35, "citationCount": 118, "influentialCitationCount": 9, "isOpenAccess": true,
        "openAccessPdf": {"url": "https://academiccommons.columbia.edu/doi/10.7916/D87S7X1D/download",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle",
        "Conference"], "publicationDate": "2003-03-05", "journal": {"pages": "113-124",
        "name": "Proceedings 19th International Conference on Data Engineering (Cat.
        No.03CH37405)"}, "authors": [{"authorId": "1685296", "name": "Eugene Agichtein"},
        {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "f9df398e5e8e173111a27a12da5ee72f1722ad11",
        "externalIds": {"MAG": "2151772234", "DBLP": "conf/icde/BrunoGKS03", "DOI":
        "10.1109/ICDE.2003.1260788", "CorpusId": 15233216}, "corpusId": 15233216,
        "publicationVenue": {"id": "f4d9ff4f-5eeb-4aaa-a916-8246dda89fad", "name":
        "Proceedings / International Conference on Data Engineering", "alternate_names":
        ["Proc  Int Conf Data Eng"], "issn": "1084-4627", "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000178"},
        "url": "https://www.semanticscholar.org/paper/f9df398e5e8e173111a27a12da5ee72f1722ad11",
        "title": "Navigation- vs. index-based XML multi-query processing", "abstract":
        "XML path queries form the basis of complex filtering of XML data. Most current
        XML path query processing techniques can be divided in two groups. Navigation-based
        algorithms compute results by analyzing an input document one tag at a time.
        In contrast, index-based algorithms take advantage of precomputed numbering
        schemes over the input XML document. We introduce a new index-based technique,
        index-filter, to answer multiple XML path queries. Index-filter uses indexes
        built over the document tags to avoid processing large portions of the input
        document that are guaranteed not to be part of any match. We analyze index-filter
        and compare it against Y-filter, a state-of-the-art navigation-based technique.
        We show that both techniques have their advantages, and we discuss the scenarios
        under which each technique is superior to the other one. In particular, we
        show that while most XML path query processing techniques work off SAX events,
        in some cases it pays off to preprocess the input document, augmenting it
        with auxiliary information that can be used to evaluate the queries faster.
        We present experimental results over real and synthetic XML documents that
        validate our claims.", "venue": "Proceedings / International Conference on
        Data Engineering", "year": 2003, "referenceCount": 25, "citationCount": 102,
        "influentialCitationCount": 5, "isOpenAccess": true, "openAccessPdf": {"url":
        "http://www1.cs.columbia.edu/~gravano/Papers/2003/icde03a.pdf", "status":
        null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle", "Conference"],
        "publicationDate": "2003-03-05", "journal": {"pages": "139-150", "name": "Proceedings
        19th International Conference on Data Engineering (Cat. No.03CH37405)"}, "authors":
        [{"authorId": "2362833", "name": "Nicolas Bruno"}, {"authorId": "1684012",
        "name": "L. Gravano"}, {"authorId": "1721062", "name": "Nick Koudas"}, {"authorId":
        "145860176", "name": "D. Srivastava"}]}, {"paperId": "10927ae8a906b482330a95b411285e2e4e407ca6",
        "externalIds": {"MAG": "2134195632", "DBLP": "journals/tods/BrunoCG02", "DOI":
        "10.1145/568518.568519", "CorpusId": 12106256}, "corpusId": 12106256, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/10927ae8a906b482330a95b411285e2e4e407ca6",
        "title": "Top-k selection queries over relational databases: Mapping strategies
        and performance evaluation", "abstract": "In many applications, users specify
        target values for certain attributes, without requiring exact matches to these
        values in return. Instead, the result to such queries is typically a rank
        of the \"top k\" tuples that best match the given attribute values. In this
        paper, we study the advantages and limitations of processing a top-k query
        by translating it into a single range query that a traditional relational
        database management system (RDBMS) can process efficiently. In particular,
        we study how to determine a range query to evaluate a top-k query by exploiting
        the statistics available to an RDBMS, and the impact of the quality of these
        statistics on the retrieval efficiency of the resulting scheme. We also report
        the first experimental evaluation of the mapping strategies over a real RDBMS,
        namely over Microsoft''s SQL Server 7.0. The experiments show that our new
        techniques are robust and significantly more efficient than previously known
        strategies requiring at least one sequential scan of the data sets.", "venue":
        "TODS", "year": 2002, "referenceCount": 41, "citationCount": 286, "influentialCitationCount":
        27, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "2002-06-01", "journal":
        {"volume": "27", "pages": "153-187", "name": "ACM Trans. Database Syst."},
        "authors": [{"authorId": "2362833", "name": "Nicolas Bruno"}, {"authorId":
        "145647476", "name": "S. Chaudhuri"}, {"authorId": "1684012", "name": "L.
        Gravano"}]}, {"paperId": "3240f47572a6efef76c6bb6656d4cc0bbb9eb03a", "externalIds":
        {"MAG": "3021013053", "DBLP": "conf/vldb/IpeirotisG02", "DOI": "10.1016/B978-155860869-6/50042-1",
        "CorpusId": 1596866}, "corpusId": 1596866, "publicationVenue": {"id": "a5c58053-0673-4cdb-b2b8-b6b0ad6911d1",
        "name": "Very Large Data Bases Conference", "type": "conference", "alternate_names":
        ["Very Large Data Bases", "Very Large Data Base", "VLDB", "Very Large Data
        Base Conf"], "url": "https://www.vldb.org/conference.html"}, "url": "https://www.semanticscholar.org/paper/3240f47572a6efef76c6bb6656d4cc0bbb9eb03a",
        "title": "Distributed Search over the Hidden Web: Hierarchical Database Sampling
        and Selection", "abstract": null, "venue": "Very Large Data Bases Conference",
        "year": 2002, "referenceCount": 38, "citationCount": 225, "influentialCitationCount":
        12, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2002-08-20",
        "journal": {"pages": "394-405"}, "authors": [{"authorId": "2942126", "name":
        "Panagiotis G. Ipeirotis"}, {"authorId": "1684012", "name": "L. Gravano"}]},
        {"paperId": "3d15b09f8c1117157a7263830210c36ae2281124", "externalIds": {"MAG":
        "109105922", "CorpusId": 59748825}, "corpusId": 59748825, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/3d15b09f8c1117157a7263830210c36ae2281124",
        "title": "Query- vs. Crawling-based Classification of Searchable Web Databases.",
        "abstract": "The World-Wide Web is one of the main channels through which
        people currently exchange information. Unfortunately, this information is
        not characterized in a way that would make its semantics readily understandable
        by computers, which complicates building value-added services on top of the
        existing information. An ambitious effort that aims to facilitate the development
        of such services is the so-called \u201cSemantic Web.\u201d According to Berners-Lee
        et al. [1]:", "venue": "", "year": 2002, "referenceCount": 10, "citationCount":
        14, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate": null,
        "journal": {"volume": "25", "pages": "43-50", "name": "IEEE Data(base) Engineering
        Bulletin"}, "authors": [{"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "2942126", "name": "Panagiotis G. Ipeirotis"}, {"authorId": "1764547", "name":
        "M. Sahami"}]}, {"paperId": "3d6c0991420130c94efecace92e99233ad0e8683", "externalIds":
        {"DBLP": "series/ads/AmbiteABFGHHKPRRSSSSSTWZ02", "MAG": "101250378", "DOI":
        "10.1007/0-306-47374-7_5", "CorpusId": 13142724}, "corpusId": 13142724, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/3d6c0991420130c94efecace92e99233ad0e8683",
        "title": "Data Integration and Access - The Digital Government Research Center''s
        Energy Data Collection (EDC) Project", "abstract": null, "venue": "Advances
        in Digital Government", "year": 2002, "referenceCount": 31, "citationCount":
        28, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Engineering", "Computer Science"], "s2FieldsOfStudy":
        [{"category": "Engineering", "source": "external"}, {"category": "Computer
        Science", "source": "external"}, {"category": "Computer Science", "source":
        "s2-fos-model"}], "publicationTypes": ["Review"], "publicationDate": null,
        "journal": {"pages": "85-106"}, "authors": [{"authorId": "2887330", "name":
        "J. Ambite"}, {"authorId": "1717530", "name": "Y. Arens"}, {"authorId": "38399249",
        "name": "Walter Bourne"}, {"authorId": "1809403", "name": "Steven K. Feiner"},
        {"authorId": "1684012", "name": "L. Gravano"}, {"authorId": "1799688", "name":
        "V. Hatzivassiloglou"}, {"authorId": "144547315", "name": "E. Hovy"}, {"authorId":
        "1761739", "name": "Judith L. Klavans"}, {"authorId": "2135707", "name": "A.
        Philpot"}, {"authorId": "3222571", "name": "Usha Ramachandran"}, {"authorId":
        "144812095", "name": "K. A. Ross"}, {"authorId": "2479999", "name": "J. Sandhaus"},
        {"authorId": "2082224307", "name": "Deniz Sari\u00f6z"}, {"authorId": "2441562",
        "name": "Rolfe R. Schmidt"}, {"authorId": "1773086", "name": "C. Shahabi"},
        {"authorId": "2061103160", "name": "Anurag Singla"}, {"authorId": "3239441",
        "name": "Surabhan Temiyabutr"}, {"authorId": "145822024", "name": "B. Whitman"},
        {"authorId": "95818578", "name": "K. A. Zaman"}]}, {"paperId": "8f88b41d82d65165b3b98820358e86f0b0a505fc",
        "externalIds": {"DBLP": "conf/dmkd/Gravano02", "MAG": "115807375", "CorpusId":
        35137858}, "corpusId": 35137858, "publicationVenue": {"id": "0cefa4c4-400c-4713-8428-85f755bd5945",
        "name": "Workshop on Research Issues on Data Mining and Knowledge Discovery",
        "type": "conference", "alternate_names": ["DMKD", "Workshop Res Issue Data
        Min Knowl Discov"]}, "url": "https://www.semanticscholar.org/paper/8f88b41d82d65165b3b98820358e86f0b0a505fc",
        "title": "Web Mining Meets Web Search", "abstract": null, "venue": "Workshop
        on Research Issues on Data Mining and Knowledge Discovery", "year": 2002,
        "referenceCount": 0, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess":
        false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": null, "journal": {"volume": "", "name": ""}, "authors":
        [{"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "a8a4502dc05e79de23a587c86071594ac39505de",
        "externalIds": {"MAG": "2119070977", "DBLP": "conf/jcdl/IpeirotisBG02", "DOI":
        "10.1145/544220.544254", "CorpusId": 8255386}, "corpusId": 8255386, "publicationVenue":
        {"id": "1da7d7d7-0481-489f-b27d-98cce1ebdf43", "name": "ACM/IEEE Joint Conference
        on Digital Libraries", "type": "conference", "alternate_names": ["ACM/IEEE
        Jt Conf Digit Libr", "JCDL"], "url": "http://www.jcdl.org/"}, "url": "https://www.semanticscholar.org/paper/a8a4502dc05e79de23a587c86071594ac39505de",
        "title": "Extending SDARTS: extracting metadata from web databases and interfacing
        with the open archives initiative", "abstract": "SDARTS is a protocol and
        toolkit designed to facilitate metasearching. SDARTS combines two complementary
        existing protocols, SDLIP and STARTS, to define a uniform interface that collections
        should support for searching and exporting metasearch-related metadata. SDARTS
        also includes a toolkit with wrappers that are easily customized to make both
        local and remote document collections SDARTS-compliant. This paper describes
        two significant ways in which we have extended the SDARTS toolkit. First,
        we have added a tool that automatically builds rich content summaries for
        remote web collections bym probing the collections with appropriate queries.
        These content summaries can then be used by a metasearcher to select over
        which collections to evaluate a given query. Second, we have enhanced the
        SDARTS toolkit so that all SDARTS-compliant collections export their metadata
        under the emerging Open Archives Initiative (OAI) protocol. Conversely, the
        SDARTS toolkit now also allows all OAI-compliant collections to be made SDARTS-compliant
        with minimal effort. As a result, we implemented a bridge between SDARTS and
        OAI, which will facilitate easy interoperability among a potentially large
        number of collections. The SDARTS toolkit, with all related documentation
        and source code, is publicly available at http://sdarts.cs.columbia.edu.",
        "venue": "ACM/IEEE Joint Conference on Digital Libraries", "year": 2002, "referenceCount":
        25, "citationCount": 4, "influentialCitationCount": 0, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "2002-07-14", "journal": {"pages": "162-170"}, "authors":
        [{"authorId": "2942126", "name": "Panagiotis G. Ipeirotis"}, {"authorId":
        "50475412", "name": "T. Barry"}, {"authorId": "1684012", "name": "L. Gravano"}]},
        {"paperId": "c6e3d4a8fba3cd5d592d62f533ff95bde84a8f22", "externalIds": {"DBLP":
        "conf/icde/BrunoGM02", "MAG": "2099797738", "DOI": "10.1109/ICDE.2002.994751",
        "CorpusId": 1218314}, "corpusId": 1218314, "publicationVenue": {"id": "f4d9ff4f-5eeb-4aaa-a916-8246dda89fad",
        "name": "Proceedings / International Conference on Data Engineering", "alternate_names":
        ["Proc  Int Conf Data Eng"], "issn": "1084-4627", "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000178"},
        "url": "https://www.semanticscholar.org/paper/c6e3d4a8fba3cd5d592d62f533ff95bde84a8f22",
        "title": "Evaluating top-k queries over Web-accessible databases", "abstract":
        "A query to a Web search engine usually consists of a list of keywords, to
        which the search engine responds with the best or \"top\" k pages for the
        query. This top-k query model is prevalent over multimedia collections in
        general, but also over plain relational data for certain applications. For
        example, consider a relation with information on available restaurants, including
        their location, price range for one diner, and overall food rating. A user
        who queries such a relation might simply specify the user''s location and
        target price range, and expect in return the best 10 restaurants in terms
        of some combination-of proximity to the user, closeness of match to the target
        price range, and overall food rating. Processing such top-k queries efficiently
        is challenging for a number of reasons. One critical such reason is that,
        in many Web applications, the relation attributes might not be available other
        than through external Web-accessible form interfaces, which we will have to
        query repeatedly for a potentially large set of candidate objects. In this
        paper, we study how to process top-k queries efficiently in this setting,
        where the attributes for which users specify target values might be handled
        by external, autonomous sources with a variety of access interfaces. We present
        several algorithms for processing such queries, and evaluate them thoroughly
        using both synthetic and real Web-accessible data.", "venue": "Proceedings
        / International Conference on Data Engineering", "year": 2002, "referenceCount":
        33, "citationCount": 556, "influentialCitationCount": 26, "isOpenAccess":
        true, "openAccessPdf": {"url": "https://academiccommons.columbia.edu/doi/10.7916/D8ZS37N6/download",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle",
        "Conference"], "publicationDate": "2002-02-26", "journal": {"pages": "369-380",
        "name": "Proceedings 18th International Conference on Data Engineering"},
        "authors": [{"authorId": "2362833", "name": "Nicolas Bruno"}, {"authorId":
        "1684012", "name": "L. Gravano"}, {"authorId": "144173226", "name": "A. Marian"}]},
        {"paperId": "19e71f233fa1f862623d841743f02fd26ad0a07f", "externalIds": {"DBLP":
        "journals/computer/AmbiteAHPGHK01", "MAG": "2037581684", "DOI": "10.1109/2.901167",
        "CorpusId": 13941778}, "corpusId": 13941778, "publicationVenue": {"id": "f6572f66-2623-4a5e-b0d9-4a5028dea98f",
        "name": "Computer", "type": "journal", "alternate_names": ["IEEE Computer",
        "IEEE Comput"], "issn": "0018-9162", "url": "http://www.computer.org/computer",
        "alternate_urls": ["https://ieeexplore.ieee.org/servlet/opac?punumber=2",
        "http://www.computer.org/portal/site/ieeecs/index.jsp", "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=2"]},
        "url": "https://www.semanticscholar.org/paper/19e71f233fa1f862623d841743f02fd26ad0a07f",
        "title": "Simplifying Data Access: The Energy Data Collection Project", "abstract":
        "Using technology developed at the Digital Government Research Center, a team
        of researchers is seeking to make government statistical data more accessible
        through the Internet. In collaboration with government experts, they are conducting
        research into advanced information systems, developing standards, interfaces
        and a shared infrastructure, and building and managing pilot systems.", "venue":
        "Computer", "year": 2001, "referenceCount": 16, "citationCount": 40, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "2001-02-01", "journal":
        {"volume": "34", "pages": "47-54", "name": "Computer"}, "authors": [{"authorId":
        "2887330", "name": "J. Ambite"}, {"authorId": "1717530", "name": "Y. Arens"},
        {"authorId": "144547315", "name": "E. Hovy"}, {"authorId": "2135707", "name":
        "A. Philpot"}, {"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "1799688", "name": "V. Hatzivassiloglou"}, {"authorId": "1761739", "name":
        "Judith L. Klavans"}]}, {"paperId": "1e2355cea9da54478de58efdec1e4f8e995cf231",
        "externalIds": {"DBLP": "conf/sigmod/IpeirotisGS01", "MAG": "2221553715",
        "DOI": "10.1145/375663.375671", "CorpusId": 721970}, "corpusId": 721970, "publicationVenue":
        {"id": "f68b9e7e-ad3d-46cb-857d-23e49384143c", "name": "ACM SIGMOD Conference",
        "type": "conference", "alternate_names": ["SIGMOD", "ACM SIGMOD Conf"], "url":
        "https://sigmod.org/conferences/"}, "url": "https://www.semanticscholar.org/paper/1e2355cea9da54478de58efdec1e4f8e995cf231",
        "title": "Probe, count, and classify: categorizing hidden web databases",
        "abstract": "The contents of many valuable web-accessible databases are only
        accessible through search interfaces and are hence invisible to traditional
        web \u201ccrawlers.\u201d Recent studies have estimated the size of this \u201chidden
        web\u201d to be 500 billion pages, while the size of the \u201ccrawlable\u201d
        web is only an estimated two billion pages. Recently, commercial web sites
        have started to manually organize web-accessible databases into Yahoo!-like
        hierarchical classification schemes. In this paper, we introduce a method
        for automating this classification process by using a small number of query
        probes. To classify a database, our algorithm does not retrieve or inspect
        any documents or pages from the database, but rather just exploits the number
        of matches that each query probe generates at the database in question. We
        have conducted an extensive experimental evaluation of our technique over
        collections of real documents, including over one hundred web-accessible databases.
        Our experiments show that our system has low overhead and achieves high classification
        accuracy across a variety of databases.", "venue": "ACM SIGMOD Conference",
        "year": 2001, "referenceCount": 30, "citationCount": 184, "influentialCitationCount":
        5, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "2001-05-01", "journal":
        {"pages": "67-78"}, "authors": [{"authorId": "2942126", "name": "Panagiotis
        G. Ipeirotis"}, {"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "1764547", "name": "M. Sahami"}]}, {"paperId": "345dfe61c6932e0c0c6040fd8e00b4b55d603de6",
        "externalIds": {"DBLP": "conf/jcdl/IpeirotisGS01", "MAG": "2027492782", "DOI":
        "10.1145/379437.379782", "CorpusId": 977714}, "corpusId": 977714, "publicationVenue":
        {"id": "1da7d7d7-0481-489f-b27d-98cce1ebdf43", "name": "ACM/IEEE Joint Conference
        on Digital Libraries", "type": "conference", "alternate_names": ["ACM/IEEE
        Jt Conf Digit Libr", "JCDL"], "url": "http://www.jcdl.org/"}, "url": "https://www.semanticscholar.org/paper/345dfe61c6932e0c0c6040fd8e00b4b55d603de6",
        "title": "PERSIVAL demo: categorizing hidden-web resources", "abstract": "The
        information available in electronic form continues to grow at an exponential
        rate and this trend is expected to continue. Although traditional search engines
        like AltaVista can address common information needs, they ignore the often
        valuable information that is \u201chidden\u201d behind search interfaces,
        the so-called \u201chidden web.\u201d Automating the classification of \u201chidden
        web\u201d resources is challenging, since the contents of these collections
        are available only by querying, not by traditional crawling. For example,
        consider the PubMed medical database from the National Library of Medicine,
        which stores medical bibliographic information and links to full-text journals
        accessible through the web. This database is accessible through a query interface.
        A query to PubMed with keyword \u201ccancer\u201d returns 1,313,266 matches,
        which are high-quality citations to medical articles, stored locally at the
        PubMed site. The contents of PubMed are not \u201ccrawlable\u201d by traditional
        search engines. Thus, a query on AltaVista for all the pages in the PubMed
        site with keyword \u201ccancer\u201d returns only 16,380 matches. Hence, techniques
        that need to have the documents available for inspection are not applicable
        to analyze and classify the \u201chidden web\u201d resources. The ability
        to access these resources and organize them for subsequent use is a central
        component of the Digital Libraries Initiative \u2013 Phase 2 (DLI2) project
        at Columbia University. The project is named PERSIVAL and its main goal is
        to provide personalized access to a distributed patient care digital library
        with all kinds of collections. The manual inspection and classification of
        these resources is a non-scalable solution, so we developed a novel technique
        to automate this task.", "venue": "ACM/IEEE Joint Conference on Digital Libraries",
        "year": 2001, "referenceCount": 3, "citationCount": 7, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": null, "journal":
        {"pages": "454"}, "authors": [{"authorId": "2942126", "name": "Panagiotis
        G. Ipeirotis"}, {"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "1764547", "name": "M. Sahami"}]}, {"paperId": "46a2ceb19aae1cef1e2bb2432d09cac08aeaf8ce",
        "externalIds": {"DBLP": "conf/jcdl/GreenIG01", "MAG": "2007905870", "DOI":
        "10.1145/379437.379496", "CorpusId": 6619605}, "corpusId": 6619605, "publicationVenue":
        {"id": "1da7d7d7-0481-489f-b27d-98cce1ebdf43", "name": "ACM/IEEE Joint Conference
        on Digital Libraries", "type": "conference", "alternate_names": ["ACM/IEEE
        Jt Conf Digit Libr", "JCDL"], "url": "http://www.jcdl.org/"}, "url": "https://www.semanticscholar.org/paper/46a2ceb19aae1cef1e2bb2432d09cac08aeaf8ce",
        "title": "SDLIP + STARTS = SDARTS a protocol and toolkit for metasearching",
        "abstract": "In this paper we describe how we combined SDLIP and STARTS, two
        comple mentary protocols for searching over distributed document collections.
        The resulting protocol, which we call SDARTS, is simple yet expressible enough
        to enable building sophisticated metasearch engines. SDARTS can be viewed
        as an instantiation of SDLIP with metasearch-specific elements from STARTS.
        We also report on our experience building three SDARTS-compliant wrappers:
        for locally available plain-text document collections, for locally available
        XML document collections, and for external web-accessible collections. These
        wrappers were developed to be easily customizable for new collections. Our
        work was developed as part of Columbia University''s Digital Libraries Initiative--Phase
        2 (DLI2) project, which involves the departments of Computer Science, Medical
        Informatics, and Electrical Engineering, the Columbia University libraries,
        and a large number of industrial partners. The main goal of the project is
        to provide personalized access to a distributed patient-care digital library.",
        "venue": "ACM/IEEE Joint Conference on Digital Libraries", "year": 2001, "referenceCount":
        24, "citationCount": 28, "influentialCitationCount": 0, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": null, "journal": {"pages": "207-214"}, "authors": [{"authorId":
        "2053843048", "name": "Noah Green"}, {"authorId": "2942126", "name": "Panagiotis
        G. Ipeirotis"}, {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId":
        "54cbc1e24f5a480c668ef8b1f55ba50e3f350434", "externalIds": {"DBLP": "conf/www/AgichteinLG01",
        "MAG": "1963832632", "DOI": "10.1145/371920.371976", "CorpusId": 2722419},
        "corpusId": 2722419, "publicationVenue": {"id": "e07422f9-c065-40c3-a37b-75e98dce79fe",
        "name": "The Web Conference", "type": "conference", "alternate_names": ["Web
        Conf", "WWW"], "url": "http://www.iw3c2.org/"}, "url": "https://www.semanticscholar.org/paper/54cbc1e24f5a480c668ef8b1f55ba50e3f350434",
        "title": "Learning search engine specific query transformations for question
        answering", "abstract": "We introduce a method for learning query transformations
        that improves the ability to retrieve answers to questions from an information
        retrieval system. During the training stage the method involves automatically
        learning phrase features for classifying questions into different types, automatically
        generating candidate query transformations from a training set of question/answer
        pairs, and automatically evaluating the candidate transforms on target information
        retrieval systems such as real-world general purpose search engines. At run
        time, questions are transformed into a set of queries, and re-ranking is performed
        on the documents retrieved. We present a prototype search engine, Tritus,
        that applies the method to web search engines. Blind evaluation on a set of
        real queries from a web search engine log shows that the method significantly
        outperforms the underlying web search engines as well as a commercial search
        engine specializing in question answering.", "venue": "The Web Conference",
        "year": 2001, "referenceCount": 57, "citationCount": 138, "influentialCitationCount":
        7, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "2001-05-01", "journal":
        {"pages": "169-178"}, "authors": [{"authorId": "1685296", "name": "Eugene
        Agichtein"}, {"authorId": "145840115", "name": "S. Lawrence"}, {"authorId":
        "1684012", "name": "L. Gravano"}]}, {"paperId": "5737a1f6fd8d928b88726ada916d7874afdfe0d7",
        "externalIds": {"MAG": "1482991935", "DBLP": "conf/vldb/GravanoIJKMS01", "DOI":
        "10.7916/D8M90HHN", "CorpusId": 463335}, "corpusId": 463335, "publicationVenue":
        {"id": "a5c58053-0673-4cdb-b2b8-b6b0ad6911d1", "name": "Very Large Data Bases
        Conference", "type": "conference", "alternate_names": ["Very Large Data Bases",
        "Very Large Data Base", "VLDB", "Very Large Data Base Conf"], "url": "https://www.vldb.org/conference.html"},
        "url": "https://www.semanticscholar.org/paper/5737a1f6fd8d928b88726ada916d7874afdfe0d7",
        "title": "Approximate String Joins in a Database (Almost) for Free", "abstract":
        "String data is ubiquitous, and its management has taken on particular importance
        in the past few years. Approximate queries are very important on string data
        especially for more complex queries involving joins. This is due, for example,
        to the prevalence of typographical errors in data, and multiple conventions
        for recording attributes such as name and address. Commercial databases do
        not support approximate string joins directly, and it is a challenge to implement
        this functionality efficiently with user-defined functions (UDFs). In this
        paper, we develop a technique for building approximate string join capabilities
        on top of commercial databases by exploiting facilities already available
        in them. At the core, our technique relies on matching short substrings of
        length , called -grams, and taking into account both positions of individual
        matches and the total number of such matches. Our approach applies to both
        approximate full string matching and approximate substring matching, with
        a variety of possible edit distance functions. The approximate string match
        predicate, with a suitable edit distance threshold, can be mapped into a vanilla
        relational expression and optimized by conventional relational optimizers.
        We demonstrate experimentally the benefits of our technique over the direct
        use of UDFs, using commercial database systems and real data. To study the
        I/O and CPU behavior of approximate string join algorithms with variations
        in edit distance and -gram length, we also describe detailed experiments based
        on a prototype implementation.", "venue": "Very Large Data Bases Conference",
        "year": 2001, "referenceCount": 18, "citationCount": 638, "influentialCitationCount":
        65, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2001-09-11",
        "journal": {"pages": "491-500"}, "authors": [{"authorId": "1684012", "name":
        "L. Gravano"}, {"authorId": "2942126", "name": "Panagiotis G. Ipeirotis"},
        {"authorId": "145531067", "name": "H. Jagadish"}, {"authorId": "1721062",
        "name": "Nick Koudas"}, {"authorId": "144963537", "name": "S. Muthukrishnan"},
        {"authorId": "145860176", "name": "D. Srivastava"}]}, {"paperId": "5d26d446c7e809bd4e1ee6e696a17764521618c7",
        "externalIds": {"DBLP": "conf/sigmod/AgichteinGV01", "MAG": "2161344493",
        "DOI": "10.1145/375663.375774", "CorpusId": 16581515}, "corpusId": 16581515,
        "publicationVenue": {"id": "f68b9e7e-ad3d-46cb-857d-23e49384143c", "name":
        "ACM SIGMOD Conference", "type": "conference", "alternate_names": ["SIGMOD",
        "ACM SIGMOD Conf"], "url": "https://sigmod.org/conferences/"}, "url": "https://www.semanticscholar.org/paper/5d26d446c7e809bd4e1ee6e696a17764521618c7",
        "title": "Snowball: a prototype system for extracting relations from large
        text collections", "abstract": "Text documents often hide valuable structured
        data. For example, a collection of newspaper articles might contain information
        on the location of the headquarters of a number of organizations. If we need
        to nd the location of the headquarters of, say, Microsoft, we could try and
        use traditional information-retrieval techniques for nding documents that
        contain the answer to our query. Alternatively, we could answer such a query
        more precisely if we somehow had available a table listing all the organization-location
        pairs that are mentioned in our document collection. One could view the extraction
        process as automatically building a materialized view over the unstructured
        text data. In this demo we present an interactive prototype of our Snowball
        system for extracting relations from collections of plain-text documents with
        minimal human participation. Our method builds on the DIPRE idea introduced
        by Brin [3]. Our system and techniques were presented in detail in [2] and
        [1].", "venue": "ACM SIGMOD Conference", "year": 2001, "referenceCount": 3,
        "citationCount": 72, "influentialCitationCount": 6, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "2001-05-01", "journal": {"pages": "612"}, "authors": [{"authorId":
        "1685296", "name": "Eugene Agichtein"}, {"authorId": "1684012", "name": "L.
        Gravano"}, {"authorId": "20772364", "name": "Jeff Pavel"}, {"authorId": "2073824059",
        "name": "Viktoriya Sokolova"}, {"authorId": "2677089", "name": "Aleksandr
        Voskoboynik"}]}, {"paperId": "6ceda089cbc5ad2a31264b75b2c84edbaaa58950", "externalIds":
        {"MAG": "2100647638", "DBLP": "conf/jcdl/McKeownCCFFGHJJKKPT01", "DOI": "10.1145/379437.379722",
        "CorpusId": 6580304}, "corpusId": 6580304, "publicationVenue": {"id": "1da7d7d7-0481-489f-b27d-98cce1ebdf43",
        "name": "ACM/IEEE Joint Conference on Digital Libraries", "type": "conference",
        "alternate_names": ["ACM/IEEE Jt Conf Digit Libr", "JCDL"], "url": "http://www.jcdl.org/"},
        "url": "https://www.semanticscholar.org/paper/6ceda089cbc5ad2a31264b75b2c84edbaaa58950",
        "title": "PERSIVAL, a system for personalized search and summarization over
        multimedia healthcare information", "abstract": "In healthcare settings, patients
        need access to online information tha t can help them understand their medical
        situation. Physicians need information that is clinically relevant to an individual
        patient. In this paper, we present our progress on developing a system, PERSIVAL,
        that is designed to provide personalized access to a distributed patient care
        digital library. Using the secure, online patient records at New York Presbyterian
        Hospital as a user model, PERSIVAL''s components tailor search, presentation
        and summarization of online multimedia information to both patients and healthcare
        providers.", "venue": "ACM/IEEE Joint Conference on Digital Libraries", "year":
        2001, "referenceCount": 31, "citationCount": 75, "influentialCitationCount":
        0, "isOpenAccess": true, "openAccessPdf": {"url": "http://www.cs.columbia.edu/~gravano/Papers/2001/jcdl01c.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Medicine",
        "source": "s2-fos-model"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": null, "journal":
        {"pages": "331-340"}, "authors": [{"authorId": "145590324", "name": "K. McKeown"},
        {"authorId": "9546964", "name": "Shih-Fu Chang"}, {"authorId": "144586369",
        "name": "J. Cimino"}, {"authorId": "1809403", "name": "Steven K. Feiner"},
        {"authorId": "145133587", "name": "C. Friedman"}, {"authorId": "1684012",
        "name": "L. Gravano"}, {"authorId": "1799688", "name": "V. Hatzivassiloglou"},
        {"authorId": "2111937078", "name": "Steven Johnson"}, {"authorId": "2057344438",
        "name": "D. Jordan"}, {"authorId": "1761739", "name": "Judith L. Klavans"},
        {"authorId": "1867747", "name": "A. Kushniruk"}, {"authorId": "1732580", "name":
        "V. Patel"}, {"authorId": "2480901", "name": "Simone Teufel"}]}, {"paperId":
        "6df03d95e357ebbd2dd2b6f2e9da6d477f21ae3a", "externalIds": {"MAG": "1514550118",
        "DOI": "10.7916/D82Z1HQ9", "CorpusId": 5895892}, "corpusId": 5895892, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/6df03d95e357ebbd2dd2b6f2e9da6d477f21ae3a",
        "title": "Summarizing and Searching Hidden-Web Databases Hierarchically Using
        Focused Probes", "abstract": "Many valuable text databases on the web have
        non-crawlable contents that are \u201chidden\u201d behind search interfaces.
        Metasearchers are helpful tools for searching over many such databases at
        once through a unified query interface. A critical task for a metasearcher
        to process a query efficiently and effectively is the selection of the most
        promising databases for the query, a task that typically relies on statistical
        summaries of the database contents. Unfortunately, web-accessible text databases
        do not generally export content summaries. In this paper, we present an algorithm
        to derive content summaries from \u201cuncooperative\u201d databases by using
        \u201cfocused query probes,\u201d which adaptively zoom in on and extract
        documents that are representative of the topic coverage of the databases.
        The content summaries that result from this algorithm are efficient to derive
        and more accurate than those from previously proposed probing techniques for
        content-summary extraction. We also present a novel database selection algorithm
        that exploits both the extracted content summaries and a hierarchical classification
        of the databases, automatically derived during probing, to produce accurate
        results even for imperfect content summaries. Finally, we evaluate our techniques
        thoroughly using a variety of databases, including 50 real web-accessible
        text databases.", "venue": "", "year": 2001, "referenceCount": 44, "citationCount":
        1, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate": null,
        "journal": {"volume": "", "name": ""}, "authors": [{"authorId": "2942126",
        "name": "Panagiotis G. Ipeirotis"}, {"authorId": "1684012", "name": "L. Gravano"}]},
        {"paperId": "72d116438a2e7ab0902e3b5fe9fa4cf37c18f5a5", "externalIds": {"MAG":
        "47292847", "DBLP": "journals/debu/GravanoIJKMPS01", "CorpusId": 59805983},
        "corpusId": 59805983, "publicationVenue": {"id": "7bf8fd30-543b-48f6-bb8a-8c518006bdd2",
        "name": "IEEE Data Engineering Bulletin", "type": "journal", "alternate_names":
        ["IEEE Data Eng Bull"], "url": "https://tc.computer.org/tcde/tcde-bulletin-issues/"},
        "url": "https://www.semanticscholar.org/paper/72d116438a2e7ab0902e3b5fe9fa4cf37c18f5a5",
        "title": "Using q-grams in a DBMS for Approximate String Processing", "abstract":
        "String data is ubiquitous, and its management has taken on particular importance
        in the past few years. Approximate queries are very important on string data.
        This is due, for example, to the prevalence of typographical errors in data,
        and multiple conventions for recording attributes such as name and address.
        Commercial databases do not support approximate string queries directly, and
        it is a challenge to implement this functionality efficiently with user-defined
        functions (UDFs). In this paper, we develop a technique for building approximate
        string processing capabilities on top of commercial databases by exploiting
        facilities already available in them. At the core, our technique relies on
        generating short substrings of length q, called q-grams, and processing them
        using standard methods available in the DBMS. The proposed technique enables
        various approximate string processing methods in a DBMS, for example approximate
        (sub)string selections and joins, and can even be used with a variety of possible
        edit distance functions. The approximate string match predicate, with a suitable
        edit distance threshold, can be mapped into a vanilla relational expression
        and optimized by conventional relational optimizers.", "venue": "IEEE Data
        Engineering Bulletin", "year": 2001, "referenceCount": 6, "citationCount":
        126, "influentialCitationCount": 4, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
        null, "journal": {"volume": "24", "pages": "28-34", "name": "IEEE Data Eng.
        Bull."}, "authors": [{"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "2942126", "name": "Panagiotis G. Ipeirotis"}, {"authorId": "145531067", "name":
        "H. Jagadish"}, {"authorId": "1721062", "name": "Nick Koudas"}, {"authorId":
        "144963537", "name": "S. Muthukrishnan"}, {"authorId": "152320428", "name":
        "Lauri Pietarinen"}, {"authorId": "145860176", "name": "D. Srivastava"}]},
        {"paperId": "77ae43841d7fa86cba93f0d07911d7202acee6be", "externalIds": {"MAG":
        "1667498960", "DOI": "10.7916/D8BG3166", "CorpusId": 1429930}, "corpusId":
        1429930, "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/77ae43841d7fa86cba93f0d07911d7202acee6be",
        "title": "QProber: A System for Automatic Classification of Hidden-Web Resources",
        "abstract": "The contents of many valuable web-accessible databases are only
        available through search interfaces and are hence invisible to traditional
        web \u201ccrawlers.\u201d Recently, commercial web sites have started to manually
        organize web-accessible databases into Yahoo!-like hierarchical classification
        schemes. Here, we introduce QProber, a modular system that automates this
        classification process by using a small number of query probes, generated
        by document classifiers. QProber can use a variety of types of classifiers
        to generate the probes. To classify a database, QProber does not retrieve
        or inspect any documents or pages from the database, but rather just exploits
        the number of matches that each query probe generates at the database in question.
        We have conducted an extensive experimental evaluation of QProber over collections
        of real documents, experimenting with different types of document classifiers
        and retrieval models. We have also tested our system with over one hundred
        web-accessible databases. Our experiments show that our system has low overhead
        and achieves high classification accuracy across a variety of databases.",
        "venue": "", "year": 2001, "referenceCount": 41, "citationCount": 8, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": null, "publicationDate": null, "journal": {"volume": "",
        "name": ""}, "authors": [{"authorId": "2942126", "name": "Panagiotis G. Ipeirotis"},
        {"authorId": "1684012", "name": "L. Gravano"}, {"authorId": "1764547", "name":
        "M. Sahami"}]}, {"paperId": "ed920f7547ce5d0b72ce69393357a323f89c70cf", "externalIds":
        {"DBLP": "conf/sigmod/BrunoCG01", "MAG": "2120108467", "DOI": "10.1145/375663.375686",
        "CorpusId": 7231548}, "corpusId": 7231548, "publicationVenue": {"id": "f68b9e7e-ad3d-46cb-857d-23e49384143c",
        "name": "ACM SIGMOD Conference", "type": "conference", "alternate_names":
        ["SIGMOD", "ACM SIGMOD Conf"], "url": "https://sigmod.org/conferences/"},
        "url": "https://www.semanticscholar.org/paper/ed920f7547ce5d0b72ce69393357a323f89c70cf",
        "title": "STHoles: a multidimensional workload-aware histogram", "abstract":
        "Attributes of a relation are not typically independent. Multidimensional
        histograms can be an effective tool for accurate multiattribute query selectivity
        estimation. In this paper, we introduce STHoles, a \u201cworkload-aware\u201d
        histogram that allows bucket nesting to capture data regions with reasonably
        uniform tuple density. STHoles histograms are built without examining the
        data sets, but rather by just analyzing query results. Buckets are allocated
        where needed the most as indicated by the workload, which leads to accurate
        query selectivity estimations. Our extensive experiments demonstrate that
        STHoles histograms consistently produce good selectivity estimates across
        synthetic and real-world data sets and across query workloads, and, in many
        cases, outperform the best multidimensional histogram techniques that require
        access to and processing of the full data sets during histogram construction.",
        "venue": "ACM SIGMOD Conference", "year": 2001, "referenceCount": 31, "citationCount":
        343, "influentialCitationCount": 34, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
        "2001-05-01", "journal": {"pages": "211-222"}, "authors": [{"authorId": "2362833",
        "name": "Nicolas Bruno"}, {"authorId": "145647476", "name": "S. Chaudhuri"},
        {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "175a7e3e4674b31ca622c49d0307a1e9e3f93ab5",
        "externalIds": {"MAG": "1576295148", "DOI": "10.7916/D8DJ5STF", "CorpusId":
        13970099}, "corpusId": 13970099, "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/175a7e3e4674b31ca622c49d0307a1e9e3f93ab5",
        "title": "Performance of Multiattribute Top-K Queries on Relational Systems",
        "abstract": "In many applications, users specify target values for the attributes
        of a relation, and expect in return the k tuples that best match these values.
        Traditional RDBMSs do not process these \u201ctop-k queries\u201d efficiently.
        In our previous work, we outlined a family of strategies to map a top-k query
        into a traditional selection query that a RDBMS can process efficiently. The
        goal of such mapping strategies is to get all needed tuples (but minimize
        the number of retrieved tuples) and thus avoid \u201crestarts\u201d to get
        additional tuples. Unfortunately, no single mapping strategy performed consistently
        the best under all data distributions. In this paper, we develop a novel mapping
        technique that leverages information about the data distribution and adapts
        itself to the local characteristics of the data and the histograms available
        to do the mapping. We also report the first experimental evaluation of the
        new and old mapping strategies over a real RDBMS, namely over Microsoft\u2019s
        SQL Server 7.0. The experiments show that our new techniques are robust and
        significantly more efficient than previously known strategies requiring at
        least one sequential scan of the data sets.", "venue": "", "year": 2000, "referenceCount":
        25, "citationCount": 6, "influentialCitationCount": 1, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate":
        null, "journal": {"volume": "", "name": ""}, "authors": [{"authorId": "2362833",
        "name": "Nicolas Bruno"}, {"authorId": "145647476", "name": "S. Chaudhuri"},
        {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "283e8528933549dae671db8a74547e5460bfde9e",
        "externalIds": {"CorpusId": 1005817}, "corpusId": 1005817, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/283e8528933549dae671db8a74547e5460bfde9e",
        "title": "Characterizing Web Resources for Improved Search Position Paper",
        "abstract": "As an important initial step to exploit such dimensions for web
        search, we have focused on geographical relevance. Web sites containing information
        on restaurants or apartment rentals, for instance, are relevant primarily
        to web users in geographical proximity to these locations. In contrast, an
        on-line newspaper may be relevant to users across the United States. We have
        studied how to mine the web and automatically estimate the geographical scope
        of web resources by using web hyperlinks and the actual content of web pages.
        For example, we can map every web page to a location based on where its hosting
        site resides. Then, we can consider the location of all the pages that point
        to, say, the Stanford Daily home page. By examining the distribution of these
        pointers, we can conclude that the Stanford Daily is of interest mainly to
        residents of the Stanford area, while The Wall Street Journal is of nation-wide
        interest. Similar conclusions can be drawn for other resources by analyzing
        the geographical locations that are mentioned in their pages.", "venue": "",
        "year": 2000, "referenceCount": 6, "citationCount": 0, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": null, "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
        null, "publicationDate": null, "journal": null, "authors": [{"authorId": "1684012",
        "name": "L. Gravano"}]}, {"paperId": "313e69f0df162ac2f791550a35d43d3e7b5eeae7",
        "externalIds": {"DBLP": "conf/dgo/AmbiteAGHHKPRSSW00", "MAG": "1591809030",
        "CorpusId": 7669126}, "corpusId": 7669126, "publicationVenue": {"id": "ccf4a25a-ab6d-4b32-8a6b-fab8cec15859",
        "name": "Digital Government Research", "type": "conference", "alternate_names":
        ["DG.O", "Digit Gov Res"]}, "url": "https://www.semanticscholar.org/paper/313e69f0df162ac2f791550a35d43d3e7b5eeae7",
        "title": "Simplifying data access: the energy data collection (EDC) project",
        "abstract": "The massive amount of statistical and text data available from
        government agencies has created a set of daunting challenges to both research
        and analysis communities. These problems include heterogeneity, size, distribution,
        and control of terminology. At the Digital Government Research Center we are
        investigating solutions to these key problems. In this paper we focus on (1)
        ontological mappings for terminology standardization, (2) data integration
        across data bases with high speed query processing, and (3) interfaces for
        query input and presentation of results. This collaboration between researchers
        from Columbia University and the Information Sciences Institute of the University
        of Southern California employs technology developed at both locations, in
        particular the SENSUS ontology, the SIMS multi-database access planner, the
        LKB automated dictionary and terminology analysis system, and others. The
        pilot application targets gasoline data from the Bureau of Labor Statistics,
        the Energy Information Administration of the Department of Energy, the Census
        Bureau, and other government agencies.", "venue": "Digital Government Research",
        "year": 2000, "referenceCount": 21, "citationCount": 11, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "2000-05-15", "journal":
        {"volume": "", "pages": "1-11", "name": ""}, "authors": [{"authorId": "2887330",
        "name": "J. Ambite"}, {"authorId": "1717530", "name": "Y. Arens"}, {"authorId":
        "1684012", "name": "L. Gravano"}, {"authorId": "1799688", "name": "V. Hatzivassiloglou"},
        {"authorId": "144547315", "name": "E. Hovy"}, {"authorId": "1761739", "name":
        "Judith L. Klavans"}, {"authorId": "2135707", "name": "A. Philpot"}, {"authorId":
        "3222571", "name": "Usha Ramachandran"}, {"authorId": "2479999", "name": "J.
        Sandhaus"}, {"authorId": "2061103160", "name": "Anurag Singla"}, {"authorId":
        "145822024", "name": "B. Whitman"}]}, {"paperId": "36609db38881b34a896f0cca58f9942f451e4815",
        "externalIds": {"MAG": "2078693345", "DBLP": "conf/sigir/HatzivassiloglouGM00",
        "DOI": "10.1145/345508.345582", "CorpusId": 8056256}, "corpusId": 8056256,
        "publicationVenue": {"id": "8dce23a9-44e0-4381-a39e-2acc1edff700", "name":
        "Annual International ACM SIGIR Conference on Research and Development in
        Information Retrieval", "type": "conference", "alternate_names": ["International
        ACM SIGIR Conference on Research and Development in Information Retrieval",
        "Int ACM SIGIR Conf Res Dev Inf Retr", "SIGIR", "Annu Int ACM SIGIR Conf Res
        Dev Inf Retr"], "url": "http://www.acm.org/sigir/"}, "url": "https://www.semanticscholar.org/paper/36609db38881b34a896f0cca58f9942f451e4815",
        "title": "An investigation of linguistic features and clustering algorithms
        for topical document clustering", "abstract": "We investigate four hierarchical
        clustering methods (single-link, complete-link, groupwise-average, and single-pass)
        and two linguistically motivated text features (noun phrase heads and proper
        names) in the context of document clustering. A statistical model for combining
        similarity information from multiple sources is described and applied to DARPA''s
        Topic Detection and Tracking phase 2 (TDT2) data. This model, based on log-linear
        regression, alleviates the need for extensive search in order to determine
        optimal weights for combining input features. Through an extensive series
        of experiments with more than 40,000 documents from multiple news sources
        and modalities, we establish that both the choice of clustering algorithm
        and the introduction of the additional features have an impact on clustering
        performance. We apply our optimal combination of features to the TDT2 test
        data, obtaining partitions of the documents that compare favorably with the
        results obtained by participants in the official TDT2 competition.", "venue":
        "Annual International ACM SIGIR Conference on Research and Development in
        Information Retrieval", "year": 2000, "referenceCount": 22, "citationCount":
        147, "influentialCitationCount": 2, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
        "2000-07-01", "journal": {"pages": "224-231"}, "authors": [{"authorId": "1799688",
        "name": "V. Hatzivassiloglou"}, {"authorId": "1684012", "name": "L. Gravano"},
        {"authorId": "3252870", "name": "Ankineedu Maganti"}]}, {"paperId": "485107f8f5d2581aa935ef1148a5bbd23f39f9fc",
        "externalIds": {"DBLP": "conf/webdb/IpeirotisGS00", "MAG": "2950754341", "ArXiv":
        "cs/0003043", "DOI": "10.1007/3-540-45271-0_16", "CorpusId": 905199}, "corpusId":
        905199, "publicationVenue": {"id": "008c1686-e07c-419a-a0e6-f2c5cbde842e",
        "name": "International Workshop on the Web and Databases", "type": "conference",
        "alternate_names": ["Int Workshop Web Database", "WebDB"], "url": "http://www.wikicfp.com/cfp/program?id=3033"},
        "url": "https://www.semanticscholar.org/paper/485107f8f5d2581aa935ef1148a5bbd23f39f9fc",
        "title": "Automatic Classification of Text Databases Through Query Probing",
        "abstract": null, "venue": "International Workshop on the Web and Databases",
        "year": 2000, "referenceCount": 19, "citationCount": 23, "influentialCitationCount":
        1, "isOpenAccess": true, "openAccessPdf": {"url": "https://academiccommons.columbia.edu/doi/10.7916/D8PC3DKR/download",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle",
        "Conference"], "publicationDate": "2000-03-08", "journal": {"volume": "cs.DB/0003043",
        "name": "ArXiv"}, "authors": [{"authorId": "2942126", "name": "Panagiotis
        G. Ipeirotis"}, {"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "1764547", "name": "M. Sahami"}]}, {"paperId": "4abe2165b0f43588134dc06ea4b4e917ba74924e",
        "externalIds": {"MAG": "1521219253", "DBLP": "conf/vldb/DingGS00", "DOI":
        "10.7916/D8PV6XJG", "CorpusId": 2036907}, "corpusId": 2036907, "publicationVenue":
        {"id": "a5c58053-0673-4cdb-b2b8-b6b0ad6911d1", "name": "Very Large Data Bases
        Conference", "type": "conference", "alternate_names": ["Very Large Data Bases",
        "Very Large Data Base", "VLDB", "Very Large Data Base Conf"], "url": "https://www.vldb.org/conference.html"},
        "url": "https://www.semanticscholar.org/paper/4abe2165b0f43588134dc06ea4b4e917ba74924e",
        "title": "Computing Geographical Scopes of Web Resources", "abstract": "Many
        information resources on the web are relevant primarily to limited geographical
        communities. For instance, web sites containing information on restaurants,
        theaters, and apartment rentals are relevant primarily to web users in geographical
        proximity to these locations. In contrast, other information resources are
        relevant to a broader geographical community. For instance, an on-line newspaper
        may be relevant to users across the United States. Unfortunately, current
        web search engines largely ignore the geographical scope of web resources.
        In this paper, we introduce techniques for automatically computing the geographical
        scope of web resources, based on the textual content of the resources, as
        well as on the geographical distribution of hyperlinks to them. We report
        an extensive experimental evaluation of our strategies using real web data.
        Finally, we describe a geographicallyaware search engine that we have built
        to showcase our techniques.", "venue": "Very Large Data Bases Conference",
        "year": 2000, "referenceCount": 19, "citationCount": 263, "influentialCitationCount":
        17, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2000-09-10",
        "journal": {"pages": "545-556"}, "authors": [{"authorId": "2110857408", "name":
        "Junyan Ding"}, {"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "1712337", "name": "N. Shivakumar"}]}, {"paperId": "7a6e96acb393774175ccc1c49c26a73372e646dc",
        "externalIds": {"MAG": "1541251836", "DBLP": "journals/debu/Gravano01", "CorpusId":
        60804173}, "corpusId": 60804173, "publicationVenue": {"id": "7bf8fd30-543b-48f6-bb8a-8c518006bdd2",
        "name": "IEEE Data Engineering Bulletin", "type": "journal", "alternate_names":
        ["IEEE Data Eng Bull"], "url": "https://tc.computer.org/tcde/tcde-bulletin-issues/"},
        "url": "https://www.semanticscholar.org/paper/7a6e96acb393774175ccc1c49c26a73372e646dc",
        "title": "Letter from the Special Issue Editor", "abstract": null, "venue":
        "IEEE Data Engineering Bulletin", "year": 2000, "referenceCount": 0, "citationCount":
        2, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Education", "source":
        "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
        null, "journal": {"volume": "24", "pages": "2", "name": "IEEE Data Eng. Bull."},
        "authors": [{"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "98a39e8a2d31d0a6adeccb86effb990067d6ab85",
        "externalIds": {"MAG": "2140014286", "DBLP": "conf/dmkd/AgichteinEG00", "DOI":
        "10.7916/D8ST821R", "CorpusId": 10810844}, "corpusId": 10810844, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/98a39e8a2d31d0a6adeccb86effb990067d6ab85",
        "title": "Combining Strategies for Extracting Relations from Text Collections",
        "abstract": "Text documents often contain valuable structured data that is
        hidden in regular English sentences. This data is best exploited if available
        as a relational table that we could use for answering precise queries or for
        running data mining tasks. Our Snowball system extracts these relations from
        document collections starting with only a handful of user-provided example
        tuples. Based on these tuples, Snowball generates patterns that are used,
        in turn, to find more tuples. In this paper we introduce a new pattern and
        tuple generation scheme for Snowball, with different strengths and weaknesses
        than those of our original system. We also show preliminary results on how
        we can combine the two versions of Snowball to extract tuples more accurately.",
        "venue": "ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge
        Discovery", "year": 2000, "referenceCount": 23, "citationCount": 19, "influentialCitationCount":
        2, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": null, "journal":
        {"pages": "86-95"}, "authors": [{"authorId": "1685296", "name": "Eugene Agichtein"},
        {"authorId": "1709847", "name": "E. Eskin"}, {"authorId": "1684012", "name":
        "L. Gravano"}]}, {"paperId": "c0596a0978e91fffbb046669e99a1ea33e42fa88", "externalIds":
        {"MAG": "2168728905", "CorpusId": 61857994}, "corpusId": 61857994, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/c0596a0978e91fffbb046669e99a1ea33e42fa88",
        "title": "Energy Data Collection Project Year 1", "abstract": "The massive
        amount of statistical and text data available from Federal Agencies has created
        a set of daunting challenges to both research and analysis communities. These
        problems include heterogeneity, size, distribution, and control of terminology.
        At the Digital Government Research Center we are investigating solutions to
        three key problems, namely, (1) ontological mappings for terminology standardization;
        (2) data integration across data bases with high speed query processing; and
        (3) interfaces for query input and presentation of results. This collaboration
        between researchers from Columbia University and the Information Sciences
        Institute of the University of Southern California employs technology developed
        at both locations, in particular the SENSUS ontology, the SIMS multi-database
        access planner, the LKB automated dictionary and terminology analysis system,
        and others. The pilot application targets gasoline data from BLS, EIA, Census,
        and other agencies.", "venue": "", "year": 2000, "referenceCount": 13, "citationCount":
        0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate": null,
        "journal": {"volume": "", "name": ""}, "authors": [{"authorId": "2887330",
        "name": "J. Ambite"}, {"authorId": "1717530", "name": "Y. Arens"}, {"authorId":
        "1684012", "name": "L. Gravano"}, {"authorId": "70336901", "name": "Vasilis
        Hatzivassiloglou"}, {"authorId": "1409203239", "name": "Hovy Eduard"}, {"authorId":
        "1761739", "name": "Judith L. Klavans"}, {"authorId": "2135707", "name": "A.
        Philpot"}, {"authorId": "3222571", "name": "Usha Ramachandran"}, {"authorId":
        "2479999", "name": "J. Sandhaus"}, {"authorId": "51005334", "name": "A. Singla"},
        {"authorId": "145822024", "name": "B. Whitman"}, {"authorId": "144547315",
        "name": "E. Hovy"}]}, {"paperId": "cee045e890270abae65455667b292db355d53728",
        "externalIds": {"MAG": "2103931177", "DBLP": "conf/dl/AgichteinG00", "DOI":
        "10.1145/336597.336644", "CorpusId": 7579604}, "corpusId": 7579604, "publicationVenue":
        {"id": "8a6203f8-814f-4359-8d48-cc365928bed5", "name": "Digital library",
        "type": "conference", "alternate_names": ["DL", "Digit Libr", "ACM int conf
        Digit libr", "Digital Libraries", "Digit libr", "ACM international conference
        on Digital libraries"], "issn": "2261-9992", "url": "https://digitallibrary.hypotheses.org/",
        "alternate_urls": ["http://www.acm.org/pubs/contents/proceedings/dl/"]}, "url":
        "https://www.semanticscholar.org/paper/cee045e890270abae65455667b292db355d53728",
        "title": "Snowball: extracting relations from large plain-text collections",
        "abstract": "Text documents often contain valuable structured data that is
        hidden Yin regular English sentences. This data is best exploited infavailable
        as arelational table that we could use for answering precise queries or running
        data mining tasks.We explore a technique for extracting such tables from document
        collections that requires only a handful of training examples from users.
        These examples are used to generate extraction patterns, that in turn result
        in new tuples being extracted from the document collection.We build on this
        idea and present our Snowball system. Snowball introduces novel strategies
        for generating patterns and extracting tuples from plain-text documents.At
        each iteration of the extraction process, Snowball evaluates the quality of
        these patterns and tuples without human intervention,and keeps only the most
        reliable ones for the next iteration. In this paper we also develop a scalable
        evaluation methodology and metrics for our task, and present a thorough experimental
        evaluation of Snowball and comparable techniques over a collection of more
        than 300,000 newspaper documents.", "venue": "Digital library", "year": 2000,
        "referenceCount": 20, "citationCount": 1431, "influentialCitationCount": 112,
        "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "2000-06-01", "journal":
        {"pages": "85-94"}, "authors": [{"authorId": "1685296", "name": "Eugene Agichtein"},
        {"authorId": "1684012", "name": "L. Gravano"}]}, {"paperId": "db8e062f6cba4e914460018de2291d03f1231839",
        "externalIds": {"DBLP": "conf/delos/Gravano00", "MAG": "1568681181", "CorpusId":
        6728352}, "corpusId": 6728352, "publicationVenue": {"id": "4b012609-3a75-477f-a91a-ae8981ee2531",
        "name": "DELOS Workshops / Conferences", "type": "conference", "alternate_names":
        ["DELOS", "Delos", "DELOS Work  Conf"], "issn": "0011-7951", "url": "http://www-dbs.inf.ethz.ch/delos/",
        "alternate_urls": ["http://ufdc.ufl.edu/AA00039101", "http://journals.fcla.edu/delos/index",
        "http://journals.fcla.edu/delos"]}, "url": "https://www.semanticscholar.org/paper/db8e062f6cba4e914460018de2291d03f1231839",
        "title": "Characterizing Web Resources for Improved Search", "abstract": "As
        an important initial step to exploit such dimensions for web search, we have
        focused on geographical relevance. Web sites containing information on restaurants
        or apartment rentals, for instance, are relevant primarily to web users in
        geographical proximity to these locations. In contrast, an on-line newspaper
        may be relevant to users across the United States. We have studied how to
        mine the web and automatically estimate the geographical scope of web resources
        by using web hyperlinks and the actual content of web pages. For example,
        we can map every web page to a location based on where its hosting site resides.
        Then, we can consider the location of all the pages that point to, say, the
        Stanford Daily home page. By examining the distribution of these pointers,
        we can conclude that the Stanford Daily is of interest mainly to residents
        of the Stanford area, while The Wall Street Journal is of nation-wide interest.
        Similar conclusions can be drawn for other resources by analyzing the geographical
        locations that are mentioned in their pages.", "venue": "DELOS Workshops /
        Conferences", "year": 2000, "referenceCount": 6, "citationCount": 5, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": null, "journal":
        {"volume": "", "name": ""}, "authors": [{"authorId": "1684012", "name": "L.
        Gravano"}]}, {"paperId": "8cd0e93f0c4a79a6a4cd6af1e89d3ffa6123d30c", "externalIds":
        {"DBLP": "journals/tods/GravanoGT99", "MAG": "2016892599", "DOI": "10.1145/320248.320252",
        "CorpusId": 8834927}, "corpusId": 8834927, "publicationVenue": null, "url":
        "https://www.semanticscholar.org/paper/8cd0e93f0c4a79a6a4cd6af1e89d3ffa6123d30c",
        "title": "GlOSS: text-source discovery over the Internet", "abstract": "The
        dramatic growth of the Internet has created a new problem for users: location
        of the relevant sources of documents. This article presents a framework for
        (and experimentally analyzes a solution to) this problem, which we call the
        text-source discovery problem. Our approach consists of two phases. First,
        each text source exports its contents to a centralized service. Second, users
        present queries to the service, which returns an ordered list of promising
        text sources. This article describes GlOSS, Glossary of Servers Server, with
        two versions: bGlOSS, which provides a Boolean query retrieval model, and
        vGlOSS, which provides a vector-space retrieval model. We also present hGlOSS,
        which provides a decentralized version of the system. We extensively describe
        the methodology for measuring the retrieval effectiveness of these systems
        and provide experimental evidence, based on actual data, that all three systems
        are highly effective in determining promising text sources for a given query.",
        "venue": "TODS", "year": 1999, "referenceCount": 41, "citationCount": 378,
        "influentialCitationCount": 26, "isOpenAccess": true, "openAccessPdf": {"url":
        "http://www1.cs.columbia.edu/~gravano/Papers/1998/TODS/tods.pdf", "status":
        null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
        "1999-06-01", "journal": {"volume": "24", "pages": "229-264", "name": "ACM
        Trans. Database Syst."}, "authors": [{"authorId": "1684012", "name": "L. Gravano"},
        {"authorId": "1398574232", "name": "H. Garcia-Molina"}, {"authorId": "1693125",
        "name": "A. Tomasic"}]}, {"paperId": "d28cfa4c4d7bf6a86eb754ba6f9f4472cc209418",
        "externalIds": {"MAG": "1488719427", "DBLP": "conf/vldb/ChaudhuriG99", "CorpusId":
        9352566}, "corpusId": 9352566, "publicationVenue": {"id": "a5c58053-0673-4cdb-b2b8-b6b0ad6911d1",
        "name": "Very Large Data Bases Conference", "type": "conference", "alternate_names":
        ["Very Large Data Bases", "Very Large Data Base", "VLDB", "Very Large Data
        Base Conf"], "url": "https://www.vldb.org/conference.html"}, "url": "https://www.semanticscholar.org/paper/d28cfa4c4d7bf6a86eb754ba6f9f4472cc209418",
        "title": "Evaluating Top-k Selection Queries", "abstract": "In many applications,
        users specify target values for certain attributes, without requiring exact
        matches to these values in return. Instead, the result to such queries is
        typically a rank of the \\top k\" tuples that best match the given attribute
        values. In this paper, we study the advantages and limitations of processing
        a top-k query by translating it into a single range query that traditional
        relational DBMSs can process eciently. In particular, we study how to determine
        a range query to evaluate a top-k query by exploiting the statistics available
        to a relational DBMS, and the impact of the quality of these statistics on
        the retrieval eciency of the resulting scheme.", "venue": "Very Large Data
        Bases Conference", "year": 1999, "referenceCount": 19, "citationCount": 334,
        "influentialCitationCount": 21, "isOpenAccess": false, "openAccessPdf": null,
        "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
        Science", "source": "external"}, {"category": "Computer Science", "source":
        "s2-fos-model"}], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate":
        "1999-09-07", "journal": {"pages": "397-410"}, "authors": [{"authorId": "145647476",
        "name": "S. Chaudhuri"}, {"authorId": "1684012", "name": "L. Gravano"}]},
        {"paperId": "fa27189fb9955538b0590d16b525af1dc3ad5a8b", "externalIds": {"DBLP":
        "conf/webdb/BuyukkoktenCGGS99", "MAG": "1496059925", "CorpusId": 1739520},
        "corpusId": 1739520, "publicationVenue": {"id": "008c1686-e07c-419a-a0e6-f2c5cbde842e",
        "name": "International Workshop on the Web and Databases", "type": "conference",
        "alternate_names": ["Int Workshop Web Database", "WebDB"], "url": "http://www.wikicfp.com/cfp/program?id=3033"},
        "url": "https://www.semanticscholar.org/paper/fa27189fb9955538b0590d16b525af1dc3ad5a8b",
        "title": "Exploiting Geographical Location Information of Web Pages", "abstract":
        "Many information resources on the web are relevant primarily to limited geographical
        communities. For instance, web sites containing information on restaurants,
        theaters, and apartment rentals are relevant primarily to web users in geographical
        proximity to these locations. In contrast, other information resources are
        relevant to a broader geographical community. For instance, an on-line newspaper
        may be relevant to users across the United States. Unfortunately, the geographical
        scope of web resources is largely ignored by web search engines. We make the
        case for identifying and exploiting the geographical location information
        of web sites so that web search engines can rank resources in a geographically
        sensitive fashion, in addition to using more traditional information-retrieval
        strategies. In this paper, we first consider how to compute the geographical
        location of web pages. Subsequently, we consider how to exploit such information
        in one specific \"proof-of-concept\" application we implemented in JAVA, and
        discuss other examples as well.", "venue": "International Workshop on the
        Web and Databases", "year": 1999, "referenceCount": 8, "citationCount": 189,
        "influentialCitationCount": 9, "isOpenAccess": false, "openAccessPdf": null,
        "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
        Science", "source": "external"}, {"category": "Computer Science", "source":
        "s2-fos-model"}], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate":
        "1999-06-03", "journal": {"pages": "91-96"}, "authors": [{"authorId": "2356107",
        "name": "Orkut Buyukkokten"}, {"authorId": "4658767", "name": "Junghoo Cho"},
        {"authorId": "1398574232", "name": "H. Garcia-Molina"}, {"authorId": "1684012",
        "name": "L. Gravano"}, {"authorId": "1712337", "name": "N. Shivakumar"}]},
        {"paperId": "0d862a75271c152537ec41e24cbf5b0cd645a41e", "externalIds": {"MAG":
        "2076299018", "DBLP": "journals/sigmod/ChangGKRS98", "DOI": "10.1145/290593.290607",
        "CorpusId": 2564021}, "corpusId": 2564021, "publicationVenue": null, "url":
        "https://www.semanticscholar.org/paper/0d862a75271c152537ec41e24cbf5b0cd645a41e",
        "title": "Database research at Columbia University", "abstract": "Columbia
        University has a number of projects that touch on database systems issues.
        In this report, we describe the Columbia Fast Query Project (Section 2), the
        JAM project (Section 3), the CARDGIS project (Section 4), the Columbia Internet
        Information Searching Project (Section 5), the Columbia Content-Based Visual
        Query project (Section 6), and projects associated with Columbia''s Programming
        Systems Laboratory (Section 7).", "venue": "SGMD", "year": 1998, "referenceCount":
        36, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": true,
        "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/290593.290607",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Engineering",
        "source": "s2-fos-model"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "1998-09-01", "journal":
        {"volume": "27", "pages": "75-80", "name": "SIGMOD Rec."}, "authors": [{"authorId":
        "9546964", "name": "Shih-Fu Chang"}, {"authorId": "1684012", "name": "L. Gravano"},
        {"authorId": "1694056", "name": "G. Kaiser"}, {"authorId": "144812095", "name":
        "K. A. Ross"}, {"authorId": "1807433", "name": "S. Stolfo"}]}, {"paperId":
        "4e54e204e30f8143b48e62a3822607df87ca53e9", "externalIds": {"DBLP": "conf/medoc/MoscheisenBCGKP98",
        "MAG": "2167735688", "DOI": "10.1007/BFb0052526", "CorpusId": 7396113}, "corpusId":
        7396113, "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/4e54e204e30f8143b48e62a3822607df87ca53e9",
        "title": "The Stanford InfoBus and Its Service Layers: Augmenting the Internet
        with High-Level Information Management Protocols", "abstract": null, "venue":
        "The MeDoc Approach", "year": 1998, "referenceCount": 31, "citationCount":
        45, "influentialCitationCount": 1, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle", "Review"],
        "publicationDate": null, "journal": {"pages": "213-230"}, "authors": [{"authorId":
        "2573037", "name": "Martin R\u00f6scheisen"}, {"authorId": "1868844", "name":
        "M. Baldonado"}, {"authorId": "143922493", "name": "K. Chang"}, {"authorId":
        "1684012", "name": "L. Gravano"}, {"authorId": "2285915", "name": "Steven
        P. Ketchpel"}, {"authorId": "1750481", "name": "A. Paepcke"}]}, {"paperId":
        "53bcd6e9ae8e9143ddb61178a02a6aef3d8995f2", "externalIds": {"MAG": "1584939207",
        "DBLP": "phd/us/Gravano97", "CorpusId": 321158}, "corpusId": 321158, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/53bcd6e9ae8e9143ddb61178a02a6aef3d8995f2",
        "title": "Querying multiple document collections across the internet", "abstract":
        "Information sources are available everywhere, both within the internal networks
        of organizations and on the Internet. The source contents are often hidden
        behind search interfaces and models that vary from source to source. Furthermore,
        these sources are usually numerous, and users cannot evaluate their queries
        over all of them. Consequently, it is crucial for users to have metasearchers,
        which are services that provide unified query interfaces to multiple information
        sources. Given a user query, the metasearcher first chooses the best sources
        to evaluate the query. Second, the metasearcher submits the query to these
        sources. Finally, the metasearcher merges the query results from the sources.
        To address the first task, we designed GlOSS, a scalable system that chooses
        the best document sources for a query. The GlOSS information about each source
        is orders of magnitude smaller than the source contents. To address the other
        two tasks above and to facilitate the extraction of the GlOSS information
        from the sources, we coordinated the design of STARTS, an emerging protocol
        for Internet retrieval and search involving around 11 companies and organizations.
        Unfortunately, extracting the best objects for a query according to the metasearcher
        might be an expensive operation, since the sources'' ranking algorithms might
        differ radically from that of the metasearcher''s. We studied a result merging
        condition that characterizes what sources are \"good\" with respect to result
        merging. Finally, we also studied the metasearching problem for a novel application:
        the detection of illegal dissemination of copyrighted material. To address
        this problem we developed dSCAM an \"illegal copy\" metasearcher that finds
        potential copies of a document over distributed text sources.", "venue": "",
        "year": 1998, "referenceCount": 81, "citationCount": 10, "influentialCitationCount":
        1, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": null, "publicationDate": "1998-03-17", "journal": {"volume":
        "", "name": ""}, "authors": [{"authorId": "1684012", "name": "L. Gravano"}]},
        {"paperId": "7e8359716df50fe4973cc87b48dc19d23af0495f", "externalIds": {"CorpusId":
        17273629}, "corpusId": 17273629, "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/7e8359716df50fe4973cc87b48dc19d23af0495f",
        "title": "International Journal of Digital Libraries Manuscript Nr. the Stanford
        Digital Library Metadata Architecture ? 2 Our Metadata Requirements", "abstract":
        "The overall goal of the Stanford Digital Library project is to provide an
        infrastructure that a ords interoperability among heterogeneous, autonomous
        digital library services. These services include both search services and
        remotely usable information processing facilities. In this paper, we survey
        and categorize the metadata required for a diverse set of Stanford Digital
        Library services that we have built. We then propose an extensible metadata
        architecture that meets these requirements. Our metadata architecture ts into
        our established infrastructure and promotes interoperability among existing
        and de-facto metadata standards. Several pieces of this architecture are implemented;
        others are under construction. The architecture includes attribute model proxies,
        attribute model translation services, metadata information facilities for
        search services, and local metadata repositories. In presenting and discussing
        the pieces of the architecture, we show how they address our motivating requirements.
        Together, these components provide, exchange, and describe metadata for information
        objects and metadata for information services. We also consider how our architecture
        relates to prior, relevant work on these two types of metadata.", "venue":
        "", "year": 1998, "referenceCount": 34, "citationCount": 0, "influentialCitationCount":
        0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": null, "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
        ["Review"], "publicationDate": null, "journal": null, "authors": [{"authorId":
        "72660638", "name": "Chen-Chuan K. Chang"}, {"authorId": "1684012", "name":
        "L. Gravano"}, {"authorId": "1750481", "name": "A. Paepcke"}]}, {"paperId":
        "89e4353bf86caa32b2a7deb1b2b3d75fc3d34ab9", "externalIds": {"MAG": "2428298",
        "DBLP": "journals/debu/GravanoP98", "CorpusId": 5974131}, "corpusId": 5974131,
        "publicationVenue": {"id": "7bf8fd30-543b-48f6-bb8a-8c518006bdd2", "name":
        "IEEE Data Engineering Bulletin", "type": "journal", "alternate_names": ["IEEE
        Data Eng Bull"], "url": "https://tc.computer.org/tcde/tcde-bulletin-issues/"},
        "url": "https://www.semanticscholar.org/paper/89e4353bf86caa32b2a7deb1b2b3d75fc3d34ab9",
        "title": "Mediating and Metasearching on the Internet", "abstract": "The Internet
        emerges as the largest database. Increasingly, users want to issue complex
        queries across Internet sources to obtain the data they require. However,
        finding relevant information sources and querying them manually is problematic:
        there are numerous sources, and they vary in the type of information objects
        they contain and in the interface they present to their users. Some sources
        contain text documents and support simple query models where a query is just
        a list of keywords. Other sources contain more structured data and provide
        query interfaces in the style of relational query languages. Furthermore,
        users have to manually fuse the query results by merging information, removing
        redundancies, ranking the answer objects in the appropriate order, and so
        on. Since it is tedious to contact several heterogeneous sources, users can
        benefit from metasearchers and mediators, which are services that provide
        users with a virtual integrated view of the heterogeneous sources. Users access
        the view using a unified query interface that offers location, model, and
        interface transparency, i.e., users have the illusion of a single database
        and do not have to be aware of the location and interface of the sources.
        Although users and applications might access data directly through wrappers,
        mediators and metasearchers offer an integrated view of the world, where information
        related to the same entity has been fused together, redundancies have been
        eliminated, and inconsistencies have been removed. The architecture of metasearchers
        and mediators are virtually identical (Figure 1). Wrappers export a common
        data model view of each source\u2019s data. Wrappers also provide a common
        query interface. After receiving a query, a wrapper translates it into a source-specific
        query or command, hence giving interface transparency to the user. Then, the
        wrapper translates the query results from the underlying source into the common
        data model or format. To evaluate a user query over multiple heterogeneous
        databases, both metasearchers and mediators will typically perform three main
        tasks:", "venue": "IEEE Data Engineering Bulletin", "year": 1998, "referenceCount":
        33, "citationCount": 39, "influentialCitationCount": 0, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": null, "journal": {"volume": "21", "pages": "28-36", "name":
        "IEEE Data Eng. Bull."}, "authors": [{"authorId": "1684012", "name": "L. Gravano"},
        {"authorId": "1786049", "name": "Y. Papakonstantinou"}]}, {"paperId": "15c5cd0f4bc3fa966924a8a76118f6011dffba41",
        "externalIds": {"MAG": "1495898622", "DBLP": "conf/vldb/GravanoG97", "CorpusId":
        752007}, "corpusId": 752007, "publicationVenue": {"id": "a5c58053-0673-4cdb-b2b8-b6b0ad6911d1",
        "name": "Very Large Data Bases Conference", "type": "conference", "alternate_names":
        ["Very Large Data Bases", "Very Large Data Base", "VLDB", "Very Large Data
        Base Conf"], "url": "https://www.vldb.org/conference.html"}, "url": "https://www.semanticscholar.org/paper/15c5cd0f4bc3fa966924a8a76118f6011dffba41",
        "title": "Merging Ranks from Heterogeneous Internet Sources", "abstract":
        "Many sources on the Internet and elsewhere rank the objects in query results
        according to how well these objects match the original query. For example,
        a real-estate agent might rank the available houses according to how well
        they match the user''s preferred location and price. In this environment,
        ``meta-brokers'''' usually query multiple autonomous, heterogeneous sources
        that might use varying result-ranking strategies. A crucial problem that a
        meta-broker then faces is extracting from the underlying sources the top objects
        for a user query according to the meta-broker''s ranking function. This problem
        is challenging because these top objects might not be ranked high by the sources
        where they appear. In this paper we discuss strategies for solving this ``meta-ranking''''
        problem. In particular, we present a condition that a source must satisfy
        so that a meta-broker can extract the top objects for a query from the source
        without examining its entire contents. Not only is this condition necessary
        but it is also sufficient, and we show an efficient algorithm to extract the
        top objects from sources that satisfy the given condition.", "venue": "Very
        Large Data Bases Conference", "year": 1997, "referenceCount": 12, "citationCount":
        71, "influentialCitationCount": 2, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle", "Conference"],
        "publicationDate": "1997-08-25", "journal": {"pages": "196-205"}, "authors":
        [{"authorId": "1684012", "name": "L. Gravano"}, {"authorId": "1398574232",
        "name": "H. Garcia-Molina"}]}, {"paperId": "182357ed2ad1bfe8806ccc0a63c366e55819a70d",
        "externalIds": {"DBLP": "journals/jodl/BaldonadoCGP97", "MAG": "2997955816",
        "DOI": "10.1007/s007990050008", "CorpusId": 8312842}, "corpusId": 8312842,
        "publicationVenue": {"id": "c79aa48a-5be0-4cc6-851b-549f1cf3df25", "name":
        "International Journal on Digital Libraries", "type": "journal", "alternate_names":
        ["Int J Digit Libr"], "issn": "1432-1300", "url": "https://link.springer.com/journal/799"},
        "url": "https://www.semanticscholar.org/paper/182357ed2ad1bfe8806ccc0a63c366e55819a70d",
        "title": "The Stanford Digital Library metadata architecture", "abstract":
        null, "venue": "International Journal on Digital Libraries", "year": 1997,
        "referenceCount": 24, "citationCount": 300, "influentialCitationCount": 11,
        "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "1997-04-15",
        "journal": {"volume": "1", "pages": "108-121", "name": "International Journal
        on Digital Libraries"}, "authors": [{"authorId": "1868844", "name": "M. Baldonado"},
        {"authorId": "143922493", "name": "K. Chang"}, {"authorId": "1684012", "name":
        "L. Gravano"}, {"authorId": "1750481", "name": "A. Paepcke"}]}, {"paperId":
        "273f7bc28571360deb92854c5f55f0ac8d577f34", "externalIds": {"DBLP": "conf/dl/BaldonadoCGP97",
        "MAG": "2045986300", "DOI": "10.1145/263690.263791", "CorpusId": 5658776},
        "corpusId": 5658776, "publicationVenue": {"id": "8a6203f8-814f-4359-8d48-cc365928bed5",
        "name": "Digital library", "type": "conference", "alternate_names": ["DL",
        "Digit Libr", "ACM int conf Digit libr", "Digital Libraries", "Digit libr",
        "ACM international conference on Digital libraries"], "issn": "2261-9992",
        "url": "https://digitallibrary.hypotheses.org/", "alternate_urls": ["http://www.acm.org/pubs/contents/proceedings/dl/"]},
        "url": "https://www.semanticscholar.org/paper/273f7bc28571360deb92854c5f55f0ac8d577f34",
        "title": "Metadata for digital libraries: architecture and design rationale",
        "abstract": "In a distributed, heterogeneous, proxy-based digital library,
        autonomous services and collections are accessed indirectly via proxies. To
        facilitate metadata compatibility and interoperability in such a digital library,
        we have designed a metadata architecture that includes four basic component
        classes: attribute model proxies, attribute model translators, metadata facilities
        for search proxies, and metadata repositories. Attribute model proxies elevate
        both attribute sets and the attributes they define to first-class objects.
        They also allow relationships among attributes to be captured. Attribute model
        translators map attributes and attribute values from one attribute model to
        another (where posMetadata facilities for search proxies provide structured
        descriptions both of the collections to which the search proxies provide access
        and of the search capabilities of the proxies. Finally, metadata repositories
        accumulate selected metadata from local instances of the other three component
        classes in order to facilitate global metadata queries and local metadata
        caching. In this paper, we outline further the roles of these component classes,
        discuss our design rationale, and analyze related work. Keywords: Metadata
        architecture, interoperability, attribute model, attribute model translation,
        metadata repository, InfoBus, proxy architecture, heterogeneity, digital libraries,
        CORBA.", "venue": "Digital library", "year": 1997, "referenceCount": 24, "citationCount":
        65, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
        "1997-07-01", "journal": {"pages": "47-56"}, "authors": [{"authorId": "1868844",
        "name": "M. Baldonado"}, {"authorId": "2246841828", "name": "Kevin Chen-Chuan
        Chang"}, {"authorId": "1684012", "name": "L. Gravano"}, {"authorId": "1750481",
        "name": "A. Paepcke"}]}, {"paperId": "2b5d18de54908db492dbc9315c9eea1ed86ac521",
        "externalIds": {"DBLP": "journals/tois/TomasicGLSH97", "MAG": "2037607644",
        "DOI": "10.1145/256163.256165", "CorpusId": 6732323}, "corpusId": 6732323,
        "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/2b5d18de54908db492dbc9315c9eea1ed86ac521",
        "title": "Data structures for efficient broker implementation", "abstract":
        "With the profusion of text databases on the Internet, it is becoming increasingly
        hard to find the most useful databases for a given query. To attack this problem,
        several existing and proposed systems employ brokers to direct user queries,
        using a local database of summary information about the available databases.
        This summary information must effectively distinguish relevant databases and
        must be compact while allowing efficient access. We offer evidence that one
        broker, GlOSS, can be effective at locating databases of interest even in
        a system of hundreds of databased and can examine the performance of accessing
        theGlOSS summeries for two promising storage methods: the grid file and partitioned
        hashing. We show that both methods can be tuned to provide good performance
        for a particular workload (within a broad range of workloads), and we discuss
        the tradeoffs between the two data structures. As a side effect of our work,
        we show that grid files are more broadly applicable than previously thought;
        inparticular, we show that by varying the policies used to construct the grid
        file we can provide good performance for a wide range of workloads even when
        storing highly skewed data.", "venue": "TOIS", "year": 1997, "referenceCount":
        55, "citationCount": 30, "influentialCitationCount": 0, "isOpenAccess": true,
        "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/256163.256165",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "1997-07-01", "journal": {"volume": "15", "pages": "223-253",
        "name": "ACM Trans. Inf. Syst."}, "authors": [{"authorId": "1693125", "name":
        "A. Tomasic"}, {"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "2263576", "name": "Calvin Lue"}, {"authorId": "39055806", "name": "P. Schwarz"},
        {"authorId": "145704391", "name": "L. Haas"}]}, {"paperId": "5296edc2dae04f759bc06f959ba83989920f6182",
        "externalIds": {"MAG": "2023657004", "DOI": "10.1145/253260.253299", "CorpusId":
        2802334}, "corpusId": 2802334, "publicationVenue": {"id": "f68b9e7e-ad3d-46cb-857d-23e49384143c",
        "name": "ACM SIGMOD Conference", "type": "conference", "alternate_names":
        ["SIGMOD", "ACM SIGMOD Conf"], "url": "https://sigmod.org/conferences/"},
        "url": "https://www.semanticscholar.org/paper/5296edc2dae04f759bc06f959ba83989920f6182",
        "title": "STARTS: Stanford proposal for Internet meta-searching", "abstract":
        "Document sources are available everywhere, both within the internal networks
        of organizations and on the Internet. Even individual organizations use search
        engines from different vendors to index their internal document collections.
        These search engines are typically incompatible in that they support different
        query models and interfaces, they do not return enough information with the
        query results for adequate merging of the results, and finally, in that they
        do not export metadata about the collections that they index (e.g., to assist
        in resource discovery). This paper describes STARTS, an emerging protocol
        for Internet retrieval and search that facilitates the task of querying multiple
        document sources. STARTS has been developed in a unique way. It is not a standard,
        but a group effort coordinated by Stanford''s Digital Library project, and
        involving over 11 companies and organizations. The objective of this paper
        is not only to give an overview of the STARTS protocol proposal, but also
        to discuss the process that led to its definition.", "venue": "ACM SIGMOD
        Conference", "year": 1997, "referenceCount": 29, "citationCount": 255, "influentialCitationCount":
        11, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["Review"], "publicationDate": "1997-06-01", "journal":
        {"volume": "26", "pages": "207-218", "name": ""}, "authors": [{"authorId":
        "1684012", "name": "L. Gravano"}, {"authorId": "72660638", "name": "Chen-Chuan
        K. Chang"}, {"authorId": "1398574232", "name": "H. Garcia-Molina"}, {"authorId":
        "1750481", "name": "A. Paepcke"}]}, {"paperId": "e23529a0bf1a475db93951c93524b6af427cec4c",
        "externalIds": {"DBLP": "conf/sigmod/GravanoCGP97", "MAG": "53649117", "DOI":
        "10.1145/253262.253299", "CorpusId": 209397916}, "corpusId": 209397916, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/e23529a0bf1a475db93951c93524b6af427cec4c",
        "title": "STARTS: Stanford Proposal for Internet Meta-Searching (Experience
        Paper)", "abstract": null, "venue": "SIGMOD Conference", "year": 1997, "referenceCount":
        0, "citationCount": 10, "influentialCitationCount": 1, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}], "publicationTypes":
        ["JournalArticle", "Conference"], "publicationDate": null, "journal": {"pages":
        "207-218"}, "authors": [{"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "143922493", "name": "K. Chang"}, {"authorId": "1398574232", "name": "H. Garcia-Molina"},
        {"authorId": "1750481", "name": "A. Paepcke"}]}, {"paperId": "f0c02277e26255b418d5f76d514c5eec0a4b47f8",
        "externalIds": {"MAG": "1586841715", "CorpusId": 60484139}, "corpusId": 60484139,
        "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/f0c02277e26255b418d5f76d514c5eec0a4b47f8",
        "title": "STARTS: Stanford Protocol Proposal for Internet Retrieval and Search",
        "abstract": "Document databases are available everywhere, both within the
        internal networks of the organizations and on the Internet. The database contents
        are often \"hidden\" behind search interfaces. These interfaces vary from
        database to database. Also, the algorithms with which the associated search
        engines rank the documents in the query results are usually incompatible across
        databases. Even individual organizations use search engines from different
        vendors to index their internal document collections. These organizations
        could benefit from unified query interfaces to multiple search engines, for
        example, that would give users the illusion of a single big document database.
        Building such \"metasearchers\" is nowadays a hard task because different
        search engines are largely incompatible and do not allow for interoperability.
        To improve this situation, the Digital Library project at Stanford has coordinated
        among search-engine vendors and other key players to reach informal agreements
        for unifying basic interactions in these three areas. This is the final writeup
        of our informal \"standards\" effort. This draft is based on feedback from
        people from Excite, Fulcrum, GILS, Harvest, Hewlett-Packard Laboratories,
        Infoseek, Microsoft Network, Netscape, PLS, Verity, and WAIS, among others.",
        "venue": "", "year": 1997, "referenceCount": 3, "citationCount": 102, "influentialCitationCount":
        3, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": null, "publicationDate": null, "journal": {"volume": "",
        "name": ""}, "authors": [{"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "143922493", "name": "K. Chang"}, {"authorId": "1398574232", "name": "H. Garcia-Molina"},
        {"authorId": "1750481", "name": "A. Paepcke"}]}, {"paperId": "1613abd9402dbd7461d652d74071cb91ef7a21b7",
        "externalIds": {"MAG": "2098025050", "DBLP": "conf/sigmod/ChaudhuriG96", "DOI":
        "10.1145/233269.233323", "CorpusId": 215985887}, "corpusId": 215985887, "publicationVenue":
        {"id": "f68b9e7e-ad3d-46cb-857d-23e49384143c", "name": "ACM SIGMOD Conference",
        "type": "conference", "alternate_names": ["SIGMOD", "ACM SIGMOD Conf"], "url":
        "https://sigmod.org/conferences/"}, "url": "https://www.semanticscholar.org/paper/1613abd9402dbd7461d652d74071cb91ef7a21b7",
        "title": "Optimizing queries over multimedia repositories", "abstract": "Repositories
        of multimedia objects having multiple types of attributes (e.g., image, text)
        are becoming increasingly common. A selection on these attributes will typically
        produce not just a set of objects, as in the traditional relational query
        model (filtering), but also a grade of match associated with each object,
        indicating how well the object matches the selection condition (ranking).
        Also, multimedia repositories may allow access to the attributes of each object
        only through indexes. We investigate how to optimize the processing of queries
        over multimedia repositories. A key issue is the choice of the indexes used
        to search the repository. We define an execution space that is search-minimal,
        i.e., the set of indexes searched is minimal. Although the general problem
        of picking an optimal plan in the search-minimal execution space is NP-hard,
        we solve the problem efficiently when the predicates in the query are independent.
        We also show that the problem of optimizing queries that ask for a few top-ranked
        objects can be viewed, in many cases, as that of evaluating selection conditions.
        Thus, both problems can be viewed together as an extended filtering problem.",
        "venue": "ACM SIGMOD Conference", "year": 1996, "referenceCount": 30, "citationCount":
        81, "influentialCitationCount": 4, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
        "1996-06-01", "journal": {"pages": "91-102"}, "authors": [{"authorId": "145647476",
        "name": "S. Chaudhuri"}, {"authorId": "1684012", "name": "L. Gravano"}]},
        {"paperId": "44e832f182dd508587d6abed2e61cad8061c68c0", "externalIds": {"DBLP":
        "conf/pdis/Garcia-MolinaGS96", "MAG": "2141359307", "DOI": "10.1109/PDIS.1996.568668",
        "CorpusId": 10239966}, "corpusId": 10239966, "publicationVenue": null, "url":
        "https://www.semanticscholar.org/paper/44e832f182dd508587d6abed2e61cad8061c68c0",
        "title": "dSCAM: finding document copies across multiple databases", "abstract":
        "The advent of the Internet has made the illegal dissemination of copyrighted
        material easy. An important problem is how to automatically detect when a
        \"new\" digital document is \"suspiciously close\" to existing ones. The SCAM
        project at Stanford University has addressed this problem when there is a
        single registered-document database. However, in practice, test documents
        may appear in many autonomous databases, and one would like to discover copies
        without having to exhaustively search in all databases. The authors'' approach,
        dSCAM, is a distributed version of SCAM that keeps succinct metainformation
        about the contents of the available document databases. Given a suspicious
        document S, dSCAM uses its information to prune all databases that cannot
        contain any document that is close enough to S, and hence the search can focus
        on the remaining sites. They also study how to query the remaining databases
        so as to minimize different querying costs. They empirically study the pruning
        and searching schemes, using a collection of 50 databases and two sets of
        test documents.", "venue": "Fourth International Conference on Parallel and
        Distributed Information Systems", "year": 1996, "referenceCount": 24, "citationCount":
        39, "influentialCitationCount": 2, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle", "Conference"],
        "publicationDate": "1996-12-01", "journal": {"pages": "68-79", "name": "Fourth
        International Conference on Parallel and Distributed Information Systems"},
        "authors": [{"authorId": "1398574232", "name": "H. Garcia-Molina"}, {"authorId":
        "1684012", "name": "L. Gravano"}, {"authorId": "1712337", "name": "N. Shivakumar"}]},
        {"paperId": "8897aed85e8da828c8331ceca2a1b98e4cd7e763", "externalIds": {"DBLP":
        "conf/vldb/GravanoG95", "MAG": "1564059483", "CorpusId": 8894988}, "corpusId":
        8894988, "publicationVenue": {"id": "a5c58053-0673-4cdb-b2b8-b6b0ad6911d1",
        "name": "Very Large Data Bases Conference", "type": "conference", "alternate_names":
        ["Very Large Data Bases", "Very Large Data Base", "VLDB", "Very Large Data
        Base Conf"], "url": "https://www.vldb.org/conference.html"}, "url": "https://www.semanticscholar.org/paper/8897aed85e8da828c8331ceca2a1b98e4cd7e763",
        "title": "Generalizing GlOSS to Vector-Space Databases and Broker Hierarchies",
        "abstract": "As large numbers of text databases have become available on the
        Internet, it is getting harder to locate the right sources for given queries.
        In this paper we present gGlOSS, a generalized Glossary-Of-Servers Server,
        that keeps statistics on the available databases to estimate which databases
        are the potentially most useful for a given query. gGlOSS extends our previous
        work, which focused on databases using the boolean model of document retrieval,
        to cover databases using the more sophisticated vector-space retrieval model.
        We evaluate our new techniques using real-user queries and 53 databases. Finally,
        we further generalize our approach by showing how to build a hierarchy of
        gGlOSS brokers. The top level of the hierarchy is so small it could be widely
        replicated, even at end-user workstations.", "venue": "Very Large Data Bases
        Conference", "year": 1995, "referenceCount": 30, "citationCount": 308, "influentialCitationCount":
        19, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "1995-09-11",
        "journal": {"pages": "78-89"}, "authors": [{"authorId": "1684012", "name":
        "L. Gravano"}, {"authorId": "1398574232", "name": "H. Garcia-Molina"}]}, {"paperId":
        "3c0c8394cbbc2fd71e3de082b2f676f45ee3f95d", "externalIds": {"DBLP": "conf/pdis/GravanoGT94",
        "MAG": "1908963334", "DOI": "10.1109/PDIS.1994.331726", "CorpusId": 3090485},
        "corpusId": 3090485, "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/3c0c8394cbbc2fd71e3de082b2f676f45ee3f95d",
        "title": "Precision and recall of GlOSS estimators for database discovery",
        "abstract": "Online information vendors and the Internet together offer thousands
        of text databases from which a user may choose for a given information need.
        This paper presents a framework for and analyses a solution to this problem,
        which we call the text-database discovery problem. Our solution is to build
        a service that can suggest potentially good databases to search. A user''s
        query goes through two steps: first, the query is presented to the GlOSS server
        (Glossary-Of-Servers Server) to select a set of promising databases to search.
        Secondly, the query is actually evaluated in the chosen databases. GlOSS gives
        a hint of what databases might be useful for the user''s query, based on word-frequency
        information for each database. This information indicates how many documents
        in each database actually contain a keyword, for each field designator. To
        evaluate the set of databases that GlOSS returns for a given query, we present
        a framework based on the precision and recall metrics of information retrieval
        theory. We define metrics for the text-database discovery problem. We further
        extend our framework by offering different definitions for a \"relevant database\".
        We have performed experiments using query traces from the FOLIO library information
        retrieval system, involving six databases available through FOLIO. The results
        obtained for different variants of GlOSS are very promising. Even though GlOSS
        keeps a small amount of information about the contents of the available databases,
        this information proved to be sufficient to produce very useful hints on where
        to search.<<ETX>>", "venue": "Proceedings of 3rd International Conference
        on Parallel and Distributed Information Systems", "year": 1994, "referenceCount":
        29, "citationCount": 49, "influentialCitationCount": 4, "isOpenAccess": true,
        "openAccessPdf": {"url": "http://www.cs.cmu.edu/~tomasic/doc/1994/GravanoGarciaTomasicPDIS1994.pdf",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle",
        "Conference"], "publicationDate": "1994-10-01", "journal": {"pages": "103-106",
        "name": "Proceedings of 3rd International Conference on Parallel and Distributed
        Information Systems"}, "authors": [{"authorId": "1684012", "name": "L. Gravano"},
        {"authorId": "1398574232", "name": "H. Garcia-Molina"}, {"authorId": "1693125",
        "name": "A. Tomasic"}]}, {"paperId": "405b70a06edf58884990df609a622bd245f816d6",
        "externalIds": {"DBLP": "journals/tpds/PifarreGFS94", "MAG": "2106836982",
        "DOI": "10.1109/71.277792", "CorpusId": 5395163}, "corpusId": 5395163, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/405b70a06edf58884990df609a622bd245f816d6",
        "title": "Fully Adaptive Minimal Deadlock-Free Packet Routing in Hypercubes,
        Meshes, and other Networks: Algorithms and Simulations", "abstract": "This
        paper deals with the problem of packet-switched routing in parallel machines.
        Several new routing algorithms for different interconnection networks are
        presented. While the new techniques apply to a wide variety of networks, routing
        algorithms will be shown for the hypercube, the two-dimensional mesh, and
        the shuffle-exchange. Although the new techniques are designed for packet
        routing, they can be used alternatively for virtual cut-through routing models.
        The techniques presented for hypercubes and meshes are fully-adaptive and
        minimal. A fully-adaptive and minimal routing is one in which all possible
        minimal paths between a source and a destination are of potential use at the
        time a message is injected into the network. Minimal paths followed by messages
        ultimately depend on the local congestion encountered in each node of the
        network. All of the new techniques are completely free of deadlock situations.
        >", "venue": "IEEE Trans. Parallel Distributed Syst.", "year": 1994, "referenceCount":
        45, "citationCount": 54, "influentialCitationCount": 4, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "1994-03-01", "journal": {"volume": "5", "pages": "247-263",
        "name": "IEEE Trans. Parallel Distributed Syst."}, "authors": [{"authorId":
        "3274819", "name": "G. Pifarr\u00e9"}, {"authorId": "1684012", "name": "L.
        Gravano"}, {"authorId": "1793017", "name": "S. A. Felperin"}, {"authorId":
        "152958943", "name": "J. Sanz"}]}, {"paperId": "70ad64e3ee1191c858e27756c80487ea8b69d2ac",
        "externalIds": {"DBLP": "conf/sigmod/GravanoGT94", "MAG": "2073788020", "DOI":
        "10.1145/191839.191869", "CorpusId": 14439809}, "corpusId": 14439809, "publicationVenue":
        {"id": "f68b9e7e-ad3d-46cb-857d-23e49384143c", "name": "ACM SIGMOD Conference",
        "type": "conference", "alternate_names": ["SIGMOD", "ACM SIGMOD Conf"], "url":
        "https://sigmod.org/conferences/"}, "url": "https://www.semanticscholar.org/paper/70ad64e3ee1191c858e27756c80487ea8b69d2ac",
        "title": "The effectiveness of GIOSS for the text database discovery problem",
        "abstract": "The popularity of on-line document databases has led to a new
        problem: finding which text databases (out of many candidate choices) are
        the most relevant to a user. Identifying the relevant databases for a given
        query is the text database discovery problem. The first part of this paper
        presents a practical solution based on estimating the result size of a query
        and a database. The method is termed GlOSS\u2014Glossary of Servers Server.
        The second part of this paper evaluates the effectiveness of GlOSS based on
        a trace of real user queries. In addition, we analyze the storage cost of
        our approach.", "venue": "ACM SIGMOD Conference", "year": 1994, "referenceCount":
        24, "citationCount": 244, "influentialCitationCount": 17, "isOpenAccess":
        true, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/191843.191869",
        "status": null}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
        "publicationDate": "1994-05-24", "journal": {"pages": "126-137"}, "authors":
        [{"authorId": "1684012", "name": "L. Gravano"}, {"authorId": "1398574232",
        "name": "H. Garcia-Molina"}, {"authorId": "1693125", "name": "A. Tomasic"}]},
        {"paperId": "8beea0917ac99f0dcd98f9d5cc56a76c1809df22", "externalIds": {"DBLP":
        "journals/tc/CypherG94", "MAG": "2125695870", "DOI": "10.1109/12.338097",
        "CorpusId": 13060161}, "corpusId": 13060161, "publicationVenue": null, "url":
        "https://www.semanticscholar.org/paper/8beea0917ac99f0dcd98f9d5cc56a76c1809df22",
        "title": "Storage-Efficient, Deadlock-Free Packet Routing Algorithms for Torus
        Networks", "abstract": "We present two new packet routing algorithms for parallel
        computers with torus interconnection networks of arbitrary size and dimension.
        Both algorithms use only minimal length paths, are fully adaptive in the sense
        that all minimal length paths may be used to avoid congestion, and are free
        of deadlock, livelock and starvation. Algorithm 1 requires only three central
        queues per routing node. It is the first known minimal length packet routing
        algorithm for torus networks which requires a constant number of queues per
        node, regardless of the size and dimension of the torus. In fact, the requirement
        of three queues per node is optimal, as no such algorithm is possible when
        all nodes have two or fewer queues. Algorithm 2 requires only that each node
        have two input buffers per edge. It is the first known minimal-fully-adaptive
        packet routing algorithm for torus networks which does not require central
        queues and which does not require any node to have more than two input or
        two output buffers per edge. Both algorithms are simple and appear to be well-suited
        to VLSI implementation. They can be used with either store-and-forward or
        virtual cut-through routing. >", "venue": "IEEE Trans. Computers", "year":
        1994, "referenceCount": 35, "citationCount": 33, "influentialCitationCount":
        3, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "1994-12-01", "journal":
        {"volume": "43", "pages": "1376-1385", "name": "IEEE Trans. Computers"}, "authors":
        [{"authorId": "144764844", "name": "R. Cypher"}, {"authorId": "1684012", "name":
        "L. Gravano"}]}, {"paperId": "90242db49d74e120e96ef1a66ecda0f0a92e1faa", "externalIds":
        {"MAG": "2168324245", "DBLP": "journals/tpds/PifarreGDS94", "DOI": "10.1109/71.329674",
        "CorpusId": 41502126}, "corpusId": 41502126, "publicationVenue": null, "url":
        "https://www.semanticscholar.org/paper/90242db49d74e120e96ef1a66ecda0f0a92e1faa",
        "title": "Adaptive Deadlock- and Livelock-Free Routing in the Hypercube Network",
        "abstract": "This paper consists of two parts. In the first one, two new algorithms
        for wormhole routing on the hypercube network are presented. These techniques
        are adaptive and are ensured to be deadlock- and livelock-free. These properties
        are guaranteed by using a small number of resources in the routing node. The
        first algorithm is adaptive and nonminimal and will be referred to as Nonminimal.
        In this technique, some moderate derouting is allowed in order to alleviate
        the potential congestion arising from highly structured communication patterns.
        The second algorithm, dubbed Subcubes, is adaptive and minimal, and is based
        on partitioning the hypercube into subcubes of smaller dimension; This technique
        requires only two virtual channels per physical link of the node. In the second
        part of the paper, a wide variety of techniques for wormhole routing in the
        hypercube are evaluated from an algorithmic point of view. Five partially
        adaptive algorithms are considered: the Hanging algorithm, the Zenith algorithm,
        the Hanging-Order algorithm, the Nonminimal algorithm; and the Subcubes algorithm.
        One oblivious algorithm, the Dimension-Order, or E-Cube routing algorithm,
        is also used. Finally, a Fully Adaptive Minimal algorithm is tried. A simple
        node model was designed and adapted to all the algorithms. >", "venue": "IEEE
        Trans. Parallel Distributed Syst.", "year": 1994, "referenceCount": 34, "citationCount":
        20, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
        "1994-11-01", "journal": {"volume": "5", "pages": "1121-1139", "name": "IEEE
        Trans. Parallel Distributed Syst."}, "authors": [{"authorId": "3274819", "name":
        "G. Pifarr\u00e9"}, {"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "2506241", "name": "Gustavo Denicolay"}, {"authorId": "152958943", "name":
        "J. Sanz"}]}, {"paperId": "ba92ba07cb9eafe18f6435e4ccadddb358195468", "externalIds":
        {"MAG": "814276127", "CorpusId": 60201111}, "corpusId": 60201111, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/ba92ba07cb9eafe18f6435e4ccadddb358195468",
        "title": "The Efficacy of GlOSS for the Text Database Retrieval Problem",
        "abstract": null, "venue": "", "year": 1994, "referenceCount": 0, "citationCount":
        0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate": null,
        "journal": {"volume": "", "name": ""}, "authors": [{"authorId": "1684012",
        "name": "L. Gravano"}, {"authorId": "1398574232", "name": "H. Garcia-Molina"},
        {"authorId": "1693125", "name": "A. Tomasic"}]}, {"paperId": "8fc1b50c90069f2d1720aecf76ed03f0d402b36b",
        "externalIds": {"MAG": "1489326036", "CorpusId": 13997384}, "corpusId": 13997384,
        "publicationVenue": {"id": "f68b9e7e-ad3d-46cb-857d-23e49384143c", "name":
        "ACM SIGMOD Conference", "type": "conference", "alternate_names": ["SIGMOD",
        "ACM SIGMOD Conf"], "url": "https://sigmod.org/conferences/"}, "url": "https://www.semanticscholar.org/paper/8fc1b50c90069f2d1720aecf76ed03f0d402b36b",
        "title": "The Efficacy of GlOSS for the Text Database Discovery Problem",
        "abstract": "The popularity of information retrieval has led users to a new
        problem: finding which text databases (out of thousands of candidate choices)
        are the most relevant to a user. Answering a given query with a list of relevant
        databases is the text database discovery problem. The first part of this paper
        presents a practical method for attacking this problem based on estimating
        the result size of a query and a database. The method is termed GlOSS--Glossary
        of Servers Server. The second part of this paper evaluates GlOSS using four
        different semantics to answer a user''''s queries. Real users'''' queries
        were used in the experiments. We also describe several variations of GlOSS
        and compare their efficacy. In addition, we analyze the storage cost of our
        approach to the problem.", "venue": "ACM SIGMOD Conference", "year": 1993,
        "referenceCount": 23, "citationCount": 42, "influentialCitationCount": 0,
        "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": null, "publicationDate": "1993-12-01", "journal": {"volume":
        "", "name": ""}, "authors": [{"authorId": "1684012", "name": "L. Gravano"},
        {"authorId": "1398574232", "name": "H. Garcia-Molina"}, {"authorId": "1693125",
        "name": "A. Tomasic"}]}, {"paperId": "278dd6415f07db4d6ec13096642e4f1cf5189f58",
        "externalIds": {"DBLP": "conf/spaa/BermanGPS92", "MAG": "2110240108", "DOI":
        "10.1145/140901.140902", "CorpusId": 8803270}, "corpusId": 8803270, "publicationVenue":
        {"id": "43893b55-fde6-4e2b-9d2e-c15a669a1f94", "name": "ACM Symposium on Parallelism
        in Algorithms and Architectures", "type": "conference", "alternate_names":
        ["SPAA", "ACM Symposium on Parallel Algorithms and Architectures", "ACM Symp
        Parallelism Algorithm Archit", "ACM Symp Parallel Algorithm Archit"], "url":
        "http://www.spaa-conference.org/"}, "url": "https://www.semanticscholar.org/paper/278dd6415f07db4d6ec13096642e4f1cf5189f58",
        "title": "Adaptive deadlock- and livelock-free routing with all minimal paths
        in Torus networks", "abstract": "This paper consists of two parts. In the
        first part, two new algorithms for deadlock- and livelock-free wormhole routing
        in the torus network are presented. The first algorithm, called Channels,
        is for the n-dimensional torus network. This technique is fully-adaptive minimal,
        that is, all paths with a minimal number of hops from source to destination
        are available for routing, and needs only five virtual channels per bidirectional
        link, the lowest channel requirement known in the literature for fully-adaptive
        minimal worm-hole routing. In addition, this result also yields the lowest
        buffer requirement known in the literature for packet-switched fully-adaptive
        minimal routing. The second algorithm, called 4-Classes, is for the bidimensional
        torus network. This technique is fully-adaptive minimal and requires only
        eight virtual channels per bidirectional link. Also, it allows for a highly
        parallel implementation of its associated routing node. In the second part
        of this paper, four worm-hole routing techniques for the two-dimensional torus
        are experimentally evaluated using a dynamic message injection model and different
        traffic patterns and message lengths. >", "venue": "ACM Symposium on Parallelism
        in Algorithms and Architectures", "year": 1992, "referenceCount": 38, "citationCount":
        169, "influentialCitationCount": 4, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
        "1992-06-01", "journal": {"volume": "5", "pages": "1233-1251", "name": "IEEE
        Trans. Parallel Distributed Syst."}, "authors": [{"authorId": "1684012", "name":
        "L. Gravano"}, {"authorId": "3274819", "name": "G. Pifarr\u00e9"}, {"authorId":
        "46543980", "name": "P. E. Berman"}, {"authorId": "152958943", "name": "J.
        Sanz"}]}, {"paperId": "9813b72e279a203cd2aea483c451b887481fc471", "externalIds":
        {"MAG": "1964352350", "DBLP": "conf/podc/CypherG92", "DOI": "10.1145/135419.135425",
        "CorpusId": 6378273}, "corpusId": 6378273, "publicationVenue": {"id": "cce4d150-8211-4378-a9ef-a234ec19414c",
        "name": "ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing",
        "type": "conference", "alternate_names": ["PODC", "Princ Distrib Comput",
        "Principles of Distributed Computing", "ACM SIGACT-SIGOPS Symp Princ Distrib
        Comput"], "url": "http://www.podc.org/"}, "url": "https://www.semanticscholar.org/paper/9813b72e279a203cd2aea483c451b887481fc471",
        "title": "Requirements for deadlock-free, adaptive packet routing", "abstract":
        "This paper studies the problem of deadlock-free packet routing in parallel
        and distributed architectures. We present three main results. First, we show
        that the standard technique of ordering the queues so that every packet always
        has the possibility of moving to a higher ordered queue is not necessary for
        deadlock-freedom. Second, we show that every deadlock-free, adaptive packet
        routing algorithm can be restricted, by limiting the adaptivity available,
        to obtain an oblivious algorithm which is also deadlock-free. Third, we show
        that any packet routing algorithm for a cycle or torus network which is free
        of deadlock and which uses only minimal length paths must require at least
        three queues in some node. This matches the known upper bound of three queues
        per node for deadlock-free, minimal packet routing on cycle and torus networks.",
        "venue": "ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing",
        "year": 1992, "referenceCount": 22, "citationCount": 39, "influentialCitationCount":
        3, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle"], "publicationDate": "1992-10-01", "journal":
        {"volume": "23", "pages": "1266-1274", "name": "SIAM J. Comput."}, "authors":
        [{"authorId": "144764844", "name": "R. Cypher"}, {"authorId": "1684012", "name":
        "L. Gravano"}]}, {"paperId": "cfb408cca6810a0509922ed963b14e6f35dbee05", "externalIds":
        {"MAG": "2120424897", "DBLP": "conf/ipps/GravanoPDS92", "DOI": "10.1109/IPPS.1992.222975",
        "CorpusId": 33984858}, "corpusId": 33984858, "publicationVenue": null, "url":
        "https://www.semanticscholar.org/paper/cfb408cca6810a0509922ed963b14e6f35dbee05",
        "title": "Adaptive deadlock-free worm-hole routing in hypercubes", "abstract":
        "Two new algorithms for worm-hole routing in the hypercube are presented.
        The first hypercube algorithm is adaptive, but non-minimal in the sense that
        some derouting is permitted. Then another deadlock-free adaptive worm-hole
        based routing algorithm for the hypercube interconnection is presented which
        is minimal. Finally some well-known worm-hole algorithms for the hypercube
        were evaluated together with the new ones on a hypercube of 2/sup 10/ nodes.
        One oblivious algorithm, the Dimension-Order, or E-Cube routing algorithm
        (W. Dally, C. Seitz, 1987) was tried. In addition, three partially adaptive
        algorithms were considered: the Hanging algorithm (Y. Birk, P. Gibbons, D.
        Soroker, J. Sanz, 1989 and S. Konstantinidou, 1990), the Zenith algorithm
        (S. Konstantinidou, 1990), and the Hanging-Order algorithm (G.-M. Chia, S.
        Chalasani, C.S. Raghavendra, 1991). Finally, a fully adaptive minimal algorithm
        presented independently by L. Gravano, G. Pifarre, S.A. Felperin and J. Sanz
        (1991) and J. Duato was tried. This algorithm allows each message to choose
        adaptively among all the shortest paths from its source to its destination.
        Only four virtual channels per physical link are needed to achieve this. This
        technique is referred to as Fully. The results obtained show that the two
        new algorithms are good candidates as a choice for worm-hole routing in the
        hypercube network.<<ETX>>", "venue": "Proceedings Sixth International Parallel
        Processing Symposium", "year": 1992, "referenceCount": 7, "citationCount":
        13, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
        null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "external"}, {"category": "Computer Science",
        "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
        "1992-03-01", "journal": {"pages": "512-515", "name": "Proceedings Sixth International
        Parallel Processing Symposium"}, "authors": [{"authorId": "1684012", "name":
        "L. Gravano"}, {"authorId": "3274819", "name": "G. Pifarr\u00e9"}, {"authorId":
        "2506241", "name": "Gustavo Denicolay"}, {"authorId": "152958943", "name":
        "J. Sanz"}]}, {"paperId": "fa198c2e553847f637d237944459fe1b8eb5540f", "externalIds":
        {"MAG": "21401474", "DBLP": "conf/icpp/CypherG92", "CorpusId": 37722984},
        "corpusId": 37722984, "publicationVenue": {"id": "29df4b17-9a16-4a4c-94a6-002f52e628b4",
        "name": "International Conference on Parallel Processing", "type": "conference",
        "alternate_names": ["ICPP", "Int Conf Parallel Process", "IEEE Int Conf Pulsed
        Power", "IEEE International Conference on Pulsed Power"], "url": "http://www.wikicfp.com/cfp/program?id=1447"},
        "url": "https://www.semanticscholar.org/paper/fa198c2e553847f637d237944459fe1b8eb5540f",
        "title": "Adaptive, Deadlock-Free Packet Routing in Torus Networks with Minimal
        Storage", "abstract": null, "venue": "International Conference on Parallel
        Processing", "year": 1992, "referenceCount": 0, "citationCount": 26, "influentialCitationCount":
        2, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Business", "source": "s2-fos-model"}], "publicationTypes":
        ["JournalArticle", "Conference"], "publicationDate": null, "journal": {"pages":
        "204-211"}, "authors": [{"authorId": "144764844", "name": "R. Cypher"}, {"authorId":
        "1684012", "name": "L. Gravano"}]}, {"paperId": "286c8b5d5b12e043954eb145eef8330f3276cc5f",
        "externalIds": {"MAG": "2134423112", "DBLP": "journals/pieee/FelperinGPS91",
        "DOI": "10.1109/5.92043", "CorpusId": 61727576}, "corpusId": 61727576, "publicationVenue":
        {"id": "6faaccca-1cc4-45a9-aeb6-96a4901d2606", "name": "Proceedings of the
        IEEE", "type": "journal", "alternate_names": ["Proc IEEE"], "issn": "0018-9219",
        "alternate_issns": ["1558-2256"], "url": "http://www.ieee.org/portal/pages/pubs/proceedings/",
        "alternate_urls": ["http://www.ieee.org/products/onlinepubs/pub/about_conference.html",
        "https://ieeexplore.ieee.org/servlet/opac?punumber=5", "http://proceedingsoftheieee.ieee.org/"]},
        "url": "https://www.semanticscholar.org/paper/286c8b5d5b12e043954eb145eef8330f3276cc5f",
        "title": "Routing techniques for massively parallel communication", "abstract":
        "A survey of some packet-switched routing methods for massively parallel computers
        is presented. Some of the techniques are applicable to both shared-memory
        and message-passing architectures. These routing methods are compared in terms
        of their efficiency in supporting programming models, efficiency in mapping
        to parallel machines, and practicality. Among the outlined methods, three
        nonadaptive techniques and some adaptive routing algorithms are discussed.
        >", "venue": "Proceedings of the IEEE", "year": 1991, "referenceCount": 30,
        "citationCount": 70, "influentialCitationCount": 1, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle",
        "Review"], "publicationDate": "1991-04-01", "journal": {"volume": "79", "pages":
        "488-503", "name": "Proc. IEEE"}, "authors": [{"authorId": "1793017", "name":
        "S. A. Felperin"}, {"authorId": "1684012", "name": "L. Gravano"}, {"authorId":
        "3274819", "name": "G. Pifarr\u00e9"}, {"authorId": "152958943", "name": "J.
        Sanz"}]}, {"paperId": "63c0e3b785d8d6c379eefa505525f8d354ceb831", "externalIds":
        {"DBLP": "conf/spaa/PifarreGFS91", "MAG": "2024759612", "DOI": "10.1145/113379.113405",
        "CorpusId": 11434699}, "corpusId": 11434699, "publicationVenue": {"id": "43893b55-fde6-4e2b-9d2e-c15a669a1f94",
        "name": "ACM Symposium on Parallelism in Algorithms and Architectures", "type":
        "conference", "alternate_names": ["SPAA", "ACM Symposium on Parallel Algorithms
        and Architectures", "ACM Symp Parallelism Algorithm Archit", "ACM Symp Parallel
        Algorithm Archit"], "url": "http://www.spaa-conference.org/"}, "url": "https://www.semanticscholar.org/paper/63c0e3b785d8d6c379eefa505525f8d354ceb831",
        "title": "Fully-adaptive minimal deadlock-free packet routing in hypercubes,
        meshes, and other networks", "abstract": "This paper deals with the problem
        of packet-switched routing in parallel machines. Several new routing algorithms
        for different interconnection networks are presented. While the new techniques
        apply to a wide variety of networks, routing algorithms will be shown for
        the bypercube, the 2-dinleusional mesh, and the shuffleexchange. The techniques
        presented for hypercubes and meshes are fully-adaptive and minimal. A similar
        technique can be devised for tori. A fully-adaptive and millimal routing is
        one in which all possible minimal paths bet,ween a source and a destination
        are of potential use at the time a message is injected into the network. Minimal
        paths followed by messages ultimately depend on the local congestion encountered
        in each node of the network. In the shuffle-exchange network, the routing
        scheme also exhibits adaptivity but paths could be up to 3 log N long for
        an N node machine. The shuflleexchange algorithm is the first adaptive and
        deadlockfree method that requires a small (and independent of N) number of
        buffers and queues in the routing nodes for that network. * ESLAI, Escuela
        Superior Latino Americana de Informitica, CC 3193,(1000) Buenos Aires, Argentina.
        t Computer Research and Advanced Applications Group, IBM Argentina, Ing. E.
        Bntti 275, (1300) Buenos Aires, Argentina. + Computer Science Dept., IBh\u20191
        Almadeu Research Center, San", "venue": "ACM Symposium on Parallelism in Algorithms
        and Architectures", "year": 1991, "referenceCount": 17, "citationCount": 39,
        "influentialCitationCount": 3, "isOpenAccess": false, "openAccessPdf": null,
        "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
        Science", "source": "external"}, {"category": "Computer Science", "source":
        "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
        "1991-06-01", "journal": {"pages": "278-290"}, "authors": [{"authorId": "3274819",
        "name": "G. Pifarr\u00e9"}, {"authorId": "1684012", "name": "L. Gravano"},
        {"authorId": "1793017", "name": "S. A. Felperin"}, {"authorId": "152958943",
        "name": "J. Sanz"}]}, {"paperId": "c60b14354b0ac82c2f883f739e16c6720ebe870a",
        "externalIds": {"DBLP": "conf/sc/FelperinGPS91", "MAG": "2129541548", "DOI":
        "10.1145/125826.126141", "CorpusId": 8405721}, "corpusId": 8405721, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/c60b14354b0ac82c2f883f739e16c6720ebe870a",
        "title": "Fully-adaptive routing: packet switching performance and wormhole
        algorithms", "abstract": "No abstract available", "venue": "Proceedings of
        the 1991 ACM/IEEE Conference on Supercomputing (Supercomputing ''91)", "year":
        1991, "referenceCount": 26, "citationCount": 26, "influentialCitationCount":
        2, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
        Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
        "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "1991-08-01",
        "journal": {"pages": "654-663", "name": "Proceedings of the 1991 ACM/IEEE
        Conference on Supercomputing (Supercomputing ''91)"}, "authors": [{"authorId":
        "1793017", "name": "S. A. Felperin"}, {"authorId": "1684012", "name": "L.
        Gravano"}, {"authorId": "3274819", "name": "G. Pifarr\u00e9"}, {"authorId":
        "152958943", "name": "J. Sanz"}]}, {"paperId": "931db0ebdc70ec875807974b850925211ff3a3f9",
        "externalIds": {"CorpusId": 14281173}, "corpusId": 14281173, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/931db0ebdc70ec875807974b850925211ff3a3f9",
        "title": "1 2000 : Project Report to NSF Energy Data Collection Project Year
        1", "abstract": "The massive amount of statistical and text data available
        from Federal Agencies has created a set of daunting challenges to both research
        and analysis communities. These problems include heterogeneity, size, distribution,
        and control of terminology. At the Digital Government Research Center we are
        investigating solutions to three key problems, namely, (1) ontological mappings
        for terminology standardization; (2) data integration across data bases with
        high speed query processing; and (3) interfaces for query input and presentation
        of results. This collaboration between researchers California employs technology
        developed at both locations, in particular the SENSUS ontology, the SIMS multi-database
        access planner, the LKB automated dictionary and terminology analysis system,
        and others. The pilot application targets gasoline data from BLS, EIA, Census,
        and other agencies. As access to the web becomes a household commodity, the
        Government (and in particular Federal Agencies such as the Census Bureau,
        the Bureau of Labor Statistics, and others) has a mandate to make its information
        available to the public. But the massive amount of statistical and text data
        available from such agencies has created a set of daunting challenges to the
        research and analysis communities. These challenges stem from the heterogeneity,
        size, distribution, and disparity of terminology of the data. Equally, they
        stem from the need to provide broad and easy access to (and support proper
        understanding of) complex data.", "venue": "", "year": null, "referenceCount":
        20, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": null, "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "s2-fos-model"}], "publicationTypes": null,
        "publicationDate": null, "journal": null, "authors": [{"authorId": "2887330",
        "name": "J. Ambite"}, {"authorId": "1717530", "name": "Y. Arens"}, {"authorId":
        "1684012", "name": "L. Gravano"}, {"authorId": "70336901", "name": "Vasilis
        Hatzivassiloglou"}, {"authorId": "144547315", "name": "E. Hovy"}, {"authorId":
        "1761739", "name": "Judith L. Klavans"}, {"authorId": "2135707", "name": "A.
        Philpot"}, {"authorId": "3222571", "name": "Usha Ramachandran"}, {"authorId":
        "2479999", "name": "J. Sandhaus"}, {"authorId": "51005334", "name": "A. Singla"},
        {"authorId": "145822024", "name": "B. Whitman"}]}, {"paperId": "d34a065a8324975ba9b14fec3e5cf4a8df1dfd46",
        "externalIds": {"CorpusId": 14561045}, "corpusId": 14561045, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/d34a065a8324975ba9b14fec3e5cf4a8df1dfd46",
        "title": "Querying Large Text Databases for Efficient Information Extraction",
        "abstract": "A wealth of data is hidden within unstructured text. This data
        is often best exploited in structured or relational form, which is suited
        for sophisticated query processing, for integration with relational databases,
        and for data mining. Current information extraction techniques extract relations
        from a text database by examining every document in the database. This exhaustive
        approach is not practical, or sometimes even feasible, for large databases.
        In this paper, we develop an efficient query-based technique to identify documents
        that are potentially useful for the extraction of a target relation. We start
        by sampling the database to characterize the documents from which an information
        extraction system manages to extract relevant tuples. Then, we apply machine
        learning and information retrieval techniques to derive queries likely to
        match additional useful documents in the database. Finally, we issue these
        queries to the database to retrieve documents from which the information extraction
        system can extract the final relation. Our technique requires that databases
        support only a minimal boolean query interface, and is independent of the
        choice of the underlying information extraction system. We report a thorough
        experimental evaluation over more than one million documents that shows that
        we significantly improve the efficiency of the extraction process by focusing
        only on promising documents. Our proposed technique could be used to query
        a standard web search engine, hence providing a building block for efficient
        information extraction over the web at large.", "venue": "", "year": null,
        "referenceCount": 15, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess":
        false, "openAccessPdf": null, "fieldsOfStudy": null, "s2FieldsOfStudy": [{"category":
        "Computer Science", "source": "s2-fos-model"}], "publicationTypes": null,
        "publicationDate": null, "journal": null, "authors": [{"authorId": "1685296",
        "name": "Eugene Agichtein"}, {"authorId": "1684012", "name": "L. Gravano"}]}]},
        {"authorId": "150112919", "externalIds": {}, "url": "https://www.semanticscholar.org/author/150112919",
        "name": "G. Luis", "aliases": ["G Cardoso Luis", "Gravano Luis"], "affiliations":
        [], "homepage": null, "paperCount": 3, "citationCount": 0, "hIndex": 0, "papers":
        [{"paperId": "eba2ac9166e4e05749ff6c196deb03088579043f", "externalIds": {"MAG":
        "2744379703", "CorpusId": 196096349}, "corpusId": 196096349, "publicationVenue":
        null, "url": "https://www.semanticscholar.org/paper/eba2ac9166e4e05749ff6c196deb03088579043f",
        "title": "\u6df1\u3044\u30a6\u30a7\u30d6\u4e0a\u3067\u306e\u60c5\u5831\u62bd\u51fa\u306e\u305f\u3081\u306e\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u6226\u7565\u3010Powered
        by NICT\u3011", "abstract": null, "venue": "", "year": 2017, "referenceCount":
        0, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Engineering",
        "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate": null,
        "journal": {"volume": "53", "pages": "331", "name": "Information Processing
        and Management"}, "authors": [{"authorId": "150045922", "name": "Barrio Pablo"},
        {"authorId": "150112919", "name": "G. Luis"}]}, {"paperId": "9bf1aa6e5801e7979d4734a319f5e74d30c769b3",
        "externalIds": {"MAG": "2743939613", "CorpusId": 195968373}, "corpusId": 195968373,
        "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/9bf1aa6e5801e7979d4734a319f5e74d30c769b3",
        "title": "\u30d5\u30eb\u30c6\u30ad\u30b9\u30c8\u7279\u5fb4\u3092\u7528\u3044\u305f\u79d1\u5b66\u7684\u6982\u5ff5\u306e\u5f71\u97ff\u3092\u4e88\u6e2c\u3059\u308b\u3010Powered
        by NICT\u3011", "abstract": null, "venue": "", "year": 2016, "referenceCount":
        0, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate":
        null, "journal": {"volume": "67", "pages": "2696", "name": "Journal of the
        Association for Information Science and Technology"}, "authors": [{"authorId":
        "150216482", "name": "McKeown Kathy"}, {"authorId": "4848335", "name": "D.
        Hal"}, {"authorId": "150065917", "name": "Chaturvedi Snigdha"}, {"authorId":
        "153437160", "name": "P. John"}, {"authorId": "150320455", "name": "Thadani
        Kapil"}, {"authorId": "150045922", "name": "Barrio Pablo"}, {"authorId": "150045876",
        "name": "Biran Or"}, {"authorId": "2080586775", "name": "Bothe Suvarna"},
        {"authorId": "2056665775", "name": "C. Michael"}, {"authorId": "144084397",
        "name": "R. Kenneth"}, {"authorId": "150112919", "name": "G. Luis"}, {"authorId":
        "73444730", "name": "J. Rahul"}, {"authorId": "153837255", "name": "K. Ben"},
        {"authorId": "2065380480", "name": "M. Kevin"}, {"authorId": "2096933805",
        "name": "Moon Taesun"}, {"authorId": "2093860999", "name": "Neelakantan Arvind"},
        {"authorId": "150252992", "name": "O. Diarmuid"}, {"authorId": "2093784564",
        "name": "R. R. Dragomir"}, {"authorId": "150318245", "name": "Templeton Clay"},
        {"authorId": "69328625", "name": "T. Simone"}]}, {"paperId": "a47bcf952c78ad0e8bfdc92141c28cea7b965a42",
        "externalIds": {"MAG": "2743502541", "CorpusId": 187116698}, "corpusId": 187116698,
        "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/a47bcf952c78ad0e8bfdc92141c28cea7b965a42",
        "title": "SCADA\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u3092\u7528\u3044\u305fDAQ\u30a8\u30ec\u30af\u30c8\u30ed\u30cb\u30af\u30b9\u306e\u5236\u5fa1\u3010Powered
        by NICT\u3011", "abstract": null, "venue": "", "year": 2016, "referenceCount":
        0, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": null, "s2FieldsOfStudy": [{"category":
        "Engineering", "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate":
        null, "journal": {"volume": "2016", "pages": "4", "name": ""}, "authors":
        [{"authorId": "150112919", "name": "G. Luis"}, {"authorId": "103058833", "name":
        "Gaspar Clara"}, {"authorId": "2089151110", "name": "V. Joao"}, {"authorId":
        "2059618308", "name": "A. Federico"}]}]}, {"authorId": "2251343232", "externalIds":
        {}, "url": "https://www.semanticscholar.org/author/2251343232", "name": "Luis
        Gravano", "aliases": null, "affiliations": [], "homepage": null, "paperCount":
        1, "citationCount": 56, "hIndex": 1, "papers": [{"paperId": "cb348f5245a45756332ccbfd402ae99be78b8e3e",
        "externalIds": {"MAG": "208461", "PubMedCentral": "4584915", "CorpusId": 263455359,
        "PubMed": "24848215"}, "corpusId": 263455359, "publicationVenue": null, "url":
        "https://www.semanticscholar.org/paper/cb348f5245a45756332ccbfd402ae99be78b8e3e",
        "title": "Using Online Reviews by Restaurant Patrons to Identify Unreported
        Cases of Foodborne Illness \u2014 New York City, 2012\u20132013", "abstract":
        "While investigating an outbreak of gastrointestinal disease associated with
        a restaurant, the New York City Department of Health and Mental Hygiene (DOHMH)
        noted that patrons had reported illnesses on the business review website Yelp
        (http://www.yelp.com) that had not been reported to DOHMH. To explore the
        potential of using Yelp to identify unreported outbreaks, DOHMH worked with
        Columbia University and Yelp on a pilot project to prospectively identify
        restaurant reviews on Yelp that referred to foodborne illness. During July
        1, 2012-March 31, 2013, approximately 294,000 Yelp restaurant reviews were
        analyzed by a software program developed for the project. The program identified
        893 reviews that required further evaluation by a foodborne disease epidemiologist.
        Of the 893 reviews, 499 (56%) described an event consistent with foodborne
        illness (e.g., patrons reported diarrhea or vomiting after their meal), and
        468 of those described an illness within 4 weeks of the review or did not
        provide a period. Only 3% of the illnesses referred to in the 468 reviews
        had also been reported directly to DOHMH via telephone and online systems
        during the same period. Closer examination determined that 129 of the 468
        reviews required further investigation, resulting in telephone interviews
        with 27 reviewers. From those 27 interviews, three previously unreported restaurant-related
        outbreaks linked to 16 illnesses met DOHMH outbreak investigation criteria;
        environmental investigation of the three restaurants identified multiple food-handling
        violations. The results suggest that online restaurant reviews might help
        to identify unreported outbreaks of foodborne illness and restaurants with
        deficiencies in food handling. However, investigating reports of illness in
        this manner might require considerable time and resources.", "venue": "MMWR.
        Morbidity and mortality weekly report", "year": 2014, "referenceCount": 11,
        "citationCount": 56, "influentialCitationCount": 0, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Medicine"], "s2FieldsOfStudy": [{"category":
        "Medicine", "source": "external"}, {"category": "Medicine", "source": "s2-fos-model"},
        {"category": "Agricultural And Food Sciences", "source": "s2-fos-model"}],
        "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2014-05-23",
        "journal": {"volume": "63", "pages": "441 - 445", "name": "Morbidity and Mortality
        Weekly Report"}, "authors": [{"authorId": "2250536028", "name": "Cassandra
        Harrison"}, {"authorId": "2251347448", "name": "Mohip Jorder"}, {"authorId":
        "2250610423", "name": "Henri Stern"}, {"authorId": "5144868", "name": "Faina
        Stavinsky"}, {"authorId": "145571127", "name": "V. Reddy"}, {"authorId": "2250707672",
        "name": "Heather Hanson"}, {"authorId": "2230796083", "name": "HaeNa A Waechter"},
        {"authorId": "2251020788", "name": "Luther Lowe"}, {"authorId": "2251343232",
        "name": "Luis Gravano"}, {"authorId": "4016664", "name": "S. Balter"}]}, {"paperId":
        "1d1482d336e3283046b6873ed4fa5f0a385c774d", "externalIds": {"MAG": "2796126483",
        "CorpusId": 264262795}, "corpusId": 264262795, "publicationVenue": {"id":
        "f68b9e7e-ad3d-46cb-857d-23e49384143c", "name": "ACM SIGMOD Conference", "type":
        "conference", "alternate_names": ["SIGMOD", "ACM SIGMOD Conf"], "url": "https://sigmod.org/conferences/"},
        "url": "https://www.semanticscholar.org/paper/1d1482d336e3283046b6873ed4fa5f0a385c774d",
        "title": "Proceedings of the 2012 ACM SIGMOD International Conference on Management
        of Data", "abstract": "We are delighted to welcome you to SIGMOD 2012, the
        2012 edition of the ACM SIGMOD International Conference on Management of Data,
        in Scottsdale, Arizona, in the Southwest of the United States. Scottsdale
        is in the heart of the Sonoran Desert and offers stunning desert vistas and
        a breathtaking setting for the conference. At the same time, Scottsdale is
        adjacent to Phoenix, one of the largest and fastest-growing cities in the
        United States. \n \nSIGMOD 2012 hosts an exciting technical program, with
        two keynote talks, by Pat Hanrahan (Stanford University and Tableau Software)
        and Amin Vahdat (University of California, San Diego and Google); a plenary
        session with \"Perspectives on Big Data,\" by Donald Kossmann (ETHZ), Kristen
        LeFevre (Google Research and University of Michigan), Sam Madden (MIT), and
        Anand Rajaraman (@WalmartLabs); 48 research paper presentations; six tutorials;
        30 demonstrations; and 18 industrial presentations. In addition to having
        full 30-minute presentation slots, research papers are included in one of
        two Research Plenary Poster Sessions. One of these sessions is jointly for
        PODS and SIGMOD research papers, to deepen the ties between the two conferences.
        Another new plenary poster session, for papers from the 11 workshops co-located
        with SIGMOD 2012, is an effort to strengthen the link and synergy between
        the workshops and the conference. \n \nSIGMOD 2012 includes several technical
        and social events designed specifically for student attendees. The SIGMOD/PODS
        2012 Ph.D. Symposium, the Database Mentoring Workshop, the Undergraduate Research
        Poster Competition, and the New Researcher Symposium are all established components
        of the SIGMOD program and are all part of SIGMOD 2012. The conference also
        hosts a session dedicated to highlighting the finalists of the SIGMOD Programming
        Contest. (This year''s task is to implement a multidimensional, high-throughput,
        in-memory indexing system.) In addition, the conference includes a new Information
        Session on Careers in Industry, aimed at bringing student attendees together
        with our Gold, Platinum, and Diamond sponsors, as well as \"vis-a-vis\" meetings
        aimed at helping Ph.D. students meet internationally recognized researchers
        in their research areas, to exchange ideas and receive guidance in a relaxed
        social setting.", "venue": "ACM SIGMOD Conference", "year": 2012, "referenceCount":
        0, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
        "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
        [{"category": "Computer Science", "source": "external"}, {"category": "Computer
        Science", "source": "s2-fos-model"}], "publicationTypes": ["Review"], "publicationDate":
        "2012-05-20", "journal": {"volume": "", "name": ""}, "authors": [{"authorId":
        "1972061357", "name": "K. Candan"}, {"authorId": "2259628029", "name": "Yi
        Chen"}, {"authorId": "2259241669", "name": "Richard T. Snodgrass"}, {"authorId":
        "2251343232", "name": "Luis Gravano"}, {"authorId": "2326719", "name": "A.
        Fuxman"}]}]}]}

        '
    headers:
      Access-Control-Allow-Origin:
      - '*'
      Connection:
      - keep-alive
      Content-Length:
      - '341856'
      Content-Type:
      - application/json
      Date:
      - Thu, 19 Oct 2023 18:07:32 GMT
      Via:
      - 1.1 91ac4dab8fb53750ccb2571903bd2844.cloudfront.net (CloudFront)
      X-Amz-Cf-Id:
      - iMwrRXslZcG4EQHlnkTLgPsbE5SyDf3WhrQr6hw7JGpvLmAWQ03vPg==
      X-Amz-Cf-Pop:
      - JFK52-P2
      X-Cache:
      - Miss from cloudfront
      x-amz-apigw-id:
      - ND5_vG3KPHcF3ZQ=
      x-amzn-Remapped-Connection:
      - keep-alive
      x-amzn-Remapped-Content-Length:
      - '341856'
      x-amzn-Remapped-Date:
      - Thu, 19 Oct 2023 18:07:32 GMT
      x-amzn-Remapped-Server:
      - gunicorn
      x-amzn-RequestId:
      - 3bf30fb6-3dd7-46d2-a92a-c6e7fb98c77f
    status:
      code: 200
      message: OK
version: 1
